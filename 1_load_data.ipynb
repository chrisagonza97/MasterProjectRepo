{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77432911-7a33-4016-a99d-a41d735a2684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel, scharr, apply_hysteresis_threshold, gaussian\n",
    "from skimage.feature import canny\n",
    "from skimage.measure import regionprops,regionprops_table\n",
    "from skimage.morphology import binary_opening, disk, binary_closing, binary_dilation, binary_erosion\n",
    "from skimage.draw import rectangle_perimeter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import label as scilabel\n",
    "import cv2\n",
    "import matplotlib; matplotlib.rcParams['figure.dpi']=300\n",
    "# make sure pytorch is installed\n",
    "# see this tutorial: https://github.com/jlevy44/medstudent_resident_informatics_tutorials/blob/main/1_image_analysis/1_image_analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f4aca-4b95-4e43-9a1a-c602c12c4b19",
   "metadata": {},
   "source": [
    "# Load cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925c5953-dade-4980-93d2-0dfde9748479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urothelial_cells=pd.read_pickle(\"urothelial_cell_toy_data.pkl\")\n",
    "images=np.transpose(urothelial_cells[\"X\"].numpy()*255,(0,2,3,1)).astype(np.uint8)\n",
    "labels=urothelial_cells[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82a2783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 256, 256, 3)\n",
      "torch.Size([200, 3, 256, 256])\n",
      "(200, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "urothelial_cells.keys()\n",
    "#print shape\n",
    "print(images.shape)\n",
    "print(urothelial_cells[\"X\"].shape)\n",
    "print(urothelial_cells[\"y\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec5498bc-84f0-403b-a84f-1033e52fb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_image=1\n",
    "img=images[idx_image]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4219c40b-fe6a-44d9-82f2-9de690de7412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "#plot respective segmentation mask in the y column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819d9e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19c0a3a62d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(labels[idx_image],alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60d44eac-4a24-45d9-adf1-9e7cde6b321f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_gray=rgb2gray(img)\n",
    "plt.imshow(img_gray,cmap=\"Greys_r\")\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b12d8daf-90f5-45e0-984f-53828356665c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[...,0],cmap=\"Reds\")\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b72fb6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  463.,  9956., 10794.,  5152.,  3323.,  1891.,  1357.,  1100.,\n",
       "         1237., 30263.]),\n",
       " array([0.03948824, 0.13553941, 0.23159059, 0.32764176, 0.42369294,\n",
       "        0.51974412, 0.61579529, 0.71184647, 0.80789765, 0.90394882,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(img_gray.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed7db268-8673-4d14-b32e-ae93bcf0df9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nucleus=img_gray<0.4\n",
    "plt.imshow(nucleus,cmap=\"Greys\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd7ec3de-0e66-472f-a0e6-d8ba33834a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nucleus=img_gray<0.4\n",
    "nucleus=binary_opening(nucleus,disk(5))\n",
    "nucleus=binary_closing(nucleus,disk(8))\n",
    "plt.imshow(nucleus,cmap=\"Greys\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12f2536f-786a-4f59-8b98-7cacc617d144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cytoplasm=np.logical_and(img_gray>=0.4,img_gray<=0.8)\n",
    "plt.imshow(cytoplasm,cmap=\"Greys\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e176717d-b487-4cc1-903c-f1e75f9dfd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nc_ratio_pred=nucleus.sum()/(nucleus.sum()+cytoplasm.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4b00769-af29-4bb8-aa88-34534faa3b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_mask=labels[idx_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f34b0a50-dc1d-4123-872b-84b521d56c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJAAAASQCAYAAACj0LUpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAC4jAAAuIwF4pT92AAAoAElEQVR4nO3d7XLbRqJFUeoWn7bxPOjXxVRq6k5FsrwtS5QAEGv9o8FIPflgPLtaJy/btm03AAAAAPiN//vdAwAAAAD4h4AEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAADp3o8BrmXOeXtmY4y9jwAAAJyQG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIL1s27b1WwCOZ8659xGewhhj7yMAAAAn4AYSAAAAAElAAgAAACAJSAAAAAAkAQkAAACAZEQbOBwD2edjjBsAAJ6bG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAA0r0fAzzenHPvIwAAAPAX3EACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQjGgDH2b8GgAA4JrcQAIAAAAgCUgAAAAAJAEJAAAAgGQDCYBXxhh7HwEAADgYN5AAAAAASAISAAAAAElAAgAAACDZQAK4MHtHAADAR7iBBAAAAEASkAAAAABIAhIAAAAASUACAAAAIBnRBrgQo9kAAMBnuIEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAApHs/huuac97OYoyx9xEAAAB4Ym4gAQAAAJAEJAAAAACSgAQAAABAsoHEJZ1p3+iz/3vsIgEAAPAobiABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIRrThSb0d1jaqDQAAwGe5gQQAAABAEpAAAAAASAISAAAAAMkGElyETaRz8dcHAAA4EjeQAAAAAEgCEgAAAABJQAIAAAAg2UDiEns/fO7PkR2en+PPNQAAcGRuIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgv27Zt/RaOzFg0nJPRbAAA4EzcQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASPd+zN7mnHsfAQAAALg4N5AAAAAASAISAAAAAElAAgAAACAJSAAAAACkl23btn4LP8VgNlzXGGPvIwAAAPyWG0gAAAAAJAEJAAAAgCQgAQAAAJDu/RiAZ9pAs7UEAAB8hhtIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAg3fsxAPzZnPPLX2OM8ZCz8Nwe8fcafCefZQA8KzeQAAAAAEgCEgAAAABJQAIAAAAgvWzbtvVbeBS7DQCPZWvk/Py7kSvy2QXAGbmBBAAAAEASkAAAAABIAhIAAAAA6d6P+R2bDQAAAMBVuIEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACDd+zEAAPBIc85Xr8cYu50FAD7KDSQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJBetm3bbhc359z7CAA8uTHGQ76Of2cBV/m8A+BY3EACAAAAIAlIAAAAACQBCQAAAIB0v52YHQgAAACA7+cGEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAdO/HAMAjzDl/+bUxxh/fAwAAR+AGEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgPSybdt2OyljowAAwHd6+x88ALgqN5AAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwNwVMuy3J7Zuq57HwEAbnPOX35tjLHLWQD25AYSAAAAAElAAgAAACAJSAAAAAAkAQkAAACAZEQb4CSefTT7I/97DWsDAMA+3EACAAAAIAlIAAAAACQBCQAAAIBkAwnggK62d/TZPy82kQAA4Ge4gQQAAABAEpAAAAAASAISAAAAAMkGEsAB2Dz6HJtIAADwM9xAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkIxoA+zAaPbP/Xk1rA0AAF/nBhIAAAAASUACAAAAIAlIAAAAADzPBtKcc+8jAPyRfaNj//WwiQQAAH/PDSQAAAAAkoAEAAAAQBKQAAAAADjvBpLNIwAezSYSAAD8PTeQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAut92Mufc61sDfNqyLHsfgQP8NV3X9VvOAgAAR+UGEgAAAABJQAIAAAAgCUgAAAAAHHMDCeAMbB7x0b8v7CIBAPDM3EACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQXrZt2247mHPu8W0B/sdANt/JqDbAdYwx9j4CwLdzAwkAAACAJCABAAAAkAQkAAAAAJINJOAybB6xJ5tIAHyVrSVgT24gAQAAAJAEJAAAAACSgAQAAABAuvdjAOBMG1y2luDjbOPtx2cVwPm4gQQAAABAEpAAAAAASAISAAAAAElAAgAAACC9bNu23XYw59zj2wJPyhAqfJ4xW87GZ/41+ay63cYYex8BuDA3kAAAAABIAhIAAAAASUACAAAAINlAAk7J/gV8L1sjfBef3zzKFT+nbCABe3IDCQAAAIAkIAEAAACQBCQAAAAAkg0k4HDsY8DxXHFrhMfwmc5PevbPKhtIwJ7cQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAOll27btdlBzzr2PAOxgWZa9jwB8wrquex+Bnfn85mh8Ln3MGGPvIwAn4AYSAAAAAElAAgAAACAJSAAAAACcdwPpLZtI8JxsZsA12CJ5Pj6/OTqfO59jEwl4jxtIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkhFt4McZXQU+ygDusfj85ux8pnyMEW3gPW4gAQAAAJAEJAAAAACSgAQAAADA82wgvWUTCY7PXgbw3WyafA+f31yVzxQbSMD73EACAAAAIAlIAAAAACQBCQAAAIBkAwl4KJsZwBldcfPE5zV8zBU/H2wgAe9xAwkAAACAJCABAAAAkAQkAAAAAJKABAAAAEC692MAgOsNSj/baK7BbADgq9xAAgAAACAJSAAAAAAkAQkAAACAZAMJ+BK7GsBVPtvOtIvksxn4ijnnq9djjN3OAhyHG0gAAAAAJAEJAAAAgCQgAQAAAJBetm3bbk/ys7nA97KpAXCOTSSf13Ddf/6P4r3dJNtKcG5uIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgHTvx8CVLcuy9xEA+ACf13Csf+bWdb1d3Zxz7yMAD+YGEgAAAABJQAIAAAAgCUgAAAAAJBtIAAAA37yRZBcJODs3kAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQj2nBR7407AnB8Pr/hOf7ZNaoNnI0bSAAAAAAkAQkAAACAJCABAAAAkGwgAQAcaM/ExhFcw2f+WbebBOzJDSQAAAAAkoAEAAAAQBKQAAAAAEgv27Ztt5Oac+59BDgNmxoAAM/l7JtIY4y9jwD8BTeQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAApHs/BgAA4Cz/kZSzD2sDx+UGEgAAAABJQAIAAAAgCUgAAAAApJdt27bbxc059z4C/MjPxAMAcC1H3kQaY+x9BOAvuIEEAAAAQBKQAAAAAEgCEgAAAADJBtIH2EjijGwgAQBwpk2ks7HhxNW4gQQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwMAAPAslmX55dfWdd3lLGc353z1eoyx21ngJ7iBBAAAAEASkAAAAABIAhIAAAAAyQYSAADAhb23i/RvNpKAf7iBBAAAAEASkAAAAABIAhIAAAAASUACAAAAIL1s27b1W5hz7n0E+NLwIQAAfCdD2x8zxtj7CPBpbiABAAAAkAQkAAAAAJKABAAAAEC692N+93OqdpEAAADe3+S0iQTPxw0kAAAAAJKABAAAAEASkAAAAABINpAAAAD41k2k99hJgnNxAwkAAACAJCABAAAAkAQkAAAAAJKABAAAAEAyog0AAMDuQ9tGteHY3EACAAAAIAlIAAAAACQBCQAAAIBkAwkAAIDDbSL9wy4SHIcbSAAAAAAkAQkAAACAJCABAAAAkF62bdv6LTzKnHPvI/DEPx8OAADP7uybSGOMvY8An+YGEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASPd+zCONMfL5nPPHzgIAAHA2y7L88T3ruv7IWeBq3EACAAAAIAlIAAAAACQBCQAAAIBkAwkAAICn3UmyiQSP4QYSAAAAAElAAgAAACAJSAAAAAAkAQkAAACAZEQbTjgECAAAnM+c8+Ffc4zx8K8J73EDCQAAAIAkIAEAAACQBCQAAAAAkg0kAAAALrMnuq7rbmeBM3MDCQAAAIAkIAEAAACQBCQAAAAAkg0kAAAALruJ9A+7SPBnbiABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIRrQPZIzxkK8z53zI1wEAALjisLZRbfiVG0gAAAAAJAEJAAAAgCQgAQAAAJBetm3b+i08GxtJ5/r5awAAYF9n20R61L4u/JsbSAAAAAAkAQkAAACAJCABAAAAkO79mGf03s/D2kUCAAD4+E7p2XaR4KvcQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAOnej4FHW5Zl7yMAAABPbM7513/MGOOvv+af/hieixtIAAAAACQBCQAAAIAkIAEAAACQbCABAADAF7dN13W9XW03iWtxAwkAAACAJCABAAAAkAQkAAAAAJKABAAAAEAyog0AAAAPHtV+z9mHtrk2N5AAAAAASAISAAAAAElAAgAAACDZQIKdfw4aAAC45v8/sInEmbiBBAAAAEASkAAAAABIAhIAAAAAyQYSAAAA7MAmEmfiBhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEj3fsxVjDFevZ5z7nYWAAAA4FjcQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAOnej7mqMcar13PO3c4CAABwBcuy/PJr67ruchZ4yw0kAAAAAJKABAAAAEASkAAAAABINpD41CbS0dlsAgAAnnEXySYSe3EDCQAAAIAkIAEAAACQBCQAAAAAkg0kAAAA4Mvbs2fbzuXvuIEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgGdEGAACAk1iW5dXrdV1vRx3V/i7GuvfhBhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgHTvx8BXrOv6y68ty7LLWQAAAOCz3EACAAAAIAlIAAAAACQBCQAAAIBkAwkAAABO6r2N1fe2WOGr3EACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAADp3o+BR1vXNZ8vy/JjZwEAAICPcAMJAAAAgCQgAQAAAJAEJAAAAACSDSSe0hjj4V9zzvnwrwkAAPBob3dV/7TDCh/hBhIAAAAASUACAAAAIAlIAAAAACQbSPCFXSW7SAAAAFyBG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSEW04mHVdf/m1ZVl2OQsAAAD8ww0kAAAAAJKABAAAAEASkAAAAABINpDgC8YYr17POXc7CwAAwHs+sqn63hYr/JsbSAAAAAAkAQkAAACAJCABAAAAkGwgwQm8/Xnkj/wMMwAAADyKG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACC9bNu29VuAj5pz7vJ9l2XZ5fsCAADPaV3X21GNMfY+wiW5gQQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIN33PgDwdeu6/vJry7LschYAAACejxtIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAADp3o8BAAAAjmPO+cf3jDF+5CxX4gYSAAAAAElAAgAAACAJSAAAAAAkAQkAAACAZEQbntS6rq9eL8uy21kAAACONrT9luHt5gYSAAAAAElAAgAAACAJSAAAAAAkG0jwQN/1M7Of+fldAAAAeBQ3kAAAAABIAhIAAAAASUACAAAAINlAghNuK9lEAgAA4Ce5gQQAAABAEpAAAAAASAISAAAAAElAAgAAACAZ0YaLWNf11etlWXY7CwAAAOfiBhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAdO/HwLNa1/WP71mW5UfOAgAAwLG5gQQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwNXtq7rq9fLsux2FgAAAPbjBhIAAAAASUACAAAAIAlIAAAAACQbSAAAAHBxb/dP4S03kAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQj2nBCY4xXr+ecuw3rLcvyI98bAACA/biBBAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAg3fsxQFvX9dXrZVl2OwsAAPDn37PDZ7iBBAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQ7v0Y4O+s6/rq9bIsu50FAACu6O3vyeER3EACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQjGgDPz7gZ1gbAADgXNxAAgAAACAJSAAAAAAkAQkAAACAZAMJntQYI5/POW9H2UWyiQQAAI/bHIXv4AYSAAAAAElAAgAAACAJSAAAAACkl23btn4LcFV77STZRAIAgPfZPDrOruzVuIEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgGdEGDj+q/R5D2wAAXJER7WMZFxradgMJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACC9bNu29VsA/mvOeTuqZVn2PgIAADzcuq57H4FvNsa4nYEbSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwOcd1zQsDYAAGdiMJsjcwMJAAAAgCQgAQAAAJAEJAAAAACSDSQAAADYgc0jzsQNJAAAAACSgAQAAABAEpAAAAAASC/btm39FoDHmnPu8n2XZdnl+wIAwD9sHvGeMcbtDNxAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkIxoA7szqg0AwNkZyOazjGgDAAAA8BQEJAAAAACSgAQAAABAuvdjgGv9nLpdJAAAPsLmEVfjBhIAAAAASUACAAAAIAlIAAAAACQbSMDuxhivXs85D/Oz7DaRAAAA3EACAAAA4A8EJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAdO/HANe2ruur18uy7HYWAACO8XtCuCI3kAAAAABIAhIAAAAASUACAAAAINlAAnjwz7/bSQIAAJ6NG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACDd+zEAf2td11evl2XZ7SwAAHz993OAG0gAAAAA/IGABAAAAEASkAAAAABINpAAdvgZertIAADAmbiBBAAAAEASkAAAAABIAhIAAAAASUACAAAAIBnRBg5njPEtX3fO+S1fFwAA4Nm5gQQAAABAEpAAAAAASAISAAAAAMkGEnDZbaU9N5HWdX31elmW3c4CAADwJ24gAQAAAJAEJAAAAACSgAQAAABAsoEEXNbbTaQ9d5FsIgEAAEfmBhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgv27Zt/RaA65hz3o5qWZa9jwAAcEnruu59BJ7YGON2Bm4gAQAAAJAEJAAAAACSgAQAAABAuvdjAI76s/c2kQAAgJ/iBhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEj3fgzAUa3r+ur1siy7nQUAAHhubiABAAAAkAQkAAAAAJKABAAAAEB62bZt67cAXMecc+8jfCs7SQAAf781CT9pjHE7IjeQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAApHs/BgAAAGDP/7DPEYa13UACAAAAIAlIAAAAACQBCQAAAIBkAwngQtZ1ffV6WZbdzgIAAHxuF2mPTSQ3kAAAAABIAhIAAAAASUACAAAAINlAAvjmnyV++/PKAAAAZ+MGEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASPd+DMBXjTF++bU55+0I1nX95deWZdnlLAAAwHG5gQQAAABAEpAAAAAASAISAAAAAMkGEgC5i2QTCQAAcAMJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAACkez8G4OrWdX31elmW3c4CAADsww0kAAAAAJKABAAAAEASkAAAAABINpAAdjDGePV6znk76ybSP+wiAQDAc3MDCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQDKiDXDAUe3P2HOI++2wtlFtAAB4Lm4gAQAAAJAEJAAAAACSgAQAAABAetm2beu3APAs9tpJsokEABzZ2z1HuMKG6t9yAwkAAACAJCABAAAAkAQkAAAAANK9HwPAz+wK2EkCAIDjcgMJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAACkez8GgJ+xruur18uy7HYWAADgNTeQAAAAAEgCEgAAAABJQAIAAAAg2UAC4BSbSO+xkwQAfMfvMYBfuYEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgGdEGuJAxxpe/xpzzdtQRTKPaAADwPdxAAgAAACAJSAAAAAAkAQkAAACAZAMJgIfvKO21k/R2E+k9dpIAAODvuYEEAAAAQBKQAAAAAEgCEgAAAADJBhIAl/KRnaS37CYBwLX+3Q/8yg0kAAAAAJKABAAAAEASkAAAAABIAhIAAAAAyYg2ADxgfNPQNgAAz8wNJAAAAACSgAQAAABAEpAAAAAASDaQAOAbdpJsIgHAcbcLgb/nBhIAAAAASUACAAAAIAlIAAAAAKSXbdu2fgsAHNOc8/ZM7CYBQLNvBP81xrj9NDeQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAuvdjAOCnrOv613/MsizfchYAOOu/G4Hv4QYSAAAAAElAAgAAACAJSAAAAAAkG0gAcGJ2kwB4FvaO4NjcQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJBetm3b+i0AcA5zzr2P8DQMbQPw3Yxmw+eNMW4/zQ0kAAAAAJKABAAAAEASkAAAAABI934MAFzRZ3Yp7CYBUGwewXH3jT7CDSQAAAAAkoAEAAAAQBKQAAAAAEgv27Zt/RYAuLY5595HuAw7SgDPwd4RnH/z6C03kAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQj2gDwAIa2f4aRbYBjMpoNn2dEGwAAAICnICABAAAAkAQkAAAAAJINJAA4CDtKP8eWEsDv2TOCnzVsIAEAAADwDAQkAAAAAJKABAAAAECygQQAJ2In6TjsKAHPwuYR7GvYQAIAAADgGQhIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAADp3o8BAHjPuq4/8n2WZfmR7wM8p5/6rAKenxtIAAAAACQBCQAAAIAkIAEAAACQbCABwEHMOfc+AifdL7GTBNdgzwjYkxtIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAA0su2bVu/BQC4GoPeGOaGxzKADfzOGON2Bm4gAQAAAJAEJAAAAACSgAQAAABAsoEEAOzG1hK2ljgje0bAI9lAAgAAAOApCEgAAAAAJAEJAAAAgHTvxwAA8H1sydiB+k7+/gJ4HDeQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJCPaAACwI0PPAJyBG0gAAAAAJAEJAAAAgCQgAQAAAJBsIAEAuxljvHo959ztLAAA/J4bSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIN37MQDAzxlj7H0ETmDOufcRAOBy3EACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEj3fgwAAMcyxnjI15lzPuTrAMAVuIEEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACDd+zEAADynMcbtCOacex8BAP7IDSQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIN37MQAA8J3GGL/82pxzl7MAwO+4gQQAAABAEpAAAAAASAISAAAAAMkGEgAAnGAX6avsKgHwFW4gAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASEa0AQDgosPchrUB+Cg3kAAAAABIAhIAAAAASUACAAAAINlAAgCAi3pvF+lP7CYBXJMbSAAAAAAkAQkAAACAJCABAAAAkGwgAQAAn95NsokEcA1uIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgPSybdvWbwEAADiWOefeRwCe3Bhj7yMcihtIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgvWzbtvVbAAAA+H9zzr2PAHyDMcbeRzg0N5AAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwMAAPBvY4xXr+ecu50F4Ke4gQQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANK9HwMAAFDGGF/+GnPOh5wF4Lu4gQQAAABAEpAAAAAASAISAAAAAMkGEgAAwAl2lOwkAXtyAwkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASC/btm39FgAAAI5mzrn3EeC0xhh7H+F03EACAAAAIAlIAAAAACQBCQAAAIBkAwkAAIDd2XQ6HztC1+IGEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASPd+DAAAAI8359z7CMBfcAMJAAAAgCQgAQAAAJAEJAAAAACSDSQAAAAeyr4RPB83kAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQj2gAAAPyPAWzgPW4gAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJDu/RgAAAA4szHG3kfgCbiBBAAAAEASkAAAAABIAhIAAAAAyQYSAAAAnJR9I36KG0gAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAANLLtm1bvwUAAACAK3MDCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAAEgCEgAAAABJQAIAAAAgCUgAAAAAJAEJAAAAgCQgAQAAAJAEJAAAAACSgAQAAABAEpAAAAAASAISAAAAAElAAgAAACAJSAAAAAAkAQkAAACAJCABAAAAkAQkAAAAAJKABAAAAEASkAAAAABIAhIAAAAASUACAAAAIAlIAAAAACQBCQAAAIAkIAEAAACQBCQAAAAAkoAEAAAAQBKQAAAAALiV/wCyWej+dolEBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(segmentation_mask,cmap=\"Greys\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81eb7916-4d16-43cb-bb71-480e86819547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cytoplasm_true=(segmentation_mask==1)\n",
    "nucleus_true=(segmentation_mask==2)\n",
    "nc_ratio_true=nucleus_true.sum()/(nucleus_true.sum()+cytoplasm_true.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a274b377-3c7e-4e7c-ae11-36affbdee630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5972044387537345), np.float64(0.7440235814296242))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_ratio_true,nc_ratio_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf40e520-1a7d-431c-8a05-9244cff8557b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(255.5), np.float64(255.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges=binary_dilation(canny(img_gray, sigma=2.),disk(2))\n",
    "img_new=img.copy()\n",
    "img_new[edges]=[255,0,0]\n",
    "plt.imshow(img_new)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc8553-b52f-435a-a257-bdd71bba3694",
   "metadata": {},
   "source": [
    "# Generate labels for deep learning analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7a259de-4982-4c08-ab13-28b9d4b94a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([160, 3, 256, 256])\n",
      "Y_train shape: torch.Size([160, 256, 256])\n",
      "X_val shape: torch.Size([40, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "X = urothelial_cells[\"X\"].numpy()  # (200, 3, 256, 256)\n",
    "Y = urothelial_cells[\"y\"]\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train = torch.FloatTensor(X_train)  # (N, C, H, W)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "Y_train = torch.LongTensor(Y_train)  # (N, 1, H, W)\n",
    "Y_val = torch.LongTensor(Y_val)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"X_train shape: {X_train.shape}\")  # Expected: (160, 3, 256, 256)\n",
    "print(f\"Y_train shape: {Y_train.shape}\")  # Expected: (160, 256, 256)\n",
    "print(f\"X_val shape: {X_val.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de85e4-bd76-471d-9512-662de831c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([160, 3, 256, 256])\n",
      "Y_train shape: torch.Size([160, 256, 256])\n",
      "Using device: cuda\n",
      "Training: Epoch 1, Batch 0, Loss: 1.25\n",
      "Training: Epoch 1, Batch 1, Loss: 1.038\n",
      "Training: Epoch 1, Batch 2, Loss: 0.999\n",
      "Training: Epoch 1, Batch 3, Loss: 0.982\n",
      "Training: Epoch 1, Batch 4, Loss: 0.992\n",
      "Training: Epoch 1, Batch 5, Loss: 0.751\n",
      "Training: Epoch 1, Batch 6, Loss: 0.816\n",
      "Training: Epoch 1, Batch 7, Loss: 0.757\n",
      "Training: Epoch 1, Batch 8, Loss: 0.944\n",
      "Training: Epoch 1, Batch 9, Loss: 0.663\n",
      "Training: Epoch 1, Batch 10, Loss: 0.592\n",
      "Training: Epoch 1, Batch 11, Loss: 0.871\n",
      "Training: Epoch 1, Batch 12, Loss: 0.714\n",
      "Training: Epoch 1, Batch 13, Loss: 0.719\n",
      "Training: Epoch 1, Batch 14, Loss: 0.719\n",
      "Training: Epoch 1, Batch 15, Loss: 0.649\n",
      "Training: Epoch 1, Batch 16, Loss: 0.586\n",
      "Training: Epoch 1, Batch 17, Loss: 0.536\n",
      "Training: Epoch 1, Batch 18, Loss: 0.604\n",
      "Training: Epoch 1, Batch 19, Loss: 0.637\n",
      "Val: Epoch 1, Loss: 1.146\n",
      "Training: Epoch 2, Batch 0, Loss: 0.51\n",
      "Training: Epoch 2, Batch 1, Loss: 0.482\n",
      "Training: Epoch 2, Batch 2, Loss: 0.47\n",
      "Training: Epoch 2, Batch 3, Loss: 0.612\n",
      "Training: Epoch 2, Batch 4, Loss: 0.497\n",
      "Training: Epoch 2, Batch 5, Loss: 0.523\n",
      "Training: Epoch 2, Batch 6, Loss: 0.502\n",
      "Training: Epoch 2, Batch 7, Loss: 0.617\n",
      "Training: Epoch 2, Batch 8, Loss: 0.583\n",
      "Training: Epoch 2, Batch 9, Loss: 0.529\n",
      "Training: Epoch 2, Batch 10, Loss: 0.442\n",
      "Training: Epoch 2, Batch 11, Loss: 0.471\n",
      "Training: Epoch 2, Batch 12, Loss: 0.597\n",
      "Training: Epoch 2, Batch 13, Loss: 0.452\n",
      "Training: Epoch 2, Batch 14, Loss: 0.428\n",
      "Training: Epoch 2, Batch 15, Loss: 0.428\n",
      "Training: Epoch 2, Batch 16, Loss: 0.56\n",
      "Training: Epoch 2, Batch 17, Loss: 0.361\n",
      "Training: Epoch 2, Batch 18, Loss: 0.408\n",
      "Training: Epoch 2, Batch 19, Loss: 0.429\n",
      "Val: Epoch 2, Loss: 0.505\n",
      "Training: Epoch 3, Batch 0, Loss: 0.389\n",
      "Training: Epoch 3, Batch 1, Loss: 0.471\n",
      "Training: Epoch 3, Batch 2, Loss: 0.432\n",
      "Training: Epoch 3, Batch 3, Loss: 0.334\n",
      "Training: Epoch 3, Batch 4, Loss: 0.462\n",
      "Training: Epoch 3, Batch 5, Loss: 0.475\n",
      "Training: Epoch 3, Batch 6, Loss: 0.407\n",
      "Training: Epoch 3, Batch 7, Loss: 0.581\n",
      "Training: Epoch 3, Batch 8, Loss: 0.373\n",
      "Training: Epoch 3, Batch 9, Loss: 0.387\n",
      "Training: Epoch 3, Batch 10, Loss: 0.416\n",
      "Training: Epoch 3, Batch 11, Loss: 0.317\n",
      "Training: Epoch 3, Batch 12, Loss: 0.377\n",
      "Training: Epoch 3, Batch 13, Loss: 0.37\n",
      "Training: Epoch 3, Batch 14, Loss: 0.343\n",
      "Training: Epoch 3, Batch 15, Loss: 0.33\n",
      "Training: Epoch 3, Batch 16, Loss: 0.447\n",
      "Training: Epoch 3, Batch 17, Loss: 0.309\n",
      "Training: Epoch 3, Batch 18, Loss: 0.351\n",
      "Training: Epoch 3, Batch 19, Loss: 0.316\n",
      "Val: Epoch 3, Loss: 0.407\n",
      "Training: Epoch 4, Batch 0, Loss: 0.288\n",
      "Training: Epoch 4, Batch 1, Loss: 0.347\n",
      "Training: Epoch 4, Batch 2, Loss: 0.338\n",
      "Training: Epoch 4, Batch 3, Loss: 0.446\n",
      "Training: Epoch 4, Batch 4, Loss: 0.345\n",
      "Training: Epoch 4, Batch 5, Loss: 0.268\n",
      "Training: Epoch 4, Batch 6, Loss: 0.323\n",
      "Training: Epoch 4, Batch 7, Loss: 0.298\n",
      "Training: Epoch 4, Batch 8, Loss: 0.296\n",
      "Training: Epoch 4, Batch 9, Loss: 0.398\n",
      "Training: Epoch 4, Batch 10, Loss: 0.319\n",
      "Training: Epoch 4, Batch 11, Loss: 0.341\n",
      "Training: Epoch 4, Batch 12, Loss: 0.333\n",
      "Training: Epoch 4, Batch 13, Loss: 0.45\n",
      "Training: Epoch 4, Batch 14, Loss: 0.357\n",
      "Training: Epoch 4, Batch 15, Loss: 0.367\n",
      "Training: Epoch 4, Batch 16, Loss: 0.375\n",
      "Training: Epoch 4, Batch 17, Loss: 0.275\n",
      "Training: Epoch 4, Batch 18, Loss: 0.286\n",
      "Training: Epoch 4, Batch 19, Loss: 0.282\n",
      "Val: Epoch 4, Loss: 0.331\n",
      "Training: Epoch 5, Batch 0, Loss: 0.267\n",
      "Training: Epoch 5, Batch 1, Loss: 0.358\n",
      "Training: Epoch 5, Batch 2, Loss: 0.333\n",
      "Training: Epoch 5, Batch 3, Loss: 0.328\n",
      "Training: Epoch 5, Batch 4, Loss: 0.251\n",
      "Training: Epoch 5, Batch 5, Loss: 0.255\n",
      "Training: Epoch 5, Batch 6, Loss: 0.276\n",
      "Training: Epoch 5, Batch 7, Loss: 0.251\n",
      "Training: Epoch 5, Batch 8, Loss: 0.282\n",
      "Training: Epoch 5, Batch 9, Loss: 0.253\n",
      "Training: Epoch 5, Batch 10, Loss: 0.256\n",
      "Training: Epoch 5, Batch 11, Loss: 0.305\n",
      "Training: Epoch 5, Batch 12, Loss: 0.227\n",
      "Training: Epoch 5, Batch 13, Loss: 0.276\n",
      "Training: Epoch 5, Batch 14, Loss: 0.333\n",
      "Training: Epoch 5, Batch 15, Loss: 0.246\n",
      "Training: Epoch 5, Batch 16, Loss: 0.247\n",
      "Training: Epoch 5, Batch 17, Loss: 0.292\n",
      "Training: Epoch 5, Batch 18, Loss: 0.437\n",
      "Training: Epoch 5, Batch 19, Loss: 0.249\n",
      "Val: Epoch 5, Loss: 0.646\n",
      "Training: Epoch 6, Batch 0, Loss: 0.263\n",
      "Training: Epoch 6, Batch 1, Loss: 0.295\n",
      "Training: Epoch 6, Batch 2, Loss: 0.253\n",
      "Training: Epoch 6, Batch 3, Loss: 0.28\n",
      "Training: Epoch 6, Batch 4, Loss: 0.22\n",
      "Training: Epoch 6, Batch 5, Loss: 0.269\n",
      "Training: Epoch 6, Batch 6, Loss: 0.286\n",
      "Training: Epoch 6, Batch 7, Loss: 0.27\n",
      "Training: Epoch 6, Batch 8, Loss: 0.29\n",
      "Training: Epoch 6, Batch 9, Loss: 0.295\n",
      "Training: Epoch 6, Batch 10, Loss: 0.279\n",
      "Training: Epoch 6, Batch 11, Loss: 0.275\n",
      "Training: Epoch 6, Batch 12, Loss: 0.252\n",
      "Training: Epoch 6, Batch 13, Loss: 0.341\n",
      "Training: Epoch 6, Batch 14, Loss: 0.412\n",
      "Training: Epoch 6, Batch 15, Loss: 0.219\n",
      "Training: Epoch 6, Batch 16, Loss: 0.262\n",
      "Training: Epoch 6, Batch 17, Loss: 0.263\n",
      "Training: Epoch 6, Batch 18, Loss: 0.295\n",
      "Training: Epoch 6, Batch 19, Loss: 0.293\n",
      "Val: Epoch 6, Loss: 0.39\n",
      "Training: Epoch 7, Batch 0, Loss: 0.247\n",
      "Training: Epoch 7, Batch 1, Loss: 0.265\n",
      "Training: Epoch 7, Batch 2, Loss: 0.22\n",
      "Training: Epoch 7, Batch 3, Loss: 0.261\n",
      "Training: Epoch 7, Batch 4, Loss: 0.225\n",
      "Training: Epoch 7, Batch 5, Loss: 0.394\n",
      "Training: Epoch 7, Batch 6, Loss: 0.301\n",
      "Training: Epoch 7, Batch 7, Loss: 0.268\n",
      "Training: Epoch 7, Batch 8, Loss: 0.337\n",
      "Training: Epoch 7, Batch 9, Loss: 0.358\n",
      "Training: Epoch 7, Batch 10, Loss: 0.248\n",
      "Training: Epoch 7, Batch 11, Loss: 0.426\n",
      "Training: Epoch 7, Batch 12, Loss: 0.283\n",
      "Training: Epoch 7, Batch 13, Loss: 0.287\n",
      "Training: Epoch 7, Batch 14, Loss: 0.273\n",
      "Training: Epoch 7, Batch 15, Loss: 0.265\n",
      "Training: Epoch 7, Batch 16, Loss: 0.251\n",
      "Training: Epoch 7, Batch 17, Loss: 0.372\n",
      "Training: Epoch 7, Batch 18, Loss: 0.294\n",
      "Training: Epoch 7, Batch 19, Loss: 0.305\n",
      "Val: Epoch 7, Loss: 0.329\n",
      "Training: Epoch 8, Batch 0, Loss: 0.227\n",
      "Training: Epoch 8, Batch 1, Loss: 0.323\n",
      "Training: Epoch 8, Batch 2, Loss: 0.266\n",
      "Training: Epoch 8, Batch 3, Loss: 0.282\n",
      "Training: Epoch 8, Batch 4, Loss: 0.228\n",
      "Training: Epoch 8, Batch 5, Loss: 0.221\n",
      "Training: Epoch 8, Batch 6, Loss: 0.236\n",
      "Training: Epoch 8, Batch 7, Loss: 0.536\n",
      "Training: Epoch 8, Batch 8, Loss: 0.224\n",
      "Training: Epoch 8, Batch 9, Loss: 0.26\n",
      "Training: Epoch 8, Batch 10, Loss: 0.244\n",
      "Training: Epoch 8, Batch 11, Loss: 0.244\n",
      "Training: Epoch 8, Batch 12, Loss: 0.251\n",
      "Training: Epoch 8, Batch 13, Loss: 0.211\n",
      "Training: Epoch 8, Batch 14, Loss: 0.274\n",
      "Training: Epoch 8, Batch 15, Loss: 0.26\n",
      "Training: Epoch 8, Batch 16, Loss: 0.235\n",
      "Training: Epoch 8, Batch 17, Loss: 0.266\n",
      "Training: Epoch 8, Batch 18, Loss: 0.197\n",
      "Training: Epoch 8, Batch 19, Loss: 0.192\n",
      "Val: Epoch 8, Loss: 0.402\n",
      "Training: Epoch 9, Batch 0, Loss: 0.194\n",
      "Training: Epoch 9, Batch 1, Loss: 0.24\n",
      "Training: Epoch 9, Batch 2, Loss: 0.222\n",
      "Training: Epoch 9, Batch 3, Loss: 0.194\n",
      "Training: Epoch 9, Batch 4, Loss: 0.195\n",
      "Training: Epoch 9, Batch 5, Loss: 0.216\n",
      "Training: Epoch 9, Batch 6, Loss: 0.332\n",
      "Training: Epoch 9, Batch 7, Loss: 0.261\n",
      "Training: Epoch 9, Batch 8, Loss: 0.193\n",
      "Training: Epoch 9, Batch 9, Loss: 0.194\n",
      "Training: Epoch 9, Batch 10, Loss: 0.248\n",
      "Training: Epoch 9, Batch 11, Loss: 0.204\n",
      "Training: Epoch 9, Batch 12, Loss: 0.247\n",
      "Training: Epoch 9, Batch 13, Loss: 0.159\n",
      "Training: Epoch 9, Batch 14, Loss: 0.155\n",
      "Training: Epoch 9, Batch 15, Loss: 0.187\n",
      "Training: Epoch 9, Batch 16, Loss: 0.243\n",
      "Training: Epoch 9, Batch 17, Loss: 0.189\n",
      "Training: Epoch 9, Batch 18, Loss: 0.212\n",
      "Training: Epoch 9, Batch 19, Loss: 0.191\n",
      "Val: Epoch 9, Loss: 0.393\n",
      "Training: Epoch 10, Batch 0, Loss: 0.17\n",
      "Training: Epoch 10, Batch 1, Loss: 0.217\n",
      "Training: Epoch 10, Batch 2, Loss: 0.323\n",
      "Training: Epoch 10, Batch 3, Loss: 0.168\n",
      "Training: Epoch 10, Batch 4, Loss: 0.18\n",
      "Training: Epoch 10, Batch 5, Loss: 0.263\n",
      "Training: Epoch 10, Batch 6, Loss: 0.292\n",
      "Training: Epoch 10, Batch 7, Loss: 0.238\n",
      "Training: Epoch 10, Batch 8, Loss: 0.298\n",
      "Training: Epoch 10, Batch 9, Loss: 0.218\n",
      "Training: Epoch 10, Batch 10, Loss: 0.224\n",
      "Training: Epoch 10, Batch 11, Loss: 0.309\n",
      "Training: Epoch 10, Batch 12, Loss: 0.216\n",
      "Training: Epoch 10, Batch 13, Loss: 0.275\n",
      "Training: Epoch 10, Batch 14, Loss: 0.177\n",
      "Training: Epoch 10, Batch 15, Loss: 0.199\n",
      "Training: Epoch 10, Batch 16, Loss: 0.188\n",
      "Training: Epoch 10, Batch 17, Loss: 0.22\n",
      "Training: Epoch 10, Batch 18, Loss: 0.212\n",
      "Training: Epoch 10, Batch 19, Loss: 0.209\n",
      "Val: Epoch 10, Loss: 0.373\n",
      "Training: Epoch 11, Batch 0, Loss: 0.213\n",
      "Training: Epoch 11, Batch 1, Loss: 0.234\n",
      "Training: Epoch 11, Batch 2, Loss: 0.166\n",
      "Training: Epoch 11, Batch 3, Loss: 0.221\n",
      "Training: Epoch 11, Batch 4, Loss: 0.227\n",
      "Training: Epoch 11, Batch 5, Loss: 0.219\n",
      "Training: Epoch 11, Batch 6, Loss: 0.187\n",
      "Training: Epoch 11, Batch 7, Loss: 0.196\n",
      "Training: Epoch 11, Batch 8, Loss: 0.243\n",
      "Training: Epoch 11, Batch 9, Loss: 0.158\n",
      "Training: Epoch 11, Batch 10, Loss: 0.31\n",
      "Training: Epoch 11, Batch 11, Loss: 0.193\n",
      "Training: Epoch 11, Batch 12, Loss: 0.167\n",
      "Training: Epoch 11, Batch 13, Loss: 0.17\n",
      "Training: Epoch 11, Batch 14, Loss: 0.216\n",
      "Training: Epoch 11, Batch 15, Loss: 0.21\n",
      "Training: Epoch 11, Batch 16, Loss: 0.315\n",
      "Training: Epoch 11, Batch 17, Loss: 0.226\n",
      "Training: Epoch 11, Batch 18, Loss: 0.169\n",
      "Training: Epoch 11, Batch 19, Loss: 0.2\n",
      "Val: Epoch 11, Loss: 0.411\n",
      "Training: Epoch 12, Batch 0, Loss: 0.185\n",
      "Training: Epoch 12, Batch 1, Loss: 0.161\n",
      "Training: Epoch 12, Batch 2, Loss: 0.177\n",
      "Training: Epoch 12, Batch 3, Loss: 0.175\n",
      "Training: Epoch 12, Batch 4, Loss: 0.194\n",
      "Training: Epoch 12, Batch 5, Loss: 0.17\n",
      "Training: Epoch 12, Batch 6, Loss: 0.174\n",
      "Training: Epoch 12, Batch 7, Loss: 0.167\n",
      "Training: Epoch 12, Batch 8, Loss: 0.185\n",
      "Training: Epoch 12, Batch 9, Loss: 0.141\n",
      "Training: Epoch 12, Batch 10, Loss: 0.181\n",
      "Training: Epoch 12, Batch 11, Loss: 0.15\n",
      "Training: Epoch 12, Batch 12, Loss: 0.185\n",
      "Training: Epoch 12, Batch 13, Loss: 0.158\n",
      "Training: Epoch 12, Batch 14, Loss: 0.155\n",
      "Training: Epoch 12, Batch 15, Loss: 0.192\n",
      "Training: Epoch 12, Batch 16, Loss: 0.154\n",
      "Training: Epoch 12, Batch 17, Loss: 0.155\n",
      "Training: Epoch 12, Batch 18, Loss: 0.141\n",
      "Training: Epoch 12, Batch 19, Loss: 0.182\n",
      "Val: Epoch 12, Loss: 0.324\n",
      "Training: Epoch 13, Batch 0, Loss: 0.133\n",
      "Training: Epoch 13, Batch 1, Loss: 0.201\n",
      "Training: Epoch 13, Batch 2, Loss: 0.152\n",
      "Training: Epoch 13, Batch 3, Loss: 0.151\n",
      "Training: Epoch 13, Batch 4, Loss: 0.148\n",
      "Training: Epoch 13, Batch 5, Loss: 0.176\n",
      "Training: Epoch 13, Batch 6, Loss: 0.14\n",
      "Training: Epoch 13, Batch 7, Loss: 0.122\n",
      "Training: Epoch 13, Batch 8, Loss: 0.183\n",
      "Training: Epoch 13, Batch 9, Loss: 0.229\n",
      "Training: Epoch 13, Batch 10, Loss: 0.168\n",
      "Training: Epoch 13, Batch 11, Loss: 0.168\n",
      "Training: Epoch 13, Batch 12, Loss: 0.233\n",
      "Training: Epoch 13, Batch 13, Loss: 0.187\n",
      "Training: Epoch 13, Batch 14, Loss: 0.146\n",
      "Training: Epoch 13, Batch 15, Loss: 0.143\n",
      "Training: Epoch 13, Batch 16, Loss: 0.16\n",
      "Training: Epoch 13, Batch 17, Loss: 0.147\n",
      "Training: Epoch 13, Batch 18, Loss: 0.156\n",
      "Training: Epoch 13, Batch 19, Loss: 0.164\n",
      "Val: Epoch 13, Loss: 0.29\n",
      "Training: Epoch 14, Batch 0, Loss: 0.295\n",
      "Training: Epoch 14, Batch 1, Loss: 0.142\n",
      "Training: Epoch 14, Batch 2, Loss: 0.148\n",
      "Training: Epoch 14, Batch 3, Loss: 0.166\n",
      "Training: Epoch 14, Batch 4, Loss: 0.132\n",
      "Training: Epoch 14, Batch 5, Loss: 0.173\n",
      "Training: Epoch 14, Batch 6, Loss: 0.139\n",
      "Training: Epoch 14, Batch 7, Loss: 0.14\n",
      "Training: Epoch 14, Batch 8, Loss: 0.166\n",
      "Training: Epoch 14, Batch 9, Loss: 0.162\n",
      "Training: Epoch 14, Batch 10, Loss: 0.159\n",
      "Training: Epoch 14, Batch 11, Loss: 0.136\n",
      "Training: Epoch 14, Batch 12, Loss: 0.238\n",
      "Training: Epoch 14, Batch 13, Loss: 0.15\n",
      "Training: Epoch 14, Batch 14, Loss: 0.207\n",
      "Training: Epoch 14, Batch 15, Loss: 0.157\n",
      "Training: Epoch 14, Batch 16, Loss: 0.148\n",
      "Training: Epoch 14, Batch 17, Loss: 0.163\n",
      "Training: Epoch 14, Batch 18, Loss: 0.178\n",
      "Training: Epoch 14, Batch 19, Loss: 0.155\n",
      "Val: Epoch 14, Loss: 0.277\n",
      "Training: Epoch 15, Batch 0, Loss: 0.151\n",
      "Training: Epoch 15, Batch 1, Loss: 0.131\n",
      "Training: Epoch 15, Batch 2, Loss: 0.13\n",
      "Training: Epoch 15, Batch 3, Loss: 0.156\n",
      "Training: Epoch 15, Batch 4, Loss: 0.141\n",
      "Training: Epoch 15, Batch 5, Loss: 0.13\n",
      "Training: Epoch 15, Batch 6, Loss: 0.13\n",
      "Training: Epoch 15, Batch 7, Loss: 0.154\n",
      "Training: Epoch 15, Batch 8, Loss: 0.183\n",
      "Training: Epoch 15, Batch 9, Loss: 0.193\n",
      "Training: Epoch 15, Batch 10, Loss: 0.152\n",
      "Training: Epoch 15, Batch 11, Loss: 0.187\n",
      "Training: Epoch 15, Batch 12, Loss: 0.205\n",
      "Training: Epoch 15, Batch 13, Loss: 0.211\n",
      "Training: Epoch 15, Batch 14, Loss: 0.139\n",
      "Training: Epoch 15, Batch 15, Loss: 0.227\n",
      "Training: Epoch 15, Batch 16, Loss: 0.189\n",
      "Training: Epoch 15, Batch 17, Loss: 0.164\n",
      "Training: Epoch 15, Batch 18, Loss: 0.123\n",
      "Training: Epoch 15, Batch 19, Loss: 0.153\n",
      "Val: Epoch 15, Loss: 0.377\n",
      "Training: Epoch 16, Batch 0, Loss: 0.154\n",
      "Training: Epoch 16, Batch 1, Loss: 0.125\n",
      "Training: Epoch 16, Batch 2, Loss: 0.152\n",
      "Training: Epoch 16, Batch 3, Loss: 0.12\n",
      "Training: Epoch 16, Batch 4, Loss: 0.134\n",
      "Training: Epoch 16, Batch 5, Loss: 0.131\n",
      "Training: Epoch 16, Batch 6, Loss: 0.151\n",
      "Training: Epoch 16, Batch 7, Loss: 0.174\n",
      "Training: Epoch 16, Batch 8, Loss: 0.149\n",
      "Training: Epoch 16, Batch 9, Loss: 0.223\n",
      "Training: Epoch 16, Batch 10, Loss: 0.147\n",
      "Training: Epoch 16, Batch 11, Loss: 0.168\n",
      "Training: Epoch 16, Batch 12, Loss: 0.149\n",
      "Training: Epoch 16, Batch 13, Loss: 0.125\n",
      "Training: Epoch 16, Batch 14, Loss: 0.141\n",
      "Training: Epoch 16, Batch 15, Loss: 0.128\n",
      "Training: Epoch 16, Batch 16, Loss: 0.135\n",
      "Training: Epoch 16, Batch 17, Loss: 0.189\n",
      "Training: Epoch 16, Batch 18, Loss: 0.149\n",
      "Training: Epoch 16, Batch 19, Loss: 0.212\n",
      "Val: Epoch 16, Loss: 0.333\n",
      "Training: Epoch 17, Batch 0, Loss: 0.121\n",
      "Training: Epoch 17, Batch 1, Loss: 0.127\n",
      "Training: Epoch 17, Batch 2, Loss: 0.121\n",
      "Training: Epoch 17, Batch 3, Loss: 0.165\n",
      "Training: Epoch 17, Batch 4, Loss: 0.131\n",
      "Training: Epoch 17, Batch 5, Loss: 0.162\n",
      "Training: Epoch 17, Batch 6, Loss: 0.161\n",
      "Training: Epoch 17, Batch 7, Loss: 0.145\n",
      "Training: Epoch 17, Batch 8, Loss: 0.13\n",
      "Training: Epoch 17, Batch 9, Loss: 0.132\n",
      "Training: Epoch 17, Batch 10, Loss: 0.163\n",
      "Training: Epoch 17, Batch 11, Loss: 0.138\n",
      "Training: Epoch 17, Batch 12, Loss: 0.116\n",
      "Training: Epoch 17, Batch 13, Loss: 0.112\n",
      "Training: Epoch 17, Batch 14, Loss: 0.115\n",
      "Training: Epoch 17, Batch 15, Loss: 0.122\n",
      "Training: Epoch 17, Batch 16, Loss: 0.107\n",
      "Training: Epoch 17, Batch 17, Loss: 0.163\n",
      "Training: Epoch 17, Batch 18, Loss: 0.156\n",
      "Training: Epoch 17, Batch 19, Loss: 0.13\n",
      "Val: Epoch 17, Loss: 0.384\n",
      "Training: Epoch 18, Batch 0, Loss: 0.135\n",
      "Training: Epoch 18, Batch 1, Loss: 0.115\n",
      "Training: Epoch 18, Batch 2, Loss: 0.142\n",
      "Training: Epoch 18, Batch 3, Loss: 0.123\n",
      "Training: Epoch 18, Batch 4, Loss: 0.12\n",
      "Training: Epoch 18, Batch 5, Loss: 0.129\n",
      "Training: Epoch 18, Batch 6, Loss: 0.136\n",
      "Training: Epoch 18, Batch 7, Loss: 0.119\n",
      "Training: Epoch 18, Batch 8, Loss: 0.123\n",
      "Training: Epoch 18, Batch 9, Loss: 0.12\n",
      "Training: Epoch 18, Batch 10, Loss: 0.113\n",
      "Training: Epoch 18, Batch 11, Loss: 0.125\n",
      "Training: Epoch 18, Batch 12, Loss: 0.112\n",
      "Training: Epoch 18, Batch 13, Loss: 0.116\n",
      "Training: Epoch 18, Batch 14, Loss: 0.116\n",
      "Training: Epoch 18, Batch 15, Loss: 0.111\n",
      "Training: Epoch 18, Batch 16, Loss: 0.131\n",
      "Training: Epoch 18, Batch 17, Loss: 0.155\n",
      "Training: Epoch 18, Batch 18, Loss: 0.153\n",
      "Training: Epoch 18, Batch 19, Loss: 0.105\n",
      "Val: Epoch 18, Loss: 0.323\n",
      "Training: Epoch 19, Batch 0, Loss: 0.153\n",
      "Training: Epoch 19, Batch 1, Loss: 0.132\n",
      "Training: Epoch 19, Batch 2, Loss: 0.101\n",
      "Training: Epoch 19, Batch 3, Loss: 0.116\n",
      "Training: Epoch 19, Batch 4, Loss: 0.101\n",
      "Training: Epoch 19, Batch 5, Loss: 0.123\n",
      "Training: Epoch 19, Batch 6, Loss: 0.1\n",
      "Training: Epoch 19, Batch 7, Loss: 0.137\n",
      "Training: Epoch 19, Batch 8, Loss: 0.102\n",
      "Training: Epoch 19, Batch 9, Loss: 0.096\n",
      "Training: Epoch 19, Batch 10, Loss: 0.114\n",
      "Training: Epoch 19, Batch 11, Loss: 0.149\n",
      "Training: Epoch 19, Batch 12, Loss: 0.159\n",
      "Training: Epoch 19, Batch 13, Loss: 0.126\n",
      "Training: Epoch 19, Batch 14, Loss: 0.109\n",
      "Training: Epoch 19, Batch 15, Loss: 0.112\n",
      "Training: Epoch 19, Batch 16, Loss: 0.105\n",
      "Training: Epoch 19, Batch 17, Loss: 0.111\n",
      "Training: Epoch 19, Batch 18, Loss: 0.111\n",
      "Training: Epoch 19, Batch 19, Loss: 0.11\n",
      "Val: Epoch 19, Loss: 0.279\n",
      "Training: Epoch 20, Batch 0, Loss: 0.106\n",
      "Training: Epoch 20, Batch 1, Loss: 0.092\n",
      "Training: Epoch 20, Batch 2, Loss: 0.111\n",
      "Training: Epoch 20, Batch 3, Loss: 0.121\n",
      "Training: Epoch 20, Batch 4, Loss: 0.11\n",
      "Training: Epoch 20, Batch 5, Loss: 0.105\n",
      "Training: Epoch 20, Batch 6, Loss: 0.108\n",
      "Training: Epoch 20, Batch 7, Loss: 0.134\n",
      "Training: Epoch 20, Batch 8, Loss: 0.091\n",
      "Training: Epoch 20, Batch 9, Loss: 0.109\n",
      "Training: Epoch 20, Batch 10, Loss: 0.098\n",
      "Training: Epoch 20, Batch 11, Loss: 0.103\n",
      "Training: Epoch 20, Batch 12, Loss: 0.097\n",
      "Training: Epoch 20, Batch 13, Loss: 0.113\n",
      "Training: Epoch 20, Batch 14, Loss: 0.103\n",
      "Training: Epoch 20, Batch 15, Loss: 0.124\n",
      "Training: Epoch 20, Batch 16, Loss: 0.113\n",
      "Training: Epoch 20, Batch 17, Loss: 0.116\n",
      "Training: Epoch 20, Batch 18, Loss: 0.103\n",
      "Training: Epoch 20, Batch 19, Loss: 0.12\n",
      "Val: Epoch 20, Loss: 0.585\n",
      "Training: Epoch 21, Batch 0, Loss: 0.126\n",
      "Training: Epoch 21, Batch 1, Loss: 0.099\n",
      "Training: Epoch 21, Batch 2, Loss: 0.092\n",
      "Training: Epoch 21, Batch 3, Loss: 0.083\n",
      "Training: Epoch 21, Batch 4, Loss: 0.098\n",
      "Training: Epoch 21, Batch 5, Loss: 0.098\n",
      "Training: Epoch 21, Batch 6, Loss: 0.108\n",
      "Training: Epoch 21, Batch 7, Loss: 0.104\n",
      "Training: Epoch 21, Batch 8, Loss: 0.088\n",
      "Training: Epoch 21, Batch 9, Loss: 0.096\n",
      "Training: Epoch 21, Batch 10, Loss: 0.137\n",
      "Training: Epoch 21, Batch 11, Loss: 0.105\n",
      "Training: Epoch 21, Batch 12, Loss: 0.098\n",
      "Training: Epoch 21, Batch 13, Loss: 0.124\n",
      "Training: Epoch 21, Batch 14, Loss: 0.121\n",
      "Training: Epoch 21, Batch 15, Loss: 0.115\n",
      "Training: Epoch 21, Batch 16, Loss: 0.089\n",
      "Training: Epoch 21, Batch 17, Loss: 0.117\n",
      "Training: Epoch 21, Batch 18, Loss: 0.103\n",
      "Training: Epoch 21, Batch 19, Loss: 0.104\n",
      "Val: Epoch 21, Loss: 0.316\n",
      "Training: Epoch 22, Batch 0, Loss: 0.082\n",
      "Training: Epoch 22, Batch 1, Loss: 0.094\n",
      "Training: Epoch 22, Batch 2, Loss: 0.101\n",
      "Training: Epoch 22, Batch 3, Loss: 0.098\n",
      "Training: Epoch 22, Batch 4, Loss: 0.133\n",
      "Training: Epoch 22, Batch 5, Loss: 0.115\n",
      "Training: Epoch 22, Batch 6, Loss: 0.129\n",
      "Training: Epoch 22, Batch 7, Loss: 0.084\n",
      "Training: Epoch 22, Batch 8, Loss: 0.124\n",
      "Training: Epoch 22, Batch 9, Loss: 0.094\n",
      "Training: Epoch 22, Batch 10, Loss: 0.111\n",
      "Training: Epoch 22, Batch 11, Loss: 0.095\n",
      "Training: Epoch 22, Batch 12, Loss: 0.104\n",
      "Training: Epoch 22, Batch 13, Loss: 0.098\n",
      "Training: Epoch 22, Batch 14, Loss: 0.128\n",
      "Training: Epoch 22, Batch 15, Loss: 0.125\n",
      "Training: Epoch 22, Batch 16, Loss: 0.093\n",
      "Training: Epoch 22, Batch 17, Loss: 0.09\n",
      "Training: Epoch 22, Batch 18, Loss: 0.1\n",
      "Training: Epoch 22, Batch 19, Loss: 0.111\n",
      "Val: Epoch 22, Loss: 0.401\n",
      "Training: Epoch 23, Batch 0, Loss: 0.096\n",
      "Training: Epoch 23, Batch 1, Loss: 0.114\n",
      "Training: Epoch 23, Batch 2, Loss: 0.103\n",
      "Training: Epoch 23, Batch 3, Loss: 0.1\n",
      "Training: Epoch 23, Batch 4, Loss: 0.089\n",
      "Training: Epoch 23, Batch 5, Loss: 0.098\n",
      "Training: Epoch 23, Batch 6, Loss: 0.084\n",
      "Training: Epoch 23, Batch 7, Loss: 0.109\n",
      "Training: Epoch 23, Batch 8, Loss: 0.111\n",
      "Training: Epoch 23, Batch 9, Loss: 0.1\n",
      "Training: Epoch 23, Batch 10, Loss: 0.097\n",
      "Training: Epoch 23, Batch 11, Loss: 0.107\n",
      "Training: Epoch 23, Batch 12, Loss: 0.11\n",
      "Training: Epoch 23, Batch 13, Loss: 0.095\n",
      "Training: Epoch 23, Batch 14, Loss: 0.222\n",
      "Training: Epoch 23, Batch 15, Loss: 0.097\n",
      "Training: Epoch 23, Batch 16, Loss: 0.093\n",
      "Training: Epoch 23, Batch 17, Loss: 0.13\n",
      "Training: Epoch 23, Batch 18, Loss: 0.101\n",
      "Training: Epoch 23, Batch 19, Loss: 0.106\n",
      "Val: Epoch 23, Loss: 0.427\n",
      "Training: Epoch 24, Batch 0, Loss: 0.134\n",
      "Training: Epoch 24, Batch 1, Loss: 0.098\n",
      "Training: Epoch 24, Batch 2, Loss: 0.108\n",
      "Training: Epoch 24, Batch 3, Loss: 0.095\n",
      "Training: Epoch 24, Batch 4, Loss: 0.113\n",
      "Training: Epoch 24, Batch 5, Loss: 0.105\n",
      "Training: Epoch 24, Batch 6, Loss: 0.123\n",
      "Training: Epoch 24, Batch 7, Loss: 0.093\n",
      "Training: Epoch 24, Batch 8, Loss: 0.101\n",
      "Training: Epoch 24, Batch 9, Loss: 0.138\n",
      "Training: Epoch 24, Batch 10, Loss: 0.093\n",
      "Training: Epoch 24, Batch 11, Loss: 0.1\n",
      "Training: Epoch 24, Batch 12, Loss: 0.094\n",
      "Training: Epoch 24, Batch 13, Loss: 0.1\n",
      "Training: Epoch 24, Batch 14, Loss: 0.132\n",
      "Training: Epoch 24, Batch 15, Loss: 0.103\n",
      "Training: Epoch 24, Batch 16, Loss: 0.104\n",
      "Training: Epoch 24, Batch 17, Loss: 0.139\n",
      "Training: Epoch 24, Batch 18, Loss: 0.104\n",
      "Training: Epoch 24, Batch 19, Loss: 0.138\n",
      "Val: Epoch 24, Loss: 0.317\n",
      "Training: Epoch 25, Batch 0, Loss: 0.098\n",
      "Training: Epoch 25, Batch 1, Loss: 0.115\n",
      "Training: Epoch 25, Batch 2, Loss: 0.088\n",
      "Training: Epoch 25, Batch 3, Loss: 0.119\n",
      "Training: Epoch 25, Batch 4, Loss: 0.079\n",
      "Training: Epoch 25, Batch 5, Loss: 0.133\n",
      "Training: Epoch 25, Batch 6, Loss: 0.1\n",
      "Training: Epoch 25, Batch 7, Loss: 0.091\n",
      "Training: Epoch 25, Batch 8, Loss: 0.092\n",
      "Training: Epoch 25, Batch 9, Loss: 0.115\n",
      "Training: Epoch 25, Batch 10, Loss: 0.095\n",
      "Training: Epoch 25, Batch 11, Loss: 0.091\n",
      "Training: Epoch 25, Batch 12, Loss: 0.1\n",
      "Training: Epoch 25, Batch 13, Loss: 0.098\n",
      "Training: Epoch 25, Batch 14, Loss: 0.09\n",
      "Training: Epoch 25, Batch 15, Loss: 0.145\n",
      "Training: Epoch 25, Batch 16, Loss: 0.094\n",
      "Training: Epoch 25, Batch 17, Loss: 0.093\n",
      "Training: Epoch 25, Batch 18, Loss: 0.09\n",
      "Training: Epoch 25, Batch 19, Loss: 0.097\n",
      "Val: Epoch 25, Loss: 0.37\n",
      "Training: Epoch 26, Batch 0, Loss: 0.09\n",
      "Training: Epoch 26, Batch 1, Loss: 0.113\n",
      "Training: Epoch 26, Batch 2, Loss: 0.091\n",
      "Training: Epoch 26, Batch 3, Loss: 0.084\n",
      "Training: Epoch 26, Batch 4, Loss: 0.092\n",
      "Training: Epoch 26, Batch 5, Loss: 0.101\n",
      "Training: Epoch 26, Batch 6, Loss: 0.11\n",
      "Training: Epoch 26, Batch 7, Loss: 0.084\n",
      "Training: Epoch 26, Batch 8, Loss: 0.093\n",
      "Training: Epoch 26, Batch 9, Loss: 0.109\n",
      "Training: Epoch 26, Batch 10, Loss: 0.097\n",
      "Training: Epoch 26, Batch 11, Loss: 0.088\n",
      "Training: Epoch 26, Batch 12, Loss: 0.091\n",
      "Training: Epoch 26, Batch 13, Loss: 0.082\n",
      "Training: Epoch 26, Batch 14, Loss: 0.099\n",
      "Training: Epoch 26, Batch 15, Loss: 0.079\n",
      "Training: Epoch 26, Batch 16, Loss: 0.081\n",
      "Training: Epoch 26, Batch 17, Loss: 0.095\n",
      "Training: Epoch 26, Batch 18, Loss: 0.08\n",
      "Training: Epoch 26, Batch 19, Loss: 0.086\n",
      "Val: Epoch 26, Loss: 0.509\n",
      "Training: Epoch 27, Batch 0, Loss: 0.076\n",
      "Training: Epoch 27, Batch 1, Loss: 0.084\n",
      "Training: Epoch 27, Batch 2, Loss: 0.074\n",
      "Training: Epoch 27, Batch 3, Loss: 0.086\n",
      "Training: Epoch 27, Batch 4, Loss: 0.093\n",
      "Training: Epoch 27, Batch 5, Loss: 0.103\n",
      "Training: Epoch 27, Batch 6, Loss: 0.078\n",
      "Training: Epoch 27, Batch 7, Loss: 0.075\n",
      "Training: Epoch 27, Batch 8, Loss: 0.092\n",
      "Training: Epoch 27, Batch 9, Loss: 0.097\n",
      "Training: Epoch 27, Batch 10, Loss: 0.089\n",
      "Training: Epoch 27, Batch 11, Loss: 0.074\n",
      "Training: Epoch 27, Batch 12, Loss: 0.082\n",
      "Training: Epoch 27, Batch 13, Loss: 0.096\n",
      "Training: Epoch 27, Batch 14, Loss: 0.074\n",
      "Training: Epoch 27, Batch 15, Loss: 0.09\n",
      "Training: Epoch 27, Batch 16, Loss: 0.076\n",
      "Training: Epoch 27, Batch 17, Loss: 0.09\n",
      "Training: Epoch 27, Batch 18, Loss: 0.08\n",
      "Training: Epoch 27, Batch 19, Loss: 0.075\n",
      "Val: Epoch 27, Loss: 0.331\n",
      "Training: Epoch 28, Batch 0, Loss: 0.075\n",
      "Training: Epoch 28, Batch 1, Loss: 0.086\n",
      "Training: Epoch 28, Batch 2, Loss: 0.102\n",
      "Training: Epoch 28, Batch 3, Loss: 0.113\n",
      "Training: Epoch 28, Batch 4, Loss: 0.073\n",
      "Training: Epoch 28, Batch 5, Loss: 0.066\n",
      "Training: Epoch 28, Batch 6, Loss: 0.084\n",
      "Training: Epoch 28, Batch 7, Loss: 0.076\n",
      "Training: Epoch 28, Batch 8, Loss: 0.082\n",
      "Training: Epoch 28, Batch 9, Loss: 0.082\n",
      "Training: Epoch 28, Batch 10, Loss: 0.074\n",
      "Training: Epoch 28, Batch 11, Loss: 0.076\n",
      "Training: Epoch 28, Batch 12, Loss: 0.091\n",
      "Training: Epoch 28, Batch 13, Loss: 0.075\n",
      "Training: Epoch 28, Batch 14, Loss: 0.072\n",
      "Training: Epoch 28, Batch 15, Loss: 0.079\n",
      "Training: Epoch 28, Batch 16, Loss: 0.091\n",
      "Training: Epoch 28, Batch 17, Loss: 0.081\n",
      "Training: Epoch 28, Batch 18, Loss: 0.076\n",
      "Training: Epoch 28, Batch 19, Loss: 0.072\n",
      "Val: Epoch 28, Loss: 0.366\n",
      "Training: Epoch 29, Batch 0, Loss: 0.116\n",
      "Training: Epoch 29, Batch 1, Loss: 0.084\n",
      "Training: Epoch 29, Batch 2, Loss: 0.088\n",
      "Training: Epoch 29, Batch 3, Loss: 0.068\n",
      "Training: Epoch 29, Batch 4, Loss: 0.092\n",
      "Training: Epoch 29, Batch 5, Loss: 0.092\n",
      "Training: Epoch 29, Batch 6, Loss: 0.08\n",
      "Training: Epoch 29, Batch 7, Loss: 0.07\n",
      "Training: Epoch 29, Batch 8, Loss: 0.072\n",
      "Training: Epoch 29, Batch 9, Loss: 0.078\n",
      "Training: Epoch 29, Batch 10, Loss: 0.084\n",
      "Training: Epoch 29, Batch 11, Loss: 0.065\n",
      "Training: Epoch 29, Batch 12, Loss: 0.083\n",
      "Training: Epoch 29, Batch 13, Loss: 0.08\n",
      "Training: Epoch 29, Batch 14, Loss: 0.075\n",
      "Training: Epoch 29, Batch 15, Loss: 0.074\n",
      "Training: Epoch 29, Batch 16, Loss: 0.072\n",
      "Training: Epoch 29, Batch 17, Loss: 0.067\n",
      "Training: Epoch 29, Batch 18, Loss: 0.066\n",
      "Training: Epoch 29, Batch 19, Loss: 0.087\n",
      "Val: Epoch 29, Loss: 0.488\n",
      "Training: Epoch 30, Batch 0, Loss: 0.068\n",
      "Training: Epoch 30, Batch 1, Loss: 0.075\n",
      "Training: Epoch 30, Batch 2, Loss: 0.08\n",
      "Training: Epoch 30, Batch 3, Loss: 0.074\n",
      "Training: Epoch 30, Batch 4, Loss: 0.113\n",
      "Training: Epoch 30, Batch 5, Loss: 0.081\n",
      "Training: Epoch 30, Batch 6, Loss: 0.085\n",
      "Training: Epoch 30, Batch 7, Loss: 0.064\n",
      "Training: Epoch 30, Batch 8, Loss: 0.07\n",
      "Training: Epoch 30, Batch 9, Loss: 0.06\n",
      "Training: Epoch 30, Batch 10, Loss: 0.059\n",
      "Training: Epoch 30, Batch 11, Loss: 0.067\n",
      "Training: Epoch 30, Batch 12, Loss: 0.064\n",
      "Training: Epoch 30, Batch 13, Loss: 0.086\n",
      "Training: Epoch 30, Batch 14, Loss: 0.067\n",
      "Training: Epoch 30, Batch 15, Loss: 0.068\n",
      "Training: Epoch 30, Batch 16, Loss: 0.07\n",
      "Training: Epoch 30, Batch 17, Loss: 0.076\n",
      "Training: Epoch 30, Batch 18, Loss: 0.066\n",
      "Training: Epoch 30, Batch 19, Loss: 0.069\n",
      "Val: Epoch 30, Loss: 0.34\n",
      "Training: Epoch 31, Batch 0, Loss: 0.062\n",
      "Training: Epoch 31, Batch 1, Loss: 0.085\n",
      "Training: Epoch 31, Batch 2, Loss: 0.059\n",
      "Training: Epoch 31, Batch 3, Loss: 0.066\n",
      "Training: Epoch 31, Batch 4, Loss: 0.066\n",
      "Training: Epoch 31, Batch 5, Loss: 0.072\n",
      "Training: Epoch 31, Batch 6, Loss: 0.082\n",
      "Training: Epoch 31, Batch 7, Loss: 0.068\n",
      "Training: Epoch 31, Batch 8, Loss: 0.06\n",
      "Training: Epoch 31, Batch 9, Loss: 0.076\n",
      "Training: Epoch 31, Batch 10, Loss: 0.064\n",
      "Training: Epoch 31, Batch 11, Loss: 0.068\n",
      "Training: Epoch 31, Batch 12, Loss: 0.065\n",
      "Training: Epoch 31, Batch 13, Loss: 0.074\n",
      "Training: Epoch 31, Batch 14, Loss: 0.084\n",
      "Training: Epoch 31, Batch 15, Loss: 0.061\n",
      "Training: Epoch 31, Batch 16, Loss: 0.065\n",
      "Training: Epoch 31, Batch 17, Loss: 0.074\n",
      "Training: Epoch 31, Batch 18, Loss: 0.075\n",
      "Training: Epoch 31, Batch 19, Loss: 0.061\n",
      "Val: Epoch 31, Loss: 0.363\n",
      "Training: Epoch 32, Batch 0, Loss: 0.061\n",
      "Training: Epoch 32, Batch 1, Loss: 0.062\n",
      "Training: Epoch 32, Batch 2, Loss: 0.059\n",
      "Training: Epoch 32, Batch 3, Loss: 0.074\n",
      "Training: Epoch 32, Batch 4, Loss: 0.067\n",
      "Training: Epoch 32, Batch 5, Loss: 0.087\n",
      "Training: Epoch 32, Batch 6, Loss: 0.061\n",
      "Training: Epoch 32, Batch 7, Loss: 0.061\n",
      "Training: Epoch 32, Batch 8, Loss: 0.08\n",
      "Training: Epoch 32, Batch 9, Loss: 0.061\n",
      "Training: Epoch 32, Batch 10, Loss: 0.066\n",
      "Training: Epoch 32, Batch 11, Loss: 0.069\n",
      "Training: Epoch 32, Batch 12, Loss: 0.065\n",
      "Training: Epoch 32, Batch 13, Loss: 0.065\n",
      "Training: Epoch 32, Batch 14, Loss: 0.069\n",
      "Training: Epoch 32, Batch 15, Loss: 0.07\n",
      "Training: Epoch 32, Batch 16, Loss: 0.054\n",
      "Training: Epoch 32, Batch 17, Loss: 0.069\n",
      "Training: Epoch 32, Batch 18, Loss: 0.057\n",
      "Training: Epoch 32, Batch 19, Loss: 0.103\n",
      "Val: Epoch 32, Loss: 0.335\n",
      "Training: Epoch 33, Batch 0, Loss: 0.058\n",
      "Training: Epoch 33, Batch 1, Loss: 0.061\n",
      "Training: Epoch 33, Batch 2, Loss: 0.066\n",
      "Training: Epoch 33, Batch 3, Loss: 0.079\n",
      "Training: Epoch 33, Batch 4, Loss: 0.079\n",
      "Training: Epoch 33, Batch 5, Loss: 0.06\n",
      "Training: Epoch 33, Batch 6, Loss: 0.056\n",
      "Training: Epoch 33, Batch 7, Loss: 0.068\n",
      "Training: Epoch 33, Batch 8, Loss: 0.056\n",
      "Training: Epoch 33, Batch 9, Loss: 0.063\n",
      "Training: Epoch 33, Batch 10, Loss: 0.064\n",
      "Training: Epoch 33, Batch 11, Loss: 0.066\n",
      "Training: Epoch 33, Batch 12, Loss: 0.055\n",
      "Training: Epoch 33, Batch 13, Loss: 0.059\n",
      "Training: Epoch 33, Batch 14, Loss: 0.068\n",
      "Training: Epoch 33, Batch 15, Loss: 0.057\n",
      "Training: Epoch 33, Batch 16, Loss: 0.054\n",
      "Training: Epoch 33, Batch 17, Loss: 0.076\n",
      "Training: Epoch 33, Batch 18, Loss: 0.053\n",
      "Training: Epoch 33, Batch 19, Loss: 0.059\n",
      "Val: Epoch 33, Loss: 0.343\n",
      "Training: Epoch 34, Batch 0, Loss: 0.061\n",
      "Training: Epoch 34, Batch 1, Loss: 0.057\n",
      "Training: Epoch 34, Batch 2, Loss: 0.057\n",
      "Training: Epoch 34, Batch 3, Loss: 0.059\n",
      "Training: Epoch 34, Batch 4, Loss: 0.053\n",
      "Training: Epoch 34, Batch 5, Loss: 0.048\n",
      "Training: Epoch 34, Batch 6, Loss: 0.058\n",
      "Training: Epoch 34, Batch 7, Loss: 0.084\n",
      "Training: Epoch 34, Batch 8, Loss: 0.056\n",
      "Training: Epoch 34, Batch 9, Loss: 0.051\n",
      "Training: Epoch 34, Batch 10, Loss: 0.049\n",
      "Training: Epoch 34, Batch 11, Loss: 0.077\n",
      "Training: Epoch 34, Batch 12, Loss: 0.063\n",
      "Training: Epoch 34, Batch 13, Loss: 0.07\n",
      "Training: Epoch 34, Batch 14, Loss: 0.067\n",
      "Training: Epoch 34, Batch 15, Loss: 0.065\n",
      "Training: Epoch 34, Batch 16, Loss: 0.062\n",
      "Training: Epoch 34, Batch 17, Loss: 0.063\n",
      "Training: Epoch 34, Batch 18, Loss: 0.076\n",
      "Training: Epoch 34, Batch 19, Loss: 0.061\n",
      "Val: Epoch 34, Loss: 0.367\n",
      "Training: Epoch 35, Batch 0, Loss: 0.057\n",
      "Training: Epoch 35, Batch 1, Loss: 0.066\n",
      "Training: Epoch 35, Batch 2, Loss: 0.063\n",
      "Training: Epoch 35, Batch 3, Loss: 0.055\n",
      "Training: Epoch 35, Batch 4, Loss: 0.061\n",
      "Training: Epoch 35, Batch 5, Loss: 0.068\n",
      "Training: Epoch 35, Batch 6, Loss: 0.057\n",
      "Training: Epoch 35, Batch 7, Loss: 0.052\n",
      "Training: Epoch 35, Batch 8, Loss: 0.052\n",
      "Training: Epoch 35, Batch 9, Loss: 0.056\n",
      "Training: Epoch 35, Batch 10, Loss: 0.063\n",
      "Training: Epoch 35, Batch 11, Loss: 0.061\n",
      "Training: Epoch 35, Batch 12, Loss: 0.07\n",
      "Training: Epoch 35, Batch 13, Loss: 0.053\n",
      "Training: Epoch 35, Batch 14, Loss: 0.043\n",
      "Training: Epoch 35, Batch 15, Loss: 0.059\n",
      "Training: Epoch 35, Batch 16, Loss: 0.069\n",
      "Training: Epoch 35, Batch 17, Loss: 0.066\n",
      "Training: Epoch 35, Batch 18, Loss: 0.063\n",
      "Training: Epoch 35, Batch 19, Loss: 0.051\n",
      "Val: Epoch 35, Loss: 0.379\n",
      "Training: Epoch 36, Batch 0, Loss: 0.057\n",
      "Training: Epoch 36, Batch 1, Loss: 0.056\n",
      "Training: Epoch 36, Batch 2, Loss: 0.067\n",
      "Training: Epoch 36, Batch 3, Loss: 0.049\n",
      "Training: Epoch 36, Batch 4, Loss: 0.066\n",
      "Training: Epoch 36, Batch 5, Loss: 0.059\n",
      "Training: Epoch 36, Batch 6, Loss: 0.063\n",
      "Training: Epoch 36, Batch 7, Loss: 0.051\n",
      "Training: Epoch 36, Batch 8, Loss: 0.053\n",
      "Training: Epoch 36, Batch 9, Loss: 0.057\n",
      "Training: Epoch 36, Batch 10, Loss: 0.057\n",
      "Training: Epoch 36, Batch 11, Loss: 0.052\n",
      "Training: Epoch 36, Batch 12, Loss: 0.064\n",
      "Training: Epoch 36, Batch 13, Loss: 0.061\n",
      "Training: Epoch 36, Batch 14, Loss: 0.06\n",
      "Training: Epoch 36, Batch 15, Loss: 0.062\n",
      "Training: Epoch 36, Batch 16, Loss: 0.057\n",
      "Training: Epoch 36, Batch 17, Loss: 0.054\n",
      "Training: Epoch 36, Batch 18, Loss: 0.05\n",
      "Training: Epoch 36, Batch 19, Loss: 0.049\n",
      "Val: Epoch 36, Loss: 0.474\n",
      "Training: Epoch 37, Batch 0, Loss: 0.052\n",
      "Training: Epoch 37, Batch 1, Loss: 0.058\n",
      "Training: Epoch 37, Batch 2, Loss: 0.054\n",
      "Training: Epoch 37, Batch 3, Loss: 0.059\n",
      "Training: Epoch 37, Batch 4, Loss: 0.068\n",
      "Training: Epoch 37, Batch 5, Loss: 0.047\n",
      "Training: Epoch 37, Batch 6, Loss: 0.06\n",
      "Training: Epoch 37, Batch 7, Loss: 0.045\n",
      "Training: Epoch 37, Batch 8, Loss: 0.058\n",
      "Training: Epoch 37, Batch 9, Loss: 0.054\n",
      "Training: Epoch 37, Batch 10, Loss: 0.045\n",
      "Training: Epoch 37, Batch 11, Loss: 0.058\n",
      "Training: Epoch 37, Batch 12, Loss: 0.045\n",
      "Training: Epoch 37, Batch 13, Loss: 0.047\n",
      "Training: Epoch 37, Batch 14, Loss: 0.053\n",
      "Training: Epoch 37, Batch 15, Loss: 0.06\n",
      "Training: Epoch 37, Batch 16, Loss: 0.052\n",
      "Training: Epoch 37, Batch 17, Loss: 0.077\n",
      "Training: Epoch 37, Batch 18, Loss: 0.061\n",
      "Training: Epoch 37, Batch 19, Loss: 0.044\n",
      "Val: Epoch 37, Loss: 0.388\n",
      "Training: Epoch 38, Batch 0, Loss: 0.056\n",
      "Training: Epoch 38, Batch 1, Loss: 0.05\n",
      "Training: Epoch 38, Batch 2, Loss: 0.073\n",
      "Training: Epoch 38, Batch 3, Loss: 0.049\n",
      "Training: Epoch 38, Batch 4, Loss: 0.045\n",
      "Training: Epoch 38, Batch 5, Loss: 0.058\n",
      "Training: Epoch 38, Batch 6, Loss: 0.048\n",
      "Training: Epoch 38, Batch 7, Loss: 0.047\n",
      "Training: Epoch 38, Batch 8, Loss: 0.06\n",
      "Training: Epoch 38, Batch 9, Loss: 0.057\n",
      "Training: Epoch 38, Batch 10, Loss: 0.079\n",
      "Training: Epoch 38, Batch 11, Loss: 0.054\n",
      "Training: Epoch 38, Batch 12, Loss: 0.065\n",
      "Training: Epoch 38, Batch 13, Loss: 0.065\n",
      "Training: Epoch 38, Batch 14, Loss: 0.051\n",
      "Training: Epoch 38, Batch 15, Loss: 0.061\n",
      "Training: Epoch 38, Batch 16, Loss: 0.055\n",
      "Training: Epoch 38, Batch 17, Loss: 0.045\n",
      "Training: Epoch 38, Batch 18, Loss: 0.057\n",
      "Training: Epoch 38, Batch 19, Loss: 0.062\n",
      "Val: Epoch 38, Loss: 0.399\n",
      "Training: Epoch 39, Batch 0, Loss: 0.053\n",
      "Training: Epoch 39, Batch 1, Loss: 0.057\n",
      "Training: Epoch 39, Batch 2, Loss: 0.048\n",
      "Training: Epoch 39, Batch 3, Loss: 0.052\n",
      "Training: Epoch 39, Batch 4, Loss: 0.051\n",
      "Training: Epoch 39, Batch 5, Loss: 0.053\n",
      "Training: Epoch 39, Batch 6, Loss: 0.048\n",
      "Training: Epoch 39, Batch 7, Loss: 0.062\n",
      "Training: Epoch 39, Batch 8, Loss: 0.06\n",
      "Training: Epoch 39, Batch 9, Loss: 0.058\n",
      "Training: Epoch 39, Batch 10, Loss: 0.058\n",
      "Training: Epoch 39, Batch 11, Loss: 0.062\n",
      "Training: Epoch 39, Batch 12, Loss: 0.05\n",
      "Training: Epoch 39, Batch 13, Loss: 0.057\n",
      "Training: Epoch 39, Batch 14, Loss: 0.048\n",
      "Training: Epoch 39, Batch 15, Loss: 0.047\n",
      "Training: Epoch 39, Batch 16, Loss: 0.051\n",
      "Training: Epoch 39, Batch 17, Loss: 0.066\n",
      "Training: Epoch 39, Batch 18, Loss: 0.043\n",
      "Training: Epoch 39, Batch 19, Loss: 0.049\n",
      "Val: Epoch 39, Loss: 0.4\n",
      "Training: Epoch 40, Batch 0, Loss: 0.062\n",
      "Training: Epoch 40, Batch 1, Loss: 0.046\n",
      "Training: Epoch 40, Batch 2, Loss: 0.073\n",
      "Training: Epoch 40, Batch 3, Loss: 0.06\n",
      "Training: Epoch 40, Batch 4, Loss: 0.044\n",
      "Training: Epoch 40, Batch 5, Loss: 0.049\n",
      "Training: Epoch 40, Batch 6, Loss: 0.049\n",
      "Training: Epoch 40, Batch 7, Loss: 0.049\n",
      "Training: Epoch 40, Batch 8, Loss: 0.05\n",
      "Training: Epoch 40, Batch 9, Loss: 0.054\n",
      "Training: Epoch 40, Batch 10, Loss: 0.048\n",
      "Training: Epoch 40, Batch 11, Loss: 0.046\n",
      "Training: Epoch 40, Batch 12, Loss: 0.057\n",
      "Training: Epoch 40, Batch 13, Loss: 0.053\n",
      "Training: Epoch 40, Batch 14, Loss: 0.061\n",
      "Training: Epoch 40, Batch 15, Loss: 0.055\n",
      "Training: Epoch 40, Batch 16, Loss: 0.062\n",
      "Training: Epoch 40, Batch 17, Loss: 0.048\n",
      "Training: Epoch 40, Batch 18, Loss: 0.04\n",
      "Training: Epoch 40, Batch 19, Loss: 0.05\n",
      "Val: Epoch 40, Loss: 0.363\n",
      "Training: Epoch 41, Batch 0, Loss: 0.055\n",
      "Training: Epoch 41, Batch 1, Loss: 0.049\n",
      "Training: Epoch 41, Batch 2, Loss: 0.047\n",
      "Training: Epoch 41, Batch 3, Loss: 0.039\n",
      "Training: Epoch 41, Batch 4, Loss: 0.051\n",
      "Training: Epoch 41, Batch 5, Loss: 0.05\n",
      "Training: Epoch 41, Batch 6, Loss: 0.059\n",
      "Training: Epoch 41, Batch 7, Loss: 0.054\n",
      "Training: Epoch 41, Batch 8, Loss: 0.051\n",
      "Training: Epoch 41, Batch 9, Loss: 0.054\n",
      "Training: Epoch 41, Batch 10, Loss: 0.055\n",
      "Training: Epoch 41, Batch 11, Loss: 0.06\n",
      "Training: Epoch 41, Batch 12, Loss: 0.043\n",
      "Training: Epoch 41, Batch 13, Loss: 0.043\n",
      "Training: Epoch 41, Batch 14, Loss: 0.046\n",
      "Training: Epoch 41, Batch 15, Loss: 0.051\n",
      "Training: Epoch 41, Batch 16, Loss: 0.057\n",
      "Training: Epoch 41, Batch 17, Loss: 0.046\n",
      "Training: Epoch 41, Batch 18, Loss: 0.048\n",
      "Training: Epoch 41, Batch 19, Loss: 0.05\n",
      "Val: Epoch 41, Loss: 0.361\n",
      "Training: Epoch 42, Batch 0, Loss: 0.048\n",
      "Training: Epoch 42, Batch 1, Loss: 0.052\n",
      "Training: Epoch 42, Batch 2, Loss: 0.049\n",
      "Training: Epoch 42, Batch 3, Loss: 0.05\n",
      "Training: Epoch 42, Batch 4, Loss: 0.05\n",
      "Training: Epoch 42, Batch 5, Loss: 0.047\n",
      "Training: Epoch 42, Batch 6, Loss: 0.048\n",
      "Training: Epoch 42, Batch 7, Loss: 0.042\n",
      "Training: Epoch 42, Batch 8, Loss: 0.054\n",
      "Training: Epoch 42, Batch 9, Loss: 0.053\n",
      "Training: Epoch 42, Batch 10, Loss: 0.048\n",
      "Training: Epoch 42, Batch 11, Loss: 0.045\n",
      "Training: Epoch 42, Batch 12, Loss: 0.053\n",
      "Training: Epoch 42, Batch 13, Loss: 0.058\n",
      "Training: Epoch 42, Batch 14, Loss: 0.05\n",
      "Training: Epoch 42, Batch 15, Loss: 0.05\n",
      "Training: Epoch 42, Batch 16, Loss: 0.049\n",
      "Training: Epoch 42, Batch 17, Loss: 0.045\n",
      "Training: Epoch 42, Batch 18, Loss: 0.049\n",
      "Training: Epoch 42, Batch 19, Loss: 0.05\n",
      "Val: Epoch 42, Loss: 0.375\n",
      "Training: Epoch 43, Batch 0, Loss: 0.059\n",
      "Training: Epoch 43, Batch 1, Loss: 0.035\n",
      "Training: Epoch 43, Batch 2, Loss: 0.04\n",
      "Training: Epoch 43, Batch 3, Loss: 0.05\n",
      "Training: Epoch 43, Batch 4, Loss: 0.049\n",
      "Training: Epoch 43, Batch 5, Loss: 0.056\n",
      "Training: Epoch 43, Batch 6, Loss: 0.046\n",
      "Training: Epoch 43, Batch 7, Loss: 0.051\n",
      "Training: Epoch 43, Batch 8, Loss: 0.046\n",
      "Training: Epoch 43, Batch 9, Loss: 0.05\n",
      "Training: Epoch 43, Batch 10, Loss: 0.065\n",
      "Training: Epoch 43, Batch 11, Loss: 0.05\n",
      "Training: Epoch 43, Batch 12, Loss: 0.053\n",
      "Training: Epoch 43, Batch 13, Loss: 0.057\n",
      "Training: Epoch 43, Batch 14, Loss: 0.057\n",
      "Training: Epoch 43, Batch 15, Loss: 0.053\n",
      "Training: Epoch 43, Batch 16, Loss: 0.043\n",
      "Training: Epoch 43, Batch 17, Loss: 0.047\n",
      "Training: Epoch 43, Batch 18, Loss: 0.051\n",
      "Training: Epoch 43, Batch 19, Loss: 0.05\n",
      "Val: Epoch 43, Loss: 0.382\n",
      "Training: Epoch 44, Batch 0, Loss: 0.047\n",
      "Training: Epoch 44, Batch 1, Loss: 0.052\n",
      "Training: Epoch 44, Batch 2, Loss: 0.053\n",
      "Training: Epoch 44, Batch 3, Loss: 0.054\n",
      "Training: Epoch 44, Batch 4, Loss: 0.058\n",
      "Training: Epoch 44, Batch 5, Loss: 0.048\n",
      "Training: Epoch 44, Batch 6, Loss: 0.044\n",
      "Training: Epoch 44, Batch 7, Loss: 0.042\n",
      "Training: Epoch 44, Batch 8, Loss: 0.045\n",
      "Training: Epoch 44, Batch 9, Loss: 0.046\n",
      "Training: Epoch 44, Batch 10, Loss: 0.053\n",
      "Training: Epoch 44, Batch 11, Loss: 0.04\n",
      "Training: Epoch 44, Batch 12, Loss: 0.044\n",
      "Training: Epoch 44, Batch 13, Loss: 0.047\n",
      "Training: Epoch 44, Batch 14, Loss: 0.052\n",
      "Training: Epoch 44, Batch 15, Loss: 0.048\n",
      "Training: Epoch 44, Batch 16, Loss: 0.057\n",
      "Training: Epoch 44, Batch 17, Loss: 0.037\n",
      "Training: Epoch 44, Batch 18, Loss: 0.055\n",
      "Training: Epoch 44, Batch 19, Loss: 0.038\n",
      "Val: Epoch 44, Loss: 0.443\n",
      "Training: Epoch 45, Batch 0, Loss: 0.055\n",
      "Training: Epoch 45, Batch 1, Loss: 0.045\n",
      "Training: Epoch 45, Batch 2, Loss: 0.047\n",
      "Training: Epoch 45, Batch 3, Loss: 0.04\n",
      "Training: Epoch 45, Batch 4, Loss: 0.054\n",
      "Training: Epoch 45, Batch 5, Loss: 0.035\n",
      "Training: Epoch 45, Batch 6, Loss: 0.041\n",
      "Training: Epoch 45, Batch 7, Loss: 0.057\n",
      "Training: Epoch 45, Batch 8, Loss: 0.039\n",
      "Training: Epoch 45, Batch 9, Loss: 0.054\n",
      "Training: Epoch 45, Batch 10, Loss: 0.041\n",
      "Training: Epoch 45, Batch 11, Loss: 0.055\n",
      "Training: Epoch 45, Batch 12, Loss: 0.048\n",
      "Training: Epoch 45, Batch 13, Loss: 0.041\n",
      "Training: Epoch 45, Batch 14, Loss: 0.042\n",
      "Training: Epoch 45, Batch 15, Loss: 0.053\n",
      "Training: Epoch 45, Batch 16, Loss: 0.045\n",
      "Training: Epoch 45, Batch 17, Loss: 0.05\n",
      "Training: Epoch 45, Batch 18, Loss: 0.046\n",
      "Training: Epoch 45, Batch 19, Loss: 0.057\n",
      "Val: Epoch 45, Loss: 0.391\n",
      "Training: Epoch 46, Batch 0, Loss: 0.051\n",
      "Training: Epoch 46, Batch 1, Loss: 0.053\n",
      "Training: Epoch 46, Batch 2, Loss: 0.048\n",
      "Training: Epoch 46, Batch 3, Loss: 0.047\n",
      "Training: Epoch 46, Batch 4, Loss: 0.046\n",
      "Training: Epoch 46, Batch 5, Loss: 0.036\n",
      "Training: Epoch 46, Batch 6, Loss: 0.055\n",
      "Training: Epoch 46, Batch 7, Loss: 0.044\n",
      "Training: Epoch 46, Batch 8, Loss: 0.05\n",
      "Training: Epoch 46, Batch 9, Loss: 0.045\n",
      "Training: Epoch 46, Batch 10, Loss: 0.05\n",
      "Training: Epoch 46, Batch 11, Loss: 0.043\n",
      "Training: Epoch 46, Batch 12, Loss: 0.05\n",
      "Training: Epoch 46, Batch 13, Loss: 0.039\n",
      "Training: Epoch 46, Batch 14, Loss: 0.045\n",
      "Training: Epoch 46, Batch 15, Loss: 0.056\n",
      "Training: Epoch 46, Batch 16, Loss: 0.061\n",
      "Training: Epoch 46, Batch 17, Loss: 0.046\n",
      "Training: Epoch 46, Batch 18, Loss: 0.049\n",
      "Training: Epoch 46, Batch 19, Loss: 0.049\n",
      "Val: Epoch 46, Loss: 0.381\n",
      "Training: Epoch 47, Batch 0, Loss: 0.06\n",
      "Training: Epoch 47, Batch 1, Loss: 0.054\n",
      "Training: Epoch 47, Batch 2, Loss: 0.043\n",
      "Training: Epoch 47, Batch 3, Loss: 0.04\n",
      "Training: Epoch 47, Batch 4, Loss: 0.065\n",
      "Training: Epoch 47, Batch 5, Loss: 0.043\n",
      "Training: Epoch 47, Batch 6, Loss: 0.041\n",
      "Training: Epoch 47, Batch 7, Loss: 0.041\n",
      "Training: Epoch 47, Batch 8, Loss: 0.052\n",
      "Training: Epoch 47, Batch 9, Loss: 0.051\n",
      "Training: Epoch 47, Batch 10, Loss: 0.047\n",
      "Training: Epoch 47, Batch 11, Loss: 0.053\n",
      "Training: Epoch 47, Batch 12, Loss: 0.039\n",
      "Training: Epoch 47, Batch 13, Loss: 0.044\n",
      "Training: Epoch 47, Batch 14, Loss: 0.056\n",
      "Training: Epoch 47, Batch 15, Loss: 0.047\n",
      "Training: Epoch 47, Batch 16, Loss: 0.047\n",
      "Training: Epoch 47, Batch 17, Loss: 0.051\n",
      "Training: Epoch 47, Batch 18, Loss: 0.046\n",
      "Training: Epoch 47, Batch 19, Loss: 0.04\n",
      "Val: Epoch 47, Loss: 0.401\n",
      "Training: Epoch 48, Batch 0, Loss: 0.044\n",
      "Training: Epoch 48, Batch 1, Loss: 0.053\n",
      "Training: Epoch 48, Batch 2, Loss: 0.037\n",
      "Training: Epoch 48, Batch 3, Loss: 0.04\n",
      "Training: Epoch 48, Batch 4, Loss: 0.038\n",
      "Training: Epoch 48, Batch 5, Loss: 0.045\n",
      "Training: Epoch 48, Batch 6, Loss: 0.048\n",
      "Training: Epoch 48, Batch 7, Loss: 0.055\n",
      "Training: Epoch 48, Batch 8, Loss: 0.041\n",
      "Training: Epoch 48, Batch 9, Loss: 0.049\n",
      "Training: Epoch 48, Batch 10, Loss: 0.042\n",
      "Training: Epoch 48, Batch 11, Loss: 0.038\n",
      "Training: Epoch 48, Batch 12, Loss: 0.041\n",
      "Training: Epoch 48, Batch 13, Loss: 0.04\n",
      "Training: Epoch 48, Batch 14, Loss: 0.041\n",
      "Training: Epoch 48, Batch 15, Loss: 0.054\n",
      "Training: Epoch 48, Batch 16, Loss: 0.042\n",
      "Training: Epoch 48, Batch 17, Loss: 0.043\n",
      "Training: Epoch 48, Batch 18, Loss: 0.049\n",
      "Training: Epoch 48, Batch 19, Loss: 0.04\n",
      "Val: Epoch 48, Loss: 0.378\n",
      "Training: Epoch 49, Batch 0, Loss: 0.05\n",
      "Training: Epoch 49, Batch 1, Loss: 0.035\n",
      "Training: Epoch 49, Batch 2, Loss: 0.038\n",
      "Training: Epoch 49, Batch 3, Loss: 0.04\n",
      "Training: Epoch 49, Batch 4, Loss: 0.041\n",
      "Training: Epoch 49, Batch 5, Loss: 0.038\n",
      "Training: Epoch 49, Batch 6, Loss: 0.047\n",
      "Training: Epoch 49, Batch 7, Loss: 0.043\n",
      "Training: Epoch 49, Batch 8, Loss: 0.045\n",
      "Training: Epoch 49, Batch 9, Loss: 0.042\n",
      "Training: Epoch 49, Batch 10, Loss: 0.041\n",
      "Training: Epoch 49, Batch 11, Loss: 0.053\n",
      "Training: Epoch 49, Batch 12, Loss: 0.041\n",
      "Training: Epoch 49, Batch 13, Loss: 0.045\n",
      "Training: Epoch 49, Batch 14, Loss: 0.043\n",
      "Training: Epoch 49, Batch 15, Loss: 0.039\n",
      "Training: Epoch 49, Batch 16, Loss: 0.043\n",
      "Training: Epoch 49, Batch 17, Loss: 0.044\n",
      "Training: Epoch 49, Batch 18, Loss: 0.044\n",
      "Training: Epoch 49, Batch 19, Loss: 0.046\n",
      "Val: Epoch 49, Loss: 0.394\n",
      "Training: Epoch 50, Batch 0, Loss: 0.044\n",
      "Training: Epoch 50, Batch 1, Loss: 0.042\n",
      "Training: Epoch 50, Batch 2, Loss: 0.045\n",
      "Training: Epoch 50, Batch 3, Loss: 0.042\n",
      "Training: Epoch 50, Batch 4, Loss: 0.048\n",
      "Training: Epoch 50, Batch 5, Loss: 0.046\n",
      "Training: Epoch 50, Batch 6, Loss: 0.043\n",
      "Training: Epoch 50, Batch 7, Loss: 0.052\n",
      "Training: Epoch 50, Batch 8, Loss: 0.041\n",
      "Training: Epoch 50, Batch 9, Loss: 0.039\n",
      "Training: Epoch 50, Batch 10, Loss: 0.04\n",
      "Training: Epoch 50, Batch 11, Loss: 0.051\n",
      "Training: Epoch 50, Batch 12, Loss: 0.039\n",
      "Training: Epoch 50, Batch 13, Loss: 0.035\n",
      "Training: Epoch 50, Batch 14, Loss: 0.052\n",
      "Training: Epoch 50, Batch 15, Loss: 0.038\n",
      "Training: Epoch 50, Batch 16, Loss: 0.04\n",
      "Training: Epoch 50, Batch 17, Loss: 0.042\n",
      "Training: Epoch 50, Batch 18, Loss: 0.041\n",
      "Training: Epoch 50, Batch 19, Loss: 0.041\n",
      "Val: Epoch 50, Loss: 0.391\n",
      "Training: Epoch 51, Batch 0, Loss: 0.048\n",
      "Training: Epoch 51, Batch 1, Loss: 0.041\n",
      "Training: Epoch 51, Batch 2, Loss: 0.041\n",
      "Training: Epoch 51, Batch 3, Loss: 0.052\n",
      "Training: Epoch 51, Batch 4, Loss: 0.039\n",
      "Training: Epoch 51, Batch 5, Loss: 0.04\n",
      "Training: Epoch 51, Batch 6, Loss: 0.039\n",
      "Training: Epoch 51, Batch 7, Loss: 0.049\n",
      "Training: Epoch 51, Batch 8, Loss: 0.042\n",
      "Training: Epoch 51, Batch 9, Loss: 0.038\n",
      "Training: Epoch 51, Batch 10, Loss: 0.033\n",
      "Training: Epoch 51, Batch 11, Loss: 0.049\n",
      "Training: Epoch 51, Batch 12, Loss: 0.042\n",
      "Training: Epoch 51, Batch 13, Loss: 0.05\n",
      "Training: Epoch 51, Batch 14, Loss: 0.039\n",
      "Training: Epoch 51, Batch 15, Loss: 0.035\n",
      "Training: Epoch 51, Batch 16, Loss: 0.044\n",
      "Training: Epoch 51, Batch 17, Loss: 0.036\n",
      "Training: Epoch 51, Batch 18, Loss: 0.042\n",
      "Training: Epoch 51, Batch 19, Loss: 0.035\n",
      "Val: Epoch 51, Loss: 0.381\n",
      "Training: Epoch 52, Batch 0, Loss: 0.042\n",
      "Training: Epoch 52, Batch 1, Loss: 0.038\n",
      "Training: Epoch 52, Batch 2, Loss: 0.041\n",
      "Training: Epoch 52, Batch 3, Loss: 0.048\n",
      "Training: Epoch 52, Batch 4, Loss: 0.038\n",
      "Training: Epoch 52, Batch 5, Loss: 0.033\n",
      "Training: Epoch 52, Batch 6, Loss: 0.041\n",
      "Training: Epoch 52, Batch 7, Loss: 0.036\n",
      "Training: Epoch 52, Batch 8, Loss: 0.056\n",
      "Training: Epoch 52, Batch 9, Loss: 0.041\n",
      "Training: Epoch 52, Batch 10, Loss: 0.033\n",
      "Training: Epoch 52, Batch 11, Loss: 0.035\n",
      "Training: Epoch 52, Batch 12, Loss: 0.039\n",
      "Training: Epoch 52, Batch 13, Loss: 0.035\n",
      "Training: Epoch 52, Batch 14, Loss: 0.03\n",
      "Training: Epoch 52, Batch 15, Loss: 0.032\n",
      "Training: Epoch 52, Batch 16, Loss: 0.032\n",
      "Training: Epoch 52, Batch 17, Loss: 0.039\n",
      "Training: Epoch 52, Batch 18, Loss: 0.038\n",
      "Training: Epoch 52, Batch 19, Loss: 0.038\n",
      "Val: Epoch 52, Loss: 0.392\n",
      "Training: Epoch 53, Batch 0, Loss: 0.028\n",
      "Training: Epoch 53, Batch 1, Loss: 0.038\n",
      "Training: Epoch 53, Batch 2, Loss: 0.032\n",
      "Training: Epoch 53, Batch 3, Loss: 0.038\n",
      "Training: Epoch 53, Batch 4, Loss: 0.035\n",
      "Training: Epoch 53, Batch 5, Loss: 0.041\n",
      "Training: Epoch 53, Batch 6, Loss: 0.034\n",
      "Training: Epoch 53, Batch 7, Loss: 0.038\n",
      "Training: Epoch 53, Batch 8, Loss: 0.038\n",
      "Training: Epoch 53, Batch 9, Loss: 0.043\n",
      "Training: Epoch 53, Batch 10, Loss: 0.042\n",
      "Training: Epoch 53, Batch 11, Loss: 0.036\n",
      "Training: Epoch 53, Batch 12, Loss: 0.038\n",
      "Training: Epoch 53, Batch 13, Loss: 0.043\n",
      "Training: Epoch 53, Batch 14, Loss: 0.034\n",
      "Training: Epoch 53, Batch 15, Loss: 0.032\n",
      "Training: Epoch 53, Batch 16, Loss: 0.036\n",
      "Training: Epoch 53, Batch 17, Loss: 0.042\n",
      "Training: Epoch 53, Batch 18, Loss: 0.042\n",
      "Training: Epoch 53, Batch 19, Loss: 0.03\n",
      "Val: Epoch 53, Loss: 0.392\n",
      "Training: Epoch 54, Batch 0, Loss: 0.04\n",
      "Training: Epoch 54, Batch 1, Loss: 0.034\n",
      "Training: Epoch 54, Batch 2, Loss: 0.035\n",
      "Training: Epoch 54, Batch 3, Loss: 0.03\n",
      "Training: Epoch 54, Batch 4, Loss: 0.05\n",
      "Training: Epoch 54, Batch 5, Loss: 0.049\n",
      "Training: Epoch 54, Batch 6, Loss: 0.038\n",
      "Training: Epoch 54, Batch 7, Loss: 0.04\n",
      "Training: Epoch 54, Batch 8, Loss: 0.037\n",
      "Training: Epoch 54, Batch 9, Loss: 0.036\n",
      "Training: Epoch 54, Batch 10, Loss: 0.033\n",
      "Training: Epoch 54, Batch 11, Loss: 0.034\n",
      "Training: Epoch 54, Batch 12, Loss: 0.032\n",
      "Training: Epoch 54, Batch 13, Loss: 0.034\n",
      "Training: Epoch 54, Batch 14, Loss: 0.046\n",
      "Training: Epoch 54, Batch 15, Loss: 0.045\n",
      "Training: Epoch 54, Batch 16, Loss: 0.033\n",
      "Training: Epoch 54, Batch 17, Loss: 0.038\n",
      "Training: Epoch 54, Batch 18, Loss: 0.047\n",
      "Training: Epoch 54, Batch 19, Loss: 0.037\n",
      "Val: Epoch 54, Loss: 0.425\n",
      "Training: Epoch 55, Batch 0, Loss: 0.037\n",
      "Training: Epoch 55, Batch 1, Loss: 0.039\n",
      "Training: Epoch 55, Batch 2, Loss: 0.046\n",
      "Training: Epoch 55, Batch 3, Loss: 0.036\n",
      "Training: Epoch 55, Batch 4, Loss: 0.035\n",
      "Training: Epoch 55, Batch 5, Loss: 0.034\n",
      "Training: Epoch 55, Batch 6, Loss: 0.029\n",
      "Training: Epoch 55, Batch 7, Loss: 0.033\n",
      "Training: Epoch 55, Batch 8, Loss: 0.04\n",
      "Training: Epoch 55, Batch 9, Loss: 0.033\n",
      "Training: Epoch 55, Batch 10, Loss: 0.036\n",
      "Training: Epoch 55, Batch 11, Loss: 0.036\n",
      "Training: Epoch 55, Batch 12, Loss: 0.036\n",
      "Training: Epoch 55, Batch 13, Loss: 0.039\n",
      "Training: Epoch 55, Batch 14, Loss: 0.054\n",
      "Training: Epoch 55, Batch 15, Loss: 0.036\n",
      "Training: Epoch 55, Batch 16, Loss: 0.04\n",
      "Training: Epoch 55, Batch 17, Loss: 0.036\n",
      "Training: Epoch 55, Batch 18, Loss: 0.045\n",
      "Training: Epoch 55, Batch 19, Loss: 0.043\n",
      "Val: Epoch 55, Loss: 0.392\n",
      "Training: Epoch 56, Batch 0, Loss: 0.036\n",
      "Training: Epoch 56, Batch 1, Loss: 0.035\n",
      "Training: Epoch 56, Batch 2, Loss: 0.037\n",
      "Training: Epoch 56, Batch 3, Loss: 0.043\n",
      "Training: Epoch 56, Batch 4, Loss: 0.044\n",
      "Training: Epoch 56, Batch 5, Loss: 0.039\n",
      "Training: Epoch 56, Batch 6, Loss: 0.034\n",
      "Training: Epoch 56, Batch 7, Loss: 0.037\n",
      "Training: Epoch 56, Batch 8, Loss: 0.044\n",
      "Training: Epoch 56, Batch 9, Loss: 0.042\n",
      "Training: Epoch 56, Batch 10, Loss: 0.044\n",
      "Training: Epoch 56, Batch 11, Loss: 0.031\n",
      "Training: Epoch 56, Batch 12, Loss: 0.058\n",
      "Training: Epoch 56, Batch 13, Loss: 0.043\n",
      "Training: Epoch 56, Batch 14, Loss: 0.037\n",
      "Training: Epoch 56, Batch 15, Loss: 0.047\n",
      "Training: Epoch 56, Batch 16, Loss: 0.031\n",
      "Training: Epoch 56, Batch 17, Loss: 0.036\n",
      "Training: Epoch 56, Batch 18, Loss: 0.039\n",
      "Training: Epoch 56, Batch 19, Loss: 0.05\n",
      "Val: Epoch 56, Loss: 0.389\n",
      "Training: Epoch 57, Batch 0, Loss: 0.041\n",
      "Training: Epoch 57, Batch 1, Loss: 0.036\n",
      "Training: Epoch 57, Batch 2, Loss: 0.035\n",
      "Training: Epoch 57, Batch 3, Loss: 0.038\n",
      "Training: Epoch 57, Batch 4, Loss: 0.03\n",
      "Training: Epoch 57, Batch 5, Loss: 0.035\n",
      "Training: Epoch 57, Batch 6, Loss: 0.044\n",
      "Training: Epoch 57, Batch 7, Loss: 0.044\n",
      "Training: Epoch 57, Batch 8, Loss: 0.04\n",
      "Training: Epoch 57, Batch 9, Loss: 0.035\n",
      "Training: Epoch 57, Batch 10, Loss: 0.041\n",
      "Training: Epoch 57, Batch 11, Loss: 0.035\n",
      "Training: Epoch 57, Batch 12, Loss: 0.054\n",
      "Training: Epoch 57, Batch 13, Loss: 0.043\n",
      "Training: Epoch 57, Batch 14, Loss: 0.034\n",
      "Training: Epoch 57, Batch 15, Loss: 0.042\n",
      "Training: Epoch 57, Batch 16, Loss: 0.039\n",
      "Training: Epoch 57, Batch 17, Loss: 0.04\n",
      "Training: Epoch 57, Batch 18, Loss: 0.038\n",
      "Training: Epoch 57, Batch 19, Loss: 0.045\n",
      "Val: Epoch 57, Loss: 0.532\n",
      "Training: Epoch 58, Batch 0, Loss: 0.053\n",
      "Training: Epoch 58, Batch 1, Loss: 0.042\n",
      "Training: Epoch 58, Batch 2, Loss: 0.034\n",
      "Training: Epoch 58, Batch 3, Loss: 0.034\n",
      "Training: Epoch 58, Batch 4, Loss: 0.045\n",
      "Training: Epoch 58, Batch 5, Loss: 0.05\n",
      "Training: Epoch 58, Batch 6, Loss: 0.041\n",
      "Training: Epoch 58, Batch 7, Loss: 0.044\n",
      "Training: Epoch 58, Batch 8, Loss: 0.031\n",
      "Training: Epoch 58, Batch 9, Loss: 0.041\n",
      "Training: Epoch 58, Batch 10, Loss: 0.044\n",
      "Training: Epoch 58, Batch 11, Loss: 0.037\n",
      "Training: Epoch 58, Batch 12, Loss: 0.043\n",
      "Training: Epoch 58, Batch 13, Loss: 0.045\n",
      "Training: Epoch 58, Batch 14, Loss: 0.031\n",
      "Training: Epoch 58, Batch 15, Loss: 0.034\n",
      "Training: Epoch 58, Batch 16, Loss: 0.036\n",
      "Training: Epoch 58, Batch 17, Loss: 0.038\n",
      "Training: Epoch 58, Batch 18, Loss: 0.036\n",
      "Training: Epoch 58, Batch 19, Loss: 0.036\n",
      "Val: Epoch 58, Loss: 0.436\n",
      "Training: Epoch 59, Batch 0, Loss: 0.052\n",
      "Training: Epoch 59, Batch 1, Loss: 0.045\n",
      "Training: Epoch 59, Batch 2, Loss: 0.044\n",
      "Training: Epoch 59, Batch 3, Loss: 0.031\n",
      "Training: Epoch 59, Batch 4, Loss: 0.037\n",
      "Training: Epoch 59, Batch 5, Loss: 0.037\n",
      "Training: Epoch 59, Batch 6, Loss: 0.036\n",
      "Training: Epoch 59, Batch 7, Loss: 0.036\n",
      "Training: Epoch 59, Batch 8, Loss: 0.043\n",
      "Training: Epoch 59, Batch 9, Loss: 0.032\n",
      "Training: Epoch 59, Batch 10, Loss: 0.041\n",
      "Training: Epoch 59, Batch 11, Loss: 0.033\n",
      "Training: Epoch 59, Batch 12, Loss: 0.032\n",
      "Training: Epoch 59, Batch 13, Loss: 0.042\n",
      "Training: Epoch 59, Batch 14, Loss: 0.038\n",
      "Training: Epoch 59, Batch 15, Loss: 0.039\n",
      "Training: Epoch 59, Batch 16, Loss: 0.048\n",
      "Training: Epoch 59, Batch 17, Loss: 0.035\n",
      "Training: Epoch 59, Batch 18, Loss: 0.034\n",
      "Training: Epoch 59, Batch 19, Loss: 0.033\n",
      "Val: Epoch 59, Loss: 0.4\n",
      "Training: Epoch 60, Batch 0, Loss: 0.038\n",
      "Training: Epoch 60, Batch 1, Loss: 0.038\n",
      "Training: Epoch 60, Batch 2, Loss: 0.033\n",
      "Training: Epoch 60, Batch 3, Loss: 0.03\n",
      "Training: Epoch 60, Batch 4, Loss: 0.043\n",
      "Training: Epoch 60, Batch 5, Loss: 0.041\n",
      "Training: Epoch 60, Batch 6, Loss: 0.038\n",
      "Training: Epoch 60, Batch 7, Loss: 0.043\n",
      "Training: Epoch 60, Batch 8, Loss: 0.038\n",
      "Training: Epoch 60, Batch 9, Loss: 0.036\n",
      "Training: Epoch 60, Batch 10, Loss: 0.031\n",
      "Training: Epoch 60, Batch 11, Loss: 0.039\n",
      "Training: Epoch 60, Batch 12, Loss: 0.037\n",
      "Training: Epoch 60, Batch 13, Loss: 0.034\n",
      "Training: Epoch 60, Batch 14, Loss: 0.035\n",
      "Training: Epoch 60, Batch 15, Loss: 0.039\n",
      "Training: Epoch 60, Batch 16, Loss: 0.035\n",
      "Training: Epoch 60, Batch 17, Loss: 0.04\n",
      "Training: Epoch 60, Batch 18, Loss: 0.042\n",
      "Training: Epoch 60, Batch 19, Loss: 0.049\n",
      "Val: Epoch 60, Loss: 0.395\n",
      "Training: Epoch 61, Batch 0, Loss: 0.031\n",
      "Training: Epoch 61, Batch 1, Loss: 0.034\n",
      "Training: Epoch 61, Batch 2, Loss: 0.04\n",
      "Training: Epoch 61, Batch 3, Loss: 0.04\n",
      "Training: Epoch 61, Batch 4, Loss: 0.033\n",
      "Training: Epoch 61, Batch 5, Loss: 0.036\n",
      "Training: Epoch 61, Batch 6, Loss: 0.036\n",
      "Training: Epoch 61, Batch 7, Loss: 0.036\n",
      "Training: Epoch 61, Batch 8, Loss: 0.032\n",
      "Training: Epoch 61, Batch 9, Loss: 0.033\n",
      "Training: Epoch 61, Batch 10, Loss: 0.037\n",
      "Training: Epoch 61, Batch 11, Loss: 0.031\n",
      "Training: Epoch 61, Batch 12, Loss: 0.029\n",
      "Training: Epoch 61, Batch 13, Loss: 0.037\n",
      "Training: Epoch 61, Batch 14, Loss: 0.028\n",
      "Training: Epoch 61, Batch 15, Loss: 0.037\n",
      "Training: Epoch 61, Batch 16, Loss: 0.035\n",
      "Training: Epoch 61, Batch 17, Loss: 0.041\n",
      "Training: Epoch 61, Batch 18, Loss: 0.038\n",
      "Training: Epoch 61, Batch 19, Loss: 0.027\n",
      "Val: Epoch 61, Loss: 0.407\n",
      "Training: Epoch 62, Batch 0, Loss: 0.027\n",
      "Training: Epoch 62, Batch 1, Loss: 0.034\n",
      "Training: Epoch 62, Batch 2, Loss: 0.031\n",
      "Training: Epoch 62, Batch 3, Loss: 0.028\n",
      "Training: Epoch 62, Batch 4, Loss: 0.047\n",
      "Training: Epoch 62, Batch 5, Loss: 0.035\n",
      "Training: Epoch 62, Batch 6, Loss: 0.029\n",
      "Training: Epoch 62, Batch 7, Loss: 0.038\n",
      "Training: Epoch 62, Batch 8, Loss: 0.037\n",
      "Training: Epoch 62, Batch 9, Loss: 0.036\n",
      "Training: Epoch 62, Batch 10, Loss: 0.028\n",
      "Training: Epoch 62, Batch 11, Loss: 0.029\n",
      "Training: Epoch 62, Batch 12, Loss: 0.042\n",
      "Training: Epoch 62, Batch 13, Loss: 0.035\n",
      "Training: Epoch 62, Batch 14, Loss: 0.038\n",
      "Training: Epoch 62, Batch 15, Loss: 0.038\n",
      "Training: Epoch 62, Batch 16, Loss: 0.032\n",
      "Training: Epoch 62, Batch 17, Loss: 0.034\n",
      "Training: Epoch 62, Batch 18, Loss: 0.038\n",
      "Training: Epoch 62, Batch 19, Loss: 0.044\n",
      "Val: Epoch 62, Loss: 0.402\n",
      "Training: Epoch 63, Batch 0, Loss: 0.054\n",
      "Training: Epoch 63, Batch 1, Loss: 0.026\n",
      "Training: Epoch 63, Batch 2, Loss: 0.031\n",
      "Training: Epoch 63, Batch 3, Loss: 0.031\n",
      "Training: Epoch 63, Batch 4, Loss: 0.036\n",
      "Training: Epoch 63, Batch 5, Loss: 0.039\n",
      "Training: Epoch 63, Batch 6, Loss: 0.035\n",
      "Training: Epoch 63, Batch 7, Loss: 0.034\n",
      "Training: Epoch 63, Batch 8, Loss: 0.035\n",
      "Training: Epoch 63, Batch 9, Loss: 0.036\n",
      "Training: Epoch 63, Batch 10, Loss: 0.034\n",
      "Training: Epoch 63, Batch 11, Loss: 0.04\n",
      "Training: Epoch 63, Batch 12, Loss: 0.042\n",
      "Training: Epoch 63, Batch 13, Loss: 0.032\n",
      "Training: Epoch 63, Batch 14, Loss: 0.035\n",
      "Training: Epoch 63, Batch 15, Loss: 0.03\n",
      "Training: Epoch 63, Batch 16, Loss: 0.038\n",
      "Training: Epoch 63, Batch 17, Loss: 0.043\n",
      "Training: Epoch 63, Batch 18, Loss: 0.038\n",
      "Training: Epoch 63, Batch 19, Loss: 0.03\n",
      "Val: Epoch 63, Loss: 0.411\n",
      "Training: Epoch 64, Batch 0, Loss: 0.039\n",
      "Training: Epoch 64, Batch 1, Loss: 0.046\n",
      "Training: Epoch 64, Batch 2, Loss: 0.039\n",
      "Training: Epoch 64, Batch 3, Loss: 0.033\n",
      "Training: Epoch 64, Batch 4, Loss: 0.029\n",
      "Training: Epoch 64, Batch 5, Loss: 0.036\n",
      "Training: Epoch 64, Batch 6, Loss: 0.03\n",
      "Training: Epoch 64, Batch 7, Loss: 0.039\n",
      "Training: Epoch 64, Batch 8, Loss: 0.036\n",
      "Training: Epoch 64, Batch 9, Loss: 0.029\n",
      "Training: Epoch 64, Batch 10, Loss: 0.026\n",
      "Training: Epoch 64, Batch 11, Loss: 0.029\n",
      "Training: Epoch 64, Batch 12, Loss: 0.034\n",
      "Training: Epoch 64, Batch 13, Loss: 0.03\n",
      "Training: Epoch 64, Batch 14, Loss: 0.046\n",
      "Training: Epoch 64, Batch 15, Loss: 0.03\n",
      "Training: Epoch 64, Batch 16, Loss: 0.036\n",
      "Training: Epoch 64, Batch 17, Loss: 0.037\n",
      "Training: Epoch 64, Batch 18, Loss: 0.03\n",
      "Training: Epoch 64, Batch 19, Loss: 0.034\n",
      "Val: Epoch 64, Loss: 0.416\n",
      "Training: Epoch 65, Batch 0, Loss: 0.034\n",
      "Training: Epoch 65, Batch 1, Loss: 0.024\n",
      "Training: Epoch 65, Batch 2, Loss: 0.027\n",
      "Training: Epoch 65, Batch 3, Loss: 0.032\n",
      "Training: Epoch 65, Batch 4, Loss: 0.035\n",
      "Training: Epoch 65, Batch 5, Loss: 0.039\n",
      "Training: Epoch 65, Batch 6, Loss: 0.029\n",
      "Training: Epoch 65, Batch 7, Loss: 0.031\n",
      "Training: Epoch 65, Batch 8, Loss: 0.029\n",
      "Training: Epoch 65, Batch 9, Loss: 0.03\n",
      "Training: Epoch 65, Batch 10, Loss: 0.039\n",
      "Training: Epoch 65, Batch 11, Loss: 0.032\n",
      "Training: Epoch 65, Batch 12, Loss: 0.03\n",
      "Training: Epoch 65, Batch 13, Loss: 0.031\n",
      "Training: Epoch 65, Batch 14, Loss: 0.034\n",
      "Training: Epoch 65, Batch 15, Loss: 0.052\n",
      "Training: Epoch 65, Batch 16, Loss: 0.035\n",
      "Training: Epoch 65, Batch 17, Loss: 0.036\n",
      "Training: Epoch 65, Batch 18, Loss: 0.032\n",
      "Training: Epoch 65, Batch 19, Loss: 0.028\n",
      "Val: Epoch 65, Loss: 0.409\n",
      "Training: Epoch 66, Batch 0, Loss: 0.03\n",
      "Training: Epoch 66, Batch 1, Loss: 0.034\n",
      "Training: Epoch 66, Batch 2, Loss: 0.027\n",
      "Training: Epoch 66, Batch 3, Loss: 0.027\n",
      "Training: Epoch 66, Batch 4, Loss: 0.029\n",
      "Training: Epoch 66, Batch 5, Loss: 0.034\n",
      "Training: Epoch 66, Batch 6, Loss: 0.025\n",
      "Training: Epoch 66, Batch 7, Loss: 0.032\n",
      "Training: Epoch 66, Batch 8, Loss: 0.028\n",
      "Training: Epoch 66, Batch 9, Loss: 0.03\n",
      "Training: Epoch 66, Batch 10, Loss: 0.026\n",
      "Training: Epoch 66, Batch 11, Loss: 0.029\n",
      "Training: Epoch 66, Batch 12, Loss: 0.035\n",
      "Training: Epoch 66, Batch 13, Loss: 0.038\n",
      "Training: Epoch 66, Batch 14, Loss: 0.032\n",
      "Training: Epoch 66, Batch 15, Loss: 0.028\n",
      "Training: Epoch 66, Batch 16, Loss: 0.041\n",
      "Training: Epoch 66, Batch 17, Loss: 0.033\n",
      "Training: Epoch 66, Batch 18, Loss: 0.033\n",
      "Training: Epoch 66, Batch 19, Loss: 0.029\n",
      "Val: Epoch 66, Loss: 0.42\n",
      "Training: Epoch 67, Batch 0, Loss: 0.039\n",
      "Training: Epoch 67, Batch 1, Loss: 0.045\n",
      "Training: Epoch 67, Batch 2, Loss: 0.028\n",
      "Training: Epoch 67, Batch 3, Loss: 0.03\n",
      "Training: Epoch 67, Batch 4, Loss: 0.027\n",
      "Training: Epoch 67, Batch 5, Loss: 0.029\n",
      "Training: Epoch 67, Batch 6, Loss: 0.032\n",
      "Training: Epoch 67, Batch 7, Loss: 0.027\n",
      "Training: Epoch 67, Batch 8, Loss: 0.029\n",
      "Training: Epoch 67, Batch 9, Loss: 0.023\n",
      "Training: Epoch 67, Batch 10, Loss: 0.034\n",
      "Training: Epoch 67, Batch 11, Loss: 0.042\n",
      "Training: Epoch 67, Batch 12, Loss: 0.029\n",
      "Training: Epoch 67, Batch 13, Loss: 0.027\n",
      "Training: Epoch 67, Batch 14, Loss: 0.031\n",
      "Training: Epoch 67, Batch 15, Loss: 0.027\n",
      "Training: Epoch 67, Batch 16, Loss: 0.031\n",
      "Training: Epoch 67, Batch 17, Loss: 0.033\n",
      "Training: Epoch 67, Batch 18, Loss: 0.024\n",
      "Training: Epoch 67, Batch 19, Loss: 0.028\n",
      "Val: Epoch 67, Loss: 0.442\n",
      "Training: Epoch 68, Batch 0, Loss: 0.03\n",
      "Training: Epoch 68, Batch 1, Loss: 0.026\n",
      "Training: Epoch 68, Batch 2, Loss: 0.032\n",
      "Training: Epoch 68, Batch 3, Loss: 0.028\n",
      "Training: Epoch 68, Batch 4, Loss: 0.042\n",
      "Training: Epoch 68, Batch 5, Loss: 0.024\n",
      "Training: Epoch 68, Batch 6, Loss: 0.027\n",
      "Training: Epoch 68, Batch 7, Loss: 0.035\n",
      "Training: Epoch 68, Batch 8, Loss: 0.027\n",
      "Training: Epoch 68, Batch 9, Loss: 0.043\n",
      "Training: Epoch 68, Batch 10, Loss: 0.038\n",
      "Training: Epoch 68, Batch 11, Loss: 0.038\n",
      "Training: Epoch 68, Batch 12, Loss: 0.027\n",
      "Training: Epoch 68, Batch 13, Loss: 0.03\n",
      "Training: Epoch 68, Batch 14, Loss: 0.035\n",
      "Training: Epoch 68, Batch 15, Loss: 0.033\n",
      "Training: Epoch 68, Batch 16, Loss: 0.03\n",
      "Training: Epoch 68, Batch 17, Loss: 0.037\n",
      "Training: Epoch 68, Batch 18, Loss: 0.037\n",
      "Training: Epoch 68, Batch 19, Loss: 0.034\n",
      "Val: Epoch 68, Loss: 0.571\n",
      "Training: Epoch 69, Batch 0, Loss: 0.033\n",
      "Training: Epoch 69, Batch 1, Loss: 0.034\n",
      "Training: Epoch 69, Batch 2, Loss: 0.039\n",
      "Training: Epoch 69, Batch 3, Loss: 0.03\n",
      "Training: Epoch 69, Batch 4, Loss: 0.04\n",
      "Training: Epoch 69, Batch 5, Loss: 0.035\n",
      "Training: Epoch 69, Batch 6, Loss: 0.028\n",
      "Training: Epoch 69, Batch 7, Loss: 0.035\n",
      "Training: Epoch 69, Batch 8, Loss: 0.026\n",
      "Training: Epoch 69, Batch 9, Loss: 0.03\n",
      "Training: Epoch 69, Batch 10, Loss: 0.035\n",
      "Training: Epoch 69, Batch 11, Loss: 0.028\n",
      "Training: Epoch 69, Batch 12, Loss: 0.034\n",
      "Training: Epoch 69, Batch 13, Loss: 0.03\n",
      "Training: Epoch 69, Batch 14, Loss: 0.029\n",
      "Training: Epoch 69, Batch 15, Loss: 0.03\n",
      "Training: Epoch 69, Batch 16, Loss: 0.028\n",
      "Training: Epoch 69, Batch 17, Loss: 0.029\n",
      "Training: Epoch 69, Batch 18, Loss: 0.032\n",
      "Training: Epoch 69, Batch 19, Loss: 0.033\n",
      "Val: Epoch 69, Loss: 0.425\n",
      "Training: Epoch 70, Batch 0, Loss: 0.027\n",
      "Training: Epoch 70, Batch 1, Loss: 0.027\n",
      "Training: Epoch 70, Batch 2, Loss: 0.028\n",
      "Training: Epoch 70, Batch 3, Loss: 0.041\n",
      "Training: Epoch 70, Batch 4, Loss: 0.025\n",
      "Training: Epoch 70, Batch 5, Loss: 0.028\n",
      "Training: Epoch 70, Batch 6, Loss: 0.03\n",
      "Training: Epoch 70, Batch 7, Loss: 0.026\n",
      "Training: Epoch 70, Batch 8, Loss: 0.036\n",
      "Training: Epoch 70, Batch 9, Loss: 0.028\n",
      "Training: Epoch 70, Batch 10, Loss: 0.036\n",
      "Training: Epoch 70, Batch 11, Loss: 0.027\n",
      "Training: Epoch 70, Batch 12, Loss: 0.029\n",
      "Training: Epoch 70, Batch 13, Loss: 0.029\n",
      "Training: Epoch 70, Batch 14, Loss: 0.026\n",
      "Training: Epoch 70, Batch 15, Loss: 0.031\n",
      "Training: Epoch 70, Batch 16, Loss: 0.029\n",
      "Training: Epoch 70, Batch 17, Loss: 0.029\n",
      "Training: Epoch 70, Batch 18, Loss: 0.03\n",
      "Training: Epoch 70, Batch 19, Loss: 0.037\n",
      "Val: Epoch 70, Loss: 0.471\n",
      "Training: Epoch 71, Batch 0, Loss: 0.026\n",
      "Training: Epoch 71, Batch 1, Loss: 0.04\n",
      "Training: Epoch 71, Batch 2, Loss: 0.03\n",
      "Training: Epoch 71, Batch 3, Loss: 0.039\n",
      "Training: Epoch 71, Batch 4, Loss: 0.031\n",
      "Training: Epoch 71, Batch 5, Loss: 0.029\n",
      "Training: Epoch 71, Batch 6, Loss: 0.024\n",
      "Training: Epoch 71, Batch 7, Loss: 0.026\n",
      "Training: Epoch 71, Batch 8, Loss: 0.033\n",
      "Training: Epoch 71, Batch 9, Loss: 0.025\n",
      "Training: Epoch 71, Batch 10, Loss: 0.033\n",
      "Training: Epoch 71, Batch 11, Loss: 0.027\n",
      "Training: Epoch 71, Batch 12, Loss: 0.027\n",
      "Training: Epoch 71, Batch 13, Loss: 0.034\n",
      "Training: Epoch 71, Batch 14, Loss: 0.028\n",
      "Training: Epoch 71, Batch 15, Loss: 0.034\n",
      "Training: Epoch 71, Batch 16, Loss: 0.022\n",
      "Training: Epoch 71, Batch 17, Loss: 0.023\n",
      "Training: Epoch 71, Batch 18, Loss: 0.03\n",
      "Training: Epoch 71, Batch 19, Loss: 0.042\n",
      "Val: Epoch 71, Loss: 0.451\n",
      "Training: Epoch 72, Batch 0, Loss: 0.029\n",
      "Training: Epoch 72, Batch 1, Loss: 0.029\n",
      "Training: Epoch 72, Batch 2, Loss: 0.03\n",
      "Training: Epoch 72, Batch 3, Loss: 0.027\n",
      "Training: Epoch 72, Batch 4, Loss: 0.024\n",
      "Training: Epoch 72, Batch 5, Loss: 0.03\n",
      "Training: Epoch 72, Batch 6, Loss: 0.03\n",
      "Training: Epoch 72, Batch 7, Loss: 0.032\n",
      "Training: Epoch 72, Batch 8, Loss: 0.027\n",
      "Training: Epoch 72, Batch 9, Loss: 0.037\n",
      "Training: Epoch 72, Batch 10, Loss: 0.025\n",
      "Training: Epoch 72, Batch 11, Loss: 0.034\n",
      "Training: Epoch 72, Batch 12, Loss: 0.027\n",
      "Training: Epoch 72, Batch 13, Loss: 0.026\n",
      "Training: Epoch 72, Batch 14, Loss: 0.024\n",
      "Training: Epoch 72, Batch 15, Loss: 0.031\n",
      "Training: Epoch 72, Batch 16, Loss: 0.025\n",
      "Training: Epoch 72, Batch 17, Loss: 0.04\n",
      "Training: Epoch 72, Batch 18, Loss: 0.027\n",
      "Training: Epoch 72, Batch 19, Loss: 0.024\n",
      "Val: Epoch 72, Loss: 0.476\n",
      "Training: Epoch 73, Batch 0, Loss: 0.033\n",
      "Training: Epoch 73, Batch 1, Loss: 0.022\n",
      "Training: Epoch 73, Batch 2, Loss: 0.03\n",
      "Training: Epoch 73, Batch 3, Loss: 0.038\n",
      "Training: Epoch 73, Batch 4, Loss: 0.035\n",
      "Training: Epoch 73, Batch 5, Loss: 0.028\n",
      "Training: Epoch 73, Batch 6, Loss: 0.029\n",
      "Training: Epoch 73, Batch 7, Loss: 0.032\n",
      "Training: Epoch 73, Batch 8, Loss: 0.029\n",
      "Training: Epoch 73, Batch 9, Loss: 0.04\n",
      "Training: Epoch 73, Batch 10, Loss: 0.033\n",
      "Training: Epoch 73, Batch 11, Loss: 0.036\n",
      "Training: Epoch 73, Batch 12, Loss: 0.034\n",
      "Training: Epoch 73, Batch 13, Loss: 0.045\n",
      "Training: Epoch 73, Batch 14, Loss: 0.034\n",
      "Training: Epoch 73, Batch 15, Loss: 0.03\n",
      "Training: Epoch 73, Batch 16, Loss: 0.045\n",
      "Training: Epoch 73, Batch 17, Loss: 0.03\n",
      "Training: Epoch 73, Batch 18, Loss: 0.037\n",
      "Training: Epoch 73, Batch 19, Loss: 0.045\n",
      "Val: Epoch 73, Loss: 0.442\n",
      "Training: Epoch 74, Batch 0, Loss: 0.048\n",
      "Training: Epoch 74, Batch 1, Loss: 0.038\n",
      "Training: Epoch 74, Batch 2, Loss: 0.04\n",
      "Training: Epoch 74, Batch 3, Loss: 0.035\n",
      "Training: Epoch 74, Batch 4, Loss: 0.034\n",
      "Training: Epoch 74, Batch 5, Loss: 0.04\n",
      "Training: Epoch 74, Batch 6, Loss: 0.035\n",
      "Training: Epoch 74, Batch 7, Loss: 0.036\n",
      "Training: Epoch 74, Batch 8, Loss: 0.031\n",
      "Training: Epoch 74, Batch 9, Loss: 0.028\n",
      "Training: Epoch 74, Batch 10, Loss: 0.032\n",
      "Training: Epoch 74, Batch 11, Loss: 0.031\n",
      "Training: Epoch 74, Batch 12, Loss: 0.03\n",
      "Training: Epoch 74, Batch 13, Loss: 0.035\n",
      "Training: Epoch 74, Batch 14, Loss: 0.037\n",
      "Training: Epoch 74, Batch 15, Loss: 0.033\n",
      "Training: Epoch 74, Batch 16, Loss: 0.044\n",
      "Training: Epoch 74, Batch 17, Loss: 0.032\n",
      "Training: Epoch 74, Batch 18, Loss: 0.032\n",
      "Training: Epoch 74, Batch 19, Loss: 0.035\n",
      "Val: Epoch 74, Loss: 0.484\n",
      "Training: Epoch 75, Batch 0, Loss: 0.035\n",
      "Training: Epoch 75, Batch 1, Loss: 0.035\n",
      "Training: Epoch 75, Batch 2, Loss: 0.029\n",
      "Training: Epoch 75, Batch 3, Loss: 0.037\n",
      "Training: Epoch 75, Batch 4, Loss: 0.033\n",
      "Training: Epoch 75, Batch 5, Loss: 0.032\n",
      "Training: Epoch 75, Batch 6, Loss: 0.03\n",
      "Training: Epoch 75, Batch 7, Loss: 0.036\n",
      "Training: Epoch 75, Batch 8, Loss: 0.027\n",
      "Training: Epoch 75, Batch 9, Loss: 0.027\n",
      "Training: Epoch 75, Batch 10, Loss: 0.034\n",
      "Training: Epoch 75, Batch 11, Loss: 0.035\n",
      "Training: Epoch 75, Batch 12, Loss: 0.034\n",
      "Training: Epoch 75, Batch 13, Loss: 0.031\n",
      "Training: Epoch 75, Batch 14, Loss: 0.036\n",
      "Training: Epoch 75, Batch 15, Loss: 0.035\n",
      "Training: Epoch 75, Batch 16, Loss: 0.037\n",
      "Training: Epoch 75, Batch 17, Loss: 0.035\n",
      "Training: Epoch 75, Batch 18, Loss: 0.032\n",
      "Training: Epoch 75, Batch 19, Loss: 0.025\n",
      "Val: Epoch 75, Loss: 0.438\n",
      "Training: Epoch 76, Batch 0, Loss: 0.027\n",
      "Training: Epoch 76, Batch 1, Loss: 0.028\n",
      "Training: Epoch 76, Batch 2, Loss: 0.024\n",
      "Training: Epoch 76, Batch 3, Loss: 0.031\n",
      "Training: Epoch 76, Batch 4, Loss: 0.033\n",
      "Training: Epoch 76, Batch 5, Loss: 0.025\n",
      "Training: Epoch 76, Batch 6, Loss: 0.024\n",
      "Training: Epoch 76, Batch 7, Loss: 0.033\n",
      "Training: Epoch 76, Batch 8, Loss: 0.027\n",
      "Training: Epoch 76, Batch 9, Loss: 0.032\n",
      "Training: Epoch 76, Batch 10, Loss: 0.031\n",
      "Training: Epoch 76, Batch 11, Loss: 0.024\n",
      "Training: Epoch 76, Batch 12, Loss: 0.023\n",
      "Training: Epoch 76, Batch 13, Loss: 0.028\n",
      "Training: Epoch 76, Batch 14, Loss: 0.027\n",
      "Training: Epoch 76, Batch 15, Loss: 0.031\n",
      "Training: Epoch 76, Batch 16, Loss: 0.026\n",
      "Training: Epoch 76, Batch 17, Loss: 0.027\n",
      "Training: Epoch 76, Batch 18, Loss: 0.046\n",
      "Training: Epoch 76, Batch 19, Loss: 0.028\n",
      "Val: Epoch 76, Loss: 0.482\n",
      "Training: Epoch 77, Batch 0, Loss: 0.033\n",
      "Training: Epoch 77, Batch 1, Loss: 0.028\n",
      "Training: Epoch 77, Batch 2, Loss: 0.023\n",
      "Training: Epoch 77, Batch 3, Loss: 0.031\n",
      "Training: Epoch 77, Batch 4, Loss: 0.026\n",
      "Training: Epoch 77, Batch 5, Loss: 0.021\n",
      "Training: Epoch 77, Batch 6, Loss: 0.03\n",
      "Training: Epoch 77, Batch 7, Loss: 0.036\n",
      "Training: Epoch 77, Batch 8, Loss: 0.022\n",
      "Training: Epoch 77, Batch 9, Loss: 0.03\n",
      "Training: Epoch 77, Batch 10, Loss: 0.028\n",
      "Training: Epoch 77, Batch 11, Loss: 0.026\n",
      "Training: Epoch 77, Batch 12, Loss: 0.023\n",
      "Training: Epoch 77, Batch 13, Loss: 0.026\n",
      "Training: Epoch 77, Batch 14, Loss: 0.028\n",
      "Training: Epoch 77, Batch 15, Loss: 0.028\n",
      "Training: Epoch 77, Batch 16, Loss: 0.028\n",
      "Training: Epoch 77, Batch 17, Loss: 0.026\n",
      "Training: Epoch 77, Batch 18, Loss: 0.026\n",
      "Training: Epoch 77, Batch 19, Loss: 0.027\n",
      "Val: Epoch 77, Loss: 0.479\n",
      "Training: Epoch 78, Batch 0, Loss: 0.024\n",
      "Training: Epoch 78, Batch 1, Loss: 0.025\n",
      "Training: Epoch 78, Batch 2, Loss: 0.024\n",
      "Training: Epoch 78, Batch 3, Loss: 0.032\n",
      "Training: Epoch 78, Batch 4, Loss: 0.024\n",
      "Training: Epoch 78, Batch 5, Loss: 0.021\n",
      "Training: Epoch 78, Batch 6, Loss: 0.024\n",
      "Training: Epoch 78, Batch 7, Loss: 0.027\n",
      "Training: Epoch 78, Batch 8, Loss: 0.034\n",
      "Training: Epoch 78, Batch 9, Loss: 0.029\n",
      "Training: Epoch 78, Batch 10, Loss: 0.031\n",
      "Training: Epoch 78, Batch 11, Loss: 0.033\n",
      "Training: Epoch 78, Batch 12, Loss: 0.027\n",
      "Training: Epoch 78, Batch 13, Loss: 0.027\n",
      "Training: Epoch 78, Batch 14, Loss: 0.027\n",
      "Training: Epoch 78, Batch 15, Loss: 0.03\n",
      "Training: Epoch 78, Batch 16, Loss: 0.02\n",
      "Training: Epoch 78, Batch 17, Loss: 0.027\n",
      "Training: Epoch 78, Batch 18, Loss: 0.027\n",
      "Training: Epoch 78, Batch 19, Loss: 0.028\n",
      "Val: Epoch 78, Loss: 0.458\n",
      "Training: Epoch 79, Batch 0, Loss: 0.025\n",
      "Training: Epoch 79, Batch 1, Loss: 0.032\n",
      "Training: Epoch 79, Batch 2, Loss: 0.024\n",
      "Training: Epoch 79, Batch 3, Loss: 0.022\n",
      "Training: Epoch 79, Batch 4, Loss: 0.027\n",
      "Training: Epoch 79, Batch 5, Loss: 0.024\n",
      "Training: Epoch 79, Batch 6, Loss: 0.025\n",
      "Training: Epoch 79, Batch 7, Loss: 0.026\n",
      "Training: Epoch 79, Batch 8, Loss: 0.027\n",
      "Training: Epoch 79, Batch 9, Loss: 0.029\n",
      "Training: Epoch 79, Batch 10, Loss: 0.027\n",
      "Training: Epoch 79, Batch 11, Loss: 0.028\n",
      "Training: Epoch 79, Batch 12, Loss: 0.023\n",
      "Training: Epoch 79, Batch 13, Loss: 0.032\n",
      "Training: Epoch 79, Batch 14, Loss: 0.03\n",
      "Training: Epoch 79, Batch 15, Loss: 0.028\n",
      "Training: Epoch 79, Batch 16, Loss: 0.025\n",
      "Training: Epoch 79, Batch 17, Loss: 0.025\n",
      "Training: Epoch 79, Batch 18, Loss: 0.024\n",
      "Training: Epoch 79, Batch 19, Loss: 0.024\n",
      "Val: Epoch 79, Loss: 0.479\n",
      "Training: Epoch 80, Batch 0, Loss: 0.025\n",
      "Training: Epoch 80, Batch 1, Loss: 0.022\n",
      "Training: Epoch 80, Batch 2, Loss: 0.023\n",
      "Training: Epoch 80, Batch 3, Loss: 0.024\n",
      "Training: Epoch 80, Batch 4, Loss: 0.025\n",
      "Training: Epoch 80, Batch 5, Loss: 0.027\n",
      "Training: Epoch 80, Batch 6, Loss: 0.027\n",
      "Training: Epoch 80, Batch 7, Loss: 0.019\n",
      "Training: Epoch 80, Batch 8, Loss: 0.025\n",
      "Training: Epoch 80, Batch 9, Loss: 0.024\n",
      "Training: Epoch 80, Batch 10, Loss: 0.021\n",
      "Training: Epoch 80, Batch 11, Loss: 0.04\n",
      "Training: Epoch 80, Batch 12, Loss: 0.019\n",
      "Training: Epoch 80, Batch 13, Loss: 0.026\n",
      "Training: Epoch 80, Batch 14, Loss: 0.019\n",
      "Training: Epoch 80, Batch 15, Loss: 0.026\n",
      "Training: Epoch 80, Batch 16, Loss: 0.026\n",
      "Training: Epoch 80, Batch 17, Loss: 0.027\n",
      "Training: Epoch 80, Batch 18, Loss: 0.026\n",
      "Training: Epoch 80, Batch 19, Loss: 0.027\n",
      "Val: Epoch 80, Loss: 0.466\n",
      "Training: Epoch 81, Batch 0, Loss: 0.031\n",
      "Training: Epoch 81, Batch 1, Loss: 0.022\n",
      "Training: Epoch 81, Batch 2, Loss: 0.025\n",
      "Training: Epoch 81, Batch 3, Loss: 0.027\n",
      "Training: Epoch 81, Batch 4, Loss: 0.021\n",
      "Training: Epoch 81, Batch 5, Loss: 0.023\n",
      "Training: Epoch 81, Batch 6, Loss: 0.021\n",
      "Training: Epoch 81, Batch 7, Loss: 0.022\n",
      "Training: Epoch 81, Batch 8, Loss: 0.027\n",
      "Training: Epoch 81, Batch 9, Loss: 0.03\n",
      "Training: Epoch 81, Batch 10, Loss: 0.027\n",
      "Training: Epoch 81, Batch 11, Loss: 0.028\n",
      "Training: Epoch 81, Batch 12, Loss: 0.024\n",
      "Training: Epoch 81, Batch 13, Loss: 0.022\n",
      "Training: Epoch 81, Batch 14, Loss: 0.036\n",
      "Training: Epoch 81, Batch 15, Loss: 0.022\n",
      "Training: Epoch 81, Batch 16, Loss: 0.026\n",
      "Training: Epoch 81, Batch 17, Loss: 0.025\n",
      "Training: Epoch 81, Batch 18, Loss: 0.024\n",
      "Training: Epoch 81, Batch 19, Loss: 0.035\n",
      "Val: Epoch 81, Loss: 0.5\n",
      "Training: Epoch 82, Batch 0, Loss: 0.025\n",
      "Training: Epoch 82, Batch 1, Loss: 0.045\n",
      "Training: Epoch 82, Batch 2, Loss: 0.025\n",
      "Training: Epoch 82, Batch 3, Loss: 0.024\n",
      "Training: Epoch 82, Batch 4, Loss: 0.034\n",
      "Training: Epoch 82, Batch 5, Loss: 0.022\n",
      "Training: Epoch 82, Batch 6, Loss: 0.027\n",
      "Training: Epoch 82, Batch 7, Loss: 0.028\n",
      "Training: Epoch 82, Batch 8, Loss: 0.034\n",
      "Training: Epoch 82, Batch 9, Loss: 0.027\n",
      "Training: Epoch 82, Batch 10, Loss: 0.03\n",
      "Training: Epoch 82, Batch 11, Loss: 0.024\n",
      "Training: Epoch 82, Batch 12, Loss: 0.024\n",
      "Training: Epoch 82, Batch 13, Loss: 0.024\n",
      "Training: Epoch 82, Batch 14, Loss: 0.027\n",
      "Training: Epoch 82, Batch 15, Loss: 0.031\n",
      "Training: Epoch 82, Batch 16, Loss: 0.028\n",
      "Training: Epoch 82, Batch 17, Loss: 0.035\n",
      "Training: Epoch 82, Batch 18, Loss: 0.028\n",
      "Training: Epoch 82, Batch 19, Loss: 0.029\n",
      "Val: Epoch 82, Loss: 0.554\n",
      "Training: Epoch 83, Batch 0, Loss: 0.026\n",
      "Training: Epoch 83, Batch 1, Loss: 0.04\n",
      "Training: Epoch 83, Batch 2, Loss: 0.038\n",
      "Training: Epoch 83, Batch 3, Loss: 0.022\n",
      "Training: Epoch 83, Batch 4, Loss: 0.031\n",
      "Training: Epoch 83, Batch 5, Loss: 0.024\n",
      "Training: Epoch 83, Batch 6, Loss: 0.025\n",
      "Training: Epoch 83, Batch 7, Loss: 0.033\n",
      "Training: Epoch 83, Batch 8, Loss: 0.024\n",
      "Training: Epoch 83, Batch 9, Loss: 0.02\n",
      "Training: Epoch 83, Batch 10, Loss: 0.031\n",
      "Training: Epoch 83, Batch 11, Loss: 0.027\n",
      "Training: Epoch 83, Batch 12, Loss: 0.028\n",
      "Training: Epoch 83, Batch 13, Loss: 0.021\n",
      "Training: Epoch 83, Batch 14, Loss: 0.036\n",
      "Training: Epoch 83, Batch 15, Loss: 0.025\n",
      "Training: Epoch 83, Batch 16, Loss: 0.031\n",
      "Training: Epoch 83, Batch 17, Loss: 0.028\n",
      "Training: Epoch 83, Batch 18, Loss: 0.023\n",
      "Training: Epoch 83, Batch 19, Loss: 0.024\n",
      "Val: Epoch 83, Loss: 0.464\n",
      "Training: Epoch 84, Batch 0, Loss: 0.025\n",
      "Training: Epoch 84, Batch 1, Loss: 0.022\n",
      "Training: Epoch 84, Batch 2, Loss: 0.024\n",
      "Training: Epoch 84, Batch 3, Loss: 0.027\n",
      "Training: Epoch 84, Batch 4, Loss: 0.029\n",
      "Training: Epoch 84, Batch 5, Loss: 0.021\n",
      "Training: Epoch 84, Batch 6, Loss: 0.031\n",
      "Training: Epoch 84, Batch 7, Loss: 0.022\n",
      "Training: Epoch 84, Batch 8, Loss: 0.023\n",
      "Training: Epoch 84, Batch 9, Loss: 0.029\n",
      "Training: Epoch 84, Batch 10, Loss: 0.025\n",
      "Training: Epoch 84, Batch 11, Loss: 0.024\n",
      "Training: Epoch 84, Batch 12, Loss: 0.021\n",
      "Training: Epoch 84, Batch 13, Loss: 0.025\n",
      "Training: Epoch 84, Batch 14, Loss: 0.03\n",
      "Training: Epoch 84, Batch 15, Loss: 0.026\n",
      "Training: Epoch 84, Batch 16, Loss: 0.028\n",
      "Training: Epoch 84, Batch 17, Loss: 0.023\n",
      "Training: Epoch 84, Batch 18, Loss: 0.027\n",
      "Training: Epoch 84, Batch 19, Loss: 0.04\n",
      "Val: Epoch 84, Loss: 0.475\n",
      "Training: Epoch 85, Batch 0, Loss: 0.028\n",
      "Training: Epoch 85, Batch 1, Loss: 0.023\n",
      "Training: Epoch 85, Batch 2, Loss: 0.025\n",
      "Training: Epoch 85, Batch 3, Loss: 0.02\n",
      "Training: Epoch 85, Batch 4, Loss: 0.019\n",
      "Training: Epoch 85, Batch 5, Loss: 0.019\n",
      "Training: Epoch 85, Batch 6, Loss: 0.024\n",
      "Training: Epoch 85, Batch 7, Loss: 0.026\n",
      "Training: Epoch 85, Batch 8, Loss: 0.022\n",
      "Training: Epoch 85, Batch 9, Loss: 0.022\n",
      "Training: Epoch 85, Batch 10, Loss: 0.03\n",
      "Training: Epoch 85, Batch 11, Loss: 0.022\n",
      "Training: Epoch 85, Batch 12, Loss: 0.025\n",
      "Training: Epoch 85, Batch 13, Loss: 0.022\n",
      "Training: Epoch 85, Batch 14, Loss: 0.022\n",
      "Training: Epoch 85, Batch 15, Loss: 0.023\n",
      "Training: Epoch 85, Batch 16, Loss: 0.03\n",
      "Training: Epoch 85, Batch 17, Loss: 0.03\n",
      "Training: Epoch 85, Batch 18, Loss: 0.022\n",
      "Training: Epoch 85, Batch 19, Loss: 0.027\n",
      "Val: Epoch 85, Loss: 0.458\n",
      "Training: Epoch 86, Batch 0, Loss: 0.028\n",
      "Training: Epoch 86, Batch 1, Loss: 0.024\n",
      "Training: Epoch 86, Batch 2, Loss: 0.026\n",
      "Training: Epoch 86, Batch 3, Loss: 0.02\n",
      "Training: Epoch 86, Batch 4, Loss: 0.022\n",
      "Training: Epoch 86, Batch 5, Loss: 0.02\n",
      "Training: Epoch 86, Batch 6, Loss: 0.025\n",
      "Training: Epoch 86, Batch 7, Loss: 0.028\n",
      "Training: Epoch 86, Batch 8, Loss: 0.022\n",
      "Training: Epoch 86, Batch 9, Loss: 0.022\n",
      "Training: Epoch 86, Batch 10, Loss: 0.019\n",
      "Training: Epoch 86, Batch 11, Loss: 0.024\n",
      "Training: Epoch 86, Batch 12, Loss: 0.025\n",
      "Training: Epoch 86, Batch 13, Loss: 0.025\n",
      "Training: Epoch 86, Batch 14, Loss: 0.029\n",
      "Training: Epoch 86, Batch 15, Loss: 0.02\n",
      "Training: Epoch 86, Batch 16, Loss: 0.023\n",
      "Training: Epoch 86, Batch 17, Loss: 0.022\n",
      "Training: Epoch 86, Batch 18, Loss: 0.023\n",
      "Training: Epoch 86, Batch 19, Loss: 0.023\n",
      "Val: Epoch 86, Loss: 0.482\n",
      "Training: Epoch 87, Batch 0, Loss: 0.02\n",
      "Training: Epoch 87, Batch 1, Loss: 0.023\n",
      "Training: Epoch 87, Batch 2, Loss: 0.021\n",
      "Training: Epoch 87, Batch 3, Loss: 0.022\n",
      "Training: Epoch 87, Batch 4, Loss: 0.022\n",
      "Training: Epoch 87, Batch 5, Loss: 0.023\n",
      "Training: Epoch 87, Batch 6, Loss: 0.026\n",
      "Training: Epoch 87, Batch 7, Loss: 0.023\n",
      "Training: Epoch 87, Batch 8, Loss: 0.021\n",
      "Training: Epoch 87, Batch 9, Loss: 0.021\n",
      "Training: Epoch 87, Batch 10, Loss: 0.021\n",
      "Training: Epoch 87, Batch 11, Loss: 0.025\n",
      "Training: Epoch 87, Batch 12, Loss: 0.023\n",
      "Training: Epoch 87, Batch 13, Loss: 0.026\n",
      "Training: Epoch 87, Batch 14, Loss: 0.02\n",
      "Training: Epoch 87, Batch 15, Loss: 0.031\n",
      "Training: Epoch 87, Batch 16, Loss: 0.023\n",
      "Training: Epoch 87, Batch 17, Loss: 0.028\n",
      "Training: Epoch 87, Batch 18, Loss: 0.026\n",
      "Training: Epoch 87, Batch 19, Loss: 0.022\n",
      "Val: Epoch 87, Loss: 0.522\n",
      "Training: Epoch 88, Batch 0, Loss: 0.024\n",
      "Training: Epoch 88, Batch 1, Loss: 0.022\n",
      "Training: Epoch 88, Batch 2, Loss: 0.021\n",
      "Training: Epoch 88, Batch 3, Loss: 0.021\n",
      "Training: Epoch 88, Batch 4, Loss: 0.021\n",
      "Training: Epoch 88, Batch 5, Loss: 0.021\n",
      "Training: Epoch 88, Batch 6, Loss: 0.021\n",
      "Training: Epoch 88, Batch 7, Loss: 0.019\n",
      "Training: Epoch 88, Batch 8, Loss: 0.017\n",
      "Training: Epoch 88, Batch 9, Loss: 0.025\n",
      "Training: Epoch 88, Batch 10, Loss: 0.021\n",
      "Training: Epoch 88, Batch 11, Loss: 0.022\n",
      "Training: Epoch 88, Batch 12, Loss: 0.021\n",
      "Training: Epoch 88, Batch 13, Loss: 0.03\n",
      "Training: Epoch 88, Batch 14, Loss: 0.024\n",
      "Training: Epoch 88, Batch 15, Loss: 0.024\n",
      "Training: Epoch 88, Batch 16, Loss: 0.031\n",
      "Training: Epoch 88, Batch 17, Loss: 0.023\n",
      "Training: Epoch 88, Batch 18, Loss: 0.022\n",
      "Training: Epoch 88, Batch 19, Loss: 0.023\n",
      "Val: Epoch 88, Loss: 0.483\n",
      "Training: Epoch 89, Batch 0, Loss: 0.024\n",
      "Training: Epoch 89, Batch 1, Loss: 0.022\n",
      "Training: Epoch 89, Batch 2, Loss: 0.028\n",
      "Training: Epoch 89, Batch 3, Loss: 0.024\n",
      "Training: Epoch 89, Batch 4, Loss: 0.022\n",
      "Training: Epoch 89, Batch 5, Loss: 0.022\n",
      "Training: Epoch 89, Batch 6, Loss: 0.02\n",
      "Training: Epoch 89, Batch 7, Loss: 0.024\n",
      "Training: Epoch 89, Batch 8, Loss: 0.025\n",
      "Training: Epoch 89, Batch 9, Loss: 0.023\n",
      "Training: Epoch 89, Batch 10, Loss: 0.023\n",
      "Training: Epoch 89, Batch 11, Loss: 0.022\n",
      "Training: Epoch 89, Batch 12, Loss: 0.021\n",
      "Training: Epoch 89, Batch 13, Loss: 0.034\n",
      "Training: Epoch 89, Batch 14, Loss: 0.018\n",
      "Training: Epoch 89, Batch 15, Loss: 0.023\n",
      "Training: Epoch 89, Batch 16, Loss: 0.025\n",
      "Training: Epoch 89, Batch 17, Loss: 0.025\n",
      "Training: Epoch 89, Batch 18, Loss: 0.022\n",
      "Training: Epoch 89, Batch 19, Loss: 0.024\n",
      "Val: Epoch 89, Loss: 0.523\n",
      "Training: Epoch 90, Batch 0, Loss: 0.017\n",
      "Training: Epoch 90, Batch 1, Loss: 0.019\n",
      "Training: Epoch 90, Batch 2, Loss: 0.021\n",
      "Training: Epoch 90, Batch 3, Loss: 0.024\n",
      "Training: Epoch 90, Batch 4, Loss: 0.026\n",
      "Training: Epoch 90, Batch 5, Loss: 0.023\n",
      "Training: Epoch 90, Batch 6, Loss: 0.022\n",
      "Training: Epoch 90, Batch 7, Loss: 0.022\n",
      "Training: Epoch 90, Batch 8, Loss: 0.024\n",
      "Training: Epoch 90, Batch 9, Loss: 0.018\n",
      "Training: Epoch 90, Batch 10, Loss: 0.025\n",
      "Training: Epoch 90, Batch 11, Loss: 0.024\n",
      "Training: Epoch 90, Batch 12, Loss: 0.025\n",
      "Training: Epoch 90, Batch 13, Loss: 0.023\n",
      "Training: Epoch 90, Batch 14, Loss: 0.017\n",
      "Training: Epoch 90, Batch 15, Loss: 0.018\n",
      "Training: Epoch 90, Batch 16, Loss: 0.019\n",
      "Training: Epoch 90, Batch 17, Loss: 0.021\n",
      "Training: Epoch 90, Batch 18, Loss: 0.023\n",
      "Training: Epoch 90, Batch 19, Loss: 0.021\n",
      "Val: Epoch 90, Loss: 0.486\n",
      "Training: Epoch 91, Batch 0, Loss: 0.019\n",
      "Training: Epoch 91, Batch 1, Loss: 0.02\n",
      "Training: Epoch 91, Batch 2, Loss: 0.02\n",
      "Training: Epoch 91, Batch 3, Loss: 0.019\n",
      "Training: Epoch 91, Batch 4, Loss: 0.026\n",
      "Training: Epoch 91, Batch 5, Loss: 0.022\n",
      "Training: Epoch 91, Batch 6, Loss: 0.029\n",
      "Training: Epoch 91, Batch 7, Loss: 0.018\n",
      "Training: Epoch 91, Batch 8, Loss: 0.026\n",
      "Training: Epoch 91, Batch 9, Loss: 0.02\n",
      "Training: Epoch 91, Batch 10, Loss: 0.021\n",
      "Training: Epoch 91, Batch 11, Loss: 0.018\n",
      "Training: Epoch 91, Batch 12, Loss: 0.019\n",
      "Training: Epoch 91, Batch 13, Loss: 0.02\n",
      "Training: Epoch 91, Batch 14, Loss: 0.019\n",
      "Training: Epoch 91, Batch 15, Loss: 0.021\n",
      "Training: Epoch 91, Batch 16, Loss: 0.014\n",
      "Training: Epoch 91, Batch 17, Loss: 0.02\n",
      "Training: Epoch 91, Batch 18, Loss: 0.022\n",
      "Training: Epoch 91, Batch 19, Loss: 0.021\n",
      "Val: Epoch 91, Loss: 0.504\n",
      "Training: Epoch 92, Batch 0, Loss: 0.017\n",
      "Training: Epoch 92, Batch 1, Loss: 0.023\n",
      "Training: Epoch 92, Batch 2, Loss: 0.019\n",
      "Training: Epoch 92, Batch 3, Loss: 0.022\n",
      "Training: Epoch 92, Batch 4, Loss: 0.023\n",
      "Training: Epoch 92, Batch 5, Loss: 0.02\n",
      "Training: Epoch 92, Batch 6, Loss: 0.022\n",
      "Training: Epoch 92, Batch 7, Loss: 0.023\n",
      "Training: Epoch 92, Batch 8, Loss: 0.018\n",
      "Training: Epoch 92, Batch 9, Loss: 0.018\n",
      "Training: Epoch 92, Batch 10, Loss: 0.02\n",
      "Training: Epoch 92, Batch 11, Loss: 0.017\n",
      "Training: Epoch 92, Batch 12, Loss: 0.018\n",
      "Training: Epoch 92, Batch 13, Loss: 0.023\n",
      "Training: Epoch 92, Batch 14, Loss: 0.019\n",
      "Training: Epoch 92, Batch 15, Loss: 0.025\n",
      "Training: Epoch 92, Batch 16, Loss: 0.022\n",
      "Training: Epoch 92, Batch 17, Loss: 0.022\n",
      "Training: Epoch 92, Batch 18, Loss: 0.022\n",
      "Training: Epoch 92, Batch 19, Loss: 0.018\n",
      "Val: Epoch 92, Loss: 0.5\n",
      "Training: Epoch 93, Batch 0, Loss: 0.018\n",
      "Training: Epoch 93, Batch 1, Loss: 0.022\n",
      "Training: Epoch 93, Batch 2, Loss: 0.017\n",
      "Training: Epoch 93, Batch 3, Loss: 0.016\n",
      "Training: Epoch 93, Batch 4, Loss: 0.023\n",
      "Training: Epoch 93, Batch 5, Loss: 0.016\n",
      "Training: Epoch 93, Batch 6, Loss: 0.022\n",
      "Training: Epoch 93, Batch 7, Loss: 0.022\n",
      "Training: Epoch 93, Batch 8, Loss: 0.021\n",
      "Training: Epoch 93, Batch 9, Loss: 0.021\n",
      "Training: Epoch 93, Batch 10, Loss: 0.024\n",
      "Training: Epoch 93, Batch 11, Loss: 0.017\n",
      "Training: Epoch 93, Batch 12, Loss: 0.031\n",
      "Training: Epoch 93, Batch 13, Loss: 0.03\n",
      "Training: Epoch 93, Batch 14, Loss: 0.02\n",
      "Training: Epoch 93, Batch 15, Loss: 0.021\n",
      "Training: Epoch 93, Batch 16, Loss: 0.028\n",
      "Training: Epoch 93, Batch 17, Loss: 0.022\n",
      "Training: Epoch 93, Batch 18, Loss: 0.024\n",
      "Training: Epoch 93, Batch 19, Loss: 0.023\n",
      "Val: Epoch 93, Loss: 0.565\n",
      "Training: Epoch 94, Batch 0, Loss: 0.019\n",
      "Training: Epoch 94, Batch 1, Loss: 0.025\n",
      "Training: Epoch 94, Batch 2, Loss: 0.021\n",
      "Training: Epoch 94, Batch 3, Loss: 0.024\n",
      "Training: Epoch 94, Batch 4, Loss: 0.019\n",
      "Training: Epoch 94, Batch 5, Loss: 0.021\n",
      "Training: Epoch 94, Batch 6, Loss: 0.02\n",
      "Training: Epoch 94, Batch 7, Loss: 0.023\n",
      "Training: Epoch 94, Batch 8, Loss: 0.036\n",
      "Training: Epoch 94, Batch 9, Loss: 0.025\n",
      "Training: Epoch 94, Batch 10, Loss: 0.025\n",
      "Training: Epoch 94, Batch 11, Loss: 0.022\n",
      "Training: Epoch 94, Batch 12, Loss: 0.023\n",
      "Training: Epoch 94, Batch 13, Loss: 0.02\n",
      "Training: Epoch 94, Batch 14, Loss: 0.021\n",
      "Training: Epoch 94, Batch 15, Loss: 0.023\n",
      "Training: Epoch 94, Batch 16, Loss: 0.022\n",
      "Training: Epoch 94, Batch 17, Loss: 0.024\n",
      "Training: Epoch 94, Batch 18, Loss: 0.025\n",
      "Training: Epoch 94, Batch 19, Loss: 0.027\n",
      "Val: Epoch 94, Loss: 0.553\n",
      "Training: Epoch 95, Batch 0, Loss: 0.022\n",
      "Training: Epoch 95, Batch 1, Loss: 0.042\n",
      "Training: Epoch 95, Batch 2, Loss: 0.017\n",
      "Training: Epoch 95, Batch 3, Loss: 0.024\n",
      "Training: Epoch 95, Batch 4, Loss: 0.019\n",
      "Training: Epoch 95, Batch 5, Loss: 0.018\n",
      "Training: Epoch 95, Batch 6, Loss: 0.025\n",
      "Training: Epoch 95, Batch 7, Loss: 0.025\n",
      "Training: Epoch 95, Batch 8, Loss: 0.022\n",
      "Training: Epoch 95, Batch 9, Loss: 0.025\n",
      "Training: Epoch 95, Batch 10, Loss: 0.023\n",
      "Training: Epoch 95, Batch 11, Loss: 0.02\n",
      "Training: Epoch 95, Batch 12, Loss: 0.031\n",
      "Training: Epoch 95, Batch 13, Loss: 0.021\n",
      "Training: Epoch 95, Batch 14, Loss: 0.022\n",
      "Training: Epoch 95, Batch 15, Loss: 0.022\n",
      "Training: Epoch 95, Batch 16, Loss: 0.02\n",
      "Training: Epoch 95, Batch 17, Loss: 0.024\n",
      "Training: Epoch 95, Batch 18, Loss: 0.022\n",
      "Training: Epoch 95, Batch 19, Loss: 0.021\n",
      "Val: Epoch 95, Loss: 0.493\n",
      "Training: Epoch 96, Batch 0, Loss: 0.02\n",
      "Training: Epoch 96, Batch 1, Loss: 0.02\n",
      "Training: Epoch 96, Batch 2, Loss: 0.021\n",
      "Training: Epoch 96, Batch 3, Loss: 0.023\n",
      "Training: Epoch 96, Batch 4, Loss: 0.022\n",
      "Training: Epoch 96, Batch 5, Loss: 0.021\n",
      "Training: Epoch 96, Batch 6, Loss: 0.021\n",
      "Training: Epoch 96, Batch 7, Loss: 0.021\n",
      "Training: Epoch 96, Batch 8, Loss: 0.026\n",
      "Training: Epoch 96, Batch 9, Loss: 0.022\n",
      "Training: Epoch 96, Batch 10, Loss: 0.019\n",
      "Training: Epoch 96, Batch 11, Loss: 0.022\n",
      "Training: Epoch 96, Batch 12, Loss: 0.02\n",
      "Training: Epoch 96, Batch 13, Loss: 0.018\n",
      "Training: Epoch 96, Batch 14, Loss: 0.021\n",
      "Training: Epoch 96, Batch 15, Loss: 0.021\n",
      "Training: Epoch 96, Batch 16, Loss: 0.026\n",
      "Training: Epoch 96, Batch 17, Loss: 0.023\n",
      "Training: Epoch 96, Batch 18, Loss: 0.023\n",
      "Training: Epoch 96, Batch 19, Loss: 0.024\n",
      "Val: Epoch 96, Loss: 0.488\n",
      "Training: Epoch 97, Batch 0, Loss: 0.02\n",
      "Training: Epoch 97, Batch 1, Loss: 0.023\n",
      "Training: Epoch 97, Batch 2, Loss: 0.021\n",
      "Training: Epoch 97, Batch 3, Loss: 0.019\n",
      "Training: Epoch 97, Batch 4, Loss: 0.024\n",
      "Training: Epoch 97, Batch 5, Loss: 0.025\n",
      "Training: Epoch 97, Batch 6, Loss: 0.018\n",
      "Training: Epoch 97, Batch 7, Loss: 0.026\n",
      "Training: Epoch 97, Batch 8, Loss: 0.021\n",
      "Training: Epoch 97, Batch 9, Loss: 0.022\n",
      "Training: Epoch 97, Batch 10, Loss: 0.02\n",
      "Training: Epoch 97, Batch 11, Loss: 0.022\n",
      "Training: Epoch 97, Batch 12, Loss: 0.02\n",
      "Training: Epoch 97, Batch 13, Loss: 0.018\n",
      "Training: Epoch 97, Batch 14, Loss: 0.019\n",
      "Training: Epoch 97, Batch 15, Loss: 0.022\n",
      "Training: Epoch 97, Batch 16, Loss: 0.021\n",
      "Training: Epoch 97, Batch 17, Loss: 0.019\n",
      "Training: Epoch 97, Batch 18, Loss: 0.019\n",
      "Training: Epoch 97, Batch 19, Loss: 0.019\n",
      "Val: Epoch 97, Loss: 0.557\n",
      "Training: Epoch 98, Batch 0, Loss: 0.018\n",
      "Training: Epoch 98, Batch 1, Loss: 0.017\n",
      "Training: Epoch 98, Batch 2, Loss: 0.016\n",
      "Training: Epoch 98, Batch 3, Loss: 0.025\n",
      "Training: Epoch 98, Batch 4, Loss: 0.017\n",
      "Training: Epoch 98, Batch 5, Loss: 0.019\n",
      "Training: Epoch 98, Batch 6, Loss: 0.016\n",
      "Training: Epoch 98, Batch 7, Loss: 0.019\n",
      "Training: Epoch 98, Batch 8, Loss: 0.02\n",
      "Training: Epoch 98, Batch 9, Loss: 0.023\n",
      "Training: Epoch 98, Batch 10, Loss: 0.017\n",
      "Training: Epoch 98, Batch 11, Loss: 0.021\n",
      "Training: Epoch 98, Batch 12, Loss: 0.021\n",
      "Training: Epoch 98, Batch 13, Loss: 0.021\n",
      "Training: Epoch 98, Batch 14, Loss: 0.021\n",
      "Training: Epoch 98, Batch 15, Loss: 0.027\n",
      "Training: Epoch 98, Batch 16, Loss: 0.023\n",
      "Training: Epoch 98, Batch 17, Loss: 0.026\n",
      "Training: Epoch 98, Batch 18, Loss: 0.02\n",
      "Training: Epoch 98, Batch 19, Loss: 0.019\n",
      "Val: Epoch 98, Loss: 0.514\n",
      "Training: Epoch 99, Batch 0, Loss: 0.018\n",
      "Training: Epoch 99, Batch 1, Loss: 0.019\n",
      "Training: Epoch 99, Batch 2, Loss: 0.02\n",
      "Training: Epoch 99, Batch 3, Loss: 0.02\n",
      "Training: Epoch 99, Batch 4, Loss: 0.024\n",
      "Training: Epoch 99, Batch 5, Loss: 0.023\n",
      "Training: Epoch 99, Batch 6, Loss: 0.019\n",
      "Training: Epoch 99, Batch 7, Loss: 0.023\n",
      "Training: Epoch 99, Batch 8, Loss: 0.02\n",
      "Training: Epoch 99, Batch 9, Loss: 0.022\n",
      "Training: Epoch 99, Batch 10, Loss: 0.026\n",
      "Training: Epoch 99, Batch 11, Loss: 0.021\n",
      "Training: Epoch 99, Batch 12, Loss: 0.021\n",
      "Training: Epoch 99, Batch 13, Loss: 0.019\n",
      "Training: Epoch 99, Batch 14, Loss: 0.018\n",
      "Training: Epoch 99, Batch 15, Loss: 0.025\n",
      "Training: Epoch 99, Batch 16, Loss: 0.021\n",
      "Training: Epoch 99, Batch 17, Loss: 0.022\n",
      "Training: Epoch 99, Batch 18, Loss: 0.023\n",
      "Training: Epoch 99, Batch 19, Loss: 0.03\n",
      "Val: Epoch 99, Loss: 0.546\n",
      "Training: Epoch 100, Batch 0, Loss: 0.019\n",
      "Training: Epoch 100, Batch 1, Loss: 0.03\n",
      "Training: Epoch 100, Batch 2, Loss: 0.025\n",
      "Training: Epoch 100, Batch 3, Loss: 0.021\n",
      "Training: Epoch 100, Batch 4, Loss: 0.019\n",
      "Training: Epoch 100, Batch 5, Loss: 0.024\n",
      "Training: Epoch 100, Batch 6, Loss: 0.017\n",
      "Training: Epoch 100, Batch 7, Loss: 0.021\n",
      "Training: Epoch 100, Batch 8, Loss: 0.021\n",
      "Training: Epoch 100, Batch 9, Loss: 0.019\n",
      "Training: Epoch 100, Batch 10, Loss: 0.029\n",
      "Training: Epoch 100, Batch 11, Loss: 0.027\n",
      "Training: Epoch 100, Batch 12, Loss: 0.024\n",
      "Training: Epoch 100, Batch 13, Loss: 0.02\n",
      "Training: Epoch 100, Batch 14, Loss: 0.019\n",
      "Training: Epoch 100, Batch 15, Loss: 0.018\n",
      "Training: Epoch 100, Batch 16, Loss: 0.025\n",
      "Training: Epoch 100, Batch 17, Loss: 0.019\n",
      "Training: Epoch 100, Batch 18, Loss: 0.02\n",
      "Training: Epoch 100, Batch 19, Loss: 0.024\n",
      "Val: Epoch 100, Loss: 0.529\n",
      "Training: Epoch 101, Batch 0, Loss: 0.022\n",
      "Training: Epoch 101, Batch 1, Loss: 0.018\n",
      "Training: Epoch 101, Batch 2, Loss: 0.021\n",
      "Training: Epoch 101, Batch 3, Loss: 0.017\n",
      "Training: Epoch 101, Batch 4, Loss: 0.026\n",
      "Training: Epoch 101, Batch 5, Loss: 0.022\n",
      "Training: Epoch 101, Batch 6, Loss: 0.019\n",
      "Training: Epoch 101, Batch 7, Loss: 0.02\n",
      "Training: Epoch 101, Batch 8, Loss: 0.019\n",
      "Training: Epoch 101, Batch 9, Loss: 0.018\n",
      "Training: Epoch 101, Batch 10, Loss: 0.017\n",
      "Training: Epoch 101, Batch 11, Loss: 0.021\n",
      "Training: Epoch 101, Batch 12, Loss: 0.019\n",
      "Training: Epoch 101, Batch 13, Loss: 0.023\n",
      "Training: Epoch 101, Batch 14, Loss: 0.019\n",
      "Training: Epoch 101, Batch 15, Loss: 0.018\n",
      "Training: Epoch 101, Batch 16, Loss: 0.024\n",
      "Training: Epoch 101, Batch 17, Loss: 0.017\n",
      "Training: Epoch 101, Batch 18, Loss: 0.019\n",
      "Training: Epoch 101, Batch 19, Loss: 0.022\n",
      "Val: Epoch 101, Loss: 0.525\n",
      "Training: Epoch 102, Batch 0, Loss: 0.019\n",
      "Training: Epoch 102, Batch 1, Loss: 0.017\n",
      "Training: Epoch 102, Batch 2, Loss: 0.024\n",
      "Training: Epoch 102, Batch 3, Loss: 0.023\n",
      "Training: Epoch 102, Batch 4, Loss: 0.018\n",
      "Training: Epoch 102, Batch 5, Loss: 0.02\n",
      "Training: Epoch 102, Batch 6, Loss: 0.016\n",
      "Training: Epoch 102, Batch 7, Loss: 0.017\n",
      "Training: Epoch 102, Batch 8, Loss: 0.028\n",
      "Training: Epoch 102, Batch 9, Loss: 0.019\n",
      "Training: Epoch 102, Batch 10, Loss: 0.021\n",
      "Training: Epoch 102, Batch 11, Loss: 0.019\n",
      "Training: Epoch 102, Batch 12, Loss: 0.02\n",
      "Training: Epoch 102, Batch 13, Loss: 0.021\n",
      "Training: Epoch 102, Batch 14, Loss: 0.019\n",
      "Training: Epoch 102, Batch 15, Loss: 0.024\n",
      "Training: Epoch 102, Batch 16, Loss: 0.022\n",
      "Training: Epoch 102, Batch 17, Loss: 0.02\n",
      "Training: Epoch 102, Batch 18, Loss: 0.019\n",
      "Training: Epoch 102, Batch 19, Loss: 0.019\n",
      "Val: Epoch 102, Loss: 0.514\n",
      "Training: Epoch 103, Batch 0, Loss: 0.021\n",
      "Training: Epoch 103, Batch 1, Loss: 0.018\n",
      "Training: Epoch 103, Batch 2, Loss: 0.02\n",
      "Training: Epoch 103, Batch 3, Loss: 0.017\n",
      "Training: Epoch 103, Batch 4, Loss: 0.02\n",
      "Training: Epoch 103, Batch 5, Loss: 0.014\n",
      "Training: Epoch 103, Batch 6, Loss: 0.018\n",
      "Training: Epoch 103, Batch 7, Loss: 0.019\n",
      "Training: Epoch 103, Batch 8, Loss: 0.023\n",
      "Training: Epoch 103, Batch 9, Loss: 0.019\n",
      "Training: Epoch 103, Batch 10, Loss: 0.021\n",
      "Training: Epoch 103, Batch 11, Loss: 0.019\n",
      "Training: Epoch 103, Batch 12, Loss: 0.021\n",
      "Training: Epoch 103, Batch 13, Loss: 0.017\n",
      "Training: Epoch 103, Batch 14, Loss: 0.02\n",
      "Training: Epoch 103, Batch 15, Loss: 0.016\n",
      "Training: Epoch 103, Batch 16, Loss: 0.025\n",
      "Training: Epoch 103, Batch 17, Loss: 0.015\n",
      "Training: Epoch 103, Batch 18, Loss: 0.02\n",
      "Training: Epoch 103, Batch 19, Loss: 0.022\n",
      "Val: Epoch 103, Loss: 0.533\n",
      "Training: Epoch 104, Batch 0, Loss: 0.022\n",
      "Training: Epoch 104, Batch 1, Loss: 0.019\n",
      "Training: Epoch 104, Batch 2, Loss: 0.032\n",
      "Training: Epoch 104, Batch 3, Loss: 0.017\n",
      "Training: Epoch 104, Batch 4, Loss: 0.022\n",
      "Training: Epoch 104, Batch 5, Loss: 0.023\n",
      "Training: Epoch 104, Batch 6, Loss: 0.025\n",
      "Training: Epoch 104, Batch 7, Loss: 0.018\n",
      "Training: Epoch 104, Batch 8, Loss: 0.02\n",
      "Training: Epoch 104, Batch 9, Loss: 0.021\n",
      "Training: Epoch 104, Batch 10, Loss: 0.018\n",
      "Training: Epoch 104, Batch 11, Loss: 0.022\n",
      "Training: Epoch 104, Batch 12, Loss: 0.024\n",
      "Training: Epoch 104, Batch 13, Loss: 0.022\n",
      "Training: Epoch 104, Batch 14, Loss: 0.018\n",
      "Training: Epoch 104, Batch 15, Loss: 0.02\n",
      "Training: Epoch 104, Batch 16, Loss: 0.016\n",
      "Training: Epoch 104, Batch 17, Loss: 0.025\n",
      "Training: Epoch 104, Batch 18, Loss: 0.026\n",
      "Training: Epoch 104, Batch 19, Loss: 0.016\n",
      "Val: Epoch 104, Loss: 0.547\n",
      "Training: Epoch 105, Batch 0, Loss: 0.03\n",
      "Training: Epoch 105, Batch 1, Loss: 0.022\n",
      "Training: Epoch 105, Batch 2, Loss: 0.016\n",
      "Training: Epoch 105, Batch 3, Loss: 0.021\n",
      "Training: Epoch 105, Batch 4, Loss: 0.018\n",
      "Training: Epoch 105, Batch 5, Loss: 0.019\n",
      "Training: Epoch 105, Batch 6, Loss: 0.021\n",
      "Training: Epoch 105, Batch 7, Loss: 0.018\n",
      "Training: Epoch 105, Batch 8, Loss: 0.023\n",
      "Training: Epoch 105, Batch 9, Loss: 0.022\n",
      "Training: Epoch 105, Batch 10, Loss: 0.022\n",
      "Training: Epoch 105, Batch 11, Loss: 0.022\n",
      "Training: Epoch 105, Batch 12, Loss: 0.025\n",
      "Training: Epoch 105, Batch 13, Loss: 0.017\n",
      "Training: Epoch 105, Batch 14, Loss: 0.018\n",
      "Training: Epoch 105, Batch 15, Loss: 0.021\n",
      "Training: Epoch 105, Batch 16, Loss: 0.022\n",
      "Training: Epoch 105, Batch 17, Loss: 0.019\n",
      "Training: Epoch 105, Batch 18, Loss: 0.021\n",
      "Training: Epoch 105, Batch 19, Loss: 0.028\n",
      "Val: Epoch 105, Loss: 0.508\n",
      "Training: Epoch 106, Batch 0, Loss: 0.023\n",
      "Training: Epoch 106, Batch 1, Loss: 0.019\n",
      "Training: Epoch 106, Batch 2, Loss: 0.017\n",
      "Training: Epoch 106, Batch 3, Loss: 0.03\n",
      "Training: Epoch 106, Batch 4, Loss: 0.017\n",
      "Training: Epoch 106, Batch 5, Loss: 0.019\n",
      "Training: Epoch 106, Batch 6, Loss: 0.02\n",
      "Training: Epoch 106, Batch 7, Loss: 0.025\n",
      "Training: Epoch 106, Batch 8, Loss: 0.021\n",
      "Training: Epoch 106, Batch 9, Loss: 0.022\n",
      "Training: Epoch 106, Batch 10, Loss: 0.022\n",
      "Training: Epoch 106, Batch 11, Loss: 0.027\n",
      "Training: Epoch 106, Batch 12, Loss: 0.023\n",
      "Training: Epoch 106, Batch 13, Loss: 0.014\n",
      "Training: Epoch 106, Batch 14, Loss: 0.023\n",
      "Training: Epoch 106, Batch 15, Loss: 0.023\n",
      "Training: Epoch 106, Batch 16, Loss: 0.021\n",
      "Training: Epoch 106, Batch 17, Loss: 0.018\n",
      "Training: Epoch 106, Batch 18, Loss: 0.019\n",
      "Training: Epoch 106, Batch 19, Loss: 0.019\n",
      "Val: Epoch 106, Loss: 0.609\n",
      "Training: Epoch 107, Batch 0, Loss: 0.018\n",
      "Training: Epoch 107, Batch 1, Loss: 0.022\n",
      "Training: Epoch 107, Batch 2, Loss: 0.02\n",
      "Training: Epoch 107, Batch 3, Loss: 0.018\n",
      "Training: Epoch 107, Batch 4, Loss: 0.021\n",
      "Training: Epoch 107, Batch 5, Loss: 0.02\n",
      "Training: Epoch 107, Batch 6, Loss: 0.019\n",
      "Training: Epoch 107, Batch 7, Loss: 0.023\n",
      "Training: Epoch 107, Batch 8, Loss: 0.016\n",
      "Training: Epoch 107, Batch 9, Loss: 0.019\n",
      "Training: Epoch 107, Batch 10, Loss: 0.016\n",
      "Training: Epoch 107, Batch 11, Loss: 0.017\n",
      "Training: Epoch 107, Batch 12, Loss: 0.022\n",
      "Training: Epoch 107, Batch 13, Loss: 0.023\n",
      "Training: Epoch 107, Batch 14, Loss: 0.015\n",
      "Training: Epoch 107, Batch 15, Loss: 0.016\n",
      "Training: Epoch 107, Batch 16, Loss: 0.017\n",
      "Training: Epoch 107, Batch 17, Loss: 0.021\n",
      "Training: Epoch 107, Batch 18, Loss: 0.018\n",
      "Training: Epoch 107, Batch 19, Loss: 0.021\n",
      "Val: Epoch 107, Loss: 0.514\n",
      "Training: Epoch 108, Batch 0, Loss: 0.019\n",
      "Training: Epoch 108, Batch 1, Loss: 0.014\n",
      "Training: Epoch 108, Batch 2, Loss: 0.016\n",
      "Training: Epoch 108, Batch 3, Loss: 0.018\n",
      "Training: Epoch 108, Batch 4, Loss: 0.021\n",
      "Training: Epoch 108, Batch 5, Loss: 0.016\n",
      "Training: Epoch 108, Batch 6, Loss: 0.017\n",
      "Training: Epoch 108, Batch 7, Loss: 0.019\n",
      "Training: Epoch 108, Batch 8, Loss: 0.016\n",
      "Training: Epoch 108, Batch 9, Loss: 0.015\n",
      "Training: Epoch 108, Batch 10, Loss: 0.02\n",
      "Training: Epoch 108, Batch 11, Loss: 0.019\n",
      "Training: Epoch 108, Batch 12, Loss: 0.02\n",
      "Training: Epoch 108, Batch 13, Loss: 0.017\n",
      "Training: Epoch 108, Batch 14, Loss: 0.017\n",
      "Training: Epoch 108, Batch 15, Loss: 0.025\n",
      "Training: Epoch 108, Batch 16, Loss: 0.016\n",
      "Training: Epoch 108, Batch 17, Loss: 0.016\n",
      "Training: Epoch 108, Batch 18, Loss: 0.028\n",
      "Training: Epoch 108, Batch 19, Loss: 0.014\n",
      "Val: Epoch 108, Loss: 0.542\n",
      "Training: Epoch 109, Batch 0, Loss: 0.018\n",
      "Training: Epoch 109, Batch 1, Loss: 0.021\n",
      "Training: Epoch 109, Batch 2, Loss: 0.018\n",
      "Training: Epoch 109, Batch 3, Loss: 0.018\n",
      "Training: Epoch 109, Batch 4, Loss: 0.017\n",
      "Training: Epoch 109, Batch 5, Loss: 0.018\n",
      "Training: Epoch 109, Batch 6, Loss: 0.016\n",
      "Training: Epoch 109, Batch 7, Loss: 0.017\n",
      "Training: Epoch 109, Batch 8, Loss: 0.024\n",
      "Training: Epoch 109, Batch 9, Loss: 0.015\n",
      "Training: Epoch 109, Batch 10, Loss: 0.017\n",
      "Training: Epoch 109, Batch 11, Loss: 0.019\n",
      "Training: Epoch 109, Batch 12, Loss: 0.018\n",
      "Training: Epoch 109, Batch 13, Loss: 0.019\n",
      "Training: Epoch 109, Batch 14, Loss: 0.02\n",
      "Training: Epoch 109, Batch 15, Loss: 0.016\n",
      "Training: Epoch 109, Batch 16, Loss: 0.018\n",
      "Training: Epoch 109, Batch 17, Loss: 0.014\n",
      "Training: Epoch 109, Batch 18, Loss: 0.014\n",
      "Training: Epoch 109, Batch 19, Loss: 0.019\n",
      "Val: Epoch 109, Loss: 0.538\n",
      "Training: Epoch 110, Batch 0, Loss: 0.02\n",
      "Training: Epoch 110, Batch 1, Loss: 0.013\n",
      "Training: Epoch 110, Batch 2, Loss: 0.015\n",
      "Training: Epoch 110, Batch 3, Loss: 0.017\n",
      "Training: Epoch 110, Batch 4, Loss: 0.015\n",
      "Training: Epoch 110, Batch 5, Loss: 0.019\n",
      "Training: Epoch 110, Batch 6, Loss: 0.016\n",
      "Training: Epoch 110, Batch 7, Loss: 0.019\n",
      "Training: Epoch 110, Batch 8, Loss: 0.017\n",
      "Training: Epoch 110, Batch 9, Loss: 0.017\n",
      "Training: Epoch 110, Batch 10, Loss: 0.019\n",
      "Training: Epoch 110, Batch 11, Loss: 0.015\n",
      "Training: Epoch 110, Batch 12, Loss: 0.019\n",
      "Training: Epoch 110, Batch 13, Loss: 0.022\n",
      "Training: Epoch 110, Batch 14, Loss: 0.019\n",
      "Training: Epoch 110, Batch 15, Loss: 0.014\n",
      "Training: Epoch 110, Batch 16, Loss: 0.017\n",
      "Training: Epoch 110, Batch 17, Loss: 0.019\n",
      "Training: Epoch 110, Batch 18, Loss: 0.023\n",
      "Training: Epoch 110, Batch 19, Loss: 0.015\n",
      "Val: Epoch 110, Loss: 0.579\n",
      "Training: Epoch 111, Batch 0, Loss: 0.015\n",
      "Training: Epoch 111, Batch 1, Loss: 0.018\n",
      "Training: Epoch 111, Batch 2, Loss: 0.016\n",
      "Training: Epoch 111, Batch 3, Loss: 0.021\n",
      "Training: Epoch 111, Batch 4, Loss: 0.016\n",
      "Training: Epoch 111, Batch 5, Loss: 0.016\n",
      "Training: Epoch 111, Batch 6, Loss: 0.015\n",
      "Training: Epoch 111, Batch 7, Loss: 0.014\n",
      "Training: Epoch 111, Batch 8, Loss: 0.018\n",
      "Training: Epoch 111, Batch 9, Loss: 0.014\n",
      "Training: Epoch 111, Batch 10, Loss: 0.015\n",
      "Training: Epoch 111, Batch 11, Loss: 0.021\n",
      "Training: Epoch 111, Batch 12, Loss: 0.018\n",
      "Training: Epoch 111, Batch 13, Loss: 0.017\n",
      "Training: Epoch 111, Batch 14, Loss: 0.017\n",
      "Training: Epoch 111, Batch 15, Loss: 0.026\n",
      "Training: Epoch 111, Batch 16, Loss: 0.016\n",
      "Training: Epoch 111, Batch 17, Loss: 0.021\n",
      "Training: Epoch 111, Batch 18, Loss: 0.013\n",
      "Training: Epoch 111, Batch 19, Loss: 0.018\n",
      "Val: Epoch 111, Loss: 0.562\n",
      "Training: Epoch 112, Batch 0, Loss: 0.014\n",
      "Training: Epoch 112, Batch 1, Loss: 0.017\n",
      "Training: Epoch 112, Batch 2, Loss: 0.017\n",
      "Training: Epoch 112, Batch 3, Loss: 0.016\n",
      "Training: Epoch 112, Batch 4, Loss: 0.016\n",
      "Training: Epoch 112, Batch 5, Loss: 0.017\n",
      "Training: Epoch 112, Batch 6, Loss: 0.017\n",
      "Training: Epoch 112, Batch 7, Loss: 0.015\n",
      "Training: Epoch 112, Batch 8, Loss: 0.016\n",
      "Training: Epoch 112, Batch 9, Loss: 0.015\n",
      "Training: Epoch 112, Batch 10, Loss: 0.015\n",
      "Training: Epoch 112, Batch 11, Loss: 0.02\n",
      "Training: Epoch 112, Batch 12, Loss: 0.019\n",
      "Training: Epoch 112, Batch 13, Loss: 0.019\n",
      "Training: Epoch 112, Batch 14, Loss: 0.015\n",
      "Training: Epoch 112, Batch 15, Loss: 0.016\n",
      "Training: Epoch 112, Batch 16, Loss: 0.017\n",
      "Training: Epoch 112, Batch 17, Loss: 0.02\n",
      "Training: Epoch 112, Batch 18, Loss: 0.016\n",
      "Training: Epoch 112, Batch 19, Loss: 0.021\n",
      "Val: Epoch 112, Loss: 0.597\n",
      "Training: Epoch 113, Batch 0, Loss: 0.016\n",
      "Training: Epoch 113, Batch 1, Loss: 0.018\n",
      "Training: Epoch 113, Batch 2, Loss: 0.014\n",
      "Training: Epoch 113, Batch 3, Loss: 0.012\n",
      "Training: Epoch 113, Batch 4, Loss: 0.018\n",
      "Training: Epoch 113, Batch 5, Loss: 0.016\n",
      "Training: Epoch 113, Batch 6, Loss: 0.014\n",
      "Training: Epoch 113, Batch 7, Loss: 0.016\n",
      "Training: Epoch 113, Batch 8, Loss: 0.016\n",
      "Training: Epoch 113, Batch 9, Loss: 0.011\n",
      "Training: Epoch 113, Batch 10, Loss: 0.025\n",
      "Training: Epoch 113, Batch 11, Loss: 0.017\n",
      "Training: Epoch 113, Batch 12, Loss: 0.018\n",
      "Training: Epoch 113, Batch 13, Loss: 0.025\n",
      "Training: Epoch 113, Batch 14, Loss: 0.015\n",
      "Training: Epoch 113, Batch 15, Loss: 0.016\n",
      "Training: Epoch 113, Batch 16, Loss: 0.019\n",
      "Training: Epoch 113, Batch 17, Loss: 0.018\n",
      "Training: Epoch 113, Batch 18, Loss: 0.023\n",
      "Training: Epoch 113, Batch 19, Loss: 0.02\n",
      "Val: Epoch 113, Loss: 0.574\n",
      "Training: Epoch 114, Batch 0, Loss: 0.018\n",
      "Training: Epoch 114, Batch 1, Loss: 0.017\n",
      "Training: Epoch 114, Batch 2, Loss: 0.023\n",
      "Training: Epoch 114, Batch 3, Loss: 0.017\n",
      "Training: Epoch 114, Batch 4, Loss: 0.019\n",
      "Training: Epoch 114, Batch 5, Loss: 0.017\n",
      "Training: Epoch 114, Batch 6, Loss: 0.018\n",
      "Training: Epoch 114, Batch 7, Loss: 0.02\n",
      "Training: Epoch 114, Batch 8, Loss: 0.02\n",
      "Training: Epoch 114, Batch 9, Loss: 0.017\n",
      "Training: Epoch 114, Batch 10, Loss: 0.017\n",
      "Training: Epoch 114, Batch 11, Loss: 0.015\n",
      "Training: Epoch 114, Batch 12, Loss: 0.012\n",
      "Training: Epoch 114, Batch 13, Loss: 0.014\n",
      "Training: Epoch 114, Batch 14, Loss: 0.016\n",
      "Training: Epoch 114, Batch 15, Loss: 0.02\n",
      "Training: Epoch 114, Batch 16, Loss: 0.015\n",
      "Training: Epoch 114, Batch 17, Loss: 0.017\n",
      "Training: Epoch 114, Batch 18, Loss: 0.014\n",
      "Training: Epoch 114, Batch 19, Loss: 0.021\n",
      "Val: Epoch 114, Loss: 0.573\n",
      "Training: Epoch 115, Batch 0, Loss: 0.016\n",
      "Training: Epoch 115, Batch 1, Loss: 0.013\n",
      "Training: Epoch 115, Batch 2, Loss: 0.016\n",
      "Training: Epoch 115, Batch 3, Loss: 0.017\n",
      "Training: Epoch 115, Batch 4, Loss: 0.017\n",
      "Training: Epoch 115, Batch 5, Loss: 0.018\n",
      "Training: Epoch 115, Batch 6, Loss: 0.018\n",
      "Training: Epoch 115, Batch 7, Loss: 0.019\n",
      "Training: Epoch 115, Batch 8, Loss: 0.016\n",
      "Training: Epoch 115, Batch 9, Loss: 0.015\n",
      "Training: Epoch 115, Batch 10, Loss: 0.017\n",
      "Training: Epoch 115, Batch 11, Loss: 0.021\n",
      "Training: Epoch 115, Batch 12, Loss: 0.015\n",
      "Training: Epoch 115, Batch 13, Loss: 0.014\n",
      "Training: Epoch 115, Batch 14, Loss: 0.015\n",
      "Training: Epoch 115, Batch 15, Loss: 0.016\n",
      "Training: Epoch 115, Batch 16, Loss: 0.016\n",
      "Training: Epoch 115, Batch 17, Loss: 0.016\n",
      "Training: Epoch 115, Batch 18, Loss: 0.016\n",
      "Training: Epoch 115, Batch 19, Loss: 0.017\n",
      "Val: Epoch 115, Loss: 0.545\n",
      "Training: Epoch 116, Batch 0, Loss: 0.018\n",
      "Training: Epoch 116, Batch 1, Loss: 0.015\n",
      "Training: Epoch 116, Batch 2, Loss: 0.021\n",
      "Training: Epoch 116, Batch 3, Loss: 0.026\n",
      "Training: Epoch 116, Batch 4, Loss: 0.018\n",
      "Training: Epoch 116, Batch 5, Loss: 0.014\n",
      "Training: Epoch 116, Batch 6, Loss: 0.018\n",
      "Training: Epoch 116, Batch 7, Loss: 0.017\n",
      "Training: Epoch 116, Batch 8, Loss: 0.021\n",
      "Training: Epoch 116, Batch 9, Loss: 0.016\n",
      "Training: Epoch 116, Batch 10, Loss: 0.018\n",
      "Training: Epoch 116, Batch 11, Loss: 0.018\n",
      "Training: Epoch 116, Batch 12, Loss: 0.015\n",
      "Training: Epoch 116, Batch 13, Loss: 0.017\n",
      "Training: Epoch 116, Batch 14, Loss: 0.025\n",
      "Training: Epoch 116, Batch 15, Loss: 0.015\n",
      "Training: Epoch 116, Batch 16, Loss: 0.016\n",
      "Training: Epoch 116, Batch 17, Loss: 0.018\n",
      "Training: Epoch 116, Batch 18, Loss: 0.02\n",
      "Training: Epoch 116, Batch 19, Loss: 0.019\n",
      "Val: Epoch 116, Loss: 0.589\n",
      "Training: Epoch 117, Batch 0, Loss: 0.015\n",
      "Training: Epoch 117, Batch 1, Loss: 0.014\n",
      "Training: Epoch 117, Batch 2, Loss: 0.015\n",
      "Training: Epoch 117, Batch 3, Loss: 0.018\n",
      "Training: Epoch 117, Batch 4, Loss: 0.018\n",
      "Training: Epoch 117, Batch 5, Loss: 0.029\n",
      "Training: Epoch 117, Batch 6, Loss: 0.022\n",
      "Training: Epoch 117, Batch 7, Loss: 0.022\n",
      "Training: Epoch 117, Batch 8, Loss: 0.017\n",
      "Training: Epoch 117, Batch 9, Loss: 0.018\n",
      "Training: Epoch 117, Batch 10, Loss: 0.017\n",
      "Training: Epoch 117, Batch 11, Loss: 0.019\n",
      "Training: Epoch 117, Batch 12, Loss: 0.017\n",
      "Training: Epoch 117, Batch 13, Loss: 0.02\n",
      "Training: Epoch 117, Batch 14, Loss: 0.017\n",
      "Training: Epoch 117, Batch 15, Loss: 0.016\n",
      "Training: Epoch 117, Batch 16, Loss: 0.017\n",
      "Training: Epoch 117, Batch 17, Loss: 0.024\n",
      "Training: Epoch 117, Batch 18, Loss: 0.016\n",
      "Training: Epoch 117, Batch 19, Loss: 0.015\n",
      "Val: Epoch 117, Loss: 0.568\n",
      "Training: Epoch 118, Batch 0, Loss: 0.019\n",
      "Training: Epoch 118, Batch 1, Loss: 0.017\n",
      "Training: Epoch 118, Batch 2, Loss: 0.017\n",
      "Training: Epoch 118, Batch 3, Loss: 0.015\n",
      "Training: Epoch 118, Batch 4, Loss: 0.02\n",
      "Training: Epoch 118, Batch 5, Loss: 0.021\n",
      "Training: Epoch 118, Batch 6, Loss: 0.02\n",
      "Training: Epoch 118, Batch 7, Loss: 0.015\n",
      "Training: Epoch 118, Batch 8, Loss: 0.019\n",
      "Training: Epoch 118, Batch 9, Loss: 0.014\n",
      "Training: Epoch 118, Batch 10, Loss: 0.018\n",
      "Training: Epoch 118, Batch 11, Loss: 0.027\n",
      "Training: Epoch 118, Batch 12, Loss: 0.017\n",
      "Training: Epoch 118, Batch 13, Loss: 0.017\n",
      "Training: Epoch 118, Batch 14, Loss: 0.016\n",
      "Training: Epoch 118, Batch 15, Loss: 0.022\n",
      "Training: Epoch 118, Batch 16, Loss: 0.02\n",
      "Training: Epoch 118, Batch 17, Loss: 0.015\n",
      "Training: Epoch 118, Batch 18, Loss: 0.024\n",
      "Training: Epoch 118, Batch 19, Loss: 0.023\n",
      "Val: Epoch 118, Loss: 0.574\n",
      "Training: Epoch 119, Batch 0, Loss: 0.022\n",
      "Training: Epoch 119, Batch 1, Loss: 0.014\n",
      "Training: Epoch 119, Batch 2, Loss: 0.015\n",
      "Training: Epoch 119, Batch 3, Loss: 0.016\n",
      "Training: Epoch 119, Batch 4, Loss: 0.019\n",
      "Training: Epoch 119, Batch 5, Loss: 0.015\n",
      "Training: Epoch 119, Batch 6, Loss: 0.019\n",
      "Training: Epoch 119, Batch 7, Loss: 0.017\n",
      "Training: Epoch 119, Batch 8, Loss: 0.016\n",
      "Training: Epoch 119, Batch 9, Loss: 0.017\n",
      "Training: Epoch 119, Batch 10, Loss: 0.017\n",
      "Training: Epoch 119, Batch 11, Loss: 0.024\n",
      "Training: Epoch 119, Batch 12, Loss: 0.015\n",
      "Training: Epoch 119, Batch 13, Loss: 0.015\n",
      "Training: Epoch 119, Batch 14, Loss: 0.017\n",
      "Training: Epoch 119, Batch 15, Loss: 0.022\n",
      "Training: Epoch 119, Batch 16, Loss: 0.015\n",
      "Training: Epoch 119, Batch 17, Loss: 0.016\n",
      "Training: Epoch 119, Batch 18, Loss: 0.021\n",
      "Training: Epoch 119, Batch 19, Loss: 0.018\n",
      "Val: Epoch 119, Loss: 0.558\n",
      "Training: Epoch 120, Batch 0, Loss: 0.02\n",
      "Training: Epoch 120, Batch 1, Loss: 0.017\n",
      "Training: Epoch 120, Batch 2, Loss: 0.025\n",
      "Training: Epoch 120, Batch 3, Loss: 0.015\n",
      "Training: Epoch 120, Batch 4, Loss: 0.018\n",
      "Training: Epoch 120, Batch 5, Loss: 0.019\n",
      "Training: Epoch 120, Batch 6, Loss: 0.017\n",
      "Training: Epoch 120, Batch 7, Loss: 0.02\n",
      "Training: Epoch 120, Batch 8, Loss: 0.016\n",
      "Training: Epoch 120, Batch 9, Loss: 0.017\n",
      "Training: Epoch 120, Batch 10, Loss: 0.02\n",
      "Training: Epoch 120, Batch 11, Loss: 0.016\n",
      "Training: Epoch 120, Batch 12, Loss: 0.016\n",
      "Training: Epoch 120, Batch 13, Loss: 0.015\n",
      "Training: Epoch 120, Batch 14, Loss: 0.018\n",
      "Training: Epoch 120, Batch 15, Loss: 0.015\n",
      "Training: Epoch 120, Batch 16, Loss: 0.02\n",
      "Training: Epoch 120, Batch 17, Loss: 0.02\n",
      "Training: Epoch 120, Batch 18, Loss: 0.021\n",
      "Training: Epoch 120, Batch 19, Loss: 0.022\n",
      "Val: Epoch 120, Loss: 0.574\n",
      "Training: Epoch 121, Batch 0, Loss: 0.015\n",
      "Training: Epoch 121, Batch 1, Loss: 0.02\n",
      "Training: Epoch 121, Batch 2, Loss: 0.021\n",
      "Training: Epoch 121, Batch 3, Loss: 0.016\n",
      "Training: Epoch 121, Batch 4, Loss: 0.02\n",
      "Training: Epoch 121, Batch 5, Loss: 0.016\n",
      "Training: Epoch 121, Batch 6, Loss: 0.02\n",
      "Training: Epoch 121, Batch 7, Loss: 0.016\n",
      "Training: Epoch 121, Batch 8, Loss: 0.018\n",
      "Training: Epoch 121, Batch 9, Loss: 0.016\n",
      "Training: Epoch 121, Batch 10, Loss: 0.016\n",
      "Training: Epoch 121, Batch 11, Loss: 0.022\n",
      "Training: Epoch 121, Batch 12, Loss: 0.02\n",
      "Training: Epoch 121, Batch 13, Loss: 0.023\n",
      "Training: Epoch 121, Batch 14, Loss: 0.022\n",
      "Training: Epoch 121, Batch 15, Loss: 0.015\n",
      "Training: Epoch 121, Batch 16, Loss: 0.021\n",
      "Training: Epoch 121, Batch 17, Loss: 0.014\n",
      "Training: Epoch 121, Batch 18, Loss: 0.016\n",
      "Training: Epoch 121, Batch 19, Loss: 0.017\n",
      "Val: Epoch 121, Loss: 0.576\n",
      "Training: Epoch 122, Batch 0, Loss: 0.014\n",
      "Training: Epoch 122, Batch 1, Loss: 0.016\n",
      "Training: Epoch 122, Batch 2, Loss: 0.018\n",
      "Training: Epoch 122, Batch 3, Loss: 0.016\n",
      "Training: Epoch 122, Batch 4, Loss: 0.022\n",
      "Training: Epoch 122, Batch 5, Loss: 0.02\n",
      "Training: Epoch 122, Batch 6, Loss: 0.021\n",
      "Training: Epoch 122, Batch 7, Loss: 0.018\n",
      "Training: Epoch 122, Batch 8, Loss: 0.015\n",
      "Training: Epoch 122, Batch 9, Loss: 0.016\n",
      "Training: Epoch 122, Batch 10, Loss: 0.017\n",
      "Training: Epoch 122, Batch 11, Loss: 0.016\n",
      "Training: Epoch 122, Batch 12, Loss: 0.017\n",
      "Training: Epoch 122, Batch 13, Loss: 0.019\n",
      "Training: Epoch 122, Batch 14, Loss: 0.021\n",
      "Training: Epoch 122, Batch 15, Loss: 0.012\n",
      "Training: Epoch 122, Batch 16, Loss: 0.015\n",
      "Training: Epoch 122, Batch 17, Loss: 0.018\n",
      "Training: Epoch 122, Batch 18, Loss: 0.014\n",
      "Training: Epoch 122, Batch 19, Loss: 0.016\n",
      "Val: Epoch 122, Loss: 0.581\n",
      "Training: Epoch 123, Batch 0, Loss: 0.014\n",
      "Training: Epoch 123, Batch 1, Loss: 0.017\n",
      "Training: Epoch 123, Batch 2, Loss: 0.013\n",
      "Training: Epoch 123, Batch 3, Loss: 0.018\n",
      "Training: Epoch 123, Batch 4, Loss: 0.017\n",
      "Training: Epoch 123, Batch 5, Loss: 0.019\n",
      "Training: Epoch 123, Batch 6, Loss: 0.017\n",
      "Training: Epoch 123, Batch 7, Loss: 0.02\n",
      "Training: Epoch 123, Batch 8, Loss: 0.017\n",
      "Training: Epoch 123, Batch 9, Loss: 0.016\n",
      "Training: Epoch 123, Batch 10, Loss: 0.015\n",
      "Training: Epoch 123, Batch 11, Loss: 0.015\n",
      "Training: Epoch 123, Batch 12, Loss: 0.016\n",
      "Training: Epoch 123, Batch 13, Loss: 0.014\n",
      "Training: Epoch 123, Batch 14, Loss: 0.015\n",
      "Training: Epoch 123, Batch 15, Loss: 0.023\n",
      "Training: Epoch 123, Batch 16, Loss: 0.014\n",
      "Training: Epoch 123, Batch 17, Loss: 0.014\n",
      "Training: Epoch 123, Batch 18, Loss: 0.022\n",
      "Training: Epoch 123, Batch 19, Loss: 0.017\n",
      "Val: Epoch 123, Loss: 0.551\n",
      "Training: Epoch 124, Batch 0, Loss: 0.017\n",
      "Training: Epoch 124, Batch 1, Loss: 0.015\n",
      "Training: Epoch 124, Batch 2, Loss: 0.015\n",
      "Training: Epoch 124, Batch 3, Loss: 0.016\n",
      "Training: Epoch 124, Batch 4, Loss: 0.018\n",
      "Training: Epoch 124, Batch 5, Loss: 0.023\n",
      "Training: Epoch 124, Batch 6, Loss: 0.015\n",
      "Training: Epoch 124, Batch 7, Loss: 0.019\n",
      "Training: Epoch 124, Batch 8, Loss: 0.016\n",
      "Training: Epoch 124, Batch 9, Loss: 0.014\n",
      "Training: Epoch 124, Batch 10, Loss: 0.018\n",
      "Training: Epoch 124, Batch 11, Loss: 0.018\n",
      "Training: Epoch 124, Batch 12, Loss: 0.018\n",
      "Training: Epoch 124, Batch 13, Loss: 0.016\n",
      "Training: Epoch 124, Batch 14, Loss: 0.016\n",
      "Training: Epoch 124, Batch 15, Loss: 0.012\n",
      "Training: Epoch 124, Batch 16, Loss: 0.016\n",
      "Training: Epoch 124, Batch 17, Loss: 0.013\n",
      "Training: Epoch 124, Batch 18, Loss: 0.013\n",
      "Training: Epoch 124, Batch 19, Loss: 0.017\n",
      "Val: Epoch 124, Loss: 0.572\n",
      "Training: Epoch 125, Batch 0, Loss: 0.015\n",
      "Training: Epoch 125, Batch 1, Loss: 0.014\n",
      "Training: Epoch 125, Batch 2, Loss: 0.015\n",
      "Training: Epoch 125, Batch 3, Loss: 0.013\n",
      "Training: Epoch 125, Batch 4, Loss: 0.013\n",
      "Training: Epoch 125, Batch 5, Loss: 0.018\n",
      "Training: Epoch 125, Batch 6, Loss: 0.014\n",
      "Training: Epoch 125, Batch 7, Loss: 0.014\n",
      "Training: Epoch 125, Batch 8, Loss: 0.015\n",
      "Training: Epoch 125, Batch 9, Loss: 0.019\n",
      "Training: Epoch 125, Batch 10, Loss: 0.017\n",
      "Training: Epoch 125, Batch 11, Loss: 0.014\n",
      "Training: Epoch 125, Batch 12, Loss: 0.014\n",
      "Training: Epoch 125, Batch 13, Loss: 0.012\n",
      "Training: Epoch 125, Batch 14, Loss: 0.017\n",
      "Training: Epoch 125, Batch 15, Loss: 0.014\n",
      "Training: Epoch 125, Batch 16, Loss: 0.012\n",
      "Training: Epoch 125, Batch 17, Loss: 0.018\n",
      "Training: Epoch 125, Batch 18, Loss: 0.018\n",
      "Training: Epoch 125, Batch 19, Loss: 0.015\n",
      "Val: Epoch 125, Loss: 0.564\n",
      "Training: Epoch 126, Batch 0, Loss: 0.013\n",
      "Training: Epoch 126, Batch 1, Loss: 0.014\n",
      "Training: Epoch 126, Batch 2, Loss: 0.014\n",
      "Training: Epoch 126, Batch 3, Loss: 0.017\n",
      "Training: Epoch 126, Batch 4, Loss: 0.016\n",
      "Training: Epoch 126, Batch 5, Loss: 0.015\n",
      "Training: Epoch 126, Batch 6, Loss: 0.015\n",
      "Training: Epoch 126, Batch 7, Loss: 0.011\n",
      "Training: Epoch 126, Batch 8, Loss: 0.012\n",
      "Training: Epoch 126, Batch 9, Loss: 0.016\n",
      "Training: Epoch 126, Batch 10, Loss: 0.014\n",
      "Training: Epoch 126, Batch 11, Loss: 0.014\n",
      "Training: Epoch 126, Batch 12, Loss: 0.018\n",
      "Training: Epoch 126, Batch 13, Loss: 0.012\n",
      "Training: Epoch 126, Batch 14, Loss: 0.014\n",
      "Training: Epoch 126, Batch 15, Loss: 0.016\n",
      "Training: Epoch 126, Batch 16, Loss: 0.017\n",
      "Training: Epoch 126, Batch 17, Loss: 0.013\n",
      "Training: Epoch 126, Batch 18, Loss: 0.017\n",
      "Training: Epoch 126, Batch 19, Loss: 0.015\n",
      "Val: Epoch 126, Loss: 0.607\n",
      "Training: Epoch 127, Batch 0, Loss: 0.017\n",
      "Training: Epoch 127, Batch 1, Loss: 0.013\n",
      "Training: Epoch 127, Batch 2, Loss: 0.016\n",
      "Training: Epoch 127, Batch 3, Loss: 0.013\n",
      "Training: Epoch 127, Batch 4, Loss: 0.02\n",
      "Training: Epoch 127, Batch 5, Loss: 0.014\n",
      "Training: Epoch 127, Batch 6, Loss: 0.012\n",
      "Training: Epoch 127, Batch 7, Loss: 0.014\n",
      "Training: Epoch 127, Batch 8, Loss: 0.013\n",
      "Training: Epoch 127, Batch 9, Loss: 0.011\n",
      "Training: Epoch 127, Batch 10, Loss: 0.018\n",
      "Training: Epoch 127, Batch 11, Loss: 0.017\n",
      "Training: Epoch 127, Batch 12, Loss: 0.012\n",
      "Training: Epoch 127, Batch 13, Loss: 0.016\n",
      "Training: Epoch 127, Batch 14, Loss: 0.011\n",
      "Training: Epoch 127, Batch 15, Loss: 0.014\n",
      "Training: Epoch 127, Batch 16, Loss: 0.024\n",
      "Training: Epoch 127, Batch 17, Loss: 0.013\n",
      "Training: Epoch 127, Batch 18, Loss: 0.015\n",
      "Training: Epoch 127, Batch 19, Loss: 0.016\n",
      "Val: Epoch 127, Loss: 0.625\n",
      "Training: Epoch 128, Batch 0, Loss: 0.014\n",
      "Training: Epoch 128, Batch 1, Loss: 0.013\n",
      "Training: Epoch 128, Batch 2, Loss: 0.015\n",
      "Training: Epoch 128, Batch 3, Loss: 0.011\n",
      "Training: Epoch 128, Batch 4, Loss: 0.015\n",
      "Training: Epoch 128, Batch 5, Loss: 0.012\n",
      "Training: Epoch 128, Batch 6, Loss: 0.016\n",
      "Training: Epoch 128, Batch 7, Loss: 0.012\n",
      "Training: Epoch 128, Batch 8, Loss: 0.017\n",
      "Training: Epoch 128, Batch 9, Loss: 0.014\n",
      "Training: Epoch 128, Batch 10, Loss: 0.012\n",
      "Training: Epoch 128, Batch 11, Loss: 0.012\n",
      "Training: Epoch 128, Batch 12, Loss: 0.016\n",
      "Training: Epoch 128, Batch 13, Loss: 0.017\n",
      "Training: Epoch 128, Batch 14, Loss: 0.017\n",
      "Training: Epoch 128, Batch 15, Loss: 0.016\n",
      "Training: Epoch 128, Batch 16, Loss: 0.019\n",
      "Training: Epoch 128, Batch 17, Loss: 0.013\n",
      "Training: Epoch 128, Batch 18, Loss: 0.018\n",
      "Training: Epoch 128, Batch 19, Loss: 0.013\n",
      "Val: Epoch 128, Loss: 0.77\n",
      "Training: Epoch 129, Batch 0, Loss: 0.018\n",
      "Training: Epoch 129, Batch 1, Loss: 0.014\n",
      "Training: Epoch 129, Batch 2, Loss: 0.012\n",
      "Training: Epoch 129, Batch 3, Loss: 0.013\n",
      "Training: Epoch 129, Batch 4, Loss: 0.015\n",
      "Training: Epoch 129, Batch 5, Loss: 0.016\n",
      "Training: Epoch 129, Batch 6, Loss: 0.015\n",
      "Training: Epoch 129, Batch 7, Loss: 0.015\n",
      "Training: Epoch 129, Batch 8, Loss: 0.014\n",
      "Training: Epoch 129, Batch 9, Loss: 0.014\n",
      "Training: Epoch 129, Batch 10, Loss: 0.02\n",
      "Training: Epoch 129, Batch 11, Loss: 0.016\n",
      "Training: Epoch 129, Batch 12, Loss: 0.015\n",
      "Training: Epoch 129, Batch 13, Loss: 0.015\n",
      "Training: Epoch 129, Batch 14, Loss: 0.016\n",
      "Training: Epoch 129, Batch 15, Loss: 0.016\n",
      "Training: Epoch 129, Batch 16, Loss: 0.011\n",
      "Training: Epoch 129, Batch 17, Loss: 0.014\n",
      "Training: Epoch 129, Batch 18, Loss: 0.011\n",
      "Training: Epoch 129, Batch 19, Loss: 0.024\n",
      "Val: Epoch 129, Loss: 0.614\n",
      "Training: Epoch 130, Batch 0, Loss: 0.016\n",
      "Training: Epoch 130, Batch 1, Loss: 0.018\n",
      "Training: Epoch 130, Batch 2, Loss: 0.014\n",
      "Training: Epoch 130, Batch 3, Loss: 0.014\n",
      "Training: Epoch 130, Batch 4, Loss: 0.016\n",
      "Training: Epoch 130, Batch 5, Loss: 0.015\n",
      "Training: Epoch 130, Batch 6, Loss: 0.013\n",
      "Training: Epoch 130, Batch 7, Loss: 0.017\n",
      "Training: Epoch 130, Batch 8, Loss: 0.014\n",
      "Training: Epoch 130, Batch 9, Loss: 0.012\n",
      "Training: Epoch 130, Batch 10, Loss: 0.012\n",
      "Training: Epoch 130, Batch 11, Loss: 0.019\n",
      "Training: Epoch 130, Batch 12, Loss: 0.014\n",
      "Training: Epoch 130, Batch 13, Loss: 0.012\n",
      "Training: Epoch 130, Batch 14, Loss: 0.013\n",
      "Training: Epoch 130, Batch 15, Loss: 0.014\n",
      "Training: Epoch 130, Batch 16, Loss: 0.015\n",
      "Training: Epoch 130, Batch 17, Loss: 0.015\n",
      "Training: Epoch 130, Batch 18, Loss: 0.013\n",
      "Training: Epoch 130, Batch 19, Loss: 0.014\n",
      "Val: Epoch 130, Loss: 0.598\n",
      "Training: Epoch 131, Batch 0, Loss: 0.012\n",
      "Training: Epoch 131, Batch 1, Loss: 0.013\n",
      "Training: Epoch 131, Batch 2, Loss: 0.013\n",
      "Training: Epoch 131, Batch 3, Loss: 0.012\n",
      "Training: Epoch 131, Batch 4, Loss: 0.014\n",
      "Training: Epoch 131, Batch 5, Loss: 0.012\n",
      "Training: Epoch 131, Batch 6, Loss: 0.016\n",
      "Training: Epoch 131, Batch 7, Loss: 0.016\n",
      "Training: Epoch 131, Batch 8, Loss: 0.013\n",
      "Training: Epoch 131, Batch 9, Loss: 0.016\n",
      "Training: Epoch 131, Batch 10, Loss: 0.013\n",
      "Training: Epoch 131, Batch 11, Loss: 0.013\n",
      "Training: Epoch 131, Batch 12, Loss: 0.016\n",
      "Training: Epoch 131, Batch 13, Loss: 0.02\n",
      "Training: Epoch 131, Batch 14, Loss: 0.015\n",
      "Training: Epoch 131, Batch 15, Loss: 0.013\n",
      "Training: Epoch 131, Batch 16, Loss: 0.011\n",
      "Training: Epoch 131, Batch 17, Loss: 0.015\n",
      "Training: Epoch 131, Batch 18, Loss: 0.014\n",
      "Training: Epoch 131, Batch 19, Loss: 0.019\n",
      "Val: Epoch 131, Loss: 0.614\n",
      "Training: Epoch 132, Batch 0, Loss: 0.013\n",
      "Training: Epoch 132, Batch 1, Loss: 0.014\n",
      "Training: Epoch 132, Batch 2, Loss: 0.014\n",
      "Training: Epoch 132, Batch 3, Loss: 0.014\n",
      "Training: Epoch 132, Batch 4, Loss: 0.016\n",
      "Training: Epoch 132, Batch 5, Loss: 0.012\n",
      "Training: Epoch 132, Batch 6, Loss: 0.017\n",
      "Training: Epoch 132, Batch 7, Loss: 0.01\n",
      "Training: Epoch 132, Batch 8, Loss: 0.013\n",
      "Training: Epoch 132, Batch 9, Loss: 0.024\n",
      "Training: Epoch 132, Batch 10, Loss: 0.013\n",
      "Training: Epoch 132, Batch 11, Loss: 0.014\n",
      "Training: Epoch 132, Batch 12, Loss: 0.016\n",
      "Training: Epoch 132, Batch 13, Loss: 0.018\n",
      "Training: Epoch 132, Batch 14, Loss: 0.015\n",
      "Training: Epoch 132, Batch 15, Loss: 0.013\n",
      "Training: Epoch 132, Batch 16, Loss: 0.013\n",
      "Training: Epoch 132, Batch 17, Loss: 0.014\n",
      "Training: Epoch 132, Batch 18, Loss: 0.013\n",
      "Training: Epoch 132, Batch 19, Loss: 0.014\n",
      "Val: Epoch 132, Loss: 0.598\n",
      "Training: Epoch 133, Batch 0, Loss: 0.013\n",
      "Training: Epoch 133, Batch 1, Loss: 0.014\n",
      "Training: Epoch 133, Batch 2, Loss: 0.013\n",
      "Training: Epoch 133, Batch 3, Loss: 0.012\n",
      "Training: Epoch 133, Batch 4, Loss: 0.008\n",
      "Training: Epoch 133, Batch 5, Loss: 0.011\n",
      "Training: Epoch 133, Batch 6, Loss: 0.012\n",
      "Training: Epoch 133, Batch 7, Loss: 0.013\n",
      "Training: Epoch 133, Batch 8, Loss: 0.016\n",
      "Training: Epoch 133, Batch 9, Loss: 0.015\n",
      "Training: Epoch 133, Batch 10, Loss: 0.013\n",
      "Training: Epoch 133, Batch 11, Loss: 0.015\n",
      "Training: Epoch 133, Batch 12, Loss: 0.014\n",
      "Training: Epoch 133, Batch 13, Loss: 0.014\n",
      "Training: Epoch 133, Batch 14, Loss: 0.017\n",
      "Training: Epoch 133, Batch 15, Loss: 0.024\n",
      "Training: Epoch 133, Batch 16, Loss: 0.014\n",
      "Training: Epoch 133, Batch 17, Loss: 0.015\n",
      "Training: Epoch 133, Batch 18, Loss: 0.014\n",
      "Training: Epoch 133, Batch 19, Loss: 0.017\n",
      "Val: Epoch 133, Loss: 0.603\n",
      "Training: Epoch 134, Batch 0, Loss: 0.018\n",
      "Training: Epoch 134, Batch 1, Loss: 0.013\n",
      "Training: Epoch 134, Batch 2, Loss: 0.015\n",
      "Training: Epoch 134, Batch 3, Loss: 0.013\n",
      "Training: Epoch 134, Batch 4, Loss: 0.012\n",
      "Training: Epoch 134, Batch 5, Loss: 0.013\n",
      "Training: Epoch 134, Batch 6, Loss: 0.015\n",
      "Training: Epoch 134, Batch 7, Loss: 0.011\n",
      "Training: Epoch 134, Batch 8, Loss: 0.014\n",
      "Training: Epoch 134, Batch 9, Loss: 0.012\n",
      "Training: Epoch 134, Batch 10, Loss: 0.013\n",
      "Training: Epoch 134, Batch 11, Loss: 0.015\n",
      "Training: Epoch 134, Batch 12, Loss: 0.018\n",
      "Training: Epoch 134, Batch 13, Loss: 0.013\n",
      "Training: Epoch 134, Batch 14, Loss: 0.012\n",
      "Training: Epoch 134, Batch 15, Loss: 0.011\n",
      "Training: Epoch 134, Batch 16, Loss: 0.018\n",
      "Training: Epoch 134, Batch 17, Loss: 0.014\n",
      "Training: Epoch 134, Batch 18, Loss: 0.013\n",
      "Training: Epoch 134, Batch 19, Loss: 0.014\n",
      "Val: Epoch 134, Loss: 0.615\n",
      "Training: Epoch 135, Batch 0, Loss: 0.011\n",
      "Training: Epoch 135, Batch 1, Loss: 0.013\n",
      "Training: Epoch 135, Batch 2, Loss: 0.015\n",
      "Training: Epoch 135, Batch 3, Loss: 0.018\n",
      "Training: Epoch 135, Batch 4, Loss: 0.014\n",
      "Training: Epoch 135, Batch 5, Loss: 0.014\n",
      "Training: Epoch 135, Batch 6, Loss: 0.013\n",
      "Training: Epoch 135, Batch 7, Loss: 0.014\n",
      "Training: Epoch 135, Batch 8, Loss: 0.013\n",
      "Training: Epoch 135, Batch 9, Loss: 0.012\n",
      "Training: Epoch 135, Batch 10, Loss: 0.012\n",
      "Training: Epoch 135, Batch 11, Loss: 0.017\n",
      "Training: Epoch 135, Batch 12, Loss: 0.016\n",
      "Training: Epoch 135, Batch 13, Loss: 0.014\n",
      "Training: Epoch 135, Batch 14, Loss: 0.012\n",
      "Training: Epoch 135, Batch 15, Loss: 0.012\n",
      "Training: Epoch 135, Batch 16, Loss: 0.014\n",
      "Training: Epoch 135, Batch 17, Loss: 0.019\n",
      "Training: Epoch 135, Batch 18, Loss: 0.016\n",
      "Training: Epoch 135, Batch 19, Loss: 0.017\n",
      "Val: Epoch 135, Loss: 0.595\n",
      "Training: Epoch 136, Batch 0, Loss: 0.02\n",
      "Training: Epoch 136, Batch 1, Loss: 0.019\n",
      "Training: Epoch 136, Batch 2, Loss: 0.017\n",
      "Training: Epoch 136, Batch 3, Loss: 0.013\n",
      "Training: Epoch 136, Batch 4, Loss: 0.011\n",
      "Training: Epoch 136, Batch 5, Loss: 0.017\n",
      "Training: Epoch 136, Batch 6, Loss: 0.011\n",
      "Training: Epoch 136, Batch 7, Loss: 0.019\n",
      "Training: Epoch 136, Batch 8, Loss: 0.012\n",
      "Training: Epoch 136, Batch 9, Loss: 0.012\n",
      "Training: Epoch 136, Batch 10, Loss: 0.014\n",
      "Training: Epoch 136, Batch 11, Loss: 0.014\n",
      "Training: Epoch 136, Batch 12, Loss: 0.014\n",
      "Training: Epoch 136, Batch 13, Loss: 0.013\n",
      "Training: Epoch 136, Batch 14, Loss: 0.015\n",
      "Training: Epoch 136, Batch 15, Loss: 0.014\n",
      "Training: Epoch 136, Batch 16, Loss: 0.014\n",
      "Training: Epoch 136, Batch 17, Loss: 0.018\n",
      "Training: Epoch 136, Batch 18, Loss: 0.021\n",
      "Training: Epoch 136, Batch 19, Loss: 0.016\n",
      "Val: Epoch 136, Loss: 0.615\n",
      "Training: Epoch 137, Batch 0, Loss: 0.013\n",
      "Training: Epoch 137, Batch 1, Loss: 0.013\n",
      "Training: Epoch 137, Batch 2, Loss: 0.013\n",
      "Training: Epoch 137, Batch 3, Loss: 0.016\n",
      "Training: Epoch 137, Batch 4, Loss: 0.017\n",
      "Training: Epoch 137, Batch 5, Loss: 0.014\n",
      "Training: Epoch 137, Batch 6, Loss: 0.015\n",
      "Training: Epoch 137, Batch 7, Loss: 0.019\n",
      "Training: Epoch 137, Batch 8, Loss: 0.016\n",
      "Training: Epoch 137, Batch 9, Loss: 0.014\n",
      "Training: Epoch 137, Batch 10, Loss: 0.019\n",
      "Training: Epoch 137, Batch 11, Loss: 0.015\n",
      "Training: Epoch 137, Batch 12, Loss: 0.016\n",
      "Training: Epoch 137, Batch 13, Loss: 0.016\n",
      "Training: Epoch 137, Batch 14, Loss: 0.013\n",
      "Training: Epoch 137, Batch 15, Loss: 0.016\n",
      "Training: Epoch 137, Batch 16, Loss: 0.013\n",
      "Training: Epoch 137, Batch 17, Loss: 0.017\n",
      "Training: Epoch 137, Batch 18, Loss: 0.013\n",
      "Training: Epoch 137, Batch 19, Loss: 0.013\n",
      "Val: Epoch 137, Loss: 0.637\n",
      "Training: Epoch 138, Batch 0, Loss: 0.014\n",
      "Training: Epoch 138, Batch 1, Loss: 0.014\n",
      "Training: Epoch 138, Batch 2, Loss: 0.014\n",
      "Training: Epoch 138, Batch 3, Loss: 0.013\n",
      "Training: Epoch 138, Batch 4, Loss: 0.013\n",
      "Training: Epoch 138, Batch 5, Loss: 0.013\n",
      "Training: Epoch 138, Batch 6, Loss: 0.014\n",
      "Training: Epoch 138, Batch 7, Loss: 0.016\n",
      "Training: Epoch 138, Batch 8, Loss: 0.012\n",
      "Training: Epoch 138, Batch 9, Loss: 0.015\n",
      "Training: Epoch 138, Batch 10, Loss: 0.014\n",
      "Training: Epoch 138, Batch 11, Loss: 0.015\n",
      "Training: Epoch 138, Batch 12, Loss: 0.014\n",
      "Training: Epoch 138, Batch 13, Loss: 0.013\n",
      "Training: Epoch 138, Batch 14, Loss: 0.02\n",
      "Training: Epoch 138, Batch 15, Loss: 0.017\n",
      "Training: Epoch 138, Batch 16, Loss: 0.015\n",
      "Training: Epoch 138, Batch 17, Loss: 0.012\n",
      "Training: Epoch 138, Batch 18, Loss: 0.016\n",
      "Training: Epoch 138, Batch 19, Loss: 0.011\n",
      "Val: Epoch 138, Loss: 0.62\n",
      "Training: Epoch 139, Batch 0, Loss: 0.016\n",
      "Training: Epoch 139, Batch 1, Loss: 0.011\n",
      "Training: Epoch 139, Batch 2, Loss: 0.012\n",
      "Training: Epoch 139, Batch 3, Loss: 0.012\n",
      "Training: Epoch 139, Batch 4, Loss: 0.017\n",
      "Training: Epoch 139, Batch 5, Loss: 0.02\n",
      "Training: Epoch 139, Batch 6, Loss: 0.016\n",
      "Training: Epoch 139, Batch 7, Loss: 0.018\n",
      "Training: Epoch 139, Batch 8, Loss: 0.01\n",
      "Training: Epoch 139, Batch 9, Loss: 0.014\n",
      "Training: Epoch 139, Batch 10, Loss: 0.014\n",
      "Training: Epoch 139, Batch 11, Loss: 0.012\n",
      "Training: Epoch 139, Batch 12, Loss: 0.016\n",
      "Training: Epoch 139, Batch 13, Loss: 0.013\n",
      "Training: Epoch 139, Batch 14, Loss: 0.014\n",
      "Training: Epoch 139, Batch 15, Loss: 0.014\n",
      "Training: Epoch 139, Batch 16, Loss: 0.016\n",
      "Training: Epoch 139, Batch 17, Loss: 0.018\n",
      "Training: Epoch 139, Batch 18, Loss: 0.012\n",
      "Training: Epoch 139, Batch 19, Loss: 0.01\n",
      "Val: Epoch 139, Loss: 0.635\n",
      "Training: Epoch 140, Batch 0, Loss: 0.015\n",
      "Training: Epoch 140, Batch 1, Loss: 0.015\n",
      "Training: Epoch 140, Batch 2, Loss: 0.012\n",
      "Training: Epoch 140, Batch 3, Loss: 0.013\n",
      "Training: Epoch 140, Batch 4, Loss: 0.015\n",
      "Training: Epoch 140, Batch 5, Loss: 0.011\n",
      "Training: Epoch 140, Batch 6, Loss: 0.015\n",
      "Training: Epoch 140, Batch 7, Loss: 0.015\n",
      "Training: Epoch 140, Batch 8, Loss: 0.024\n",
      "Training: Epoch 140, Batch 9, Loss: 0.015\n",
      "Training: Epoch 140, Batch 10, Loss: 0.017\n",
      "Training: Epoch 140, Batch 11, Loss: 0.015\n",
      "Training: Epoch 140, Batch 12, Loss: 0.014\n",
      "Training: Epoch 140, Batch 13, Loss: 0.013\n",
      "Training: Epoch 140, Batch 14, Loss: 0.021\n",
      "Training: Epoch 140, Batch 15, Loss: 0.014\n",
      "Training: Epoch 140, Batch 16, Loss: 0.015\n",
      "Training: Epoch 140, Batch 17, Loss: 0.014\n",
      "Training: Epoch 140, Batch 18, Loss: 0.018\n",
      "Training: Epoch 140, Batch 19, Loss: 0.015\n",
      "Val: Epoch 140, Loss: 0.63\n",
      "Training: Epoch 141, Batch 0, Loss: 0.011\n",
      "Training: Epoch 141, Batch 1, Loss: 0.012\n",
      "Training: Epoch 141, Batch 2, Loss: 0.019\n",
      "Training: Epoch 141, Batch 3, Loss: 0.013\n",
      "Training: Epoch 141, Batch 4, Loss: 0.014\n",
      "Training: Epoch 141, Batch 5, Loss: 0.013\n",
      "Training: Epoch 141, Batch 6, Loss: 0.014\n",
      "Training: Epoch 141, Batch 7, Loss: 0.019\n",
      "Training: Epoch 141, Batch 8, Loss: 0.013\n",
      "Training: Epoch 141, Batch 9, Loss: 0.029\n",
      "Training: Epoch 141, Batch 10, Loss: 0.013\n",
      "Training: Epoch 141, Batch 11, Loss: 0.017\n",
      "Training: Epoch 141, Batch 12, Loss: 0.011\n",
      "Training: Epoch 141, Batch 13, Loss: 0.016\n",
      "Training: Epoch 141, Batch 14, Loss: 0.016\n",
      "Training: Epoch 141, Batch 15, Loss: 0.016\n",
      "Training: Epoch 141, Batch 16, Loss: 0.015\n",
      "Training: Epoch 141, Batch 17, Loss: 0.013\n",
      "Training: Epoch 141, Batch 18, Loss: 0.016\n",
      "Training: Epoch 141, Batch 19, Loss: 0.015\n",
      "Val: Epoch 141, Loss: 0.598\n",
      "Training: Epoch 142, Batch 0, Loss: 0.013\n",
      "Training: Epoch 142, Batch 1, Loss: 0.014\n",
      "Training: Epoch 142, Batch 2, Loss: 0.02\n",
      "Training: Epoch 142, Batch 3, Loss: 0.014\n",
      "Training: Epoch 142, Batch 4, Loss: 0.014\n",
      "Training: Epoch 142, Batch 5, Loss: 0.013\n",
      "Training: Epoch 142, Batch 6, Loss: 0.016\n",
      "Training: Epoch 142, Batch 7, Loss: 0.014\n",
      "Training: Epoch 142, Batch 8, Loss: 0.014\n",
      "Training: Epoch 142, Batch 9, Loss: 0.016\n",
      "Training: Epoch 142, Batch 10, Loss: 0.013\n",
      "Training: Epoch 142, Batch 11, Loss: 0.013\n",
      "Training: Epoch 142, Batch 12, Loss: 0.014\n",
      "Training: Epoch 142, Batch 13, Loss: 0.015\n",
      "Training: Epoch 142, Batch 14, Loss: 0.015\n",
      "Training: Epoch 142, Batch 15, Loss: 0.017\n",
      "Training: Epoch 142, Batch 16, Loss: 0.017\n",
      "Training: Epoch 142, Batch 17, Loss: 0.017\n",
      "Training: Epoch 142, Batch 18, Loss: 0.015\n",
      "Training: Epoch 142, Batch 19, Loss: 0.012\n",
      "Val: Epoch 142, Loss: 0.593\n",
      "Training: Epoch 143, Batch 0, Loss: 0.014\n",
      "Training: Epoch 143, Batch 1, Loss: 0.013\n",
      "Training: Epoch 143, Batch 2, Loss: 0.018\n",
      "Training: Epoch 143, Batch 3, Loss: 0.012\n",
      "Training: Epoch 143, Batch 4, Loss: 0.015\n",
      "Training: Epoch 143, Batch 5, Loss: 0.014\n",
      "Training: Epoch 143, Batch 6, Loss: 0.017\n",
      "Training: Epoch 143, Batch 7, Loss: 0.014\n",
      "Training: Epoch 143, Batch 8, Loss: 0.012\n",
      "Training: Epoch 143, Batch 9, Loss: 0.012\n",
      "Training: Epoch 143, Batch 10, Loss: 0.011\n",
      "Training: Epoch 143, Batch 11, Loss: 0.011\n",
      "Training: Epoch 143, Batch 12, Loss: 0.013\n",
      "Training: Epoch 143, Batch 13, Loss: 0.014\n",
      "Training: Epoch 143, Batch 14, Loss: 0.015\n",
      "Training: Epoch 143, Batch 15, Loss: 0.013\n",
      "Training: Epoch 143, Batch 16, Loss: 0.013\n",
      "Training: Epoch 143, Batch 17, Loss: 0.013\n",
      "Training: Epoch 143, Batch 18, Loss: 0.01\n",
      "Training: Epoch 143, Batch 19, Loss: 0.015\n",
      "Val: Epoch 143, Loss: 0.632\n",
      "Training: Epoch 144, Batch 0, Loss: 0.01\n",
      "Training: Epoch 144, Batch 1, Loss: 0.011\n",
      "Training: Epoch 144, Batch 2, Loss: 0.012\n",
      "Training: Epoch 144, Batch 3, Loss: 0.013\n",
      "Training: Epoch 144, Batch 4, Loss: 0.011\n",
      "Training: Epoch 144, Batch 5, Loss: 0.015\n",
      "Training: Epoch 144, Batch 6, Loss: 0.013\n",
      "Training: Epoch 144, Batch 7, Loss: 0.012\n",
      "Training: Epoch 144, Batch 8, Loss: 0.011\n",
      "Training: Epoch 144, Batch 9, Loss: 0.011\n",
      "Training: Epoch 144, Batch 10, Loss: 0.011\n",
      "Training: Epoch 144, Batch 11, Loss: 0.013\n",
      "Training: Epoch 144, Batch 12, Loss: 0.014\n",
      "Training: Epoch 144, Batch 13, Loss: 0.014\n",
      "Training: Epoch 144, Batch 14, Loss: 0.012\n",
      "Training: Epoch 144, Batch 15, Loss: 0.013\n",
      "Training: Epoch 144, Batch 16, Loss: 0.018\n",
      "Training: Epoch 144, Batch 17, Loss: 0.013\n",
      "Training: Epoch 144, Batch 18, Loss: 0.013\n",
      "Training: Epoch 144, Batch 19, Loss: 0.022\n",
      "Val: Epoch 144, Loss: 0.65\n",
      "Training: Epoch 145, Batch 0, Loss: 0.012\n",
      "Training: Epoch 145, Batch 1, Loss: 0.015\n",
      "Training: Epoch 145, Batch 2, Loss: 0.013\n",
      "Training: Epoch 145, Batch 3, Loss: 0.009\n",
      "Training: Epoch 145, Batch 4, Loss: 0.011\n",
      "Training: Epoch 145, Batch 5, Loss: 0.011\n",
      "Training: Epoch 145, Batch 6, Loss: 0.01\n",
      "Training: Epoch 145, Batch 7, Loss: 0.014\n",
      "Training: Epoch 145, Batch 8, Loss: 0.01\n",
      "Training: Epoch 145, Batch 9, Loss: 0.013\n",
      "Training: Epoch 145, Batch 10, Loss: 0.012\n",
      "Training: Epoch 145, Batch 11, Loss: 0.009\n",
      "Training: Epoch 145, Batch 12, Loss: 0.017\n",
      "Training: Epoch 145, Batch 13, Loss: 0.013\n",
      "Training: Epoch 145, Batch 14, Loss: 0.017\n",
      "Training: Epoch 145, Batch 15, Loss: 0.018\n",
      "Training: Epoch 145, Batch 16, Loss: 0.015\n",
      "Training: Epoch 145, Batch 17, Loss: 0.014\n",
      "Training: Epoch 145, Batch 18, Loss: 0.012\n",
      "Training: Epoch 145, Batch 19, Loss: 0.012\n",
      "Val: Epoch 145, Loss: 0.76\n",
      "Training: Epoch 146, Batch 0, Loss: 0.014\n",
      "Training: Epoch 146, Batch 1, Loss: 0.013\n",
      "Training: Epoch 146, Batch 2, Loss: 0.011\n",
      "Training: Epoch 146, Batch 3, Loss: 0.014\n",
      "Training: Epoch 146, Batch 4, Loss: 0.02\n",
      "Training: Epoch 146, Batch 5, Loss: 0.013\n",
      "Training: Epoch 146, Batch 6, Loss: 0.013\n",
      "Training: Epoch 146, Batch 7, Loss: 0.012\n",
      "Training: Epoch 146, Batch 8, Loss: 0.014\n",
      "Training: Epoch 146, Batch 9, Loss: 0.015\n",
      "Training: Epoch 146, Batch 10, Loss: 0.019\n",
      "Training: Epoch 146, Batch 11, Loss: 0.016\n",
      "Training: Epoch 146, Batch 12, Loss: 0.015\n",
      "Training: Epoch 146, Batch 13, Loss: 0.014\n",
      "Training: Epoch 146, Batch 14, Loss: 0.015\n",
      "Training: Epoch 146, Batch 15, Loss: 0.013\n",
      "Training: Epoch 146, Batch 16, Loss: 0.013\n",
      "Training: Epoch 146, Batch 17, Loss: 0.016\n",
      "Training: Epoch 146, Batch 18, Loss: 0.015\n",
      "Training: Epoch 146, Batch 19, Loss: 0.01\n",
      "Val: Epoch 146, Loss: 0.733\n",
      "Training: Epoch 147, Batch 0, Loss: 0.018\n",
      "Training: Epoch 147, Batch 1, Loss: 0.01\n",
      "Training: Epoch 147, Batch 2, Loss: 0.014\n",
      "Training: Epoch 147, Batch 3, Loss: 0.015\n",
      "Training: Epoch 147, Batch 4, Loss: 0.013\n",
      "Training: Epoch 147, Batch 5, Loss: 0.014\n",
      "Training: Epoch 147, Batch 6, Loss: 0.011\n",
      "Training: Epoch 147, Batch 7, Loss: 0.017\n",
      "Training: Epoch 147, Batch 8, Loss: 0.013\n",
      "Training: Epoch 147, Batch 9, Loss: 0.013\n",
      "Training: Epoch 147, Batch 10, Loss: 0.011\n",
      "Training: Epoch 147, Batch 11, Loss: 0.013\n",
      "Training: Epoch 147, Batch 12, Loss: 0.014\n",
      "Training: Epoch 147, Batch 13, Loss: 0.012\n",
      "Training: Epoch 147, Batch 14, Loss: 0.017\n",
      "Training: Epoch 147, Batch 15, Loss: 0.01\n",
      "Training: Epoch 147, Batch 16, Loss: 0.013\n",
      "Training: Epoch 147, Batch 17, Loss: 0.015\n",
      "Training: Epoch 147, Batch 18, Loss: 0.016\n",
      "Training: Epoch 147, Batch 19, Loss: 0.019\n",
      "Val: Epoch 147, Loss: 0.638\n",
      "Training: Epoch 148, Batch 0, Loss: 0.016\n",
      "Training: Epoch 148, Batch 1, Loss: 0.012\n",
      "Training: Epoch 148, Batch 2, Loss: 0.013\n",
      "Training: Epoch 148, Batch 3, Loss: 0.011\n",
      "Training: Epoch 148, Batch 4, Loss: 0.013\n",
      "Training: Epoch 148, Batch 5, Loss: 0.014\n",
      "Training: Epoch 148, Batch 6, Loss: 0.014\n",
      "Training: Epoch 148, Batch 7, Loss: 0.009\n",
      "Training: Epoch 148, Batch 8, Loss: 0.012\n",
      "Training: Epoch 148, Batch 9, Loss: 0.011\n",
      "Training: Epoch 148, Batch 10, Loss: 0.014\n",
      "Training: Epoch 148, Batch 11, Loss: 0.013\n",
      "Training: Epoch 148, Batch 12, Loss: 0.011\n",
      "Training: Epoch 148, Batch 13, Loss: 0.009\n",
      "Training: Epoch 148, Batch 14, Loss: 0.016\n",
      "Training: Epoch 148, Batch 15, Loss: 0.011\n",
      "Training: Epoch 148, Batch 16, Loss: 0.014\n",
      "Training: Epoch 148, Batch 17, Loss: 0.011\n",
      "Training: Epoch 148, Batch 18, Loss: 0.014\n",
      "Training: Epoch 148, Batch 19, Loss: 0.015\n",
      "Val: Epoch 148, Loss: 0.706\n",
      "Training: Epoch 149, Batch 0, Loss: 0.016\n",
      "Training: Epoch 149, Batch 1, Loss: 0.013\n",
      "Training: Epoch 149, Batch 2, Loss: 0.015\n",
      "Training: Epoch 149, Batch 3, Loss: 0.012\n",
      "Training: Epoch 149, Batch 4, Loss: 0.014\n",
      "Training: Epoch 149, Batch 5, Loss: 0.012\n",
      "Training: Epoch 149, Batch 6, Loss: 0.01\n",
      "Training: Epoch 149, Batch 7, Loss: 0.014\n",
      "Training: Epoch 149, Batch 8, Loss: 0.013\n",
      "Training: Epoch 149, Batch 9, Loss: 0.014\n",
      "Training: Epoch 149, Batch 10, Loss: 0.015\n",
      "Training: Epoch 149, Batch 11, Loss: 0.013\n",
      "Training: Epoch 149, Batch 12, Loss: 0.011\n",
      "Training: Epoch 149, Batch 13, Loss: 0.013\n",
      "Training: Epoch 149, Batch 14, Loss: 0.014\n",
      "Training: Epoch 149, Batch 15, Loss: 0.014\n",
      "Training: Epoch 149, Batch 16, Loss: 0.012\n",
      "Training: Epoch 149, Batch 17, Loss: 0.012\n",
      "Training: Epoch 149, Batch 18, Loss: 0.013\n",
      "Training: Epoch 149, Batch 19, Loss: 0.017\n",
      "Val: Epoch 149, Loss: 0.611\n",
      "Training: Epoch 150, Batch 0, Loss: 0.015\n",
      "Training: Epoch 150, Batch 1, Loss: 0.01\n",
      "Training: Epoch 150, Batch 2, Loss: 0.014\n",
      "Training: Epoch 150, Batch 3, Loss: 0.011\n",
      "Training: Epoch 150, Batch 4, Loss: 0.011\n",
      "Training: Epoch 150, Batch 5, Loss: 0.014\n",
      "Training: Epoch 150, Batch 6, Loss: 0.011\n",
      "Training: Epoch 150, Batch 7, Loss: 0.016\n",
      "Training: Epoch 150, Batch 8, Loss: 0.014\n",
      "Training: Epoch 150, Batch 9, Loss: 0.013\n",
      "Training: Epoch 150, Batch 10, Loss: 0.018\n",
      "Training: Epoch 150, Batch 11, Loss: 0.015\n",
      "Training: Epoch 150, Batch 12, Loss: 0.013\n",
      "Training: Epoch 150, Batch 13, Loss: 0.015\n",
      "Training: Epoch 150, Batch 14, Loss: 0.018\n",
      "Training: Epoch 150, Batch 15, Loss: 0.016\n",
      "Training: Epoch 150, Batch 16, Loss: 0.012\n",
      "Training: Epoch 150, Batch 17, Loss: 0.014\n",
      "Training: Epoch 150, Batch 18, Loss: 0.013\n",
      "Training: Epoch 150, Batch 19, Loss: 0.011\n",
      "Val: Epoch 150, Loss: 0.647\n",
      "Training: Epoch 151, Batch 0, Loss: 0.015\n",
      "Training: Epoch 151, Batch 1, Loss: 0.014\n",
      "Training: Epoch 151, Batch 2, Loss: 0.011\n",
      "Training: Epoch 151, Batch 3, Loss: 0.015\n",
      "Training: Epoch 151, Batch 4, Loss: 0.011\n",
      "Training: Epoch 151, Batch 5, Loss: 0.013\n",
      "Training: Epoch 151, Batch 6, Loss: 0.018\n",
      "Training: Epoch 151, Batch 7, Loss: 0.018\n",
      "Training: Epoch 151, Batch 8, Loss: 0.012\n",
      "Training: Epoch 151, Batch 9, Loss: 0.021\n",
      "Training: Epoch 151, Batch 10, Loss: 0.013\n",
      "Training: Epoch 151, Batch 11, Loss: 0.017\n",
      "Training: Epoch 151, Batch 12, Loss: 0.017\n",
      "Training: Epoch 151, Batch 13, Loss: 0.019\n",
      "Training: Epoch 151, Batch 14, Loss: 0.015\n",
      "Training: Epoch 151, Batch 15, Loss: 0.015\n",
      "Training: Epoch 151, Batch 16, Loss: 0.016\n",
      "Training: Epoch 151, Batch 17, Loss: 0.016\n",
      "Training: Epoch 151, Batch 18, Loss: 0.011\n",
      "Training: Epoch 151, Batch 19, Loss: 0.012\n",
      "Val: Epoch 151, Loss: 0.634\n",
      "Training: Epoch 152, Batch 0, Loss: 0.017\n",
      "Training: Epoch 152, Batch 1, Loss: 0.014\n",
      "Training: Epoch 152, Batch 2, Loss: 0.016\n",
      "Training: Epoch 152, Batch 3, Loss: 0.011\n",
      "Training: Epoch 152, Batch 4, Loss: 0.018\n",
      "Training: Epoch 152, Batch 5, Loss: 0.012\n",
      "Training: Epoch 152, Batch 6, Loss: 0.016\n",
      "Training: Epoch 152, Batch 7, Loss: 0.011\n",
      "Training: Epoch 152, Batch 8, Loss: 0.011\n",
      "Training: Epoch 152, Batch 9, Loss: 0.013\n",
      "Training: Epoch 152, Batch 10, Loss: 0.013\n",
      "Training: Epoch 152, Batch 11, Loss: 0.013\n",
      "Training: Epoch 152, Batch 12, Loss: 0.015\n",
      "Training: Epoch 152, Batch 13, Loss: 0.013\n",
      "Training: Epoch 152, Batch 14, Loss: 0.017\n",
      "Training: Epoch 152, Batch 15, Loss: 0.015\n",
      "Training: Epoch 152, Batch 16, Loss: 0.015\n",
      "Training: Epoch 152, Batch 17, Loss: 0.016\n",
      "Training: Epoch 152, Batch 18, Loss: 0.014\n",
      "Training: Epoch 152, Batch 19, Loss: 0.025\n",
      "Val: Epoch 152, Loss: 0.631\n",
      "Training: Epoch 153, Batch 0, Loss: 0.01\n",
      "Training: Epoch 153, Batch 1, Loss: 0.013\n",
      "Training: Epoch 153, Batch 2, Loss: 0.011\n",
      "Training: Epoch 153, Batch 3, Loss: 0.011\n",
      "Training: Epoch 153, Batch 4, Loss: 0.011\n",
      "Training: Epoch 153, Batch 5, Loss: 0.017\n",
      "Training: Epoch 153, Batch 6, Loss: 0.016\n",
      "Training: Epoch 153, Batch 7, Loss: 0.018\n",
      "Training: Epoch 153, Batch 8, Loss: 0.015\n",
      "Training: Epoch 153, Batch 9, Loss: 0.012\n",
      "Training: Epoch 153, Batch 10, Loss: 0.016\n",
      "Training: Epoch 153, Batch 11, Loss: 0.013\n",
      "Training: Epoch 153, Batch 12, Loss: 0.012\n",
      "Training: Epoch 153, Batch 13, Loss: 0.015\n",
      "Training: Epoch 153, Batch 14, Loss: 0.015\n",
      "Training: Epoch 153, Batch 15, Loss: 0.014\n",
      "Training: Epoch 153, Batch 16, Loss: 0.011\n",
      "Training: Epoch 153, Batch 17, Loss: 0.014\n",
      "Training: Epoch 153, Batch 18, Loss: 0.012\n",
      "Training: Epoch 153, Batch 19, Loss: 0.011\n",
      "Val: Epoch 153, Loss: 0.631\n",
      "Training: Epoch 154, Batch 0, Loss: 0.012\n",
      "Training: Epoch 154, Batch 1, Loss: 0.013\n",
      "Training: Epoch 154, Batch 2, Loss: 0.011\n",
      "Training: Epoch 154, Batch 3, Loss: 0.014\n",
      "Training: Epoch 154, Batch 4, Loss: 0.012\n",
      "Training: Epoch 154, Batch 5, Loss: 0.011\n",
      "Training: Epoch 154, Batch 6, Loss: 0.013\n",
      "Training: Epoch 154, Batch 7, Loss: 0.014\n",
      "Training: Epoch 154, Batch 8, Loss: 0.013\n",
      "Training: Epoch 154, Batch 9, Loss: 0.015\n",
      "Training: Epoch 154, Batch 10, Loss: 0.012\n",
      "Training: Epoch 154, Batch 11, Loss: 0.01\n",
      "Training: Epoch 154, Batch 12, Loss: 0.01\n",
      "Training: Epoch 154, Batch 13, Loss: 0.015\n",
      "Training: Epoch 154, Batch 14, Loss: 0.013\n",
      "Training: Epoch 154, Batch 15, Loss: 0.013\n",
      "Training: Epoch 154, Batch 16, Loss: 0.014\n",
      "Training: Epoch 154, Batch 17, Loss: 0.013\n",
      "Training: Epoch 154, Batch 18, Loss: 0.011\n",
      "Training: Epoch 154, Batch 19, Loss: 0.012\n",
      "Val: Epoch 154, Loss: 0.623\n",
      "Training: Epoch 155, Batch 0, Loss: 0.011\n",
      "Training: Epoch 155, Batch 1, Loss: 0.015\n",
      "Training: Epoch 155, Batch 2, Loss: 0.012\n",
      "Training: Epoch 155, Batch 3, Loss: 0.012\n",
      "Training: Epoch 155, Batch 4, Loss: 0.013\n",
      "Training: Epoch 155, Batch 5, Loss: 0.01\n",
      "Training: Epoch 155, Batch 6, Loss: 0.011\n",
      "Training: Epoch 155, Batch 7, Loss: 0.014\n",
      "Training: Epoch 155, Batch 8, Loss: 0.013\n",
      "Training: Epoch 155, Batch 9, Loss: 0.011\n",
      "Training: Epoch 155, Batch 10, Loss: 0.012\n",
      "Training: Epoch 155, Batch 11, Loss: 0.011\n",
      "Training: Epoch 155, Batch 12, Loss: 0.01\n",
      "Training: Epoch 155, Batch 13, Loss: 0.015\n",
      "Training: Epoch 155, Batch 14, Loss: 0.014\n",
      "Training: Epoch 155, Batch 15, Loss: 0.01\n",
      "Training: Epoch 155, Batch 16, Loss: 0.015\n",
      "Training: Epoch 155, Batch 17, Loss: 0.01\n",
      "Training: Epoch 155, Batch 18, Loss: 0.01\n",
      "Training: Epoch 155, Batch 19, Loss: 0.013\n",
      "Val: Epoch 155, Loss: 0.67\n",
      "Training: Epoch 156, Batch 0, Loss: 0.011\n",
      "Training: Epoch 156, Batch 1, Loss: 0.015\n",
      "Training: Epoch 156, Batch 2, Loss: 0.012\n",
      "Training: Epoch 156, Batch 3, Loss: 0.011\n",
      "Training: Epoch 156, Batch 4, Loss: 0.01\n",
      "Training: Epoch 156, Batch 5, Loss: 0.011\n",
      "Training: Epoch 156, Batch 6, Loss: 0.01\n",
      "Training: Epoch 156, Batch 7, Loss: 0.013\n",
      "Training: Epoch 156, Batch 8, Loss: 0.011\n",
      "Training: Epoch 156, Batch 9, Loss: 0.01\n",
      "Training: Epoch 156, Batch 10, Loss: 0.01\n",
      "Training: Epoch 156, Batch 11, Loss: 0.011\n",
      "Training: Epoch 156, Batch 12, Loss: 0.01\n",
      "Training: Epoch 156, Batch 13, Loss: 0.012\n",
      "Training: Epoch 156, Batch 14, Loss: 0.018\n",
      "Training: Epoch 156, Batch 15, Loss: 0.015\n",
      "Training: Epoch 156, Batch 16, Loss: 0.013\n",
      "Training: Epoch 156, Batch 17, Loss: 0.014\n",
      "Training: Epoch 156, Batch 18, Loss: 0.014\n",
      "Training: Epoch 156, Batch 19, Loss: 0.012\n",
      "Val: Epoch 156, Loss: 0.614\n",
      "Training: Epoch 157, Batch 0, Loss: 0.014\n",
      "Training: Epoch 157, Batch 1, Loss: 0.012\n",
      "Training: Epoch 157, Batch 2, Loss: 0.011\n",
      "Training: Epoch 157, Batch 3, Loss: 0.013\n",
      "Training: Epoch 157, Batch 4, Loss: 0.012\n",
      "Training: Epoch 157, Batch 5, Loss: 0.013\n",
      "Training: Epoch 157, Batch 6, Loss: 0.014\n",
      "Training: Epoch 157, Batch 7, Loss: 0.011\n",
      "Training: Epoch 157, Batch 8, Loss: 0.01\n",
      "Training: Epoch 157, Batch 9, Loss: 0.013\n",
      "Training: Epoch 157, Batch 10, Loss: 0.016\n",
      "Training: Epoch 157, Batch 11, Loss: 0.011\n",
      "Training: Epoch 157, Batch 12, Loss: 0.013\n",
      "Training: Epoch 157, Batch 13, Loss: 0.015\n",
      "Training: Epoch 157, Batch 14, Loss: 0.012\n",
      "Training: Epoch 157, Batch 15, Loss: 0.012\n",
      "Training: Epoch 157, Batch 16, Loss: 0.01\n",
      "Training: Epoch 157, Batch 17, Loss: 0.013\n",
      "Training: Epoch 157, Batch 18, Loss: 0.011\n",
      "Training: Epoch 157, Batch 19, Loss: 0.012\n",
      "Val: Epoch 157, Loss: 0.734\n",
      "Training: Epoch 158, Batch 0, Loss: 0.009\n",
      "Training: Epoch 158, Batch 1, Loss: 0.011\n",
      "Training: Epoch 158, Batch 2, Loss: 0.011\n",
      "Training: Epoch 158, Batch 3, Loss: 0.011\n",
      "Training: Epoch 158, Batch 4, Loss: 0.014\n",
      "Training: Epoch 158, Batch 5, Loss: 0.008\n",
      "Training: Epoch 158, Batch 6, Loss: 0.013\n",
      "Training: Epoch 158, Batch 7, Loss: 0.011\n",
      "Training: Epoch 158, Batch 8, Loss: 0.01\n",
      "Training: Epoch 158, Batch 9, Loss: 0.01\n",
      "Training: Epoch 158, Batch 10, Loss: 0.012\n",
      "Training: Epoch 158, Batch 11, Loss: 0.012\n",
      "Training: Epoch 158, Batch 12, Loss: 0.009\n",
      "Training: Epoch 158, Batch 13, Loss: 0.014\n",
      "Training: Epoch 158, Batch 14, Loss: 0.012\n",
      "Training: Epoch 158, Batch 15, Loss: 0.012\n",
      "Training: Epoch 158, Batch 16, Loss: 0.012\n",
      "Training: Epoch 158, Batch 17, Loss: 0.015\n",
      "Training: Epoch 158, Batch 18, Loss: 0.012\n",
      "Training: Epoch 158, Batch 19, Loss: 0.012\n",
      "Val: Epoch 158, Loss: 0.688\n",
      "Training: Epoch 159, Batch 0, Loss: 0.009\n",
      "Training: Epoch 159, Batch 1, Loss: 0.011\n",
      "Training: Epoch 159, Batch 2, Loss: 0.007\n",
      "Training: Epoch 159, Batch 3, Loss: 0.014\n",
      "Training: Epoch 159, Batch 4, Loss: 0.011\n",
      "Training: Epoch 159, Batch 5, Loss: 0.02\n",
      "Training: Epoch 159, Batch 6, Loss: 0.012\n",
      "Training: Epoch 159, Batch 7, Loss: 0.01\n",
      "Training: Epoch 159, Batch 8, Loss: 0.01\n",
      "Training: Epoch 159, Batch 9, Loss: 0.011\n",
      "Training: Epoch 159, Batch 10, Loss: 0.014\n",
      "Training: Epoch 159, Batch 11, Loss: 0.012\n",
      "Training: Epoch 159, Batch 12, Loss: 0.014\n",
      "Training: Epoch 159, Batch 13, Loss: 0.013\n",
      "Training: Epoch 159, Batch 14, Loss: 0.013\n",
      "Training: Epoch 159, Batch 15, Loss: 0.011\n",
      "Training: Epoch 159, Batch 16, Loss: 0.012\n",
      "Training: Epoch 159, Batch 17, Loss: 0.013\n",
      "Training: Epoch 159, Batch 18, Loss: 0.01\n",
      "Training: Epoch 159, Batch 19, Loss: 0.01\n",
      "Val: Epoch 159, Loss: 0.645\n",
      "Training: Epoch 160, Batch 0, Loss: 0.013\n",
      "Training: Epoch 160, Batch 1, Loss: 0.01\n",
      "Training: Epoch 160, Batch 2, Loss: 0.013\n",
      "Training: Epoch 160, Batch 3, Loss: 0.013\n",
      "Training: Epoch 160, Batch 4, Loss: 0.012\n",
      "Training: Epoch 160, Batch 5, Loss: 0.011\n",
      "Training: Epoch 160, Batch 6, Loss: 0.011\n",
      "Training: Epoch 160, Batch 7, Loss: 0.01\n",
      "Training: Epoch 160, Batch 8, Loss: 0.017\n",
      "Training: Epoch 160, Batch 9, Loss: 0.012\n",
      "Training: Epoch 160, Batch 10, Loss: 0.011\n",
      "Training: Epoch 160, Batch 11, Loss: 0.011\n",
      "Training: Epoch 160, Batch 12, Loss: 0.012\n",
      "Training: Epoch 160, Batch 13, Loss: 0.011\n",
      "Training: Epoch 160, Batch 14, Loss: 0.011\n",
      "Training: Epoch 160, Batch 15, Loss: 0.013\n",
      "Training: Epoch 160, Batch 16, Loss: 0.014\n",
      "Training: Epoch 160, Batch 17, Loss: 0.01\n",
      "Training: Epoch 160, Batch 18, Loss: 0.01\n",
      "Training: Epoch 160, Batch 19, Loss: 0.015\n",
      "Val: Epoch 160, Loss: 0.693\n",
      "Training: Epoch 161, Batch 0, Loss: 0.011\n",
      "Training: Epoch 161, Batch 1, Loss: 0.012\n",
      "Training: Epoch 161, Batch 2, Loss: 0.013\n",
      "Training: Epoch 161, Batch 3, Loss: 0.013\n",
      "Training: Epoch 161, Batch 4, Loss: 0.012\n",
      "Training: Epoch 161, Batch 5, Loss: 0.013\n",
      "Training: Epoch 161, Batch 6, Loss: 0.008\n",
      "Training: Epoch 161, Batch 7, Loss: 0.013\n",
      "Training: Epoch 161, Batch 8, Loss: 0.012\n",
      "Training: Epoch 161, Batch 9, Loss: 0.01\n",
      "Training: Epoch 161, Batch 10, Loss: 0.009\n",
      "Training: Epoch 161, Batch 11, Loss: 0.011\n",
      "Training: Epoch 161, Batch 12, Loss: 0.012\n",
      "Training: Epoch 161, Batch 13, Loss: 0.014\n",
      "Training: Epoch 161, Batch 14, Loss: 0.013\n",
      "Training: Epoch 161, Batch 15, Loss: 0.009\n",
      "Training: Epoch 161, Batch 16, Loss: 0.011\n",
      "Training: Epoch 161, Batch 17, Loss: 0.011\n",
      "Training: Epoch 161, Batch 18, Loss: 0.009\n",
      "Training: Epoch 161, Batch 19, Loss: 0.012\n",
      "Val: Epoch 161, Loss: 0.662\n",
      "Training: Epoch 162, Batch 0, Loss: 0.01\n",
      "Training: Epoch 162, Batch 1, Loss: 0.008\n",
      "Training: Epoch 162, Batch 2, Loss: 0.011\n",
      "Training: Epoch 162, Batch 3, Loss: 0.016\n",
      "Training: Epoch 162, Batch 4, Loss: 0.016\n",
      "Training: Epoch 162, Batch 5, Loss: 0.013\n",
      "Training: Epoch 162, Batch 6, Loss: 0.009\n",
      "Training: Epoch 162, Batch 7, Loss: 0.011\n",
      "Training: Epoch 162, Batch 8, Loss: 0.013\n",
      "Training: Epoch 162, Batch 9, Loss: 0.012\n",
      "Training: Epoch 162, Batch 10, Loss: 0.011\n",
      "Training: Epoch 162, Batch 11, Loss: 0.012\n",
      "Training: Epoch 162, Batch 12, Loss: 0.01\n",
      "Training: Epoch 162, Batch 13, Loss: 0.01\n",
      "Training: Epoch 162, Batch 14, Loss: 0.013\n",
      "Training: Epoch 162, Batch 15, Loss: 0.013\n",
      "Training: Epoch 162, Batch 16, Loss: 0.01\n",
      "Training: Epoch 162, Batch 17, Loss: 0.011\n",
      "Training: Epoch 162, Batch 18, Loss: 0.008\n",
      "Training: Epoch 162, Batch 19, Loss: 0.013\n",
      "Val: Epoch 162, Loss: 0.686\n",
      "Training: Epoch 163, Batch 0, Loss: 0.011\n",
      "Training: Epoch 163, Batch 1, Loss: 0.014\n",
      "Training: Epoch 163, Batch 2, Loss: 0.009\n",
      "Training: Epoch 163, Batch 3, Loss: 0.012\n",
      "Training: Epoch 163, Batch 4, Loss: 0.013\n",
      "Training: Epoch 163, Batch 5, Loss: 0.01\n",
      "Training: Epoch 163, Batch 6, Loss: 0.012\n",
      "Training: Epoch 163, Batch 7, Loss: 0.014\n",
      "Training: Epoch 163, Batch 8, Loss: 0.011\n",
      "Training: Epoch 163, Batch 9, Loss: 0.014\n",
      "Training: Epoch 163, Batch 10, Loss: 0.01\n",
      "Training: Epoch 163, Batch 11, Loss: 0.015\n",
      "Training: Epoch 163, Batch 12, Loss: 0.013\n",
      "Training: Epoch 163, Batch 13, Loss: 0.01\n",
      "Training: Epoch 163, Batch 14, Loss: 0.008\n",
      "Training: Epoch 163, Batch 15, Loss: 0.01\n",
      "Training: Epoch 163, Batch 16, Loss: 0.011\n",
      "Training: Epoch 163, Batch 17, Loss: 0.015\n",
      "Training: Epoch 163, Batch 18, Loss: 0.013\n",
      "Training: Epoch 163, Batch 19, Loss: 0.019\n",
      "Val: Epoch 163, Loss: 0.68\n",
      "Training: Epoch 164, Batch 0, Loss: 0.01\n",
      "Training: Epoch 164, Batch 1, Loss: 0.011\n",
      "Training: Epoch 164, Batch 2, Loss: 0.012\n",
      "Training: Epoch 164, Batch 3, Loss: 0.013\n",
      "Training: Epoch 164, Batch 4, Loss: 0.011\n",
      "Training: Epoch 164, Batch 5, Loss: 0.011\n",
      "Training: Epoch 164, Batch 6, Loss: 0.009\n",
      "Training: Epoch 164, Batch 7, Loss: 0.013\n",
      "Training: Epoch 164, Batch 8, Loss: 0.012\n",
      "Training: Epoch 164, Batch 9, Loss: 0.014\n",
      "Training: Epoch 164, Batch 10, Loss: 0.008\n",
      "Training: Epoch 164, Batch 11, Loss: 0.012\n",
      "Training: Epoch 164, Batch 12, Loss: 0.013\n",
      "Training: Epoch 164, Batch 13, Loss: 0.009\n",
      "Training: Epoch 164, Batch 14, Loss: 0.01\n",
      "Training: Epoch 164, Batch 15, Loss: 0.01\n",
      "Training: Epoch 164, Batch 16, Loss: 0.013\n",
      "Training: Epoch 164, Batch 17, Loss: 0.012\n",
      "Training: Epoch 164, Batch 18, Loss: 0.013\n",
      "Training: Epoch 164, Batch 19, Loss: 0.01\n",
      "Val: Epoch 164, Loss: 0.698\n",
      "Training: Epoch 165, Batch 0, Loss: 0.013\n",
      "Training: Epoch 165, Batch 1, Loss: 0.011\n",
      "Training: Epoch 165, Batch 2, Loss: 0.009\n",
      "Training: Epoch 165, Batch 3, Loss: 0.014\n",
      "Training: Epoch 165, Batch 4, Loss: 0.012\n",
      "Training: Epoch 165, Batch 5, Loss: 0.012\n",
      "Training: Epoch 165, Batch 6, Loss: 0.014\n",
      "Training: Epoch 165, Batch 7, Loss: 0.011\n",
      "Training: Epoch 165, Batch 8, Loss: 0.01\n",
      "Training: Epoch 165, Batch 9, Loss: 0.01\n",
      "Training: Epoch 165, Batch 10, Loss: 0.011\n",
      "Training: Epoch 165, Batch 11, Loss: 0.012\n",
      "Training: Epoch 165, Batch 12, Loss: 0.008\n",
      "Training: Epoch 165, Batch 13, Loss: 0.008\n",
      "Training: Epoch 165, Batch 14, Loss: 0.013\n",
      "Training: Epoch 165, Batch 15, Loss: 0.015\n",
      "Training: Epoch 165, Batch 16, Loss: 0.008\n",
      "Training: Epoch 165, Batch 17, Loss: 0.012\n",
      "Training: Epoch 165, Batch 18, Loss: 0.015\n",
      "Training: Epoch 165, Batch 19, Loss: 0.015\n",
      "Val: Epoch 165, Loss: 0.66\n",
      "Training: Epoch 166, Batch 0, Loss: 0.009\n",
      "Training: Epoch 166, Batch 1, Loss: 0.011\n",
      "Training: Epoch 166, Batch 2, Loss: 0.008\n",
      "Training: Epoch 166, Batch 3, Loss: 0.013\n",
      "Training: Epoch 166, Batch 4, Loss: 0.008\n",
      "Training: Epoch 166, Batch 5, Loss: 0.013\n",
      "Training: Epoch 166, Batch 6, Loss: 0.013\n",
      "Training: Epoch 166, Batch 7, Loss: 0.012\n",
      "Training: Epoch 166, Batch 8, Loss: 0.009\n",
      "Training: Epoch 166, Batch 9, Loss: 0.011\n",
      "Training: Epoch 166, Batch 10, Loss: 0.01\n",
      "Training: Epoch 166, Batch 11, Loss: 0.012\n",
      "Training: Epoch 166, Batch 12, Loss: 0.015\n",
      "Training: Epoch 166, Batch 13, Loss: 0.01\n",
      "Training: Epoch 166, Batch 14, Loss: 0.011\n",
      "Training: Epoch 166, Batch 15, Loss: 0.008\n",
      "Training: Epoch 166, Batch 16, Loss: 0.011\n",
      "Training: Epoch 166, Batch 17, Loss: 0.008\n",
      "Training: Epoch 166, Batch 18, Loss: 0.011\n",
      "Training: Epoch 166, Batch 19, Loss: 0.012\n",
      "Val: Epoch 166, Loss: 0.668\n",
      "Training: Epoch 167, Batch 0, Loss: 0.011\n",
      "Training: Epoch 167, Batch 1, Loss: 0.008\n",
      "Training: Epoch 167, Batch 2, Loss: 0.01\n",
      "Training: Epoch 167, Batch 3, Loss: 0.011\n",
      "Training: Epoch 167, Batch 4, Loss: 0.011\n",
      "Training: Epoch 167, Batch 5, Loss: 0.01\n",
      "Training: Epoch 167, Batch 6, Loss: 0.012\n",
      "Training: Epoch 167, Batch 7, Loss: 0.009\n",
      "Training: Epoch 167, Batch 8, Loss: 0.008\n",
      "Training: Epoch 167, Batch 9, Loss: 0.012\n",
      "Training: Epoch 167, Batch 10, Loss: 0.009\n",
      "Training: Epoch 167, Batch 11, Loss: 0.012\n",
      "Training: Epoch 167, Batch 12, Loss: 0.009\n",
      "Training: Epoch 167, Batch 13, Loss: 0.009\n",
      "Training: Epoch 167, Batch 14, Loss: 0.011\n",
      "Training: Epoch 167, Batch 15, Loss: 0.009\n",
      "Training: Epoch 167, Batch 16, Loss: 0.006\n",
      "Training: Epoch 167, Batch 17, Loss: 0.011\n",
      "Training: Epoch 167, Batch 18, Loss: 0.013\n",
      "Training: Epoch 167, Batch 19, Loss: 0.01\n",
      "Val: Epoch 167, Loss: 0.688\n",
      "Training: Epoch 168, Batch 0, Loss: 0.01\n",
      "Training: Epoch 168, Batch 1, Loss: 0.012\n",
      "Training: Epoch 168, Batch 2, Loss: 0.011\n",
      "Training: Epoch 168, Batch 3, Loss: 0.009\n",
      "Training: Epoch 168, Batch 4, Loss: 0.011\n",
      "Training: Epoch 168, Batch 5, Loss: 0.011\n",
      "Training: Epoch 168, Batch 6, Loss: 0.008\n",
      "Training: Epoch 168, Batch 7, Loss: 0.009\n",
      "Training: Epoch 168, Batch 8, Loss: 0.008\n",
      "Training: Epoch 168, Batch 9, Loss: 0.012\n",
      "Training: Epoch 168, Batch 10, Loss: 0.008\n",
      "Training: Epoch 168, Batch 11, Loss: 0.015\n",
      "Training: Epoch 168, Batch 12, Loss: 0.01\n",
      "Training: Epoch 168, Batch 13, Loss: 0.013\n",
      "Training: Epoch 168, Batch 14, Loss: 0.009\n",
      "Training: Epoch 168, Batch 15, Loss: 0.01\n",
      "Training: Epoch 168, Batch 16, Loss: 0.013\n",
      "Training: Epoch 168, Batch 17, Loss: 0.009\n",
      "Training: Epoch 168, Batch 18, Loss: 0.01\n",
      "Training: Epoch 168, Batch 19, Loss: 0.009\n",
      "Val: Epoch 168, Loss: 0.726\n",
      "Training: Epoch 169, Batch 0, Loss: 0.013\n",
      "Training: Epoch 169, Batch 1, Loss: 0.014\n",
      "Training: Epoch 169, Batch 2, Loss: 0.009\n",
      "Training: Epoch 169, Batch 3, Loss: 0.012\n",
      "Training: Epoch 169, Batch 4, Loss: 0.011\n",
      "Training: Epoch 169, Batch 5, Loss: 0.012\n",
      "Training: Epoch 169, Batch 6, Loss: 0.011\n",
      "Training: Epoch 169, Batch 7, Loss: 0.013\n",
      "Training: Epoch 169, Batch 8, Loss: 0.01\n",
      "Training: Epoch 169, Batch 9, Loss: 0.012\n",
      "Training: Epoch 169, Batch 10, Loss: 0.013\n",
      "Training: Epoch 169, Batch 11, Loss: 0.013\n",
      "Training: Epoch 169, Batch 12, Loss: 0.011\n",
      "Training: Epoch 169, Batch 13, Loss: 0.01\n",
      "Training: Epoch 169, Batch 14, Loss: 0.019\n",
      "Training: Epoch 169, Batch 15, Loss: 0.009\n",
      "Training: Epoch 169, Batch 16, Loss: 0.014\n",
      "Training: Epoch 169, Batch 17, Loss: 0.013\n",
      "Training: Epoch 169, Batch 18, Loss: 0.009\n",
      "Training: Epoch 169, Batch 19, Loss: 0.009\n",
      "Val: Epoch 169, Loss: 0.683\n",
      "Training: Epoch 170, Batch 0, Loss: 0.009\n",
      "Training: Epoch 170, Batch 1, Loss: 0.008\n",
      "Training: Epoch 170, Batch 2, Loss: 0.012\n",
      "Training: Epoch 170, Batch 3, Loss: 0.012\n",
      "Training: Epoch 170, Batch 4, Loss: 0.013\n",
      "Training: Epoch 170, Batch 5, Loss: 0.012\n",
      "Training: Epoch 170, Batch 6, Loss: 0.011\n",
      "Training: Epoch 170, Batch 7, Loss: 0.009\n",
      "Training: Epoch 170, Batch 8, Loss: 0.014\n",
      "Training: Epoch 170, Batch 9, Loss: 0.012\n",
      "Training: Epoch 170, Batch 10, Loss: 0.013\n",
      "Training: Epoch 170, Batch 11, Loss: 0.01\n",
      "Training: Epoch 170, Batch 12, Loss: 0.015\n",
      "Training: Epoch 170, Batch 13, Loss: 0.011\n",
      "Training: Epoch 170, Batch 14, Loss: 0.011\n",
      "Training: Epoch 170, Batch 15, Loss: 0.01\n",
      "Training: Epoch 170, Batch 16, Loss: 0.012\n",
      "Training: Epoch 170, Batch 17, Loss: 0.012\n",
      "Training: Epoch 170, Batch 18, Loss: 0.01\n",
      "Training: Epoch 170, Batch 19, Loss: 0.013\n",
      "Val: Epoch 170, Loss: 0.741\n",
      "Training: Epoch 171, Batch 0, Loss: 0.012\n",
      "Training: Epoch 171, Batch 1, Loss: 0.008\n",
      "Training: Epoch 171, Batch 2, Loss: 0.01\n",
      "Training: Epoch 171, Batch 3, Loss: 0.01\n",
      "Training: Epoch 171, Batch 4, Loss: 0.011\n",
      "Training: Epoch 171, Batch 5, Loss: 0.011\n",
      "Training: Epoch 171, Batch 6, Loss: 0.011\n",
      "Training: Epoch 171, Batch 7, Loss: 0.014\n",
      "Training: Epoch 171, Batch 8, Loss: 0.012\n",
      "Training: Epoch 171, Batch 9, Loss: 0.013\n",
      "Training: Epoch 171, Batch 10, Loss: 0.01\n",
      "Training: Epoch 171, Batch 11, Loss: 0.01\n",
      "Training: Epoch 171, Batch 12, Loss: 0.024\n",
      "Training: Epoch 171, Batch 13, Loss: 0.009\n",
      "Training: Epoch 171, Batch 14, Loss: 0.011\n",
      "Training: Epoch 171, Batch 15, Loss: 0.012\n",
      "Training: Epoch 171, Batch 16, Loss: 0.013\n",
      "Training: Epoch 171, Batch 17, Loss: 0.011\n",
      "Training: Epoch 171, Batch 18, Loss: 0.009\n",
      "Training: Epoch 171, Batch 19, Loss: 0.011\n",
      "Val: Epoch 171, Loss: 0.68\n",
      "Training: Epoch 172, Batch 0, Loss: 0.01\n",
      "Training: Epoch 172, Batch 1, Loss: 0.012\n",
      "Training: Epoch 172, Batch 2, Loss: 0.012\n",
      "Training: Epoch 172, Batch 3, Loss: 0.01\n",
      "Training: Epoch 172, Batch 4, Loss: 0.008\n",
      "Training: Epoch 172, Batch 5, Loss: 0.012\n",
      "Training: Epoch 172, Batch 6, Loss: 0.016\n",
      "Training: Epoch 172, Batch 7, Loss: 0.011\n",
      "Training: Epoch 172, Batch 8, Loss: 0.011\n",
      "Training: Epoch 172, Batch 9, Loss: 0.011\n",
      "Training: Epoch 172, Batch 10, Loss: 0.019\n",
      "Training: Epoch 172, Batch 11, Loss: 0.014\n",
      "Training: Epoch 172, Batch 12, Loss: 0.01\n",
      "Training: Epoch 172, Batch 13, Loss: 0.01\n",
      "Training: Epoch 172, Batch 14, Loss: 0.011\n",
      "Training: Epoch 172, Batch 15, Loss: 0.009\n",
      "Training: Epoch 172, Batch 16, Loss: 0.012\n",
      "Training: Epoch 172, Batch 17, Loss: 0.011\n",
      "Training: Epoch 172, Batch 18, Loss: 0.013\n",
      "Training: Epoch 172, Batch 19, Loss: 0.011\n",
      "Val: Epoch 172, Loss: 0.682\n",
      "Training: Epoch 173, Batch 0, Loss: 0.012\n",
      "Training: Epoch 173, Batch 1, Loss: 0.01\n",
      "Training: Epoch 173, Batch 2, Loss: 0.014\n",
      "Training: Epoch 173, Batch 3, Loss: 0.011\n",
      "Training: Epoch 173, Batch 4, Loss: 0.022\n",
      "Training: Epoch 173, Batch 5, Loss: 0.019\n",
      "Training: Epoch 173, Batch 6, Loss: 0.009\n",
      "Training: Epoch 173, Batch 7, Loss: 0.012\n",
      "Training: Epoch 173, Batch 8, Loss: 0.018\n",
      "Training: Epoch 173, Batch 9, Loss: 0.019\n",
      "Training: Epoch 173, Batch 10, Loss: 0.042\n",
      "Training: Epoch 173, Batch 11, Loss: 0.017\n",
      "Training: Epoch 173, Batch 12, Loss: 0.056\n",
      "Training: Epoch 173, Batch 13, Loss: 0.034\n",
      "Training: Epoch 173, Batch 14, Loss: 0.059\n",
      "Training: Epoch 173, Batch 15, Loss: 0.105\n",
      "Training: Epoch 173, Batch 16, Loss: 0.293\n",
      "Training: Epoch 173, Batch 17, Loss: 0.186\n",
      "Training: Epoch 173, Batch 18, Loss: 0.236\n",
      "Training: Epoch 173, Batch 19, Loss: 0.353\n",
      "Val: Epoch 173, Loss: 7.227\n",
      "Training: Epoch 174, Batch 0, Loss: 0.371\n",
      "Training: Epoch 174, Batch 1, Loss: 0.287\n",
      "Training: Epoch 174, Batch 2, Loss: 0.232\n",
      "Training: Epoch 174, Batch 3, Loss: 0.219\n",
      "Training: Epoch 174, Batch 4, Loss: 0.218\n",
      "Training: Epoch 174, Batch 5, Loss: 0.266\n",
      "Training: Epoch 174, Batch 6, Loss: 0.249\n",
      "Training: Epoch 174, Batch 7, Loss: 0.471\n",
      "Training: Epoch 174, Batch 8, Loss: 0.273\n",
      "Training: Epoch 174, Batch 9, Loss: 0.339\n",
      "Training: Epoch 174, Batch 10, Loss: 0.305\n",
      "Training: Epoch 174, Batch 11, Loss: 0.275\n",
      "Training: Epoch 174, Batch 12, Loss: 0.399\n",
      "Training: Epoch 174, Batch 13, Loss: 0.304\n",
      "Training: Epoch 174, Batch 14, Loss: 0.216\n",
      "Training: Epoch 174, Batch 15, Loss: 0.183\n",
      "Training: Epoch 174, Batch 16, Loss: 0.292\n",
      "Training: Epoch 174, Batch 17, Loss: 0.178\n",
      "Training: Epoch 174, Batch 18, Loss: 0.32\n",
      "Training: Epoch 174, Batch 19, Loss: 0.307\n",
      "Val: Epoch 174, Loss: 0.56\n",
      "Training: Epoch 175, Batch 0, Loss: 0.23\n",
      "Training: Epoch 175, Batch 1, Loss: 0.199\n",
      "Training: Epoch 175, Batch 2, Loss: 0.178\n",
      "Training: Epoch 175, Batch 3, Loss: 0.185\n",
      "Training: Epoch 175, Batch 4, Loss: 0.234\n",
      "Training: Epoch 175, Batch 5, Loss: 0.189\n",
      "Training: Epoch 175, Batch 6, Loss: 0.208\n",
      "Training: Epoch 175, Batch 7, Loss: 0.242\n",
      "Training: Epoch 175, Batch 8, Loss: 0.186\n",
      "Training: Epoch 175, Batch 9, Loss: 0.16\n",
      "Training: Epoch 175, Batch 10, Loss: 0.211\n",
      "Training: Epoch 175, Batch 11, Loss: 0.274\n",
      "Training: Epoch 175, Batch 12, Loss: 0.199\n",
      "Training: Epoch 175, Batch 13, Loss: 0.23\n",
      "Training: Epoch 175, Batch 14, Loss: 0.177\n",
      "Training: Epoch 175, Batch 15, Loss: 0.155\n",
      "Training: Epoch 175, Batch 16, Loss: 0.188\n",
      "Training: Epoch 175, Batch 17, Loss: 0.206\n",
      "Training: Epoch 175, Batch 18, Loss: 0.174\n",
      "Training: Epoch 175, Batch 19, Loss: 0.208\n",
      "Val: Epoch 175, Loss: 0.329\n",
      "Training: Epoch 176, Batch 0, Loss: 0.178\n",
      "Training: Epoch 176, Batch 1, Loss: 0.214\n",
      "Training: Epoch 176, Batch 2, Loss: 0.319\n",
      "Training: Epoch 176, Batch 3, Loss: 0.436\n",
      "Training: Epoch 176, Batch 4, Loss: 0.225\n",
      "Training: Epoch 176, Batch 5, Loss: 0.176\n",
      "Training: Epoch 176, Batch 6, Loss: 0.17\n",
      "Training: Epoch 176, Batch 7, Loss: 0.187\n",
      "Training: Epoch 176, Batch 8, Loss: 0.175\n",
      "Training: Epoch 176, Batch 9, Loss: 0.278\n",
      "Training: Epoch 176, Batch 10, Loss: 0.27\n",
      "Training: Epoch 176, Batch 11, Loss: 0.198\n",
      "Training: Epoch 176, Batch 12, Loss: 0.219\n",
      "Training: Epoch 176, Batch 13, Loss: 0.187\n",
      "Training: Epoch 176, Batch 14, Loss: 0.243\n",
      "Training: Epoch 176, Batch 15, Loss: 0.168\n",
      "Training: Epoch 176, Batch 16, Loss: 0.238\n",
      "Training: Epoch 176, Batch 17, Loss: 0.167\n",
      "Training: Epoch 176, Batch 18, Loss: 0.182\n",
      "Training: Epoch 176, Batch 19, Loss: 0.179\n",
      "Val: Epoch 176, Loss: 0.49\n",
      "Training: Epoch 177, Batch 0, Loss: 0.186\n",
      "Training: Epoch 177, Batch 1, Loss: 0.147\n",
      "Training: Epoch 177, Batch 2, Loss: 0.146\n",
      "Training: Epoch 177, Batch 3, Loss: 0.151\n",
      "Training: Epoch 177, Batch 4, Loss: 0.167\n",
      "Training: Epoch 177, Batch 5, Loss: 0.455\n",
      "Training: Epoch 177, Batch 6, Loss: 0.186\n",
      "Training: Epoch 177, Batch 7, Loss: 0.158\n",
      "Training: Epoch 177, Batch 8, Loss: 0.154\n",
      "Training: Epoch 177, Batch 9, Loss: 0.176\n",
      "Training: Epoch 177, Batch 10, Loss: 0.224\n",
      "Training: Epoch 177, Batch 11, Loss: 0.191\n",
      "Training: Epoch 177, Batch 12, Loss: 0.152\n",
      "Training: Epoch 177, Batch 13, Loss: 0.219\n",
      "Training: Epoch 177, Batch 14, Loss: 0.148\n",
      "Training: Epoch 177, Batch 15, Loss: 0.215\n",
      "Training: Epoch 177, Batch 16, Loss: 0.138\n",
      "Training: Epoch 177, Batch 17, Loss: 0.184\n",
      "Training: Epoch 177, Batch 18, Loss: 0.16\n",
      "Training: Epoch 177, Batch 19, Loss: 0.148\n",
      "Val: Epoch 177, Loss: 0.467\n",
      "Training: Epoch 178, Batch 0, Loss: 0.167\n",
      "Training: Epoch 178, Batch 1, Loss: 0.137\n",
      "Training: Epoch 178, Batch 2, Loss: 0.152\n",
      "Training: Epoch 178, Batch 3, Loss: 0.116\n",
      "Training: Epoch 178, Batch 4, Loss: 0.168\n",
      "Training: Epoch 178, Batch 5, Loss: 0.204\n",
      "Training: Epoch 178, Batch 6, Loss: 0.139\n",
      "Training: Epoch 178, Batch 7, Loss: 0.119\n",
      "Training: Epoch 178, Batch 8, Loss: 0.118\n",
      "Training: Epoch 178, Batch 9, Loss: 0.143\n",
      "Training: Epoch 178, Batch 10, Loss: 0.162\n",
      "Training: Epoch 178, Batch 11, Loss: 0.232\n",
      "Training: Epoch 178, Batch 12, Loss: 0.183\n",
      "Training: Epoch 178, Batch 13, Loss: 0.166\n",
      "Training: Epoch 178, Batch 14, Loss: 0.187\n",
      "Training: Epoch 178, Batch 15, Loss: 0.146\n",
      "Training: Epoch 178, Batch 16, Loss: 0.166\n",
      "Training: Epoch 178, Batch 17, Loss: 0.117\n",
      "Training: Epoch 178, Batch 18, Loss: 0.157\n",
      "Training: Epoch 178, Batch 19, Loss: 0.137\n",
      "Val: Epoch 178, Loss: 0.771\n",
      "Training: Epoch 179, Batch 0, Loss: 0.127\n",
      "Training: Epoch 179, Batch 1, Loss: 0.138\n",
      "Training: Epoch 179, Batch 2, Loss: 0.137\n",
      "Training: Epoch 179, Batch 3, Loss: 0.126\n",
      "Training: Epoch 179, Batch 4, Loss: 0.116\n",
      "Training: Epoch 179, Batch 5, Loss: 0.121\n",
      "Training: Epoch 179, Batch 6, Loss: 0.107\n",
      "Training: Epoch 179, Batch 7, Loss: 0.126\n",
      "Training: Epoch 179, Batch 8, Loss: 0.162\n",
      "Training: Epoch 179, Batch 9, Loss: 0.188\n",
      "Training: Epoch 179, Batch 10, Loss: 0.109\n",
      "Training: Epoch 179, Batch 11, Loss: 0.153\n",
      "Training: Epoch 179, Batch 12, Loss: 0.096\n",
      "Training: Epoch 179, Batch 13, Loss: 0.098\n",
      "Training: Epoch 179, Batch 14, Loss: 0.116\n",
      "Training: Epoch 179, Batch 15, Loss: 0.205\n",
      "Training: Epoch 179, Batch 16, Loss: 0.093\n",
      "Training: Epoch 179, Batch 17, Loss: 0.161\n",
      "Training: Epoch 179, Batch 18, Loss: 0.139\n",
      "Training: Epoch 179, Batch 19, Loss: 0.253\n",
      "Val: Epoch 179, Loss: 0.374\n",
      "Training: Epoch 180, Batch 0, Loss: 0.127\n",
      "Training: Epoch 180, Batch 1, Loss: 0.104\n",
      "Training: Epoch 180, Batch 2, Loss: 0.204\n",
      "Training: Epoch 180, Batch 3, Loss: 0.118\n",
      "Training: Epoch 180, Batch 4, Loss: 0.108\n",
      "Training: Epoch 180, Batch 5, Loss: 0.131\n",
      "Training: Epoch 180, Batch 6, Loss: 0.114\n",
      "Training: Epoch 180, Batch 7, Loss: 0.111\n",
      "Training: Epoch 180, Batch 8, Loss: 0.115\n",
      "Training: Epoch 180, Batch 9, Loss: 0.145\n",
      "Training: Epoch 180, Batch 10, Loss: 0.103\n",
      "Training: Epoch 180, Batch 11, Loss: 0.119\n",
      "Training: Epoch 180, Batch 12, Loss: 0.108\n",
      "Training: Epoch 180, Batch 13, Loss: 0.108\n",
      "Training: Epoch 180, Batch 14, Loss: 0.148\n",
      "Training: Epoch 180, Batch 15, Loss: 0.097\n",
      "Training: Epoch 180, Batch 16, Loss: 0.141\n",
      "Training: Epoch 180, Batch 17, Loss: 0.111\n",
      "Training: Epoch 180, Batch 18, Loss: 0.123\n",
      "Training: Epoch 180, Batch 19, Loss: 0.094\n",
      "Val: Epoch 180, Loss: 0.606\n",
      "Training: Epoch 181, Batch 0, Loss: 0.079\n",
      "Training: Epoch 181, Batch 1, Loss: 0.131\n",
      "Training: Epoch 181, Batch 2, Loss: 0.116\n",
      "Training: Epoch 181, Batch 3, Loss: 0.096\n",
      "Training: Epoch 181, Batch 4, Loss: 0.086\n",
      "Training: Epoch 181, Batch 5, Loss: 0.111\n",
      "Training: Epoch 181, Batch 6, Loss: 0.084\n",
      "Training: Epoch 181, Batch 7, Loss: 0.092\n",
      "Training: Epoch 181, Batch 8, Loss: 0.09\n",
      "Training: Epoch 181, Batch 9, Loss: 0.095\n",
      "Training: Epoch 181, Batch 10, Loss: 0.105\n",
      "Training: Epoch 181, Batch 11, Loss: 0.116\n",
      "Training: Epoch 181, Batch 12, Loss: 0.085\n",
      "Training: Epoch 181, Batch 13, Loss: 0.099\n",
      "Training: Epoch 181, Batch 14, Loss: 0.088\n",
      "Training: Epoch 181, Batch 15, Loss: 0.101\n",
      "Training: Epoch 181, Batch 16, Loss: 0.121\n",
      "Training: Epoch 181, Batch 17, Loss: 0.088\n",
      "Training: Epoch 181, Batch 18, Loss: 0.085\n",
      "Training: Epoch 181, Batch 19, Loss: 0.114\n",
      "Val: Epoch 181, Loss: 0.305\n",
      "Training: Epoch 182, Batch 0, Loss: 0.093\n",
      "Training: Epoch 182, Batch 1, Loss: 0.086\n",
      "Training: Epoch 182, Batch 2, Loss: 0.075\n",
      "Training: Epoch 182, Batch 3, Loss: 0.099\n",
      "Training: Epoch 182, Batch 4, Loss: 0.072\n",
      "Training: Epoch 182, Batch 5, Loss: 0.081\n",
      "Training: Epoch 182, Batch 6, Loss: 0.086\n",
      "Training: Epoch 182, Batch 7, Loss: 0.083\n",
      "Training: Epoch 182, Batch 8, Loss: 0.082\n",
      "Training: Epoch 182, Batch 9, Loss: 0.074\n",
      "Training: Epoch 182, Batch 10, Loss: 0.091\n",
      "Training: Epoch 182, Batch 11, Loss: 0.101\n",
      "Training: Epoch 182, Batch 12, Loss: 0.078\n",
      "Training: Epoch 182, Batch 13, Loss: 0.081\n",
      "Training: Epoch 182, Batch 14, Loss: 0.082\n",
      "Training: Epoch 182, Batch 15, Loss: 0.1\n",
      "Training: Epoch 182, Batch 16, Loss: 0.07\n",
      "Training: Epoch 182, Batch 17, Loss: 0.077\n",
      "Training: Epoch 182, Batch 18, Loss: 0.096\n",
      "Training: Epoch 182, Batch 19, Loss: 0.09\n",
      "Val: Epoch 182, Loss: 0.314\n",
      "Training: Epoch 183, Batch 0, Loss: 0.08\n",
      "Training: Epoch 183, Batch 1, Loss: 0.078\n",
      "Training: Epoch 183, Batch 2, Loss: 0.064\n",
      "Training: Epoch 183, Batch 3, Loss: 0.086\n",
      "Training: Epoch 183, Batch 4, Loss: 0.064\n",
      "Training: Epoch 183, Batch 5, Loss: 0.065\n",
      "Training: Epoch 183, Batch 6, Loss: 0.062\n",
      "Training: Epoch 183, Batch 7, Loss: 0.083\n",
      "Training: Epoch 183, Batch 8, Loss: 0.07\n",
      "Training: Epoch 183, Batch 9, Loss: 0.071\n",
      "Training: Epoch 183, Batch 10, Loss: 0.076\n",
      "Training: Epoch 183, Batch 11, Loss: 0.073\n",
      "Training: Epoch 183, Batch 12, Loss: 0.056\n",
      "Training: Epoch 183, Batch 13, Loss: 0.09\n",
      "Training: Epoch 183, Batch 14, Loss: 0.068\n",
      "Training: Epoch 183, Batch 15, Loss: 0.069\n",
      "Training: Epoch 183, Batch 16, Loss: 0.065\n",
      "Training: Epoch 183, Batch 17, Loss: 0.061\n",
      "Training: Epoch 183, Batch 18, Loss: 0.065\n",
      "Training: Epoch 183, Batch 19, Loss: 0.08\n",
      "Val: Epoch 183, Loss: 0.312\n",
      "Training: Epoch 184, Batch 0, Loss: 0.057\n",
      "Training: Epoch 184, Batch 1, Loss: 0.068\n",
      "Training: Epoch 184, Batch 2, Loss: 0.069\n",
      "Training: Epoch 184, Batch 3, Loss: 0.069\n",
      "Training: Epoch 184, Batch 4, Loss: 0.057\n",
      "Training: Epoch 184, Batch 5, Loss: 0.06\n",
      "Training: Epoch 184, Batch 6, Loss: 0.077\n",
      "Training: Epoch 184, Batch 7, Loss: 0.06\n",
      "Training: Epoch 184, Batch 8, Loss: 0.06\n",
      "Training: Epoch 184, Batch 9, Loss: 0.06\n",
      "Training: Epoch 184, Batch 10, Loss: 0.067\n",
      "Training: Epoch 184, Batch 11, Loss: 0.088\n",
      "Training: Epoch 184, Batch 12, Loss: 0.077\n",
      "Training: Epoch 184, Batch 13, Loss: 0.069\n",
      "Training: Epoch 184, Batch 14, Loss: 0.056\n",
      "Training: Epoch 184, Batch 15, Loss: 0.077\n",
      "Training: Epoch 184, Batch 16, Loss: 0.064\n",
      "Training: Epoch 184, Batch 17, Loss: 0.066\n",
      "Training: Epoch 184, Batch 18, Loss: 0.071\n",
      "Training: Epoch 184, Batch 19, Loss: 0.058\n",
      "Val: Epoch 184, Loss: 1.181\n",
      "Training: Epoch 185, Batch 0, Loss: 0.066\n",
      "Training: Epoch 185, Batch 1, Loss: 0.062\n",
      "Training: Epoch 185, Batch 2, Loss: 0.062\n",
      "Training: Epoch 185, Batch 3, Loss: 0.078\n",
      "Training: Epoch 185, Batch 4, Loss: 0.058\n",
      "Training: Epoch 185, Batch 5, Loss: 0.055\n",
      "Training: Epoch 185, Batch 6, Loss: 0.052\n",
      "Training: Epoch 185, Batch 7, Loss: 0.059\n",
      "Training: Epoch 185, Batch 8, Loss: 0.061\n",
      "Training: Epoch 185, Batch 9, Loss: 0.072\n",
      "Training: Epoch 185, Batch 10, Loss: 0.056\n",
      "Training: Epoch 185, Batch 11, Loss: 0.057\n",
      "Training: Epoch 185, Batch 12, Loss: 0.074\n",
      "Training: Epoch 185, Batch 13, Loss: 0.067\n",
      "Training: Epoch 185, Batch 14, Loss: 0.06\n",
      "Training: Epoch 185, Batch 15, Loss: 0.068\n",
      "Training: Epoch 185, Batch 16, Loss: 0.049\n",
      "Training: Epoch 185, Batch 17, Loss: 0.056\n",
      "Training: Epoch 185, Batch 18, Loss: 0.07\n",
      "Training: Epoch 185, Batch 19, Loss: 0.063\n",
      "Val: Epoch 185, Loss: 0.744\n",
      "Training: Epoch 186, Batch 0, Loss: 0.05\n",
      "Training: Epoch 186, Batch 1, Loss: 0.059\n",
      "Training: Epoch 186, Batch 2, Loss: 0.058\n",
      "Training: Epoch 186, Batch 3, Loss: 0.071\n",
      "Training: Epoch 186, Batch 4, Loss: 0.056\n",
      "Training: Epoch 186, Batch 5, Loss: 0.054\n",
      "Training: Epoch 186, Batch 6, Loss: 0.057\n",
      "Training: Epoch 186, Batch 7, Loss: 0.042\n",
      "Training: Epoch 186, Batch 8, Loss: 0.052\n",
      "Training: Epoch 186, Batch 9, Loss: 0.057\n",
      "Training: Epoch 186, Batch 10, Loss: 0.05\n",
      "Training: Epoch 186, Batch 11, Loss: 0.073\n",
      "Training: Epoch 186, Batch 12, Loss: 0.054\n",
      "Training: Epoch 186, Batch 13, Loss: 0.064\n",
      "Training: Epoch 186, Batch 14, Loss: 0.08\n",
      "Training: Epoch 186, Batch 15, Loss: 0.054\n",
      "Training: Epoch 186, Batch 16, Loss: 0.054\n",
      "Training: Epoch 186, Batch 17, Loss: 0.051\n",
      "Training: Epoch 186, Batch 18, Loss: 0.054\n",
      "Training: Epoch 186, Batch 19, Loss: 0.052\n",
      "Val: Epoch 186, Loss: 0.321\n",
      "Training: Epoch 187, Batch 0, Loss: 0.047\n",
      "Training: Epoch 187, Batch 1, Loss: 0.05\n",
      "Training: Epoch 187, Batch 2, Loss: 0.05\n",
      "Training: Epoch 187, Batch 3, Loss: 0.057\n",
      "Training: Epoch 187, Batch 4, Loss: 0.053\n",
      "Training: Epoch 187, Batch 5, Loss: 0.053\n",
      "Training: Epoch 187, Batch 6, Loss: 0.046\n",
      "Training: Epoch 187, Batch 7, Loss: 0.047\n",
      "Training: Epoch 187, Batch 8, Loss: 0.09\n",
      "Training: Epoch 187, Batch 9, Loss: 0.045\n",
      "Training: Epoch 187, Batch 10, Loss: 0.068\n",
      "Training: Epoch 187, Batch 11, Loss: 0.06\n",
      "Training: Epoch 187, Batch 12, Loss: 0.078\n",
      "Training: Epoch 187, Batch 13, Loss: 0.063\n",
      "Training: Epoch 187, Batch 14, Loss: 0.062\n",
      "Training: Epoch 187, Batch 15, Loss: 0.061\n",
      "Training: Epoch 187, Batch 16, Loss: 0.065\n",
      "Training: Epoch 187, Batch 17, Loss: 0.053\n",
      "Training: Epoch 187, Batch 18, Loss: 0.07\n",
      "Training: Epoch 187, Batch 19, Loss: 0.062\n",
      "Val: Epoch 187, Loss: 0.394\n",
      "Training: Epoch 188, Batch 0, Loss: 0.069\n",
      "Training: Epoch 188, Batch 1, Loss: 0.053\n",
      "Training: Epoch 188, Batch 2, Loss: 0.047\n",
      "Training: Epoch 188, Batch 3, Loss: 0.051\n",
      "Training: Epoch 188, Batch 4, Loss: 0.13\n",
      "Training: Epoch 188, Batch 5, Loss: 0.058\n",
      "Training: Epoch 188, Batch 6, Loss: 0.072\n",
      "Training: Epoch 188, Batch 7, Loss: 0.058\n",
      "Training: Epoch 188, Batch 8, Loss: 0.059\n",
      "Training: Epoch 188, Batch 9, Loss: 0.052\n",
      "Training: Epoch 188, Batch 10, Loss: 0.073\n",
      "Training: Epoch 188, Batch 11, Loss: 0.062\n",
      "Training: Epoch 188, Batch 12, Loss: 0.066\n",
      "Training: Epoch 188, Batch 13, Loss: 0.082\n",
      "Training: Epoch 188, Batch 14, Loss: 0.071\n",
      "Training: Epoch 188, Batch 15, Loss: 0.058\n",
      "Training: Epoch 188, Batch 16, Loss: 0.084\n",
      "Training: Epoch 188, Batch 17, Loss: 0.06\n",
      "Training: Epoch 188, Batch 18, Loss: 0.064\n",
      "Training: Epoch 188, Batch 19, Loss: 0.068\n",
      "Val: Epoch 188, Loss: 0.441\n",
      "Training: Epoch 189, Batch 0, Loss: 0.064\n",
      "Training: Epoch 189, Batch 1, Loss: 0.059\n",
      "Training: Epoch 189, Batch 2, Loss: 0.061\n",
      "Training: Epoch 189, Batch 3, Loss: 0.064\n",
      "Training: Epoch 189, Batch 4, Loss: 0.058\n",
      "Training: Epoch 189, Batch 5, Loss: 0.06\n",
      "Training: Epoch 189, Batch 6, Loss: 0.06\n",
      "Training: Epoch 189, Batch 7, Loss: 0.055\n",
      "Training: Epoch 189, Batch 8, Loss: 0.058\n",
      "Training: Epoch 189, Batch 9, Loss: 0.063\n",
      "Training: Epoch 189, Batch 10, Loss: 0.045\n",
      "Training: Epoch 189, Batch 11, Loss: 0.063\n",
      "Training: Epoch 189, Batch 12, Loss: 0.06\n",
      "Training: Epoch 189, Batch 13, Loss: 0.065\n",
      "Training: Epoch 189, Batch 14, Loss: 0.059\n",
      "Training: Epoch 189, Batch 15, Loss: 0.054\n",
      "Training: Epoch 189, Batch 16, Loss: 0.051\n",
      "Training: Epoch 189, Batch 17, Loss: 0.06\n",
      "Training: Epoch 189, Batch 18, Loss: 0.072\n",
      "Training: Epoch 189, Batch 19, Loss: 0.067\n",
      "Val: Epoch 189, Loss: 0.332\n",
      "Training: Epoch 190, Batch 0, Loss: 0.049\n",
      "Training: Epoch 190, Batch 1, Loss: 0.047\n",
      "Training: Epoch 190, Batch 2, Loss: 0.057\n",
      "Training: Epoch 190, Batch 3, Loss: 0.063\n",
      "Training: Epoch 190, Batch 4, Loss: 0.043\n",
      "Training: Epoch 190, Batch 5, Loss: 0.05\n",
      "Training: Epoch 190, Batch 6, Loss: 0.069\n",
      "Training: Epoch 190, Batch 7, Loss: 0.038\n",
      "Training: Epoch 190, Batch 8, Loss: 0.045\n",
      "Training: Epoch 190, Batch 9, Loss: 0.058\n",
      "Training: Epoch 190, Batch 10, Loss: 0.058\n",
      "Training: Epoch 190, Batch 11, Loss: 0.052\n",
      "Training: Epoch 190, Batch 12, Loss: 0.055\n",
      "Training: Epoch 190, Batch 13, Loss: 0.061\n",
      "Training: Epoch 190, Batch 14, Loss: 0.047\n",
      "Training: Epoch 190, Batch 15, Loss: 0.055\n",
      "Training: Epoch 190, Batch 16, Loss: 0.041\n",
      "Training: Epoch 190, Batch 17, Loss: 0.058\n",
      "Training: Epoch 190, Batch 18, Loss: 0.05\n",
      "Training: Epoch 190, Batch 19, Loss: 0.039\n",
      "Val: Epoch 190, Loss: 0.64\n",
      "Training: Epoch 191, Batch 0, Loss: 0.053\n",
      "Training: Epoch 191, Batch 1, Loss: 0.04\n",
      "Training: Epoch 191, Batch 2, Loss: 0.043\n",
      "Training: Epoch 191, Batch 3, Loss: 0.046\n",
      "Training: Epoch 191, Batch 4, Loss: 0.044\n",
      "Training: Epoch 191, Batch 5, Loss: 0.044\n",
      "Training: Epoch 191, Batch 6, Loss: 0.049\n",
      "Training: Epoch 191, Batch 7, Loss: 0.042\n",
      "Training: Epoch 191, Batch 8, Loss: 0.044\n",
      "Training: Epoch 191, Batch 9, Loss: 0.065\n",
      "Training: Epoch 191, Batch 10, Loss: 0.038\n",
      "Training: Epoch 191, Batch 11, Loss: 0.034\n",
      "Training: Epoch 191, Batch 12, Loss: 0.054\n",
      "Training: Epoch 191, Batch 13, Loss: 0.046\n",
      "Training: Epoch 191, Batch 14, Loss: 0.043\n",
      "Training: Epoch 191, Batch 15, Loss: 0.038\n",
      "Training: Epoch 191, Batch 16, Loss: 0.047\n",
      "Training: Epoch 191, Batch 17, Loss: 0.044\n",
      "Training: Epoch 191, Batch 18, Loss: 0.04\n",
      "Training: Epoch 191, Batch 19, Loss: 0.049\n",
      "Val: Epoch 191, Loss: 0.351\n",
      "Training: Epoch 192, Batch 0, Loss: 0.045\n",
      "Training: Epoch 192, Batch 1, Loss: 0.038\n",
      "Training: Epoch 192, Batch 2, Loss: 0.048\n",
      "Training: Epoch 192, Batch 3, Loss: 0.037\n",
      "Training: Epoch 192, Batch 4, Loss: 0.046\n",
      "Training: Epoch 192, Batch 5, Loss: 0.043\n",
      "Training: Epoch 192, Batch 6, Loss: 0.046\n",
      "Training: Epoch 192, Batch 7, Loss: 0.034\n",
      "Training: Epoch 192, Batch 8, Loss: 0.034\n",
      "Training: Epoch 192, Batch 9, Loss: 0.039\n",
      "Training: Epoch 192, Batch 10, Loss: 0.037\n",
      "Training: Epoch 192, Batch 11, Loss: 0.04\n",
      "Training: Epoch 192, Batch 12, Loss: 0.043\n",
      "Training: Epoch 192, Batch 13, Loss: 0.038\n",
      "Training: Epoch 192, Batch 14, Loss: 0.038\n",
      "Training: Epoch 192, Batch 15, Loss: 0.047\n",
      "Training: Epoch 192, Batch 16, Loss: 0.039\n",
      "Training: Epoch 192, Batch 17, Loss: 0.032\n",
      "Training: Epoch 192, Batch 18, Loss: 0.039\n",
      "Training: Epoch 192, Batch 19, Loss: 0.042\n",
      "Val: Epoch 192, Loss: 0.356\n",
      "Training: Epoch 193, Batch 0, Loss: 0.042\n",
      "Training: Epoch 193, Batch 1, Loss: 0.038\n",
      "Training: Epoch 193, Batch 2, Loss: 0.034\n",
      "Training: Epoch 193, Batch 3, Loss: 0.047\n",
      "Training: Epoch 193, Batch 4, Loss: 0.036\n",
      "Training: Epoch 193, Batch 5, Loss: 0.038\n",
      "Training: Epoch 193, Batch 6, Loss: 0.043\n",
      "Training: Epoch 193, Batch 7, Loss: 0.038\n",
      "Training: Epoch 193, Batch 8, Loss: 0.041\n",
      "Training: Epoch 193, Batch 9, Loss: 0.035\n",
      "Training: Epoch 193, Batch 10, Loss: 0.045\n",
      "Training: Epoch 193, Batch 11, Loss: 0.034\n",
      "Training: Epoch 193, Batch 12, Loss: 0.042\n",
      "Training: Epoch 193, Batch 13, Loss: 0.037\n",
      "Training: Epoch 193, Batch 14, Loss: 0.036\n",
      "Training: Epoch 193, Batch 15, Loss: 0.037\n",
      "Training: Epoch 193, Batch 16, Loss: 0.035\n",
      "Training: Epoch 193, Batch 17, Loss: 0.032\n",
      "Training: Epoch 193, Batch 18, Loss: 0.03\n",
      "Training: Epoch 193, Batch 19, Loss: 0.036\n",
      "Val: Epoch 193, Loss: 0.363\n",
      "Training: Epoch 194, Batch 0, Loss: 0.036\n",
      "Training: Epoch 194, Batch 1, Loss: 0.036\n",
      "Training: Epoch 194, Batch 2, Loss: 0.033\n",
      "Training: Epoch 194, Batch 3, Loss: 0.033\n",
      "Training: Epoch 194, Batch 4, Loss: 0.044\n",
      "Training: Epoch 194, Batch 5, Loss: 0.042\n",
      "Training: Epoch 194, Batch 6, Loss: 0.031\n",
      "Training: Epoch 194, Batch 7, Loss: 0.031\n",
      "Training: Epoch 194, Batch 8, Loss: 0.035\n",
      "Training: Epoch 194, Batch 9, Loss: 0.033\n",
      "Training: Epoch 194, Batch 10, Loss: 0.036\n",
      "Training: Epoch 194, Batch 11, Loss: 0.031\n",
      "Training: Epoch 194, Batch 12, Loss: 0.04\n",
      "Training: Epoch 194, Batch 13, Loss: 0.035\n",
      "Training: Epoch 194, Batch 14, Loss: 0.038\n",
      "Training: Epoch 194, Batch 15, Loss: 0.038\n",
      "Training: Epoch 194, Batch 16, Loss: 0.036\n",
      "Training: Epoch 194, Batch 17, Loss: 0.033\n",
      "Training: Epoch 194, Batch 18, Loss: 0.045\n",
      "Training: Epoch 194, Batch 19, Loss: 0.033\n",
      "Val: Epoch 194, Loss: 0.404\n",
      "Training: Epoch 195, Batch 0, Loss: 0.034\n",
      "Training: Epoch 195, Batch 1, Loss: 0.046\n",
      "Training: Epoch 195, Batch 2, Loss: 0.033\n",
      "Training: Epoch 195, Batch 3, Loss: 0.03\n",
      "Training: Epoch 195, Batch 4, Loss: 0.037\n",
      "Training: Epoch 195, Batch 5, Loss: 0.032\n",
      "Training: Epoch 195, Batch 6, Loss: 0.034\n",
      "Training: Epoch 195, Batch 7, Loss: 0.03\n",
      "Training: Epoch 195, Batch 8, Loss: 0.035\n",
      "Training: Epoch 195, Batch 9, Loss: 0.04\n",
      "Training: Epoch 195, Batch 10, Loss: 0.038\n",
      "Training: Epoch 195, Batch 11, Loss: 0.031\n",
      "Training: Epoch 195, Batch 12, Loss: 0.035\n",
      "Training: Epoch 195, Batch 13, Loss: 0.039\n",
      "Training: Epoch 195, Batch 14, Loss: 0.035\n",
      "Training: Epoch 195, Batch 15, Loss: 0.04\n",
      "Training: Epoch 195, Batch 16, Loss: 0.029\n",
      "Training: Epoch 195, Batch 17, Loss: 0.032\n",
      "Training: Epoch 195, Batch 18, Loss: 0.034\n",
      "Training: Epoch 195, Batch 19, Loss: 0.036\n",
      "Val: Epoch 195, Loss: 0.398\n",
      "Training: Epoch 196, Batch 0, Loss: 0.038\n",
      "Training: Epoch 196, Batch 1, Loss: 0.034\n",
      "Training: Epoch 196, Batch 2, Loss: 0.03\n",
      "Training: Epoch 196, Batch 3, Loss: 0.03\n",
      "Training: Epoch 196, Batch 4, Loss: 0.034\n",
      "Training: Epoch 196, Batch 5, Loss: 0.034\n",
      "Training: Epoch 196, Batch 6, Loss: 0.032\n",
      "Training: Epoch 196, Batch 7, Loss: 0.031\n",
      "Training: Epoch 196, Batch 8, Loss: 0.03\n",
      "Training: Epoch 196, Batch 9, Loss: 0.027\n",
      "Training: Epoch 196, Batch 10, Loss: 0.035\n",
      "Training: Epoch 196, Batch 11, Loss: 0.031\n",
      "Training: Epoch 196, Batch 12, Loss: 0.037\n",
      "Training: Epoch 196, Batch 13, Loss: 0.032\n",
      "Training: Epoch 196, Batch 14, Loss: 0.038\n",
      "Training: Epoch 196, Batch 15, Loss: 0.036\n",
      "Training: Epoch 196, Batch 16, Loss: 0.035\n",
      "Training: Epoch 196, Batch 17, Loss: 0.03\n",
      "Training: Epoch 196, Batch 18, Loss: 0.031\n",
      "Training: Epoch 196, Batch 19, Loss: 0.032\n",
      "Val: Epoch 196, Loss: 0.418\n",
      "Training: Epoch 197, Batch 0, Loss: 0.039\n",
      "Training: Epoch 197, Batch 1, Loss: 0.029\n",
      "Training: Epoch 197, Batch 2, Loss: 0.027\n",
      "Training: Epoch 197, Batch 3, Loss: 0.023\n",
      "Training: Epoch 197, Batch 4, Loss: 0.036\n",
      "Training: Epoch 197, Batch 5, Loss: 0.03\n",
      "Training: Epoch 197, Batch 6, Loss: 0.03\n",
      "Training: Epoch 197, Batch 7, Loss: 0.03\n",
      "Training: Epoch 197, Batch 8, Loss: 0.031\n",
      "Training: Epoch 197, Batch 9, Loss: 0.029\n",
      "Training: Epoch 197, Batch 10, Loss: 0.029\n",
      "Training: Epoch 197, Batch 11, Loss: 0.029\n",
      "Training: Epoch 197, Batch 12, Loss: 0.033\n",
      "Training: Epoch 197, Batch 13, Loss: 0.031\n",
      "Training: Epoch 197, Batch 14, Loss: 0.034\n",
      "Training: Epoch 197, Batch 15, Loss: 0.028\n",
      "Training: Epoch 197, Batch 16, Loss: 0.032\n",
      "Training: Epoch 197, Batch 17, Loss: 0.03\n",
      "Training: Epoch 197, Batch 18, Loss: 0.031\n",
      "Training: Epoch 197, Batch 19, Loss: 0.024\n",
      "Val: Epoch 197, Loss: 0.4\n",
      "Training: Epoch 198, Batch 0, Loss: 0.033\n",
      "Training: Epoch 198, Batch 1, Loss: 0.027\n",
      "Training: Epoch 198, Batch 2, Loss: 0.023\n",
      "Training: Epoch 198, Batch 3, Loss: 0.023\n",
      "Training: Epoch 198, Batch 4, Loss: 0.026\n",
      "Training: Epoch 198, Batch 5, Loss: 0.029\n",
      "Training: Epoch 198, Batch 6, Loss: 0.035\n",
      "Training: Epoch 198, Batch 7, Loss: 0.025\n",
      "Training: Epoch 198, Batch 8, Loss: 0.026\n",
      "Training: Epoch 198, Batch 9, Loss: 0.026\n",
      "Training: Epoch 198, Batch 10, Loss: 0.027\n",
      "Training: Epoch 198, Batch 11, Loss: 0.033\n",
      "Training: Epoch 198, Batch 12, Loss: 0.046\n",
      "Training: Epoch 198, Batch 13, Loss: 0.031\n",
      "Training: Epoch 198, Batch 14, Loss: 0.034\n",
      "Training: Epoch 198, Batch 15, Loss: 0.035\n",
      "Training: Epoch 198, Batch 16, Loss: 0.033\n",
      "Training: Epoch 198, Batch 17, Loss: 0.034\n",
      "Training: Epoch 198, Batch 18, Loss: 0.031\n",
      "Training: Epoch 198, Batch 19, Loss: 0.032\n",
      "Val: Epoch 198, Loss: 0.436\n",
      "Training: Epoch 199, Batch 0, Loss: 0.028\n",
      "Training: Epoch 199, Batch 1, Loss: 0.03\n",
      "Training: Epoch 199, Batch 2, Loss: 0.033\n",
      "Training: Epoch 199, Batch 3, Loss: 0.031\n",
      "Training: Epoch 199, Batch 4, Loss: 0.025\n",
      "Training: Epoch 199, Batch 5, Loss: 0.027\n",
      "Training: Epoch 199, Batch 6, Loss: 0.028\n",
      "Training: Epoch 199, Batch 7, Loss: 0.029\n",
      "Training: Epoch 199, Batch 8, Loss: 0.025\n",
      "Training: Epoch 199, Batch 9, Loss: 0.033\n",
      "Training: Epoch 199, Batch 10, Loss: 0.026\n",
      "Training: Epoch 199, Batch 11, Loss: 0.049\n",
      "Training: Epoch 199, Batch 12, Loss: 0.034\n",
      "Training: Epoch 199, Batch 13, Loss: 0.03\n",
      "Training: Epoch 199, Batch 14, Loss: 0.028\n",
      "Training: Epoch 199, Batch 15, Loss: 0.029\n",
      "Training: Epoch 199, Batch 16, Loss: 0.031\n",
      "Training: Epoch 199, Batch 17, Loss: 0.033\n",
      "Training: Epoch 199, Batch 18, Loss: 0.03\n",
      "Training: Epoch 199, Batch 19, Loss: 0.025\n",
      "Val: Epoch 199, Loss: 0.452\n",
      "Training: Epoch 200, Batch 0, Loss: 0.034\n",
      "Training: Epoch 200, Batch 1, Loss: 0.033\n",
      "Training: Epoch 200, Batch 2, Loss: 0.027\n",
      "Training: Epoch 200, Batch 3, Loss: 0.026\n",
      "Training: Epoch 200, Batch 4, Loss: 0.032\n",
      "Training: Epoch 200, Batch 5, Loss: 0.027\n",
      "Training: Epoch 200, Batch 6, Loss: 0.029\n",
      "Training: Epoch 200, Batch 7, Loss: 0.026\n",
      "Training: Epoch 200, Batch 8, Loss: 0.029\n",
      "Training: Epoch 200, Batch 9, Loss: 0.027\n",
      "Training: Epoch 200, Batch 10, Loss: 0.029\n",
      "Training: Epoch 200, Batch 11, Loss: 0.032\n",
      "Training: Epoch 200, Batch 12, Loss: 0.028\n",
      "Training: Epoch 200, Batch 13, Loss: 0.028\n",
      "Training: Epoch 200, Batch 14, Loss: 0.033\n",
      "Training: Epoch 200, Batch 15, Loss: 0.027\n",
      "Training: Epoch 200, Batch 16, Loss: 0.026\n",
      "Training: Epoch 200, Batch 17, Loss: 0.032\n",
      "Training: Epoch 200, Batch 18, Loss: 0.032\n",
      "Training: Epoch 200, Batch 19, Loss: 0.034\n",
      "Val: Epoch 200, Loss: 0.412\n",
      "Best model found at epoch 14\n",
      "Total training time: 272.0974700450897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:293: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[-1],map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models/bestunet_model.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96    937035\n",
      "           1       0.94      0.81      0.87   1187442\n",
      "           2       0.74      0.90      0.81    496963\n",
      "\n",
      "    accuracy                           0.89   2621440\n",
      "   macro avg       0.87      0.90      0.88   2621440\n",
      "weighted avg       0.90      0.89      0.89   2621440\n",
      "\n",
      "Training loss: 0.2769550234079361\n",
      "AUROC: 0.9773081837856911\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from semseg_functions import train_model,make_predictions\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "model, best_model_loss=train_model(X_train,Y_train,X_val,Y_val)\n",
    "end_time = time.time()\n",
    "print(\"Total training time:\", end_time-start_time)\n",
    "y_val_pred=make_predictions(X_val,model=None)\n",
    "y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "print(\"Val loss:\", best_model_loss)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Flatten prediction: shape (B, C, H, W) to (N, C)\n",
    "y_val_pred_flat = y_val_pred.transpose(0, 2, 3, 1).reshape(-1, y_val_pred.shape[1])\n",
    "\n",
    "# Flatten true labels: shape (B, H, W) to (N,)\n",
    "y_true = Y_val.numpy().flatten()\n",
    "\n",
    "# Binarize true labels for multiclass AUROC\n",
    "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(y_true_binarized, y_val_pred_flat, multi_class='ovr')\n",
    "\n",
    "print(\"AUROC:\", auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "319283b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([160, 3, 256, 256])\n",
      "Y_train shape: torch.Size([160, 256, 256])\n",
      "Using device: cuda\n",
      "Training: Epoch 1, Batch 0, Loss: 1.109\n",
      "Training: Epoch 1, Batch 1, Loss: 1.107\n",
      "Training: Epoch 1, Batch 2, Loss: 1.106\n",
      "Training: Epoch 1, Batch 3, Loss: 1.102\n",
      "Training: Epoch 1, Batch 4, Loss: 1.099\n",
      "Training: Epoch 1, Batch 5, Loss: 1.103\n",
      "Training: Epoch 1, Batch 6, Loss: 1.093\n",
      "Training: Epoch 1, Batch 7, Loss: 1.097\n",
      "Training: Epoch 1, Batch 8, Loss: 1.092\n",
      "Training: Epoch 1, Batch 9, Loss: 1.085\n",
      "Training: Epoch 1, Batch 10, Loss: 1.087\n",
      "Training: Epoch 1, Batch 11, Loss: 1.085\n",
      "Training: Epoch 1, Batch 12, Loss: 1.078\n",
      "Training: Epoch 1, Batch 13, Loss: 1.077\n",
      "Training: Epoch 1, Batch 14, Loss: 1.068\n",
      "Training: Epoch 1, Batch 15, Loss: 1.073\n",
      "Training: Epoch 1, Batch 16, Loss: 1.069\n",
      "Training: Epoch 1, Batch 17, Loss: 1.064\n",
      "Training: Epoch 1, Batch 18, Loss: 1.055\n",
      "Training: Epoch 1, Batch 19, Loss: 1.057\n",
      "Val: Epoch 1, Loss: 1.074\n",
      "Training: Epoch 2, Batch 0, Loss: 1.059\n",
      "Training: Epoch 2, Batch 1, Loss: 1.047\n",
      "Training: Epoch 2, Batch 2, Loss: 1.04\n",
      "Training: Epoch 2, Batch 3, Loss: 1.037\n",
      "Training: Epoch 2, Batch 4, Loss: 1.04\n",
      "Training: Epoch 2, Batch 5, Loss: 1.028\n",
      "Training: Epoch 2, Batch 6, Loss: 1.022\n",
      "Training: Epoch 2, Batch 7, Loss: 1.011\n",
      "Training: Epoch 2, Batch 8, Loss: 1.013\n",
      "Training: Epoch 2, Batch 9, Loss: 1.007\n",
      "Training: Epoch 2, Batch 10, Loss: 0.995\n",
      "Training: Epoch 2, Batch 11, Loss: 0.995\n",
      "Training: Epoch 2, Batch 12, Loss: 0.99\n",
      "Training: Epoch 2, Batch 13, Loss: 0.95\n",
      "Training: Epoch 2, Batch 14, Loss: 0.951\n",
      "Training: Epoch 2, Batch 15, Loss: 0.936\n",
      "Training: Epoch 2, Batch 16, Loss: 0.931\n",
      "Training: Epoch 2, Batch 17, Loss: 0.923\n",
      "Training: Epoch 2, Batch 18, Loss: 0.898\n",
      "Training: Epoch 2, Batch 19, Loss: 0.903\n",
      "Val: Epoch 2, Loss: 0.908\n",
      "Training: Epoch 3, Batch 0, Loss: 0.905\n",
      "Training: Epoch 3, Batch 1, Loss: 0.849\n",
      "Training: Epoch 3, Batch 2, Loss: 0.823\n",
      "Training: Epoch 3, Batch 3, Loss: 0.846\n",
      "Training: Epoch 3, Batch 4, Loss: 0.815\n",
      "Training: Epoch 3, Batch 5, Loss: 0.792\n",
      "Training: Epoch 3, Batch 6, Loss: 0.758\n",
      "Training: Epoch 3, Batch 7, Loss: 0.727\n",
      "Training: Epoch 3, Batch 8, Loss: 0.718\n",
      "Training: Epoch 3, Batch 9, Loss: 0.731\n",
      "Training: Epoch 3, Batch 10, Loss: 0.697\n",
      "Training: Epoch 3, Batch 11, Loss: 0.717\n",
      "Training: Epoch 3, Batch 12, Loss: 0.606\n",
      "Training: Epoch 3, Batch 13, Loss: 0.624\n",
      "Training: Epoch 3, Batch 14, Loss: 0.588\n",
      "Training: Epoch 3, Batch 15, Loss: 0.598\n",
      "Training: Epoch 3, Batch 16, Loss: 0.576\n",
      "Training: Epoch 3, Batch 17, Loss: 0.542\n",
      "Training: Epoch 3, Batch 18, Loss: 0.545\n",
      "Training: Epoch 3, Batch 19, Loss: 0.51\n",
      "Val: Epoch 3, Loss: 0.514\n",
      "Training: Epoch 4, Batch 0, Loss: 0.565\n",
      "Training: Epoch 4, Batch 1, Loss: 0.447\n",
      "Training: Epoch 4, Batch 2, Loss: 0.478\n",
      "Training: Epoch 4, Batch 3, Loss: 0.447\n",
      "Training: Epoch 4, Batch 4, Loss: 0.439\n",
      "Training: Epoch 4, Batch 5, Loss: 0.413\n",
      "Training: Epoch 4, Batch 6, Loss: 0.43\n",
      "Training: Epoch 4, Batch 7, Loss: 0.43\n",
      "Training: Epoch 4, Batch 8, Loss: 0.455\n",
      "Training: Epoch 4, Batch 9, Loss: 0.387\n",
      "Training: Epoch 4, Batch 10, Loss: 0.481\n",
      "Training: Epoch 4, Batch 11, Loss: 0.405\n",
      "Training: Epoch 4, Batch 12, Loss: 0.394\n",
      "Training: Epoch 4, Batch 13, Loss: 0.339\n",
      "Training: Epoch 4, Batch 14, Loss: 0.52\n",
      "Training: Epoch 4, Batch 15, Loss: 0.5\n",
      "Training: Epoch 4, Batch 16, Loss: 0.344\n",
      "Training: Epoch 4, Batch 17, Loss: 0.413\n",
      "Training: Epoch 4, Batch 18, Loss: 0.306\n",
      "Training: Epoch 4, Batch 19, Loss: 0.454\n",
      "Val: Epoch 4, Loss: 0.381\n",
      "Training: Epoch 5, Batch 0, Loss: 0.315\n",
      "Training: Epoch 5, Batch 1, Loss: 0.349\n",
      "Training: Epoch 5, Batch 2, Loss: 0.433\n",
      "Training: Epoch 5, Batch 3, Loss: 0.427\n",
      "Training: Epoch 5, Batch 4, Loss: 0.281\n",
      "Training: Epoch 5, Batch 5, Loss: 0.334\n",
      "Training: Epoch 5, Batch 6, Loss: 0.261\n",
      "Training: Epoch 5, Batch 7, Loss: 0.39\n",
      "Training: Epoch 5, Batch 8, Loss: 0.374\n",
      "Training: Epoch 5, Batch 9, Loss: 0.334\n",
      "Training: Epoch 5, Batch 10, Loss: 0.453\n",
      "Training: Epoch 5, Batch 11, Loss: 0.616\n",
      "Training: Epoch 5, Batch 12, Loss: 0.479\n",
      "Training: Epoch 5, Batch 13, Loss: 0.332\n",
      "Training: Epoch 5, Batch 14, Loss: 0.449\n",
      "Training: Epoch 5, Batch 15, Loss: 0.923\n",
      "Training: Epoch 5, Batch 16, Loss: 0.432\n",
      "Training: Epoch 5, Batch 17, Loss: 0.548\n",
      "Training: Epoch 5, Batch 18, Loss: 0.54\n",
      "Training: Epoch 5, Batch 19, Loss: 0.515\n",
      "Val: Epoch 5, Loss: 0.512\n",
      "Training: Epoch 6, Batch 0, Loss: 0.418\n",
      "Training: Epoch 6, Batch 1, Loss: 0.425\n",
      "Training: Epoch 6, Batch 2, Loss: 0.35\n",
      "Training: Epoch 6, Batch 3, Loss: 0.423\n",
      "Training: Epoch 6, Batch 4, Loss: 0.403\n",
      "Training: Epoch 6, Batch 5, Loss: 0.424\n",
      "Training: Epoch 6, Batch 6, Loss: 0.407\n",
      "Training: Epoch 6, Batch 7, Loss: 0.406\n",
      "Training: Epoch 6, Batch 8, Loss: 0.435\n",
      "Training: Epoch 6, Batch 9, Loss: 0.404\n",
      "Training: Epoch 6, Batch 10, Loss: 0.374\n",
      "Training: Epoch 6, Batch 11, Loss: 0.442\n",
      "Training: Epoch 6, Batch 12, Loss: 0.393\n",
      "Training: Epoch 6, Batch 13, Loss: 0.368\n",
      "Training: Epoch 6, Batch 14, Loss: 0.522\n",
      "Training: Epoch 6, Batch 15, Loss: 0.342\n",
      "Training: Epoch 6, Batch 16, Loss: 0.388\n",
      "Training: Epoch 6, Batch 17, Loss: 0.332\n",
      "Training: Epoch 6, Batch 18, Loss: 0.352\n",
      "Training: Epoch 6, Batch 19, Loss: 0.302\n",
      "Val: Epoch 6, Loss: 0.357\n",
      "Training: Epoch 7, Batch 0, Loss: 0.439\n",
      "Training: Epoch 7, Batch 1, Loss: 0.428\n",
      "Training: Epoch 7, Batch 2, Loss: 0.268\n",
      "Training: Epoch 7, Batch 3, Loss: 0.448\n",
      "Training: Epoch 7, Batch 4, Loss: 0.297\n",
      "Training: Epoch 7, Batch 5, Loss: 0.285\n",
      "Training: Epoch 7, Batch 6, Loss: 0.345\n",
      "Training: Epoch 7, Batch 7, Loss: 0.266\n",
      "Training: Epoch 7, Batch 8, Loss: 0.454\n",
      "Training: Epoch 7, Batch 9, Loss: 0.322\n",
      "Training: Epoch 7, Batch 10, Loss: 0.338\n",
      "Training: Epoch 7, Batch 11, Loss: 0.281\n",
      "Training: Epoch 7, Batch 12, Loss: 0.279\n",
      "Training: Epoch 7, Batch 13, Loss: 0.287\n",
      "Training: Epoch 7, Batch 14, Loss: 0.26\n",
      "Training: Epoch 7, Batch 15, Loss: 0.396\n",
      "Training: Epoch 7, Batch 16, Loss: 0.395\n",
      "Training: Epoch 7, Batch 17, Loss: 0.28\n",
      "Training: Epoch 7, Batch 18, Loss: 0.309\n",
      "Training: Epoch 7, Batch 19, Loss: 0.265\n",
      "Val: Epoch 7, Loss: 0.371\n",
      "Training: Epoch 8, Batch 0, Loss: 0.419\n",
      "Training: Epoch 8, Batch 1, Loss: 0.294\n",
      "Training: Epoch 8, Batch 2, Loss: 0.305\n",
      "Training: Epoch 8, Batch 3, Loss: 0.344\n",
      "Training: Epoch 8, Batch 4, Loss: 0.445\n",
      "Training: Epoch 8, Batch 5, Loss: 0.351\n",
      "Training: Epoch 8, Batch 6, Loss: 0.503\n",
      "Training: Epoch 8, Batch 7, Loss: 0.446\n",
      "Training: Epoch 8, Batch 8, Loss: 0.25\n",
      "Training: Epoch 8, Batch 9, Loss: 0.447\n",
      "Training: Epoch 8, Batch 10, Loss: 0.307\n",
      "Training: Epoch 8, Batch 11, Loss: 0.301\n",
      "Training: Epoch 8, Batch 12, Loss: 0.306\n",
      "Training: Epoch 8, Batch 13, Loss: 0.271\n",
      "Training: Epoch 8, Batch 14, Loss: 0.287\n",
      "Training: Epoch 8, Batch 15, Loss: 0.345\n",
      "Training: Epoch 8, Batch 16, Loss: 0.327\n",
      "Training: Epoch 8, Batch 17, Loss: 0.283\n",
      "Training: Epoch 8, Batch 18, Loss: 0.3\n",
      "Training: Epoch 8, Batch 19, Loss: 0.205\n",
      "Val: Epoch 8, Loss: 0.302\n",
      "Training: Epoch 9, Batch 0, Loss: 0.308\n",
      "Training: Epoch 9, Batch 1, Loss: 0.311\n",
      "Training: Epoch 9, Batch 2, Loss: 0.251\n",
      "Training: Epoch 9, Batch 3, Loss: 0.284\n",
      "Training: Epoch 9, Batch 4, Loss: 0.469\n",
      "Training: Epoch 9, Batch 5, Loss: 0.242\n",
      "Training: Epoch 9, Batch 6, Loss: 0.316\n",
      "Training: Epoch 9, Batch 7, Loss: 0.314\n",
      "Training: Epoch 9, Batch 8, Loss: 0.407\n",
      "Training: Epoch 9, Batch 9, Loss: 0.266\n",
      "Training: Epoch 9, Batch 10, Loss: 0.289\n",
      "Training: Epoch 9, Batch 11, Loss: 0.363\n",
      "Training: Epoch 9, Batch 12, Loss: 0.44\n",
      "Training: Epoch 9, Batch 13, Loss: 0.311\n",
      "Training: Epoch 9, Batch 14, Loss: 0.243\n",
      "Training: Epoch 9, Batch 15, Loss: 0.231\n",
      "Training: Epoch 9, Batch 16, Loss: 0.517\n",
      "Training: Epoch 9, Batch 17, Loss: 0.298\n",
      "Training: Epoch 9, Batch 18, Loss: 0.37\n",
      "Training: Epoch 9, Batch 19, Loss: 0.467\n",
      "Val: Epoch 9, Loss: 0.379\n",
      "Training: Epoch 10, Batch 0, Loss: 0.311\n",
      "Training: Epoch 10, Batch 1, Loss: 0.365\n",
      "Training: Epoch 10, Batch 2, Loss: 0.383\n",
      "Training: Epoch 10, Batch 3, Loss: 0.266\n",
      "Training: Epoch 10, Batch 4, Loss: 0.4\n",
      "Training: Epoch 10, Batch 5, Loss: 0.392\n",
      "Training: Epoch 10, Batch 6, Loss: 0.407\n",
      "Training: Epoch 10, Batch 7, Loss: 0.32\n",
      "Training: Epoch 10, Batch 8, Loss: 0.321\n",
      "Training: Epoch 10, Batch 9, Loss: 0.277\n",
      "Training: Epoch 10, Batch 10, Loss: 0.317\n",
      "Training: Epoch 10, Batch 11, Loss: 0.432\n",
      "Training: Epoch 10, Batch 12, Loss: 0.27\n",
      "Training: Epoch 10, Batch 13, Loss: 0.275\n",
      "Training: Epoch 10, Batch 14, Loss: 0.273\n",
      "Training: Epoch 10, Batch 15, Loss: 0.283\n",
      "Training: Epoch 10, Batch 16, Loss: 0.493\n",
      "Training: Epoch 10, Batch 17, Loss: 0.323\n",
      "Training: Epoch 10, Batch 18, Loss: 0.376\n",
      "Training: Epoch 10, Batch 19, Loss: 0.239\n",
      "Val: Epoch 10, Loss: 0.302\n",
      "Training: Epoch 11, Batch 0, Loss: 0.397\n",
      "Training: Epoch 11, Batch 1, Loss: 0.323\n",
      "Training: Epoch 11, Batch 2, Loss: 0.318\n",
      "Training: Epoch 11, Batch 3, Loss: 0.265\n",
      "Training: Epoch 11, Batch 4, Loss: 0.264\n",
      "Training: Epoch 11, Batch 5, Loss: 0.344\n",
      "Training: Epoch 11, Batch 6, Loss: 0.402\n",
      "Training: Epoch 11, Batch 7, Loss: 0.245\n",
      "Training: Epoch 11, Batch 8, Loss: 0.304\n",
      "Training: Epoch 11, Batch 9, Loss: 0.317\n",
      "Training: Epoch 11, Batch 10, Loss: 0.298\n",
      "Training: Epoch 11, Batch 11, Loss: 0.207\n",
      "Training: Epoch 11, Batch 12, Loss: 0.23\n",
      "Training: Epoch 11, Batch 13, Loss: 0.364\n",
      "Training: Epoch 11, Batch 14, Loss: 0.363\n",
      "Training: Epoch 11, Batch 15, Loss: 0.368\n",
      "Training: Epoch 11, Batch 16, Loss: 0.244\n",
      "Training: Epoch 11, Batch 17, Loss: 0.339\n",
      "Training: Epoch 11, Batch 18, Loss: 0.317\n",
      "Training: Epoch 11, Batch 19, Loss: 0.297\n",
      "Val: Epoch 11, Loss: 0.304\n",
      "Training: Epoch 12, Batch 0, Loss: 0.228\n",
      "Training: Epoch 12, Batch 1, Loss: 0.332\n",
      "Training: Epoch 12, Batch 2, Loss: 0.261\n",
      "Training: Epoch 12, Batch 3, Loss: 0.378\n",
      "Training: Epoch 12, Batch 4, Loss: 0.217\n",
      "Training: Epoch 12, Batch 5, Loss: 0.285\n",
      "Training: Epoch 12, Batch 6, Loss: 0.362\n",
      "Training: Epoch 12, Batch 7, Loss: 0.366\n",
      "Training: Epoch 12, Batch 8, Loss: 0.272\n",
      "Training: Epoch 12, Batch 9, Loss: 0.245\n",
      "Training: Epoch 12, Batch 10, Loss: 0.344\n",
      "Training: Epoch 12, Batch 11, Loss: 0.286\n",
      "Training: Epoch 12, Batch 12, Loss: 0.29\n",
      "Training: Epoch 12, Batch 13, Loss: 0.275\n",
      "Training: Epoch 12, Batch 14, Loss: 0.378\n",
      "Training: Epoch 12, Batch 15, Loss: 0.22\n",
      "Training: Epoch 12, Batch 16, Loss: 0.253\n",
      "Training: Epoch 12, Batch 17, Loss: 0.331\n",
      "Training: Epoch 12, Batch 18, Loss: 0.385\n",
      "Training: Epoch 12, Batch 19, Loss: 0.321\n",
      "Val: Epoch 12, Loss: 0.287\n",
      "Training: Epoch 13, Batch 0, Loss: 0.295\n",
      "Training: Epoch 13, Batch 1, Loss: 0.229\n",
      "Training: Epoch 13, Batch 2, Loss: 0.384\n",
      "Training: Epoch 13, Batch 3, Loss: 0.402\n",
      "Training: Epoch 13, Batch 4, Loss: 0.344\n",
      "Training: Epoch 13, Batch 5, Loss: 0.32\n",
      "Training: Epoch 13, Batch 6, Loss: 0.3\n",
      "Training: Epoch 13, Batch 7, Loss: 0.34\n",
      "Training: Epoch 13, Batch 8, Loss: 0.27\n",
      "Training: Epoch 13, Batch 9, Loss: 0.22\n",
      "Training: Epoch 13, Batch 10, Loss: 0.355\n",
      "Training: Epoch 13, Batch 11, Loss: 0.274\n",
      "Training: Epoch 13, Batch 12, Loss: 0.262\n",
      "Training: Epoch 13, Batch 13, Loss: 0.292\n",
      "Training: Epoch 13, Batch 14, Loss: 0.318\n",
      "Training: Epoch 13, Batch 15, Loss: 0.283\n",
      "Training: Epoch 13, Batch 16, Loss: 0.178\n",
      "Training: Epoch 13, Batch 17, Loss: 0.319\n",
      "Training: Epoch 13, Batch 18, Loss: 0.307\n",
      "Training: Epoch 13, Batch 19, Loss: 0.345\n",
      "Val: Epoch 13, Loss: 0.301\n",
      "Training: Epoch 14, Batch 0, Loss: 0.328\n",
      "Training: Epoch 14, Batch 1, Loss: 0.392\n",
      "Training: Epoch 14, Batch 2, Loss: 0.308\n",
      "Training: Epoch 14, Batch 3, Loss: 0.517\n",
      "Training: Epoch 14, Batch 4, Loss: 0.254\n",
      "Training: Epoch 14, Batch 5, Loss: 0.175\n",
      "Training: Epoch 14, Batch 6, Loss: 0.284\n",
      "Training: Epoch 14, Batch 7, Loss: 0.283\n",
      "Training: Epoch 14, Batch 8, Loss: 0.271\n",
      "Training: Epoch 14, Batch 9, Loss: 0.294\n",
      "Training: Epoch 14, Batch 10, Loss: 0.228\n",
      "Training: Epoch 14, Batch 11, Loss: 0.288\n",
      "Training: Epoch 14, Batch 12, Loss: 0.326\n",
      "Training: Epoch 14, Batch 13, Loss: 0.333\n",
      "Training: Epoch 14, Batch 14, Loss: 0.219\n",
      "Training: Epoch 14, Batch 15, Loss: 0.353\n",
      "Training: Epoch 14, Batch 16, Loss: 0.285\n",
      "Training: Epoch 14, Batch 17, Loss: 0.364\n",
      "Training: Epoch 14, Batch 18, Loss: 0.231\n",
      "Training: Epoch 14, Batch 19, Loss: 0.28\n",
      "Val: Epoch 14, Loss: 0.292\n",
      "Training: Epoch 15, Batch 0, Loss: 0.261\n",
      "Training: Epoch 15, Batch 1, Loss: 0.232\n",
      "Training: Epoch 15, Batch 2, Loss: 0.306\n",
      "Training: Epoch 15, Batch 3, Loss: 0.377\n",
      "Training: Epoch 15, Batch 4, Loss: 0.184\n",
      "Training: Epoch 15, Batch 5, Loss: 0.255\n",
      "Training: Epoch 15, Batch 6, Loss: 0.275\n",
      "Training: Epoch 15, Batch 7, Loss: 0.304\n",
      "Training: Epoch 15, Batch 8, Loss: 0.256\n",
      "Training: Epoch 15, Batch 9, Loss: 0.309\n",
      "Training: Epoch 15, Batch 10, Loss: 0.378\n",
      "Training: Epoch 15, Batch 11, Loss: 0.258\n",
      "Training: Epoch 15, Batch 12, Loss: 0.246\n",
      "Training: Epoch 15, Batch 13, Loss: 0.259\n",
      "Training: Epoch 15, Batch 14, Loss: 0.277\n",
      "Training: Epoch 15, Batch 15, Loss: 0.344\n",
      "Training: Epoch 15, Batch 16, Loss: 0.306\n",
      "Training: Epoch 15, Batch 17, Loss: 0.268\n",
      "Training: Epoch 15, Batch 18, Loss: 0.543\n",
      "Training: Epoch 15, Batch 19, Loss: 0.268\n",
      "Val: Epoch 15, Loss: 0.299\n",
      "Training: Epoch 16, Batch 0, Loss: 0.229\n",
      "Training: Epoch 16, Batch 1, Loss: 0.172\n",
      "Training: Epoch 16, Batch 2, Loss: 0.252\n",
      "Training: Epoch 16, Batch 3, Loss: 0.403\n",
      "Training: Epoch 16, Batch 4, Loss: 0.275\n",
      "Training: Epoch 16, Batch 5, Loss: 0.28\n",
      "Training: Epoch 16, Batch 6, Loss: 0.311\n",
      "Training: Epoch 16, Batch 7, Loss: 0.337\n",
      "Training: Epoch 16, Batch 8, Loss: 0.268\n",
      "Training: Epoch 16, Batch 9, Loss: 0.319\n",
      "Training: Epoch 16, Batch 10, Loss: 0.237\n",
      "Training: Epoch 16, Batch 11, Loss: 0.29\n",
      "Training: Epoch 16, Batch 12, Loss: 0.281\n",
      "Training: Epoch 16, Batch 13, Loss: 0.345\n",
      "Training: Epoch 16, Batch 14, Loss: 0.418\n",
      "Training: Epoch 16, Batch 15, Loss: 0.271\n",
      "Training: Epoch 16, Batch 16, Loss: 0.446\n",
      "Training: Epoch 16, Batch 17, Loss: 0.223\n",
      "Training: Epoch 16, Batch 18, Loss: 0.336\n",
      "Training: Epoch 16, Batch 19, Loss: 0.269\n",
      "Val: Epoch 16, Loss: 0.289\n",
      "Training: Epoch 17, Batch 0, Loss: 0.316\n",
      "Training: Epoch 17, Batch 1, Loss: 0.244\n",
      "Training: Epoch 17, Batch 2, Loss: 0.338\n",
      "Training: Epoch 17, Batch 3, Loss: 0.35\n",
      "Training: Epoch 17, Batch 4, Loss: 0.279\n",
      "Training: Epoch 17, Batch 5, Loss: 0.193\n",
      "Training: Epoch 17, Batch 6, Loss: 0.256\n",
      "Training: Epoch 17, Batch 7, Loss: 0.254\n",
      "Training: Epoch 17, Batch 8, Loss: 0.236\n",
      "Training: Epoch 17, Batch 9, Loss: 0.309\n",
      "Training: Epoch 17, Batch 10, Loss: 0.335\n",
      "Training: Epoch 17, Batch 11, Loss: 0.374\n",
      "Training: Epoch 17, Batch 12, Loss: 0.269\n",
      "Training: Epoch 17, Batch 13, Loss: 0.247\n",
      "Training: Epoch 17, Batch 14, Loss: 0.433\n",
      "Training: Epoch 17, Batch 15, Loss: 0.313\n",
      "Training: Epoch 17, Batch 16, Loss: 0.338\n",
      "Training: Epoch 17, Batch 17, Loss: 0.414\n",
      "Training: Epoch 17, Batch 18, Loss: 0.231\n",
      "Training: Epoch 17, Batch 19, Loss: 0.368\n",
      "Val: Epoch 17, Loss: 0.293\n",
      "Training: Epoch 18, Batch 0, Loss: 0.317\n",
      "Training: Epoch 18, Batch 1, Loss: 0.266\n",
      "Training: Epoch 18, Batch 2, Loss: 0.265\n",
      "Training: Epoch 18, Batch 3, Loss: 0.288\n",
      "Training: Epoch 18, Batch 4, Loss: 0.213\n",
      "Training: Epoch 18, Batch 5, Loss: 0.351\n",
      "Training: Epoch 18, Batch 6, Loss: 0.309\n",
      "Training: Epoch 18, Batch 7, Loss: 0.329\n",
      "Training: Epoch 18, Batch 8, Loss: 0.277\n",
      "Training: Epoch 18, Batch 9, Loss: 0.223\n",
      "Training: Epoch 18, Batch 10, Loss: 0.319\n",
      "Training: Epoch 18, Batch 11, Loss: 0.321\n",
      "Training: Epoch 18, Batch 12, Loss: 0.257\n",
      "Training: Epoch 18, Batch 13, Loss: 0.268\n",
      "Training: Epoch 18, Batch 14, Loss: 0.269\n",
      "Training: Epoch 18, Batch 15, Loss: 0.267\n",
      "Training: Epoch 18, Batch 16, Loss: 0.206\n",
      "Training: Epoch 18, Batch 17, Loss: 0.247\n",
      "Training: Epoch 18, Batch 18, Loss: 0.218\n",
      "Training: Epoch 18, Batch 19, Loss: 0.3\n",
      "Val: Epoch 18, Loss: 0.281\n",
      "Training: Epoch 19, Batch 0, Loss: 0.225\n",
      "Training: Epoch 19, Batch 1, Loss: 0.386\n",
      "Training: Epoch 19, Batch 2, Loss: 0.224\n",
      "Training: Epoch 19, Batch 3, Loss: 0.29\n",
      "Training: Epoch 19, Batch 4, Loss: 0.275\n",
      "Training: Epoch 19, Batch 5, Loss: 0.384\n",
      "Training: Epoch 19, Batch 6, Loss: 0.289\n",
      "Training: Epoch 19, Batch 7, Loss: 0.337\n",
      "Training: Epoch 19, Batch 8, Loss: 0.251\n",
      "Training: Epoch 19, Batch 9, Loss: 0.263\n",
      "Training: Epoch 19, Batch 10, Loss: 0.246\n",
      "Training: Epoch 19, Batch 11, Loss: 0.358\n",
      "Training: Epoch 19, Batch 12, Loss: 0.255\n",
      "Training: Epoch 19, Batch 13, Loss: 0.225\n",
      "Training: Epoch 19, Batch 14, Loss: 0.218\n",
      "Training: Epoch 19, Batch 15, Loss: 0.315\n",
      "Training: Epoch 19, Batch 16, Loss: 0.241\n",
      "Training: Epoch 19, Batch 17, Loss: 0.261\n",
      "Training: Epoch 19, Batch 18, Loss: 0.312\n",
      "Training: Epoch 19, Batch 19, Loss: 0.486\n",
      "Val: Epoch 19, Loss: 0.341\n",
      "Training: Epoch 20, Batch 0, Loss: 0.31\n",
      "Training: Epoch 20, Batch 1, Loss: 0.364\n",
      "Training: Epoch 20, Batch 2, Loss: 0.26\n",
      "Training: Epoch 20, Batch 3, Loss: 0.315\n",
      "Training: Epoch 20, Batch 4, Loss: 0.325\n",
      "Training: Epoch 20, Batch 5, Loss: 0.245\n",
      "Training: Epoch 20, Batch 6, Loss: 0.172\n",
      "Training: Epoch 20, Batch 7, Loss: 0.228\n",
      "Training: Epoch 20, Batch 8, Loss: 0.206\n",
      "Training: Epoch 20, Batch 9, Loss: 0.243\n",
      "Training: Epoch 20, Batch 10, Loss: 0.452\n",
      "Training: Epoch 20, Batch 11, Loss: 0.242\n",
      "Training: Epoch 20, Batch 12, Loss: 0.316\n",
      "Training: Epoch 20, Batch 13, Loss: 0.279\n",
      "Training: Epoch 20, Batch 14, Loss: 0.373\n",
      "Training: Epoch 20, Batch 15, Loss: 0.243\n",
      "Training: Epoch 20, Batch 16, Loss: 0.256\n",
      "Training: Epoch 20, Batch 17, Loss: 0.28\n",
      "Training: Epoch 20, Batch 18, Loss: 0.355\n",
      "Training: Epoch 20, Batch 19, Loss: 0.263\n",
      "Val: Epoch 20, Loss: 0.284\n",
      "Training: Epoch 21, Batch 0, Loss: 0.339\n",
      "Training: Epoch 21, Batch 1, Loss: 0.273\n",
      "Training: Epoch 21, Batch 2, Loss: 0.201\n",
      "Training: Epoch 21, Batch 3, Loss: 0.221\n",
      "Training: Epoch 21, Batch 4, Loss: 0.321\n",
      "Training: Epoch 21, Batch 5, Loss: 0.355\n",
      "Training: Epoch 21, Batch 6, Loss: 0.221\n",
      "Training: Epoch 21, Batch 7, Loss: 0.249\n",
      "Training: Epoch 21, Batch 8, Loss: 0.313\n",
      "Training: Epoch 21, Batch 9, Loss: 0.254\n",
      "Training: Epoch 21, Batch 10, Loss: 0.202\n",
      "Training: Epoch 21, Batch 11, Loss: 0.274\n",
      "Training: Epoch 21, Batch 12, Loss: 0.287\n",
      "Training: Epoch 21, Batch 13, Loss: 0.314\n",
      "Training: Epoch 21, Batch 14, Loss: 0.238\n",
      "Training: Epoch 21, Batch 15, Loss: 0.185\n",
      "Training: Epoch 21, Batch 16, Loss: 0.289\n",
      "Training: Epoch 21, Batch 17, Loss: 0.29\n",
      "Training: Epoch 21, Batch 18, Loss: 0.218\n",
      "Training: Epoch 21, Batch 19, Loss: 0.231\n",
      "Val: Epoch 21, Loss: 0.308\n",
      "Training: Epoch 22, Batch 0, Loss: 0.263\n",
      "Training: Epoch 22, Batch 1, Loss: 0.188\n",
      "Training: Epoch 22, Batch 2, Loss: 0.23\n",
      "Training: Epoch 22, Batch 3, Loss: 0.203\n",
      "Training: Epoch 22, Batch 4, Loss: 0.258\n",
      "Training: Epoch 22, Batch 5, Loss: 0.245\n",
      "Training: Epoch 22, Batch 6, Loss: 0.282\n",
      "Training: Epoch 22, Batch 7, Loss: 0.248\n",
      "Training: Epoch 22, Batch 8, Loss: 0.26\n",
      "Training: Epoch 22, Batch 9, Loss: 0.253\n",
      "Training: Epoch 22, Batch 10, Loss: 0.316\n",
      "Training: Epoch 22, Batch 11, Loss: 0.292\n",
      "Training: Epoch 22, Batch 12, Loss: 0.277\n",
      "Training: Epoch 22, Batch 13, Loss: 0.305\n",
      "Training: Epoch 22, Batch 14, Loss: 0.219\n",
      "Training: Epoch 22, Batch 15, Loss: 0.208\n",
      "Training: Epoch 22, Batch 16, Loss: 0.212\n",
      "Training: Epoch 22, Batch 17, Loss: 0.321\n",
      "Training: Epoch 22, Batch 18, Loss: 0.374\n",
      "Training: Epoch 22, Batch 19, Loss: 0.206\n",
      "Val: Epoch 22, Loss: 0.29\n",
      "Training: Epoch 23, Batch 0, Loss: 0.223\n",
      "Training: Epoch 23, Batch 1, Loss: 0.408\n",
      "Training: Epoch 23, Batch 2, Loss: 0.321\n",
      "Training: Epoch 23, Batch 3, Loss: 0.296\n",
      "Training: Epoch 23, Batch 4, Loss: 0.323\n",
      "Training: Epoch 23, Batch 5, Loss: 0.221\n",
      "Training: Epoch 23, Batch 6, Loss: 0.363\n",
      "Training: Epoch 23, Batch 7, Loss: 0.244\n",
      "Training: Epoch 23, Batch 8, Loss: 0.347\n",
      "Training: Epoch 23, Batch 9, Loss: 0.188\n",
      "Training: Epoch 23, Batch 10, Loss: 0.22\n",
      "Training: Epoch 23, Batch 11, Loss: 0.245\n",
      "Training: Epoch 23, Batch 12, Loss: 0.558\n",
      "Training: Epoch 23, Batch 13, Loss: 0.528\n",
      "Training: Epoch 23, Batch 14, Loss: 0.239\n",
      "Training: Epoch 23, Batch 15, Loss: 0.378\n",
      "Training: Epoch 23, Batch 16, Loss: 0.318\n",
      "Training: Epoch 23, Batch 17, Loss: 0.299\n",
      "Training: Epoch 23, Batch 18, Loss: 0.353\n",
      "Training: Epoch 23, Batch 19, Loss: 0.204\n",
      "Val: Epoch 23, Loss: 0.285\n",
      "Training: Epoch 24, Batch 0, Loss: 0.326\n",
      "Training: Epoch 24, Batch 1, Loss: 0.197\n",
      "Training: Epoch 24, Batch 2, Loss: 0.298\n",
      "Training: Epoch 24, Batch 3, Loss: 0.208\n",
      "Training: Epoch 24, Batch 4, Loss: 0.242\n",
      "Training: Epoch 24, Batch 5, Loss: 0.414\n",
      "Training: Epoch 24, Batch 6, Loss: 0.405\n",
      "Training: Epoch 24, Batch 7, Loss: 0.531\n",
      "Training: Epoch 24, Batch 8, Loss: 0.255\n",
      "Training: Epoch 24, Batch 9, Loss: 0.396\n",
      "Training: Epoch 24, Batch 10, Loss: 0.281\n",
      "Training: Epoch 24, Batch 11, Loss: 0.223\n",
      "Training: Epoch 24, Batch 12, Loss: 0.242\n",
      "Training: Epoch 24, Batch 13, Loss: 0.337\n",
      "Training: Epoch 24, Batch 14, Loss: 0.19\n",
      "Training: Epoch 24, Batch 15, Loss: 0.31\n",
      "Training: Epoch 24, Batch 16, Loss: 0.266\n",
      "Training: Epoch 24, Batch 17, Loss: 0.312\n",
      "Training: Epoch 24, Batch 18, Loss: 0.319\n",
      "Training: Epoch 24, Batch 19, Loss: 0.215\n",
      "Val: Epoch 24, Loss: 0.273\n",
      "Training: Epoch 25, Batch 0, Loss: 0.336\n",
      "Training: Epoch 25, Batch 1, Loss: 0.247\n",
      "Training: Epoch 25, Batch 2, Loss: 0.322\n",
      "Training: Epoch 25, Batch 3, Loss: 0.294\n",
      "Training: Epoch 25, Batch 4, Loss: 0.302\n",
      "Training: Epoch 25, Batch 5, Loss: 0.371\n",
      "Training: Epoch 25, Batch 6, Loss: 0.245\n",
      "Training: Epoch 25, Batch 7, Loss: 0.32\n",
      "Training: Epoch 25, Batch 8, Loss: 0.236\n",
      "Training: Epoch 25, Batch 9, Loss: 0.266\n",
      "Training: Epoch 25, Batch 10, Loss: 0.19\n",
      "Training: Epoch 25, Batch 11, Loss: 0.188\n",
      "Training: Epoch 25, Batch 12, Loss: 0.243\n",
      "Training: Epoch 25, Batch 13, Loss: 0.417\n",
      "Training: Epoch 25, Batch 14, Loss: 0.281\n",
      "Training: Epoch 25, Batch 15, Loss: 0.226\n",
      "Training: Epoch 25, Batch 16, Loss: 0.207\n",
      "Training: Epoch 25, Batch 17, Loss: 0.211\n",
      "Training: Epoch 25, Batch 18, Loss: 0.316\n",
      "Training: Epoch 25, Batch 19, Loss: 0.314\n",
      "Val: Epoch 25, Loss: 0.293\n",
      "Training: Epoch 26, Batch 0, Loss: 0.342\n",
      "Training: Epoch 26, Batch 1, Loss: 0.241\n",
      "Training: Epoch 26, Batch 2, Loss: 0.286\n",
      "Training: Epoch 26, Batch 3, Loss: 0.339\n",
      "Training: Epoch 26, Batch 4, Loss: 0.233\n",
      "Training: Epoch 26, Batch 5, Loss: 0.342\n",
      "Training: Epoch 26, Batch 6, Loss: 0.299\n",
      "Training: Epoch 26, Batch 7, Loss: 0.227\n",
      "Training: Epoch 26, Batch 8, Loss: 0.205\n",
      "Training: Epoch 26, Batch 9, Loss: 0.334\n",
      "Training: Epoch 26, Batch 10, Loss: 0.271\n",
      "Training: Epoch 26, Batch 11, Loss: 0.302\n",
      "Training: Epoch 26, Batch 12, Loss: 0.242\n",
      "Training: Epoch 26, Batch 13, Loss: 0.294\n",
      "Training: Epoch 26, Batch 14, Loss: 0.291\n",
      "Training: Epoch 26, Batch 15, Loss: 0.347\n",
      "Training: Epoch 26, Batch 16, Loss: 0.488\n",
      "Training: Epoch 26, Batch 17, Loss: 0.318\n",
      "Training: Epoch 26, Batch 18, Loss: 0.257\n",
      "Training: Epoch 26, Batch 19, Loss: 0.245\n",
      "Val: Epoch 26, Loss: 0.3\n",
      "Training: Epoch 27, Batch 0, Loss: 0.323\n",
      "Training: Epoch 27, Batch 1, Loss: 0.281\n",
      "Training: Epoch 27, Batch 2, Loss: 0.333\n",
      "Training: Epoch 27, Batch 3, Loss: 0.327\n",
      "Training: Epoch 27, Batch 4, Loss: 0.225\n",
      "Training: Epoch 27, Batch 5, Loss: 0.262\n",
      "Training: Epoch 27, Batch 6, Loss: 0.216\n",
      "Training: Epoch 27, Batch 7, Loss: 0.233\n",
      "Training: Epoch 27, Batch 8, Loss: 0.307\n",
      "Training: Epoch 27, Batch 9, Loss: 0.251\n",
      "Training: Epoch 27, Batch 10, Loss: 0.23\n",
      "Training: Epoch 27, Batch 11, Loss: 0.282\n",
      "Training: Epoch 27, Batch 12, Loss: 0.374\n",
      "Training: Epoch 27, Batch 13, Loss: 0.243\n",
      "Training: Epoch 27, Batch 14, Loss: 0.261\n",
      "Training: Epoch 27, Batch 15, Loss: 0.225\n",
      "Training: Epoch 27, Batch 16, Loss: 0.213\n",
      "Training: Epoch 27, Batch 17, Loss: 0.219\n",
      "Training: Epoch 27, Batch 18, Loss: 0.511\n",
      "Training: Epoch 27, Batch 19, Loss: 0.21\n",
      "Val: Epoch 27, Loss: 0.289\n",
      "Training: Epoch 28, Batch 0, Loss: 0.221\n",
      "Training: Epoch 28, Batch 1, Loss: 0.3\n",
      "Training: Epoch 28, Batch 2, Loss: 0.317\n",
      "Training: Epoch 28, Batch 3, Loss: 0.275\n",
      "Training: Epoch 28, Batch 4, Loss: 0.248\n",
      "Training: Epoch 28, Batch 5, Loss: 0.315\n",
      "Training: Epoch 28, Batch 6, Loss: 0.24\n",
      "Training: Epoch 28, Batch 7, Loss: 0.317\n",
      "Training: Epoch 28, Batch 8, Loss: 0.389\n",
      "Training: Epoch 28, Batch 9, Loss: 0.301\n",
      "Training: Epoch 28, Batch 10, Loss: 0.237\n",
      "Training: Epoch 28, Batch 11, Loss: 0.213\n",
      "Training: Epoch 28, Batch 12, Loss: 0.181\n",
      "Training: Epoch 28, Batch 13, Loss: 0.254\n",
      "Training: Epoch 28, Batch 14, Loss: 0.324\n",
      "Training: Epoch 28, Batch 15, Loss: 0.245\n",
      "Training: Epoch 28, Batch 16, Loss: 0.168\n",
      "Training: Epoch 28, Batch 17, Loss: 0.284\n",
      "Training: Epoch 28, Batch 18, Loss: 0.361\n",
      "Training: Epoch 28, Batch 19, Loss: 0.2\n",
      "Val: Epoch 28, Loss: 0.291\n",
      "Training: Epoch 29, Batch 0, Loss: 0.387\n",
      "Training: Epoch 29, Batch 1, Loss: 0.266\n",
      "Training: Epoch 29, Batch 2, Loss: 0.241\n",
      "Training: Epoch 29, Batch 3, Loss: 0.316\n",
      "Training: Epoch 29, Batch 4, Loss: 0.432\n",
      "Training: Epoch 29, Batch 5, Loss: 0.206\n",
      "Training: Epoch 29, Batch 6, Loss: 0.24\n",
      "Training: Epoch 29, Batch 7, Loss: 0.235\n",
      "Training: Epoch 29, Batch 8, Loss: 0.194\n",
      "Training: Epoch 29, Batch 9, Loss: 0.247\n",
      "Training: Epoch 29, Batch 10, Loss: 0.247\n",
      "Training: Epoch 29, Batch 11, Loss: 0.283\n",
      "Training: Epoch 29, Batch 12, Loss: 0.19\n",
      "Training: Epoch 29, Batch 13, Loss: 0.217\n",
      "Training: Epoch 29, Batch 14, Loss: 0.254\n",
      "Training: Epoch 29, Batch 15, Loss: 0.273\n",
      "Training: Epoch 29, Batch 16, Loss: 0.207\n",
      "Training: Epoch 29, Batch 17, Loss: 0.34\n",
      "Training: Epoch 29, Batch 18, Loss: 0.187\n",
      "Training: Epoch 29, Batch 19, Loss: 0.288\n",
      "Val: Epoch 29, Loss: 0.27\n",
      "Training: Epoch 30, Batch 0, Loss: 0.2\n",
      "Training: Epoch 30, Batch 1, Loss: 0.199\n",
      "Training: Epoch 30, Batch 2, Loss: 0.243\n",
      "Training: Epoch 30, Batch 3, Loss: 0.309\n",
      "Training: Epoch 30, Batch 4, Loss: 0.3\n",
      "Training: Epoch 30, Batch 5, Loss: 0.169\n",
      "Training: Epoch 30, Batch 6, Loss: 0.284\n",
      "Training: Epoch 30, Batch 7, Loss: 0.274\n",
      "Training: Epoch 30, Batch 8, Loss: 0.211\n",
      "Training: Epoch 30, Batch 9, Loss: 0.237\n",
      "Training: Epoch 30, Batch 10, Loss: 0.275\n",
      "Training: Epoch 30, Batch 11, Loss: 0.268\n",
      "Training: Epoch 30, Batch 12, Loss: 0.205\n",
      "Training: Epoch 30, Batch 13, Loss: 0.264\n",
      "Training: Epoch 30, Batch 14, Loss: 0.297\n",
      "Training: Epoch 30, Batch 15, Loss: 0.273\n",
      "Training: Epoch 30, Batch 16, Loss: 0.234\n",
      "Training: Epoch 30, Batch 17, Loss: 0.34\n",
      "Training: Epoch 30, Batch 18, Loss: 0.297\n",
      "Training: Epoch 30, Batch 19, Loss: 0.253\n",
      "Val: Epoch 30, Loss: 0.273\n",
      "Training: Epoch 31, Batch 0, Loss: 0.254\n",
      "Training: Epoch 31, Batch 1, Loss: 0.205\n",
      "Training: Epoch 31, Batch 2, Loss: 0.27\n",
      "Training: Epoch 31, Batch 3, Loss: 0.218\n",
      "Training: Epoch 31, Batch 4, Loss: 0.372\n",
      "Training: Epoch 31, Batch 5, Loss: 0.237\n",
      "Training: Epoch 31, Batch 6, Loss: 0.167\n",
      "Training: Epoch 31, Batch 7, Loss: 0.205\n",
      "Training: Epoch 31, Batch 8, Loss: 0.535\n",
      "Training: Epoch 31, Batch 9, Loss: 0.211\n",
      "Training: Epoch 31, Batch 10, Loss: 0.271\n",
      "Training: Epoch 31, Batch 11, Loss: 0.228\n",
      "Training: Epoch 31, Batch 12, Loss: 0.466\n",
      "Training: Epoch 31, Batch 13, Loss: 0.271\n",
      "Training: Epoch 31, Batch 14, Loss: 0.243\n",
      "Training: Epoch 31, Batch 15, Loss: 0.181\n",
      "Training: Epoch 31, Batch 16, Loss: 0.301\n",
      "Training: Epoch 31, Batch 17, Loss: 0.224\n",
      "Training: Epoch 31, Batch 18, Loss: 0.165\n",
      "Training: Epoch 31, Batch 19, Loss: 0.326\n",
      "Val: Epoch 31, Loss: 0.319\n",
      "Training: Epoch 32, Batch 0, Loss: 0.226\n",
      "Training: Epoch 32, Batch 1, Loss: 0.377\n",
      "Training: Epoch 32, Batch 2, Loss: 0.254\n",
      "Training: Epoch 32, Batch 3, Loss: 0.215\n",
      "Training: Epoch 32, Batch 4, Loss: 0.357\n",
      "Training: Epoch 32, Batch 5, Loss: 0.399\n",
      "Training: Epoch 32, Batch 6, Loss: 0.236\n",
      "Training: Epoch 32, Batch 7, Loss: 0.301\n",
      "Training: Epoch 32, Batch 8, Loss: 0.31\n",
      "Training: Epoch 32, Batch 9, Loss: 0.199\n",
      "Training: Epoch 32, Batch 10, Loss: 0.241\n",
      "Training: Epoch 32, Batch 11, Loss: 0.192\n",
      "Training: Epoch 32, Batch 12, Loss: 0.238\n",
      "Training: Epoch 32, Batch 13, Loss: 0.319\n",
      "Training: Epoch 32, Batch 14, Loss: 0.197\n",
      "Training: Epoch 32, Batch 15, Loss: 0.322\n",
      "Training: Epoch 32, Batch 16, Loss: 0.257\n",
      "Training: Epoch 32, Batch 17, Loss: 0.196\n",
      "Training: Epoch 32, Batch 18, Loss: 0.287\n",
      "Training: Epoch 32, Batch 19, Loss: 0.186\n",
      "Val: Epoch 32, Loss: 0.271\n",
      "Training: Epoch 33, Batch 0, Loss: 0.26\n",
      "Training: Epoch 33, Batch 1, Loss: 0.237\n",
      "Training: Epoch 33, Batch 2, Loss: 0.211\n",
      "Training: Epoch 33, Batch 3, Loss: 0.248\n",
      "Training: Epoch 33, Batch 4, Loss: 0.249\n",
      "Training: Epoch 33, Batch 5, Loss: 0.274\n",
      "Training: Epoch 33, Batch 6, Loss: 0.212\n",
      "Training: Epoch 33, Batch 7, Loss: 0.151\n",
      "Training: Epoch 33, Batch 8, Loss: 0.214\n",
      "Training: Epoch 33, Batch 9, Loss: 0.225\n",
      "Training: Epoch 33, Batch 10, Loss: 0.204\n",
      "Training: Epoch 33, Batch 11, Loss: 0.175\n",
      "Training: Epoch 33, Batch 12, Loss: 0.238\n",
      "Training: Epoch 33, Batch 13, Loss: 0.236\n",
      "Training: Epoch 33, Batch 14, Loss: 0.198\n",
      "Training: Epoch 33, Batch 15, Loss: 0.208\n",
      "Training: Epoch 33, Batch 16, Loss: 0.246\n",
      "Training: Epoch 33, Batch 17, Loss: 0.251\n",
      "Training: Epoch 33, Batch 18, Loss: 0.255\n",
      "Training: Epoch 33, Batch 19, Loss: 0.239\n",
      "Val: Epoch 33, Loss: 0.273\n",
      "Training: Epoch 34, Batch 0, Loss: 0.246\n",
      "Training: Epoch 34, Batch 1, Loss: 0.19\n",
      "Training: Epoch 34, Batch 2, Loss: 0.196\n",
      "Training: Epoch 34, Batch 3, Loss: 0.238\n",
      "Training: Epoch 34, Batch 4, Loss: 0.419\n",
      "Training: Epoch 34, Batch 5, Loss: 0.25\n",
      "Training: Epoch 34, Batch 6, Loss: 0.183\n",
      "Training: Epoch 34, Batch 7, Loss: 0.195\n",
      "Training: Epoch 34, Batch 8, Loss: 0.345\n",
      "Training: Epoch 34, Batch 9, Loss: 0.229\n",
      "Training: Epoch 34, Batch 10, Loss: 0.172\n",
      "Training: Epoch 34, Batch 11, Loss: 0.205\n",
      "Training: Epoch 34, Batch 12, Loss: 0.223\n",
      "Training: Epoch 34, Batch 13, Loss: 0.189\n",
      "Training: Epoch 34, Batch 14, Loss: 0.184\n",
      "Training: Epoch 34, Batch 15, Loss: 0.322\n",
      "Training: Epoch 34, Batch 16, Loss: 0.212\n",
      "Training: Epoch 34, Batch 17, Loss: 0.23\n",
      "Training: Epoch 34, Batch 18, Loss: 0.245\n",
      "Training: Epoch 34, Batch 19, Loss: 0.225\n",
      "Val: Epoch 34, Loss: 0.293\n",
      "Training: Epoch 35, Batch 0, Loss: 0.262\n",
      "Training: Epoch 35, Batch 1, Loss: 0.282\n",
      "Training: Epoch 35, Batch 2, Loss: 0.268\n",
      "Training: Epoch 35, Batch 3, Loss: 0.23\n",
      "Training: Epoch 35, Batch 4, Loss: 0.205\n",
      "Training: Epoch 35, Batch 5, Loss: 0.179\n",
      "Training: Epoch 35, Batch 6, Loss: 0.259\n",
      "Training: Epoch 35, Batch 7, Loss: 0.174\n",
      "Training: Epoch 35, Batch 8, Loss: 0.229\n",
      "Training: Epoch 35, Batch 9, Loss: 0.265\n",
      "Training: Epoch 35, Batch 10, Loss: 0.247\n",
      "Training: Epoch 35, Batch 11, Loss: 0.194\n",
      "Training: Epoch 35, Batch 12, Loss: 0.283\n",
      "Training: Epoch 35, Batch 13, Loss: 0.258\n",
      "Training: Epoch 35, Batch 14, Loss: 0.212\n",
      "Training: Epoch 35, Batch 15, Loss: 0.259\n",
      "Training: Epoch 35, Batch 16, Loss: 0.225\n",
      "Training: Epoch 35, Batch 17, Loss: 0.233\n",
      "Training: Epoch 35, Batch 18, Loss: 0.181\n",
      "Training: Epoch 35, Batch 19, Loss: 0.212\n",
      "Val: Epoch 35, Loss: 0.3\n",
      "Training: Epoch 36, Batch 0, Loss: 0.31\n",
      "Training: Epoch 36, Batch 1, Loss: 0.264\n",
      "Training: Epoch 36, Batch 2, Loss: 0.165\n",
      "Training: Epoch 36, Batch 3, Loss: 0.302\n",
      "Training: Epoch 36, Batch 4, Loss: 0.173\n",
      "Training: Epoch 36, Batch 5, Loss: 0.176\n",
      "Training: Epoch 36, Batch 6, Loss: 0.245\n",
      "Training: Epoch 36, Batch 7, Loss: 0.203\n",
      "Training: Epoch 36, Batch 8, Loss: 0.2\n",
      "Training: Epoch 36, Batch 9, Loss: 0.231\n",
      "Training: Epoch 36, Batch 10, Loss: 0.321\n",
      "Training: Epoch 36, Batch 11, Loss: 0.162\n",
      "Training: Epoch 36, Batch 12, Loss: 0.23\n",
      "Training: Epoch 36, Batch 13, Loss: 0.182\n",
      "Training: Epoch 36, Batch 14, Loss: 0.23\n",
      "Training: Epoch 36, Batch 15, Loss: 0.191\n",
      "Training: Epoch 36, Batch 16, Loss: 0.192\n",
      "Training: Epoch 36, Batch 17, Loss: 0.196\n",
      "Training: Epoch 36, Batch 18, Loss: 0.224\n",
      "Training: Epoch 36, Batch 19, Loss: 0.205\n",
      "Val: Epoch 36, Loss: 0.276\n",
      "Training: Epoch 37, Batch 0, Loss: 0.167\n",
      "Training: Epoch 37, Batch 1, Loss: 0.33\n",
      "Training: Epoch 37, Batch 2, Loss: 0.197\n",
      "Training: Epoch 37, Batch 3, Loss: 0.25\n",
      "Training: Epoch 37, Batch 4, Loss: 0.242\n",
      "Training: Epoch 37, Batch 5, Loss: 0.266\n",
      "Training: Epoch 37, Batch 6, Loss: 0.29\n",
      "Training: Epoch 37, Batch 7, Loss: 0.416\n",
      "Training: Epoch 37, Batch 8, Loss: 0.225\n",
      "Training: Epoch 37, Batch 9, Loss: 0.162\n",
      "Training: Epoch 37, Batch 10, Loss: 0.233\n",
      "Training: Epoch 37, Batch 11, Loss: 0.232\n",
      "Training: Epoch 37, Batch 12, Loss: 0.207\n",
      "Training: Epoch 37, Batch 13, Loss: 0.31\n",
      "Training: Epoch 37, Batch 14, Loss: 0.354\n",
      "Training: Epoch 37, Batch 15, Loss: 0.51\n",
      "Training: Epoch 37, Batch 16, Loss: 0.227\n",
      "Training: Epoch 37, Batch 17, Loss: 0.267\n",
      "Training: Epoch 37, Batch 18, Loss: 0.356\n",
      "Training: Epoch 37, Batch 19, Loss: 0.268\n",
      "Val: Epoch 37, Loss: 0.369\n",
      "Training: Epoch 38, Batch 0, Loss: 0.351\n",
      "Training: Epoch 38, Batch 1, Loss: 0.293\n",
      "Training: Epoch 38, Batch 2, Loss: 0.398\n",
      "Training: Epoch 38, Batch 3, Loss: 0.429\n",
      "Training: Epoch 38, Batch 4, Loss: 0.176\n",
      "Training: Epoch 38, Batch 5, Loss: 0.202\n",
      "Training: Epoch 38, Batch 6, Loss: 0.254\n",
      "Training: Epoch 38, Batch 7, Loss: 0.249\n",
      "Training: Epoch 38, Batch 8, Loss: 0.197\n",
      "Training: Epoch 38, Batch 9, Loss: 0.296\n",
      "Training: Epoch 38, Batch 10, Loss: 0.222\n",
      "Training: Epoch 38, Batch 11, Loss: 0.203\n",
      "Training: Epoch 38, Batch 12, Loss: 0.409\n",
      "Training: Epoch 38, Batch 13, Loss: 0.273\n",
      "Training: Epoch 38, Batch 14, Loss: 0.223\n",
      "Training: Epoch 38, Batch 15, Loss: 0.267\n",
      "Training: Epoch 38, Batch 16, Loss: 0.23\n",
      "Training: Epoch 38, Batch 17, Loss: 0.248\n",
      "Training: Epoch 38, Batch 18, Loss: 0.265\n",
      "Training: Epoch 38, Batch 19, Loss: 0.208\n",
      "Val: Epoch 38, Loss: 0.299\n",
      "Training: Epoch 39, Batch 0, Loss: 0.263\n",
      "Training: Epoch 39, Batch 1, Loss: 0.273\n",
      "Training: Epoch 39, Batch 2, Loss: 0.253\n",
      "Training: Epoch 39, Batch 3, Loss: 0.253\n",
      "Training: Epoch 39, Batch 4, Loss: 0.236\n",
      "Training: Epoch 39, Batch 5, Loss: 0.213\n",
      "Training: Epoch 39, Batch 6, Loss: 0.276\n",
      "Training: Epoch 39, Batch 7, Loss: 0.192\n",
      "Training: Epoch 39, Batch 8, Loss: 0.187\n",
      "Training: Epoch 39, Batch 9, Loss: 0.258\n",
      "Training: Epoch 39, Batch 10, Loss: 0.219\n",
      "Training: Epoch 39, Batch 11, Loss: 0.341\n",
      "Training: Epoch 39, Batch 12, Loss: 0.304\n",
      "Training: Epoch 39, Batch 13, Loss: 0.193\n",
      "Training: Epoch 39, Batch 14, Loss: 0.174\n",
      "Training: Epoch 39, Batch 15, Loss: 0.226\n",
      "Training: Epoch 39, Batch 16, Loss: 0.302\n",
      "Training: Epoch 39, Batch 17, Loss: 0.277\n",
      "Training: Epoch 39, Batch 18, Loss: 0.258\n",
      "Training: Epoch 39, Batch 19, Loss: 0.182\n",
      "Val: Epoch 39, Loss: 0.283\n",
      "Training: Epoch 40, Batch 0, Loss: 0.249\n",
      "Training: Epoch 40, Batch 1, Loss: 0.198\n",
      "Training: Epoch 40, Batch 2, Loss: 0.179\n",
      "Training: Epoch 40, Batch 3, Loss: 0.202\n",
      "Training: Epoch 40, Batch 4, Loss: 0.28\n",
      "Training: Epoch 40, Batch 5, Loss: 0.191\n",
      "Training: Epoch 40, Batch 6, Loss: 0.156\n",
      "Training: Epoch 40, Batch 7, Loss: 0.25\n",
      "Training: Epoch 40, Batch 8, Loss: 0.297\n",
      "Training: Epoch 40, Batch 9, Loss: 0.379\n",
      "Training: Epoch 40, Batch 10, Loss: 0.258\n",
      "Training: Epoch 40, Batch 11, Loss: 0.162\n",
      "Training: Epoch 40, Batch 12, Loss: 0.212\n",
      "Training: Epoch 40, Batch 13, Loss: 0.248\n",
      "Training: Epoch 40, Batch 14, Loss: 0.269\n",
      "Training: Epoch 40, Batch 15, Loss: 0.242\n",
      "Training: Epoch 40, Batch 16, Loss: 0.211\n",
      "Training: Epoch 40, Batch 17, Loss: 0.253\n",
      "Training: Epoch 40, Batch 18, Loss: 0.219\n",
      "Training: Epoch 40, Batch 19, Loss: 0.239\n",
      "Val: Epoch 40, Loss: 0.311\n",
      "Training: Epoch 41, Batch 0, Loss: 0.241\n",
      "Training: Epoch 41, Batch 1, Loss: 0.293\n",
      "Training: Epoch 41, Batch 2, Loss: 0.214\n",
      "Training: Epoch 41, Batch 3, Loss: 0.332\n",
      "Training: Epoch 41, Batch 4, Loss: 0.213\n",
      "Training: Epoch 41, Batch 5, Loss: 0.205\n",
      "Training: Epoch 41, Batch 6, Loss: 0.209\n",
      "Training: Epoch 41, Batch 7, Loss: 0.231\n",
      "Training: Epoch 41, Batch 8, Loss: 0.174\n",
      "Training: Epoch 41, Batch 9, Loss: 0.309\n",
      "Training: Epoch 41, Batch 10, Loss: 0.397\n",
      "Training: Epoch 41, Batch 11, Loss: 0.212\n",
      "Training: Epoch 41, Batch 12, Loss: 0.24\n",
      "Training: Epoch 41, Batch 13, Loss: 0.204\n",
      "Training: Epoch 41, Batch 14, Loss: 0.155\n",
      "Training: Epoch 41, Batch 15, Loss: 0.229\n",
      "Training: Epoch 41, Batch 16, Loss: 0.211\n",
      "Training: Epoch 41, Batch 17, Loss: 0.214\n",
      "Training: Epoch 41, Batch 18, Loss: 0.451\n",
      "Training: Epoch 41, Batch 19, Loss: 0.171\n",
      "Val: Epoch 41, Loss: 0.321\n",
      "Training: Epoch 42, Batch 0, Loss: 0.223\n",
      "Training: Epoch 42, Batch 1, Loss: 0.349\n",
      "Training: Epoch 42, Batch 2, Loss: 0.295\n",
      "Training: Epoch 42, Batch 3, Loss: 0.372\n",
      "Training: Epoch 42, Batch 4, Loss: 0.232\n",
      "Training: Epoch 42, Batch 5, Loss: 0.183\n",
      "Training: Epoch 42, Batch 6, Loss: 0.215\n",
      "Training: Epoch 42, Batch 7, Loss: 0.295\n",
      "Training: Epoch 42, Batch 8, Loss: 0.283\n",
      "Training: Epoch 42, Batch 9, Loss: 0.216\n",
      "Training: Epoch 42, Batch 10, Loss: 0.207\n",
      "Training: Epoch 42, Batch 11, Loss: 0.199\n",
      "Training: Epoch 42, Batch 12, Loss: 0.255\n",
      "Training: Epoch 42, Batch 13, Loss: 0.191\n",
      "Training: Epoch 42, Batch 14, Loss: 0.357\n",
      "Training: Epoch 42, Batch 15, Loss: 0.173\n",
      "Training: Epoch 42, Batch 16, Loss: 0.156\n",
      "Training: Epoch 42, Batch 17, Loss: 0.225\n",
      "Training: Epoch 42, Batch 18, Loss: 0.222\n",
      "Training: Epoch 42, Batch 19, Loss: 0.255\n",
      "Val: Epoch 42, Loss: 0.273\n",
      "Training: Epoch 43, Batch 0, Loss: 0.24\n",
      "Training: Epoch 43, Batch 1, Loss: 0.333\n",
      "Training: Epoch 43, Batch 2, Loss: 0.297\n",
      "Training: Epoch 43, Batch 3, Loss: 0.207\n",
      "Training: Epoch 43, Batch 4, Loss: 0.23\n",
      "Training: Epoch 43, Batch 5, Loss: 0.223\n",
      "Training: Epoch 43, Batch 6, Loss: 0.201\n",
      "Training: Epoch 43, Batch 7, Loss: 0.267\n",
      "Training: Epoch 43, Batch 8, Loss: 0.16\n",
      "Training: Epoch 43, Batch 9, Loss: 0.233\n",
      "Training: Epoch 43, Batch 10, Loss: 0.2\n",
      "Training: Epoch 43, Batch 11, Loss: 0.203\n",
      "Training: Epoch 43, Batch 12, Loss: 0.257\n",
      "Training: Epoch 43, Batch 13, Loss: 0.193\n",
      "Training: Epoch 43, Batch 14, Loss: 0.207\n",
      "Training: Epoch 43, Batch 15, Loss: 0.211\n",
      "Training: Epoch 43, Batch 16, Loss: 0.232\n",
      "Training: Epoch 43, Batch 17, Loss: 0.332\n",
      "Training: Epoch 43, Batch 18, Loss: 0.208\n",
      "Training: Epoch 43, Batch 19, Loss: 0.181\n",
      "Val: Epoch 43, Loss: 0.274\n",
      "Training: Epoch 44, Batch 0, Loss: 0.192\n",
      "Training: Epoch 44, Batch 1, Loss: 0.188\n",
      "Training: Epoch 44, Batch 2, Loss: 0.174\n",
      "Training: Epoch 44, Batch 3, Loss: 0.161\n",
      "Training: Epoch 44, Batch 4, Loss: 0.208\n",
      "Training: Epoch 44, Batch 5, Loss: 0.255\n",
      "Training: Epoch 44, Batch 6, Loss: 0.177\n",
      "Training: Epoch 44, Batch 7, Loss: 0.19\n",
      "Training: Epoch 44, Batch 8, Loss: 0.306\n",
      "Training: Epoch 44, Batch 9, Loss: 0.222\n",
      "Training: Epoch 44, Batch 10, Loss: 0.22\n",
      "Training: Epoch 44, Batch 11, Loss: 0.306\n",
      "Training: Epoch 44, Batch 12, Loss: 0.315\n",
      "Training: Epoch 44, Batch 13, Loss: 0.216\n",
      "Training: Epoch 44, Batch 14, Loss: 0.222\n",
      "Training: Epoch 44, Batch 15, Loss: 0.214\n",
      "Training: Epoch 44, Batch 16, Loss: 0.241\n",
      "Training: Epoch 44, Batch 17, Loss: 0.232\n",
      "Training: Epoch 44, Batch 18, Loss: 0.275\n",
      "Training: Epoch 44, Batch 19, Loss: 0.226\n",
      "Val: Epoch 44, Loss: 0.256\n",
      "Training: Epoch 45, Batch 0, Loss: 0.285\n",
      "Training: Epoch 45, Batch 1, Loss: 0.205\n",
      "Training: Epoch 45, Batch 2, Loss: 0.223\n",
      "Training: Epoch 45, Batch 3, Loss: 0.193\n",
      "Training: Epoch 45, Batch 4, Loss: 0.178\n",
      "Training: Epoch 45, Batch 5, Loss: 0.248\n",
      "Training: Epoch 45, Batch 6, Loss: 0.206\n",
      "Training: Epoch 45, Batch 7, Loss: 0.227\n",
      "Training: Epoch 45, Batch 8, Loss: 0.242\n",
      "Training: Epoch 45, Batch 9, Loss: 0.238\n",
      "Training: Epoch 45, Batch 10, Loss: 0.19\n",
      "Training: Epoch 45, Batch 11, Loss: 0.175\n",
      "Training: Epoch 45, Batch 12, Loss: 0.211\n",
      "Training: Epoch 45, Batch 13, Loss: 0.209\n",
      "Training: Epoch 45, Batch 14, Loss: 0.245\n",
      "Training: Epoch 45, Batch 15, Loss: 0.276\n",
      "Training: Epoch 45, Batch 16, Loss: 0.184\n",
      "Training: Epoch 45, Batch 17, Loss: 0.243\n",
      "Training: Epoch 45, Batch 18, Loss: 0.207\n",
      "Training: Epoch 45, Batch 19, Loss: 0.186\n",
      "Val: Epoch 45, Loss: 0.256\n",
      "Training: Epoch 46, Batch 0, Loss: 0.152\n",
      "Training: Epoch 46, Batch 1, Loss: 0.196\n",
      "Training: Epoch 46, Batch 2, Loss: 0.191\n",
      "Training: Epoch 46, Batch 3, Loss: 0.206\n",
      "Training: Epoch 46, Batch 4, Loss: 0.238\n",
      "Training: Epoch 46, Batch 5, Loss: 0.163\n",
      "Training: Epoch 46, Batch 6, Loss: 0.229\n",
      "Training: Epoch 46, Batch 7, Loss: 0.188\n",
      "Training: Epoch 46, Batch 8, Loss: 0.211\n",
      "Training: Epoch 46, Batch 9, Loss: 0.289\n",
      "Training: Epoch 46, Batch 10, Loss: 0.226\n",
      "Training: Epoch 46, Batch 11, Loss: 0.173\n",
      "Training: Epoch 46, Batch 12, Loss: 0.257\n",
      "Training: Epoch 46, Batch 13, Loss: 0.255\n",
      "Training: Epoch 46, Batch 14, Loss: 0.191\n",
      "Training: Epoch 46, Batch 15, Loss: 0.183\n",
      "Training: Epoch 46, Batch 16, Loss: 0.22\n",
      "Training: Epoch 46, Batch 17, Loss: 0.239\n",
      "Training: Epoch 46, Batch 18, Loss: 0.214\n",
      "Training: Epoch 46, Batch 19, Loss: 0.201\n",
      "Val: Epoch 46, Loss: 0.264\n",
      "Training: Epoch 47, Batch 0, Loss: 0.195\n",
      "Training: Epoch 47, Batch 1, Loss: 0.288\n",
      "Training: Epoch 47, Batch 2, Loss: 0.234\n",
      "Training: Epoch 47, Batch 3, Loss: 0.258\n",
      "Training: Epoch 47, Batch 4, Loss: 0.221\n",
      "Training: Epoch 47, Batch 5, Loss: 0.201\n",
      "Training: Epoch 47, Batch 6, Loss: 0.163\n",
      "Training: Epoch 47, Batch 7, Loss: 0.205\n",
      "Training: Epoch 47, Batch 8, Loss: 0.231\n",
      "Training: Epoch 47, Batch 9, Loss: 0.24\n",
      "Training: Epoch 47, Batch 10, Loss: 0.212\n",
      "Training: Epoch 47, Batch 11, Loss: 0.165\n",
      "Training: Epoch 47, Batch 12, Loss: 0.154\n",
      "Training: Epoch 47, Batch 13, Loss: 0.26\n",
      "Training: Epoch 47, Batch 14, Loss: 0.268\n",
      "Training: Epoch 47, Batch 15, Loss: 0.176\n",
      "Training: Epoch 47, Batch 16, Loss: 0.159\n",
      "Training: Epoch 47, Batch 17, Loss: 0.269\n",
      "Training: Epoch 47, Batch 18, Loss: 0.186\n",
      "Training: Epoch 47, Batch 19, Loss: 0.225\n",
      "Val: Epoch 47, Loss: 0.263\n",
      "Training: Epoch 48, Batch 0, Loss: 0.216\n",
      "Training: Epoch 48, Batch 1, Loss: 0.19\n",
      "Training: Epoch 48, Batch 2, Loss: 0.192\n",
      "Training: Epoch 48, Batch 3, Loss: 0.169\n",
      "Training: Epoch 48, Batch 4, Loss: 0.151\n",
      "Training: Epoch 48, Batch 5, Loss: 0.236\n",
      "Training: Epoch 48, Batch 6, Loss: 0.183\n",
      "Training: Epoch 48, Batch 7, Loss: 0.24\n",
      "Training: Epoch 48, Batch 8, Loss: 0.224\n",
      "Training: Epoch 48, Batch 9, Loss: 0.18\n",
      "Training: Epoch 48, Batch 10, Loss: 0.186\n",
      "Training: Epoch 48, Batch 11, Loss: 0.331\n",
      "Training: Epoch 48, Batch 12, Loss: 0.179\n",
      "Training: Epoch 48, Batch 13, Loss: 0.242\n",
      "Training: Epoch 48, Batch 14, Loss: 0.163\n",
      "Training: Epoch 48, Batch 15, Loss: 0.241\n",
      "Training: Epoch 48, Batch 16, Loss: 0.257\n",
      "Training: Epoch 48, Batch 17, Loss: 0.171\n",
      "Training: Epoch 48, Batch 18, Loss: 0.218\n",
      "Training: Epoch 48, Batch 19, Loss: 0.387\n",
      "Val: Epoch 48, Loss: 0.277\n",
      "Training: Epoch 49, Batch 0, Loss: 0.213\n",
      "Training: Epoch 49, Batch 1, Loss: 0.198\n",
      "Training: Epoch 49, Batch 2, Loss: 0.146\n",
      "Training: Epoch 49, Batch 3, Loss: 0.182\n",
      "Training: Epoch 49, Batch 4, Loss: 0.177\n",
      "Training: Epoch 49, Batch 5, Loss: 0.182\n",
      "Training: Epoch 49, Batch 6, Loss: 0.237\n",
      "Training: Epoch 49, Batch 7, Loss: 0.179\n",
      "Training: Epoch 49, Batch 8, Loss: 0.293\n",
      "Training: Epoch 49, Batch 9, Loss: 0.333\n",
      "Training: Epoch 49, Batch 10, Loss: 0.172\n",
      "Training: Epoch 49, Batch 11, Loss: 0.219\n",
      "Training: Epoch 49, Batch 12, Loss: 0.166\n",
      "Training: Epoch 49, Batch 13, Loss: 0.227\n",
      "Training: Epoch 49, Batch 14, Loss: 0.181\n",
      "Training: Epoch 49, Batch 15, Loss: 0.281\n",
      "Training: Epoch 49, Batch 16, Loss: 0.235\n",
      "Training: Epoch 49, Batch 17, Loss: 0.2\n",
      "Training: Epoch 49, Batch 18, Loss: 0.186\n",
      "Training: Epoch 49, Batch 19, Loss: 0.201\n",
      "Val: Epoch 49, Loss: 0.27\n",
      "Training: Epoch 50, Batch 0, Loss: 0.24\n",
      "Training: Epoch 50, Batch 1, Loss: 0.295\n",
      "Training: Epoch 50, Batch 2, Loss: 0.164\n",
      "Training: Epoch 50, Batch 3, Loss: 0.166\n",
      "Training: Epoch 50, Batch 4, Loss: 0.192\n",
      "Training: Epoch 50, Batch 5, Loss: 0.258\n",
      "Training: Epoch 50, Batch 6, Loss: 0.233\n",
      "Training: Epoch 50, Batch 7, Loss: 0.151\n",
      "Training: Epoch 50, Batch 8, Loss: 0.229\n",
      "Training: Epoch 50, Batch 9, Loss: 0.246\n",
      "Training: Epoch 50, Batch 10, Loss: 0.263\n",
      "Training: Epoch 50, Batch 11, Loss: 0.257\n",
      "Training: Epoch 50, Batch 12, Loss: 0.279\n",
      "Training: Epoch 50, Batch 13, Loss: 0.197\n",
      "Training: Epoch 50, Batch 14, Loss: 0.23\n",
      "Training: Epoch 50, Batch 15, Loss: 0.296\n",
      "Training: Epoch 50, Batch 16, Loss: 0.224\n",
      "Training: Epoch 50, Batch 17, Loss: 0.2\n",
      "Training: Epoch 50, Batch 18, Loss: 0.153\n",
      "Training: Epoch 50, Batch 19, Loss: 0.212\n",
      "Val: Epoch 50, Loss: 0.396\n",
      "Training: Epoch 51, Batch 0, Loss: 0.268\n",
      "Training: Epoch 51, Batch 1, Loss: 0.194\n",
      "Training: Epoch 51, Batch 2, Loss: 0.173\n",
      "Training: Epoch 51, Batch 3, Loss: 0.189\n",
      "Training: Epoch 51, Batch 4, Loss: 0.242\n",
      "Training: Epoch 51, Batch 5, Loss: 0.209\n",
      "Training: Epoch 51, Batch 6, Loss: 0.171\n",
      "Training: Epoch 51, Batch 7, Loss: 0.137\n",
      "Training: Epoch 51, Batch 8, Loss: 0.194\n",
      "Training: Epoch 51, Batch 9, Loss: 0.215\n",
      "Training: Epoch 51, Batch 10, Loss: 0.211\n",
      "Training: Epoch 51, Batch 11, Loss: 0.157\n",
      "Training: Epoch 51, Batch 12, Loss: 0.209\n",
      "Training: Epoch 51, Batch 13, Loss: 0.166\n",
      "Training: Epoch 51, Batch 14, Loss: 0.213\n",
      "Training: Epoch 51, Batch 15, Loss: 0.225\n",
      "Training: Epoch 51, Batch 16, Loss: 0.268\n",
      "Training: Epoch 51, Batch 17, Loss: 0.146\n",
      "Training: Epoch 51, Batch 18, Loss: 0.155\n",
      "Training: Epoch 51, Batch 19, Loss: 0.207\n",
      "Val: Epoch 51, Loss: 0.256\n",
      "Training: Epoch 52, Batch 0, Loss: 0.29\n",
      "Training: Epoch 52, Batch 1, Loss: 0.178\n",
      "Training: Epoch 52, Batch 2, Loss: 0.137\n",
      "Training: Epoch 52, Batch 3, Loss: 0.268\n",
      "Training: Epoch 52, Batch 4, Loss: 0.189\n",
      "Training: Epoch 52, Batch 5, Loss: 0.201\n",
      "Training: Epoch 52, Batch 6, Loss: 0.178\n",
      "Training: Epoch 52, Batch 7, Loss: 0.303\n",
      "Training: Epoch 52, Batch 8, Loss: 0.192\n",
      "Training: Epoch 52, Batch 9, Loss: 0.187\n",
      "Training: Epoch 52, Batch 10, Loss: 0.198\n",
      "Training: Epoch 52, Batch 11, Loss: 0.169\n",
      "Training: Epoch 52, Batch 12, Loss: 0.245\n",
      "Training: Epoch 52, Batch 13, Loss: 0.172\n",
      "Training: Epoch 52, Batch 14, Loss: 0.195\n",
      "Training: Epoch 52, Batch 15, Loss: 0.223\n",
      "Training: Epoch 52, Batch 16, Loss: 0.155\n",
      "Training: Epoch 52, Batch 17, Loss: 0.204\n",
      "Training: Epoch 52, Batch 18, Loss: 0.22\n",
      "Training: Epoch 52, Batch 19, Loss: 0.186\n",
      "Val: Epoch 52, Loss: 0.297\n",
      "Training: Epoch 53, Batch 0, Loss: 0.241\n",
      "Training: Epoch 53, Batch 1, Loss: 0.168\n",
      "Training: Epoch 53, Batch 2, Loss: 0.198\n",
      "Training: Epoch 53, Batch 3, Loss: 0.215\n",
      "Training: Epoch 53, Batch 4, Loss: 0.177\n",
      "Training: Epoch 53, Batch 5, Loss: 0.241\n",
      "Training: Epoch 53, Batch 6, Loss: 0.301\n",
      "Training: Epoch 53, Batch 7, Loss: 0.145\n",
      "Training: Epoch 53, Batch 8, Loss: 0.167\n",
      "Training: Epoch 53, Batch 9, Loss: 0.186\n",
      "Training: Epoch 53, Batch 10, Loss: 0.155\n",
      "Training: Epoch 53, Batch 11, Loss: 0.177\n",
      "Training: Epoch 53, Batch 12, Loss: 0.164\n",
      "Training: Epoch 53, Batch 13, Loss: 0.17\n",
      "Training: Epoch 53, Batch 14, Loss: 0.194\n",
      "Training: Epoch 53, Batch 15, Loss: 0.325\n",
      "Training: Epoch 53, Batch 16, Loss: 0.145\n",
      "Training: Epoch 53, Batch 17, Loss: 0.16\n",
      "Training: Epoch 53, Batch 18, Loss: 0.18\n",
      "Training: Epoch 53, Batch 19, Loss: 0.286\n",
      "Val: Epoch 53, Loss: 0.276\n",
      "Training: Epoch 54, Batch 0, Loss: 0.287\n",
      "Training: Epoch 54, Batch 1, Loss: 0.229\n",
      "Training: Epoch 54, Batch 2, Loss: 0.188\n",
      "Training: Epoch 54, Batch 3, Loss: 0.233\n",
      "Training: Epoch 54, Batch 4, Loss: 0.235\n",
      "Training: Epoch 54, Batch 5, Loss: 0.159\n",
      "Training: Epoch 54, Batch 6, Loss: 0.309\n",
      "Training: Epoch 54, Batch 7, Loss: 0.17\n",
      "Training: Epoch 54, Batch 8, Loss: 0.288\n",
      "Training: Epoch 54, Batch 9, Loss: 0.203\n",
      "Training: Epoch 54, Batch 10, Loss: 0.175\n",
      "Training: Epoch 54, Batch 11, Loss: 0.149\n",
      "Training: Epoch 54, Batch 12, Loss: 0.211\n",
      "Training: Epoch 54, Batch 13, Loss: 0.283\n",
      "Training: Epoch 54, Batch 14, Loss: 0.37\n",
      "Training: Epoch 54, Batch 15, Loss: 0.289\n",
      "Training: Epoch 54, Batch 16, Loss: 0.161\n",
      "Training: Epoch 54, Batch 17, Loss: 0.266\n",
      "Training: Epoch 54, Batch 18, Loss: 0.167\n",
      "Training: Epoch 54, Batch 19, Loss: 0.257\n",
      "Val: Epoch 54, Loss: 0.302\n",
      "Training: Epoch 55, Batch 0, Loss: 0.169\n",
      "Training: Epoch 55, Batch 1, Loss: 0.211\n",
      "Training: Epoch 55, Batch 2, Loss: 0.241\n",
      "Training: Epoch 55, Batch 3, Loss: 0.2\n",
      "Training: Epoch 55, Batch 4, Loss: 0.173\n",
      "Training: Epoch 55, Batch 5, Loss: 0.191\n",
      "Training: Epoch 55, Batch 6, Loss: 0.222\n",
      "Training: Epoch 55, Batch 7, Loss: 0.223\n",
      "Training: Epoch 55, Batch 8, Loss: 0.22\n",
      "Training: Epoch 55, Batch 9, Loss: 0.251\n",
      "Training: Epoch 55, Batch 10, Loss: 0.17\n",
      "Training: Epoch 55, Batch 11, Loss: 0.166\n",
      "Training: Epoch 55, Batch 12, Loss: 0.179\n",
      "Training: Epoch 55, Batch 13, Loss: 0.201\n",
      "Training: Epoch 55, Batch 14, Loss: 0.221\n",
      "Training: Epoch 55, Batch 15, Loss: 0.128\n",
      "Training: Epoch 55, Batch 16, Loss: 0.248\n",
      "Training: Epoch 55, Batch 17, Loss: 0.226\n",
      "Training: Epoch 55, Batch 18, Loss: 0.171\n",
      "Training: Epoch 55, Batch 19, Loss: 0.253\n",
      "Val: Epoch 55, Loss: 0.264\n",
      "Training: Epoch 56, Batch 0, Loss: 0.173\n",
      "Training: Epoch 56, Batch 1, Loss: 0.213\n",
      "Training: Epoch 56, Batch 2, Loss: 0.195\n",
      "Training: Epoch 56, Batch 3, Loss: 0.18\n",
      "Training: Epoch 56, Batch 4, Loss: 0.157\n",
      "Training: Epoch 56, Batch 5, Loss: 0.171\n",
      "Training: Epoch 56, Batch 6, Loss: 0.196\n",
      "Training: Epoch 56, Batch 7, Loss: 0.171\n",
      "Training: Epoch 56, Batch 8, Loss: 0.224\n",
      "Training: Epoch 56, Batch 9, Loss: 0.169\n",
      "Training: Epoch 56, Batch 10, Loss: 0.186\n",
      "Training: Epoch 56, Batch 11, Loss: 0.197\n",
      "Training: Epoch 56, Batch 12, Loss: 0.19\n",
      "Training: Epoch 56, Batch 13, Loss: 0.248\n",
      "Training: Epoch 56, Batch 14, Loss: 0.143\n",
      "Training: Epoch 56, Batch 15, Loss: 0.234\n",
      "Training: Epoch 56, Batch 16, Loss: 0.243\n",
      "Training: Epoch 56, Batch 17, Loss: 0.192\n",
      "Training: Epoch 56, Batch 18, Loss: 0.239\n",
      "Training: Epoch 56, Batch 19, Loss: 0.193\n",
      "Val: Epoch 56, Loss: 0.312\n",
      "Training: Epoch 57, Batch 0, Loss: 0.191\n",
      "Training: Epoch 57, Batch 1, Loss: 0.153\n",
      "Training: Epoch 57, Batch 2, Loss: 0.179\n",
      "Training: Epoch 57, Batch 3, Loss: 0.255\n",
      "Training: Epoch 57, Batch 4, Loss: 0.152\n",
      "Training: Epoch 57, Batch 5, Loss: 0.229\n",
      "Training: Epoch 57, Batch 6, Loss: 0.164\n",
      "Training: Epoch 57, Batch 7, Loss: 0.277\n",
      "Training: Epoch 57, Batch 8, Loss: 0.174\n",
      "Training: Epoch 57, Batch 9, Loss: 0.188\n",
      "Training: Epoch 57, Batch 10, Loss: 0.162\n",
      "Training: Epoch 57, Batch 11, Loss: 0.174\n",
      "Training: Epoch 57, Batch 12, Loss: 0.174\n",
      "Training: Epoch 57, Batch 13, Loss: 0.195\n",
      "Training: Epoch 57, Batch 14, Loss: 0.195\n",
      "Training: Epoch 57, Batch 15, Loss: 0.183\n",
      "Training: Epoch 57, Batch 16, Loss: 0.167\n",
      "Training: Epoch 57, Batch 17, Loss: 0.157\n",
      "Training: Epoch 57, Batch 18, Loss: 0.141\n",
      "Training: Epoch 57, Batch 19, Loss: 0.219\n",
      "Val: Epoch 57, Loss: 0.346\n",
      "Training: Epoch 58, Batch 0, Loss: 0.233\n",
      "Training: Epoch 58, Batch 1, Loss: 0.18\n",
      "Training: Epoch 58, Batch 2, Loss: 0.13\n",
      "Training: Epoch 58, Batch 3, Loss: 0.148\n",
      "Training: Epoch 58, Batch 4, Loss: 0.218\n",
      "Training: Epoch 58, Batch 5, Loss: 0.204\n",
      "Training: Epoch 58, Batch 6, Loss: 0.226\n",
      "Training: Epoch 58, Batch 7, Loss: 0.254\n",
      "Training: Epoch 58, Batch 8, Loss: 0.343\n",
      "Training: Epoch 58, Batch 9, Loss: 0.185\n",
      "Training: Epoch 58, Batch 10, Loss: 0.252\n",
      "Training: Epoch 58, Batch 11, Loss: 0.212\n",
      "Training: Epoch 58, Batch 12, Loss: 0.163\n",
      "Training: Epoch 58, Batch 13, Loss: 0.211\n",
      "Training: Epoch 58, Batch 14, Loss: 0.255\n",
      "Training: Epoch 58, Batch 15, Loss: 0.211\n",
      "Training: Epoch 58, Batch 16, Loss: 0.174\n",
      "Training: Epoch 58, Batch 17, Loss: 0.182\n",
      "Training: Epoch 58, Batch 18, Loss: 0.136\n",
      "Training: Epoch 58, Batch 19, Loss: 0.154\n",
      "Val: Epoch 58, Loss: 0.347\n",
      "Training: Epoch 59, Batch 0, Loss: 0.246\n",
      "Training: Epoch 59, Batch 1, Loss: 0.214\n",
      "Training: Epoch 59, Batch 2, Loss: 0.181\n",
      "Training: Epoch 59, Batch 3, Loss: 0.182\n",
      "Training: Epoch 59, Batch 4, Loss: 0.17\n",
      "Training: Epoch 59, Batch 5, Loss: 0.286\n",
      "Training: Epoch 59, Batch 6, Loss: 0.184\n",
      "Training: Epoch 59, Batch 7, Loss: 0.19\n",
      "Training: Epoch 59, Batch 8, Loss: 0.142\n",
      "Training: Epoch 59, Batch 9, Loss: 0.191\n",
      "Training: Epoch 59, Batch 10, Loss: 0.178\n",
      "Training: Epoch 59, Batch 11, Loss: 0.153\n",
      "Training: Epoch 59, Batch 12, Loss: 0.159\n",
      "Training: Epoch 59, Batch 13, Loss: 0.168\n",
      "Training: Epoch 59, Batch 14, Loss: 0.123\n",
      "Training: Epoch 59, Batch 15, Loss: 0.134\n",
      "Training: Epoch 59, Batch 16, Loss: 0.243\n",
      "Training: Epoch 59, Batch 17, Loss: 0.163\n",
      "Training: Epoch 59, Batch 18, Loss: 0.137\n",
      "Training: Epoch 59, Batch 19, Loss: 0.159\n",
      "Val: Epoch 59, Loss: 0.266\n",
      "Training: Epoch 60, Batch 0, Loss: 0.153\n",
      "Training: Epoch 60, Batch 1, Loss: 0.167\n",
      "Training: Epoch 60, Batch 2, Loss: 0.22\n",
      "Training: Epoch 60, Batch 3, Loss: 0.183\n",
      "Training: Epoch 60, Batch 4, Loss: 0.127\n",
      "Training: Epoch 60, Batch 5, Loss: 0.21\n",
      "Training: Epoch 60, Batch 6, Loss: 0.251\n",
      "Training: Epoch 60, Batch 7, Loss: 0.157\n",
      "Training: Epoch 60, Batch 8, Loss: 0.204\n",
      "Training: Epoch 60, Batch 9, Loss: 0.219\n",
      "Training: Epoch 60, Batch 10, Loss: 0.129\n",
      "Training: Epoch 60, Batch 11, Loss: 0.133\n",
      "Training: Epoch 60, Batch 12, Loss: 0.167\n",
      "Training: Epoch 60, Batch 13, Loss: 0.163\n",
      "Training: Epoch 60, Batch 14, Loss: 0.191\n",
      "Training: Epoch 60, Batch 15, Loss: 0.173\n",
      "Training: Epoch 60, Batch 16, Loss: 0.176\n",
      "Training: Epoch 60, Batch 17, Loss: 0.169\n",
      "Training: Epoch 60, Batch 18, Loss: 0.206\n",
      "Training: Epoch 60, Batch 19, Loss: 0.197\n",
      "Val: Epoch 60, Loss: 0.274\n",
      "Training: Epoch 61, Batch 0, Loss: 0.154\n",
      "Training: Epoch 61, Batch 1, Loss: 0.158\n",
      "Training: Epoch 61, Batch 2, Loss: 0.193\n",
      "Training: Epoch 61, Batch 3, Loss: 0.161\n",
      "Training: Epoch 61, Batch 4, Loss: 0.201\n",
      "Training: Epoch 61, Batch 5, Loss: 0.231\n",
      "Training: Epoch 61, Batch 6, Loss: 0.22\n",
      "Training: Epoch 61, Batch 7, Loss: 0.16\n",
      "Training: Epoch 61, Batch 8, Loss: 0.222\n",
      "Training: Epoch 61, Batch 9, Loss: 0.152\n",
      "Training: Epoch 61, Batch 10, Loss: 0.159\n",
      "Training: Epoch 61, Batch 11, Loss: 0.225\n",
      "Training: Epoch 61, Batch 12, Loss: 0.195\n",
      "Training: Epoch 61, Batch 13, Loss: 0.153\n",
      "Training: Epoch 61, Batch 14, Loss: 0.177\n",
      "Training: Epoch 61, Batch 15, Loss: 0.163\n",
      "Training: Epoch 61, Batch 16, Loss: 0.22\n",
      "Training: Epoch 61, Batch 17, Loss: 0.145\n",
      "Training: Epoch 61, Batch 18, Loss: 0.166\n",
      "Training: Epoch 61, Batch 19, Loss: 0.151\n",
      "Val: Epoch 61, Loss: 0.247\n",
      "Training: Epoch 62, Batch 0, Loss: 0.175\n",
      "Training: Epoch 62, Batch 1, Loss: 0.165\n",
      "Training: Epoch 62, Batch 2, Loss: 0.167\n",
      "Training: Epoch 62, Batch 3, Loss: 0.166\n",
      "Training: Epoch 62, Batch 4, Loss: 0.177\n",
      "Training: Epoch 62, Batch 5, Loss: 0.185\n",
      "Training: Epoch 62, Batch 6, Loss: 0.129\n",
      "Training: Epoch 62, Batch 7, Loss: 0.163\n",
      "Training: Epoch 62, Batch 8, Loss: 0.19\n",
      "Training: Epoch 62, Batch 9, Loss: 0.17\n",
      "Training: Epoch 62, Batch 10, Loss: 0.294\n",
      "Training: Epoch 62, Batch 11, Loss: 0.155\n",
      "Training: Epoch 62, Batch 12, Loss: 0.17\n",
      "Training: Epoch 62, Batch 13, Loss: 0.171\n",
      "Training: Epoch 62, Batch 14, Loss: 0.177\n",
      "Training: Epoch 62, Batch 15, Loss: 0.283\n",
      "Training: Epoch 62, Batch 16, Loss: 0.179\n",
      "Training: Epoch 62, Batch 17, Loss: 0.15\n",
      "Training: Epoch 62, Batch 18, Loss: 0.201\n",
      "Training: Epoch 62, Batch 19, Loss: 0.232\n",
      "Val: Epoch 62, Loss: 0.267\n",
      "Training: Epoch 63, Batch 0, Loss: 0.136\n",
      "Training: Epoch 63, Batch 1, Loss: 0.267\n",
      "Training: Epoch 63, Batch 2, Loss: 0.167\n",
      "Training: Epoch 63, Batch 3, Loss: 0.247\n",
      "Training: Epoch 63, Batch 4, Loss: 0.138\n",
      "Training: Epoch 63, Batch 5, Loss: 0.174\n",
      "Training: Epoch 63, Batch 6, Loss: 0.241\n",
      "Training: Epoch 63, Batch 7, Loss: 0.163\n",
      "Training: Epoch 63, Batch 8, Loss: 0.169\n",
      "Training: Epoch 63, Batch 9, Loss: 0.21\n",
      "Training: Epoch 63, Batch 10, Loss: 0.196\n",
      "Training: Epoch 63, Batch 11, Loss: 0.162\n",
      "Training: Epoch 63, Batch 12, Loss: 0.246\n",
      "Training: Epoch 63, Batch 13, Loss: 0.163\n",
      "Training: Epoch 63, Batch 14, Loss: 0.143\n",
      "Training: Epoch 63, Batch 15, Loss: 0.162\n",
      "Training: Epoch 63, Batch 16, Loss: 0.196\n",
      "Training: Epoch 63, Batch 17, Loss: 0.168\n",
      "Training: Epoch 63, Batch 18, Loss: 0.139\n",
      "Training: Epoch 63, Batch 19, Loss: 0.203\n",
      "Val: Epoch 63, Loss: 0.273\n",
      "Training: Epoch 64, Batch 0, Loss: 0.207\n",
      "Training: Epoch 64, Batch 1, Loss: 0.17\n",
      "Training: Epoch 64, Batch 2, Loss: 0.165\n",
      "Training: Epoch 64, Batch 3, Loss: 0.163\n",
      "Training: Epoch 64, Batch 4, Loss: 0.154\n",
      "Training: Epoch 64, Batch 5, Loss: 0.209\n",
      "Training: Epoch 64, Batch 6, Loss: 0.155\n",
      "Training: Epoch 64, Batch 7, Loss: 0.14\n",
      "Training: Epoch 64, Batch 8, Loss: 0.16\n",
      "Training: Epoch 64, Batch 9, Loss: 0.158\n",
      "Training: Epoch 64, Batch 10, Loss: 0.255\n",
      "Training: Epoch 64, Batch 11, Loss: 0.277\n",
      "Training: Epoch 64, Batch 12, Loss: 0.168\n",
      "Training: Epoch 64, Batch 13, Loss: 0.192\n",
      "Training: Epoch 64, Batch 14, Loss: 0.22\n",
      "Training: Epoch 64, Batch 15, Loss: 0.219\n",
      "Training: Epoch 64, Batch 16, Loss: 0.192\n",
      "Training: Epoch 64, Batch 17, Loss: 0.191\n",
      "Training: Epoch 64, Batch 18, Loss: 0.164\n",
      "Training: Epoch 64, Batch 19, Loss: 0.146\n",
      "Val: Epoch 64, Loss: 0.267\n",
      "Training: Epoch 65, Batch 0, Loss: 0.174\n",
      "Training: Epoch 65, Batch 1, Loss: 0.178\n",
      "Training: Epoch 65, Batch 2, Loss: 0.199\n",
      "Training: Epoch 65, Batch 3, Loss: 0.161\n",
      "Training: Epoch 65, Batch 4, Loss: 0.216\n",
      "Training: Epoch 65, Batch 5, Loss: 0.211\n",
      "Training: Epoch 65, Batch 6, Loss: 0.138\n",
      "Training: Epoch 65, Batch 7, Loss: 0.209\n",
      "Training: Epoch 65, Batch 8, Loss: 0.188\n",
      "Training: Epoch 65, Batch 9, Loss: 0.145\n",
      "Training: Epoch 65, Batch 10, Loss: 0.192\n",
      "Training: Epoch 65, Batch 11, Loss: 0.264\n",
      "Training: Epoch 65, Batch 12, Loss: 0.165\n",
      "Training: Epoch 65, Batch 13, Loss: 0.139\n",
      "Training: Epoch 65, Batch 14, Loss: 0.186\n",
      "Training: Epoch 65, Batch 15, Loss: 0.172\n",
      "Training: Epoch 65, Batch 16, Loss: 0.183\n",
      "Training: Epoch 65, Batch 17, Loss: 0.204\n",
      "Training: Epoch 65, Batch 18, Loss: 0.16\n",
      "Training: Epoch 65, Batch 19, Loss: 0.164\n",
      "Val: Epoch 65, Loss: 0.257\n",
      "Training: Epoch 66, Batch 0, Loss: 0.254\n",
      "Training: Epoch 66, Batch 1, Loss: 0.156\n",
      "Training: Epoch 66, Batch 2, Loss: 0.186\n",
      "Training: Epoch 66, Batch 3, Loss: 0.12\n",
      "Training: Epoch 66, Batch 4, Loss: 0.185\n",
      "Training: Epoch 66, Batch 5, Loss: 0.144\n",
      "Training: Epoch 66, Batch 6, Loss: 0.202\n",
      "Training: Epoch 66, Batch 7, Loss: 0.161\n",
      "Training: Epoch 66, Batch 8, Loss: 0.219\n",
      "Training: Epoch 66, Batch 9, Loss: 0.169\n",
      "Training: Epoch 66, Batch 10, Loss: 0.162\n",
      "Training: Epoch 66, Batch 11, Loss: 0.184\n",
      "Training: Epoch 66, Batch 12, Loss: 0.175\n",
      "Training: Epoch 66, Batch 13, Loss: 0.203\n",
      "Training: Epoch 66, Batch 14, Loss: 0.168\n",
      "Training: Epoch 66, Batch 15, Loss: 0.19\n",
      "Training: Epoch 66, Batch 16, Loss: 0.17\n",
      "Training: Epoch 66, Batch 17, Loss: 0.137\n",
      "Training: Epoch 66, Batch 18, Loss: 0.15\n",
      "Training: Epoch 66, Batch 19, Loss: 0.145\n",
      "Val: Epoch 66, Loss: 0.323\n",
      "Training: Epoch 67, Batch 0, Loss: 0.178\n",
      "Training: Epoch 67, Batch 1, Loss: 0.173\n",
      "Training: Epoch 67, Batch 2, Loss: 0.189\n",
      "Training: Epoch 67, Batch 3, Loss: 0.173\n",
      "Training: Epoch 67, Batch 4, Loss: 0.219\n",
      "Training: Epoch 67, Batch 5, Loss: 0.182\n",
      "Training: Epoch 67, Batch 6, Loss: 0.204\n",
      "Training: Epoch 67, Batch 7, Loss: 0.152\n",
      "Training: Epoch 67, Batch 8, Loss: 0.178\n",
      "Training: Epoch 67, Batch 9, Loss: 0.153\n",
      "Training: Epoch 67, Batch 10, Loss: 0.23\n",
      "Training: Epoch 67, Batch 11, Loss: 0.168\n",
      "Training: Epoch 67, Batch 12, Loss: 0.13\n",
      "Training: Epoch 67, Batch 13, Loss: 0.18\n",
      "Training: Epoch 67, Batch 14, Loss: 0.201\n",
      "Training: Epoch 67, Batch 15, Loss: 0.254\n",
      "Training: Epoch 67, Batch 16, Loss: 0.13\n",
      "Training: Epoch 67, Batch 17, Loss: 0.171\n",
      "Training: Epoch 67, Batch 18, Loss: 0.191\n",
      "Training: Epoch 67, Batch 19, Loss: 0.13\n",
      "Val: Epoch 67, Loss: 0.357\n",
      "Training: Epoch 68, Batch 0, Loss: 0.162\n",
      "Training: Epoch 68, Batch 1, Loss: 0.17\n",
      "Training: Epoch 68, Batch 2, Loss: 0.181\n",
      "Training: Epoch 68, Batch 3, Loss: 0.17\n",
      "Training: Epoch 68, Batch 4, Loss: 0.187\n",
      "Training: Epoch 68, Batch 5, Loss: 0.151\n",
      "Training: Epoch 68, Batch 6, Loss: 0.244\n",
      "Training: Epoch 68, Batch 7, Loss: 0.141\n",
      "Training: Epoch 68, Batch 8, Loss: 0.14\n",
      "Training: Epoch 68, Batch 9, Loss: 0.194\n",
      "Training: Epoch 68, Batch 10, Loss: 0.215\n",
      "Training: Epoch 68, Batch 11, Loss: 0.232\n",
      "Training: Epoch 68, Batch 12, Loss: 0.199\n",
      "Training: Epoch 68, Batch 13, Loss: 0.201\n",
      "Training: Epoch 68, Batch 14, Loss: 0.195\n",
      "Training: Epoch 68, Batch 15, Loss: 0.24\n",
      "Training: Epoch 68, Batch 16, Loss: 0.158\n",
      "Training: Epoch 68, Batch 17, Loss: 0.161\n",
      "Training: Epoch 68, Batch 18, Loss: 0.18\n",
      "Training: Epoch 68, Batch 19, Loss: 0.147\n",
      "Val: Epoch 68, Loss: 0.248\n",
      "Training: Epoch 69, Batch 0, Loss: 0.161\n",
      "Training: Epoch 69, Batch 1, Loss: 0.239\n",
      "Training: Epoch 69, Batch 2, Loss: 0.153\n",
      "Training: Epoch 69, Batch 3, Loss: 0.171\n",
      "Training: Epoch 69, Batch 4, Loss: 0.232\n",
      "Training: Epoch 69, Batch 5, Loss: 0.188\n",
      "Training: Epoch 69, Batch 6, Loss: 0.218\n",
      "Training: Epoch 69, Batch 7, Loss: 0.138\n",
      "Training: Epoch 69, Batch 8, Loss: 0.18\n",
      "Training: Epoch 69, Batch 9, Loss: 0.188\n",
      "Training: Epoch 69, Batch 10, Loss: 0.149\n",
      "Training: Epoch 69, Batch 11, Loss: 0.239\n",
      "Training: Epoch 69, Batch 12, Loss: 0.158\n",
      "Training: Epoch 69, Batch 13, Loss: 0.214\n",
      "Training: Epoch 69, Batch 14, Loss: 0.109\n",
      "Training: Epoch 69, Batch 15, Loss: 0.186\n",
      "Training: Epoch 69, Batch 16, Loss: 0.135\n",
      "Training: Epoch 69, Batch 17, Loss: 0.156\n",
      "Training: Epoch 69, Batch 18, Loss: 0.223\n",
      "Training: Epoch 69, Batch 19, Loss: 0.164\n",
      "Val: Epoch 69, Loss: 0.263\n",
      "Training: Epoch 70, Batch 0, Loss: 0.182\n",
      "Training: Epoch 70, Batch 1, Loss: 0.168\n",
      "Training: Epoch 70, Batch 2, Loss: 0.146\n",
      "Training: Epoch 70, Batch 3, Loss: 0.232\n",
      "Training: Epoch 70, Batch 4, Loss: 0.132\n",
      "Training: Epoch 70, Batch 5, Loss: 0.218\n",
      "Training: Epoch 70, Batch 6, Loss: 0.221\n",
      "Training: Epoch 70, Batch 7, Loss: 0.191\n",
      "Training: Epoch 70, Batch 8, Loss: 0.158\n",
      "Training: Epoch 70, Batch 9, Loss: 0.163\n",
      "Training: Epoch 70, Batch 10, Loss: 0.21\n",
      "Training: Epoch 70, Batch 11, Loss: 0.149\n",
      "Training: Epoch 70, Batch 12, Loss: 0.145\n",
      "Training: Epoch 70, Batch 13, Loss: 0.145\n",
      "Training: Epoch 70, Batch 14, Loss: 0.131\n",
      "Training: Epoch 70, Batch 15, Loss: 0.169\n",
      "Training: Epoch 70, Batch 16, Loss: 0.165\n",
      "Training: Epoch 70, Batch 17, Loss: 0.187\n",
      "Training: Epoch 70, Batch 18, Loss: 0.168\n",
      "Training: Epoch 70, Batch 19, Loss: 0.167\n",
      "Val: Epoch 70, Loss: 0.268\n",
      "Training: Epoch 71, Batch 0, Loss: 0.175\n",
      "Training: Epoch 71, Batch 1, Loss: 0.13\n",
      "Training: Epoch 71, Batch 2, Loss: 0.122\n",
      "Training: Epoch 71, Batch 3, Loss: 0.233\n",
      "Training: Epoch 71, Batch 4, Loss: 0.157\n",
      "Training: Epoch 71, Batch 5, Loss: 0.198\n",
      "Training: Epoch 71, Batch 6, Loss: 0.2\n",
      "Training: Epoch 71, Batch 7, Loss: 0.165\n",
      "Training: Epoch 71, Batch 8, Loss: 0.181\n",
      "Training: Epoch 71, Batch 9, Loss: 0.139\n",
      "Training: Epoch 71, Batch 10, Loss: 0.166\n",
      "Training: Epoch 71, Batch 11, Loss: 0.195\n",
      "Training: Epoch 71, Batch 12, Loss: 0.162\n",
      "Training: Epoch 71, Batch 13, Loss: 0.183\n",
      "Training: Epoch 71, Batch 14, Loss: 0.145\n",
      "Training: Epoch 71, Batch 15, Loss: 0.14\n",
      "Training: Epoch 71, Batch 16, Loss: 0.165\n",
      "Training: Epoch 71, Batch 17, Loss: 0.18\n",
      "Training: Epoch 71, Batch 18, Loss: 0.143\n",
      "Training: Epoch 71, Batch 19, Loss: 0.133\n",
      "Val: Epoch 71, Loss: 0.278\n",
      "Training: Epoch 72, Batch 0, Loss: 0.142\n",
      "Training: Epoch 72, Batch 1, Loss: 0.135\n",
      "Training: Epoch 72, Batch 2, Loss: 0.183\n",
      "Training: Epoch 72, Batch 3, Loss: 0.174\n",
      "Training: Epoch 72, Batch 4, Loss: 0.175\n",
      "Training: Epoch 72, Batch 5, Loss: 0.233\n",
      "Training: Epoch 72, Batch 6, Loss: 0.229\n",
      "Training: Epoch 72, Batch 7, Loss: 0.154\n",
      "Training: Epoch 72, Batch 8, Loss: 0.178\n",
      "Training: Epoch 72, Batch 9, Loss: 0.142\n",
      "Training: Epoch 72, Batch 10, Loss: 0.15\n",
      "Training: Epoch 72, Batch 11, Loss: 0.206\n",
      "Training: Epoch 72, Batch 12, Loss: 0.148\n",
      "Training: Epoch 72, Batch 13, Loss: 0.193\n",
      "Training: Epoch 72, Batch 14, Loss: 0.173\n",
      "Training: Epoch 72, Batch 15, Loss: 0.127\n",
      "Training: Epoch 72, Batch 16, Loss: 0.146\n",
      "Training: Epoch 72, Batch 17, Loss: 0.183\n",
      "Training: Epoch 72, Batch 18, Loss: 0.157\n",
      "Training: Epoch 72, Batch 19, Loss: 0.148\n",
      "Val: Epoch 72, Loss: 0.264\n",
      "Training: Epoch 73, Batch 0, Loss: 0.15\n",
      "Training: Epoch 73, Batch 1, Loss: 0.16\n",
      "Training: Epoch 73, Batch 2, Loss: 0.116\n",
      "Training: Epoch 73, Batch 3, Loss: 0.179\n",
      "Training: Epoch 73, Batch 4, Loss: 0.15\n",
      "Training: Epoch 73, Batch 5, Loss: 0.23\n",
      "Training: Epoch 73, Batch 6, Loss: 0.172\n",
      "Training: Epoch 73, Batch 7, Loss: 0.145\n",
      "Training: Epoch 73, Batch 8, Loss: 0.153\n",
      "Training: Epoch 73, Batch 9, Loss: 0.119\n",
      "Training: Epoch 73, Batch 10, Loss: 0.164\n",
      "Training: Epoch 73, Batch 11, Loss: 0.164\n",
      "Training: Epoch 73, Batch 12, Loss: 0.16\n",
      "Training: Epoch 73, Batch 13, Loss: 0.113\n",
      "Training: Epoch 73, Batch 14, Loss: 0.187\n",
      "Training: Epoch 73, Batch 15, Loss: 0.166\n",
      "Training: Epoch 73, Batch 16, Loss: 0.178\n",
      "Training: Epoch 73, Batch 17, Loss: 0.156\n",
      "Training: Epoch 73, Batch 18, Loss: 0.177\n",
      "Training: Epoch 73, Batch 19, Loss: 0.218\n",
      "Val: Epoch 73, Loss: 0.262\n",
      "Training: Epoch 74, Batch 0, Loss: 0.122\n",
      "Training: Epoch 74, Batch 1, Loss: 0.131\n",
      "Training: Epoch 74, Batch 2, Loss: 0.135\n",
      "Training: Epoch 74, Batch 3, Loss: 0.165\n",
      "Training: Epoch 74, Batch 4, Loss: 0.186\n",
      "Training: Epoch 74, Batch 5, Loss: 0.197\n",
      "Training: Epoch 74, Batch 6, Loss: 0.147\n",
      "Training: Epoch 74, Batch 7, Loss: 0.171\n",
      "Training: Epoch 74, Batch 8, Loss: 0.213\n",
      "Training: Epoch 74, Batch 9, Loss: 0.144\n",
      "Training: Epoch 74, Batch 10, Loss: 0.276\n",
      "Training: Epoch 74, Batch 11, Loss: 0.198\n",
      "Training: Epoch 74, Batch 12, Loss: 0.154\n",
      "Training: Epoch 74, Batch 13, Loss: 0.152\n",
      "Training: Epoch 74, Batch 14, Loss: 0.19\n",
      "Training: Epoch 74, Batch 15, Loss: 0.192\n",
      "Training: Epoch 74, Batch 16, Loss: 0.133\n",
      "Training: Epoch 74, Batch 17, Loss: 0.132\n",
      "Training: Epoch 74, Batch 18, Loss: 0.157\n",
      "Training: Epoch 74, Batch 19, Loss: 0.176\n",
      "Val: Epoch 74, Loss: 0.275\n",
      "Training: Epoch 75, Batch 0, Loss: 0.157\n",
      "Training: Epoch 75, Batch 1, Loss: 0.173\n",
      "Training: Epoch 75, Batch 2, Loss: 0.175\n",
      "Training: Epoch 75, Batch 3, Loss: 0.245\n",
      "Training: Epoch 75, Batch 4, Loss: 0.111\n",
      "Training: Epoch 75, Batch 5, Loss: 0.179\n",
      "Training: Epoch 75, Batch 6, Loss: 0.126\n",
      "Training: Epoch 75, Batch 7, Loss: 0.167\n",
      "Training: Epoch 75, Batch 8, Loss: 0.195\n",
      "Training: Epoch 75, Batch 9, Loss: 0.162\n",
      "Training: Epoch 75, Batch 10, Loss: 0.152\n",
      "Training: Epoch 75, Batch 11, Loss: 0.189\n",
      "Training: Epoch 75, Batch 12, Loss: 0.262\n",
      "Training: Epoch 75, Batch 13, Loss: 0.137\n",
      "Training: Epoch 75, Batch 14, Loss: 0.222\n",
      "Training: Epoch 75, Batch 15, Loss: 0.145\n",
      "Training: Epoch 75, Batch 16, Loss: 0.159\n",
      "Training: Epoch 75, Batch 17, Loss: 0.14\n",
      "Training: Epoch 75, Batch 18, Loss: 0.148\n",
      "Training: Epoch 75, Batch 19, Loss: 0.208\n",
      "Val: Epoch 75, Loss: 0.295\n",
      "Training: Epoch 76, Batch 0, Loss: 0.135\n",
      "Training: Epoch 76, Batch 1, Loss: 0.168\n",
      "Training: Epoch 76, Batch 2, Loss: 0.14\n",
      "Training: Epoch 76, Batch 3, Loss: 0.179\n",
      "Training: Epoch 76, Batch 4, Loss: 0.116\n",
      "Training: Epoch 76, Batch 5, Loss: 0.182\n",
      "Training: Epoch 76, Batch 6, Loss: 0.138\n",
      "Training: Epoch 76, Batch 7, Loss: 0.15\n",
      "Training: Epoch 76, Batch 8, Loss: 0.135\n",
      "Training: Epoch 76, Batch 9, Loss: 0.194\n",
      "Training: Epoch 76, Batch 10, Loss: 0.176\n",
      "Training: Epoch 76, Batch 11, Loss: 0.134\n",
      "Training: Epoch 76, Batch 12, Loss: 0.2\n",
      "Training: Epoch 76, Batch 13, Loss: 0.154\n",
      "Training: Epoch 76, Batch 14, Loss: 0.142\n",
      "Training: Epoch 76, Batch 15, Loss: 0.183\n",
      "Training: Epoch 76, Batch 16, Loss: 0.174\n",
      "Training: Epoch 76, Batch 17, Loss: 0.147\n",
      "Training: Epoch 76, Batch 18, Loss: 0.223\n",
      "Training: Epoch 76, Batch 19, Loss: 0.17\n",
      "Val: Epoch 76, Loss: 0.265\n",
      "Training: Epoch 77, Batch 0, Loss: 0.138\n",
      "Training: Epoch 77, Batch 1, Loss: 0.147\n",
      "Training: Epoch 77, Batch 2, Loss: 0.183\n",
      "Training: Epoch 77, Batch 3, Loss: 0.168\n",
      "Training: Epoch 77, Batch 4, Loss: 0.185\n",
      "Training: Epoch 77, Batch 5, Loss: 0.221\n",
      "Training: Epoch 77, Batch 6, Loss: 0.22\n",
      "Training: Epoch 77, Batch 7, Loss: 0.182\n",
      "Training: Epoch 77, Batch 8, Loss: 0.122\n",
      "Training: Epoch 77, Batch 9, Loss: 0.196\n",
      "Training: Epoch 77, Batch 10, Loss: 0.147\n",
      "Training: Epoch 77, Batch 11, Loss: 0.176\n",
      "Training: Epoch 77, Batch 12, Loss: 0.182\n",
      "Training: Epoch 77, Batch 13, Loss: 0.258\n",
      "Training: Epoch 77, Batch 14, Loss: 0.151\n",
      "Training: Epoch 77, Batch 15, Loss: 0.19\n",
      "Training: Epoch 77, Batch 16, Loss: 0.208\n",
      "Training: Epoch 77, Batch 17, Loss: 0.431\n",
      "Training: Epoch 77, Batch 18, Loss: 0.182\n",
      "Training: Epoch 77, Batch 19, Loss: 0.131\n",
      "Val: Epoch 77, Loss: 0.308\n",
      "Training: Epoch 78, Batch 0, Loss: 0.164\n",
      "Training: Epoch 78, Batch 1, Loss: 0.234\n",
      "Training: Epoch 78, Batch 2, Loss: 0.336\n",
      "Training: Epoch 78, Batch 3, Loss: 0.262\n",
      "Training: Epoch 78, Batch 4, Loss: 0.284\n",
      "Training: Epoch 78, Batch 5, Loss: 0.189\n",
      "Training: Epoch 78, Batch 6, Loss: 0.163\n",
      "Training: Epoch 78, Batch 7, Loss: 0.2\n",
      "Training: Epoch 78, Batch 8, Loss: 0.209\n",
      "Training: Epoch 78, Batch 9, Loss: 0.231\n",
      "Training: Epoch 78, Batch 10, Loss: 0.181\n",
      "Training: Epoch 78, Batch 11, Loss: 0.145\n",
      "Training: Epoch 78, Batch 12, Loss: 0.184\n",
      "Training: Epoch 78, Batch 13, Loss: 0.368\n",
      "Training: Epoch 78, Batch 14, Loss: 0.135\n",
      "Training: Epoch 78, Batch 15, Loss: 0.204\n",
      "Training: Epoch 78, Batch 16, Loss: 0.21\n",
      "Training: Epoch 78, Batch 17, Loss: 0.154\n",
      "Training: Epoch 78, Batch 18, Loss: 0.198\n",
      "Training: Epoch 78, Batch 19, Loss: 0.202\n",
      "Val: Epoch 78, Loss: 0.263\n",
      "Training: Epoch 79, Batch 0, Loss: 0.19\n",
      "Training: Epoch 79, Batch 1, Loss: 0.136\n",
      "Training: Epoch 79, Batch 2, Loss: 0.175\n",
      "Training: Epoch 79, Batch 3, Loss: 0.152\n",
      "Training: Epoch 79, Batch 4, Loss: 0.216\n",
      "Training: Epoch 79, Batch 5, Loss: 0.122\n",
      "Training: Epoch 79, Batch 6, Loss: 0.174\n",
      "Training: Epoch 79, Batch 7, Loss: 0.218\n",
      "Training: Epoch 79, Batch 8, Loss: 0.205\n",
      "Training: Epoch 79, Batch 9, Loss: 0.162\n",
      "Training: Epoch 79, Batch 10, Loss: 0.217\n",
      "Training: Epoch 79, Batch 11, Loss: 0.179\n",
      "Training: Epoch 79, Batch 12, Loss: 0.163\n",
      "Training: Epoch 79, Batch 13, Loss: 0.166\n",
      "Training: Epoch 79, Batch 14, Loss: 0.142\n",
      "Training: Epoch 79, Batch 15, Loss: 0.215\n",
      "Training: Epoch 79, Batch 16, Loss: 0.166\n",
      "Training: Epoch 79, Batch 17, Loss: 0.174\n",
      "Training: Epoch 79, Batch 18, Loss: 0.137\n",
      "Training: Epoch 79, Batch 19, Loss: 0.133\n",
      "Val: Epoch 79, Loss: 0.233\n",
      "Training: Epoch 80, Batch 0, Loss: 0.188\n",
      "Training: Epoch 80, Batch 1, Loss: 0.162\n",
      "Training: Epoch 80, Batch 2, Loss: 0.183\n",
      "Training: Epoch 80, Batch 3, Loss: 0.158\n",
      "Training: Epoch 80, Batch 4, Loss: 0.141\n",
      "Training: Epoch 80, Batch 5, Loss: 0.16\n",
      "Training: Epoch 80, Batch 6, Loss: 0.23\n",
      "Training: Epoch 80, Batch 7, Loss: 0.205\n",
      "Training: Epoch 80, Batch 8, Loss: 0.15\n",
      "Training: Epoch 80, Batch 9, Loss: 0.137\n",
      "Training: Epoch 80, Batch 10, Loss: 0.168\n",
      "Training: Epoch 80, Batch 11, Loss: 0.174\n",
      "Training: Epoch 80, Batch 12, Loss: 0.177\n",
      "Training: Epoch 80, Batch 13, Loss: 0.159\n",
      "Training: Epoch 80, Batch 14, Loss: 0.236\n",
      "Training: Epoch 80, Batch 15, Loss: 0.208\n",
      "Training: Epoch 80, Batch 16, Loss: 0.144\n",
      "Training: Epoch 80, Batch 17, Loss: 0.147\n",
      "Training: Epoch 80, Batch 18, Loss: 0.189\n",
      "Training: Epoch 80, Batch 19, Loss: 0.204\n",
      "Val: Epoch 80, Loss: 0.275\n",
      "Training: Epoch 81, Batch 0, Loss: 0.152\n",
      "Training: Epoch 81, Batch 1, Loss: 0.205\n",
      "Training: Epoch 81, Batch 2, Loss: 0.177\n",
      "Training: Epoch 81, Batch 3, Loss: 0.161\n",
      "Training: Epoch 81, Batch 4, Loss: 0.149\n",
      "Training: Epoch 81, Batch 5, Loss: 0.326\n",
      "Training: Epoch 81, Batch 6, Loss: 0.203\n",
      "Training: Epoch 81, Batch 7, Loss: 0.204\n",
      "Training: Epoch 81, Batch 8, Loss: 0.143\n",
      "Training: Epoch 81, Batch 9, Loss: 0.151\n",
      "Training: Epoch 81, Batch 10, Loss: 0.174\n",
      "Training: Epoch 81, Batch 11, Loss: 0.182\n",
      "Training: Epoch 81, Batch 12, Loss: 0.265\n",
      "Training: Epoch 81, Batch 13, Loss: 0.175\n",
      "Training: Epoch 81, Batch 14, Loss: 0.148\n",
      "Training: Epoch 81, Batch 15, Loss: 0.245\n",
      "Training: Epoch 81, Batch 16, Loss: 0.127\n",
      "Training: Epoch 81, Batch 17, Loss: 0.326\n",
      "Training: Epoch 81, Batch 18, Loss: 0.178\n",
      "Training: Epoch 81, Batch 19, Loss: 0.18\n",
      "Val: Epoch 81, Loss: 0.257\n",
      "Training: Epoch 82, Batch 0, Loss: 0.174\n",
      "Training: Epoch 82, Batch 1, Loss: 0.158\n",
      "Training: Epoch 82, Batch 2, Loss: 0.183\n",
      "Training: Epoch 82, Batch 3, Loss: 0.213\n",
      "Training: Epoch 82, Batch 4, Loss: 0.185\n",
      "Training: Epoch 82, Batch 5, Loss: 0.156\n",
      "Training: Epoch 82, Batch 6, Loss: 0.162\n",
      "Training: Epoch 82, Batch 7, Loss: 0.208\n",
      "Training: Epoch 82, Batch 8, Loss: 0.18\n",
      "Training: Epoch 82, Batch 9, Loss: 0.22\n",
      "Training: Epoch 82, Batch 10, Loss: 0.137\n",
      "Training: Epoch 82, Batch 11, Loss: 0.133\n",
      "Training: Epoch 82, Batch 12, Loss: 0.132\n",
      "Training: Epoch 82, Batch 13, Loss: 0.183\n",
      "Training: Epoch 82, Batch 14, Loss: 0.184\n",
      "Training: Epoch 82, Batch 15, Loss: 0.165\n",
      "Training: Epoch 82, Batch 16, Loss: 0.138\n",
      "Training: Epoch 82, Batch 17, Loss: 0.245\n",
      "Training: Epoch 82, Batch 18, Loss: 0.149\n",
      "Training: Epoch 82, Batch 19, Loss: 0.143\n",
      "Val: Epoch 82, Loss: 0.254\n",
      "Training: Epoch 83, Batch 0, Loss: 0.144\n",
      "Training: Epoch 83, Batch 1, Loss: 0.165\n",
      "Training: Epoch 83, Batch 2, Loss: 0.137\n",
      "Training: Epoch 83, Batch 3, Loss: 0.218\n",
      "Training: Epoch 83, Batch 4, Loss: 0.158\n",
      "Training: Epoch 83, Batch 5, Loss: 0.139\n",
      "Training: Epoch 83, Batch 6, Loss: 0.148\n",
      "Training: Epoch 83, Batch 7, Loss: 0.143\n",
      "Training: Epoch 83, Batch 8, Loss: 0.173\n",
      "Training: Epoch 83, Batch 9, Loss: 0.237\n",
      "Training: Epoch 83, Batch 10, Loss: 0.154\n",
      "Training: Epoch 83, Batch 11, Loss: 0.189\n",
      "Training: Epoch 83, Batch 12, Loss: 0.138\n",
      "Training: Epoch 83, Batch 13, Loss: 0.131\n",
      "Training: Epoch 83, Batch 14, Loss: 0.148\n",
      "Training: Epoch 83, Batch 15, Loss: 0.143\n",
      "Training: Epoch 83, Batch 16, Loss: 0.14\n",
      "Training: Epoch 83, Batch 17, Loss: 0.159\n",
      "Training: Epoch 83, Batch 18, Loss: 0.208\n",
      "Training: Epoch 83, Batch 19, Loss: 0.152\n",
      "Val: Epoch 83, Loss: 0.247\n",
      "Training: Epoch 84, Batch 0, Loss: 0.148\n",
      "Training: Epoch 84, Batch 1, Loss: 0.203\n",
      "Training: Epoch 84, Batch 2, Loss: 0.195\n",
      "Training: Epoch 84, Batch 3, Loss: 0.154\n",
      "Training: Epoch 84, Batch 4, Loss: 0.213\n",
      "Training: Epoch 84, Batch 5, Loss: 0.175\n",
      "Training: Epoch 84, Batch 6, Loss: 0.131\n",
      "Training: Epoch 84, Batch 7, Loss: 0.144\n",
      "Training: Epoch 84, Batch 8, Loss: 0.15\n",
      "Training: Epoch 84, Batch 9, Loss: 0.166\n",
      "Training: Epoch 84, Batch 10, Loss: 0.149\n",
      "Training: Epoch 84, Batch 11, Loss: 0.15\n",
      "Training: Epoch 84, Batch 12, Loss: 0.164\n",
      "Training: Epoch 84, Batch 13, Loss: 0.154\n",
      "Training: Epoch 84, Batch 14, Loss: 0.16\n",
      "Training: Epoch 84, Batch 15, Loss: 0.129\n",
      "Training: Epoch 84, Batch 16, Loss: 0.17\n",
      "Training: Epoch 84, Batch 17, Loss: 0.214\n",
      "Training: Epoch 84, Batch 18, Loss: 0.146\n",
      "Training: Epoch 84, Batch 19, Loss: 0.152\n",
      "Val: Epoch 84, Loss: 0.262\n",
      "Training: Epoch 85, Batch 0, Loss: 0.172\n",
      "Training: Epoch 85, Batch 1, Loss: 0.243\n",
      "Training: Epoch 85, Batch 2, Loss: 0.138\n",
      "Training: Epoch 85, Batch 3, Loss: 0.126\n",
      "Training: Epoch 85, Batch 4, Loss: 0.154\n",
      "Training: Epoch 85, Batch 5, Loss: 0.146\n",
      "Training: Epoch 85, Batch 6, Loss: 0.172\n",
      "Training: Epoch 85, Batch 7, Loss: 0.179\n",
      "Training: Epoch 85, Batch 8, Loss: 0.146\n",
      "Training: Epoch 85, Batch 9, Loss: 0.16\n",
      "Training: Epoch 85, Batch 10, Loss: 0.175\n",
      "Training: Epoch 85, Batch 11, Loss: 0.121\n",
      "Training: Epoch 85, Batch 12, Loss: 0.147\n",
      "Training: Epoch 85, Batch 13, Loss: 0.18\n",
      "Training: Epoch 85, Batch 14, Loss: 0.178\n",
      "Training: Epoch 85, Batch 15, Loss: 0.156\n",
      "Training: Epoch 85, Batch 16, Loss: 0.175\n",
      "Training: Epoch 85, Batch 17, Loss: 0.209\n",
      "Training: Epoch 85, Batch 18, Loss: 0.176\n",
      "Training: Epoch 85, Batch 19, Loss: 0.141\n",
      "Val: Epoch 85, Loss: 0.272\n",
      "Training: Epoch 86, Batch 0, Loss: 0.184\n",
      "Training: Epoch 86, Batch 1, Loss: 0.215\n",
      "Training: Epoch 86, Batch 2, Loss: 0.138\n",
      "Training: Epoch 86, Batch 3, Loss: 0.156\n",
      "Training: Epoch 86, Batch 4, Loss: 0.168\n",
      "Training: Epoch 86, Batch 5, Loss: 0.157\n",
      "Training: Epoch 86, Batch 6, Loss: 0.207\n",
      "Training: Epoch 86, Batch 7, Loss: 0.148\n",
      "Training: Epoch 86, Batch 8, Loss: 0.171\n",
      "Training: Epoch 86, Batch 9, Loss: 0.136\n",
      "Training: Epoch 86, Batch 10, Loss: 0.155\n",
      "Training: Epoch 86, Batch 11, Loss: 0.174\n",
      "Training: Epoch 86, Batch 12, Loss: 0.177\n",
      "Training: Epoch 86, Batch 13, Loss: 0.254\n",
      "Training: Epoch 86, Batch 14, Loss: 0.158\n",
      "Training: Epoch 86, Batch 15, Loss: 0.175\n",
      "Training: Epoch 86, Batch 16, Loss: 0.152\n",
      "Training: Epoch 86, Batch 17, Loss: 0.129\n",
      "Training: Epoch 86, Batch 18, Loss: 0.289\n",
      "Training: Epoch 86, Batch 19, Loss: 0.213\n",
      "Val: Epoch 86, Loss: 0.261\n",
      "Training: Epoch 87, Batch 0, Loss: 0.209\n",
      "Training: Epoch 87, Batch 1, Loss: 0.212\n",
      "Training: Epoch 87, Batch 2, Loss: 0.138\n",
      "Training: Epoch 87, Batch 3, Loss: 0.182\n",
      "Training: Epoch 87, Batch 4, Loss: 0.193\n",
      "Training: Epoch 87, Batch 5, Loss: 0.142\n",
      "Training: Epoch 87, Batch 6, Loss: 0.178\n",
      "Training: Epoch 87, Batch 7, Loss: 0.195\n",
      "Training: Epoch 87, Batch 8, Loss: 0.118\n",
      "Training: Epoch 87, Batch 9, Loss: 0.189\n",
      "Training: Epoch 87, Batch 10, Loss: 0.143\n",
      "Training: Epoch 87, Batch 11, Loss: 0.235\n",
      "Training: Epoch 87, Batch 12, Loss: 0.2\n",
      "Training: Epoch 87, Batch 13, Loss: 0.168\n",
      "Training: Epoch 87, Batch 14, Loss: 0.24\n",
      "Training: Epoch 87, Batch 15, Loss: 0.151\n",
      "Training: Epoch 87, Batch 16, Loss: 0.24\n",
      "Training: Epoch 87, Batch 17, Loss: 0.181\n",
      "Training: Epoch 87, Batch 18, Loss: 0.129\n",
      "Training: Epoch 87, Batch 19, Loss: 0.133\n",
      "Val: Epoch 87, Loss: 0.246\n",
      "Training: Epoch 88, Batch 0, Loss: 0.139\n",
      "Training: Epoch 88, Batch 1, Loss: 0.234\n",
      "Training: Epoch 88, Batch 2, Loss: 0.231\n",
      "Training: Epoch 88, Batch 3, Loss: 0.194\n",
      "Training: Epoch 88, Batch 4, Loss: 0.181\n",
      "Training: Epoch 88, Batch 5, Loss: 0.15\n",
      "Training: Epoch 88, Batch 6, Loss: 0.166\n",
      "Training: Epoch 88, Batch 7, Loss: 0.135\n",
      "Training: Epoch 88, Batch 8, Loss: 0.146\n",
      "Training: Epoch 88, Batch 9, Loss: 0.188\n",
      "Training: Epoch 88, Batch 10, Loss: 0.116\n",
      "Training: Epoch 88, Batch 11, Loss: 0.158\n",
      "Training: Epoch 88, Batch 12, Loss: 0.103\n",
      "Training: Epoch 88, Batch 13, Loss: 0.143\n",
      "Training: Epoch 88, Batch 14, Loss: 0.126\n",
      "Training: Epoch 88, Batch 15, Loss: 0.163\n",
      "Training: Epoch 88, Batch 16, Loss: 0.12\n",
      "Training: Epoch 88, Batch 17, Loss: 0.189\n",
      "Training: Epoch 88, Batch 18, Loss: 0.141\n",
      "Training: Epoch 88, Batch 19, Loss: 0.132\n",
      "Val: Epoch 88, Loss: 0.26\n",
      "Training: Epoch 89, Batch 0, Loss: 0.165\n",
      "Training: Epoch 89, Batch 1, Loss: 0.144\n",
      "Training: Epoch 89, Batch 2, Loss: 0.165\n",
      "Training: Epoch 89, Batch 3, Loss: 0.174\n",
      "Training: Epoch 89, Batch 4, Loss: 0.13\n",
      "Training: Epoch 89, Batch 5, Loss: 0.106\n",
      "Training: Epoch 89, Batch 6, Loss: 0.185\n",
      "Training: Epoch 89, Batch 7, Loss: 0.164\n",
      "Training: Epoch 89, Batch 8, Loss: 0.177\n",
      "Training: Epoch 89, Batch 9, Loss: 0.122\n",
      "Training: Epoch 89, Batch 10, Loss: 0.183\n",
      "Training: Epoch 89, Batch 11, Loss: 0.189\n",
      "Training: Epoch 89, Batch 12, Loss: 0.115\n",
      "Training: Epoch 89, Batch 13, Loss: 0.158\n",
      "Training: Epoch 89, Batch 14, Loss: 0.178\n",
      "Training: Epoch 89, Batch 15, Loss: 0.168\n",
      "Training: Epoch 89, Batch 16, Loss: 0.13\n",
      "Training: Epoch 89, Batch 17, Loss: 0.195\n",
      "Training: Epoch 89, Batch 18, Loss: 0.13\n",
      "Training: Epoch 89, Batch 19, Loss: 0.182\n",
      "Val: Epoch 89, Loss: 0.329\n",
      "Training: Epoch 90, Batch 0, Loss: 0.133\n",
      "Training: Epoch 90, Batch 1, Loss: 0.237\n",
      "Training: Epoch 90, Batch 2, Loss: 0.116\n",
      "Training: Epoch 90, Batch 3, Loss: 0.142\n",
      "Training: Epoch 90, Batch 4, Loss: 0.149\n",
      "Training: Epoch 90, Batch 5, Loss: 0.165\n",
      "Training: Epoch 90, Batch 6, Loss: 0.132\n",
      "Training: Epoch 90, Batch 7, Loss: 0.202\n",
      "Training: Epoch 90, Batch 8, Loss: 0.16\n",
      "Training: Epoch 90, Batch 9, Loss: 0.217\n",
      "Training: Epoch 90, Batch 10, Loss: 0.143\n",
      "Training: Epoch 90, Batch 11, Loss: 0.165\n",
      "Training: Epoch 90, Batch 12, Loss: 0.134\n",
      "Training: Epoch 90, Batch 13, Loss: 0.129\n",
      "Training: Epoch 90, Batch 14, Loss: 0.23\n",
      "Training: Epoch 90, Batch 15, Loss: 0.189\n",
      "Training: Epoch 90, Batch 16, Loss: 0.22\n",
      "Training: Epoch 90, Batch 17, Loss: 0.127\n",
      "Training: Epoch 90, Batch 18, Loss: 0.135\n",
      "Training: Epoch 90, Batch 19, Loss: 0.235\n",
      "Val: Epoch 90, Loss: 0.282\n",
      "Training: Epoch 91, Batch 0, Loss: 0.184\n",
      "Training: Epoch 91, Batch 1, Loss: 0.163\n",
      "Training: Epoch 91, Batch 2, Loss: 0.159\n",
      "Training: Epoch 91, Batch 3, Loss: 0.183\n",
      "Training: Epoch 91, Batch 4, Loss: 0.185\n",
      "Training: Epoch 91, Batch 5, Loss: 0.143\n",
      "Training: Epoch 91, Batch 6, Loss: 0.138\n",
      "Training: Epoch 91, Batch 7, Loss: 0.151\n",
      "Training: Epoch 91, Batch 8, Loss: 0.123\n",
      "Training: Epoch 91, Batch 9, Loss: 0.17\n",
      "Training: Epoch 91, Batch 10, Loss: 0.181\n",
      "Training: Epoch 91, Batch 11, Loss: 0.186\n",
      "Training: Epoch 91, Batch 12, Loss: 0.124\n",
      "Training: Epoch 91, Batch 13, Loss: 0.103\n",
      "Training: Epoch 91, Batch 14, Loss: 0.172\n",
      "Training: Epoch 91, Batch 15, Loss: 0.174\n",
      "Training: Epoch 91, Batch 16, Loss: 0.226\n",
      "Training: Epoch 91, Batch 17, Loss: 0.142\n",
      "Training: Epoch 91, Batch 18, Loss: 0.194\n",
      "Training: Epoch 91, Batch 19, Loss: 0.175\n",
      "Val: Epoch 91, Loss: 0.252\n",
      "Training: Epoch 92, Batch 0, Loss: 0.132\n",
      "Training: Epoch 92, Batch 1, Loss: 0.193\n",
      "Training: Epoch 92, Batch 2, Loss: 0.129\n",
      "Training: Epoch 92, Batch 3, Loss: 0.138\n",
      "Training: Epoch 92, Batch 4, Loss: 0.136\n",
      "Training: Epoch 92, Batch 5, Loss: 0.186\n",
      "Training: Epoch 92, Batch 6, Loss: 0.187\n",
      "Training: Epoch 92, Batch 7, Loss: 0.127\n",
      "Training: Epoch 92, Batch 8, Loss: 0.121\n",
      "Training: Epoch 92, Batch 9, Loss: 0.153\n",
      "Training: Epoch 92, Batch 10, Loss: 0.137\n",
      "Training: Epoch 92, Batch 11, Loss: 0.151\n",
      "Training: Epoch 92, Batch 12, Loss: 0.224\n",
      "Training: Epoch 92, Batch 13, Loss: 0.136\n",
      "Training: Epoch 92, Batch 14, Loss: 0.189\n",
      "Training: Epoch 92, Batch 15, Loss: 0.151\n",
      "Training: Epoch 92, Batch 16, Loss: 0.144\n",
      "Training: Epoch 92, Batch 17, Loss: 0.156\n",
      "Training: Epoch 92, Batch 18, Loss: 0.148\n",
      "Training: Epoch 92, Batch 19, Loss: 0.148\n",
      "Val: Epoch 92, Loss: 0.251\n",
      "Training: Epoch 93, Batch 0, Loss: 0.143\n",
      "Training: Epoch 93, Batch 1, Loss: 0.136\n",
      "Training: Epoch 93, Batch 2, Loss: 0.2\n",
      "Training: Epoch 93, Batch 3, Loss: 0.129\n",
      "Training: Epoch 93, Batch 4, Loss: 0.151\n",
      "Training: Epoch 93, Batch 5, Loss: 0.18\n",
      "Training: Epoch 93, Batch 6, Loss: 0.148\n",
      "Training: Epoch 93, Batch 7, Loss: 0.163\n",
      "Training: Epoch 93, Batch 8, Loss: 0.17\n",
      "Training: Epoch 93, Batch 9, Loss: 0.182\n",
      "Training: Epoch 93, Batch 10, Loss: 0.146\n",
      "Training: Epoch 93, Batch 11, Loss: 0.223\n",
      "Training: Epoch 93, Batch 12, Loss: 0.165\n",
      "Training: Epoch 93, Batch 13, Loss: 0.1\n",
      "Training: Epoch 93, Batch 14, Loss: 0.129\n",
      "Training: Epoch 93, Batch 15, Loss: 0.138\n",
      "Training: Epoch 93, Batch 16, Loss: 0.151\n",
      "Training: Epoch 93, Batch 17, Loss: 0.174\n",
      "Training: Epoch 93, Batch 18, Loss: 0.128\n",
      "Training: Epoch 93, Batch 19, Loss: 0.192\n",
      "Val: Epoch 93, Loss: 0.281\n",
      "Training: Epoch 94, Batch 0, Loss: 0.132\n",
      "Training: Epoch 94, Batch 1, Loss: 0.178\n",
      "Training: Epoch 94, Batch 2, Loss: 0.152\n",
      "Training: Epoch 94, Batch 3, Loss: 0.16\n",
      "Training: Epoch 94, Batch 4, Loss: 0.215\n",
      "Training: Epoch 94, Batch 5, Loss: 0.161\n",
      "Training: Epoch 94, Batch 6, Loss: 0.15\n",
      "Training: Epoch 94, Batch 7, Loss: 0.158\n",
      "Training: Epoch 94, Batch 8, Loss: 0.136\n",
      "Training: Epoch 94, Batch 9, Loss: 0.135\n",
      "Training: Epoch 94, Batch 10, Loss: 0.151\n",
      "Training: Epoch 94, Batch 11, Loss: 0.188\n",
      "Training: Epoch 94, Batch 12, Loss: 0.175\n",
      "Training: Epoch 94, Batch 13, Loss: 0.152\n",
      "Training: Epoch 94, Batch 14, Loss: 0.133\n",
      "Training: Epoch 94, Batch 15, Loss: 0.162\n",
      "Training: Epoch 94, Batch 16, Loss: 0.153\n",
      "Training: Epoch 94, Batch 17, Loss: 0.159\n",
      "Training: Epoch 94, Batch 18, Loss: 0.167\n",
      "Training: Epoch 94, Batch 19, Loss: 0.144\n",
      "Val: Epoch 94, Loss: 0.241\n",
      "Training: Epoch 95, Batch 0, Loss: 0.176\n",
      "Training: Epoch 95, Batch 1, Loss: 0.161\n",
      "Training: Epoch 95, Batch 2, Loss: 0.149\n",
      "Training: Epoch 95, Batch 3, Loss: 0.151\n",
      "Training: Epoch 95, Batch 4, Loss: 0.128\n",
      "Training: Epoch 95, Batch 5, Loss: 0.143\n",
      "Training: Epoch 95, Batch 6, Loss: 0.141\n",
      "Training: Epoch 95, Batch 7, Loss: 0.143\n",
      "Training: Epoch 95, Batch 8, Loss: 0.181\n",
      "Training: Epoch 95, Batch 9, Loss: 0.153\n",
      "Training: Epoch 95, Batch 10, Loss: 0.162\n",
      "Training: Epoch 95, Batch 11, Loss: 0.134\n",
      "Training: Epoch 95, Batch 12, Loss: 0.158\n",
      "Training: Epoch 95, Batch 13, Loss: 0.133\n",
      "Training: Epoch 95, Batch 14, Loss: 0.144\n",
      "Training: Epoch 95, Batch 15, Loss: 0.118\n",
      "Training: Epoch 95, Batch 16, Loss: 0.142\n",
      "Training: Epoch 95, Batch 17, Loss: 0.168\n",
      "Training: Epoch 95, Batch 18, Loss: 0.179\n",
      "Training: Epoch 95, Batch 19, Loss: 0.121\n",
      "Val: Epoch 95, Loss: 0.239\n",
      "Training: Epoch 96, Batch 0, Loss: 0.109\n",
      "Training: Epoch 96, Batch 1, Loss: 0.166\n",
      "Training: Epoch 96, Batch 2, Loss: 0.108\n",
      "Training: Epoch 96, Batch 3, Loss: 0.156\n",
      "Training: Epoch 96, Batch 4, Loss: 0.171\n",
      "Training: Epoch 96, Batch 5, Loss: 0.166\n",
      "Training: Epoch 96, Batch 6, Loss: 0.192\n",
      "Training: Epoch 96, Batch 7, Loss: 0.122\n",
      "Training: Epoch 96, Batch 8, Loss: 0.187\n",
      "Training: Epoch 96, Batch 9, Loss: 0.146\n",
      "Training: Epoch 96, Batch 10, Loss: 0.139\n",
      "Training: Epoch 96, Batch 11, Loss: 0.162\n",
      "Training: Epoch 96, Batch 12, Loss: 0.121\n",
      "Training: Epoch 96, Batch 13, Loss: 0.255\n",
      "Training: Epoch 96, Batch 14, Loss: 0.156\n",
      "Training: Epoch 96, Batch 15, Loss: 0.124\n",
      "Training: Epoch 96, Batch 16, Loss: 0.19\n",
      "Training: Epoch 96, Batch 17, Loss: 0.135\n",
      "Training: Epoch 96, Batch 18, Loss: 0.161\n",
      "Training: Epoch 96, Batch 19, Loss: 0.123\n",
      "Val: Epoch 96, Loss: 0.24\n",
      "Training: Epoch 97, Batch 0, Loss: 0.13\n",
      "Training: Epoch 97, Batch 1, Loss: 0.121\n",
      "Training: Epoch 97, Batch 2, Loss: 0.109\n",
      "Training: Epoch 97, Batch 3, Loss: 0.188\n",
      "Training: Epoch 97, Batch 4, Loss: 0.168\n",
      "Training: Epoch 97, Batch 5, Loss: 0.15\n",
      "Training: Epoch 97, Batch 6, Loss: 0.154\n",
      "Training: Epoch 97, Batch 7, Loss: 0.187\n",
      "Training: Epoch 97, Batch 8, Loss: 0.195\n",
      "Training: Epoch 97, Batch 9, Loss: 0.146\n",
      "Training: Epoch 97, Batch 10, Loss: 0.145\n",
      "Training: Epoch 97, Batch 11, Loss: 0.111\n",
      "Training: Epoch 97, Batch 12, Loss: 0.179\n",
      "Training: Epoch 97, Batch 13, Loss: 0.135\n",
      "Training: Epoch 97, Batch 14, Loss: 0.132\n",
      "Training: Epoch 97, Batch 15, Loss: 0.146\n",
      "Training: Epoch 97, Batch 16, Loss: 0.136\n",
      "Training: Epoch 97, Batch 17, Loss: 0.138\n",
      "Training: Epoch 97, Batch 18, Loss: 0.178\n",
      "Training: Epoch 97, Batch 19, Loss: 0.181\n",
      "Val: Epoch 97, Loss: 0.244\n",
      "Training: Epoch 98, Batch 0, Loss: 0.1\n",
      "Training: Epoch 98, Batch 1, Loss: 0.139\n",
      "Training: Epoch 98, Batch 2, Loss: 0.163\n",
      "Training: Epoch 98, Batch 3, Loss: 0.113\n",
      "Training: Epoch 98, Batch 4, Loss: 0.125\n",
      "Training: Epoch 98, Batch 5, Loss: 0.184\n",
      "Training: Epoch 98, Batch 6, Loss: 0.229\n",
      "Training: Epoch 98, Batch 7, Loss: 0.167\n",
      "Training: Epoch 98, Batch 8, Loss: 0.085\n",
      "Training: Epoch 98, Batch 9, Loss: 0.136\n",
      "Training: Epoch 98, Batch 10, Loss: 0.192\n",
      "Training: Epoch 98, Batch 11, Loss: 0.258\n",
      "Training: Epoch 98, Batch 12, Loss: 0.164\n",
      "Training: Epoch 98, Batch 13, Loss: 0.154\n",
      "Training: Epoch 98, Batch 14, Loss: 0.15\n",
      "Training: Epoch 98, Batch 15, Loss: 0.158\n",
      "Training: Epoch 98, Batch 16, Loss: 0.22\n",
      "Training: Epoch 98, Batch 17, Loss: 0.174\n",
      "Training: Epoch 98, Batch 18, Loss: 0.185\n",
      "Training: Epoch 98, Batch 19, Loss: 0.195\n",
      "Val: Epoch 98, Loss: 0.246\n",
      "Training: Epoch 99, Batch 0, Loss: 0.125\n",
      "Training: Epoch 99, Batch 1, Loss: 0.151\n",
      "Training: Epoch 99, Batch 2, Loss: 0.173\n",
      "Training: Epoch 99, Batch 3, Loss: 0.16\n",
      "Training: Epoch 99, Batch 4, Loss: 0.167\n",
      "Training: Epoch 99, Batch 5, Loss: 0.165\n",
      "Training: Epoch 99, Batch 6, Loss: 0.139\n",
      "Training: Epoch 99, Batch 7, Loss: 0.153\n",
      "Training: Epoch 99, Batch 8, Loss: 0.165\n",
      "Training: Epoch 99, Batch 9, Loss: 0.158\n",
      "Training: Epoch 99, Batch 10, Loss: 0.249\n",
      "Training: Epoch 99, Batch 11, Loss: 0.172\n",
      "Training: Epoch 99, Batch 12, Loss: 0.173\n",
      "Training: Epoch 99, Batch 13, Loss: 0.153\n",
      "Training: Epoch 99, Batch 14, Loss: 0.169\n",
      "Training: Epoch 99, Batch 15, Loss: 0.124\n",
      "Training: Epoch 99, Batch 16, Loss: 0.254\n",
      "Training: Epoch 99, Batch 17, Loss: 0.146\n",
      "Training: Epoch 99, Batch 18, Loss: 0.214\n",
      "Training: Epoch 99, Batch 19, Loss: 0.218\n",
      "Val: Epoch 99, Loss: 0.26\n",
      "Training: Epoch 100, Batch 0, Loss: 0.172\n",
      "Training: Epoch 100, Batch 1, Loss: 0.194\n",
      "Training: Epoch 100, Batch 2, Loss: 0.254\n",
      "Training: Epoch 100, Batch 3, Loss: 0.208\n",
      "Training: Epoch 100, Batch 4, Loss: 0.168\n",
      "Training: Epoch 100, Batch 5, Loss: 0.154\n",
      "Training: Epoch 100, Batch 6, Loss: 0.192\n",
      "Training: Epoch 100, Batch 7, Loss: 0.204\n",
      "Training: Epoch 100, Batch 8, Loss: 0.245\n",
      "Training: Epoch 100, Batch 9, Loss: 0.144\n",
      "Training: Epoch 100, Batch 10, Loss: 0.137\n",
      "Training: Epoch 100, Batch 11, Loss: 0.193\n",
      "Training: Epoch 100, Batch 12, Loss: 0.166\n",
      "Training: Epoch 100, Batch 13, Loss: 0.197\n",
      "Training: Epoch 100, Batch 14, Loss: 0.173\n",
      "Training: Epoch 100, Batch 15, Loss: 0.145\n",
      "Training: Epoch 100, Batch 16, Loss: 0.198\n",
      "Training: Epoch 100, Batch 17, Loss: 0.193\n",
      "Training: Epoch 100, Batch 18, Loss: 0.176\n",
      "Training: Epoch 100, Batch 19, Loss: 0.212\n",
      "Val: Epoch 100, Loss: 0.251\n",
      "Training: Epoch 101, Batch 0, Loss: 0.149\n",
      "Training: Epoch 101, Batch 1, Loss: 0.184\n",
      "Training: Epoch 101, Batch 2, Loss: 0.228\n",
      "Training: Epoch 101, Batch 3, Loss: 0.156\n",
      "Training: Epoch 101, Batch 4, Loss: 0.192\n",
      "Training: Epoch 101, Batch 5, Loss: 0.155\n",
      "Training: Epoch 101, Batch 6, Loss: 0.172\n",
      "Training: Epoch 101, Batch 7, Loss: 0.161\n",
      "Training: Epoch 101, Batch 8, Loss: 0.134\n",
      "Training: Epoch 101, Batch 9, Loss: 0.199\n",
      "Training: Epoch 101, Batch 10, Loss: 0.187\n",
      "Training: Epoch 101, Batch 11, Loss: 0.178\n",
      "Training: Epoch 101, Batch 12, Loss: 0.131\n",
      "Training: Epoch 101, Batch 13, Loss: 0.133\n",
      "Training: Epoch 101, Batch 14, Loss: 0.185\n",
      "Training: Epoch 101, Batch 15, Loss: 0.168\n",
      "Training: Epoch 101, Batch 16, Loss: 0.146\n",
      "Training: Epoch 101, Batch 17, Loss: 0.119\n",
      "Training: Epoch 101, Batch 18, Loss: 0.133\n",
      "Training: Epoch 101, Batch 19, Loss: 0.161\n",
      "Val: Epoch 101, Loss: 0.296\n",
      "Training: Epoch 102, Batch 0, Loss: 0.154\n",
      "Training: Epoch 102, Batch 1, Loss: 0.242\n",
      "Training: Epoch 102, Batch 2, Loss: 0.133\n",
      "Training: Epoch 102, Batch 3, Loss: 0.101\n",
      "Training: Epoch 102, Batch 4, Loss: 0.185\n",
      "Training: Epoch 102, Batch 5, Loss: 0.213\n",
      "Training: Epoch 102, Batch 6, Loss: 0.206\n",
      "Training: Epoch 102, Batch 7, Loss: 0.197\n",
      "Training: Epoch 102, Batch 8, Loss: 0.125\n",
      "Training: Epoch 102, Batch 9, Loss: 0.143\n",
      "Training: Epoch 102, Batch 10, Loss: 0.145\n",
      "Training: Epoch 102, Batch 11, Loss: 0.209\n",
      "Training: Epoch 102, Batch 12, Loss: 0.163\n",
      "Training: Epoch 102, Batch 13, Loss: 0.172\n",
      "Training: Epoch 102, Batch 14, Loss: 0.184\n",
      "Training: Epoch 102, Batch 15, Loss: 0.17\n",
      "Training: Epoch 102, Batch 16, Loss: 0.117\n",
      "Training: Epoch 102, Batch 17, Loss: 0.148\n",
      "Training: Epoch 102, Batch 18, Loss: 0.184\n",
      "Training: Epoch 102, Batch 19, Loss: 0.183\n",
      "Val: Epoch 102, Loss: 0.233\n",
      "Training: Epoch 103, Batch 0, Loss: 0.119\n",
      "Training: Epoch 103, Batch 1, Loss: 0.166\n",
      "Training: Epoch 103, Batch 2, Loss: 0.147\n",
      "Training: Epoch 103, Batch 3, Loss: 0.124\n",
      "Training: Epoch 103, Batch 4, Loss: 0.135\n",
      "Training: Epoch 103, Batch 5, Loss: 0.172\n",
      "Training: Epoch 103, Batch 6, Loss: 0.173\n",
      "Training: Epoch 103, Batch 7, Loss: 0.148\n",
      "Training: Epoch 103, Batch 8, Loss: 0.175\n",
      "Training: Epoch 103, Batch 9, Loss: 0.182\n",
      "Training: Epoch 103, Batch 10, Loss: 0.142\n",
      "Training: Epoch 103, Batch 11, Loss: 0.152\n",
      "Training: Epoch 103, Batch 12, Loss: 0.16\n",
      "Training: Epoch 103, Batch 13, Loss: 0.143\n",
      "Training: Epoch 103, Batch 14, Loss: 0.152\n",
      "Training: Epoch 103, Batch 15, Loss: 0.155\n",
      "Training: Epoch 103, Batch 16, Loss: 0.144\n",
      "Training: Epoch 103, Batch 17, Loss: 0.177\n",
      "Training: Epoch 103, Batch 18, Loss: 0.136\n",
      "Training: Epoch 103, Batch 19, Loss: 0.137\n",
      "Val: Epoch 103, Loss: 0.248\n",
      "Training: Epoch 104, Batch 0, Loss: 0.124\n",
      "Training: Epoch 104, Batch 1, Loss: 0.198\n",
      "Training: Epoch 104, Batch 2, Loss: 0.182\n",
      "Training: Epoch 104, Batch 3, Loss: 0.172\n",
      "Training: Epoch 104, Batch 4, Loss: 0.121\n",
      "Training: Epoch 104, Batch 5, Loss: 0.107\n",
      "Training: Epoch 104, Batch 6, Loss: 0.154\n",
      "Training: Epoch 104, Batch 7, Loss: 0.114\n",
      "Training: Epoch 104, Batch 8, Loss: 0.151\n",
      "Training: Epoch 104, Batch 9, Loss: 0.144\n",
      "Training: Epoch 104, Batch 10, Loss: 0.149\n",
      "Training: Epoch 104, Batch 11, Loss: 0.132\n",
      "Training: Epoch 104, Batch 12, Loss: 0.149\n",
      "Training: Epoch 104, Batch 13, Loss: 0.127\n",
      "Training: Epoch 104, Batch 14, Loss: 0.143\n",
      "Training: Epoch 104, Batch 15, Loss: 0.144\n",
      "Training: Epoch 104, Batch 16, Loss: 0.117\n",
      "Training: Epoch 104, Batch 17, Loss: 0.125\n",
      "Training: Epoch 104, Batch 18, Loss: 0.169\n",
      "Training: Epoch 104, Batch 19, Loss: 0.173\n",
      "Val: Epoch 104, Loss: 0.237\n",
      "Training: Epoch 105, Batch 0, Loss: 0.158\n",
      "Training: Epoch 105, Batch 1, Loss: 0.177\n",
      "Training: Epoch 105, Batch 2, Loss: 0.135\n",
      "Training: Epoch 105, Batch 3, Loss: 0.118\n",
      "Training: Epoch 105, Batch 4, Loss: 0.118\n",
      "Training: Epoch 105, Batch 5, Loss: 0.143\n",
      "Training: Epoch 105, Batch 6, Loss: 0.159\n",
      "Training: Epoch 105, Batch 7, Loss: 0.178\n",
      "Training: Epoch 105, Batch 8, Loss: 0.173\n",
      "Training: Epoch 105, Batch 9, Loss: 0.128\n",
      "Training: Epoch 105, Batch 10, Loss: 0.143\n",
      "Training: Epoch 105, Batch 11, Loss: 0.139\n",
      "Training: Epoch 105, Batch 12, Loss: 0.13\n",
      "Training: Epoch 105, Batch 13, Loss: 0.207\n",
      "Training: Epoch 105, Batch 14, Loss: 0.138\n",
      "Training: Epoch 105, Batch 15, Loss: 0.138\n",
      "Training: Epoch 105, Batch 16, Loss: 0.171\n",
      "Training: Epoch 105, Batch 17, Loss: 0.156\n",
      "Training: Epoch 105, Batch 18, Loss: 0.116\n",
      "Training: Epoch 105, Batch 19, Loss: 0.156\n",
      "Val: Epoch 105, Loss: 0.238\n",
      "Training: Epoch 106, Batch 0, Loss: 0.125\n",
      "Training: Epoch 106, Batch 1, Loss: 0.093\n",
      "Training: Epoch 106, Batch 2, Loss: 0.16\n",
      "Training: Epoch 106, Batch 3, Loss: 0.115\n",
      "Training: Epoch 106, Batch 4, Loss: 0.149\n",
      "Training: Epoch 106, Batch 5, Loss: 0.181\n",
      "Training: Epoch 106, Batch 6, Loss: 0.154\n",
      "Training: Epoch 106, Batch 7, Loss: 0.171\n",
      "Training: Epoch 106, Batch 8, Loss: 0.199\n",
      "Training: Epoch 106, Batch 9, Loss: 0.148\n",
      "Training: Epoch 106, Batch 10, Loss: 0.145\n",
      "Training: Epoch 106, Batch 11, Loss: 0.172\n",
      "Training: Epoch 106, Batch 12, Loss: 0.2\n",
      "Training: Epoch 106, Batch 13, Loss: 0.18\n",
      "Training: Epoch 106, Batch 14, Loss: 0.13\n",
      "Training: Epoch 106, Batch 15, Loss: 0.162\n",
      "Training: Epoch 106, Batch 16, Loss: 0.11\n",
      "Training: Epoch 106, Batch 17, Loss: 0.165\n",
      "Training: Epoch 106, Batch 18, Loss: 0.136\n",
      "Training: Epoch 106, Batch 19, Loss: 0.118\n",
      "Val: Epoch 106, Loss: 0.245\n",
      "Training: Epoch 107, Batch 0, Loss: 0.179\n",
      "Training: Epoch 107, Batch 1, Loss: 0.149\n",
      "Training: Epoch 107, Batch 2, Loss: 0.128\n",
      "Training: Epoch 107, Batch 3, Loss: 0.177\n",
      "Training: Epoch 107, Batch 4, Loss: 0.164\n",
      "Training: Epoch 107, Batch 5, Loss: 0.125\n",
      "Training: Epoch 107, Batch 6, Loss: 0.146\n",
      "Training: Epoch 107, Batch 7, Loss: 0.143\n",
      "Training: Epoch 107, Batch 8, Loss: 0.12\n",
      "Training: Epoch 107, Batch 9, Loss: 0.127\n",
      "Training: Epoch 107, Batch 10, Loss: 0.087\n",
      "Training: Epoch 107, Batch 11, Loss: 0.127\n",
      "Training: Epoch 107, Batch 12, Loss: 0.142\n",
      "Training: Epoch 107, Batch 13, Loss: 0.148\n",
      "Training: Epoch 107, Batch 14, Loss: 0.133\n",
      "Training: Epoch 107, Batch 15, Loss: 0.162\n",
      "Training: Epoch 107, Batch 16, Loss: 0.24\n",
      "Training: Epoch 107, Batch 17, Loss: 0.144\n",
      "Training: Epoch 107, Batch 18, Loss: 0.141\n",
      "Training: Epoch 107, Batch 19, Loss: 0.139\n",
      "Val: Epoch 107, Loss: 0.259\n",
      "Training: Epoch 108, Batch 0, Loss: 0.14\n",
      "Training: Epoch 108, Batch 1, Loss: 0.153\n",
      "Training: Epoch 108, Batch 2, Loss: 0.155\n",
      "Training: Epoch 108, Batch 3, Loss: 0.12\n",
      "Training: Epoch 108, Batch 4, Loss: 0.157\n",
      "Training: Epoch 108, Batch 5, Loss: 0.11\n",
      "Training: Epoch 108, Batch 6, Loss: 0.1\n",
      "Training: Epoch 108, Batch 7, Loss: 0.134\n",
      "Training: Epoch 108, Batch 8, Loss: 0.16\n",
      "Training: Epoch 108, Batch 9, Loss: 0.183\n",
      "Training: Epoch 108, Batch 10, Loss: 0.173\n",
      "Training: Epoch 108, Batch 11, Loss: 0.126\n",
      "Training: Epoch 108, Batch 12, Loss: 0.131\n",
      "Training: Epoch 108, Batch 13, Loss: 0.194\n",
      "Training: Epoch 108, Batch 14, Loss: 0.221\n",
      "Training: Epoch 108, Batch 15, Loss: 0.111\n",
      "Training: Epoch 108, Batch 16, Loss: 0.161\n",
      "Training: Epoch 108, Batch 17, Loss: 0.166\n",
      "Training: Epoch 108, Batch 18, Loss: 0.135\n",
      "Training: Epoch 108, Batch 19, Loss: 0.171\n",
      "Val: Epoch 108, Loss: 0.248\n",
      "Training: Epoch 109, Batch 0, Loss: 0.117\n",
      "Training: Epoch 109, Batch 1, Loss: 0.122\n",
      "Training: Epoch 109, Batch 2, Loss: 0.142\n",
      "Training: Epoch 109, Batch 3, Loss: 0.149\n",
      "Training: Epoch 109, Batch 4, Loss: 0.156\n",
      "Training: Epoch 109, Batch 5, Loss: 0.134\n",
      "Training: Epoch 109, Batch 6, Loss: 0.166\n",
      "Training: Epoch 109, Batch 7, Loss: 0.268\n",
      "Training: Epoch 109, Batch 8, Loss: 0.191\n",
      "Training: Epoch 109, Batch 9, Loss: 0.14\n",
      "Training: Epoch 109, Batch 10, Loss: 0.178\n",
      "Training: Epoch 109, Batch 11, Loss: 0.163\n",
      "Training: Epoch 109, Batch 12, Loss: 0.152\n",
      "Training: Epoch 109, Batch 13, Loss: 0.139\n",
      "Training: Epoch 109, Batch 14, Loss: 0.187\n",
      "Training: Epoch 109, Batch 15, Loss: 0.131\n",
      "Training: Epoch 109, Batch 16, Loss: 0.175\n",
      "Training: Epoch 109, Batch 17, Loss: 0.122\n",
      "Training: Epoch 109, Batch 18, Loss: 0.156\n",
      "Training: Epoch 109, Batch 19, Loss: 0.134\n",
      "Val: Epoch 109, Loss: 0.289\n",
      "Training: Epoch 110, Batch 0, Loss: 0.125\n",
      "Training: Epoch 110, Batch 1, Loss: 0.181\n",
      "Training: Epoch 110, Batch 2, Loss: 0.144\n",
      "Training: Epoch 110, Batch 3, Loss: 0.126\n",
      "Training: Epoch 110, Batch 4, Loss: 0.145\n",
      "Training: Epoch 110, Batch 5, Loss: 0.141\n",
      "Training: Epoch 110, Batch 6, Loss: 0.114\n",
      "Training: Epoch 110, Batch 7, Loss: 0.169\n",
      "Training: Epoch 110, Batch 8, Loss: 0.141\n",
      "Training: Epoch 110, Batch 9, Loss: 0.122\n",
      "Training: Epoch 110, Batch 10, Loss: 0.158\n",
      "Training: Epoch 110, Batch 11, Loss: 0.177\n",
      "Training: Epoch 110, Batch 12, Loss: 0.21\n",
      "Training: Epoch 110, Batch 13, Loss: 0.141\n",
      "Training: Epoch 110, Batch 14, Loss: 0.146\n",
      "Training: Epoch 110, Batch 15, Loss: 0.124\n",
      "Training: Epoch 110, Batch 16, Loss: 0.171\n",
      "Training: Epoch 110, Batch 17, Loss: 0.142\n",
      "Training: Epoch 110, Batch 18, Loss: 0.117\n",
      "Training: Epoch 110, Batch 19, Loss: 0.128\n",
      "Val: Epoch 110, Loss: 0.235\n",
      "Training: Epoch 111, Batch 0, Loss: 0.169\n",
      "Training: Epoch 111, Batch 1, Loss: 0.11\n",
      "Training: Epoch 111, Batch 2, Loss: 0.132\n",
      "Training: Epoch 111, Batch 3, Loss: 0.136\n",
      "Training: Epoch 111, Batch 4, Loss: 0.129\n",
      "Training: Epoch 111, Batch 5, Loss: 0.119\n",
      "Training: Epoch 111, Batch 6, Loss: 0.172\n",
      "Training: Epoch 111, Batch 7, Loss: 0.143\n",
      "Training: Epoch 111, Batch 8, Loss: 0.12\n",
      "Training: Epoch 111, Batch 9, Loss: 0.189\n",
      "Training: Epoch 111, Batch 10, Loss: 0.088\n",
      "Training: Epoch 111, Batch 11, Loss: 0.136\n",
      "Training: Epoch 111, Batch 12, Loss: 0.132\n",
      "Training: Epoch 111, Batch 13, Loss: 0.159\n",
      "Training: Epoch 111, Batch 14, Loss: 0.184\n",
      "Training: Epoch 111, Batch 15, Loss: 0.105\n",
      "Training: Epoch 111, Batch 16, Loss: 0.151\n",
      "Training: Epoch 111, Batch 17, Loss: 0.132\n",
      "Training: Epoch 111, Batch 18, Loss: 0.193\n",
      "Training: Epoch 111, Batch 19, Loss: 0.1\n",
      "Val: Epoch 111, Loss: 0.231\n",
      "Training: Epoch 112, Batch 0, Loss: 0.116\n",
      "Training: Epoch 112, Batch 1, Loss: 0.168\n",
      "Training: Epoch 112, Batch 2, Loss: 0.147\n",
      "Training: Epoch 112, Batch 3, Loss: 0.156\n",
      "Training: Epoch 112, Batch 4, Loss: 0.113\n",
      "Training: Epoch 112, Batch 5, Loss: 0.159\n",
      "Training: Epoch 112, Batch 6, Loss: 0.227\n",
      "Training: Epoch 112, Batch 7, Loss: 0.136\n",
      "Training: Epoch 112, Batch 8, Loss: 0.117\n",
      "Training: Epoch 112, Batch 9, Loss: 0.137\n",
      "Training: Epoch 112, Batch 10, Loss: 0.13\n",
      "Training: Epoch 112, Batch 11, Loss: 0.118\n",
      "Training: Epoch 112, Batch 12, Loss: 0.196\n",
      "Training: Epoch 112, Batch 13, Loss: 0.14\n",
      "Training: Epoch 112, Batch 14, Loss: 0.147\n",
      "Training: Epoch 112, Batch 15, Loss: 0.144\n",
      "Training: Epoch 112, Batch 16, Loss: 0.179\n",
      "Training: Epoch 112, Batch 17, Loss: 0.201\n",
      "Training: Epoch 112, Batch 18, Loss: 0.158\n",
      "Training: Epoch 112, Batch 19, Loss: 0.111\n",
      "Val: Epoch 112, Loss: 0.235\n",
      "Training: Epoch 113, Batch 0, Loss: 0.163\n",
      "Training: Epoch 113, Batch 1, Loss: 0.136\n",
      "Training: Epoch 113, Batch 2, Loss: 0.115\n",
      "Training: Epoch 113, Batch 3, Loss: 0.149\n",
      "Training: Epoch 113, Batch 4, Loss: 0.173\n",
      "Training: Epoch 113, Batch 5, Loss: 0.154\n",
      "Training: Epoch 113, Batch 6, Loss: 0.163\n",
      "Training: Epoch 113, Batch 7, Loss: 0.101\n",
      "Training: Epoch 113, Batch 8, Loss: 0.152\n",
      "Training: Epoch 113, Batch 9, Loss: 0.146\n",
      "Training: Epoch 113, Batch 10, Loss: 0.138\n",
      "Training: Epoch 113, Batch 11, Loss: 0.148\n",
      "Training: Epoch 113, Batch 12, Loss: 0.149\n",
      "Training: Epoch 113, Batch 13, Loss: 0.134\n",
      "Training: Epoch 113, Batch 14, Loss: 0.159\n",
      "Training: Epoch 113, Batch 15, Loss: 0.143\n",
      "Training: Epoch 113, Batch 16, Loss: 0.143\n",
      "Training: Epoch 113, Batch 17, Loss: 0.13\n",
      "Training: Epoch 113, Batch 18, Loss: 0.137\n",
      "Training: Epoch 113, Batch 19, Loss: 0.159\n",
      "Val: Epoch 113, Loss: 0.238\n",
      "Training: Epoch 114, Batch 0, Loss: 0.148\n",
      "Training: Epoch 114, Batch 1, Loss: 0.205\n",
      "Training: Epoch 114, Batch 2, Loss: 0.175\n",
      "Training: Epoch 114, Batch 3, Loss: 0.119\n",
      "Training: Epoch 114, Batch 4, Loss: 0.139\n",
      "Training: Epoch 114, Batch 5, Loss: 0.116\n",
      "Training: Epoch 114, Batch 6, Loss: 0.156\n",
      "Training: Epoch 114, Batch 7, Loss: 0.153\n",
      "Training: Epoch 114, Batch 8, Loss: 0.127\n",
      "Training: Epoch 114, Batch 9, Loss: 0.151\n",
      "Training: Epoch 114, Batch 10, Loss: 0.165\n",
      "Training: Epoch 114, Batch 11, Loss: 0.163\n",
      "Training: Epoch 114, Batch 12, Loss: 0.116\n",
      "Training: Epoch 114, Batch 13, Loss: 0.113\n",
      "Training: Epoch 114, Batch 14, Loss: 0.124\n",
      "Training: Epoch 114, Batch 15, Loss: 0.139\n",
      "Training: Epoch 114, Batch 16, Loss: 0.112\n",
      "Training: Epoch 114, Batch 17, Loss: 0.198\n",
      "Training: Epoch 114, Batch 18, Loss: 0.104\n",
      "Training: Epoch 114, Batch 19, Loss: 0.178\n",
      "Val: Epoch 114, Loss: 0.247\n",
      "Training: Epoch 115, Batch 0, Loss: 0.175\n",
      "Training: Epoch 115, Batch 1, Loss: 0.131\n",
      "Training: Epoch 115, Batch 2, Loss: 0.142\n",
      "Training: Epoch 115, Batch 3, Loss: 0.14\n",
      "Training: Epoch 115, Batch 4, Loss: 0.154\n",
      "Training: Epoch 115, Batch 5, Loss: 0.135\n",
      "Training: Epoch 115, Batch 6, Loss: 0.172\n",
      "Training: Epoch 115, Batch 7, Loss: 0.158\n",
      "Training: Epoch 115, Batch 8, Loss: 0.13\n",
      "Training: Epoch 115, Batch 9, Loss: 0.117\n",
      "Training: Epoch 115, Batch 10, Loss: 0.142\n",
      "Training: Epoch 115, Batch 11, Loss: 0.165\n",
      "Training: Epoch 115, Batch 12, Loss: 0.159\n",
      "Training: Epoch 115, Batch 13, Loss: 0.137\n",
      "Training: Epoch 115, Batch 14, Loss: 0.137\n",
      "Training: Epoch 115, Batch 15, Loss: 0.134\n",
      "Training: Epoch 115, Batch 16, Loss: 0.126\n",
      "Training: Epoch 115, Batch 17, Loss: 0.142\n",
      "Training: Epoch 115, Batch 18, Loss: 0.123\n",
      "Training: Epoch 115, Batch 19, Loss: 0.109\n",
      "Val: Epoch 115, Loss: 0.248\n",
      "Training: Epoch 116, Batch 0, Loss: 0.113\n",
      "Training: Epoch 116, Batch 1, Loss: 0.135\n",
      "Training: Epoch 116, Batch 2, Loss: 0.111\n",
      "Training: Epoch 116, Batch 3, Loss: 0.243\n",
      "Training: Epoch 116, Batch 4, Loss: 0.145\n",
      "Training: Epoch 116, Batch 5, Loss: 0.126\n",
      "Training: Epoch 116, Batch 6, Loss: 0.162\n",
      "Training: Epoch 116, Batch 7, Loss: 0.128\n",
      "Training: Epoch 116, Batch 8, Loss: 0.153\n",
      "Training: Epoch 116, Batch 9, Loss: 0.113\n",
      "Training: Epoch 116, Batch 10, Loss: 0.172\n",
      "Training: Epoch 116, Batch 11, Loss: 0.143\n",
      "Training: Epoch 116, Batch 12, Loss: 0.155\n",
      "Training: Epoch 116, Batch 13, Loss: 0.158\n",
      "Training: Epoch 116, Batch 14, Loss: 0.15\n",
      "Training: Epoch 116, Batch 15, Loss: 0.128\n",
      "Training: Epoch 116, Batch 16, Loss: 0.105\n",
      "Training: Epoch 116, Batch 17, Loss: 0.137\n",
      "Training: Epoch 116, Batch 18, Loss: 0.182\n",
      "Training: Epoch 116, Batch 19, Loss: 0.123\n",
      "Val: Epoch 116, Loss: 0.218\n",
      "Training: Epoch 117, Batch 0, Loss: 0.144\n",
      "Training: Epoch 117, Batch 1, Loss: 0.149\n",
      "Training: Epoch 117, Batch 2, Loss: 0.161\n",
      "Training: Epoch 117, Batch 3, Loss: 0.15\n",
      "Training: Epoch 117, Batch 4, Loss: 0.171\n",
      "Training: Epoch 117, Batch 5, Loss: 0.092\n",
      "Training: Epoch 117, Batch 6, Loss: 0.143\n",
      "Training: Epoch 117, Batch 7, Loss: 0.162\n",
      "Training: Epoch 117, Batch 8, Loss: 0.156\n",
      "Training: Epoch 117, Batch 9, Loss: 0.125\n",
      "Training: Epoch 117, Batch 10, Loss: 0.151\n",
      "Training: Epoch 117, Batch 11, Loss: 0.163\n",
      "Training: Epoch 117, Batch 12, Loss: 0.101\n",
      "Training: Epoch 117, Batch 13, Loss: 0.156\n",
      "Training: Epoch 117, Batch 14, Loss: 0.133\n",
      "Training: Epoch 117, Batch 15, Loss: 0.105\n",
      "Training: Epoch 117, Batch 16, Loss: 0.117\n",
      "Training: Epoch 117, Batch 17, Loss: 0.146\n",
      "Training: Epoch 117, Batch 18, Loss: 0.127\n",
      "Training: Epoch 117, Batch 19, Loss: 0.166\n",
      "Val: Epoch 117, Loss: 0.229\n",
      "Training: Epoch 118, Batch 0, Loss: 0.114\n",
      "Training: Epoch 118, Batch 1, Loss: 0.131\n",
      "Training: Epoch 118, Batch 2, Loss: 0.129\n",
      "Training: Epoch 118, Batch 3, Loss: 0.221\n",
      "Training: Epoch 118, Batch 4, Loss: 0.1\n",
      "Training: Epoch 118, Batch 5, Loss: 0.097\n",
      "Training: Epoch 118, Batch 6, Loss: 0.113\n",
      "Training: Epoch 118, Batch 7, Loss: 0.209\n",
      "Training: Epoch 118, Batch 8, Loss: 0.141\n",
      "Training: Epoch 118, Batch 9, Loss: 0.132\n",
      "Training: Epoch 118, Batch 10, Loss: 0.157\n",
      "Training: Epoch 118, Batch 11, Loss: 0.177\n",
      "Training: Epoch 118, Batch 12, Loss: 0.106\n",
      "Training: Epoch 118, Batch 13, Loss: 0.163\n",
      "Training: Epoch 118, Batch 14, Loss: 0.199\n",
      "Training: Epoch 118, Batch 15, Loss: 0.193\n",
      "Training: Epoch 118, Batch 16, Loss: 0.132\n",
      "Training: Epoch 118, Batch 17, Loss: 0.178\n",
      "Training: Epoch 118, Batch 18, Loss: 0.156\n",
      "Training: Epoch 118, Batch 19, Loss: 0.134\n",
      "Val: Epoch 118, Loss: 0.249\n",
      "Training: Epoch 119, Batch 0, Loss: 0.161\n",
      "Training: Epoch 119, Batch 1, Loss: 0.136\n",
      "Training: Epoch 119, Batch 2, Loss: 0.156\n",
      "Training: Epoch 119, Batch 3, Loss: 0.154\n",
      "Training: Epoch 119, Batch 4, Loss: 0.155\n",
      "Training: Epoch 119, Batch 5, Loss: 0.16\n",
      "Training: Epoch 119, Batch 6, Loss: 0.114\n",
      "Training: Epoch 119, Batch 7, Loss: 0.11\n",
      "Training: Epoch 119, Batch 8, Loss: 0.165\n",
      "Training: Epoch 119, Batch 9, Loss: 0.158\n",
      "Training: Epoch 119, Batch 10, Loss: 0.15\n",
      "Training: Epoch 119, Batch 11, Loss: 0.149\n",
      "Training: Epoch 119, Batch 12, Loss: 0.136\n",
      "Training: Epoch 119, Batch 13, Loss: 0.158\n",
      "Training: Epoch 119, Batch 14, Loss: 0.127\n",
      "Training: Epoch 119, Batch 15, Loss: 0.1\n",
      "Training: Epoch 119, Batch 16, Loss: 0.121\n",
      "Training: Epoch 119, Batch 17, Loss: 0.17\n",
      "Training: Epoch 119, Batch 18, Loss: 0.132\n",
      "Training: Epoch 119, Batch 19, Loss: 0.122\n",
      "Val: Epoch 119, Loss: 0.238\n",
      "Training: Epoch 120, Batch 0, Loss: 0.145\n",
      "Training: Epoch 120, Batch 1, Loss: 0.111\n",
      "Training: Epoch 120, Batch 2, Loss: 0.105\n",
      "Training: Epoch 120, Batch 3, Loss: 0.147\n",
      "Training: Epoch 120, Batch 4, Loss: 0.107\n",
      "Training: Epoch 120, Batch 5, Loss: 0.163\n",
      "Training: Epoch 120, Batch 6, Loss: 0.145\n",
      "Training: Epoch 120, Batch 7, Loss: 0.118\n",
      "Training: Epoch 120, Batch 8, Loss: 0.138\n",
      "Training: Epoch 120, Batch 9, Loss: 0.13\n",
      "Training: Epoch 120, Batch 10, Loss: 0.142\n",
      "Training: Epoch 120, Batch 11, Loss: 0.12\n",
      "Training: Epoch 120, Batch 12, Loss: 0.112\n",
      "Training: Epoch 120, Batch 13, Loss: 0.158\n",
      "Training: Epoch 120, Batch 14, Loss: 0.135\n",
      "Training: Epoch 120, Batch 15, Loss: 0.148\n",
      "Training: Epoch 120, Batch 16, Loss: 0.116\n",
      "Training: Epoch 120, Batch 17, Loss: 0.13\n",
      "Training: Epoch 120, Batch 18, Loss: 0.186\n",
      "Training: Epoch 120, Batch 19, Loss: 0.19\n",
      "Val: Epoch 120, Loss: 0.255\n",
      "Training: Epoch 121, Batch 0, Loss: 0.119\n",
      "Training: Epoch 121, Batch 1, Loss: 0.196\n",
      "Training: Epoch 121, Batch 2, Loss: 0.131\n",
      "Training: Epoch 121, Batch 3, Loss: 0.133\n",
      "Training: Epoch 121, Batch 4, Loss: 0.168\n",
      "Training: Epoch 121, Batch 5, Loss: 0.129\n",
      "Training: Epoch 121, Batch 6, Loss: 0.117\n",
      "Training: Epoch 121, Batch 7, Loss: 0.139\n",
      "Training: Epoch 121, Batch 8, Loss: 0.146\n",
      "Training: Epoch 121, Batch 9, Loss: 0.128\n",
      "Training: Epoch 121, Batch 10, Loss: 0.109\n",
      "Training: Epoch 121, Batch 11, Loss: 0.128\n",
      "Training: Epoch 121, Batch 12, Loss: 0.129\n",
      "Training: Epoch 121, Batch 13, Loss: 0.107\n",
      "Training: Epoch 121, Batch 14, Loss: 0.198\n",
      "Training: Epoch 121, Batch 15, Loss: 0.147\n",
      "Training: Epoch 121, Batch 16, Loss: 0.154\n",
      "Training: Epoch 121, Batch 17, Loss: 0.133\n",
      "Training: Epoch 121, Batch 18, Loss: 0.143\n",
      "Training: Epoch 121, Batch 19, Loss: 0.138\n",
      "Val: Epoch 121, Loss: 0.237\n",
      "Training: Epoch 122, Batch 0, Loss: 0.179\n",
      "Training: Epoch 122, Batch 1, Loss: 0.113\n",
      "Training: Epoch 122, Batch 2, Loss: 0.163\n",
      "Training: Epoch 122, Batch 3, Loss: 0.161\n",
      "Training: Epoch 122, Batch 4, Loss: 0.092\n",
      "Training: Epoch 122, Batch 5, Loss: 0.156\n",
      "Training: Epoch 122, Batch 6, Loss: 0.125\n",
      "Training: Epoch 122, Batch 7, Loss: 0.142\n",
      "Training: Epoch 122, Batch 8, Loss: 0.127\n",
      "Training: Epoch 122, Batch 9, Loss: 0.129\n",
      "Training: Epoch 122, Batch 10, Loss: 0.195\n",
      "Training: Epoch 122, Batch 11, Loss: 0.115\n",
      "Training: Epoch 122, Batch 12, Loss: 0.133\n",
      "Training: Epoch 122, Batch 13, Loss: 0.111\n",
      "Training: Epoch 122, Batch 14, Loss: 0.138\n",
      "Training: Epoch 122, Batch 15, Loss: 0.151\n",
      "Training: Epoch 122, Batch 16, Loss: 0.118\n",
      "Training: Epoch 122, Batch 17, Loss: 0.16\n",
      "Training: Epoch 122, Batch 18, Loss: 0.184\n",
      "Training: Epoch 122, Batch 19, Loss: 0.174\n",
      "Val: Epoch 122, Loss: 0.245\n",
      "Training: Epoch 123, Batch 0, Loss: 0.135\n",
      "Training: Epoch 123, Batch 1, Loss: 0.14\n",
      "Training: Epoch 123, Batch 2, Loss: 0.148\n",
      "Training: Epoch 123, Batch 3, Loss: 0.167\n",
      "Training: Epoch 123, Batch 4, Loss: 0.135\n",
      "Training: Epoch 123, Batch 5, Loss: 0.125\n",
      "Training: Epoch 123, Batch 6, Loss: 0.194\n",
      "Training: Epoch 123, Batch 7, Loss: 0.125\n",
      "Training: Epoch 123, Batch 8, Loss: 0.101\n",
      "Training: Epoch 123, Batch 9, Loss: 0.122\n",
      "Training: Epoch 123, Batch 10, Loss: 0.15\n",
      "Training: Epoch 123, Batch 11, Loss: 0.149\n",
      "Training: Epoch 123, Batch 12, Loss: 0.103\n",
      "Training: Epoch 123, Batch 13, Loss: 0.124\n",
      "Training: Epoch 123, Batch 14, Loss: 0.2\n",
      "Training: Epoch 123, Batch 15, Loss: 0.116\n",
      "Training: Epoch 123, Batch 16, Loss: 0.117\n",
      "Training: Epoch 123, Batch 17, Loss: 0.139\n",
      "Training: Epoch 123, Batch 18, Loss: 0.144\n",
      "Training: Epoch 123, Batch 19, Loss: 0.156\n",
      "Val: Epoch 123, Loss: 0.238\n",
      "Training: Epoch 124, Batch 0, Loss: 0.144\n",
      "Training: Epoch 124, Batch 1, Loss: 0.131\n",
      "Training: Epoch 124, Batch 2, Loss: 0.143\n",
      "Training: Epoch 124, Batch 3, Loss: 0.137\n",
      "Training: Epoch 124, Batch 4, Loss: 0.136\n",
      "Training: Epoch 124, Batch 5, Loss: 0.117\n",
      "Training: Epoch 124, Batch 6, Loss: 0.161\n",
      "Training: Epoch 124, Batch 7, Loss: 0.133\n",
      "Training: Epoch 124, Batch 8, Loss: 0.149\n",
      "Training: Epoch 124, Batch 9, Loss: 0.102\n",
      "Training: Epoch 124, Batch 10, Loss: 0.134\n",
      "Training: Epoch 124, Batch 11, Loss: 0.154\n",
      "Training: Epoch 124, Batch 12, Loss: 0.152\n",
      "Training: Epoch 124, Batch 13, Loss: 0.104\n",
      "Training: Epoch 124, Batch 14, Loss: 0.167\n",
      "Training: Epoch 124, Batch 15, Loss: 0.117\n",
      "Training: Epoch 124, Batch 16, Loss: 0.217\n",
      "Training: Epoch 124, Batch 17, Loss: 0.159\n",
      "Training: Epoch 124, Batch 18, Loss: 0.091\n",
      "Training: Epoch 124, Batch 19, Loss: 0.138\n",
      "Val: Epoch 124, Loss: 0.285\n",
      "Training: Epoch 125, Batch 0, Loss: 0.127\n",
      "Training: Epoch 125, Batch 1, Loss: 0.105\n",
      "Training: Epoch 125, Batch 2, Loss: 0.144\n",
      "Training: Epoch 125, Batch 3, Loss: 0.111\n",
      "Training: Epoch 125, Batch 4, Loss: 0.124\n",
      "Training: Epoch 125, Batch 5, Loss: 0.123\n",
      "Training: Epoch 125, Batch 6, Loss: 0.165\n",
      "Training: Epoch 125, Batch 7, Loss: 0.124\n",
      "Training: Epoch 125, Batch 8, Loss: 0.159\n",
      "Training: Epoch 125, Batch 9, Loss: 0.152\n",
      "Training: Epoch 125, Batch 10, Loss: 0.1\n",
      "Training: Epoch 125, Batch 11, Loss: 0.117\n",
      "Training: Epoch 125, Batch 12, Loss: 0.125\n",
      "Training: Epoch 125, Batch 13, Loss: 0.135\n",
      "Training: Epoch 125, Batch 14, Loss: 0.139\n",
      "Training: Epoch 125, Batch 15, Loss: 0.128\n",
      "Training: Epoch 125, Batch 16, Loss: 0.165\n",
      "Training: Epoch 125, Batch 17, Loss: 0.12\n",
      "Training: Epoch 125, Batch 18, Loss: 0.151\n",
      "Training: Epoch 125, Batch 19, Loss: 0.141\n",
      "Val: Epoch 125, Loss: 0.241\n",
      "Training: Epoch 126, Batch 0, Loss: 0.167\n",
      "Training: Epoch 126, Batch 1, Loss: 0.138\n",
      "Training: Epoch 126, Batch 2, Loss: 0.137\n",
      "Training: Epoch 126, Batch 3, Loss: 0.126\n",
      "Training: Epoch 126, Batch 4, Loss: 0.132\n",
      "Training: Epoch 126, Batch 5, Loss: 0.162\n",
      "Training: Epoch 126, Batch 6, Loss: 0.17\n",
      "Training: Epoch 126, Batch 7, Loss: 0.129\n",
      "Training: Epoch 126, Batch 8, Loss: 0.187\n",
      "Training: Epoch 126, Batch 9, Loss: 0.155\n",
      "Training: Epoch 126, Batch 10, Loss: 0.192\n",
      "Training: Epoch 126, Batch 11, Loss: 0.229\n",
      "Training: Epoch 126, Batch 12, Loss: 0.201\n",
      "Training: Epoch 126, Batch 13, Loss: 0.158\n",
      "Training: Epoch 126, Batch 14, Loss: 0.151\n",
      "Training: Epoch 126, Batch 15, Loss: 0.182\n",
      "Training: Epoch 126, Batch 16, Loss: 0.118\n",
      "Training: Epoch 126, Batch 17, Loss: 0.144\n",
      "Training: Epoch 126, Batch 18, Loss: 0.121\n",
      "Training: Epoch 126, Batch 19, Loss: 0.279\n",
      "Val: Epoch 126, Loss: 0.258\n",
      "Training: Epoch 127, Batch 0, Loss: 0.129\n",
      "Training: Epoch 127, Batch 1, Loss: 0.124\n",
      "Training: Epoch 127, Batch 2, Loss: 0.098\n",
      "Training: Epoch 127, Batch 3, Loss: 0.146\n",
      "Training: Epoch 127, Batch 4, Loss: 0.197\n",
      "Training: Epoch 127, Batch 5, Loss: 0.239\n",
      "Training: Epoch 127, Batch 6, Loss: 0.155\n",
      "Training: Epoch 127, Batch 7, Loss: 0.154\n",
      "Training: Epoch 127, Batch 8, Loss: 0.127\n",
      "Training: Epoch 127, Batch 9, Loss: 0.132\n",
      "Training: Epoch 127, Batch 10, Loss: 0.104\n",
      "Training: Epoch 127, Batch 11, Loss: 0.126\n",
      "Training: Epoch 127, Batch 12, Loss: 0.179\n",
      "Training: Epoch 127, Batch 13, Loss: 0.133\n",
      "Training: Epoch 127, Batch 14, Loss: 0.142\n",
      "Training: Epoch 127, Batch 15, Loss: 0.117\n",
      "Training: Epoch 127, Batch 16, Loss: 0.13\n",
      "Training: Epoch 127, Batch 17, Loss: 0.156\n",
      "Training: Epoch 127, Batch 18, Loss: 0.105\n",
      "Training: Epoch 127, Batch 19, Loss: 0.21\n",
      "Val: Epoch 127, Loss: 0.233\n",
      "Training: Epoch 128, Batch 0, Loss: 0.153\n",
      "Training: Epoch 128, Batch 1, Loss: 0.134\n",
      "Training: Epoch 128, Batch 2, Loss: 0.156\n",
      "Training: Epoch 128, Batch 3, Loss: 0.162\n",
      "Training: Epoch 128, Batch 4, Loss: 0.11\n",
      "Training: Epoch 128, Batch 5, Loss: 0.115\n",
      "Training: Epoch 128, Batch 6, Loss: 0.116\n",
      "Training: Epoch 128, Batch 7, Loss: 0.132\n",
      "Training: Epoch 128, Batch 8, Loss: 0.13\n",
      "Training: Epoch 128, Batch 9, Loss: 0.156\n",
      "Training: Epoch 128, Batch 10, Loss: 0.134\n",
      "Training: Epoch 128, Batch 11, Loss: 0.119\n",
      "Training: Epoch 128, Batch 12, Loss: 0.162\n",
      "Training: Epoch 128, Batch 13, Loss: 0.104\n",
      "Training: Epoch 128, Batch 14, Loss: 0.119\n",
      "Training: Epoch 128, Batch 15, Loss: 0.165\n",
      "Training: Epoch 128, Batch 16, Loss: 0.137\n",
      "Training: Epoch 128, Batch 17, Loss: 0.144\n",
      "Training: Epoch 128, Batch 18, Loss: 0.11\n",
      "Training: Epoch 128, Batch 19, Loss: 0.1\n",
      "Val: Epoch 128, Loss: 0.252\n",
      "Training: Epoch 129, Batch 0, Loss: 0.151\n",
      "Training: Epoch 129, Batch 1, Loss: 0.153\n",
      "Training: Epoch 129, Batch 2, Loss: 0.125\n",
      "Training: Epoch 129, Batch 3, Loss: 0.129\n",
      "Training: Epoch 129, Batch 4, Loss: 0.123\n",
      "Training: Epoch 129, Batch 5, Loss: 0.182\n",
      "Training: Epoch 129, Batch 6, Loss: 0.122\n",
      "Training: Epoch 129, Batch 7, Loss: 0.136\n",
      "Training: Epoch 129, Batch 8, Loss: 0.123\n",
      "Training: Epoch 129, Batch 9, Loss: 0.177\n",
      "Training: Epoch 129, Batch 10, Loss: 0.168\n",
      "Training: Epoch 129, Batch 11, Loss: 0.153\n",
      "Training: Epoch 129, Batch 12, Loss: 0.106\n",
      "Training: Epoch 129, Batch 13, Loss: 0.126\n",
      "Training: Epoch 129, Batch 14, Loss: 0.119\n",
      "Training: Epoch 129, Batch 15, Loss: 0.166\n",
      "Training: Epoch 129, Batch 16, Loss: 0.142\n",
      "Training: Epoch 129, Batch 17, Loss: 0.128\n",
      "Training: Epoch 129, Batch 18, Loss: 0.132\n",
      "Training: Epoch 129, Batch 19, Loss: 0.137\n",
      "Val: Epoch 129, Loss: 0.303\n",
      "Training: Epoch 130, Batch 0, Loss: 0.15\n",
      "Training: Epoch 130, Batch 1, Loss: 0.171\n",
      "Training: Epoch 130, Batch 2, Loss: 0.115\n",
      "Training: Epoch 130, Batch 3, Loss: 0.153\n",
      "Training: Epoch 130, Batch 4, Loss: 0.123\n",
      "Training: Epoch 130, Batch 5, Loss: 0.142\n",
      "Training: Epoch 130, Batch 6, Loss: 0.145\n",
      "Training: Epoch 130, Batch 7, Loss: 0.128\n",
      "Training: Epoch 130, Batch 8, Loss: 0.107\n",
      "Training: Epoch 130, Batch 9, Loss: 0.12\n",
      "Training: Epoch 130, Batch 10, Loss: 0.166\n",
      "Training: Epoch 130, Batch 11, Loss: 0.137\n",
      "Training: Epoch 130, Batch 12, Loss: 0.117\n",
      "Training: Epoch 130, Batch 13, Loss: 0.134\n",
      "Training: Epoch 130, Batch 14, Loss: 0.181\n",
      "Training: Epoch 130, Batch 15, Loss: 0.152\n",
      "Training: Epoch 130, Batch 16, Loss: 0.199\n",
      "Training: Epoch 130, Batch 17, Loss: 0.1\n",
      "Training: Epoch 130, Batch 18, Loss: 0.12\n",
      "Training: Epoch 130, Batch 19, Loss: 0.115\n",
      "Val: Epoch 130, Loss: 0.235\n",
      "Training: Epoch 131, Batch 0, Loss: 0.141\n",
      "Training: Epoch 131, Batch 1, Loss: 0.132\n",
      "Training: Epoch 131, Batch 2, Loss: 0.138\n",
      "Training: Epoch 131, Batch 3, Loss: 0.122\n",
      "Training: Epoch 131, Batch 4, Loss: 0.169\n",
      "Training: Epoch 131, Batch 5, Loss: 0.104\n",
      "Training: Epoch 131, Batch 6, Loss: 0.097\n",
      "Training: Epoch 131, Batch 7, Loss: 0.152\n",
      "Training: Epoch 131, Batch 8, Loss: 0.143\n",
      "Training: Epoch 131, Batch 9, Loss: 0.203\n",
      "Training: Epoch 131, Batch 10, Loss: 0.099\n",
      "Training: Epoch 131, Batch 11, Loss: 0.153\n",
      "Training: Epoch 131, Batch 12, Loss: 0.09\n",
      "Training: Epoch 131, Batch 13, Loss: 0.128\n",
      "Training: Epoch 131, Batch 14, Loss: 0.153\n",
      "Training: Epoch 131, Batch 15, Loss: 0.128\n",
      "Training: Epoch 131, Batch 16, Loss: 0.158\n",
      "Training: Epoch 131, Batch 17, Loss: 0.123\n",
      "Training: Epoch 131, Batch 18, Loss: 0.097\n",
      "Training: Epoch 131, Batch 19, Loss: 0.13\n",
      "Val: Epoch 131, Loss: 0.25\n",
      "Training: Epoch 132, Batch 0, Loss: 0.132\n",
      "Training: Epoch 132, Batch 1, Loss: 0.185\n",
      "Training: Epoch 132, Batch 2, Loss: 0.105\n",
      "Training: Epoch 132, Batch 3, Loss: 0.151\n",
      "Training: Epoch 132, Batch 4, Loss: 0.118\n",
      "Training: Epoch 132, Batch 5, Loss: 0.155\n",
      "Training: Epoch 132, Batch 6, Loss: 0.129\n",
      "Training: Epoch 132, Batch 7, Loss: 0.122\n",
      "Training: Epoch 132, Batch 8, Loss: 0.109\n",
      "Training: Epoch 132, Batch 9, Loss: 0.121\n",
      "Training: Epoch 132, Batch 10, Loss: 0.162\n",
      "Training: Epoch 132, Batch 11, Loss: 0.136\n",
      "Training: Epoch 132, Batch 12, Loss: 0.105\n",
      "Training: Epoch 132, Batch 13, Loss: 0.129\n",
      "Training: Epoch 132, Batch 14, Loss: 0.143\n",
      "Training: Epoch 132, Batch 15, Loss: 0.134\n",
      "Training: Epoch 132, Batch 16, Loss: 0.127\n",
      "Training: Epoch 132, Batch 17, Loss: 0.152\n",
      "Training: Epoch 132, Batch 18, Loss: 0.112\n",
      "Training: Epoch 132, Batch 19, Loss: 0.082\n",
      "Val: Epoch 132, Loss: 0.261\n",
      "Training: Epoch 133, Batch 0, Loss: 0.127\n",
      "Training: Epoch 133, Batch 1, Loss: 0.11\n",
      "Training: Epoch 133, Batch 2, Loss: 0.134\n",
      "Training: Epoch 133, Batch 3, Loss: 0.129\n",
      "Training: Epoch 133, Batch 4, Loss: 0.112\n",
      "Training: Epoch 133, Batch 5, Loss: 0.123\n",
      "Training: Epoch 133, Batch 6, Loss: 0.156\n",
      "Training: Epoch 133, Batch 7, Loss: 0.136\n",
      "Training: Epoch 133, Batch 8, Loss: 0.17\n",
      "Training: Epoch 133, Batch 9, Loss: 0.115\n",
      "Training: Epoch 133, Batch 10, Loss: 0.152\n",
      "Training: Epoch 133, Batch 11, Loss: 0.136\n",
      "Training: Epoch 133, Batch 12, Loss: 0.124\n",
      "Training: Epoch 133, Batch 13, Loss: 0.244\n",
      "Training: Epoch 133, Batch 14, Loss: 0.15\n",
      "Training: Epoch 133, Batch 15, Loss: 0.142\n",
      "Training: Epoch 133, Batch 16, Loss: 0.131\n",
      "Training: Epoch 133, Batch 17, Loss: 0.134\n",
      "Training: Epoch 133, Batch 18, Loss: 0.235\n",
      "Training: Epoch 133, Batch 19, Loss: 0.151\n",
      "Val: Epoch 133, Loss: 0.257\n",
      "Training: Epoch 134, Batch 0, Loss: 0.141\n",
      "Training: Epoch 134, Batch 1, Loss: 0.173\n",
      "Training: Epoch 134, Batch 2, Loss: 0.136\n",
      "Training: Epoch 134, Batch 3, Loss: 0.111\n",
      "Training: Epoch 134, Batch 4, Loss: 0.119\n",
      "Training: Epoch 134, Batch 5, Loss: 0.138\n",
      "Training: Epoch 134, Batch 6, Loss: 0.125\n",
      "Training: Epoch 134, Batch 7, Loss: 0.119\n",
      "Training: Epoch 134, Batch 8, Loss: 0.118\n",
      "Training: Epoch 134, Batch 9, Loss: 0.153\n",
      "Training: Epoch 134, Batch 10, Loss: 0.147\n",
      "Training: Epoch 134, Batch 11, Loss: 0.211\n",
      "Training: Epoch 134, Batch 12, Loss: 0.168\n",
      "Training: Epoch 134, Batch 13, Loss: 0.153\n",
      "Training: Epoch 134, Batch 14, Loss: 0.148\n",
      "Training: Epoch 134, Batch 15, Loss: 0.143\n",
      "Training: Epoch 134, Batch 16, Loss: 0.167\n",
      "Training: Epoch 134, Batch 17, Loss: 0.456\n",
      "Training: Epoch 134, Batch 18, Loss: 0.122\n",
      "Training: Epoch 134, Batch 19, Loss: 0.195\n",
      "Val: Epoch 134, Loss: 0.309\n",
      "Training: Epoch 135, Batch 0, Loss: 0.176\n",
      "Training: Epoch 135, Batch 1, Loss: 0.165\n",
      "Training: Epoch 135, Batch 2, Loss: 0.184\n",
      "Training: Epoch 135, Batch 3, Loss: 0.171\n",
      "Training: Epoch 135, Batch 4, Loss: 0.175\n",
      "Training: Epoch 135, Batch 5, Loss: 0.235\n",
      "Training: Epoch 135, Batch 6, Loss: 0.132\n",
      "Training: Epoch 135, Batch 7, Loss: 0.175\n",
      "Training: Epoch 135, Batch 8, Loss: 0.154\n",
      "Training: Epoch 135, Batch 9, Loss: 0.111\n",
      "Training: Epoch 135, Batch 10, Loss: 0.189\n",
      "Training: Epoch 135, Batch 11, Loss: 0.281\n",
      "Training: Epoch 135, Batch 12, Loss: 0.135\n",
      "Training: Epoch 135, Batch 13, Loss: 0.149\n",
      "Training: Epoch 135, Batch 14, Loss: 0.137\n",
      "Training: Epoch 135, Batch 15, Loss: 0.161\n",
      "Training: Epoch 135, Batch 16, Loss: 0.188\n",
      "Training: Epoch 135, Batch 17, Loss: 0.156\n",
      "Training: Epoch 135, Batch 18, Loss: 0.13\n",
      "Training: Epoch 135, Batch 19, Loss: 0.33\n",
      "Val: Epoch 135, Loss: 0.268\n",
      "Training: Epoch 136, Batch 0, Loss: 0.161\n",
      "Training: Epoch 136, Batch 1, Loss: 0.165\n",
      "Training: Epoch 136, Batch 2, Loss: 0.129\n",
      "Training: Epoch 136, Batch 3, Loss: 0.157\n",
      "Training: Epoch 136, Batch 4, Loss: 0.192\n",
      "Training: Epoch 136, Batch 5, Loss: 0.121\n",
      "Training: Epoch 136, Batch 6, Loss: 0.139\n",
      "Training: Epoch 136, Batch 7, Loss: 0.109\n",
      "Training: Epoch 136, Batch 8, Loss: 0.149\n",
      "Training: Epoch 136, Batch 9, Loss: 0.169\n",
      "Training: Epoch 136, Batch 10, Loss: 0.15\n",
      "Training: Epoch 136, Batch 11, Loss: 0.138\n",
      "Training: Epoch 136, Batch 12, Loss: 0.194\n",
      "Training: Epoch 136, Batch 13, Loss: 0.14\n",
      "Training: Epoch 136, Batch 14, Loss: 0.15\n",
      "Training: Epoch 136, Batch 15, Loss: 0.154\n",
      "Training: Epoch 136, Batch 16, Loss: 0.156\n",
      "Training: Epoch 136, Batch 17, Loss: 0.144\n",
      "Training: Epoch 136, Batch 18, Loss: 0.157\n",
      "Training: Epoch 136, Batch 19, Loss: 0.198\n",
      "Val: Epoch 136, Loss: 0.306\n",
      "Training: Epoch 137, Batch 0, Loss: 0.114\n",
      "Training: Epoch 137, Batch 1, Loss: 0.177\n",
      "Training: Epoch 137, Batch 2, Loss: 0.189\n",
      "Training: Epoch 137, Batch 3, Loss: 0.122\n",
      "Training: Epoch 137, Batch 4, Loss: 0.219\n",
      "Training: Epoch 137, Batch 5, Loss: 0.175\n",
      "Training: Epoch 137, Batch 6, Loss: 0.237\n",
      "Training: Epoch 137, Batch 7, Loss: 0.113\n",
      "Training: Epoch 137, Batch 8, Loss: 0.141\n",
      "Training: Epoch 137, Batch 9, Loss: 0.198\n",
      "Training: Epoch 137, Batch 10, Loss: 0.142\n",
      "Training: Epoch 137, Batch 11, Loss: 0.143\n",
      "Training: Epoch 137, Batch 12, Loss: 0.111\n",
      "Training: Epoch 137, Batch 13, Loss: 0.18\n",
      "Training: Epoch 137, Batch 14, Loss: 0.214\n",
      "Training: Epoch 137, Batch 15, Loss: 0.174\n",
      "Training: Epoch 137, Batch 16, Loss: 0.15\n",
      "Training: Epoch 137, Batch 17, Loss: 0.125\n",
      "Training: Epoch 137, Batch 18, Loss: 0.177\n",
      "Training: Epoch 137, Batch 19, Loss: 0.191\n",
      "Val: Epoch 137, Loss: 0.29\n",
      "Training: Epoch 138, Batch 0, Loss: 0.149\n",
      "Training: Epoch 138, Batch 1, Loss: 0.18\n",
      "Training: Epoch 138, Batch 2, Loss: 0.192\n",
      "Training: Epoch 138, Batch 3, Loss: 0.149\n",
      "Training: Epoch 138, Batch 4, Loss: 0.181\n",
      "Training: Epoch 138, Batch 5, Loss: 0.137\n",
      "Training: Epoch 138, Batch 6, Loss: 0.155\n",
      "Training: Epoch 138, Batch 7, Loss: 0.246\n",
      "Training: Epoch 138, Batch 8, Loss: 0.141\n",
      "Training: Epoch 138, Batch 9, Loss: 0.182\n",
      "Training: Epoch 138, Batch 10, Loss: 0.126\n",
      "Training: Epoch 138, Batch 11, Loss: 0.194\n",
      "Training: Epoch 138, Batch 12, Loss: 0.151\n",
      "Training: Epoch 138, Batch 13, Loss: 0.137\n",
      "Training: Epoch 138, Batch 14, Loss: 0.142\n",
      "Training: Epoch 138, Batch 15, Loss: 0.178\n",
      "Training: Epoch 138, Batch 16, Loss: 0.151\n",
      "Training: Epoch 138, Batch 17, Loss: 0.129\n",
      "Training: Epoch 138, Batch 18, Loss: 0.142\n",
      "Training: Epoch 138, Batch 19, Loss: 0.112\n",
      "Val: Epoch 138, Loss: 0.245\n",
      "Training: Epoch 139, Batch 0, Loss: 0.135\n",
      "Training: Epoch 139, Batch 1, Loss: 0.107\n",
      "Training: Epoch 139, Batch 2, Loss: 0.121\n",
      "Training: Epoch 139, Batch 3, Loss: 0.115\n",
      "Training: Epoch 139, Batch 4, Loss: 0.178\n",
      "Training: Epoch 139, Batch 5, Loss: 0.138\n",
      "Training: Epoch 139, Batch 6, Loss: 0.188\n",
      "Training: Epoch 139, Batch 7, Loss: 0.224\n",
      "Training: Epoch 139, Batch 8, Loss: 0.131\n",
      "Training: Epoch 139, Batch 9, Loss: 0.102\n",
      "Training: Epoch 139, Batch 10, Loss: 0.181\n",
      "Training: Epoch 139, Batch 11, Loss: 0.143\n",
      "Training: Epoch 139, Batch 12, Loss: 0.29\n",
      "Training: Epoch 139, Batch 13, Loss: 0.174\n",
      "Training: Epoch 139, Batch 14, Loss: 0.185\n",
      "Training: Epoch 139, Batch 15, Loss: 0.22\n",
      "Training: Epoch 139, Batch 16, Loss: 0.132\n",
      "Training: Epoch 139, Batch 17, Loss: 0.218\n",
      "Training: Epoch 139, Batch 18, Loss: 0.145\n",
      "Training: Epoch 139, Batch 19, Loss: 0.152\n",
      "Val: Epoch 139, Loss: 0.259\n",
      "Training: Epoch 140, Batch 0, Loss: 0.126\n",
      "Training: Epoch 140, Batch 1, Loss: 0.228\n",
      "Training: Epoch 140, Batch 2, Loss: 0.21\n",
      "Training: Epoch 140, Batch 3, Loss: 0.121\n",
      "Training: Epoch 140, Batch 4, Loss: 0.128\n",
      "Training: Epoch 140, Batch 5, Loss: 0.115\n",
      "Training: Epoch 140, Batch 6, Loss: 0.149\n",
      "Training: Epoch 140, Batch 7, Loss: 0.208\n",
      "Training: Epoch 140, Batch 8, Loss: 0.193\n",
      "Training: Epoch 140, Batch 9, Loss: 0.16\n",
      "Training: Epoch 140, Batch 10, Loss: 0.139\n",
      "Training: Epoch 140, Batch 11, Loss: 0.142\n",
      "Training: Epoch 140, Batch 12, Loss: 0.204\n",
      "Training: Epoch 140, Batch 13, Loss: 0.17\n",
      "Training: Epoch 140, Batch 14, Loss: 0.097\n",
      "Training: Epoch 140, Batch 15, Loss: 0.12\n",
      "Training: Epoch 140, Batch 16, Loss: 0.149\n",
      "Training: Epoch 140, Batch 17, Loss: 0.165\n",
      "Training: Epoch 140, Batch 18, Loss: 0.215\n",
      "Training: Epoch 140, Batch 19, Loss: 0.179\n",
      "Val: Epoch 140, Loss: 0.241\n",
      "Training: Epoch 141, Batch 0, Loss: 0.15\n",
      "Training: Epoch 141, Batch 1, Loss: 0.137\n",
      "Training: Epoch 141, Batch 2, Loss: 0.129\n",
      "Training: Epoch 141, Batch 3, Loss: 0.192\n",
      "Training: Epoch 141, Batch 4, Loss: 0.155\n",
      "Training: Epoch 141, Batch 5, Loss: 0.13\n",
      "Training: Epoch 141, Batch 6, Loss: 0.155\n",
      "Training: Epoch 141, Batch 7, Loss: 0.15\n",
      "Training: Epoch 141, Batch 8, Loss: 0.251\n",
      "Training: Epoch 141, Batch 9, Loss: 0.173\n",
      "Training: Epoch 141, Batch 10, Loss: 0.223\n",
      "Training: Epoch 141, Batch 11, Loss: 0.17\n",
      "Training: Epoch 141, Batch 12, Loss: 0.129\n",
      "Training: Epoch 141, Batch 13, Loss: 0.19\n",
      "Training: Epoch 141, Batch 14, Loss: 0.145\n",
      "Training: Epoch 141, Batch 15, Loss: 0.16\n",
      "Training: Epoch 141, Batch 16, Loss: 0.099\n",
      "Training: Epoch 141, Batch 17, Loss: 0.121\n",
      "Training: Epoch 141, Batch 18, Loss: 0.13\n",
      "Training: Epoch 141, Batch 19, Loss: 0.173\n",
      "Val: Epoch 141, Loss: 0.283\n",
      "Training: Epoch 142, Batch 0, Loss: 0.148\n",
      "Training: Epoch 142, Batch 1, Loss: 0.106\n",
      "Training: Epoch 142, Batch 2, Loss: 0.12\n",
      "Training: Epoch 142, Batch 3, Loss: 0.166\n",
      "Training: Epoch 142, Batch 4, Loss: 0.139\n",
      "Training: Epoch 142, Batch 5, Loss: 0.209\n",
      "Training: Epoch 142, Batch 6, Loss: 0.13\n",
      "Training: Epoch 142, Batch 7, Loss: 0.143\n",
      "Training: Epoch 142, Batch 8, Loss: 0.117\n",
      "Training: Epoch 142, Batch 9, Loss: 0.159\n",
      "Training: Epoch 142, Batch 10, Loss: 0.164\n",
      "Training: Epoch 142, Batch 11, Loss: 0.145\n",
      "Training: Epoch 142, Batch 12, Loss: 0.143\n",
      "Training: Epoch 142, Batch 13, Loss: 0.134\n",
      "Training: Epoch 142, Batch 14, Loss: 0.14\n",
      "Training: Epoch 142, Batch 15, Loss: 0.098\n",
      "Training: Epoch 142, Batch 16, Loss: 0.113\n",
      "Training: Epoch 142, Batch 17, Loss: 0.189\n",
      "Training: Epoch 142, Batch 18, Loss: 0.154\n",
      "Training: Epoch 142, Batch 19, Loss: 0.12\n",
      "Val: Epoch 142, Loss: 0.249\n",
      "Training: Epoch 143, Batch 0, Loss: 0.143\n",
      "Training: Epoch 143, Batch 1, Loss: 0.14\n",
      "Training: Epoch 143, Batch 2, Loss: 0.149\n",
      "Training: Epoch 143, Batch 3, Loss: 0.169\n",
      "Training: Epoch 143, Batch 4, Loss: 0.135\n",
      "Training: Epoch 143, Batch 5, Loss: 0.131\n",
      "Training: Epoch 143, Batch 6, Loss: 0.116\n",
      "Training: Epoch 143, Batch 7, Loss: 0.105\n",
      "Training: Epoch 143, Batch 8, Loss: 0.16\n",
      "Training: Epoch 143, Batch 9, Loss: 0.115\n",
      "Training: Epoch 143, Batch 10, Loss: 0.128\n",
      "Training: Epoch 143, Batch 11, Loss: 0.149\n",
      "Training: Epoch 143, Batch 12, Loss: 0.182\n",
      "Training: Epoch 143, Batch 13, Loss: 0.111\n",
      "Training: Epoch 143, Batch 14, Loss: 0.195\n",
      "Training: Epoch 143, Batch 15, Loss: 0.174\n",
      "Training: Epoch 143, Batch 16, Loss: 0.125\n",
      "Training: Epoch 143, Batch 17, Loss: 0.124\n",
      "Training: Epoch 143, Batch 18, Loss: 0.134\n",
      "Training: Epoch 143, Batch 19, Loss: 0.147\n",
      "Val: Epoch 143, Loss: 0.255\n",
      "Training: Epoch 144, Batch 0, Loss: 0.157\n",
      "Training: Epoch 144, Batch 1, Loss: 0.16\n",
      "Training: Epoch 144, Batch 2, Loss: 0.166\n",
      "Training: Epoch 144, Batch 3, Loss: 0.124\n",
      "Training: Epoch 144, Batch 4, Loss: 0.127\n",
      "Training: Epoch 144, Batch 5, Loss: 0.135\n",
      "Training: Epoch 144, Batch 6, Loss: 0.111\n",
      "Training: Epoch 144, Batch 7, Loss: 0.126\n",
      "Training: Epoch 144, Batch 8, Loss: 0.13\n",
      "Training: Epoch 144, Batch 9, Loss: 0.13\n",
      "Training: Epoch 144, Batch 10, Loss: 0.127\n",
      "Training: Epoch 144, Batch 11, Loss: 0.158\n",
      "Training: Epoch 144, Batch 12, Loss: 0.16\n",
      "Training: Epoch 144, Batch 13, Loss: 0.125\n",
      "Training: Epoch 144, Batch 14, Loss: 0.11\n",
      "Training: Epoch 144, Batch 15, Loss: 0.146\n",
      "Training: Epoch 144, Batch 16, Loss: 0.102\n",
      "Training: Epoch 144, Batch 17, Loss: 0.167\n",
      "Training: Epoch 144, Batch 18, Loss: 0.143\n",
      "Training: Epoch 144, Batch 19, Loss: 0.103\n",
      "Val: Epoch 144, Loss: 0.246\n",
      "Training: Epoch 145, Batch 0, Loss: 0.133\n",
      "Training: Epoch 145, Batch 1, Loss: 0.147\n",
      "Training: Epoch 145, Batch 2, Loss: 0.159\n",
      "Training: Epoch 145, Batch 3, Loss: 0.123\n",
      "Training: Epoch 145, Batch 4, Loss: 0.124\n",
      "Training: Epoch 145, Batch 5, Loss: 0.151\n",
      "Training: Epoch 145, Batch 6, Loss: 0.137\n",
      "Training: Epoch 145, Batch 7, Loss: 0.128\n",
      "Training: Epoch 145, Batch 8, Loss: 0.094\n",
      "Training: Epoch 145, Batch 9, Loss: 0.125\n",
      "Training: Epoch 145, Batch 10, Loss: 0.108\n",
      "Training: Epoch 145, Batch 11, Loss: 0.122\n",
      "Training: Epoch 145, Batch 12, Loss: 0.131\n",
      "Training: Epoch 145, Batch 13, Loss: 0.162\n",
      "Training: Epoch 145, Batch 14, Loss: 0.11\n",
      "Training: Epoch 145, Batch 15, Loss: 0.112\n",
      "Training: Epoch 145, Batch 16, Loss: 0.191\n",
      "Training: Epoch 145, Batch 17, Loss: 0.121\n",
      "Training: Epoch 145, Batch 18, Loss: 0.093\n",
      "Training: Epoch 145, Batch 19, Loss: 0.107\n",
      "Val: Epoch 145, Loss: 0.252\n",
      "Training: Epoch 146, Batch 0, Loss: 0.136\n",
      "Training: Epoch 146, Batch 1, Loss: 0.127\n",
      "Training: Epoch 146, Batch 2, Loss: 0.098\n",
      "Training: Epoch 146, Batch 3, Loss: 0.229\n",
      "Training: Epoch 146, Batch 4, Loss: 0.15\n",
      "Training: Epoch 146, Batch 5, Loss: 0.11\n",
      "Training: Epoch 146, Batch 6, Loss: 0.168\n",
      "Training: Epoch 146, Batch 7, Loss: 0.196\n",
      "Training: Epoch 146, Batch 8, Loss: 0.151\n",
      "Training: Epoch 146, Batch 9, Loss: 0.135\n",
      "Training: Epoch 146, Batch 10, Loss: 0.139\n",
      "Training: Epoch 146, Batch 11, Loss: 0.182\n",
      "Training: Epoch 146, Batch 12, Loss: 0.124\n",
      "Training: Epoch 146, Batch 13, Loss: 0.117\n",
      "Training: Epoch 146, Batch 14, Loss: 0.111\n",
      "Training: Epoch 146, Batch 15, Loss: 0.122\n",
      "Training: Epoch 146, Batch 16, Loss: 0.118\n",
      "Training: Epoch 146, Batch 17, Loss: 0.166\n",
      "Training: Epoch 146, Batch 18, Loss: 0.135\n",
      "Training: Epoch 146, Batch 19, Loss: 0.153\n",
      "Val: Epoch 146, Loss: 0.267\n",
      "Training: Epoch 147, Batch 0, Loss: 0.134\n",
      "Training: Epoch 147, Batch 1, Loss: 0.125\n",
      "Training: Epoch 147, Batch 2, Loss: 0.163\n",
      "Training: Epoch 147, Batch 3, Loss: 0.113\n",
      "Training: Epoch 147, Batch 4, Loss: 0.214\n",
      "Training: Epoch 147, Batch 5, Loss: 0.203\n",
      "Training: Epoch 147, Batch 6, Loss: 0.166\n",
      "Training: Epoch 147, Batch 7, Loss: 0.12\n",
      "Training: Epoch 147, Batch 8, Loss: 0.151\n",
      "Training: Epoch 147, Batch 9, Loss: 0.19\n",
      "Training: Epoch 147, Batch 10, Loss: 0.131\n",
      "Training: Epoch 147, Batch 11, Loss: 0.151\n",
      "Training: Epoch 147, Batch 12, Loss: 0.123\n",
      "Training: Epoch 147, Batch 13, Loss: 0.135\n",
      "Training: Epoch 147, Batch 14, Loss: 0.143\n",
      "Training: Epoch 147, Batch 15, Loss: 0.134\n",
      "Training: Epoch 147, Batch 16, Loss: 0.149\n",
      "Training: Epoch 147, Batch 17, Loss: 0.124\n",
      "Training: Epoch 147, Batch 18, Loss: 0.135\n",
      "Training: Epoch 147, Batch 19, Loss: 0.126\n",
      "Val: Epoch 147, Loss: 0.239\n",
      "Training: Epoch 148, Batch 0, Loss: 0.117\n",
      "Training: Epoch 148, Batch 1, Loss: 0.105\n",
      "Training: Epoch 148, Batch 2, Loss: 0.127\n",
      "Training: Epoch 148, Batch 3, Loss: 0.115\n",
      "Training: Epoch 148, Batch 4, Loss: 0.171\n",
      "Training: Epoch 148, Batch 5, Loss: 0.158\n",
      "Training: Epoch 148, Batch 6, Loss: 0.165\n",
      "Training: Epoch 148, Batch 7, Loss: 0.183\n",
      "Training: Epoch 148, Batch 8, Loss: 0.129\n",
      "Training: Epoch 148, Batch 9, Loss: 0.13\n",
      "Training: Epoch 148, Batch 10, Loss: 0.138\n",
      "Training: Epoch 148, Batch 11, Loss: 0.118\n",
      "Training: Epoch 148, Batch 12, Loss: 0.134\n",
      "Training: Epoch 148, Batch 13, Loss: 0.142\n",
      "Training: Epoch 148, Batch 14, Loss: 0.144\n",
      "Training: Epoch 148, Batch 15, Loss: 0.124\n",
      "Training: Epoch 148, Batch 16, Loss: 0.132\n",
      "Training: Epoch 148, Batch 17, Loss: 0.114\n",
      "Training: Epoch 148, Batch 18, Loss: 0.13\n",
      "Training: Epoch 148, Batch 19, Loss: 0.124\n",
      "Val: Epoch 148, Loss: 0.228\n",
      "Training: Epoch 149, Batch 0, Loss: 0.125\n",
      "Training: Epoch 149, Batch 1, Loss: 0.154\n",
      "Training: Epoch 149, Batch 2, Loss: 0.117\n",
      "Training: Epoch 149, Batch 3, Loss: 0.139\n",
      "Training: Epoch 149, Batch 4, Loss: 0.236\n",
      "Training: Epoch 149, Batch 5, Loss: 0.147\n",
      "Training: Epoch 149, Batch 6, Loss: 0.109\n",
      "Training: Epoch 149, Batch 7, Loss: 0.154\n",
      "Training: Epoch 149, Batch 8, Loss: 0.105\n",
      "Training: Epoch 149, Batch 9, Loss: 0.132\n",
      "Training: Epoch 149, Batch 10, Loss: 0.115\n",
      "Training: Epoch 149, Batch 11, Loss: 0.155\n",
      "Training: Epoch 149, Batch 12, Loss: 0.124\n",
      "Training: Epoch 149, Batch 13, Loss: 0.131\n",
      "Training: Epoch 149, Batch 14, Loss: 0.123\n",
      "Training: Epoch 149, Batch 15, Loss: 0.116\n",
      "Training: Epoch 149, Batch 16, Loss: 0.116\n",
      "Training: Epoch 149, Batch 17, Loss: 0.139\n",
      "Training: Epoch 149, Batch 18, Loss: 0.162\n",
      "Training: Epoch 149, Batch 19, Loss: 0.105\n",
      "Val: Epoch 149, Loss: 0.248\n",
      "Training: Epoch 150, Batch 0, Loss: 0.126\n",
      "Training: Epoch 150, Batch 1, Loss: 0.135\n",
      "Training: Epoch 150, Batch 2, Loss: 0.108\n",
      "Training: Epoch 150, Batch 3, Loss: 0.176\n",
      "Training: Epoch 150, Batch 4, Loss: 0.114\n",
      "Training: Epoch 150, Batch 5, Loss: 0.142\n",
      "Training: Epoch 150, Batch 6, Loss: 0.133\n",
      "Training: Epoch 150, Batch 7, Loss: 0.204\n",
      "Training: Epoch 150, Batch 8, Loss: 0.132\n",
      "Training: Epoch 150, Batch 9, Loss: 0.135\n",
      "Training: Epoch 150, Batch 10, Loss: 0.124\n",
      "Training: Epoch 150, Batch 11, Loss: 0.131\n",
      "Training: Epoch 150, Batch 12, Loss: 0.147\n",
      "Training: Epoch 150, Batch 13, Loss: 0.151\n",
      "Training: Epoch 150, Batch 14, Loss: 0.11\n",
      "Training: Epoch 150, Batch 15, Loss: 0.117\n",
      "Training: Epoch 150, Batch 16, Loss: 0.237\n",
      "Training: Epoch 150, Batch 17, Loss: 0.179\n",
      "Training: Epoch 150, Batch 18, Loss: 0.111\n",
      "Training: Epoch 150, Batch 19, Loss: 0.119\n",
      "Val: Epoch 150, Loss: 0.24\n",
      "Training: Epoch 151, Batch 0, Loss: 0.154\n",
      "Training: Epoch 151, Batch 1, Loss: 0.146\n",
      "Training: Epoch 151, Batch 2, Loss: 0.119\n",
      "Training: Epoch 151, Batch 3, Loss: 0.16\n",
      "Training: Epoch 151, Batch 4, Loss: 0.13\n",
      "Training: Epoch 151, Batch 5, Loss: 0.13\n",
      "Training: Epoch 151, Batch 6, Loss: 0.093\n",
      "Training: Epoch 151, Batch 7, Loss: 0.141\n",
      "Training: Epoch 151, Batch 8, Loss: 0.159\n",
      "Training: Epoch 151, Batch 9, Loss: 0.107\n",
      "Training: Epoch 151, Batch 10, Loss: 0.132\n",
      "Training: Epoch 151, Batch 11, Loss: 0.133\n",
      "Training: Epoch 151, Batch 12, Loss: 0.131\n",
      "Training: Epoch 151, Batch 13, Loss: 0.139\n",
      "Training: Epoch 151, Batch 14, Loss: 0.214\n",
      "Training: Epoch 151, Batch 15, Loss: 0.151\n",
      "Training: Epoch 151, Batch 16, Loss: 0.115\n",
      "Training: Epoch 151, Batch 17, Loss: 0.147\n",
      "Training: Epoch 151, Batch 18, Loss: 0.112\n",
      "Training: Epoch 151, Batch 19, Loss: 0.13\n",
      "Val: Epoch 151, Loss: 0.341\n",
      "Training: Epoch 152, Batch 0, Loss: 0.124\n",
      "Training: Epoch 152, Batch 1, Loss: 0.161\n",
      "Training: Epoch 152, Batch 2, Loss: 0.138\n",
      "Training: Epoch 152, Batch 3, Loss: 0.133\n",
      "Training: Epoch 152, Batch 4, Loss: 0.187\n",
      "Training: Epoch 152, Batch 5, Loss: 0.119\n",
      "Training: Epoch 152, Batch 6, Loss: 0.15\n",
      "Training: Epoch 152, Batch 7, Loss: 0.124\n",
      "Training: Epoch 152, Batch 8, Loss: 0.193\n",
      "Training: Epoch 152, Batch 9, Loss: 0.178\n",
      "Training: Epoch 152, Batch 10, Loss: 0.136\n",
      "Training: Epoch 152, Batch 11, Loss: 0.14\n",
      "Training: Epoch 152, Batch 12, Loss: 0.156\n",
      "Training: Epoch 152, Batch 13, Loss: 0.127\n",
      "Training: Epoch 152, Batch 14, Loss: 0.163\n",
      "Training: Epoch 152, Batch 15, Loss: 0.167\n",
      "Training: Epoch 152, Batch 16, Loss: 0.203\n",
      "Training: Epoch 152, Batch 17, Loss: 0.183\n",
      "Training: Epoch 152, Batch 18, Loss: 0.096\n",
      "Training: Epoch 152, Batch 19, Loss: 0.147\n",
      "Val: Epoch 152, Loss: 0.226\n",
      "Training: Epoch 153, Batch 0, Loss: 0.131\n",
      "Training: Epoch 153, Batch 1, Loss: 0.151\n",
      "Training: Epoch 153, Batch 2, Loss: 0.107\n",
      "Training: Epoch 153, Batch 3, Loss: 0.165\n",
      "Training: Epoch 153, Batch 4, Loss: 0.108\n",
      "Training: Epoch 153, Batch 5, Loss: 0.162\n",
      "Training: Epoch 153, Batch 6, Loss: 0.178\n",
      "Training: Epoch 153, Batch 7, Loss: 0.149\n",
      "Training: Epoch 153, Batch 8, Loss: 0.119\n",
      "Training: Epoch 153, Batch 9, Loss: 0.118\n",
      "Training: Epoch 153, Batch 10, Loss: 0.167\n",
      "Training: Epoch 153, Batch 11, Loss: 0.133\n",
      "Training: Epoch 153, Batch 12, Loss: 0.158\n",
      "Training: Epoch 153, Batch 13, Loss: 0.131\n",
      "Training: Epoch 153, Batch 14, Loss: 0.101\n",
      "Training: Epoch 153, Batch 15, Loss: 0.139\n",
      "Training: Epoch 153, Batch 16, Loss: 0.11\n",
      "Training: Epoch 153, Batch 17, Loss: 0.124\n",
      "Training: Epoch 153, Batch 18, Loss: 0.099\n",
      "Training: Epoch 153, Batch 19, Loss: 0.16\n",
      "Val: Epoch 153, Loss: 0.215\n",
      "Training: Epoch 154, Batch 0, Loss: 0.142\n",
      "Training: Epoch 154, Batch 1, Loss: 0.156\n",
      "Training: Epoch 154, Batch 2, Loss: 0.098\n",
      "Training: Epoch 154, Batch 3, Loss: 0.129\n",
      "Training: Epoch 154, Batch 4, Loss: 0.133\n",
      "Training: Epoch 154, Batch 5, Loss: 0.202\n",
      "Training: Epoch 154, Batch 6, Loss: 0.123\n",
      "Training: Epoch 154, Batch 7, Loss: 0.178\n",
      "Training: Epoch 154, Batch 8, Loss: 0.145\n",
      "Training: Epoch 154, Batch 9, Loss: 0.11\n",
      "Training: Epoch 154, Batch 10, Loss: 0.122\n",
      "Training: Epoch 154, Batch 11, Loss: 0.17\n",
      "Training: Epoch 154, Batch 12, Loss: 0.122\n",
      "Training: Epoch 154, Batch 13, Loss: 0.162\n",
      "Training: Epoch 154, Batch 14, Loss: 0.284\n",
      "Training: Epoch 154, Batch 15, Loss: 0.101\n",
      "Training: Epoch 154, Batch 16, Loss: 0.132\n",
      "Training: Epoch 154, Batch 17, Loss: 0.127\n",
      "Training: Epoch 154, Batch 18, Loss: 0.149\n",
      "Training: Epoch 154, Batch 19, Loss: 0.199\n",
      "Val: Epoch 154, Loss: 0.409\n",
      "Training: Epoch 155, Batch 0, Loss: 0.123\n",
      "Training: Epoch 155, Batch 1, Loss: 0.121\n",
      "Training: Epoch 155, Batch 2, Loss: 0.204\n",
      "Training: Epoch 155, Batch 3, Loss: 0.161\n",
      "Training: Epoch 155, Batch 4, Loss: 0.145\n",
      "Training: Epoch 155, Batch 5, Loss: 0.186\n",
      "Training: Epoch 155, Batch 6, Loss: 0.145\n",
      "Training: Epoch 155, Batch 7, Loss: 0.172\n",
      "Training: Epoch 155, Batch 8, Loss: 0.212\n",
      "Training: Epoch 155, Batch 9, Loss: 0.148\n",
      "Training: Epoch 155, Batch 10, Loss: 0.133\n",
      "Training: Epoch 155, Batch 11, Loss: 0.166\n",
      "Training: Epoch 155, Batch 12, Loss: 0.172\n",
      "Training: Epoch 155, Batch 13, Loss: 0.113\n",
      "Training: Epoch 155, Batch 14, Loss: 0.163\n",
      "Training: Epoch 155, Batch 15, Loss: 0.17\n",
      "Training: Epoch 155, Batch 16, Loss: 0.143\n",
      "Training: Epoch 155, Batch 17, Loss: 0.126\n",
      "Training: Epoch 155, Batch 18, Loss: 0.143\n",
      "Training: Epoch 155, Batch 19, Loss: 0.151\n",
      "Val: Epoch 155, Loss: 0.24\n",
      "Training: Epoch 156, Batch 0, Loss: 0.133\n",
      "Training: Epoch 156, Batch 1, Loss: 0.163\n",
      "Training: Epoch 156, Batch 2, Loss: 0.128\n",
      "Training: Epoch 156, Batch 3, Loss: 0.099\n",
      "Training: Epoch 156, Batch 4, Loss: 0.113\n",
      "Training: Epoch 156, Batch 5, Loss: 0.146\n",
      "Training: Epoch 156, Batch 6, Loss: 0.184\n",
      "Training: Epoch 156, Batch 7, Loss: 0.162\n",
      "Training: Epoch 156, Batch 8, Loss: 0.142\n",
      "Training: Epoch 156, Batch 9, Loss: 0.175\n",
      "Training: Epoch 156, Batch 10, Loss: 0.126\n",
      "Training: Epoch 156, Batch 11, Loss: 0.14\n",
      "Training: Epoch 156, Batch 12, Loss: 0.208\n",
      "Training: Epoch 156, Batch 13, Loss: 0.175\n",
      "Training: Epoch 156, Batch 14, Loss: 0.089\n",
      "Training: Epoch 156, Batch 15, Loss: 0.144\n",
      "Training: Epoch 156, Batch 16, Loss: 0.127\n",
      "Training: Epoch 156, Batch 17, Loss: 0.163\n",
      "Training: Epoch 156, Batch 18, Loss: 0.159\n",
      "Training: Epoch 156, Batch 19, Loss: 0.148\n",
      "Val: Epoch 156, Loss: 0.26\n",
      "Training: Epoch 157, Batch 0, Loss: 0.152\n",
      "Training: Epoch 157, Batch 1, Loss: 0.13\n",
      "Training: Epoch 157, Batch 2, Loss: 0.16\n",
      "Training: Epoch 157, Batch 3, Loss: 0.137\n",
      "Training: Epoch 157, Batch 4, Loss: 0.145\n",
      "Training: Epoch 157, Batch 5, Loss: 0.138\n",
      "Training: Epoch 157, Batch 6, Loss: 0.156\n",
      "Training: Epoch 157, Batch 7, Loss: 0.132\n",
      "Training: Epoch 157, Batch 8, Loss: 0.107\n",
      "Training: Epoch 157, Batch 9, Loss: 0.142\n",
      "Training: Epoch 157, Batch 10, Loss: 0.124\n",
      "Training: Epoch 157, Batch 11, Loss: 0.151\n",
      "Training: Epoch 157, Batch 12, Loss: 0.114\n",
      "Training: Epoch 157, Batch 13, Loss: 0.111\n",
      "Training: Epoch 157, Batch 14, Loss: 0.144\n",
      "Training: Epoch 157, Batch 15, Loss: 0.094\n",
      "Training: Epoch 157, Batch 16, Loss: 0.144\n",
      "Training: Epoch 157, Batch 17, Loss: 0.135\n",
      "Training: Epoch 157, Batch 18, Loss: 0.081\n",
      "Training: Epoch 157, Batch 19, Loss: 0.108\n",
      "Val: Epoch 157, Loss: 0.23\n",
      "Training: Epoch 158, Batch 0, Loss: 0.147\n",
      "Training: Epoch 158, Batch 1, Loss: 0.115\n",
      "Training: Epoch 158, Batch 2, Loss: 0.112\n",
      "Training: Epoch 158, Batch 3, Loss: 0.152\n",
      "Training: Epoch 158, Batch 4, Loss: 0.105\n",
      "Training: Epoch 158, Batch 5, Loss: 0.147\n",
      "Training: Epoch 158, Batch 6, Loss: 0.103\n",
      "Training: Epoch 158, Batch 7, Loss: 0.107\n",
      "Training: Epoch 158, Batch 8, Loss: 0.115\n",
      "Training: Epoch 158, Batch 9, Loss: 0.119\n",
      "Training: Epoch 158, Batch 10, Loss: 0.131\n",
      "Training: Epoch 158, Batch 11, Loss: 0.157\n",
      "Training: Epoch 158, Batch 12, Loss: 0.13\n",
      "Training: Epoch 158, Batch 13, Loss: 0.126\n",
      "Training: Epoch 158, Batch 14, Loss: 0.123\n",
      "Training: Epoch 158, Batch 15, Loss: 0.123\n",
      "Training: Epoch 158, Batch 16, Loss: 0.097\n",
      "Training: Epoch 158, Batch 17, Loss: 0.138\n",
      "Training: Epoch 158, Batch 18, Loss: 0.097\n",
      "Training: Epoch 158, Batch 19, Loss: 0.103\n",
      "Val: Epoch 158, Loss: 0.24\n",
      "Training: Epoch 159, Batch 0, Loss: 0.126\n",
      "Training: Epoch 159, Batch 1, Loss: 0.1\n",
      "Training: Epoch 159, Batch 2, Loss: 0.132\n",
      "Training: Epoch 159, Batch 3, Loss: 0.146\n",
      "Training: Epoch 159, Batch 4, Loss: 0.105\n",
      "Training: Epoch 159, Batch 5, Loss: 0.075\n",
      "Training: Epoch 159, Batch 6, Loss: 0.101\n",
      "Training: Epoch 159, Batch 7, Loss: 0.117\n",
      "Training: Epoch 159, Batch 8, Loss: 0.119\n",
      "Training: Epoch 159, Batch 9, Loss: 0.153\n",
      "Training: Epoch 159, Batch 10, Loss: 0.117\n",
      "Training: Epoch 159, Batch 11, Loss: 0.129\n",
      "Training: Epoch 159, Batch 12, Loss: 0.14\n",
      "Training: Epoch 159, Batch 13, Loss: 0.137\n",
      "Training: Epoch 159, Batch 14, Loss: 0.095\n",
      "Training: Epoch 159, Batch 15, Loss: 0.098\n",
      "Training: Epoch 159, Batch 16, Loss: 0.147\n",
      "Training: Epoch 159, Batch 17, Loss: 0.132\n",
      "Training: Epoch 159, Batch 18, Loss: 0.087\n",
      "Training: Epoch 159, Batch 19, Loss: 0.145\n",
      "Val: Epoch 159, Loss: 0.256\n",
      "Training: Epoch 160, Batch 0, Loss: 0.174\n",
      "Training: Epoch 160, Batch 1, Loss: 0.089\n",
      "Training: Epoch 160, Batch 2, Loss: 0.141\n",
      "Training: Epoch 160, Batch 3, Loss: 0.136\n",
      "Training: Epoch 160, Batch 4, Loss: 0.145\n",
      "Training: Epoch 160, Batch 5, Loss: 0.097\n",
      "Training: Epoch 160, Batch 6, Loss: 0.122\n",
      "Training: Epoch 160, Batch 7, Loss: 0.111\n",
      "Training: Epoch 160, Batch 8, Loss: 0.118\n",
      "Training: Epoch 160, Batch 9, Loss: 0.158\n",
      "Training: Epoch 160, Batch 10, Loss: 0.115\n",
      "Training: Epoch 160, Batch 11, Loss: 0.125\n",
      "Training: Epoch 160, Batch 12, Loss: 0.128\n",
      "Training: Epoch 160, Batch 13, Loss: 0.12\n",
      "Training: Epoch 160, Batch 14, Loss: 0.092\n",
      "Training: Epoch 160, Batch 15, Loss: 0.119\n",
      "Training: Epoch 160, Batch 16, Loss: 0.122\n",
      "Training: Epoch 160, Batch 17, Loss: 0.108\n",
      "Training: Epoch 160, Batch 18, Loss: 0.094\n",
      "Training: Epoch 160, Batch 19, Loss: 0.151\n",
      "Val: Epoch 160, Loss: 0.239\n",
      "Training: Epoch 161, Batch 0, Loss: 0.13\n",
      "Training: Epoch 161, Batch 1, Loss: 0.107\n",
      "Training: Epoch 161, Batch 2, Loss: 0.116\n",
      "Training: Epoch 161, Batch 3, Loss: 0.129\n",
      "Training: Epoch 161, Batch 4, Loss: 0.105\n",
      "Training: Epoch 161, Batch 5, Loss: 0.117\n",
      "Training: Epoch 161, Batch 6, Loss: 0.139\n",
      "Training: Epoch 161, Batch 7, Loss: 0.132\n",
      "Training: Epoch 161, Batch 8, Loss: 0.134\n",
      "Training: Epoch 161, Batch 9, Loss: 0.134\n",
      "Training: Epoch 161, Batch 10, Loss: 0.114\n",
      "Training: Epoch 161, Batch 11, Loss: 0.15\n",
      "Training: Epoch 161, Batch 12, Loss: 0.114\n",
      "Training: Epoch 161, Batch 13, Loss: 0.104\n",
      "Training: Epoch 161, Batch 14, Loss: 0.097\n",
      "Training: Epoch 161, Batch 15, Loss: 0.101\n",
      "Training: Epoch 161, Batch 16, Loss: 0.11\n",
      "Training: Epoch 161, Batch 17, Loss: 0.122\n",
      "Training: Epoch 161, Batch 18, Loss: 0.113\n",
      "Training: Epoch 161, Batch 19, Loss: 0.095\n",
      "Val: Epoch 161, Loss: 0.249\n",
      "Training: Epoch 162, Batch 0, Loss: 0.13\n",
      "Training: Epoch 162, Batch 1, Loss: 0.128\n",
      "Training: Epoch 162, Batch 2, Loss: 0.152\n",
      "Training: Epoch 162, Batch 3, Loss: 0.114\n",
      "Training: Epoch 162, Batch 4, Loss: 0.104\n",
      "Training: Epoch 162, Batch 5, Loss: 0.122\n",
      "Training: Epoch 162, Batch 6, Loss: 0.149\n",
      "Training: Epoch 162, Batch 7, Loss: 0.118\n",
      "Training: Epoch 162, Batch 8, Loss: 0.13\n",
      "Training: Epoch 162, Batch 9, Loss: 0.118\n",
      "Training: Epoch 162, Batch 10, Loss: 0.121\n",
      "Training: Epoch 162, Batch 11, Loss: 0.13\n",
      "Training: Epoch 162, Batch 12, Loss: 0.118\n",
      "Training: Epoch 162, Batch 13, Loss: 0.104\n",
      "Training: Epoch 162, Batch 14, Loss: 0.103\n",
      "Training: Epoch 162, Batch 15, Loss: 0.1\n",
      "Training: Epoch 162, Batch 16, Loss: 0.118\n",
      "Training: Epoch 162, Batch 17, Loss: 0.117\n",
      "Training: Epoch 162, Batch 18, Loss: 0.096\n",
      "Training: Epoch 162, Batch 19, Loss: 0.105\n",
      "Val: Epoch 162, Loss: 0.238\n",
      "Training: Epoch 163, Batch 0, Loss: 0.091\n",
      "Training: Epoch 163, Batch 1, Loss: 0.138\n",
      "Training: Epoch 163, Batch 2, Loss: 0.1\n",
      "Training: Epoch 163, Batch 3, Loss: 0.118\n",
      "Training: Epoch 163, Batch 4, Loss: 0.163\n",
      "Training: Epoch 163, Batch 5, Loss: 0.131\n",
      "Training: Epoch 163, Batch 6, Loss: 0.1\n",
      "Training: Epoch 163, Batch 7, Loss: 0.136\n",
      "Training: Epoch 163, Batch 8, Loss: 0.115\n",
      "Training: Epoch 163, Batch 9, Loss: 0.127\n",
      "Training: Epoch 163, Batch 10, Loss: 0.144\n",
      "Training: Epoch 163, Batch 11, Loss: 0.088\n",
      "Training: Epoch 163, Batch 12, Loss: 0.109\n",
      "Training: Epoch 163, Batch 13, Loss: 0.117\n",
      "Training: Epoch 163, Batch 14, Loss: 0.115\n",
      "Training: Epoch 163, Batch 15, Loss: 0.168\n",
      "Training: Epoch 163, Batch 16, Loss: 0.13\n",
      "Training: Epoch 163, Batch 17, Loss: 0.108\n",
      "Training: Epoch 163, Batch 18, Loss: 0.084\n",
      "Training: Epoch 163, Batch 19, Loss: 0.147\n",
      "Val: Epoch 163, Loss: 0.256\n",
      "Training: Epoch 164, Batch 0, Loss: 0.118\n",
      "Training: Epoch 164, Batch 1, Loss: 0.123\n",
      "Training: Epoch 164, Batch 2, Loss: 0.136\n",
      "Training: Epoch 164, Batch 3, Loss: 0.116\n",
      "Training: Epoch 164, Batch 4, Loss: 0.1\n",
      "Training: Epoch 164, Batch 5, Loss: 0.15\n",
      "Training: Epoch 164, Batch 6, Loss: 0.096\n",
      "Training: Epoch 164, Batch 7, Loss: 0.112\n",
      "Training: Epoch 164, Batch 8, Loss: 0.11\n",
      "Training: Epoch 164, Batch 9, Loss: 0.075\n",
      "Training: Epoch 164, Batch 10, Loss: 0.124\n",
      "Training: Epoch 164, Batch 11, Loss: 0.1\n",
      "Training: Epoch 164, Batch 12, Loss: 0.101\n",
      "Training: Epoch 164, Batch 13, Loss: 0.098\n",
      "Training: Epoch 164, Batch 14, Loss: 0.128\n",
      "Training: Epoch 164, Batch 15, Loss: 0.108\n",
      "Training: Epoch 164, Batch 16, Loss: 0.113\n",
      "Training: Epoch 164, Batch 17, Loss: 0.109\n",
      "Training: Epoch 164, Batch 18, Loss: 0.13\n",
      "Training: Epoch 164, Batch 19, Loss: 0.113\n",
      "Val: Epoch 164, Loss: 0.256\n",
      "Training: Epoch 165, Batch 0, Loss: 0.12\n",
      "Training: Epoch 165, Batch 1, Loss: 0.125\n",
      "Training: Epoch 165, Batch 2, Loss: 0.102\n",
      "Training: Epoch 165, Batch 3, Loss: 0.122\n",
      "Training: Epoch 165, Batch 4, Loss: 0.148\n",
      "Training: Epoch 165, Batch 5, Loss: 0.107\n",
      "Training: Epoch 165, Batch 6, Loss: 0.101\n",
      "Training: Epoch 165, Batch 7, Loss: 0.098\n",
      "Training: Epoch 165, Batch 8, Loss: 0.101\n",
      "Training: Epoch 165, Batch 9, Loss: 0.163\n",
      "Training: Epoch 165, Batch 10, Loss: 0.155\n",
      "Training: Epoch 165, Batch 11, Loss: 0.124\n",
      "Training: Epoch 165, Batch 12, Loss: 0.131\n",
      "Training: Epoch 165, Batch 13, Loss: 0.114\n",
      "Training: Epoch 165, Batch 14, Loss: 0.157\n",
      "Training: Epoch 165, Batch 15, Loss: 0.127\n",
      "Training: Epoch 165, Batch 16, Loss: 0.119\n",
      "Training: Epoch 165, Batch 17, Loss: 0.106\n",
      "Training: Epoch 165, Batch 18, Loss: 0.106\n",
      "Training: Epoch 165, Batch 19, Loss: 0.112\n",
      "Val: Epoch 165, Loss: 0.252\n",
      "Training: Epoch 166, Batch 0, Loss: 0.111\n",
      "Training: Epoch 166, Batch 1, Loss: 0.122\n",
      "Training: Epoch 166, Batch 2, Loss: 0.111\n",
      "Training: Epoch 166, Batch 3, Loss: 0.108\n",
      "Training: Epoch 166, Batch 4, Loss: 0.148\n",
      "Training: Epoch 166, Batch 5, Loss: 0.099\n",
      "Training: Epoch 166, Batch 6, Loss: 0.135\n",
      "Training: Epoch 166, Batch 7, Loss: 0.097\n",
      "Training: Epoch 166, Batch 8, Loss: 0.101\n",
      "Training: Epoch 166, Batch 9, Loss: 0.108\n",
      "Training: Epoch 166, Batch 10, Loss: 0.127\n",
      "Training: Epoch 166, Batch 11, Loss: 0.103\n",
      "Training: Epoch 166, Batch 12, Loss: 0.12\n",
      "Training: Epoch 166, Batch 13, Loss: 0.139\n",
      "Training: Epoch 166, Batch 14, Loss: 0.097\n",
      "Training: Epoch 166, Batch 15, Loss: 0.131\n",
      "Training: Epoch 166, Batch 16, Loss: 0.121\n",
      "Training: Epoch 166, Batch 17, Loss: 0.132\n",
      "Training: Epoch 166, Batch 18, Loss: 0.125\n",
      "Training: Epoch 166, Batch 19, Loss: 0.113\n",
      "Val: Epoch 166, Loss: 0.246\n",
      "Training: Epoch 167, Batch 0, Loss: 0.099\n",
      "Training: Epoch 167, Batch 1, Loss: 0.1\n",
      "Training: Epoch 167, Batch 2, Loss: 0.123\n",
      "Training: Epoch 167, Batch 3, Loss: 0.092\n",
      "Training: Epoch 167, Batch 4, Loss: 0.148\n",
      "Training: Epoch 167, Batch 5, Loss: 0.086\n",
      "Training: Epoch 167, Batch 6, Loss: 0.155\n",
      "Training: Epoch 167, Batch 7, Loss: 0.103\n",
      "Training: Epoch 167, Batch 8, Loss: 0.116\n",
      "Training: Epoch 167, Batch 9, Loss: 0.11\n",
      "Training: Epoch 167, Batch 10, Loss: 0.136\n",
      "Training: Epoch 167, Batch 11, Loss: 0.122\n",
      "Training: Epoch 167, Batch 12, Loss: 0.097\n",
      "Training: Epoch 167, Batch 13, Loss: 0.101\n",
      "Training: Epoch 167, Batch 14, Loss: 0.099\n",
      "Training: Epoch 167, Batch 15, Loss: 0.125\n",
      "Training: Epoch 167, Batch 16, Loss: 0.116\n",
      "Training: Epoch 167, Batch 17, Loss: 0.107\n",
      "Training: Epoch 167, Batch 18, Loss: 0.106\n",
      "Training: Epoch 167, Batch 19, Loss: 0.107\n",
      "Val: Epoch 167, Loss: 0.255\n",
      "Training: Epoch 168, Batch 0, Loss: 0.11\n",
      "Training: Epoch 168, Batch 1, Loss: 0.101\n",
      "Training: Epoch 168, Batch 2, Loss: 0.118\n",
      "Training: Epoch 168, Batch 3, Loss: 0.114\n",
      "Training: Epoch 168, Batch 4, Loss: 0.133\n",
      "Training: Epoch 168, Batch 5, Loss: 0.137\n",
      "Training: Epoch 168, Batch 6, Loss: 0.114\n",
      "Training: Epoch 168, Batch 7, Loss: 0.086\n",
      "Training: Epoch 168, Batch 8, Loss: 0.167\n",
      "Training: Epoch 168, Batch 9, Loss: 0.111\n",
      "Training: Epoch 168, Batch 10, Loss: 0.118\n",
      "Training: Epoch 168, Batch 11, Loss: 0.128\n",
      "Training: Epoch 168, Batch 12, Loss: 0.124\n",
      "Training: Epoch 168, Batch 13, Loss: 0.139\n",
      "Training: Epoch 168, Batch 14, Loss: 0.099\n",
      "Training: Epoch 168, Batch 15, Loss: 0.11\n",
      "Training: Epoch 168, Batch 16, Loss: 0.197\n",
      "Training: Epoch 168, Batch 17, Loss: 0.118\n",
      "Training: Epoch 168, Batch 18, Loss: 0.101\n",
      "Training: Epoch 168, Batch 19, Loss: 0.089\n",
      "Val: Epoch 168, Loss: 0.269\n",
      "Training: Epoch 169, Batch 0, Loss: 0.114\n",
      "Training: Epoch 169, Batch 1, Loss: 0.081\n",
      "Training: Epoch 169, Batch 2, Loss: 0.115\n",
      "Training: Epoch 169, Batch 3, Loss: 0.113\n",
      "Training: Epoch 169, Batch 4, Loss: 0.101\n",
      "Training: Epoch 169, Batch 5, Loss: 0.11\n",
      "Training: Epoch 169, Batch 6, Loss: 0.123\n",
      "Training: Epoch 169, Batch 7, Loss: 0.138\n",
      "Training: Epoch 169, Batch 8, Loss: 0.098\n",
      "Training: Epoch 169, Batch 9, Loss: 0.116\n",
      "Training: Epoch 169, Batch 10, Loss: 0.101\n",
      "Training: Epoch 169, Batch 11, Loss: 0.127\n",
      "Training: Epoch 169, Batch 12, Loss: 0.11\n",
      "Training: Epoch 169, Batch 13, Loss: 0.122\n",
      "Training: Epoch 169, Batch 14, Loss: 0.131\n",
      "Training: Epoch 169, Batch 15, Loss: 0.119\n",
      "Training: Epoch 169, Batch 16, Loss: 0.127\n",
      "Training: Epoch 169, Batch 17, Loss: 0.123\n",
      "Training: Epoch 169, Batch 18, Loss: 0.113\n",
      "Training: Epoch 169, Batch 19, Loss: 0.109\n",
      "Val: Epoch 169, Loss: 0.264\n",
      "Training: Epoch 170, Batch 0, Loss: 0.11\n",
      "Training: Epoch 170, Batch 1, Loss: 0.134\n",
      "Training: Epoch 170, Batch 2, Loss: 0.114\n",
      "Training: Epoch 170, Batch 3, Loss: 0.122\n",
      "Training: Epoch 170, Batch 4, Loss: 0.085\n",
      "Training: Epoch 170, Batch 5, Loss: 0.128\n",
      "Training: Epoch 170, Batch 6, Loss: 0.109\n",
      "Training: Epoch 170, Batch 7, Loss: 0.108\n",
      "Training: Epoch 170, Batch 8, Loss: 0.103\n",
      "Training: Epoch 170, Batch 9, Loss: 0.139\n",
      "Training: Epoch 170, Batch 10, Loss: 0.128\n",
      "Training: Epoch 170, Batch 11, Loss: 0.09\n",
      "Training: Epoch 170, Batch 12, Loss: 0.096\n",
      "Training: Epoch 170, Batch 13, Loss: 0.117\n",
      "Training: Epoch 170, Batch 14, Loss: 0.18\n",
      "Training: Epoch 170, Batch 15, Loss: 0.136\n",
      "Training: Epoch 170, Batch 16, Loss: 0.12\n",
      "Training: Epoch 170, Batch 17, Loss: 0.14\n",
      "Training: Epoch 170, Batch 18, Loss: 0.186\n",
      "Training: Epoch 170, Batch 19, Loss: 0.163\n",
      "Val: Epoch 170, Loss: 0.557\n",
      "Training: Epoch 171, Batch 0, Loss: 0.109\n",
      "Training: Epoch 171, Batch 1, Loss: 0.134\n",
      "Training: Epoch 171, Batch 2, Loss: 0.107\n",
      "Training: Epoch 171, Batch 3, Loss: 0.122\n",
      "Training: Epoch 171, Batch 4, Loss: 0.102\n",
      "Training: Epoch 171, Batch 5, Loss: 0.122\n",
      "Training: Epoch 171, Batch 6, Loss: 0.122\n",
      "Training: Epoch 171, Batch 7, Loss: 0.099\n",
      "Training: Epoch 171, Batch 8, Loss: 0.113\n",
      "Training: Epoch 171, Batch 9, Loss: 0.122\n",
      "Training: Epoch 171, Batch 10, Loss: 0.099\n",
      "Training: Epoch 171, Batch 11, Loss: 0.152\n",
      "Training: Epoch 171, Batch 12, Loss: 0.13\n",
      "Training: Epoch 171, Batch 13, Loss: 0.094\n",
      "Training: Epoch 171, Batch 14, Loss: 0.095\n",
      "Training: Epoch 171, Batch 15, Loss: 0.13\n",
      "Training: Epoch 171, Batch 16, Loss: 0.109\n",
      "Training: Epoch 171, Batch 17, Loss: 0.112\n",
      "Training: Epoch 171, Batch 18, Loss: 0.116\n",
      "Training: Epoch 171, Batch 19, Loss: 0.132\n",
      "Val: Epoch 171, Loss: 0.249\n",
      "Training: Epoch 172, Batch 0, Loss: 0.12\n",
      "Training: Epoch 172, Batch 1, Loss: 0.123\n",
      "Training: Epoch 172, Batch 2, Loss: 0.098\n",
      "Training: Epoch 172, Batch 3, Loss: 0.102\n",
      "Training: Epoch 172, Batch 4, Loss: 0.085\n",
      "Training: Epoch 172, Batch 5, Loss: 0.135\n",
      "Training: Epoch 172, Batch 6, Loss: 0.093\n",
      "Training: Epoch 172, Batch 7, Loss: 0.129\n",
      "Training: Epoch 172, Batch 8, Loss: 0.138\n",
      "Training: Epoch 172, Batch 9, Loss: 0.086\n",
      "Training: Epoch 172, Batch 10, Loss: 0.117\n",
      "Training: Epoch 172, Batch 11, Loss: 0.101\n",
      "Training: Epoch 172, Batch 12, Loss: 0.108\n",
      "Training: Epoch 172, Batch 13, Loss: 0.104\n",
      "Training: Epoch 172, Batch 14, Loss: 0.104\n",
      "Training: Epoch 172, Batch 15, Loss: 0.138\n",
      "Training: Epoch 172, Batch 16, Loss: 0.08\n",
      "Training: Epoch 172, Batch 17, Loss: 0.106\n",
      "Training: Epoch 172, Batch 18, Loss: 0.103\n",
      "Training: Epoch 172, Batch 19, Loss: 0.152\n",
      "Val: Epoch 172, Loss: 0.261\n",
      "Training: Epoch 173, Batch 0, Loss: 0.128\n",
      "Training: Epoch 173, Batch 1, Loss: 0.096\n",
      "Training: Epoch 173, Batch 2, Loss: 0.102\n",
      "Training: Epoch 173, Batch 3, Loss: 0.1\n",
      "Training: Epoch 173, Batch 4, Loss: 0.171\n",
      "Training: Epoch 173, Batch 5, Loss: 0.13\n",
      "Training: Epoch 173, Batch 6, Loss: 0.105\n",
      "Training: Epoch 173, Batch 7, Loss: 0.122\n",
      "Training: Epoch 173, Batch 8, Loss: 0.094\n",
      "Training: Epoch 173, Batch 9, Loss: 0.103\n",
      "Training: Epoch 173, Batch 10, Loss: 0.12\n",
      "Training: Epoch 173, Batch 11, Loss: 0.107\n",
      "Training: Epoch 173, Batch 12, Loss: 0.117\n",
      "Training: Epoch 173, Batch 13, Loss: 0.13\n",
      "Training: Epoch 173, Batch 14, Loss: 0.126\n",
      "Training: Epoch 173, Batch 15, Loss: 0.08\n",
      "Training: Epoch 173, Batch 16, Loss: 0.121\n",
      "Training: Epoch 173, Batch 17, Loss: 0.112\n",
      "Training: Epoch 173, Batch 18, Loss: 0.092\n",
      "Training: Epoch 173, Batch 19, Loss: 0.096\n",
      "Val: Epoch 173, Loss: 0.302\n",
      "Training: Epoch 174, Batch 0, Loss: 0.116\n",
      "Training: Epoch 174, Batch 1, Loss: 0.137\n",
      "Training: Epoch 174, Batch 2, Loss: 0.103\n",
      "Training: Epoch 174, Batch 3, Loss: 0.117\n",
      "Training: Epoch 174, Batch 4, Loss: 0.088\n",
      "Training: Epoch 174, Batch 5, Loss: 0.117\n",
      "Training: Epoch 174, Batch 6, Loss: 0.099\n",
      "Training: Epoch 174, Batch 7, Loss: 0.099\n",
      "Training: Epoch 174, Batch 8, Loss: 0.089\n",
      "Training: Epoch 174, Batch 9, Loss: 0.132\n",
      "Training: Epoch 174, Batch 10, Loss: 0.102\n",
      "Training: Epoch 174, Batch 11, Loss: 0.102\n",
      "Training: Epoch 174, Batch 12, Loss: 0.107\n",
      "Training: Epoch 174, Batch 13, Loss: 0.116\n",
      "Training: Epoch 174, Batch 14, Loss: 0.126\n",
      "Training: Epoch 174, Batch 15, Loss: 0.098\n",
      "Training: Epoch 174, Batch 16, Loss: 0.126\n",
      "Training: Epoch 174, Batch 17, Loss: 0.101\n",
      "Training: Epoch 174, Batch 18, Loss: 0.151\n",
      "Training: Epoch 174, Batch 19, Loss: 0.084\n",
      "Val: Epoch 174, Loss: 0.28\n",
      "Training: Epoch 175, Batch 0, Loss: 0.119\n",
      "Training: Epoch 175, Batch 1, Loss: 0.124\n",
      "Training: Epoch 175, Batch 2, Loss: 0.114\n",
      "Training: Epoch 175, Batch 3, Loss: 0.082\n",
      "Training: Epoch 175, Batch 4, Loss: 0.131\n",
      "Training: Epoch 175, Batch 5, Loss: 0.084\n",
      "Training: Epoch 175, Batch 6, Loss: 0.101\n",
      "Training: Epoch 175, Batch 7, Loss: 0.11\n",
      "Training: Epoch 175, Batch 8, Loss: 0.117\n",
      "Training: Epoch 175, Batch 9, Loss: 0.086\n",
      "Training: Epoch 175, Batch 10, Loss: 0.095\n",
      "Training: Epoch 175, Batch 11, Loss: 0.104\n",
      "Training: Epoch 175, Batch 12, Loss: 0.114\n",
      "Training: Epoch 175, Batch 13, Loss: 0.126\n",
      "Training: Epoch 175, Batch 14, Loss: 0.095\n",
      "Training: Epoch 175, Batch 15, Loss: 0.121\n",
      "Training: Epoch 175, Batch 16, Loss: 0.133\n",
      "Training: Epoch 175, Batch 17, Loss: 0.15\n",
      "Training: Epoch 175, Batch 18, Loss: 0.102\n",
      "Training: Epoch 175, Batch 19, Loss: 0.105\n",
      "Val: Epoch 175, Loss: 0.266\n",
      "Training: Epoch 176, Batch 0, Loss: 0.116\n",
      "Training: Epoch 176, Batch 1, Loss: 0.117\n",
      "Training: Epoch 176, Batch 2, Loss: 0.109\n",
      "Training: Epoch 176, Batch 3, Loss: 0.107\n",
      "Training: Epoch 176, Batch 4, Loss: 0.093\n",
      "Training: Epoch 176, Batch 5, Loss: 0.178\n",
      "Training: Epoch 176, Batch 6, Loss: 0.112\n",
      "Training: Epoch 176, Batch 7, Loss: 0.093\n",
      "Training: Epoch 176, Batch 8, Loss: 0.102\n",
      "Training: Epoch 176, Batch 9, Loss: 0.12\n",
      "Training: Epoch 176, Batch 10, Loss: 0.119\n",
      "Training: Epoch 176, Batch 11, Loss: 0.098\n",
      "Training: Epoch 176, Batch 12, Loss: 0.099\n",
      "Training: Epoch 176, Batch 13, Loss: 0.134\n",
      "Training: Epoch 176, Batch 14, Loss: 0.133\n",
      "Training: Epoch 176, Batch 15, Loss: 0.122\n",
      "Training: Epoch 176, Batch 16, Loss: 0.088\n",
      "Training: Epoch 176, Batch 17, Loss: 0.099\n",
      "Training: Epoch 176, Batch 18, Loss: 0.116\n",
      "Training: Epoch 176, Batch 19, Loss: 0.182\n",
      "Val: Epoch 176, Loss: 0.256\n",
      "Training: Epoch 177, Batch 0, Loss: 0.116\n",
      "Training: Epoch 177, Batch 1, Loss: 0.089\n",
      "Training: Epoch 177, Batch 2, Loss: 0.103\n",
      "Training: Epoch 177, Batch 3, Loss: 0.119\n",
      "Training: Epoch 177, Batch 4, Loss: 0.1\n",
      "Training: Epoch 177, Batch 5, Loss: 0.128\n",
      "Training: Epoch 177, Batch 6, Loss: 0.135\n",
      "Training: Epoch 177, Batch 7, Loss: 0.201\n",
      "Training: Epoch 177, Batch 8, Loss: 0.117\n",
      "Training: Epoch 177, Batch 9, Loss: 0.13\n",
      "Training: Epoch 177, Batch 10, Loss: 0.137\n",
      "Training: Epoch 177, Batch 11, Loss: 0.122\n",
      "Training: Epoch 177, Batch 12, Loss: 0.094\n",
      "Training: Epoch 177, Batch 13, Loss: 0.15\n",
      "Training: Epoch 177, Batch 14, Loss: 0.122\n",
      "Training: Epoch 177, Batch 15, Loss: 0.118\n",
      "Training: Epoch 177, Batch 16, Loss: 0.127\n",
      "Training: Epoch 177, Batch 17, Loss: 0.116\n",
      "Training: Epoch 177, Batch 18, Loss: 0.099\n",
      "Training: Epoch 177, Batch 19, Loss: 0.14\n",
      "Val: Epoch 177, Loss: 0.267\n",
      "Training: Epoch 178, Batch 0, Loss: 0.131\n",
      "Training: Epoch 178, Batch 1, Loss: 0.132\n",
      "Training: Epoch 178, Batch 2, Loss: 0.112\n",
      "Training: Epoch 178, Batch 3, Loss: 0.099\n",
      "Training: Epoch 178, Batch 4, Loss: 0.12\n",
      "Training: Epoch 178, Batch 5, Loss: 0.097\n",
      "Training: Epoch 178, Batch 6, Loss: 0.079\n",
      "Training: Epoch 178, Batch 7, Loss: 0.116\n",
      "Training: Epoch 178, Batch 8, Loss: 0.109\n",
      "Training: Epoch 178, Batch 9, Loss: 0.119\n",
      "Training: Epoch 178, Batch 10, Loss: 0.09\n",
      "Training: Epoch 178, Batch 11, Loss: 0.142\n",
      "Training: Epoch 178, Batch 12, Loss: 0.147\n",
      "Training: Epoch 178, Batch 13, Loss: 0.109\n",
      "Training: Epoch 178, Batch 14, Loss: 0.17\n",
      "Training: Epoch 178, Batch 15, Loss: 0.113\n",
      "Training: Epoch 178, Batch 16, Loss: 0.116\n",
      "Training: Epoch 178, Batch 17, Loss: 0.132\n",
      "Training: Epoch 178, Batch 18, Loss: 0.104\n",
      "Training: Epoch 178, Batch 19, Loss: 0.102\n",
      "Val: Epoch 178, Loss: 0.253\n",
      "Training: Epoch 179, Batch 0, Loss: 0.125\n",
      "Training: Epoch 179, Batch 1, Loss: 0.119\n",
      "Training: Epoch 179, Batch 2, Loss: 0.094\n",
      "Training: Epoch 179, Batch 3, Loss: 0.119\n",
      "Training: Epoch 179, Batch 4, Loss: 0.097\n",
      "Training: Epoch 179, Batch 5, Loss: 0.11\n",
      "Training: Epoch 179, Batch 6, Loss: 0.094\n",
      "Training: Epoch 179, Batch 7, Loss: 0.112\n",
      "Training: Epoch 179, Batch 8, Loss: 0.116\n",
      "Training: Epoch 179, Batch 9, Loss: 0.097\n",
      "Training: Epoch 179, Batch 10, Loss: 0.103\n",
      "Training: Epoch 179, Batch 11, Loss: 0.121\n",
      "Training: Epoch 179, Batch 12, Loss: 0.112\n",
      "Training: Epoch 179, Batch 13, Loss: 0.098\n",
      "Training: Epoch 179, Batch 14, Loss: 0.135\n",
      "Training: Epoch 179, Batch 15, Loss: 0.109\n",
      "Training: Epoch 179, Batch 16, Loss: 0.124\n",
      "Training: Epoch 179, Batch 17, Loss: 0.119\n",
      "Training: Epoch 179, Batch 18, Loss: 0.106\n",
      "Training: Epoch 179, Batch 19, Loss: 0.097\n",
      "Val: Epoch 179, Loss: 0.25\n",
      "Training: Epoch 180, Batch 0, Loss: 0.091\n",
      "Training: Epoch 180, Batch 1, Loss: 0.102\n",
      "Training: Epoch 180, Batch 2, Loss: 0.109\n",
      "Training: Epoch 180, Batch 3, Loss: 0.129\n",
      "Training: Epoch 180, Batch 4, Loss: 0.094\n",
      "Training: Epoch 180, Batch 5, Loss: 0.12\n",
      "Training: Epoch 180, Batch 6, Loss: 0.088\n",
      "Training: Epoch 180, Batch 7, Loss: 0.096\n",
      "Training: Epoch 180, Batch 8, Loss: 0.111\n",
      "Training: Epoch 180, Batch 9, Loss: 0.097\n",
      "Training: Epoch 180, Batch 10, Loss: 0.113\n",
      "Training: Epoch 180, Batch 11, Loss: 0.097\n",
      "Training: Epoch 180, Batch 12, Loss: 0.114\n",
      "Training: Epoch 180, Batch 13, Loss: 0.109\n",
      "Training: Epoch 180, Batch 14, Loss: 0.1\n",
      "Training: Epoch 180, Batch 15, Loss: 0.101\n",
      "Training: Epoch 180, Batch 16, Loss: 0.111\n",
      "Training: Epoch 180, Batch 17, Loss: 0.081\n",
      "Training: Epoch 180, Batch 18, Loss: 0.122\n",
      "Training: Epoch 180, Batch 19, Loss: 0.109\n",
      "Val: Epoch 180, Loss: 0.268\n",
      "Training: Epoch 181, Batch 0, Loss: 0.1\n",
      "Training: Epoch 181, Batch 1, Loss: 0.106\n",
      "Training: Epoch 181, Batch 2, Loss: 0.101\n",
      "Training: Epoch 181, Batch 3, Loss: 0.148\n",
      "Training: Epoch 181, Batch 4, Loss: 0.1\n",
      "Training: Epoch 181, Batch 5, Loss: 0.078\n",
      "Training: Epoch 181, Batch 6, Loss: 0.086\n",
      "Training: Epoch 181, Batch 7, Loss: 0.109\n",
      "Training: Epoch 181, Batch 8, Loss: 0.103\n",
      "Training: Epoch 181, Batch 9, Loss: 0.096\n",
      "Training: Epoch 181, Batch 10, Loss: 0.101\n",
      "Training: Epoch 181, Batch 11, Loss: 0.163\n",
      "Training: Epoch 181, Batch 12, Loss: 0.118\n",
      "Training: Epoch 181, Batch 13, Loss: 0.119\n",
      "Training: Epoch 181, Batch 14, Loss: 0.083\n",
      "Training: Epoch 181, Batch 15, Loss: 0.12\n",
      "Training: Epoch 181, Batch 16, Loss: 0.121\n",
      "Training: Epoch 181, Batch 17, Loss: 0.111\n",
      "Training: Epoch 181, Batch 18, Loss: 0.112\n",
      "Training: Epoch 181, Batch 19, Loss: 0.111\n",
      "Val: Epoch 181, Loss: 0.315\n",
      "Training: Epoch 182, Batch 0, Loss: 0.113\n",
      "Training: Epoch 182, Batch 1, Loss: 0.101\n",
      "Training: Epoch 182, Batch 2, Loss: 0.14\n",
      "Training: Epoch 182, Batch 3, Loss: 0.101\n",
      "Training: Epoch 182, Batch 4, Loss: 0.117\n",
      "Training: Epoch 182, Batch 5, Loss: 0.103\n",
      "Training: Epoch 182, Batch 6, Loss: 0.111\n",
      "Training: Epoch 182, Batch 7, Loss: 0.12\n",
      "Training: Epoch 182, Batch 8, Loss: 0.129\n",
      "Training: Epoch 182, Batch 9, Loss: 0.101\n",
      "Training: Epoch 182, Batch 10, Loss: 0.095\n",
      "Training: Epoch 182, Batch 11, Loss: 0.117\n",
      "Training: Epoch 182, Batch 12, Loss: 0.095\n",
      "Training: Epoch 182, Batch 13, Loss: 0.108\n",
      "Training: Epoch 182, Batch 14, Loss: 0.1\n",
      "Training: Epoch 182, Batch 15, Loss: 0.118\n",
      "Training: Epoch 182, Batch 16, Loss: 0.08\n",
      "Training: Epoch 182, Batch 17, Loss: 0.111\n",
      "Training: Epoch 182, Batch 18, Loss: 0.11\n",
      "Training: Epoch 182, Batch 19, Loss: 0.119\n",
      "Val: Epoch 182, Loss: 0.272\n",
      "Training: Epoch 183, Batch 0, Loss: 0.102\n",
      "Training: Epoch 183, Batch 1, Loss: 0.116\n",
      "Training: Epoch 183, Batch 2, Loss: 0.095\n",
      "Training: Epoch 183, Batch 3, Loss: 0.084\n",
      "Training: Epoch 183, Batch 4, Loss: 0.124\n",
      "Training: Epoch 183, Batch 5, Loss: 0.109\n",
      "Training: Epoch 183, Batch 6, Loss: 0.099\n",
      "Training: Epoch 183, Batch 7, Loss: 0.102\n",
      "Training: Epoch 183, Batch 8, Loss: 0.091\n",
      "Training: Epoch 183, Batch 9, Loss: 0.124\n",
      "Training: Epoch 183, Batch 10, Loss: 0.133\n",
      "Training: Epoch 183, Batch 11, Loss: 0.091\n",
      "Training: Epoch 183, Batch 12, Loss: 0.095\n",
      "Training: Epoch 183, Batch 13, Loss: 0.105\n",
      "Training: Epoch 183, Batch 14, Loss: 0.111\n",
      "Training: Epoch 183, Batch 15, Loss: 0.103\n",
      "Training: Epoch 183, Batch 16, Loss: 0.109\n",
      "Training: Epoch 183, Batch 17, Loss: 0.105\n",
      "Training: Epoch 183, Batch 18, Loss: 0.098\n",
      "Training: Epoch 183, Batch 19, Loss: 0.12\n",
      "Val: Epoch 183, Loss: 0.281\n",
      "Training: Epoch 184, Batch 0, Loss: 0.127\n",
      "Training: Epoch 184, Batch 1, Loss: 0.102\n",
      "Training: Epoch 184, Batch 2, Loss: 0.117\n",
      "Training: Epoch 184, Batch 3, Loss: 0.083\n",
      "Training: Epoch 184, Batch 4, Loss: 0.101\n",
      "Training: Epoch 184, Batch 5, Loss: 0.102\n",
      "Training: Epoch 184, Batch 6, Loss: 0.123\n",
      "Training: Epoch 184, Batch 7, Loss: 0.105\n",
      "Training: Epoch 184, Batch 8, Loss: 0.093\n",
      "Training: Epoch 184, Batch 9, Loss: 0.125\n",
      "Training: Epoch 184, Batch 10, Loss: 0.096\n",
      "Training: Epoch 184, Batch 11, Loss: 0.112\n",
      "Training: Epoch 184, Batch 12, Loss: 0.099\n",
      "Training: Epoch 184, Batch 13, Loss: 0.117\n",
      "Training: Epoch 184, Batch 14, Loss: 0.13\n",
      "Training: Epoch 184, Batch 15, Loss: 0.104\n",
      "Training: Epoch 184, Batch 16, Loss: 0.104\n",
      "Training: Epoch 184, Batch 17, Loss: 0.123\n",
      "Training: Epoch 184, Batch 18, Loss: 0.113\n",
      "Training: Epoch 184, Batch 19, Loss: 0.1\n",
      "Val: Epoch 184, Loss: 0.261\n",
      "Training: Epoch 185, Batch 0, Loss: 0.104\n",
      "Training: Epoch 185, Batch 1, Loss: 0.125\n",
      "Training: Epoch 185, Batch 2, Loss: 0.106\n",
      "Training: Epoch 185, Batch 3, Loss: 0.124\n",
      "Training: Epoch 185, Batch 4, Loss: 0.094\n",
      "Training: Epoch 185, Batch 5, Loss: 0.113\n",
      "Training: Epoch 185, Batch 6, Loss: 0.102\n",
      "Training: Epoch 185, Batch 7, Loss: 0.076\n",
      "Training: Epoch 185, Batch 8, Loss: 0.079\n",
      "Training: Epoch 185, Batch 9, Loss: 0.101\n",
      "Training: Epoch 185, Batch 10, Loss: 0.086\n",
      "Training: Epoch 185, Batch 11, Loss: 0.096\n",
      "Training: Epoch 185, Batch 12, Loss: 0.112\n",
      "Training: Epoch 185, Batch 13, Loss: 0.087\n",
      "Training: Epoch 185, Batch 14, Loss: 0.105\n",
      "Training: Epoch 185, Batch 15, Loss: 0.129\n",
      "Training: Epoch 185, Batch 16, Loss: 0.089\n",
      "Training: Epoch 185, Batch 17, Loss: 0.09\n",
      "Training: Epoch 185, Batch 18, Loss: 0.096\n",
      "Training: Epoch 185, Batch 19, Loss: 0.108\n",
      "Val: Epoch 185, Loss: 0.291\n",
      "Training: Epoch 186, Batch 0, Loss: 0.096\n",
      "Training: Epoch 186, Batch 1, Loss: 0.078\n",
      "Training: Epoch 186, Batch 2, Loss: 0.133\n",
      "Training: Epoch 186, Batch 3, Loss: 0.099\n",
      "Training: Epoch 186, Batch 4, Loss: 0.097\n",
      "Training: Epoch 186, Batch 5, Loss: 0.107\n",
      "Training: Epoch 186, Batch 6, Loss: 0.112\n",
      "Training: Epoch 186, Batch 7, Loss: 0.081\n",
      "Training: Epoch 186, Batch 8, Loss: 0.108\n",
      "Training: Epoch 186, Batch 9, Loss: 0.129\n",
      "Training: Epoch 186, Batch 10, Loss: 0.088\n",
      "Training: Epoch 186, Batch 11, Loss: 0.112\n",
      "Training: Epoch 186, Batch 12, Loss: 0.144\n",
      "Training: Epoch 186, Batch 13, Loss: 0.092\n",
      "Training: Epoch 186, Batch 14, Loss: 0.135\n",
      "Training: Epoch 186, Batch 15, Loss: 0.099\n",
      "Training: Epoch 186, Batch 16, Loss: 0.128\n",
      "Training: Epoch 186, Batch 17, Loss: 0.139\n",
      "Training: Epoch 186, Batch 18, Loss: 0.099\n",
      "Training: Epoch 186, Batch 19, Loss: 0.116\n",
      "Val: Epoch 186, Loss: 0.699\n",
      "Training: Epoch 187, Batch 0, Loss: 0.113\n",
      "Training: Epoch 187, Batch 1, Loss: 0.128\n",
      "Training: Epoch 187, Batch 2, Loss: 0.092\n",
      "Training: Epoch 187, Batch 3, Loss: 0.113\n",
      "Training: Epoch 187, Batch 4, Loss: 0.117\n",
      "Training: Epoch 187, Batch 5, Loss: 0.085\n",
      "Training: Epoch 187, Batch 6, Loss: 0.093\n",
      "Training: Epoch 187, Batch 7, Loss: 0.142\n",
      "Training: Epoch 187, Batch 8, Loss: 0.113\n",
      "Training: Epoch 187, Batch 9, Loss: 0.121\n",
      "Training: Epoch 187, Batch 10, Loss: 0.108\n",
      "Training: Epoch 187, Batch 11, Loss: 0.094\n",
      "Training: Epoch 187, Batch 12, Loss: 0.126\n",
      "Training: Epoch 187, Batch 13, Loss: 0.116\n",
      "Training: Epoch 187, Batch 14, Loss: 0.126\n",
      "Training: Epoch 187, Batch 15, Loss: 0.107\n",
      "Training: Epoch 187, Batch 16, Loss: 0.095\n",
      "Training: Epoch 187, Batch 17, Loss: 0.113\n",
      "Training: Epoch 187, Batch 18, Loss: 0.098\n",
      "Training: Epoch 187, Batch 19, Loss: 0.084\n",
      "Val: Epoch 187, Loss: 0.259\n",
      "Training: Epoch 188, Batch 0, Loss: 0.089\n",
      "Training: Epoch 188, Batch 1, Loss: 0.109\n",
      "Training: Epoch 188, Batch 2, Loss: 0.11\n",
      "Training: Epoch 188, Batch 3, Loss: 0.168\n",
      "Training: Epoch 188, Batch 4, Loss: 0.106\n",
      "Training: Epoch 188, Batch 5, Loss: 0.129\n",
      "Training: Epoch 188, Batch 6, Loss: 0.105\n",
      "Training: Epoch 188, Batch 7, Loss: 0.116\n",
      "Training: Epoch 188, Batch 8, Loss: 0.124\n",
      "Training: Epoch 188, Batch 9, Loss: 0.096\n",
      "Training: Epoch 188, Batch 10, Loss: 0.087\n",
      "Training: Epoch 188, Batch 11, Loss: 0.119\n",
      "Training: Epoch 188, Batch 12, Loss: 0.107\n",
      "Training: Epoch 188, Batch 13, Loss: 0.126\n",
      "Training: Epoch 188, Batch 14, Loss: 0.088\n",
      "Training: Epoch 188, Batch 15, Loss: 0.121\n",
      "Training: Epoch 188, Batch 16, Loss: 0.087\n",
      "Training: Epoch 188, Batch 17, Loss: 0.112\n",
      "Training: Epoch 188, Batch 18, Loss: 0.104\n",
      "Training: Epoch 188, Batch 19, Loss: 0.111\n",
      "Val: Epoch 188, Loss: 0.285\n",
      "Training: Epoch 189, Batch 0, Loss: 0.103\n",
      "Training: Epoch 189, Batch 1, Loss: 0.102\n",
      "Training: Epoch 189, Batch 2, Loss: 0.08\n",
      "Training: Epoch 189, Batch 3, Loss: 0.098\n",
      "Training: Epoch 189, Batch 4, Loss: 0.147\n",
      "Training: Epoch 189, Batch 5, Loss: 0.084\n",
      "Training: Epoch 189, Batch 6, Loss: 0.121\n",
      "Training: Epoch 189, Batch 7, Loss: 0.106\n",
      "Training: Epoch 189, Batch 8, Loss: 0.082\n",
      "Training: Epoch 189, Batch 9, Loss: 0.132\n",
      "Training: Epoch 189, Batch 10, Loss: 0.101\n",
      "Training: Epoch 189, Batch 11, Loss: 0.123\n",
      "Training: Epoch 189, Batch 12, Loss: 0.093\n",
      "Training: Epoch 189, Batch 13, Loss: 0.102\n",
      "Training: Epoch 189, Batch 14, Loss: 0.099\n",
      "Training: Epoch 189, Batch 15, Loss: 0.09\n",
      "Training: Epoch 189, Batch 16, Loss: 0.092\n",
      "Training: Epoch 189, Batch 17, Loss: 0.101\n",
      "Training: Epoch 189, Batch 18, Loss: 0.086\n",
      "Training: Epoch 189, Batch 19, Loss: 0.104\n",
      "Val: Epoch 189, Loss: 0.252\n",
      "Training: Epoch 190, Batch 0, Loss: 0.088\n",
      "Training: Epoch 190, Batch 1, Loss: 0.105\n",
      "Training: Epoch 190, Batch 2, Loss: 0.087\n",
      "Training: Epoch 190, Batch 3, Loss: 0.096\n",
      "Training: Epoch 190, Batch 4, Loss: 0.085\n",
      "Training: Epoch 190, Batch 5, Loss: 0.097\n",
      "Training: Epoch 190, Batch 6, Loss: 0.097\n",
      "Training: Epoch 190, Batch 7, Loss: 0.163\n",
      "Training: Epoch 190, Batch 8, Loss: 0.077\n",
      "Training: Epoch 190, Batch 9, Loss: 0.084\n",
      "Training: Epoch 190, Batch 10, Loss: 0.08\n",
      "Training: Epoch 190, Batch 11, Loss: 0.081\n",
      "Training: Epoch 190, Batch 12, Loss: 0.137\n",
      "Training: Epoch 190, Batch 13, Loss: 0.108\n",
      "Training: Epoch 190, Batch 14, Loss: 0.099\n",
      "Training: Epoch 190, Batch 15, Loss: 0.122\n",
      "Training: Epoch 190, Batch 16, Loss: 0.111\n",
      "Training: Epoch 190, Batch 17, Loss: 0.142\n",
      "Training: Epoch 190, Batch 18, Loss: 0.092\n",
      "Training: Epoch 190, Batch 19, Loss: 0.107\n",
      "Val: Epoch 190, Loss: 0.248\n",
      "Training: Epoch 191, Batch 0, Loss: 0.151\n",
      "Training: Epoch 191, Batch 1, Loss: 0.098\n",
      "Training: Epoch 191, Batch 2, Loss: 0.103\n",
      "Training: Epoch 191, Batch 3, Loss: 0.138\n",
      "Training: Epoch 191, Batch 4, Loss: 0.089\n",
      "Training: Epoch 191, Batch 5, Loss: 0.098\n",
      "Training: Epoch 191, Batch 6, Loss: 0.102\n",
      "Training: Epoch 191, Batch 7, Loss: 0.129\n",
      "Training: Epoch 191, Batch 8, Loss: 0.09\n",
      "Training: Epoch 191, Batch 9, Loss: 0.103\n",
      "Training: Epoch 191, Batch 10, Loss: 0.11\n",
      "Training: Epoch 191, Batch 11, Loss: 0.111\n",
      "Training: Epoch 191, Batch 12, Loss: 0.104\n",
      "Training: Epoch 191, Batch 13, Loss: 0.101\n",
      "Training: Epoch 191, Batch 14, Loss: 0.106\n",
      "Training: Epoch 191, Batch 15, Loss: 0.101\n",
      "Training: Epoch 191, Batch 16, Loss: 0.092\n",
      "Training: Epoch 191, Batch 17, Loss: 0.119\n",
      "Training: Epoch 191, Batch 18, Loss: 0.121\n",
      "Training: Epoch 191, Batch 19, Loss: 0.086\n",
      "Val: Epoch 191, Loss: 0.273\n",
      "Training: Epoch 192, Batch 0, Loss: 0.139\n",
      "Training: Epoch 192, Batch 1, Loss: 0.097\n",
      "Training: Epoch 192, Batch 2, Loss: 0.1\n",
      "Training: Epoch 192, Batch 3, Loss: 0.091\n",
      "Training: Epoch 192, Batch 4, Loss: 0.092\n",
      "Training: Epoch 192, Batch 5, Loss: 0.109\n",
      "Training: Epoch 192, Batch 6, Loss: 0.121\n",
      "Training: Epoch 192, Batch 7, Loss: 0.082\n",
      "Training: Epoch 192, Batch 8, Loss: 0.112\n",
      "Training: Epoch 192, Batch 9, Loss: 0.08\n",
      "Training: Epoch 192, Batch 10, Loss: 0.121\n",
      "Training: Epoch 192, Batch 11, Loss: 0.089\n",
      "Training: Epoch 192, Batch 12, Loss: 0.109\n",
      "Training: Epoch 192, Batch 13, Loss: 0.104\n",
      "Training: Epoch 192, Batch 14, Loss: 0.105\n",
      "Training: Epoch 192, Batch 15, Loss: 0.096\n",
      "Training: Epoch 192, Batch 16, Loss: 0.122\n",
      "Training: Epoch 192, Batch 17, Loss: 0.114\n",
      "Training: Epoch 192, Batch 18, Loss: 0.092\n",
      "Training: Epoch 192, Batch 19, Loss: 0.096\n",
      "Val: Epoch 192, Loss: 0.307\n",
      "Training: Epoch 193, Batch 0, Loss: 0.106\n",
      "Training: Epoch 193, Batch 1, Loss: 0.127\n",
      "Training: Epoch 193, Batch 2, Loss: 0.123\n",
      "Training: Epoch 193, Batch 3, Loss: 0.082\n",
      "Training: Epoch 193, Batch 4, Loss: 0.098\n",
      "Training: Epoch 193, Batch 5, Loss: 0.109\n",
      "Training: Epoch 193, Batch 6, Loss: 0.102\n",
      "Training: Epoch 193, Batch 7, Loss: 0.124\n",
      "Training: Epoch 193, Batch 8, Loss: 0.098\n",
      "Training: Epoch 193, Batch 9, Loss: 0.095\n",
      "Training: Epoch 193, Batch 10, Loss: 0.088\n",
      "Training: Epoch 193, Batch 11, Loss: 0.102\n",
      "Training: Epoch 193, Batch 12, Loss: 0.091\n",
      "Training: Epoch 193, Batch 13, Loss: 0.107\n",
      "Training: Epoch 193, Batch 14, Loss: 0.117\n",
      "Training: Epoch 193, Batch 15, Loss: 0.086\n",
      "Training: Epoch 193, Batch 16, Loss: 0.103\n",
      "Training: Epoch 193, Batch 17, Loss: 0.078\n",
      "Training: Epoch 193, Batch 18, Loss: 0.103\n",
      "Training: Epoch 193, Batch 19, Loss: 0.095\n",
      "Val: Epoch 193, Loss: 0.264\n",
      "Training: Epoch 194, Batch 0, Loss: 0.113\n",
      "Training: Epoch 194, Batch 1, Loss: 0.116\n",
      "Training: Epoch 194, Batch 2, Loss: 0.096\n",
      "Training: Epoch 194, Batch 3, Loss: 0.094\n",
      "Training: Epoch 194, Batch 4, Loss: 0.086\n",
      "Training: Epoch 194, Batch 5, Loss: 0.09\n",
      "Training: Epoch 194, Batch 6, Loss: 0.091\n",
      "Training: Epoch 194, Batch 7, Loss: 0.082\n",
      "Training: Epoch 194, Batch 8, Loss: 0.107\n",
      "Training: Epoch 194, Batch 9, Loss: 0.099\n",
      "Training: Epoch 194, Batch 10, Loss: 0.1\n",
      "Training: Epoch 194, Batch 11, Loss: 0.074\n",
      "Training: Epoch 194, Batch 12, Loss: 0.114\n",
      "Training: Epoch 194, Batch 13, Loss: 0.078\n",
      "Training: Epoch 194, Batch 14, Loss: 0.095\n",
      "Training: Epoch 194, Batch 15, Loss: 0.103\n",
      "Training: Epoch 194, Batch 16, Loss: 0.081\n",
      "Training: Epoch 194, Batch 17, Loss: 0.079\n",
      "Training: Epoch 194, Batch 18, Loss: 0.102\n",
      "Training: Epoch 194, Batch 19, Loss: 0.112\n",
      "Val: Epoch 194, Loss: 0.254\n",
      "Training: Epoch 195, Batch 0, Loss: 0.122\n",
      "Training: Epoch 195, Batch 1, Loss: 0.08\n",
      "Training: Epoch 195, Batch 2, Loss: 0.088\n",
      "Training: Epoch 195, Batch 3, Loss: 0.098\n",
      "Training: Epoch 195, Batch 4, Loss: 0.111\n",
      "Training: Epoch 195, Batch 5, Loss: 0.084\n",
      "Training: Epoch 195, Batch 6, Loss: 0.104\n",
      "Training: Epoch 195, Batch 7, Loss: 0.11\n",
      "Training: Epoch 195, Batch 8, Loss: 0.112\n",
      "Training: Epoch 195, Batch 9, Loss: 0.094\n",
      "Training: Epoch 195, Batch 10, Loss: 0.102\n",
      "Training: Epoch 195, Batch 11, Loss: 0.081\n",
      "Training: Epoch 195, Batch 12, Loss: 0.08\n",
      "Training: Epoch 195, Batch 13, Loss: 0.1\n",
      "Training: Epoch 195, Batch 14, Loss: 0.086\n",
      "Training: Epoch 195, Batch 15, Loss: 0.106\n",
      "Training: Epoch 195, Batch 16, Loss: 0.07\n",
      "Training: Epoch 195, Batch 17, Loss: 0.092\n",
      "Training: Epoch 195, Batch 18, Loss: 0.078\n",
      "Training: Epoch 195, Batch 19, Loss: 0.098\n",
      "Val: Epoch 195, Loss: 0.239\n",
      "Training: Epoch 196, Batch 0, Loss: 0.107\n",
      "Training: Epoch 196, Batch 1, Loss: 0.074\n",
      "Training: Epoch 196, Batch 2, Loss: 0.122\n",
      "Training: Epoch 196, Batch 3, Loss: 0.092\n",
      "Training: Epoch 196, Batch 4, Loss: 0.088\n",
      "Training: Epoch 196, Batch 5, Loss: 0.095\n",
      "Training: Epoch 196, Batch 6, Loss: 0.083\n",
      "Training: Epoch 196, Batch 7, Loss: 0.097\n",
      "Training: Epoch 196, Batch 8, Loss: 0.106\n",
      "Training: Epoch 196, Batch 9, Loss: 0.084\n",
      "Training: Epoch 196, Batch 10, Loss: 0.08\n",
      "Training: Epoch 196, Batch 11, Loss: 0.093\n",
      "Training: Epoch 196, Batch 12, Loss: 0.12\n",
      "Training: Epoch 196, Batch 13, Loss: 0.118\n",
      "Training: Epoch 196, Batch 14, Loss: 0.098\n",
      "Training: Epoch 196, Batch 15, Loss: 0.089\n",
      "Training: Epoch 196, Batch 16, Loss: 0.086\n",
      "Training: Epoch 196, Batch 17, Loss: 0.083\n",
      "Training: Epoch 196, Batch 18, Loss: 0.116\n",
      "Training: Epoch 196, Batch 19, Loss: 0.086\n",
      "Val: Epoch 196, Loss: 0.258\n",
      "Training: Epoch 197, Batch 0, Loss: 0.087\n",
      "Training: Epoch 197, Batch 1, Loss: 0.077\n",
      "Training: Epoch 197, Batch 2, Loss: 0.12\n",
      "Training: Epoch 197, Batch 3, Loss: 0.103\n",
      "Training: Epoch 197, Batch 4, Loss: 0.161\n",
      "Training: Epoch 197, Batch 5, Loss: 0.105\n",
      "Training: Epoch 197, Batch 6, Loss: 0.092\n",
      "Training: Epoch 197, Batch 7, Loss: 0.079\n",
      "Training: Epoch 197, Batch 8, Loss: 0.107\n",
      "Training: Epoch 197, Batch 9, Loss: 0.107\n",
      "Training: Epoch 197, Batch 10, Loss: 0.11\n",
      "Training: Epoch 197, Batch 11, Loss: 0.077\n",
      "Training: Epoch 197, Batch 12, Loss: 0.094\n",
      "Training: Epoch 197, Batch 13, Loss: 0.099\n",
      "Training: Epoch 197, Batch 14, Loss: 0.109\n",
      "Training: Epoch 197, Batch 15, Loss: 0.092\n",
      "Training: Epoch 197, Batch 16, Loss: 0.101\n",
      "Training: Epoch 197, Batch 17, Loss: 0.089\n",
      "Training: Epoch 197, Batch 18, Loss: 0.101\n",
      "Training: Epoch 197, Batch 19, Loss: 0.089\n",
      "Val: Epoch 197, Loss: 0.263\n",
      "Training: Epoch 198, Batch 0, Loss: 0.092\n",
      "Training: Epoch 198, Batch 1, Loss: 0.12\n",
      "Training: Epoch 198, Batch 2, Loss: 0.122\n",
      "Training: Epoch 198, Batch 3, Loss: 0.087\n",
      "Training: Epoch 198, Batch 4, Loss: 0.088\n",
      "Training: Epoch 198, Batch 5, Loss: 0.091\n",
      "Training: Epoch 198, Batch 6, Loss: 0.111\n",
      "Training: Epoch 198, Batch 7, Loss: 0.111\n",
      "Training: Epoch 198, Batch 8, Loss: 0.089\n",
      "Training: Epoch 198, Batch 9, Loss: 0.134\n",
      "Training: Epoch 198, Batch 10, Loss: 0.09\n",
      "Training: Epoch 198, Batch 11, Loss: 0.115\n",
      "Training: Epoch 198, Batch 12, Loss: 0.084\n",
      "Training: Epoch 198, Batch 13, Loss: 0.09\n",
      "Training: Epoch 198, Batch 14, Loss: 0.092\n",
      "Training: Epoch 198, Batch 15, Loss: 0.085\n",
      "Training: Epoch 198, Batch 16, Loss: 0.092\n",
      "Training: Epoch 198, Batch 17, Loss: 0.092\n",
      "Training: Epoch 198, Batch 18, Loss: 0.134\n",
      "Training: Epoch 198, Batch 19, Loss: 0.105\n",
      "Val: Epoch 198, Loss: 0.272\n",
      "Training: Epoch 199, Batch 0, Loss: 0.1\n",
      "Training: Epoch 199, Batch 1, Loss: 0.091\n",
      "Training: Epoch 199, Batch 2, Loss: 0.076\n",
      "Training: Epoch 199, Batch 3, Loss: 0.101\n",
      "Training: Epoch 199, Batch 4, Loss: 0.112\n",
      "Training: Epoch 199, Batch 5, Loss: 0.085\n",
      "Training: Epoch 199, Batch 6, Loss: 0.099\n",
      "Training: Epoch 199, Batch 7, Loss: 0.091\n",
      "Training: Epoch 199, Batch 8, Loss: 0.102\n",
      "Training: Epoch 199, Batch 9, Loss: 0.095\n",
      "Training: Epoch 199, Batch 10, Loss: 0.092\n",
      "Training: Epoch 199, Batch 11, Loss: 0.098\n",
      "Training: Epoch 199, Batch 12, Loss: 0.111\n",
      "Training: Epoch 199, Batch 13, Loss: 0.109\n",
      "Training: Epoch 199, Batch 14, Loss: 0.092\n",
      "Training: Epoch 199, Batch 15, Loss: 0.101\n",
      "Training: Epoch 199, Batch 16, Loss: 0.124\n",
      "Training: Epoch 199, Batch 17, Loss: 0.11\n",
      "Training: Epoch 199, Batch 18, Loss: 0.11\n",
      "Training: Epoch 199, Batch 19, Loss: 0.091\n",
      "Val: Epoch 199, Loss: 0.308\n",
      "Training: Epoch 200, Batch 0, Loss: 0.115\n",
      "Training: Epoch 200, Batch 1, Loss: 0.113\n",
      "Training: Epoch 200, Batch 2, Loss: 0.107\n",
      "Training: Epoch 200, Batch 3, Loss: 0.087\n",
      "Training: Epoch 200, Batch 4, Loss: 0.137\n",
      "Training: Epoch 200, Batch 5, Loss: 0.146\n",
      "Training: Epoch 200, Batch 6, Loss: 0.084\n",
      "Training: Epoch 200, Batch 7, Loss: 0.099\n",
      "Training: Epoch 200, Batch 8, Loss: 0.088\n",
      "Training: Epoch 200, Batch 9, Loss: 0.091\n",
      "Training: Epoch 200, Batch 10, Loss: 0.093\n",
      "Training: Epoch 200, Batch 11, Loss: 0.095\n",
      "Training: Epoch 200, Batch 12, Loss: 0.107\n",
      "Training: Epoch 200, Batch 13, Loss: 0.11\n",
      "Training: Epoch 200, Batch 14, Loss: 0.084\n",
      "Training: Epoch 200, Batch 15, Loss: 0.093\n",
      "Training: Epoch 200, Batch 16, Loss: 0.09\n",
      "Training: Epoch 200, Batch 17, Loss: 0.082\n",
      "Training: Epoch 200, Batch 18, Loss: 0.094\n",
      "Training: Epoch 200, Batch 19, Loss: 0.153\n",
      "Val: Epoch 200, Loss: 0.248\n",
      "Best model found at epoch 153\n",
      "Total training time: 1194.9186787605286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[-1],map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_model.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96    937035\n",
      "           1       0.91      0.90      0.90   1187442\n",
      "           2       0.80      0.90      0.85    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.90      0.91      0.90   2621440\n",
      "weighted avg       0.92      0.91      0.91   2621440\n",
      "\n",
      "Val loss: 0.21520392894744872\n",
      "AUROC: 0.9848283707237656\n"
     ]
    }
   ],
   "source": [
    "from semseg_functions import train_model_transunet, make_predictions_transunet\n",
    "from transunet import TransUNet\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#model = TransUNet()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "#X_train,Y_train,X_val,Y_val=load_imgs_labels()\n",
    "start_time = time.time()\n",
    "model, best_model_loss=train_model_transunet(X_train,Y_train,X_val,Y_val, lr= 0.003, momentum= 0.9, weight_decay= 0.01)\n",
    "end_time = time.time()\n",
    "print(\"Total training time:\", end_time-start_time)\n",
    "y_val_pred=make_predictions_transunet(X_val,model=None)\n",
    "y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "#print loss\n",
    "print(\"Val loss:\", best_model_loss)\n",
    "\n",
    "# Flatten prediction: shape (B, C, H, W) → (N, C)\n",
    "y_val_pred_flat = y_val_pred.transpose(0, 2, 3, 1).reshape(-1, y_val_pred.shape[1])\n",
    "\n",
    "# Flatten true labels: shape (B, H, W) → (N,)\n",
    "y_true = Y_val.numpy().flatten()\n",
    "\n",
    "# Binarize true labels for multiclass AUROC\n",
    "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(y_true_binarized, y_val_pred_flat, multi_class='ovr')\n",
    "\n",
    "print(\"AUROC:\", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2748ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([160, 3, 256, 256])\n",
      "Y_train shape: torch.Size([160, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:4969: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented X shape: torch.Size([480, 3, 256, 256]), Augmented Y shape: torch.Size([480, 256, 256])\n",
      "X_train_aug shape: torch.Size([480, 3, 256, 256])\n",
      "Y_train_aug shape: torch.Size([480, 256, 256])\n",
      "Using device: cuda\n",
      "Training: Epoch 1, Batch 0, Loss: 1.113\n",
      "Training: Epoch 1, Batch 1, Loss: 1.099\n",
      "Training: Epoch 1, Batch 2, Loss: 1.106\n",
      "Training: Epoch 1, Batch 3, Loss: 1.099\n",
      "Training: Epoch 1, Batch 4, Loss: 1.097\n",
      "Training: Epoch 1, Batch 5, Loss: 1.091\n",
      "Training: Epoch 1, Batch 6, Loss: 1.08\n",
      "Training: Epoch 1, Batch 7, Loss: 1.081\n",
      "Training: Epoch 1, Batch 8, Loss: 1.084\n",
      "Training: Epoch 1, Batch 9, Loss: 1.08\n",
      "Training: Epoch 1, Batch 10, Loss: 1.085\n",
      "Training: Epoch 1, Batch 11, Loss: 1.09\n",
      "Training: Epoch 1, Batch 12, Loss: 1.076\n",
      "Training: Epoch 1, Batch 13, Loss: 1.061\n",
      "Training: Epoch 1, Batch 14, Loss: 1.072\n",
      "Training: Epoch 1, Batch 15, Loss: 1.067\n",
      "Training: Epoch 1, Batch 16, Loss: 1.069\n",
      "Training: Epoch 1, Batch 17, Loss: 1.052\n",
      "Training: Epoch 1, Batch 18, Loss: 1.041\n",
      "Training: Epoch 1, Batch 19, Loss: 1.059\n",
      "Training: Epoch 1, Batch 20, Loss: 1.059\n",
      "Training: Epoch 1, Batch 21, Loss: 1.036\n",
      "Training: Epoch 1, Batch 22, Loss: 1.019\n",
      "Training: Epoch 1, Batch 23, Loss: 1.033\n",
      "Training: Epoch 1, Batch 24, Loss: 1.016\n",
      "Training: Epoch 1, Batch 25, Loss: 1.023\n",
      "Training: Epoch 1, Batch 26, Loss: 0.985\n",
      "Training: Epoch 1, Batch 27, Loss: 1.003\n",
      "Training: Epoch 1, Batch 28, Loss: 0.994\n",
      "Training: Epoch 1, Batch 29, Loss: 0.98\n",
      "Training: Epoch 1, Batch 30, Loss: 0.946\n",
      "Training: Epoch 1, Batch 31, Loss: 0.935\n",
      "Training: Epoch 1, Batch 32, Loss: 0.916\n",
      "Training: Epoch 1, Batch 33, Loss: 0.954\n",
      "Training: Epoch 1, Batch 34, Loss: 0.966\n",
      "Training: Epoch 1, Batch 35, Loss: 0.97\n",
      "Training: Epoch 1, Batch 36, Loss: 0.892\n",
      "Training: Epoch 1, Batch 37, Loss: 0.925\n",
      "Training: Epoch 1, Batch 38, Loss: 0.815\n",
      "Training: Epoch 1, Batch 39, Loss: 0.925\n",
      "Training: Epoch 1, Batch 40, Loss: 0.878\n",
      "Training: Epoch 1, Batch 41, Loss: 0.785\n",
      "Training: Epoch 1, Batch 42, Loss: 0.874\n",
      "Training: Epoch 1, Batch 43, Loss: 0.747\n",
      "Training: Epoch 1, Batch 44, Loss: 0.801\n",
      "Training: Epoch 1, Batch 45, Loss: 0.71\n",
      "Training: Epoch 1, Batch 46, Loss: 0.702\n",
      "Training: Epoch 1, Batch 47, Loss: 0.765\n",
      "Training: Epoch 1, Batch 48, Loss: 0.658\n",
      "Training: Epoch 1, Batch 49, Loss: 0.713\n",
      "Training: Epoch 1, Batch 50, Loss: 0.707\n",
      "Training: Epoch 1, Batch 51, Loss: 0.79\n",
      "Training: Epoch 1, Batch 52, Loss: 0.657\n",
      "Training: Epoch 1, Batch 53, Loss: 0.73\n",
      "Training: Epoch 1, Batch 54, Loss: 0.561\n",
      "Training: Epoch 1, Batch 55, Loss: 0.664\n",
      "Training: Epoch 1, Batch 56, Loss: 0.573\n",
      "Training: Epoch 1, Batch 57, Loss: 0.655\n",
      "Training: Epoch 1, Batch 58, Loss: 0.649\n",
      "Training: Epoch 1, Batch 59, Loss: 0.513\n",
      "Val: Epoch 1, Loss: 0.562\n",
      "Training: Epoch 2, Batch 0, Loss: 0.742\n",
      "Training: Epoch 2, Batch 1, Loss: 0.697\n",
      "Training: Epoch 2, Batch 2, Loss: 0.624\n",
      "Training: Epoch 2, Batch 3, Loss: 0.612\n",
      "Training: Epoch 2, Batch 4, Loss: 0.722\n",
      "Training: Epoch 2, Batch 5, Loss: 0.512\n",
      "Training: Epoch 2, Batch 6, Loss: 0.596\n",
      "Training: Epoch 2, Batch 7, Loss: 0.596\n",
      "Training: Epoch 2, Batch 8, Loss: 0.467\n",
      "Training: Epoch 2, Batch 9, Loss: 0.558\n",
      "Training: Epoch 2, Batch 10, Loss: 0.664\n",
      "Training: Epoch 2, Batch 11, Loss: 0.598\n",
      "Training: Epoch 2, Batch 12, Loss: 0.702\n",
      "Training: Epoch 2, Batch 13, Loss: 0.481\n",
      "Training: Epoch 2, Batch 14, Loss: 0.635\n",
      "Training: Epoch 2, Batch 15, Loss: 0.552\n",
      "Training: Epoch 2, Batch 16, Loss: 0.505\n",
      "Training: Epoch 2, Batch 17, Loss: 0.549\n",
      "Training: Epoch 2, Batch 18, Loss: 0.407\n",
      "Training: Epoch 2, Batch 19, Loss: 0.497\n",
      "Training: Epoch 2, Batch 20, Loss: 0.419\n",
      "Training: Epoch 2, Batch 21, Loss: 0.516\n",
      "Training: Epoch 2, Batch 22, Loss: 0.564\n",
      "Training: Epoch 2, Batch 23, Loss: 0.452\n",
      "Training: Epoch 2, Batch 24, Loss: 0.446\n",
      "Training: Epoch 2, Batch 25, Loss: 0.478\n",
      "Training: Epoch 2, Batch 26, Loss: 0.569\n",
      "Training: Epoch 2, Batch 27, Loss: 0.54\n",
      "Training: Epoch 2, Batch 28, Loss: 0.455\n",
      "Training: Epoch 2, Batch 29, Loss: 0.397\n",
      "Training: Epoch 2, Batch 30, Loss: 0.397\n",
      "Training: Epoch 2, Batch 31, Loss: 0.547\n",
      "Training: Epoch 2, Batch 32, Loss: 0.494\n",
      "Training: Epoch 2, Batch 33, Loss: 0.422\n",
      "Training: Epoch 2, Batch 34, Loss: 0.579\n",
      "Training: Epoch 2, Batch 35, Loss: 0.508\n",
      "Training: Epoch 2, Batch 36, Loss: 0.441\n",
      "Training: Epoch 2, Batch 37, Loss: 0.397\n",
      "Training: Epoch 2, Batch 38, Loss: 0.914\n",
      "Training: Epoch 2, Batch 39, Loss: 0.503\n",
      "Training: Epoch 2, Batch 40, Loss: 0.452\n",
      "Training: Epoch 2, Batch 41, Loss: 0.559\n",
      "Training: Epoch 2, Batch 42, Loss: 0.662\n",
      "Training: Epoch 2, Batch 43, Loss: 0.565\n",
      "Training: Epoch 2, Batch 44, Loss: 0.479\n",
      "Training: Epoch 2, Batch 45, Loss: 0.472\n",
      "Training: Epoch 2, Batch 46, Loss: 0.526\n",
      "Training: Epoch 2, Batch 47, Loss: 0.724\n",
      "Training: Epoch 2, Batch 48, Loss: 0.558\n",
      "Training: Epoch 2, Batch 49, Loss: 0.441\n",
      "Training: Epoch 2, Batch 50, Loss: 0.635\n",
      "Training: Epoch 2, Batch 51, Loss: 0.507\n",
      "Training: Epoch 2, Batch 52, Loss: 0.412\n",
      "Training: Epoch 2, Batch 53, Loss: 0.522\n",
      "Training: Epoch 2, Batch 54, Loss: 0.555\n",
      "Training: Epoch 2, Batch 55, Loss: 0.595\n",
      "Training: Epoch 2, Batch 56, Loss: 0.533\n",
      "Training: Epoch 2, Batch 57, Loss: 0.422\n",
      "Training: Epoch 2, Batch 58, Loss: 0.435\n",
      "Training: Epoch 2, Batch 59, Loss: 0.368\n",
      "Val: Epoch 2, Loss: 0.443\n",
      "Training: Epoch 3, Batch 0, Loss: 0.454\n",
      "Training: Epoch 3, Batch 1, Loss: 0.475\n",
      "Training: Epoch 3, Batch 2, Loss: 0.463\n",
      "Training: Epoch 3, Batch 3, Loss: 0.518\n",
      "Training: Epoch 3, Batch 4, Loss: 0.406\n",
      "Training: Epoch 3, Batch 5, Loss: 0.444\n",
      "Training: Epoch 3, Batch 6, Loss: 0.39\n",
      "Training: Epoch 3, Batch 7, Loss: 0.399\n",
      "Training: Epoch 3, Batch 8, Loss: 0.492\n",
      "Training: Epoch 3, Batch 9, Loss: 0.321\n",
      "Training: Epoch 3, Batch 10, Loss: 0.431\n",
      "Training: Epoch 3, Batch 11, Loss: 0.384\n",
      "Training: Epoch 3, Batch 12, Loss: 0.583\n",
      "Training: Epoch 3, Batch 13, Loss: 0.357\n",
      "Training: Epoch 3, Batch 14, Loss: 0.494\n",
      "Training: Epoch 3, Batch 15, Loss: 0.367\n",
      "Training: Epoch 3, Batch 16, Loss: 0.702\n",
      "Training: Epoch 3, Batch 17, Loss: 0.352\n",
      "Training: Epoch 3, Batch 18, Loss: 0.471\n",
      "Training: Epoch 3, Batch 19, Loss: 0.431\n",
      "Training: Epoch 3, Batch 20, Loss: 0.415\n",
      "Training: Epoch 3, Batch 21, Loss: 0.538\n",
      "Training: Epoch 3, Batch 22, Loss: 0.433\n",
      "Training: Epoch 3, Batch 23, Loss: 0.399\n",
      "Training: Epoch 3, Batch 24, Loss: 0.429\n",
      "Training: Epoch 3, Batch 25, Loss: 0.351\n",
      "Training: Epoch 3, Batch 26, Loss: 0.425\n",
      "Training: Epoch 3, Batch 27, Loss: 0.336\n",
      "Training: Epoch 3, Batch 28, Loss: 0.351\n",
      "Training: Epoch 3, Batch 29, Loss: 0.496\n",
      "Training: Epoch 3, Batch 30, Loss: 0.375\n",
      "Training: Epoch 3, Batch 31, Loss: 0.322\n",
      "Training: Epoch 3, Batch 32, Loss: 0.38\n",
      "Training: Epoch 3, Batch 33, Loss: 0.284\n",
      "Training: Epoch 3, Batch 34, Loss: 0.345\n",
      "Training: Epoch 3, Batch 35, Loss: 0.393\n",
      "Training: Epoch 3, Batch 36, Loss: 0.45\n",
      "Training: Epoch 3, Batch 37, Loss: 0.39\n",
      "Training: Epoch 3, Batch 38, Loss: 0.32\n",
      "Training: Epoch 3, Batch 39, Loss: 0.546\n",
      "Training: Epoch 3, Batch 40, Loss: 0.422\n",
      "Training: Epoch 3, Batch 41, Loss: 0.516\n",
      "Training: Epoch 3, Batch 42, Loss: 0.344\n",
      "Training: Epoch 3, Batch 43, Loss: 0.397\n",
      "Training: Epoch 3, Batch 44, Loss: 0.445\n",
      "Training: Epoch 3, Batch 45, Loss: 0.397\n",
      "Training: Epoch 3, Batch 46, Loss: 0.303\n",
      "Training: Epoch 3, Batch 47, Loss: 0.328\n",
      "Training: Epoch 3, Batch 48, Loss: 0.401\n",
      "Training: Epoch 3, Batch 49, Loss: 0.501\n",
      "Training: Epoch 3, Batch 50, Loss: 0.423\n",
      "Training: Epoch 3, Batch 51, Loss: 0.438\n",
      "Training: Epoch 3, Batch 52, Loss: 0.483\n",
      "Training: Epoch 3, Batch 53, Loss: 0.364\n",
      "Training: Epoch 3, Batch 54, Loss: 0.45\n",
      "Training: Epoch 3, Batch 55, Loss: 0.33\n",
      "Training: Epoch 3, Batch 56, Loss: 0.548\n",
      "Training: Epoch 3, Batch 57, Loss: 0.49\n",
      "Training: Epoch 3, Batch 58, Loss: 0.369\n",
      "Training: Epoch 3, Batch 59, Loss: 0.465\n",
      "Val: Epoch 3, Loss: 0.326\n",
      "Training: Epoch 4, Batch 0, Loss: 0.326\n",
      "Training: Epoch 4, Batch 1, Loss: 0.335\n",
      "Training: Epoch 4, Batch 2, Loss: 0.316\n",
      "Training: Epoch 4, Batch 3, Loss: 0.34\n",
      "Training: Epoch 4, Batch 4, Loss: 0.37\n",
      "Training: Epoch 4, Batch 5, Loss: 0.428\n",
      "Training: Epoch 4, Batch 6, Loss: 0.272\n",
      "Training: Epoch 4, Batch 7, Loss: 0.385\n",
      "Training: Epoch 4, Batch 8, Loss: 0.381\n",
      "Training: Epoch 4, Batch 9, Loss: 0.473\n",
      "Training: Epoch 4, Batch 10, Loss: 0.296\n",
      "Training: Epoch 4, Batch 11, Loss: 0.422\n",
      "Training: Epoch 4, Batch 12, Loss: 0.393\n",
      "Training: Epoch 4, Batch 13, Loss: 0.326\n",
      "Training: Epoch 4, Batch 14, Loss: 0.319\n",
      "Training: Epoch 4, Batch 15, Loss: 0.617\n",
      "Training: Epoch 4, Batch 16, Loss: 0.347\n",
      "Training: Epoch 4, Batch 17, Loss: 0.392\n",
      "Training: Epoch 4, Batch 18, Loss: 0.289\n",
      "Training: Epoch 4, Batch 19, Loss: 0.344\n",
      "Training: Epoch 4, Batch 20, Loss: 0.553\n",
      "Training: Epoch 4, Batch 21, Loss: 0.251\n",
      "Training: Epoch 4, Batch 22, Loss: 0.48\n",
      "Training: Epoch 4, Batch 23, Loss: 0.249\n",
      "Training: Epoch 4, Batch 24, Loss: 0.338\n",
      "Training: Epoch 4, Batch 25, Loss: 0.401\n",
      "Training: Epoch 4, Batch 26, Loss: 0.37\n",
      "Training: Epoch 4, Batch 27, Loss: 0.286\n",
      "Training: Epoch 4, Batch 28, Loss: 0.38\n",
      "Training: Epoch 4, Batch 29, Loss: 0.399\n",
      "Training: Epoch 4, Batch 30, Loss: 0.527\n",
      "Training: Epoch 4, Batch 31, Loss: 0.303\n",
      "Training: Epoch 4, Batch 32, Loss: 0.469\n",
      "Training: Epoch 4, Batch 33, Loss: 0.323\n",
      "Training: Epoch 4, Batch 34, Loss: 0.302\n",
      "Training: Epoch 4, Batch 35, Loss: 0.303\n",
      "Training: Epoch 4, Batch 36, Loss: 0.276\n",
      "Training: Epoch 4, Batch 37, Loss: 0.346\n",
      "Training: Epoch 4, Batch 38, Loss: 0.31\n",
      "Training: Epoch 4, Batch 39, Loss: 0.324\n",
      "Training: Epoch 4, Batch 40, Loss: 0.207\n",
      "Training: Epoch 4, Batch 41, Loss: 0.279\n",
      "Training: Epoch 4, Batch 42, Loss: 0.267\n",
      "Training: Epoch 4, Batch 43, Loss: 0.367\n",
      "Training: Epoch 4, Batch 44, Loss: 0.464\n",
      "Training: Epoch 4, Batch 45, Loss: 0.27\n",
      "Training: Epoch 4, Batch 46, Loss: 0.328\n",
      "Training: Epoch 4, Batch 47, Loss: 0.429\n",
      "Training: Epoch 4, Batch 48, Loss: 0.475\n",
      "Training: Epoch 4, Batch 49, Loss: 0.457\n",
      "Training: Epoch 4, Batch 50, Loss: 0.527\n",
      "Training: Epoch 4, Batch 51, Loss: 0.312\n",
      "Training: Epoch 4, Batch 52, Loss: 0.422\n",
      "Training: Epoch 4, Batch 53, Loss: 0.296\n",
      "Training: Epoch 4, Batch 54, Loss: 0.495\n",
      "Training: Epoch 4, Batch 55, Loss: 0.297\n",
      "Training: Epoch 4, Batch 56, Loss: 0.479\n",
      "Training: Epoch 4, Batch 57, Loss: 0.389\n",
      "Training: Epoch 4, Batch 58, Loss: 0.26\n",
      "Training: Epoch 4, Batch 59, Loss: 0.302\n",
      "Val: Epoch 4, Loss: 0.347\n",
      "Training: Epoch 5, Batch 0, Loss: 0.311\n",
      "Training: Epoch 5, Batch 1, Loss: 0.3\n",
      "Training: Epoch 5, Batch 2, Loss: 0.352\n",
      "Training: Epoch 5, Batch 3, Loss: 0.295\n",
      "Training: Epoch 5, Batch 4, Loss: 0.381\n",
      "Training: Epoch 5, Batch 5, Loss: 0.282\n",
      "Training: Epoch 5, Batch 6, Loss: 0.453\n",
      "Training: Epoch 5, Batch 7, Loss: 0.27\n",
      "Training: Epoch 5, Batch 8, Loss: 0.294\n",
      "Training: Epoch 5, Batch 9, Loss: 0.488\n",
      "Training: Epoch 5, Batch 10, Loss: 0.294\n",
      "Training: Epoch 5, Batch 11, Loss: 0.271\n",
      "Training: Epoch 5, Batch 12, Loss: 0.274\n",
      "Training: Epoch 5, Batch 13, Loss: 0.314\n",
      "Training: Epoch 5, Batch 14, Loss: 0.341\n",
      "Training: Epoch 5, Batch 15, Loss: 0.402\n",
      "Training: Epoch 5, Batch 16, Loss: 0.358\n",
      "Training: Epoch 5, Batch 17, Loss: 0.309\n",
      "Training: Epoch 5, Batch 18, Loss: 0.369\n",
      "Training: Epoch 5, Batch 19, Loss: 0.382\n",
      "Training: Epoch 5, Batch 20, Loss: 0.521\n",
      "Training: Epoch 5, Batch 21, Loss: 0.378\n",
      "Training: Epoch 5, Batch 22, Loss: 0.335\n",
      "Training: Epoch 5, Batch 23, Loss: 0.342\n",
      "Training: Epoch 5, Batch 24, Loss: 0.497\n",
      "Training: Epoch 5, Batch 25, Loss: 0.236\n",
      "Training: Epoch 5, Batch 26, Loss: 0.376\n",
      "Training: Epoch 5, Batch 27, Loss: 0.307\n",
      "Training: Epoch 5, Batch 28, Loss: 0.262\n",
      "Training: Epoch 5, Batch 29, Loss: 0.483\n",
      "Training: Epoch 5, Batch 30, Loss: 0.43\n",
      "Training: Epoch 5, Batch 31, Loss: 0.425\n",
      "Training: Epoch 5, Batch 32, Loss: 0.345\n",
      "Training: Epoch 5, Batch 33, Loss: 0.312\n",
      "Training: Epoch 5, Batch 34, Loss: 0.323\n",
      "Training: Epoch 5, Batch 35, Loss: 0.424\n",
      "Training: Epoch 5, Batch 36, Loss: 0.295\n",
      "Training: Epoch 5, Batch 37, Loss: 0.306\n",
      "Training: Epoch 5, Batch 38, Loss: 0.349\n",
      "Training: Epoch 5, Batch 39, Loss: 0.446\n",
      "Training: Epoch 5, Batch 40, Loss: 0.354\n",
      "Training: Epoch 5, Batch 41, Loss: 0.305\n",
      "Training: Epoch 5, Batch 42, Loss: 0.322\n",
      "Training: Epoch 5, Batch 43, Loss: 0.274\n",
      "Training: Epoch 5, Batch 44, Loss: 0.311\n",
      "Training: Epoch 5, Batch 45, Loss: 0.292\n",
      "Training: Epoch 5, Batch 46, Loss: 0.281\n",
      "Training: Epoch 5, Batch 47, Loss: 0.282\n",
      "Training: Epoch 5, Batch 48, Loss: 0.323\n",
      "Training: Epoch 5, Batch 49, Loss: 0.291\n",
      "Training: Epoch 5, Batch 50, Loss: 0.461\n",
      "Training: Epoch 5, Batch 51, Loss: 0.269\n",
      "Training: Epoch 5, Batch 52, Loss: 0.304\n",
      "Training: Epoch 5, Batch 53, Loss: 0.343\n",
      "Training: Epoch 5, Batch 54, Loss: 0.422\n",
      "Training: Epoch 5, Batch 55, Loss: 0.322\n",
      "Training: Epoch 5, Batch 56, Loss: 0.374\n",
      "Training: Epoch 5, Batch 57, Loss: 0.399\n",
      "Training: Epoch 5, Batch 58, Loss: 0.293\n",
      "Training: Epoch 5, Batch 59, Loss: 0.35\n",
      "Val: Epoch 5, Loss: 0.441\n",
      "Training: Epoch 6, Batch 0, Loss: 0.499\n",
      "Training: Epoch 6, Batch 1, Loss: 0.263\n",
      "Training: Epoch 6, Batch 2, Loss: 0.334\n",
      "Training: Epoch 6, Batch 3, Loss: 0.385\n",
      "Training: Epoch 6, Batch 4, Loss: 0.382\n",
      "Training: Epoch 6, Batch 5, Loss: 0.324\n",
      "Training: Epoch 6, Batch 6, Loss: 0.4\n",
      "Training: Epoch 6, Batch 7, Loss: 0.342\n",
      "Training: Epoch 6, Batch 8, Loss: 0.365\n",
      "Training: Epoch 6, Batch 9, Loss: 0.277\n",
      "Training: Epoch 6, Batch 10, Loss: 0.253\n",
      "Training: Epoch 6, Batch 11, Loss: 0.324\n",
      "Training: Epoch 6, Batch 12, Loss: 0.4\n",
      "Training: Epoch 6, Batch 13, Loss: 0.299\n",
      "Training: Epoch 6, Batch 14, Loss: 0.206\n",
      "Training: Epoch 6, Batch 15, Loss: 0.389\n",
      "Training: Epoch 6, Batch 16, Loss: 0.363\n",
      "Training: Epoch 6, Batch 17, Loss: 0.238\n",
      "Training: Epoch 6, Batch 18, Loss: 0.306\n",
      "Training: Epoch 6, Batch 19, Loss: 0.205\n",
      "Training: Epoch 6, Batch 20, Loss: 0.27\n",
      "Training: Epoch 6, Batch 21, Loss: 0.278\n",
      "Training: Epoch 6, Batch 22, Loss: 0.285\n",
      "Training: Epoch 6, Batch 23, Loss: 0.355\n",
      "Training: Epoch 6, Batch 24, Loss: 0.354\n",
      "Training: Epoch 6, Batch 25, Loss: 0.266\n",
      "Training: Epoch 6, Batch 26, Loss: 0.29\n",
      "Training: Epoch 6, Batch 27, Loss: 0.324\n",
      "Training: Epoch 6, Batch 28, Loss: 0.314\n",
      "Training: Epoch 6, Batch 29, Loss: 0.36\n",
      "Training: Epoch 6, Batch 30, Loss: 0.279\n",
      "Training: Epoch 6, Batch 31, Loss: 0.275\n",
      "Training: Epoch 6, Batch 32, Loss: 0.305\n",
      "Training: Epoch 6, Batch 33, Loss: 0.6\n",
      "Training: Epoch 6, Batch 34, Loss: 0.276\n",
      "Training: Epoch 6, Batch 35, Loss: 0.325\n",
      "Training: Epoch 6, Batch 36, Loss: 0.434\n",
      "Training: Epoch 6, Batch 37, Loss: 0.325\n",
      "Training: Epoch 6, Batch 38, Loss: 0.377\n",
      "Training: Epoch 6, Batch 39, Loss: 0.289\n",
      "Training: Epoch 6, Batch 40, Loss: 0.345\n",
      "Training: Epoch 6, Batch 41, Loss: 0.37\n",
      "Training: Epoch 6, Batch 42, Loss: 0.304\n",
      "Training: Epoch 6, Batch 43, Loss: 0.283\n",
      "Training: Epoch 6, Batch 44, Loss: 0.293\n",
      "Training: Epoch 6, Batch 45, Loss: 0.299\n",
      "Training: Epoch 6, Batch 46, Loss: 0.327\n",
      "Training: Epoch 6, Batch 47, Loss: 0.275\n",
      "Training: Epoch 6, Batch 48, Loss: 0.303\n",
      "Training: Epoch 6, Batch 49, Loss: 0.406\n",
      "Training: Epoch 6, Batch 50, Loss: 0.259\n",
      "Training: Epoch 6, Batch 51, Loss: 0.328\n",
      "Training: Epoch 6, Batch 52, Loss: 0.364\n",
      "Training: Epoch 6, Batch 53, Loss: 0.263\n",
      "Training: Epoch 6, Batch 54, Loss: 0.303\n",
      "Training: Epoch 6, Batch 55, Loss: 0.381\n",
      "Training: Epoch 6, Batch 56, Loss: 0.263\n",
      "Training: Epoch 6, Batch 57, Loss: 0.287\n",
      "Training: Epoch 6, Batch 58, Loss: 0.314\n",
      "Training: Epoch 6, Batch 59, Loss: 0.31\n",
      "Val: Epoch 6, Loss: 0.305\n",
      "Training: Epoch 7, Batch 0, Loss: 0.329\n",
      "Training: Epoch 7, Batch 1, Loss: 0.383\n",
      "Training: Epoch 7, Batch 2, Loss: 0.255\n",
      "Training: Epoch 7, Batch 3, Loss: 0.285\n",
      "Training: Epoch 7, Batch 4, Loss: 0.353\n",
      "Training: Epoch 7, Batch 5, Loss: 0.241\n",
      "Training: Epoch 7, Batch 6, Loss: 0.398\n",
      "Training: Epoch 7, Batch 7, Loss: 0.459\n",
      "Training: Epoch 7, Batch 8, Loss: 0.277\n",
      "Training: Epoch 7, Batch 9, Loss: 0.283\n",
      "Training: Epoch 7, Batch 10, Loss: 0.262\n",
      "Training: Epoch 7, Batch 11, Loss: 0.371\n",
      "Training: Epoch 7, Batch 12, Loss: 0.356\n",
      "Training: Epoch 7, Batch 13, Loss: 0.252\n",
      "Training: Epoch 7, Batch 14, Loss: 0.253\n",
      "Training: Epoch 7, Batch 15, Loss: 0.414\n",
      "Training: Epoch 7, Batch 16, Loss: 0.28\n",
      "Training: Epoch 7, Batch 17, Loss: 0.42\n",
      "Training: Epoch 7, Batch 18, Loss: 0.283\n",
      "Training: Epoch 7, Batch 19, Loss: 0.369\n",
      "Training: Epoch 7, Batch 20, Loss: 0.233\n",
      "Training: Epoch 7, Batch 21, Loss: 0.303\n",
      "Training: Epoch 7, Batch 22, Loss: 0.269\n",
      "Training: Epoch 7, Batch 23, Loss: 0.244\n",
      "Training: Epoch 7, Batch 24, Loss: 0.342\n",
      "Training: Epoch 7, Batch 25, Loss: 0.319\n",
      "Training: Epoch 7, Batch 26, Loss: 0.253\n",
      "Training: Epoch 7, Batch 27, Loss: 0.443\n",
      "Training: Epoch 7, Batch 28, Loss: 0.335\n",
      "Training: Epoch 7, Batch 29, Loss: 0.293\n",
      "Training: Epoch 7, Batch 30, Loss: 0.31\n",
      "Training: Epoch 7, Batch 31, Loss: 0.226\n",
      "Training: Epoch 7, Batch 32, Loss: 0.291\n",
      "Training: Epoch 7, Batch 33, Loss: 0.286\n",
      "Training: Epoch 7, Batch 34, Loss: 0.276\n",
      "Training: Epoch 7, Batch 35, Loss: 0.301\n",
      "Training: Epoch 7, Batch 36, Loss: 0.262\n",
      "Training: Epoch 7, Batch 37, Loss: 0.297\n",
      "Training: Epoch 7, Batch 38, Loss: 0.27\n",
      "Training: Epoch 7, Batch 39, Loss: 0.304\n",
      "Training: Epoch 7, Batch 40, Loss: 0.212\n",
      "Training: Epoch 7, Batch 41, Loss: 0.29\n",
      "Training: Epoch 7, Batch 42, Loss: 0.316\n",
      "Training: Epoch 7, Batch 43, Loss: 0.336\n",
      "Training: Epoch 7, Batch 44, Loss: 0.302\n",
      "Training: Epoch 7, Batch 45, Loss: 0.351\n",
      "Training: Epoch 7, Batch 46, Loss: 0.283\n",
      "Training: Epoch 7, Batch 47, Loss: 0.245\n",
      "Training: Epoch 7, Batch 48, Loss: 0.237\n",
      "Training: Epoch 7, Batch 49, Loss: 0.231\n",
      "Training: Epoch 7, Batch 50, Loss: 0.463\n",
      "Training: Epoch 7, Batch 51, Loss: 0.364\n",
      "Training: Epoch 7, Batch 52, Loss: 0.248\n",
      "Training: Epoch 7, Batch 53, Loss: 0.432\n",
      "Training: Epoch 7, Batch 54, Loss: 0.434\n",
      "Training: Epoch 7, Batch 55, Loss: 0.258\n",
      "Training: Epoch 7, Batch 56, Loss: 0.385\n",
      "Training: Epoch 7, Batch 57, Loss: 0.461\n",
      "Training: Epoch 7, Batch 58, Loss: 0.44\n",
      "Training: Epoch 7, Batch 59, Loss: 0.214\n",
      "Val: Epoch 7, Loss: 0.284\n",
      "Training: Epoch 8, Batch 0, Loss: 0.306\n",
      "Training: Epoch 8, Batch 1, Loss: 0.209\n",
      "Training: Epoch 8, Batch 2, Loss: 0.276\n",
      "Training: Epoch 8, Batch 3, Loss: 0.31\n",
      "Training: Epoch 8, Batch 4, Loss: 0.311\n",
      "Training: Epoch 8, Batch 5, Loss: 0.277\n",
      "Training: Epoch 8, Batch 6, Loss: 0.266\n",
      "Training: Epoch 8, Batch 7, Loss: 0.256\n",
      "Training: Epoch 8, Batch 8, Loss: 0.293\n",
      "Training: Epoch 8, Batch 9, Loss: 0.295\n",
      "Training: Epoch 8, Batch 10, Loss: 0.296\n",
      "Training: Epoch 8, Batch 11, Loss: 0.284\n",
      "Training: Epoch 8, Batch 12, Loss: 0.323\n",
      "Training: Epoch 8, Batch 13, Loss: 0.302\n",
      "Training: Epoch 8, Batch 14, Loss: 0.35\n",
      "Training: Epoch 8, Batch 15, Loss: 0.317\n",
      "Training: Epoch 8, Batch 16, Loss: 0.3\n",
      "Training: Epoch 8, Batch 17, Loss: 0.374\n",
      "Training: Epoch 8, Batch 18, Loss: 0.28\n",
      "Training: Epoch 8, Batch 19, Loss: 0.234\n",
      "Training: Epoch 8, Batch 20, Loss: 0.44\n",
      "Training: Epoch 8, Batch 21, Loss: 0.365\n",
      "Training: Epoch 8, Batch 22, Loss: 0.262\n",
      "Training: Epoch 8, Batch 23, Loss: 0.349\n",
      "Training: Epoch 8, Batch 24, Loss: 0.31\n",
      "Training: Epoch 8, Batch 25, Loss: 0.241\n",
      "Training: Epoch 8, Batch 26, Loss: 0.32\n",
      "Training: Epoch 8, Batch 27, Loss: 0.285\n",
      "Training: Epoch 8, Batch 28, Loss: 0.245\n",
      "Training: Epoch 8, Batch 29, Loss: 0.246\n",
      "Training: Epoch 8, Batch 30, Loss: 0.41\n",
      "Training: Epoch 8, Batch 31, Loss: 0.267\n",
      "Training: Epoch 8, Batch 32, Loss: 0.278\n",
      "Training: Epoch 8, Batch 33, Loss: 0.219\n",
      "Training: Epoch 8, Batch 34, Loss: 0.281\n",
      "Training: Epoch 8, Batch 35, Loss: 0.25\n",
      "Training: Epoch 8, Batch 36, Loss: 0.292\n",
      "Training: Epoch 8, Batch 37, Loss: 0.288\n",
      "Training: Epoch 8, Batch 38, Loss: 0.546\n",
      "Training: Epoch 8, Batch 39, Loss: 0.297\n",
      "Training: Epoch 8, Batch 40, Loss: 0.197\n",
      "Training: Epoch 8, Batch 41, Loss: 0.466\n",
      "Training: Epoch 8, Batch 42, Loss: 0.416\n",
      "Training: Epoch 8, Batch 43, Loss: 0.416\n",
      "Training: Epoch 8, Batch 44, Loss: 0.319\n",
      "Training: Epoch 8, Batch 45, Loss: 0.312\n",
      "Training: Epoch 8, Batch 46, Loss: 0.252\n",
      "Training: Epoch 8, Batch 47, Loss: 0.254\n",
      "Training: Epoch 8, Batch 48, Loss: 0.268\n",
      "Training: Epoch 8, Batch 49, Loss: 0.317\n",
      "Training: Epoch 8, Batch 50, Loss: 0.269\n",
      "Training: Epoch 8, Batch 51, Loss: 0.372\n",
      "Training: Epoch 8, Batch 52, Loss: 0.2\n",
      "Training: Epoch 8, Batch 53, Loss: 0.299\n",
      "Training: Epoch 8, Batch 54, Loss: 0.285\n",
      "Training: Epoch 8, Batch 55, Loss: 0.269\n",
      "Training: Epoch 8, Batch 56, Loss: 0.24\n",
      "Training: Epoch 8, Batch 57, Loss: 0.287\n",
      "Training: Epoch 8, Batch 58, Loss: 0.256\n",
      "Training: Epoch 8, Batch 59, Loss: 0.335\n",
      "Val: Epoch 8, Loss: 0.279\n",
      "Training: Epoch 9, Batch 0, Loss: 0.354\n",
      "Training: Epoch 9, Batch 1, Loss: 0.273\n",
      "Training: Epoch 9, Batch 2, Loss: 0.28\n",
      "Training: Epoch 9, Batch 3, Loss: 0.261\n",
      "Training: Epoch 9, Batch 4, Loss: 0.283\n",
      "Training: Epoch 9, Batch 5, Loss: 0.525\n",
      "Training: Epoch 9, Batch 6, Loss: 0.246\n",
      "Training: Epoch 9, Batch 7, Loss: 0.303\n",
      "Training: Epoch 9, Batch 8, Loss: 0.257\n",
      "Training: Epoch 9, Batch 9, Loss: 0.247\n",
      "Training: Epoch 9, Batch 10, Loss: 0.2\n",
      "Training: Epoch 9, Batch 11, Loss: 0.255\n",
      "Training: Epoch 9, Batch 12, Loss: 0.291\n",
      "Training: Epoch 9, Batch 13, Loss: 0.298\n",
      "Training: Epoch 9, Batch 14, Loss: 0.33\n",
      "Training: Epoch 9, Batch 15, Loss: 0.306\n",
      "Training: Epoch 9, Batch 16, Loss: 0.257\n",
      "Training: Epoch 9, Batch 17, Loss: 0.296\n",
      "Training: Epoch 9, Batch 18, Loss: 0.253\n",
      "Training: Epoch 9, Batch 19, Loss: 0.287\n",
      "Training: Epoch 9, Batch 20, Loss: 0.301\n",
      "Training: Epoch 9, Batch 21, Loss: 0.324\n",
      "Training: Epoch 9, Batch 22, Loss: 0.289\n",
      "Training: Epoch 9, Batch 23, Loss: 0.22\n",
      "Training: Epoch 9, Batch 24, Loss: 0.303\n",
      "Training: Epoch 9, Batch 25, Loss: 0.297\n",
      "Training: Epoch 9, Batch 26, Loss: 0.304\n",
      "Training: Epoch 9, Batch 27, Loss: 0.282\n",
      "Training: Epoch 9, Batch 28, Loss: 0.365\n",
      "Training: Epoch 9, Batch 29, Loss: 0.245\n",
      "Training: Epoch 9, Batch 30, Loss: 0.334\n",
      "Training: Epoch 9, Batch 31, Loss: 0.213\n",
      "Training: Epoch 9, Batch 32, Loss: 0.3\n",
      "Training: Epoch 9, Batch 33, Loss: 0.285\n",
      "Training: Epoch 9, Batch 34, Loss: 0.323\n",
      "Training: Epoch 9, Batch 35, Loss: 0.268\n",
      "Training: Epoch 9, Batch 36, Loss: 0.255\n",
      "Training: Epoch 9, Batch 37, Loss: 0.242\n",
      "Training: Epoch 9, Batch 38, Loss: 0.217\n",
      "Training: Epoch 9, Batch 39, Loss: 0.234\n",
      "Training: Epoch 9, Batch 40, Loss: 0.296\n",
      "Training: Epoch 9, Batch 41, Loss: 0.373\n",
      "Training: Epoch 9, Batch 42, Loss: 0.277\n",
      "Training: Epoch 9, Batch 43, Loss: 0.361\n",
      "Training: Epoch 9, Batch 44, Loss: 0.247\n",
      "Training: Epoch 9, Batch 45, Loss: 0.25\n",
      "Training: Epoch 9, Batch 46, Loss: 0.328\n",
      "Training: Epoch 9, Batch 47, Loss: 0.261\n",
      "Training: Epoch 9, Batch 48, Loss: 0.212\n",
      "Training: Epoch 9, Batch 49, Loss: 0.42\n",
      "Training: Epoch 9, Batch 50, Loss: 0.351\n",
      "Training: Epoch 9, Batch 51, Loss: 0.341\n",
      "Training: Epoch 9, Batch 52, Loss: 0.318\n",
      "Training: Epoch 9, Batch 53, Loss: 0.273\n",
      "Training: Epoch 9, Batch 54, Loss: 0.301\n",
      "Training: Epoch 9, Batch 55, Loss: 0.343\n",
      "Training: Epoch 9, Batch 56, Loss: 0.283\n",
      "Training: Epoch 9, Batch 57, Loss: 0.233\n",
      "Training: Epoch 9, Batch 58, Loss: 0.297\n",
      "Training: Epoch 9, Batch 59, Loss: 0.339\n",
      "Val: Epoch 9, Loss: 0.305\n",
      "Training: Epoch 10, Batch 0, Loss: 0.21\n",
      "Training: Epoch 10, Batch 1, Loss: 0.289\n",
      "Training: Epoch 10, Batch 2, Loss: 0.261\n",
      "Training: Epoch 10, Batch 3, Loss: 0.386\n",
      "Training: Epoch 10, Batch 4, Loss: 0.235\n",
      "Training: Epoch 10, Batch 5, Loss: 0.315\n",
      "Training: Epoch 10, Batch 6, Loss: 0.327\n",
      "Training: Epoch 10, Batch 7, Loss: 0.27\n",
      "Training: Epoch 10, Batch 8, Loss: 0.388\n",
      "Training: Epoch 10, Batch 9, Loss: 0.324\n",
      "Training: Epoch 10, Batch 10, Loss: 0.278\n",
      "Training: Epoch 10, Batch 11, Loss: 0.354\n",
      "Training: Epoch 10, Batch 12, Loss: 0.416\n",
      "Training: Epoch 10, Batch 13, Loss: 0.206\n",
      "Training: Epoch 10, Batch 14, Loss: 0.281\n",
      "Training: Epoch 10, Batch 15, Loss: 0.285\n",
      "Training: Epoch 10, Batch 16, Loss: 0.263\n",
      "Training: Epoch 10, Batch 17, Loss: 0.36\n",
      "Training: Epoch 10, Batch 18, Loss: 0.356\n",
      "Training: Epoch 10, Batch 19, Loss: 0.285\n",
      "Training: Epoch 10, Batch 20, Loss: 0.302\n",
      "Training: Epoch 10, Batch 21, Loss: 0.247\n",
      "Training: Epoch 10, Batch 22, Loss: 0.292\n",
      "Training: Epoch 10, Batch 23, Loss: 0.259\n",
      "Training: Epoch 10, Batch 24, Loss: 0.435\n",
      "Training: Epoch 10, Batch 25, Loss: 0.44\n",
      "Training: Epoch 10, Batch 26, Loss: 0.271\n",
      "Training: Epoch 10, Batch 27, Loss: 0.269\n",
      "Training: Epoch 10, Batch 28, Loss: 0.292\n",
      "Training: Epoch 10, Batch 29, Loss: 0.355\n",
      "Training: Epoch 10, Batch 30, Loss: 0.32\n",
      "Training: Epoch 10, Batch 31, Loss: 0.292\n",
      "Training: Epoch 10, Batch 32, Loss: 0.278\n",
      "Training: Epoch 10, Batch 33, Loss: 0.307\n",
      "Training: Epoch 10, Batch 34, Loss: 0.275\n",
      "Training: Epoch 10, Batch 35, Loss: 0.244\n",
      "Training: Epoch 10, Batch 36, Loss: 0.593\n",
      "Training: Epoch 10, Batch 37, Loss: 0.522\n",
      "Training: Epoch 10, Batch 38, Loss: 0.228\n",
      "Training: Epoch 10, Batch 39, Loss: 0.334\n",
      "Training: Epoch 10, Batch 40, Loss: 0.291\n",
      "Training: Epoch 10, Batch 41, Loss: 0.325\n",
      "Training: Epoch 10, Batch 42, Loss: 0.203\n",
      "Training: Epoch 10, Batch 43, Loss: 0.374\n",
      "Training: Epoch 10, Batch 44, Loss: 0.349\n",
      "Training: Epoch 10, Batch 45, Loss: 0.239\n",
      "Training: Epoch 10, Batch 46, Loss: 0.202\n",
      "Training: Epoch 10, Batch 47, Loss: 0.205\n",
      "Training: Epoch 10, Batch 48, Loss: 0.369\n",
      "Training: Epoch 10, Batch 49, Loss: 0.285\n",
      "Training: Epoch 10, Batch 50, Loss: 0.384\n",
      "Training: Epoch 10, Batch 51, Loss: 0.218\n",
      "Training: Epoch 10, Batch 52, Loss: 0.331\n",
      "Training: Epoch 10, Batch 53, Loss: 0.226\n",
      "Training: Epoch 10, Batch 54, Loss: 0.237\n",
      "Training: Epoch 10, Batch 55, Loss: 0.29\n",
      "Training: Epoch 10, Batch 56, Loss: 0.349\n",
      "Training: Epoch 10, Batch 57, Loss: 0.232\n",
      "Training: Epoch 10, Batch 58, Loss: 0.237\n",
      "Training: Epoch 10, Batch 59, Loss: 0.302\n",
      "Val: Epoch 10, Loss: 0.273\n",
      "Training: Epoch 11, Batch 0, Loss: 0.286\n",
      "Training: Epoch 11, Batch 1, Loss: 0.292\n",
      "Training: Epoch 11, Batch 2, Loss: 0.228\n",
      "Training: Epoch 11, Batch 3, Loss: 0.343\n",
      "Training: Epoch 11, Batch 4, Loss: 0.263\n",
      "Training: Epoch 11, Batch 5, Loss: 0.349\n",
      "Training: Epoch 11, Batch 6, Loss: 0.281\n",
      "Training: Epoch 11, Batch 7, Loss: 0.268\n",
      "Training: Epoch 11, Batch 8, Loss: 0.286\n",
      "Training: Epoch 11, Batch 9, Loss: 0.21\n",
      "Training: Epoch 11, Batch 10, Loss: 0.357\n",
      "Training: Epoch 11, Batch 11, Loss: 0.299\n",
      "Training: Epoch 11, Batch 12, Loss: 0.247\n",
      "Training: Epoch 11, Batch 13, Loss: 0.201\n",
      "Training: Epoch 11, Batch 14, Loss: 0.247\n",
      "Training: Epoch 11, Batch 15, Loss: 0.185\n",
      "Training: Epoch 11, Batch 16, Loss: 0.272\n",
      "Training: Epoch 11, Batch 17, Loss: 0.312\n",
      "Training: Epoch 11, Batch 18, Loss: 0.306\n",
      "Training: Epoch 11, Batch 19, Loss: 0.252\n",
      "Training: Epoch 11, Batch 20, Loss: 0.279\n",
      "Training: Epoch 11, Batch 21, Loss: 0.251\n",
      "Training: Epoch 11, Batch 22, Loss: 0.224\n",
      "Training: Epoch 11, Batch 23, Loss: 0.231\n",
      "Training: Epoch 11, Batch 24, Loss: 0.269\n",
      "Training: Epoch 11, Batch 25, Loss: 0.268\n",
      "Training: Epoch 11, Batch 26, Loss: 0.229\n",
      "Training: Epoch 11, Batch 27, Loss: 0.244\n",
      "Training: Epoch 11, Batch 28, Loss: 0.295\n",
      "Training: Epoch 11, Batch 29, Loss: 0.208\n",
      "Training: Epoch 11, Batch 30, Loss: 0.279\n",
      "Training: Epoch 11, Batch 31, Loss: 0.289\n",
      "Training: Epoch 11, Batch 32, Loss: 0.247\n",
      "Training: Epoch 11, Batch 33, Loss: 0.284\n",
      "Training: Epoch 11, Batch 34, Loss: 0.267\n",
      "Training: Epoch 11, Batch 35, Loss: 0.25\n",
      "Training: Epoch 11, Batch 36, Loss: 0.29\n",
      "Training: Epoch 11, Batch 37, Loss: 0.216\n",
      "Training: Epoch 11, Batch 38, Loss: 0.303\n",
      "Training: Epoch 11, Batch 39, Loss: 0.287\n",
      "Training: Epoch 11, Batch 40, Loss: 0.291\n",
      "Training: Epoch 11, Batch 41, Loss: 0.283\n",
      "Training: Epoch 11, Batch 42, Loss: 0.239\n",
      "Training: Epoch 11, Batch 43, Loss: 0.276\n",
      "Training: Epoch 11, Batch 44, Loss: 0.283\n",
      "Training: Epoch 11, Batch 45, Loss: 0.323\n",
      "Training: Epoch 11, Batch 46, Loss: 0.261\n",
      "Training: Epoch 11, Batch 47, Loss: 0.434\n",
      "Training: Epoch 11, Batch 48, Loss: 0.272\n",
      "Training: Epoch 11, Batch 49, Loss: 0.397\n",
      "Training: Epoch 11, Batch 50, Loss: 0.322\n",
      "Training: Epoch 11, Batch 51, Loss: 0.313\n",
      "Training: Epoch 11, Batch 52, Loss: 0.352\n",
      "Training: Epoch 11, Batch 53, Loss: 0.207\n",
      "Training: Epoch 11, Batch 54, Loss: 0.434\n",
      "Training: Epoch 11, Batch 55, Loss: 0.2\n",
      "Training: Epoch 11, Batch 56, Loss: 0.222\n",
      "Training: Epoch 11, Batch 57, Loss: 0.3\n",
      "Training: Epoch 11, Batch 58, Loss: 0.32\n",
      "Training: Epoch 11, Batch 59, Loss: 0.221\n",
      "Val: Epoch 11, Loss: 0.333\n",
      "Training: Epoch 12, Batch 0, Loss: 0.35\n",
      "Training: Epoch 12, Batch 1, Loss: 0.205\n",
      "Training: Epoch 12, Batch 2, Loss: 0.234\n",
      "Training: Epoch 12, Batch 3, Loss: 0.157\n",
      "Training: Epoch 12, Batch 4, Loss: 0.262\n",
      "Training: Epoch 12, Batch 5, Loss: 0.293\n",
      "Training: Epoch 12, Batch 6, Loss: 0.399\n",
      "Training: Epoch 12, Batch 7, Loss: 0.267\n",
      "Training: Epoch 12, Batch 8, Loss: 0.277\n",
      "Training: Epoch 12, Batch 9, Loss: 0.319\n",
      "Training: Epoch 12, Batch 10, Loss: 0.252\n",
      "Training: Epoch 12, Batch 11, Loss: 0.218\n",
      "Training: Epoch 12, Batch 12, Loss: 0.221\n",
      "Training: Epoch 12, Batch 13, Loss: 0.276\n",
      "Training: Epoch 12, Batch 14, Loss: 0.347\n",
      "Training: Epoch 12, Batch 15, Loss: 0.377\n",
      "Training: Epoch 12, Batch 16, Loss: 0.323\n",
      "Training: Epoch 12, Batch 17, Loss: 0.207\n",
      "Training: Epoch 12, Batch 18, Loss: 0.26\n",
      "Training: Epoch 12, Batch 19, Loss: 0.219\n",
      "Training: Epoch 12, Batch 20, Loss: 0.29\n",
      "Training: Epoch 12, Batch 21, Loss: 0.302\n",
      "Training: Epoch 12, Batch 22, Loss: 0.227\n",
      "Training: Epoch 12, Batch 23, Loss: 0.296\n",
      "Training: Epoch 12, Batch 24, Loss: 0.3\n",
      "Training: Epoch 12, Batch 25, Loss: 0.319\n",
      "Training: Epoch 12, Batch 26, Loss: 0.264\n",
      "Training: Epoch 12, Batch 27, Loss: 0.247\n",
      "Training: Epoch 12, Batch 28, Loss: 0.285\n",
      "Training: Epoch 12, Batch 29, Loss: 0.238\n",
      "Training: Epoch 12, Batch 30, Loss: 0.275\n",
      "Training: Epoch 12, Batch 31, Loss: 0.206\n",
      "Training: Epoch 12, Batch 32, Loss: 0.27\n",
      "Training: Epoch 12, Batch 33, Loss: 0.261\n",
      "Training: Epoch 12, Batch 34, Loss: 0.221\n",
      "Training: Epoch 12, Batch 35, Loss: 0.276\n",
      "Training: Epoch 12, Batch 36, Loss: 0.232\n",
      "Training: Epoch 12, Batch 37, Loss: 0.228\n",
      "Training: Epoch 12, Batch 38, Loss: 0.195\n",
      "Training: Epoch 12, Batch 39, Loss: 0.309\n",
      "Training: Epoch 12, Batch 40, Loss: 0.211\n",
      "Training: Epoch 12, Batch 41, Loss: 0.336\n",
      "Training: Epoch 12, Batch 42, Loss: 0.214\n",
      "Training: Epoch 12, Batch 43, Loss: 0.204\n",
      "Training: Epoch 12, Batch 44, Loss: 0.328\n",
      "Training: Epoch 12, Batch 45, Loss: 0.29\n",
      "Training: Epoch 12, Batch 46, Loss: 0.231\n",
      "Training: Epoch 12, Batch 47, Loss: 0.242\n",
      "Training: Epoch 12, Batch 48, Loss: 0.223\n",
      "Training: Epoch 12, Batch 49, Loss: 0.332\n",
      "Training: Epoch 12, Batch 50, Loss: 0.232\n",
      "Training: Epoch 12, Batch 51, Loss: 0.231\n",
      "Training: Epoch 12, Batch 52, Loss: 0.348\n",
      "Training: Epoch 12, Batch 53, Loss: 0.308\n",
      "Training: Epoch 12, Batch 54, Loss: 0.21\n",
      "Training: Epoch 12, Batch 55, Loss: 0.246\n",
      "Training: Epoch 12, Batch 56, Loss: 0.23\n",
      "Training: Epoch 12, Batch 57, Loss: 0.24\n",
      "Training: Epoch 12, Batch 58, Loss: 0.347\n",
      "Training: Epoch 12, Batch 59, Loss: 0.323\n",
      "Val: Epoch 12, Loss: 0.244\n",
      "Training: Epoch 13, Batch 0, Loss: 0.259\n",
      "Training: Epoch 13, Batch 1, Loss: 0.259\n",
      "Training: Epoch 13, Batch 2, Loss: 0.258\n",
      "Training: Epoch 13, Batch 3, Loss: 0.36\n",
      "Training: Epoch 13, Batch 4, Loss: 0.238\n",
      "Training: Epoch 13, Batch 5, Loss: 0.21\n",
      "Training: Epoch 13, Batch 6, Loss: 0.238\n",
      "Training: Epoch 13, Batch 7, Loss: 0.22\n",
      "Training: Epoch 13, Batch 8, Loss: 0.233\n",
      "Training: Epoch 13, Batch 9, Loss: 0.186\n",
      "Training: Epoch 13, Batch 10, Loss: 0.231\n",
      "Training: Epoch 13, Batch 11, Loss: 0.223\n",
      "Training: Epoch 13, Batch 12, Loss: 0.292\n",
      "Training: Epoch 13, Batch 13, Loss: 0.314\n",
      "Training: Epoch 13, Batch 14, Loss: 0.195\n",
      "Training: Epoch 13, Batch 15, Loss: 0.176\n",
      "Training: Epoch 13, Batch 16, Loss: 0.247\n",
      "Training: Epoch 13, Batch 17, Loss: 0.176\n",
      "Training: Epoch 13, Batch 18, Loss: 0.306\n",
      "Training: Epoch 13, Batch 19, Loss: 0.325\n",
      "Training: Epoch 13, Batch 20, Loss: 0.284\n",
      "Training: Epoch 13, Batch 21, Loss: 0.424\n",
      "Training: Epoch 13, Batch 22, Loss: 0.203\n",
      "Training: Epoch 13, Batch 23, Loss: 0.272\n",
      "Training: Epoch 13, Batch 24, Loss: 0.219\n",
      "Training: Epoch 13, Batch 25, Loss: 0.277\n",
      "Training: Epoch 13, Batch 26, Loss: 0.252\n",
      "Training: Epoch 13, Batch 27, Loss: 0.234\n",
      "Training: Epoch 13, Batch 28, Loss: 0.219\n",
      "Training: Epoch 13, Batch 29, Loss: 0.259\n",
      "Training: Epoch 13, Batch 30, Loss: 0.396\n",
      "Training: Epoch 13, Batch 31, Loss: 0.256\n",
      "Training: Epoch 13, Batch 32, Loss: 0.226\n",
      "Training: Epoch 13, Batch 33, Loss: 0.377\n",
      "Training: Epoch 13, Batch 34, Loss: 0.315\n",
      "Training: Epoch 13, Batch 35, Loss: 0.33\n",
      "Training: Epoch 13, Batch 36, Loss: 0.363\n",
      "Training: Epoch 13, Batch 37, Loss: 0.269\n",
      "Training: Epoch 13, Batch 38, Loss: 0.242\n",
      "Training: Epoch 13, Batch 39, Loss: 0.219\n",
      "Training: Epoch 13, Batch 40, Loss: 0.242\n",
      "Training: Epoch 13, Batch 41, Loss: 0.245\n",
      "Training: Epoch 13, Batch 42, Loss: 0.42\n",
      "Training: Epoch 13, Batch 43, Loss: 0.183\n",
      "Training: Epoch 13, Batch 44, Loss: 0.248\n",
      "Training: Epoch 13, Batch 45, Loss: 0.242\n",
      "Training: Epoch 13, Batch 46, Loss: 0.217\n",
      "Training: Epoch 13, Batch 47, Loss: 0.361\n",
      "Training: Epoch 13, Batch 48, Loss: 0.223\n",
      "Training: Epoch 13, Batch 49, Loss: 0.247\n",
      "Training: Epoch 13, Batch 50, Loss: 0.207\n",
      "Training: Epoch 13, Batch 51, Loss: 0.37\n",
      "Training: Epoch 13, Batch 52, Loss: 0.246\n",
      "Training: Epoch 13, Batch 53, Loss: 0.381\n",
      "Training: Epoch 13, Batch 54, Loss: 0.282\n",
      "Training: Epoch 13, Batch 55, Loss: 0.292\n",
      "Training: Epoch 13, Batch 56, Loss: 0.315\n",
      "Training: Epoch 13, Batch 57, Loss: 0.297\n",
      "Training: Epoch 13, Batch 58, Loss: 0.242\n",
      "Training: Epoch 13, Batch 59, Loss: 0.274\n",
      "Val: Epoch 13, Loss: 0.296\n",
      "Training: Epoch 14, Batch 0, Loss: 0.279\n",
      "Training: Epoch 14, Batch 1, Loss: 0.318\n",
      "Training: Epoch 14, Batch 2, Loss: 0.324\n",
      "Training: Epoch 14, Batch 3, Loss: 0.405\n",
      "Training: Epoch 14, Batch 4, Loss: 0.326\n",
      "Training: Epoch 14, Batch 5, Loss: 0.176\n",
      "Training: Epoch 14, Batch 6, Loss: 0.275\n",
      "Training: Epoch 14, Batch 7, Loss: 0.308\n",
      "Training: Epoch 14, Batch 8, Loss: 0.234\n",
      "Training: Epoch 14, Batch 9, Loss: 0.229\n",
      "Training: Epoch 14, Batch 10, Loss: 0.291\n",
      "Training: Epoch 14, Batch 11, Loss: 0.267\n",
      "Training: Epoch 14, Batch 12, Loss: 0.333\n",
      "Training: Epoch 14, Batch 13, Loss: 0.25\n",
      "Training: Epoch 14, Batch 14, Loss: 0.258\n",
      "Training: Epoch 14, Batch 15, Loss: 0.324\n",
      "Training: Epoch 14, Batch 16, Loss: 0.316\n",
      "Training: Epoch 14, Batch 17, Loss: 0.236\n",
      "Training: Epoch 14, Batch 18, Loss: 0.26\n",
      "Training: Epoch 14, Batch 19, Loss: 0.508\n",
      "Training: Epoch 14, Batch 20, Loss: 0.275\n",
      "Training: Epoch 14, Batch 21, Loss: 0.219\n",
      "Training: Epoch 14, Batch 22, Loss: 0.259\n",
      "Training: Epoch 14, Batch 23, Loss: 0.289\n",
      "Training: Epoch 14, Batch 24, Loss: 0.254\n",
      "Training: Epoch 14, Batch 25, Loss: 0.233\n",
      "Training: Epoch 14, Batch 26, Loss: 0.26\n",
      "Training: Epoch 14, Batch 27, Loss: 0.27\n",
      "Training: Epoch 14, Batch 28, Loss: 0.235\n",
      "Training: Epoch 14, Batch 29, Loss: 0.234\n",
      "Training: Epoch 14, Batch 30, Loss: 0.251\n",
      "Training: Epoch 14, Batch 31, Loss: 0.21\n",
      "Training: Epoch 14, Batch 32, Loss: 0.208\n",
      "Training: Epoch 14, Batch 33, Loss: 0.269\n",
      "Training: Epoch 14, Batch 34, Loss: 0.224\n",
      "Training: Epoch 14, Batch 35, Loss: 0.277\n",
      "Training: Epoch 14, Batch 36, Loss: 0.231\n",
      "Training: Epoch 14, Batch 37, Loss: 0.217\n",
      "Training: Epoch 14, Batch 38, Loss: 0.334\n",
      "Training: Epoch 14, Batch 39, Loss: 0.245\n",
      "Training: Epoch 14, Batch 40, Loss: 0.209\n",
      "Training: Epoch 14, Batch 41, Loss: 0.255\n",
      "Training: Epoch 14, Batch 42, Loss: 0.277\n",
      "Training: Epoch 14, Batch 43, Loss: 0.335\n",
      "Training: Epoch 14, Batch 44, Loss: 0.215\n",
      "Training: Epoch 14, Batch 45, Loss: 0.254\n",
      "Training: Epoch 14, Batch 46, Loss: 0.221\n",
      "Training: Epoch 14, Batch 47, Loss: 0.175\n",
      "Training: Epoch 14, Batch 48, Loss: 0.242\n",
      "Training: Epoch 14, Batch 49, Loss: 0.282\n",
      "Training: Epoch 14, Batch 50, Loss: 0.214\n",
      "Training: Epoch 14, Batch 51, Loss: 0.235\n",
      "Training: Epoch 14, Batch 52, Loss: 0.234\n",
      "Training: Epoch 14, Batch 53, Loss: 0.236\n",
      "Training: Epoch 14, Batch 54, Loss: 0.348\n",
      "Training: Epoch 14, Batch 55, Loss: 0.265\n",
      "Training: Epoch 14, Batch 56, Loss: 0.295\n",
      "Training: Epoch 14, Batch 57, Loss: 0.211\n",
      "Training: Epoch 14, Batch 58, Loss: 0.26\n",
      "Training: Epoch 14, Batch 59, Loss: 0.271\n",
      "Val: Epoch 14, Loss: 0.314\n",
      "Training: Epoch 15, Batch 0, Loss: 0.175\n",
      "Training: Epoch 15, Batch 1, Loss: 0.189\n",
      "Training: Epoch 15, Batch 2, Loss: 0.291\n",
      "Training: Epoch 15, Batch 3, Loss: 0.294\n",
      "Training: Epoch 15, Batch 4, Loss: 0.21\n",
      "Training: Epoch 15, Batch 5, Loss: 0.227\n",
      "Training: Epoch 15, Batch 6, Loss: 0.24\n",
      "Training: Epoch 15, Batch 7, Loss: 0.388\n",
      "Training: Epoch 15, Batch 8, Loss: 0.274\n",
      "Training: Epoch 15, Batch 9, Loss: 0.245\n",
      "Training: Epoch 15, Batch 10, Loss: 0.244\n",
      "Training: Epoch 15, Batch 11, Loss: 0.201\n",
      "Training: Epoch 15, Batch 12, Loss: 0.302\n",
      "Training: Epoch 15, Batch 13, Loss: 0.26\n",
      "Training: Epoch 15, Batch 14, Loss: 0.382\n",
      "Training: Epoch 15, Batch 15, Loss: 0.199\n",
      "Training: Epoch 15, Batch 16, Loss: 0.324\n",
      "Training: Epoch 15, Batch 17, Loss: 0.334\n",
      "Training: Epoch 15, Batch 18, Loss: 0.317\n",
      "Training: Epoch 15, Batch 19, Loss: 0.275\n",
      "Training: Epoch 15, Batch 20, Loss: 0.28\n",
      "Training: Epoch 15, Batch 21, Loss: 0.288\n",
      "Training: Epoch 15, Batch 22, Loss: 0.242\n",
      "Training: Epoch 15, Batch 23, Loss: 0.275\n",
      "Training: Epoch 15, Batch 24, Loss: 0.223\n",
      "Training: Epoch 15, Batch 25, Loss: 0.182\n",
      "Training: Epoch 15, Batch 26, Loss: 0.367\n",
      "Training: Epoch 15, Batch 27, Loss: 0.287\n",
      "Training: Epoch 15, Batch 28, Loss: 0.224\n",
      "Training: Epoch 15, Batch 29, Loss: 0.212\n",
      "Training: Epoch 15, Batch 30, Loss: 0.24\n",
      "Training: Epoch 15, Batch 31, Loss: 0.24\n",
      "Training: Epoch 15, Batch 32, Loss: 0.216\n",
      "Training: Epoch 15, Batch 33, Loss: 0.301\n",
      "Training: Epoch 15, Batch 34, Loss: 0.257\n",
      "Training: Epoch 15, Batch 35, Loss: 0.209\n",
      "Training: Epoch 15, Batch 36, Loss: 0.221\n",
      "Training: Epoch 15, Batch 37, Loss: 0.258\n",
      "Training: Epoch 15, Batch 38, Loss: 0.237\n",
      "Training: Epoch 15, Batch 39, Loss: 0.284\n",
      "Training: Epoch 15, Batch 40, Loss: 0.299\n",
      "Training: Epoch 15, Batch 41, Loss: 0.307\n",
      "Training: Epoch 15, Batch 42, Loss: 0.318\n",
      "Training: Epoch 15, Batch 43, Loss: 0.235\n",
      "Training: Epoch 15, Batch 44, Loss: 0.246\n",
      "Training: Epoch 15, Batch 45, Loss: 0.282\n",
      "Training: Epoch 15, Batch 46, Loss: 0.248\n",
      "Training: Epoch 15, Batch 47, Loss: 0.379\n",
      "Training: Epoch 15, Batch 48, Loss: 0.261\n",
      "Training: Epoch 15, Batch 49, Loss: 0.213\n",
      "Training: Epoch 15, Batch 50, Loss: 0.222\n",
      "Training: Epoch 15, Batch 51, Loss: 0.214\n",
      "Training: Epoch 15, Batch 52, Loss: 0.239\n",
      "Training: Epoch 15, Batch 53, Loss: 0.207\n",
      "Training: Epoch 15, Batch 54, Loss: 0.253\n",
      "Training: Epoch 15, Batch 55, Loss: 0.271\n",
      "Training: Epoch 15, Batch 56, Loss: 0.237\n",
      "Training: Epoch 15, Batch 57, Loss: 0.189\n",
      "Training: Epoch 15, Batch 58, Loss: 0.214\n",
      "Training: Epoch 15, Batch 59, Loss: 0.22\n",
      "Val: Epoch 15, Loss: 0.276\n",
      "Training: Epoch 16, Batch 0, Loss: 0.259\n",
      "Training: Epoch 16, Batch 1, Loss: 0.161\n",
      "Training: Epoch 16, Batch 2, Loss: 0.243\n",
      "Training: Epoch 16, Batch 3, Loss: 0.257\n",
      "Training: Epoch 16, Batch 4, Loss: 0.257\n",
      "Training: Epoch 16, Batch 5, Loss: 0.256\n",
      "Training: Epoch 16, Batch 6, Loss: 0.206\n",
      "Training: Epoch 16, Batch 7, Loss: 0.205\n",
      "Training: Epoch 16, Batch 8, Loss: 0.24\n",
      "Training: Epoch 16, Batch 9, Loss: 0.192\n",
      "Training: Epoch 16, Batch 10, Loss: 0.222\n",
      "Training: Epoch 16, Batch 11, Loss: 0.287\n",
      "Training: Epoch 16, Batch 12, Loss: 0.243\n",
      "Training: Epoch 16, Batch 13, Loss: 0.223\n",
      "Training: Epoch 16, Batch 14, Loss: 0.291\n",
      "Training: Epoch 16, Batch 15, Loss: 0.297\n",
      "Training: Epoch 16, Batch 16, Loss: 0.333\n",
      "Training: Epoch 16, Batch 17, Loss: 0.243\n",
      "Training: Epoch 16, Batch 18, Loss: 0.215\n",
      "Training: Epoch 16, Batch 19, Loss: 0.204\n",
      "Training: Epoch 16, Batch 20, Loss: 0.23\n",
      "Training: Epoch 16, Batch 21, Loss: 0.531\n",
      "Training: Epoch 16, Batch 22, Loss: 0.362\n",
      "Training: Epoch 16, Batch 23, Loss: 0.256\n",
      "Training: Epoch 16, Batch 24, Loss: 0.266\n",
      "Training: Epoch 16, Batch 25, Loss: 0.27\n",
      "Training: Epoch 16, Batch 26, Loss: 0.241\n",
      "Training: Epoch 16, Batch 27, Loss: 0.296\n",
      "Training: Epoch 16, Batch 28, Loss: 0.293\n",
      "Training: Epoch 16, Batch 29, Loss: 0.177\n",
      "Training: Epoch 16, Batch 30, Loss: 0.332\n",
      "Training: Epoch 16, Batch 31, Loss: 0.299\n",
      "Training: Epoch 16, Batch 32, Loss: 0.188\n",
      "Training: Epoch 16, Batch 33, Loss: 0.336\n",
      "Training: Epoch 16, Batch 34, Loss: 0.255\n",
      "Training: Epoch 16, Batch 35, Loss: 0.215\n",
      "Training: Epoch 16, Batch 36, Loss: 0.177\n",
      "Training: Epoch 16, Batch 37, Loss: 0.37\n",
      "Training: Epoch 16, Batch 38, Loss: 0.275\n",
      "Training: Epoch 16, Batch 39, Loss: 0.237\n",
      "Training: Epoch 16, Batch 40, Loss: 0.208\n",
      "Training: Epoch 16, Batch 41, Loss: 0.184\n",
      "Training: Epoch 16, Batch 42, Loss: 0.233\n",
      "Training: Epoch 16, Batch 43, Loss: 0.233\n",
      "Training: Epoch 16, Batch 44, Loss: 0.26\n",
      "Training: Epoch 16, Batch 45, Loss: 0.22\n",
      "Training: Epoch 16, Batch 46, Loss: 0.247\n",
      "Training: Epoch 16, Batch 47, Loss: 0.234\n",
      "Training: Epoch 16, Batch 48, Loss: 0.201\n",
      "Training: Epoch 16, Batch 49, Loss: 0.233\n",
      "Training: Epoch 16, Batch 50, Loss: 0.186\n",
      "Training: Epoch 16, Batch 51, Loss: 0.243\n",
      "Training: Epoch 16, Batch 52, Loss: 0.238\n",
      "Training: Epoch 16, Batch 53, Loss: 0.267\n",
      "Training: Epoch 16, Batch 54, Loss: 0.254\n",
      "Training: Epoch 16, Batch 55, Loss: 0.203\n",
      "Training: Epoch 16, Batch 56, Loss: 0.273\n",
      "Training: Epoch 16, Batch 57, Loss: 0.266\n",
      "Training: Epoch 16, Batch 58, Loss: 0.182\n",
      "Training: Epoch 16, Batch 59, Loss: 0.188\n",
      "Val: Epoch 16, Loss: 0.264\n",
      "Training: Epoch 17, Batch 0, Loss: 0.172\n",
      "Training: Epoch 17, Batch 1, Loss: 0.341\n",
      "Training: Epoch 17, Batch 2, Loss: 0.246\n",
      "Training: Epoch 17, Batch 3, Loss: 0.257\n",
      "Training: Epoch 17, Batch 4, Loss: 0.279\n",
      "Training: Epoch 17, Batch 5, Loss: 0.249\n",
      "Training: Epoch 17, Batch 6, Loss: 0.175\n",
      "Training: Epoch 17, Batch 7, Loss: 0.242\n",
      "Training: Epoch 17, Batch 8, Loss: 0.165\n",
      "Training: Epoch 17, Batch 9, Loss: 0.211\n",
      "Training: Epoch 17, Batch 10, Loss: 0.25\n",
      "Training: Epoch 17, Batch 11, Loss: 0.2\n",
      "Training: Epoch 17, Batch 12, Loss: 0.235\n",
      "Training: Epoch 17, Batch 13, Loss: 0.312\n",
      "Training: Epoch 17, Batch 14, Loss: 0.23\n",
      "Training: Epoch 17, Batch 15, Loss: 0.177\n",
      "Training: Epoch 17, Batch 16, Loss: 0.276\n",
      "Training: Epoch 17, Batch 17, Loss: 0.274\n",
      "Training: Epoch 17, Batch 18, Loss: 0.287\n",
      "Training: Epoch 17, Batch 19, Loss: 0.22\n",
      "Training: Epoch 17, Batch 20, Loss: 0.225\n",
      "Training: Epoch 17, Batch 21, Loss: 0.248\n",
      "Training: Epoch 17, Batch 22, Loss: 0.229\n",
      "Training: Epoch 17, Batch 23, Loss: 0.259\n",
      "Training: Epoch 17, Batch 24, Loss: 0.259\n",
      "Training: Epoch 17, Batch 25, Loss: 0.309\n",
      "Training: Epoch 17, Batch 26, Loss: 0.261\n",
      "Training: Epoch 17, Batch 27, Loss: 0.233\n",
      "Training: Epoch 17, Batch 28, Loss: 0.213\n",
      "Training: Epoch 17, Batch 29, Loss: 0.204\n",
      "Training: Epoch 17, Batch 30, Loss: 0.388\n",
      "Training: Epoch 17, Batch 31, Loss: 0.234\n",
      "Training: Epoch 17, Batch 32, Loss: 0.29\n",
      "Training: Epoch 17, Batch 33, Loss: 0.176\n",
      "Training: Epoch 17, Batch 34, Loss: 0.21\n",
      "Training: Epoch 17, Batch 35, Loss: 0.182\n",
      "Training: Epoch 17, Batch 36, Loss: 0.34\n",
      "Training: Epoch 17, Batch 37, Loss: 0.254\n",
      "Training: Epoch 17, Batch 38, Loss: 0.288\n",
      "Training: Epoch 17, Batch 39, Loss: 0.242\n",
      "Training: Epoch 17, Batch 40, Loss: 0.269\n",
      "Training: Epoch 17, Batch 41, Loss: 0.281\n",
      "Training: Epoch 17, Batch 42, Loss: 0.274\n",
      "Training: Epoch 17, Batch 43, Loss: 0.538\n",
      "Training: Epoch 17, Batch 44, Loss: 0.184\n",
      "Training: Epoch 17, Batch 45, Loss: 0.493\n",
      "Training: Epoch 17, Batch 46, Loss: 0.203\n",
      "Training: Epoch 17, Batch 47, Loss: 0.246\n",
      "Training: Epoch 17, Batch 48, Loss: 0.192\n",
      "Training: Epoch 17, Batch 49, Loss: 0.251\n",
      "Training: Epoch 17, Batch 50, Loss: 0.272\n",
      "Training: Epoch 17, Batch 51, Loss: 0.227\n",
      "Training: Epoch 17, Batch 52, Loss: 0.262\n",
      "Training: Epoch 17, Batch 53, Loss: 0.232\n",
      "Training: Epoch 17, Batch 54, Loss: 0.324\n",
      "Training: Epoch 17, Batch 55, Loss: 0.345\n",
      "Training: Epoch 17, Batch 56, Loss: 0.238\n",
      "Training: Epoch 17, Batch 57, Loss: 0.251\n",
      "Training: Epoch 17, Batch 58, Loss: 0.214\n",
      "Training: Epoch 17, Batch 59, Loss: 0.22\n",
      "Val: Epoch 17, Loss: 0.322\n",
      "Training: Epoch 18, Batch 0, Loss: 0.227\n",
      "Training: Epoch 18, Batch 1, Loss: 0.199\n",
      "Training: Epoch 18, Batch 2, Loss: 0.299\n",
      "Training: Epoch 18, Batch 3, Loss: 0.23\n",
      "Training: Epoch 18, Batch 4, Loss: 0.189\n",
      "Training: Epoch 18, Batch 5, Loss: 0.289\n",
      "Training: Epoch 18, Batch 6, Loss: 0.233\n",
      "Training: Epoch 18, Batch 7, Loss: 0.236\n",
      "Training: Epoch 18, Batch 8, Loss: 0.278\n",
      "Training: Epoch 18, Batch 9, Loss: 0.242\n",
      "Training: Epoch 18, Batch 10, Loss: 0.236\n",
      "Training: Epoch 18, Batch 11, Loss: 0.204\n",
      "Training: Epoch 18, Batch 12, Loss: 0.227\n",
      "Training: Epoch 18, Batch 13, Loss: 0.227\n",
      "Training: Epoch 18, Batch 14, Loss: 0.307\n",
      "Training: Epoch 18, Batch 15, Loss: 0.287\n",
      "Training: Epoch 18, Batch 16, Loss: 0.235\n",
      "Training: Epoch 18, Batch 17, Loss: 0.236\n",
      "Training: Epoch 18, Batch 18, Loss: 0.207\n",
      "Training: Epoch 18, Batch 19, Loss: 0.213\n",
      "Training: Epoch 18, Batch 20, Loss: 0.192\n",
      "Training: Epoch 18, Batch 21, Loss: 0.208\n",
      "Training: Epoch 18, Batch 22, Loss: 0.279\n",
      "Training: Epoch 18, Batch 23, Loss: 0.343\n",
      "Training: Epoch 18, Batch 24, Loss: 0.401\n",
      "Training: Epoch 18, Batch 25, Loss: 0.207\n",
      "Training: Epoch 18, Batch 26, Loss: 0.215\n",
      "Training: Epoch 18, Batch 27, Loss: 0.247\n",
      "Training: Epoch 18, Batch 28, Loss: 0.297\n",
      "Training: Epoch 18, Batch 29, Loss: 0.201\n",
      "Training: Epoch 18, Batch 30, Loss: 0.234\n",
      "Training: Epoch 18, Batch 31, Loss: 0.209\n",
      "Training: Epoch 18, Batch 32, Loss: 0.251\n",
      "Training: Epoch 18, Batch 33, Loss: 0.231\n",
      "Training: Epoch 18, Batch 34, Loss: 0.207\n",
      "Training: Epoch 18, Batch 35, Loss: 0.26\n",
      "Training: Epoch 18, Batch 36, Loss: 0.259\n",
      "Training: Epoch 18, Batch 37, Loss: 0.182\n",
      "Training: Epoch 18, Batch 38, Loss: 0.227\n",
      "Training: Epoch 18, Batch 39, Loss: 0.241\n",
      "Training: Epoch 18, Batch 40, Loss: 0.26\n",
      "Training: Epoch 18, Batch 41, Loss: 0.219\n",
      "Training: Epoch 18, Batch 42, Loss: 0.173\n",
      "Training: Epoch 18, Batch 43, Loss: 0.236\n",
      "Training: Epoch 18, Batch 44, Loss: 0.222\n",
      "Training: Epoch 18, Batch 45, Loss: 0.22\n",
      "Training: Epoch 18, Batch 46, Loss: 0.223\n",
      "Training: Epoch 18, Batch 47, Loss: 0.253\n",
      "Training: Epoch 18, Batch 48, Loss: 0.252\n",
      "Training: Epoch 18, Batch 49, Loss: 0.227\n",
      "Training: Epoch 18, Batch 50, Loss: 0.275\n",
      "Training: Epoch 18, Batch 51, Loss: 0.212\n",
      "Training: Epoch 18, Batch 52, Loss: 0.216\n",
      "Training: Epoch 18, Batch 53, Loss: 0.221\n",
      "Training: Epoch 18, Batch 54, Loss: 0.18\n",
      "Training: Epoch 18, Batch 55, Loss: 0.259\n",
      "Training: Epoch 18, Batch 56, Loss: 0.219\n",
      "Training: Epoch 18, Batch 57, Loss: 0.204\n",
      "Training: Epoch 18, Batch 58, Loss: 0.253\n",
      "Training: Epoch 18, Batch 59, Loss: 0.23\n",
      "Val: Epoch 18, Loss: 0.918\n",
      "Training: Epoch 19, Batch 0, Loss: 0.262\n",
      "Training: Epoch 19, Batch 1, Loss: 0.218\n",
      "Training: Epoch 19, Batch 2, Loss: 0.195\n",
      "Training: Epoch 19, Batch 3, Loss: 0.215\n",
      "Training: Epoch 19, Batch 4, Loss: 0.226\n",
      "Training: Epoch 19, Batch 5, Loss: 0.161\n",
      "Training: Epoch 19, Batch 6, Loss: 0.203\n",
      "Training: Epoch 19, Batch 7, Loss: 0.211\n",
      "Training: Epoch 19, Batch 8, Loss: 0.286\n",
      "Training: Epoch 19, Batch 9, Loss: 0.344\n",
      "Training: Epoch 19, Batch 10, Loss: 0.296\n",
      "Training: Epoch 19, Batch 11, Loss: 0.155\n",
      "Training: Epoch 19, Batch 12, Loss: 0.191\n",
      "Training: Epoch 19, Batch 13, Loss: 0.223\n",
      "Training: Epoch 19, Batch 14, Loss: 0.395\n",
      "Training: Epoch 19, Batch 15, Loss: 0.305\n",
      "Training: Epoch 19, Batch 16, Loss: 0.24\n",
      "Training: Epoch 19, Batch 17, Loss: 0.307\n",
      "Training: Epoch 19, Batch 18, Loss: 0.193\n",
      "Training: Epoch 19, Batch 19, Loss: 0.193\n",
      "Training: Epoch 19, Batch 20, Loss: 0.214\n",
      "Training: Epoch 19, Batch 21, Loss: 0.159\n",
      "Training: Epoch 19, Batch 22, Loss: 0.196\n",
      "Training: Epoch 19, Batch 23, Loss: 0.306\n",
      "Training: Epoch 19, Batch 24, Loss: 0.254\n",
      "Training: Epoch 19, Batch 25, Loss: 0.24\n",
      "Training: Epoch 19, Batch 26, Loss: 0.187\n",
      "Training: Epoch 19, Batch 27, Loss: 0.212\n",
      "Training: Epoch 19, Batch 28, Loss: 0.152\n",
      "Training: Epoch 19, Batch 29, Loss: 0.16\n",
      "Training: Epoch 19, Batch 30, Loss: 0.215\n",
      "Training: Epoch 19, Batch 31, Loss: 0.301\n",
      "Training: Epoch 19, Batch 32, Loss: 0.375\n",
      "Training: Epoch 19, Batch 33, Loss: 0.237\n",
      "Training: Epoch 19, Batch 34, Loss: 0.223\n",
      "Training: Epoch 19, Batch 35, Loss: 0.252\n",
      "Training: Epoch 19, Batch 36, Loss: 0.188\n",
      "Training: Epoch 19, Batch 37, Loss: 0.267\n",
      "Training: Epoch 19, Batch 38, Loss: 0.205\n",
      "Training: Epoch 19, Batch 39, Loss: 0.286\n",
      "Training: Epoch 19, Batch 40, Loss: 0.192\n",
      "Training: Epoch 19, Batch 41, Loss: 0.332\n",
      "Training: Epoch 19, Batch 42, Loss: 0.256\n",
      "Training: Epoch 19, Batch 43, Loss: 0.327\n",
      "Training: Epoch 19, Batch 44, Loss: 0.152\n",
      "Training: Epoch 19, Batch 45, Loss: 0.238\n",
      "Training: Epoch 19, Batch 46, Loss: 0.276\n",
      "Training: Epoch 19, Batch 47, Loss: 0.231\n",
      "Training: Epoch 19, Batch 48, Loss: 0.265\n",
      "Training: Epoch 19, Batch 49, Loss: 0.399\n",
      "Training: Epoch 19, Batch 50, Loss: 0.238\n",
      "Training: Epoch 19, Batch 51, Loss: 0.253\n",
      "Training: Epoch 19, Batch 52, Loss: 0.217\n",
      "Training: Epoch 19, Batch 53, Loss: 0.194\n",
      "Training: Epoch 19, Batch 54, Loss: 0.3\n",
      "Training: Epoch 19, Batch 55, Loss: 0.298\n",
      "Training: Epoch 19, Batch 56, Loss: 0.208\n",
      "Training: Epoch 19, Batch 57, Loss: 0.268\n",
      "Training: Epoch 19, Batch 58, Loss: 0.272\n",
      "Training: Epoch 19, Batch 59, Loss: 0.207\n",
      "Val: Epoch 19, Loss: 0.293\n",
      "Training: Epoch 20, Batch 0, Loss: 0.23\n",
      "Training: Epoch 20, Batch 1, Loss: 0.179\n",
      "Training: Epoch 20, Batch 2, Loss: 0.267\n",
      "Training: Epoch 20, Batch 3, Loss: 0.174\n",
      "Training: Epoch 20, Batch 4, Loss: 0.159\n",
      "Training: Epoch 20, Batch 5, Loss: 0.256\n",
      "Training: Epoch 20, Batch 6, Loss: 0.27\n",
      "Training: Epoch 20, Batch 7, Loss: 0.186\n",
      "Training: Epoch 20, Batch 8, Loss: 0.211\n",
      "Training: Epoch 20, Batch 9, Loss: 0.193\n",
      "Training: Epoch 20, Batch 10, Loss: 0.285\n",
      "Training: Epoch 20, Batch 11, Loss: 0.252\n",
      "Training: Epoch 20, Batch 12, Loss: 0.216\n",
      "Training: Epoch 20, Batch 13, Loss: 0.242\n",
      "Training: Epoch 20, Batch 14, Loss: 0.225\n",
      "Training: Epoch 20, Batch 15, Loss: 0.219\n",
      "Training: Epoch 20, Batch 16, Loss: 0.206\n",
      "Training: Epoch 20, Batch 17, Loss: 0.204\n",
      "Training: Epoch 20, Batch 18, Loss: 0.183\n",
      "Training: Epoch 20, Batch 19, Loss: 0.238\n",
      "Training: Epoch 20, Batch 20, Loss: 0.199\n",
      "Training: Epoch 20, Batch 21, Loss: 0.305\n",
      "Training: Epoch 20, Batch 22, Loss: 0.303\n",
      "Training: Epoch 20, Batch 23, Loss: 0.28\n",
      "Training: Epoch 20, Batch 24, Loss: 0.159\n",
      "Training: Epoch 20, Batch 25, Loss: 0.218\n",
      "Training: Epoch 20, Batch 26, Loss: 0.21\n",
      "Training: Epoch 20, Batch 27, Loss: 0.254\n",
      "Training: Epoch 20, Batch 28, Loss: 0.258\n",
      "Training: Epoch 20, Batch 29, Loss: 0.227\n",
      "Training: Epoch 20, Batch 30, Loss: 0.27\n",
      "Training: Epoch 20, Batch 31, Loss: 0.303\n",
      "Training: Epoch 20, Batch 32, Loss: 0.201\n",
      "Training: Epoch 20, Batch 33, Loss: 0.188\n",
      "Training: Epoch 20, Batch 34, Loss: 0.223\n",
      "Training: Epoch 20, Batch 35, Loss: 0.205\n",
      "Training: Epoch 20, Batch 36, Loss: 0.196\n",
      "Training: Epoch 20, Batch 37, Loss: 0.229\n",
      "Training: Epoch 20, Batch 38, Loss: 0.201\n",
      "Training: Epoch 20, Batch 39, Loss: 0.194\n",
      "Training: Epoch 20, Batch 40, Loss: 0.186\n",
      "Training: Epoch 20, Batch 41, Loss: 0.267\n",
      "Training: Epoch 20, Batch 42, Loss: 0.29\n",
      "Training: Epoch 20, Batch 43, Loss: 0.176\n",
      "Training: Epoch 20, Batch 44, Loss: 0.193\n",
      "Training: Epoch 20, Batch 45, Loss: 0.286\n",
      "Training: Epoch 20, Batch 46, Loss: 0.268\n",
      "Training: Epoch 20, Batch 47, Loss: 0.181\n",
      "Training: Epoch 20, Batch 48, Loss: 0.134\n",
      "Training: Epoch 20, Batch 49, Loss: 0.186\n",
      "Training: Epoch 20, Batch 50, Loss: 0.236\n",
      "Training: Epoch 20, Batch 51, Loss: 0.255\n",
      "Training: Epoch 20, Batch 52, Loss: 0.261\n",
      "Training: Epoch 20, Batch 53, Loss: 0.23\n",
      "Training: Epoch 20, Batch 54, Loss: 0.192\n",
      "Training: Epoch 20, Batch 55, Loss: 0.17\n",
      "Training: Epoch 20, Batch 56, Loss: 0.176\n",
      "Training: Epoch 20, Batch 57, Loss: 0.24\n",
      "Training: Epoch 20, Batch 58, Loss: 0.256\n",
      "Training: Epoch 20, Batch 59, Loss: 0.155\n",
      "Val: Epoch 20, Loss: 0.778\n",
      "Training: Epoch 21, Batch 0, Loss: 0.212\n",
      "Training: Epoch 21, Batch 1, Loss: 0.257\n",
      "Training: Epoch 21, Batch 2, Loss: 0.273\n",
      "Training: Epoch 21, Batch 3, Loss: 0.215\n",
      "Training: Epoch 21, Batch 4, Loss: 0.242\n",
      "Training: Epoch 21, Batch 5, Loss: 0.223\n",
      "Training: Epoch 21, Batch 6, Loss: 0.211\n",
      "Training: Epoch 21, Batch 7, Loss: 0.21\n",
      "Training: Epoch 21, Batch 8, Loss: 0.213\n",
      "Training: Epoch 21, Batch 9, Loss: 0.263\n",
      "Training: Epoch 21, Batch 10, Loss: 0.195\n",
      "Training: Epoch 21, Batch 11, Loss: 0.161\n",
      "Training: Epoch 21, Batch 12, Loss: 0.222\n",
      "Training: Epoch 21, Batch 13, Loss: 0.204\n",
      "Training: Epoch 21, Batch 14, Loss: 0.182\n",
      "Training: Epoch 21, Batch 15, Loss: 0.188\n",
      "Training: Epoch 21, Batch 16, Loss: 0.272\n",
      "Training: Epoch 21, Batch 17, Loss: 0.205\n",
      "Training: Epoch 21, Batch 18, Loss: 0.226\n",
      "Training: Epoch 21, Batch 19, Loss: 0.224\n",
      "Training: Epoch 21, Batch 20, Loss: 0.253\n",
      "Training: Epoch 21, Batch 21, Loss: 0.212\n",
      "Training: Epoch 21, Batch 22, Loss: 0.22\n",
      "Training: Epoch 21, Batch 23, Loss: 0.186\n",
      "Training: Epoch 21, Batch 24, Loss: 0.187\n",
      "Training: Epoch 21, Batch 25, Loss: 0.264\n",
      "Training: Epoch 21, Batch 26, Loss: 0.208\n",
      "Training: Epoch 21, Batch 27, Loss: 0.172\n",
      "Training: Epoch 21, Batch 28, Loss: 0.218\n",
      "Training: Epoch 21, Batch 29, Loss: 0.224\n",
      "Training: Epoch 21, Batch 30, Loss: 0.249\n",
      "Training: Epoch 21, Batch 31, Loss: 0.195\n",
      "Training: Epoch 21, Batch 32, Loss: 0.18\n",
      "Training: Epoch 21, Batch 33, Loss: 0.297\n",
      "Training: Epoch 21, Batch 34, Loss: 0.236\n",
      "Training: Epoch 21, Batch 35, Loss: 0.241\n",
      "Training: Epoch 21, Batch 36, Loss: 0.27\n",
      "Training: Epoch 21, Batch 37, Loss: 0.192\n",
      "Training: Epoch 21, Batch 38, Loss: 0.183\n",
      "Training: Epoch 21, Batch 39, Loss: 0.211\n",
      "Training: Epoch 21, Batch 40, Loss: 0.297\n",
      "Training: Epoch 21, Batch 41, Loss: 0.285\n",
      "Training: Epoch 21, Batch 42, Loss: 0.17\n",
      "Training: Epoch 21, Batch 43, Loss: 0.225\n",
      "Training: Epoch 21, Batch 44, Loss: 0.228\n",
      "Training: Epoch 21, Batch 45, Loss: 0.182\n",
      "Training: Epoch 21, Batch 46, Loss: 0.258\n",
      "Training: Epoch 21, Batch 47, Loss: 0.187\n",
      "Training: Epoch 21, Batch 48, Loss: 0.229\n",
      "Training: Epoch 21, Batch 49, Loss: 0.179\n",
      "Training: Epoch 21, Batch 50, Loss: 0.198\n",
      "Training: Epoch 21, Batch 51, Loss: 0.212\n",
      "Training: Epoch 21, Batch 52, Loss: 0.199\n",
      "Training: Epoch 21, Batch 53, Loss: 0.289\n",
      "Training: Epoch 21, Batch 54, Loss: 0.196\n",
      "Training: Epoch 21, Batch 55, Loss: 0.278\n",
      "Training: Epoch 21, Batch 56, Loss: 0.287\n",
      "Training: Epoch 21, Batch 57, Loss: 0.243\n",
      "Training: Epoch 21, Batch 58, Loss: 0.338\n",
      "Training: Epoch 21, Batch 59, Loss: 0.321\n",
      "Val: Epoch 21, Loss: 0.235\n",
      "Training: Epoch 22, Batch 0, Loss: 0.191\n",
      "Training: Epoch 22, Batch 1, Loss: 0.27\n",
      "Training: Epoch 22, Batch 2, Loss: 0.333\n",
      "Training: Epoch 22, Batch 3, Loss: 0.316\n",
      "Training: Epoch 22, Batch 4, Loss: 0.215\n",
      "Training: Epoch 22, Batch 5, Loss: 0.223\n",
      "Training: Epoch 22, Batch 6, Loss: 0.222\n",
      "Training: Epoch 22, Batch 7, Loss: 0.156\n",
      "Training: Epoch 22, Batch 8, Loss: 0.14\n",
      "Training: Epoch 22, Batch 9, Loss: 0.173\n",
      "Training: Epoch 22, Batch 10, Loss: 0.217\n",
      "Training: Epoch 22, Batch 11, Loss: 0.249\n",
      "Training: Epoch 22, Batch 12, Loss: 0.221\n",
      "Training: Epoch 22, Batch 13, Loss: 0.221\n",
      "Training: Epoch 22, Batch 14, Loss: 0.208\n",
      "Training: Epoch 22, Batch 15, Loss: 0.241\n",
      "Training: Epoch 22, Batch 16, Loss: 0.235\n",
      "Training: Epoch 22, Batch 17, Loss: 0.244\n",
      "Training: Epoch 22, Batch 18, Loss: 0.192\n",
      "Training: Epoch 22, Batch 19, Loss: 0.227\n",
      "Training: Epoch 22, Batch 20, Loss: 0.204\n",
      "Training: Epoch 22, Batch 21, Loss: 0.215\n",
      "Training: Epoch 22, Batch 22, Loss: 0.238\n",
      "Training: Epoch 22, Batch 23, Loss: 0.206\n",
      "Training: Epoch 22, Batch 24, Loss: 0.165\n",
      "Training: Epoch 22, Batch 25, Loss: 0.207\n",
      "Training: Epoch 22, Batch 26, Loss: 0.138\n",
      "Training: Epoch 22, Batch 27, Loss: 0.2\n",
      "Training: Epoch 22, Batch 28, Loss: 0.201\n",
      "Training: Epoch 22, Batch 29, Loss: 0.282\n",
      "Training: Epoch 22, Batch 30, Loss: 0.154\n",
      "Training: Epoch 22, Batch 31, Loss: 0.203\n",
      "Training: Epoch 22, Batch 32, Loss: 0.2\n",
      "Training: Epoch 22, Batch 33, Loss: 0.145\n",
      "Training: Epoch 22, Batch 34, Loss: 0.22\n",
      "Training: Epoch 22, Batch 35, Loss: 0.214\n",
      "Training: Epoch 22, Batch 36, Loss: 0.186\n",
      "Training: Epoch 22, Batch 37, Loss: 0.265\n",
      "Training: Epoch 22, Batch 38, Loss: 0.207\n",
      "Training: Epoch 22, Batch 39, Loss: 0.214\n",
      "Training: Epoch 22, Batch 40, Loss: 0.228\n",
      "Training: Epoch 22, Batch 41, Loss: 0.198\n",
      "Training: Epoch 22, Batch 42, Loss: 0.174\n",
      "Training: Epoch 22, Batch 43, Loss: 0.227\n",
      "Training: Epoch 22, Batch 44, Loss: 0.201\n",
      "Training: Epoch 22, Batch 45, Loss: 0.241\n",
      "Training: Epoch 22, Batch 46, Loss: 0.21\n",
      "Training: Epoch 22, Batch 47, Loss: 0.241\n",
      "Training: Epoch 22, Batch 48, Loss: 0.235\n",
      "Training: Epoch 22, Batch 49, Loss: 0.19\n",
      "Training: Epoch 22, Batch 50, Loss: 0.203\n",
      "Training: Epoch 22, Batch 51, Loss: 0.274\n",
      "Training: Epoch 22, Batch 52, Loss: 0.194\n",
      "Training: Epoch 22, Batch 53, Loss: 0.283\n",
      "Training: Epoch 22, Batch 54, Loss: 0.294\n",
      "Training: Epoch 22, Batch 55, Loss: 0.211\n",
      "Training: Epoch 22, Batch 56, Loss: 0.273\n",
      "Training: Epoch 22, Batch 57, Loss: 0.13\n",
      "Training: Epoch 22, Batch 58, Loss: 0.178\n",
      "Training: Epoch 22, Batch 59, Loss: 0.164\n",
      "Val: Epoch 22, Loss: 0.244\n",
      "Training: Epoch 23, Batch 0, Loss: 0.265\n",
      "Training: Epoch 23, Batch 1, Loss: 0.233\n",
      "Training: Epoch 23, Batch 2, Loss: 0.292\n",
      "Training: Epoch 23, Batch 3, Loss: 0.209\n",
      "Training: Epoch 23, Batch 4, Loss: 0.154\n",
      "Training: Epoch 23, Batch 5, Loss: 0.255\n",
      "Training: Epoch 23, Batch 6, Loss: 0.241\n",
      "Training: Epoch 23, Batch 7, Loss: 0.247\n",
      "Training: Epoch 23, Batch 8, Loss: 0.248\n",
      "Training: Epoch 23, Batch 9, Loss: 0.193\n",
      "Training: Epoch 23, Batch 10, Loss: 0.162\n",
      "Training: Epoch 23, Batch 11, Loss: 0.271\n",
      "Training: Epoch 23, Batch 12, Loss: 0.219\n",
      "Training: Epoch 23, Batch 13, Loss: 0.239\n",
      "Training: Epoch 23, Batch 14, Loss: 0.263\n",
      "Training: Epoch 23, Batch 15, Loss: 0.304\n",
      "Training: Epoch 23, Batch 16, Loss: 0.222\n",
      "Training: Epoch 23, Batch 17, Loss: 0.279\n",
      "Training: Epoch 23, Batch 18, Loss: 0.23\n",
      "Training: Epoch 23, Batch 19, Loss: 0.298\n",
      "Training: Epoch 23, Batch 20, Loss: 0.224\n",
      "Training: Epoch 23, Batch 21, Loss: 0.219\n",
      "Training: Epoch 23, Batch 22, Loss: 0.178\n",
      "Training: Epoch 23, Batch 23, Loss: 0.268\n",
      "Training: Epoch 23, Batch 24, Loss: 0.242\n",
      "Training: Epoch 23, Batch 25, Loss: 0.132\n",
      "Training: Epoch 23, Batch 26, Loss: 0.309\n",
      "Training: Epoch 23, Batch 27, Loss: 0.202\n",
      "Training: Epoch 23, Batch 28, Loss: 0.204\n",
      "Training: Epoch 23, Batch 29, Loss: 0.375\n",
      "Training: Epoch 23, Batch 30, Loss: 0.283\n",
      "Training: Epoch 23, Batch 31, Loss: 0.147\n",
      "Training: Epoch 23, Batch 32, Loss: 0.209\n",
      "Training: Epoch 23, Batch 33, Loss: 0.215\n",
      "Training: Epoch 23, Batch 34, Loss: 0.216\n",
      "Training: Epoch 23, Batch 35, Loss: 0.176\n",
      "Training: Epoch 23, Batch 36, Loss: 0.282\n",
      "Training: Epoch 23, Batch 37, Loss: 0.181\n",
      "Training: Epoch 23, Batch 38, Loss: 0.205\n",
      "Training: Epoch 23, Batch 39, Loss: 0.169\n",
      "Training: Epoch 23, Batch 40, Loss: 0.235\n",
      "Training: Epoch 23, Batch 41, Loss: 0.207\n",
      "Training: Epoch 23, Batch 42, Loss: 0.213\n",
      "Training: Epoch 23, Batch 43, Loss: 0.163\n",
      "Training: Epoch 23, Batch 44, Loss: 0.229\n",
      "Training: Epoch 23, Batch 45, Loss: 0.251\n",
      "Training: Epoch 23, Batch 46, Loss: 0.193\n",
      "Training: Epoch 23, Batch 47, Loss: 0.198\n",
      "Training: Epoch 23, Batch 48, Loss: 0.174\n",
      "Training: Epoch 23, Batch 49, Loss: 0.179\n",
      "Training: Epoch 23, Batch 50, Loss: 0.227\n",
      "Training: Epoch 23, Batch 51, Loss: 0.207\n",
      "Training: Epoch 23, Batch 52, Loss: 0.187\n",
      "Training: Epoch 23, Batch 53, Loss: 0.231\n",
      "Training: Epoch 23, Batch 54, Loss: 0.18\n",
      "Training: Epoch 23, Batch 55, Loss: 0.172\n",
      "Training: Epoch 23, Batch 56, Loss: 0.188\n",
      "Training: Epoch 23, Batch 57, Loss: 0.186\n",
      "Training: Epoch 23, Batch 58, Loss: 0.237\n",
      "Training: Epoch 23, Batch 59, Loss: 0.235\n",
      "Val: Epoch 23, Loss: 0.251\n",
      "Training: Epoch 24, Batch 0, Loss: 0.175\n",
      "Training: Epoch 24, Batch 1, Loss: 0.262\n",
      "Training: Epoch 24, Batch 2, Loss: 0.19\n",
      "Training: Epoch 24, Batch 3, Loss: 0.239\n",
      "Training: Epoch 24, Batch 4, Loss: 0.255\n",
      "Training: Epoch 24, Batch 5, Loss: 0.258\n",
      "Training: Epoch 24, Batch 6, Loss: 0.152\n",
      "Training: Epoch 24, Batch 7, Loss: 0.181\n",
      "Training: Epoch 24, Batch 8, Loss: 0.181\n",
      "Training: Epoch 24, Batch 9, Loss: 0.26\n",
      "Training: Epoch 24, Batch 10, Loss: 0.222\n",
      "Training: Epoch 24, Batch 11, Loss: 0.232\n",
      "Training: Epoch 24, Batch 12, Loss: 0.214\n",
      "Training: Epoch 24, Batch 13, Loss: 0.366\n",
      "Training: Epoch 24, Batch 14, Loss: 0.277\n",
      "Training: Epoch 24, Batch 15, Loss: 0.182\n",
      "Training: Epoch 24, Batch 16, Loss: 0.188\n",
      "Training: Epoch 24, Batch 17, Loss: 0.177\n",
      "Training: Epoch 24, Batch 18, Loss: 0.158\n",
      "Training: Epoch 24, Batch 19, Loss: 0.198\n",
      "Training: Epoch 24, Batch 20, Loss: 0.166\n",
      "Training: Epoch 24, Batch 21, Loss: 0.169\n",
      "Training: Epoch 24, Batch 22, Loss: 0.197\n",
      "Training: Epoch 24, Batch 23, Loss: 0.178\n",
      "Training: Epoch 24, Batch 24, Loss: 0.198\n",
      "Training: Epoch 24, Batch 25, Loss: 0.158\n",
      "Training: Epoch 24, Batch 26, Loss: 0.152\n",
      "Training: Epoch 24, Batch 27, Loss: 0.223\n",
      "Training: Epoch 24, Batch 28, Loss: 0.203\n",
      "Training: Epoch 24, Batch 29, Loss: 0.153\n",
      "Training: Epoch 24, Batch 30, Loss: 0.176\n",
      "Training: Epoch 24, Batch 31, Loss: 0.233\n",
      "Training: Epoch 24, Batch 32, Loss: 0.183\n",
      "Training: Epoch 24, Batch 33, Loss: 0.249\n",
      "Training: Epoch 24, Batch 34, Loss: 0.166\n",
      "Training: Epoch 24, Batch 35, Loss: 0.17\n",
      "Training: Epoch 24, Batch 36, Loss: 0.239\n",
      "Training: Epoch 24, Batch 37, Loss: 0.208\n",
      "Training: Epoch 24, Batch 38, Loss: 0.212\n",
      "Training: Epoch 24, Batch 39, Loss: 0.189\n",
      "Training: Epoch 24, Batch 40, Loss: 0.172\n",
      "Training: Epoch 24, Batch 41, Loss: 0.235\n",
      "Training: Epoch 24, Batch 42, Loss: 0.237\n",
      "Training: Epoch 24, Batch 43, Loss: 0.235\n",
      "Training: Epoch 24, Batch 44, Loss: 0.238\n",
      "Training: Epoch 24, Batch 45, Loss: 0.2\n",
      "Training: Epoch 24, Batch 46, Loss: 0.242\n",
      "Training: Epoch 24, Batch 47, Loss: 0.162\n",
      "Training: Epoch 24, Batch 48, Loss: 0.194\n",
      "Training: Epoch 24, Batch 49, Loss: 0.16\n",
      "Training: Epoch 24, Batch 50, Loss: 0.207\n",
      "Training: Epoch 24, Batch 51, Loss: 0.228\n",
      "Training: Epoch 24, Batch 52, Loss: 0.232\n",
      "Training: Epoch 24, Batch 53, Loss: 0.214\n",
      "Training: Epoch 24, Batch 54, Loss: 0.203\n",
      "Training: Epoch 24, Batch 55, Loss: 0.149\n",
      "Training: Epoch 24, Batch 56, Loss: 0.217\n",
      "Training: Epoch 24, Batch 57, Loss: 0.199\n",
      "Training: Epoch 24, Batch 58, Loss: 0.216\n",
      "Training: Epoch 24, Batch 59, Loss: 0.191\n",
      "Val: Epoch 24, Loss: 0.252\n",
      "Training: Epoch 25, Batch 0, Loss: 0.147\n",
      "Training: Epoch 25, Batch 1, Loss: 0.24\n",
      "Training: Epoch 25, Batch 2, Loss: 0.162\n",
      "Training: Epoch 25, Batch 3, Loss: 0.184\n",
      "Training: Epoch 25, Batch 4, Loss: 0.17\n",
      "Training: Epoch 25, Batch 5, Loss: 0.233\n",
      "Training: Epoch 25, Batch 6, Loss: 0.219\n",
      "Training: Epoch 25, Batch 7, Loss: 0.174\n",
      "Training: Epoch 25, Batch 8, Loss: 0.181\n",
      "Training: Epoch 25, Batch 9, Loss: 0.155\n",
      "Training: Epoch 25, Batch 10, Loss: 0.155\n",
      "Training: Epoch 25, Batch 11, Loss: 0.187\n",
      "Training: Epoch 25, Batch 12, Loss: 0.222\n",
      "Training: Epoch 25, Batch 13, Loss: 0.195\n",
      "Training: Epoch 25, Batch 14, Loss: 0.18\n",
      "Training: Epoch 25, Batch 15, Loss: 0.247\n",
      "Training: Epoch 25, Batch 16, Loss: 0.193\n",
      "Training: Epoch 25, Batch 17, Loss: 0.148\n",
      "Training: Epoch 25, Batch 18, Loss: 0.197\n",
      "Training: Epoch 25, Batch 19, Loss: 0.215\n",
      "Training: Epoch 25, Batch 20, Loss: 0.207\n",
      "Training: Epoch 25, Batch 21, Loss: 0.176\n",
      "Training: Epoch 25, Batch 22, Loss: 0.164\n",
      "Training: Epoch 25, Batch 23, Loss: 0.255\n",
      "Training: Epoch 25, Batch 24, Loss: 0.188\n",
      "Training: Epoch 25, Batch 25, Loss: 0.157\n",
      "Training: Epoch 25, Batch 26, Loss: 0.208\n",
      "Training: Epoch 25, Batch 27, Loss: 0.185\n",
      "Training: Epoch 25, Batch 28, Loss: 0.174\n",
      "Training: Epoch 25, Batch 29, Loss: 0.27\n",
      "Training: Epoch 25, Batch 30, Loss: 0.252\n",
      "Training: Epoch 25, Batch 31, Loss: 0.171\n",
      "Training: Epoch 25, Batch 32, Loss: 0.196\n",
      "Training: Epoch 25, Batch 33, Loss: 0.23\n",
      "Training: Epoch 25, Batch 34, Loss: 0.223\n",
      "Training: Epoch 25, Batch 35, Loss: 0.237\n",
      "Training: Epoch 25, Batch 36, Loss: 0.203\n",
      "Training: Epoch 25, Batch 37, Loss: 0.205\n",
      "Training: Epoch 25, Batch 38, Loss: 0.186\n",
      "Training: Epoch 25, Batch 39, Loss: 0.179\n",
      "Training: Epoch 25, Batch 40, Loss: 0.226\n",
      "Training: Epoch 25, Batch 41, Loss: 0.337\n",
      "Training: Epoch 25, Batch 42, Loss: 0.368\n",
      "Training: Epoch 25, Batch 43, Loss: 0.195\n",
      "Training: Epoch 25, Batch 44, Loss: 0.192\n",
      "Training: Epoch 25, Batch 45, Loss: 0.217\n",
      "Training: Epoch 25, Batch 46, Loss: 0.273\n",
      "Training: Epoch 25, Batch 47, Loss: 0.211\n",
      "Training: Epoch 25, Batch 48, Loss: 0.184\n",
      "Training: Epoch 25, Batch 49, Loss: 0.239\n",
      "Training: Epoch 25, Batch 50, Loss: 0.193\n",
      "Training: Epoch 25, Batch 51, Loss: 0.198\n",
      "Training: Epoch 25, Batch 52, Loss: 0.193\n",
      "Training: Epoch 25, Batch 53, Loss: 0.193\n",
      "Training: Epoch 25, Batch 54, Loss: 0.181\n",
      "Training: Epoch 25, Batch 55, Loss: 0.251\n",
      "Training: Epoch 25, Batch 56, Loss: 0.189\n",
      "Training: Epoch 25, Batch 57, Loss: 0.169\n",
      "Training: Epoch 25, Batch 58, Loss: 0.195\n",
      "Training: Epoch 25, Batch 59, Loss: 0.194\n",
      "Val: Epoch 25, Loss: 0.231\n",
      "Training: Epoch 26, Batch 0, Loss: 0.181\n",
      "Training: Epoch 26, Batch 1, Loss: 0.179\n",
      "Training: Epoch 26, Batch 2, Loss: 0.211\n",
      "Training: Epoch 26, Batch 3, Loss: 0.181\n",
      "Training: Epoch 26, Batch 4, Loss: 0.205\n",
      "Training: Epoch 26, Batch 5, Loss: 0.17\n",
      "Training: Epoch 26, Batch 6, Loss: 0.229\n",
      "Training: Epoch 26, Batch 7, Loss: 0.185\n",
      "Training: Epoch 26, Batch 8, Loss: 0.335\n",
      "Training: Epoch 26, Batch 9, Loss: 0.175\n",
      "Training: Epoch 26, Batch 10, Loss: 0.145\n",
      "Training: Epoch 26, Batch 11, Loss: 0.167\n",
      "Training: Epoch 26, Batch 12, Loss: 0.207\n",
      "Training: Epoch 26, Batch 13, Loss: 0.147\n",
      "Training: Epoch 26, Batch 14, Loss: 0.232\n",
      "Training: Epoch 26, Batch 15, Loss: 0.185\n",
      "Training: Epoch 26, Batch 16, Loss: 0.171\n",
      "Training: Epoch 26, Batch 17, Loss: 0.198\n",
      "Training: Epoch 26, Batch 18, Loss: 0.176\n",
      "Training: Epoch 26, Batch 19, Loss: 0.233\n",
      "Training: Epoch 26, Batch 20, Loss: 0.203\n",
      "Training: Epoch 26, Batch 21, Loss: 0.356\n",
      "Training: Epoch 26, Batch 22, Loss: 0.226\n",
      "Training: Epoch 26, Batch 23, Loss: 0.152\n",
      "Training: Epoch 26, Batch 24, Loss: 0.2\n",
      "Training: Epoch 26, Batch 25, Loss: 0.278\n",
      "Training: Epoch 26, Batch 26, Loss: 0.205\n",
      "Training: Epoch 26, Batch 27, Loss: 0.181\n",
      "Training: Epoch 26, Batch 28, Loss: 0.26\n",
      "Training: Epoch 26, Batch 29, Loss: 0.203\n",
      "Training: Epoch 26, Batch 30, Loss: 0.19\n",
      "Training: Epoch 26, Batch 31, Loss: 0.185\n",
      "Training: Epoch 26, Batch 32, Loss: 0.131\n",
      "Training: Epoch 26, Batch 33, Loss: 0.158\n",
      "Training: Epoch 26, Batch 34, Loss: 0.18\n",
      "Training: Epoch 26, Batch 35, Loss: 0.252\n",
      "Training: Epoch 26, Batch 36, Loss: 0.158\n",
      "Training: Epoch 26, Batch 37, Loss: 0.236\n",
      "Training: Epoch 26, Batch 38, Loss: 0.187\n",
      "Training: Epoch 26, Batch 39, Loss: 0.193\n",
      "Training: Epoch 26, Batch 40, Loss: 0.204\n",
      "Training: Epoch 26, Batch 41, Loss: 0.248\n",
      "Training: Epoch 26, Batch 42, Loss: 0.168\n",
      "Training: Epoch 26, Batch 43, Loss: 0.236\n",
      "Training: Epoch 26, Batch 44, Loss: 0.186\n",
      "Training: Epoch 26, Batch 45, Loss: 0.201\n",
      "Training: Epoch 26, Batch 46, Loss: 0.207\n",
      "Training: Epoch 26, Batch 47, Loss: 0.259\n",
      "Training: Epoch 26, Batch 48, Loss: 0.214\n",
      "Training: Epoch 26, Batch 49, Loss: 0.172\n",
      "Training: Epoch 26, Batch 50, Loss: 0.223\n",
      "Training: Epoch 26, Batch 51, Loss: 0.19\n",
      "Training: Epoch 26, Batch 52, Loss: 0.227\n",
      "Training: Epoch 26, Batch 53, Loss: 0.199\n",
      "Training: Epoch 26, Batch 54, Loss: 0.243\n",
      "Training: Epoch 26, Batch 55, Loss: 0.226\n",
      "Training: Epoch 26, Batch 56, Loss: 0.223\n",
      "Training: Epoch 26, Batch 57, Loss: 0.195\n",
      "Training: Epoch 26, Batch 58, Loss: 0.245\n",
      "Training: Epoch 26, Batch 59, Loss: 0.345\n",
      "Val: Epoch 26, Loss: 0.283\n",
      "Training: Epoch 27, Batch 0, Loss: 0.322\n",
      "Training: Epoch 27, Batch 1, Loss: 0.236\n",
      "Training: Epoch 27, Batch 2, Loss: 0.275\n",
      "Training: Epoch 27, Batch 3, Loss: 0.239\n",
      "Training: Epoch 27, Batch 4, Loss: 0.179\n",
      "Training: Epoch 27, Batch 5, Loss: 0.245\n",
      "Training: Epoch 27, Batch 6, Loss: 0.276\n",
      "Training: Epoch 27, Batch 7, Loss: 0.277\n",
      "Training: Epoch 27, Batch 8, Loss: 0.212\n",
      "Training: Epoch 27, Batch 9, Loss: 0.194\n",
      "Training: Epoch 27, Batch 10, Loss: 0.229\n",
      "Training: Epoch 27, Batch 11, Loss: 0.197\n",
      "Training: Epoch 27, Batch 12, Loss: 0.197\n",
      "Training: Epoch 27, Batch 13, Loss: 0.211\n",
      "Training: Epoch 27, Batch 14, Loss: 0.157\n",
      "Training: Epoch 27, Batch 15, Loss: 0.208\n",
      "Training: Epoch 27, Batch 16, Loss: 0.208\n",
      "Training: Epoch 27, Batch 17, Loss: 0.22\n",
      "Training: Epoch 27, Batch 18, Loss: 0.246\n",
      "Training: Epoch 27, Batch 19, Loss: 0.215\n",
      "Training: Epoch 27, Batch 20, Loss: 0.188\n",
      "Training: Epoch 27, Batch 21, Loss: 0.227\n",
      "Training: Epoch 27, Batch 22, Loss: 0.256\n",
      "Training: Epoch 27, Batch 23, Loss: 0.171\n",
      "Training: Epoch 27, Batch 24, Loss: 0.199\n",
      "Training: Epoch 27, Batch 25, Loss: 0.166\n",
      "Training: Epoch 27, Batch 26, Loss: 0.175\n",
      "Training: Epoch 27, Batch 27, Loss: 0.245\n",
      "Training: Epoch 27, Batch 28, Loss: 0.219\n",
      "Training: Epoch 27, Batch 29, Loss: 0.197\n",
      "Training: Epoch 27, Batch 30, Loss: 0.166\n",
      "Training: Epoch 27, Batch 31, Loss: 0.245\n",
      "Training: Epoch 27, Batch 32, Loss: 0.146\n",
      "Training: Epoch 27, Batch 33, Loss: 0.235\n",
      "Training: Epoch 27, Batch 34, Loss: 0.149\n",
      "Training: Epoch 27, Batch 35, Loss: 0.293\n",
      "Training: Epoch 27, Batch 36, Loss: 0.237\n",
      "Training: Epoch 27, Batch 37, Loss: 0.174\n",
      "Training: Epoch 27, Batch 38, Loss: 0.204\n",
      "Training: Epoch 27, Batch 39, Loss: 0.209\n",
      "Training: Epoch 27, Batch 40, Loss: 0.168\n",
      "Training: Epoch 27, Batch 41, Loss: 0.157\n",
      "Training: Epoch 27, Batch 42, Loss: 0.324\n",
      "Training: Epoch 27, Batch 43, Loss: 0.183\n",
      "Training: Epoch 27, Batch 44, Loss: 0.168\n",
      "Training: Epoch 27, Batch 45, Loss: 0.186\n",
      "Training: Epoch 27, Batch 46, Loss: 0.225\n",
      "Training: Epoch 27, Batch 47, Loss: 0.175\n",
      "Training: Epoch 27, Batch 48, Loss: 0.203\n",
      "Training: Epoch 27, Batch 49, Loss: 0.211\n",
      "Training: Epoch 27, Batch 50, Loss: 0.177\n",
      "Training: Epoch 27, Batch 51, Loss: 0.199\n",
      "Training: Epoch 27, Batch 52, Loss: 0.204\n",
      "Training: Epoch 27, Batch 53, Loss: 0.182\n",
      "Training: Epoch 27, Batch 54, Loss: 0.151\n",
      "Training: Epoch 27, Batch 55, Loss: 0.234\n",
      "Training: Epoch 27, Batch 56, Loss: 0.148\n",
      "Training: Epoch 27, Batch 57, Loss: 0.182\n",
      "Training: Epoch 27, Batch 58, Loss: 0.142\n",
      "Training: Epoch 27, Batch 59, Loss: 0.179\n",
      "Val: Epoch 27, Loss: 0.244\n",
      "Training: Epoch 28, Batch 0, Loss: 0.18\n",
      "Training: Epoch 28, Batch 1, Loss: 0.2\n",
      "Training: Epoch 28, Batch 2, Loss: 0.217\n",
      "Training: Epoch 28, Batch 3, Loss: 0.204\n",
      "Training: Epoch 28, Batch 4, Loss: 0.257\n",
      "Training: Epoch 28, Batch 5, Loss: 0.187\n",
      "Training: Epoch 28, Batch 6, Loss: 0.181\n",
      "Training: Epoch 28, Batch 7, Loss: 0.214\n",
      "Training: Epoch 28, Batch 8, Loss: 0.156\n",
      "Training: Epoch 28, Batch 9, Loss: 0.182\n",
      "Training: Epoch 28, Batch 10, Loss: 0.16\n",
      "Training: Epoch 28, Batch 11, Loss: 0.179\n",
      "Training: Epoch 28, Batch 12, Loss: 0.264\n",
      "Training: Epoch 28, Batch 13, Loss: 0.154\n",
      "Training: Epoch 28, Batch 14, Loss: 0.173\n",
      "Training: Epoch 28, Batch 15, Loss: 0.236\n",
      "Training: Epoch 28, Batch 16, Loss: 0.171\n",
      "Training: Epoch 28, Batch 17, Loss: 0.211\n",
      "Training: Epoch 28, Batch 18, Loss: 0.163\n",
      "Training: Epoch 28, Batch 19, Loss: 0.211\n",
      "Training: Epoch 28, Batch 20, Loss: 0.156\n",
      "Training: Epoch 28, Batch 21, Loss: 0.178\n",
      "Training: Epoch 28, Batch 22, Loss: 0.245\n",
      "Training: Epoch 28, Batch 23, Loss: 0.294\n",
      "Training: Epoch 28, Batch 24, Loss: 0.14\n",
      "Training: Epoch 28, Batch 25, Loss: 0.163\n",
      "Training: Epoch 28, Batch 26, Loss: 0.335\n",
      "Training: Epoch 28, Batch 27, Loss: 0.181\n",
      "Training: Epoch 28, Batch 28, Loss: 0.203\n",
      "Training: Epoch 28, Batch 29, Loss: 0.226\n",
      "Training: Epoch 28, Batch 30, Loss: 0.162\n",
      "Training: Epoch 28, Batch 31, Loss: 0.189\n",
      "Training: Epoch 28, Batch 32, Loss: 0.211\n",
      "Training: Epoch 28, Batch 33, Loss: 0.17\n",
      "Training: Epoch 28, Batch 34, Loss: 0.205\n",
      "Training: Epoch 28, Batch 35, Loss: 0.228\n",
      "Training: Epoch 28, Batch 36, Loss: 0.178\n",
      "Training: Epoch 28, Batch 37, Loss: 0.26\n",
      "Training: Epoch 28, Batch 38, Loss: 0.184\n",
      "Training: Epoch 28, Batch 39, Loss: 0.176\n",
      "Training: Epoch 28, Batch 40, Loss: 0.193\n",
      "Training: Epoch 28, Batch 41, Loss: 0.226\n",
      "Training: Epoch 28, Batch 42, Loss: 0.18\n",
      "Training: Epoch 28, Batch 43, Loss: 0.246\n",
      "Training: Epoch 28, Batch 44, Loss: 0.267\n",
      "Training: Epoch 28, Batch 45, Loss: 0.208\n",
      "Training: Epoch 28, Batch 46, Loss: 0.164\n",
      "Training: Epoch 28, Batch 47, Loss: 0.223\n",
      "Training: Epoch 28, Batch 48, Loss: 0.205\n",
      "Training: Epoch 28, Batch 49, Loss: 0.178\n",
      "Training: Epoch 28, Batch 50, Loss: 0.206\n",
      "Training: Epoch 28, Batch 51, Loss: 0.155\n",
      "Training: Epoch 28, Batch 52, Loss: 0.17\n",
      "Training: Epoch 28, Batch 53, Loss: 0.189\n",
      "Training: Epoch 28, Batch 54, Loss: 0.183\n",
      "Training: Epoch 28, Batch 55, Loss: 0.194\n",
      "Training: Epoch 28, Batch 56, Loss: 0.186\n",
      "Training: Epoch 28, Batch 57, Loss: 0.232\n",
      "Training: Epoch 28, Batch 58, Loss: 0.211\n",
      "Training: Epoch 28, Batch 59, Loss: 0.204\n",
      "Val: Epoch 28, Loss: 0.241\n",
      "Training: Epoch 29, Batch 0, Loss: 0.189\n",
      "Training: Epoch 29, Batch 1, Loss: 0.197\n",
      "Training: Epoch 29, Batch 2, Loss: 0.147\n",
      "Training: Epoch 29, Batch 3, Loss: 0.216\n",
      "Training: Epoch 29, Batch 4, Loss: 0.175\n",
      "Training: Epoch 29, Batch 5, Loss: 0.125\n",
      "Training: Epoch 29, Batch 6, Loss: 0.209\n",
      "Training: Epoch 29, Batch 7, Loss: 0.178\n",
      "Training: Epoch 29, Batch 8, Loss: 0.173\n",
      "Training: Epoch 29, Batch 9, Loss: 0.169\n",
      "Training: Epoch 29, Batch 10, Loss: 0.197\n",
      "Training: Epoch 29, Batch 11, Loss: 0.181\n",
      "Training: Epoch 29, Batch 12, Loss: 0.191\n",
      "Training: Epoch 29, Batch 13, Loss: 0.197\n",
      "Training: Epoch 29, Batch 14, Loss: 0.15\n",
      "Training: Epoch 29, Batch 15, Loss: 0.174\n",
      "Training: Epoch 29, Batch 16, Loss: 0.24\n",
      "Training: Epoch 29, Batch 17, Loss: 0.196\n",
      "Training: Epoch 29, Batch 18, Loss: 0.187\n",
      "Training: Epoch 29, Batch 19, Loss: 0.265\n",
      "Training: Epoch 29, Batch 20, Loss: 0.203\n",
      "Training: Epoch 29, Batch 21, Loss: 0.175\n",
      "Training: Epoch 29, Batch 22, Loss: 0.229\n",
      "Training: Epoch 29, Batch 23, Loss: 0.295\n",
      "Training: Epoch 29, Batch 24, Loss: 0.179\n",
      "Training: Epoch 29, Batch 25, Loss: 0.203\n",
      "Training: Epoch 29, Batch 26, Loss: 0.273\n",
      "Training: Epoch 29, Batch 27, Loss: 0.272\n",
      "Training: Epoch 29, Batch 28, Loss: 0.152\n",
      "Training: Epoch 29, Batch 29, Loss: 0.17\n",
      "Training: Epoch 29, Batch 30, Loss: 0.249\n",
      "Training: Epoch 29, Batch 31, Loss: 0.21\n",
      "Training: Epoch 29, Batch 32, Loss: 0.193\n",
      "Training: Epoch 29, Batch 33, Loss: 0.169\n",
      "Training: Epoch 29, Batch 34, Loss: 0.249\n",
      "Training: Epoch 29, Batch 35, Loss: 0.138\n",
      "Training: Epoch 29, Batch 36, Loss: 0.194\n",
      "Training: Epoch 29, Batch 37, Loss: 0.151\n",
      "Training: Epoch 29, Batch 38, Loss: 0.154\n",
      "Training: Epoch 29, Batch 39, Loss: 0.167\n",
      "Training: Epoch 29, Batch 40, Loss: 0.283\n",
      "Training: Epoch 29, Batch 41, Loss: 0.196\n",
      "Training: Epoch 29, Batch 42, Loss: 0.154\n",
      "Training: Epoch 29, Batch 43, Loss: 0.335\n",
      "Training: Epoch 29, Batch 44, Loss: 0.226\n",
      "Training: Epoch 29, Batch 45, Loss: 0.213\n",
      "Training: Epoch 29, Batch 46, Loss: 0.175\n",
      "Training: Epoch 29, Batch 47, Loss: 0.281\n",
      "Training: Epoch 29, Batch 48, Loss: 0.224\n",
      "Training: Epoch 29, Batch 49, Loss: 0.136\n",
      "Training: Epoch 29, Batch 50, Loss: 0.221\n",
      "Training: Epoch 29, Batch 51, Loss: 0.136\n",
      "Training: Epoch 29, Batch 52, Loss: 0.21\n",
      "Training: Epoch 29, Batch 53, Loss: 0.18\n",
      "Training: Epoch 29, Batch 54, Loss: 0.188\n",
      "Training: Epoch 29, Batch 55, Loss: 0.184\n",
      "Training: Epoch 29, Batch 56, Loss: 0.211\n",
      "Training: Epoch 29, Batch 57, Loss: 0.198\n",
      "Training: Epoch 29, Batch 58, Loss: 0.202\n",
      "Training: Epoch 29, Batch 59, Loss: 0.168\n",
      "Val: Epoch 29, Loss: 0.221\n",
      "Training: Epoch 30, Batch 0, Loss: 0.225\n",
      "Training: Epoch 30, Batch 1, Loss: 0.168\n",
      "Training: Epoch 30, Batch 2, Loss: 0.251\n",
      "Training: Epoch 30, Batch 3, Loss: 0.244\n",
      "Training: Epoch 30, Batch 4, Loss: 0.152\n",
      "Training: Epoch 30, Batch 5, Loss: 0.211\n",
      "Training: Epoch 30, Batch 6, Loss: 0.264\n",
      "Training: Epoch 30, Batch 7, Loss: 0.258\n",
      "Training: Epoch 30, Batch 8, Loss: 0.186\n",
      "Training: Epoch 30, Batch 9, Loss: 0.186\n",
      "Training: Epoch 30, Batch 10, Loss: 0.316\n",
      "Training: Epoch 30, Batch 11, Loss: 0.233\n",
      "Training: Epoch 30, Batch 12, Loss: 0.208\n",
      "Training: Epoch 30, Batch 13, Loss: 0.201\n",
      "Training: Epoch 30, Batch 14, Loss: 0.185\n",
      "Training: Epoch 30, Batch 15, Loss: 0.158\n",
      "Training: Epoch 30, Batch 16, Loss: 0.199\n",
      "Training: Epoch 30, Batch 17, Loss: 0.24\n",
      "Training: Epoch 30, Batch 18, Loss: 0.238\n",
      "Training: Epoch 30, Batch 19, Loss: 0.276\n",
      "Training: Epoch 30, Batch 20, Loss: 0.291\n",
      "Training: Epoch 30, Batch 21, Loss: 0.222\n",
      "Training: Epoch 30, Batch 22, Loss: 0.192\n",
      "Training: Epoch 30, Batch 23, Loss: 0.204\n",
      "Training: Epoch 30, Batch 24, Loss: 0.232\n",
      "Training: Epoch 30, Batch 25, Loss: 0.194\n",
      "Training: Epoch 30, Batch 26, Loss: 0.201\n",
      "Training: Epoch 30, Batch 27, Loss: 0.273\n",
      "Training: Epoch 30, Batch 28, Loss: 0.198\n",
      "Training: Epoch 30, Batch 29, Loss: 0.193\n",
      "Training: Epoch 30, Batch 30, Loss: 0.239\n",
      "Training: Epoch 30, Batch 31, Loss: 0.278\n",
      "Training: Epoch 30, Batch 32, Loss: 0.16\n",
      "Training: Epoch 30, Batch 33, Loss: 0.177\n",
      "Training: Epoch 30, Batch 34, Loss: 0.218\n",
      "Training: Epoch 30, Batch 35, Loss: 0.234\n",
      "Training: Epoch 30, Batch 36, Loss: 0.193\n",
      "Training: Epoch 30, Batch 37, Loss: 0.228\n",
      "Training: Epoch 30, Batch 38, Loss: 0.247\n",
      "Training: Epoch 30, Batch 39, Loss: 0.192\n",
      "Training: Epoch 30, Batch 40, Loss: 0.167\n",
      "Training: Epoch 30, Batch 41, Loss: 0.188\n",
      "Training: Epoch 30, Batch 42, Loss: 0.145\n",
      "Training: Epoch 30, Batch 43, Loss: 0.199\n",
      "Training: Epoch 30, Batch 44, Loss: 0.176\n",
      "Training: Epoch 30, Batch 45, Loss: 0.182\n",
      "Training: Epoch 30, Batch 46, Loss: 0.263\n",
      "Training: Epoch 30, Batch 47, Loss: 0.13\n",
      "Training: Epoch 30, Batch 48, Loss: 0.238\n",
      "Training: Epoch 30, Batch 49, Loss: 0.135\n",
      "Training: Epoch 30, Batch 50, Loss: 0.216\n",
      "Training: Epoch 30, Batch 51, Loss: 0.168\n",
      "Training: Epoch 30, Batch 52, Loss: 0.175\n",
      "Training: Epoch 30, Batch 53, Loss: 0.17\n",
      "Training: Epoch 30, Batch 54, Loss: 0.202\n",
      "Training: Epoch 30, Batch 55, Loss: 0.152\n",
      "Training: Epoch 30, Batch 56, Loss: 0.179\n",
      "Training: Epoch 30, Batch 57, Loss: 0.174\n",
      "Training: Epoch 30, Batch 58, Loss: 0.228\n",
      "Training: Epoch 30, Batch 59, Loss: 0.146\n",
      "Val: Epoch 30, Loss: 0.253\n",
      "Training: Epoch 31, Batch 0, Loss: 0.186\n",
      "Training: Epoch 31, Batch 1, Loss: 0.168\n",
      "Training: Epoch 31, Batch 2, Loss: 0.19\n",
      "Training: Epoch 31, Batch 3, Loss: 0.169\n",
      "Training: Epoch 31, Batch 4, Loss: 0.193\n",
      "Training: Epoch 31, Batch 5, Loss: 0.242\n",
      "Training: Epoch 31, Batch 6, Loss: 0.178\n",
      "Training: Epoch 31, Batch 7, Loss: 0.159\n",
      "Training: Epoch 31, Batch 8, Loss: 0.181\n",
      "Training: Epoch 31, Batch 9, Loss: 0.125\n",
      "Training: Epoch 31, Batch 10, Loss: 0.158\n",
      "Training: Epoch 31, Batch 11, Loss: 0.162\n",
      "Training: Epoch 31, Batch 12, Loss: 0.154\n",
      "Training: Epoch 31, Batch 13, Loss: 0.159\n",
      "Training: Epoch 31, Batch 14, Loss: 0.178\n",
      "Training: Epoch 31, Batch 15, Loss: 0.176\n",
      "Training: Epoch 31, Batch 16, Loss: 0.196\n",
      "Training: Epoch 31, Batch 17, Loss: 0.191\n",
      "Training: Epoch 31, Batch 18, Loss: 0.155\n",
      "Training: Epoch 31, Batch 19, Loss: 0.154\n",
      "Training: Epoch 31, Batch 20, Loss: 0.169\n",
      "Training: Epoch 31, Batch 21, Loss: 0.174\n",
      "Training: Epoch 31, Batch 22, Loss: 0.181\n",
      "Training: Epoch 31, Batch 23, Loss: 0.198\n",
      "Training: Epoch 31, Batch 24, Loss: 0.19\n",
      "Training: Epoch 31, Batch 25, Loss: 0.137\n",
      "Training: Epoch 31, Batch 26, Loss: 0.173\n",
      "Training: Epoch 31, Batch 27, Loss: 0.227\n",
      "Training: Epoch 31, Batch 28, Loss: 0.235\n",
      "Training: Epoch 31, Batch 29, Loss: 0.158\n",
      "Training: Epoch 31, Batch 30, Loss: 0.179\n",
      "Training: Epoch 31, Batch 31, Loss: 0.194\n",
      "Training: Epoch 31, Batch 32, Loss: 0.166\n",
      "Training: Epoch 31, Batch 33, Loss: 0.169\n",
      "Training: Epoch 31, Batch 34, Loss: 0.179\n",
      "Training: Epoch 31, Batch 35, Loss: 0.152\n",
      "Training: Epoch 31, Batch 36, Loss: 0.206\n",
      "Training: Epoch 31, Batch 37, Loss: 0.202\n",
      "Training: Epoch 31, Batch 38, Loss: 0.143\n",
      "Training: Epoch 31, Batch 39, Loss: 0.219\n",
      "Training: Epoch 31, Batch 40, Loss: 0.145\n",
      "Training: Epoch 31, Batch 41, Loss: 0.19\n",
      "Training: Epoch 31, Batch 42, Loss: 0.212\n",
      "Training: Epoch 31, Batch 43, Loss: 0.161\n",
      "Training: Epoch 31, Batch 44, Loss: 0.13\n",
      "Training: Epoch 31, Batch 45, Loss: 0.196\n",
      "Training: Epoch 31, Batch 46, Loss: 0.324\n",
      "Training: Epoch 31, Batch 47, Loss: 0.192\n",
      "Training: Epoch 31, Batch 48, Loss: 0.16\n",
      "Training: Epoch 31, Batch 49, Loss: 0.153\n",
      "Training: Epoch 31, Batch 50, Loss: 0.23\n",
      "Training: Epoch 31, Batch 51, Loss: 0.155\n",
      "Training: Epoch 31, Batch 52, Loss: 0.177\n",
      "Training: Epoch 31, Batch 53, Loss: 0.152\n",
      "Training: Epoch 31, Batch 54, Loss: 0.232\n",
      "Training: Epoch 31, Batch 55, Loss: 0.195\n",
      "Training: Epoch 31, Batch 56, Loss: 0.191\n",
      "Training: Epoch 31, Batch 57, Loss: 0.193\n",
      "Training: Epoch 31, Batch 58, Loss: 0.18\n",
      "Training: Epoch 31, Batch 59, Loss: 0.192\n",
      "Val: Epoch 31, Loss: 0.232\n",
      "Training: Epoch 32, Batch 0, Loss: 0.257\n",
      "Training: Epoch 32, Batch 1, Loss: 0.192\n",
      "Training: Epoch 32, Batch 2, Loss: 0.171\n",
      "Training: Epoch 32, Batch 3, Loss: 0.192\n",
      "Training: Epoch 32, Batch 4, Loss: 0.172\n",
      "Training: Epoch 32, Batch 5, Loss: 0.146\n",
      "Training: Epoch 32, Batch 6, Loss: 0.192\n",
      "Training: Epoch 32, Batch 7, Loss: 0.158\n",
      "Training: Epoch 32, Batch 8, Loss: 0.141\n",
      "Training: Epoch 32, Batch 9, Loss: 0.164\n",
      "Training: Epoch 32, Batch 10, Loss: 0.231\n",
      "Training: Epoch 32, Batch 11, Loss: 0.226\n",
      "Training: Epoch 32, Batch 12, Loss: 0.154\n",
      "Training: Epoch 32, Batch 13, Loss: 0.117\n",
      "Training: Epoch 32, Batch 14, Loss: 0.191\n",
      "Training: Epoch 32, Batch 15, Loss: 0.145\n",
      "Training: Epoch 32, Batch 16, Loss: 0.176\n",
      "Training: Epoch 32, Batch 17, Loss: 0.195\n",
      "Training: Epoch 32, Batch 18, Loss: 0.214\n",
      "Training: Epoch 32, Batch 19, Loss: 0.182\n",
      "Training: Epoch 32, Batch 20, Loss: 0.163\n",
      "Training: Epoch 32, Batch 21, Loss: 0.214\n",
      "Training: Epoch 32, Batch 22, Loss: 0.171\n",
      "Training: Epoch 32, Batch 23, Loss: 0.158\n",
      "Training: Epoch 32, Batch 24, Loss: 0.198\n",
      "Training: Epoch 32, Batch 25, Loss: 0.2\n",
      "Training: Epoch 32, Batch 26, Loss: 0.221\n",
      "Training: Epoch 32, Batch 27, Loss: 0.24\n",
      "Training: Epoch 32, Batch 28, Loss: 0.15\n",
      "Training: Epoch 32, Batch 29, Loss: 0.167\n",
      "Training: Epoch 32, Batch 30, Loss: 0.175\n",
      "Training: Epoch 32, Batch 31, Loss: 0.219\n",
      "Training: Epoch 32, Batch 32, Loss: 0.157\n",
      "Training: Epoch 32, Batch 33, Loss: 0.176\n",
      "Training: Epoch 32, Batch 34, Loss: 0.204\n",
      "Training: Epoch 32, Batch 35, Loss: 0.165\n",
      "Training: Epoch 32, Batch 36, Loss: 0.167\n",
      "Training: Epoch 32, Batch 37, Loss: 0.174\n",
      "Training: Epoch 32, Batch 38, Loss: 0.205\n",
      "Training: Epoch 32, Batch 39, Loss: 0.236\n",
      "Training: Epoch 32, Batch 40, Loss: 0.154\n",
      "Training: Epoch 32, Batch 41, Loss: 0.221\n",
      "Training: Epoch 32, Batch 42, Loss: 0.23\n",
      "Training: Epoch 32, Batch 43, Loss: 0.159\n",
      "Training: Epoch 32, Batch 44, Loss: 0.179\n",
      "Training: Epoch 32, Batch 45, Loss: 0.18\n",
      "Training: Epoch 32, Batch 46, Loss: 0.145\n",
      "Training: Epoch 32, Batch 47, Loss: 0.177\n",
      "Training: Epoch 32, Batch 48, Loss: 0.236\n",
      "Training: Epoch 32, Batch 49, Loss: 0.133\n",
      "Training: Epoch 32, Batch 50, Loss: 0.261\n",
      "Training: Epoch 32, Batch 51, Loss: 0.238\n",
      "Training: Epoch 32, Batch 52, Loss: 0.142\n",
      "Training: Epoch 32, Batch 53, Loss: 0.15\n",
      "Training: Epoch 32, Batch 54, Loss: 0.154\n",
      "Training: Epoch 32, Batch 55, Loss: 0.217\n",
      "Training: Epoch 32, Batch 56, Loss: 0.143\n",
      "Training: Epoch 32, Batch 57, Loss: 0.161\n",
      "Training: Epoch 32, Batch 58, Loss: 0.193\n",
      "Training: Epoch 32, Batch 59, Loss: 0.247\n",
      "Val: Epoch 32, Loss: 0.216\n",
      "Training: Epoch 33, Batch 0, Loss: 0.145\n",
      "Training: Epoch 33, Batch 1, Loss: 0.158\n",
      "Training: Epoch 33, Batch 2, Loss: 0.232\n",
      "Training: Epoch 33, Batch 3, Loss: 0.168\n",
      "Training: Epoch 33, Batch 4, Loss: 0.151\n",
      "Training: Epoch 33, Batch 5, Loss: 0.225\n",
      "Training: Epoch 33, Batch 6, Loss: 0.181\n",
      "Training: Epoch 33, Batch 7, Loss: 0.207\n",
      "Training: Epoch 33, Batch 8, Loss: 0.148\n",
      "Training: Epoch 33, Batch 9, Loss: 0.185\n",
      "Training: Epoch 33, Batch 10, Loss: 0.219\n",
      "Training: Epoch 33, Batch 11, Loss: 0.218\n",
      "Training: Epoch 33, Batch 12, Loss: 0.19\n",
      "Training: Epoch 33, Batch 13, Loss: 0.227\n",
      "Training: Epoch 33, Batch 14, Loss: 0.153\n",
      "Training: Epoch 33, Batch 15, Loss: 0.16\n",
      "Training: Epoch 33, Batch 16, Loss: 0.21\n",
      "Training: Epoch 33, Batch 17, Loss: 0.144\n",
      "Training: Epoch 33, Batch 18, Loss: 0.141\n",
      "Training: Epoch 33, Batch 19, Loss: 0.169\n",
      "Training: Epoch 33, Batch 20, Loss: 0.183\n",
      "Training: Epoch 33, Batch 21, Loss: 0.216\n",
      "Training: Epoch 33, Batch 22, Loss: 0.138\n",
      "Training: Epoch 33, Batch 23, Loss: 0.201\n",
      "Training: Epoch 33, Batch 24, Loss: 0.156\n",
      "Training: Epoch 33, Batch 25, Loss: 0.169\n",
      "Training: Epoch 33, Batch 26, Loss: 0.172\n",
      "Training: Epoch 33, Batch 27, Loss: 0.172\n",
      "Training: Epoch 33, Batch 28, Loss: 0.166\n",
      "Training: Epoch 33, Batch 29, Loss: 0.196\n",
      "Training: Epoch 33, Batch 30, Loss: 0.247\n",
      "Training: Epoch 33, Batch 31, Loss: 0.192\n",
      "Training: Epoch 33, Batch 32, Loss: 0.183\n",
      "Training: Epoch 33, Batch 33, Loss: 0.164\n",
      "Training: Epoch 33, Batch 34, Loss: 0.188\n",
      "Training: Epoch 33, Batch 35, Loss: 0.17\n",
      "Training: Epoch 33, Batch 36, Loss: 0.22\n",
      "Training: Epoch 33, Batch 37, Loss: 0.215\n",
      "Training: Epoch 33, Batch 38, Loss: 0.13\n",
      "Training: Epoch 33, Batch 39, Loss: 0.163\n",
      "Training: Epoch 33, Batch 40, Loss: 0.138\n",
      "Training: Epoch 33, Batch 41, Loss: 0.144\n",
      "Training: Epoch 33, Batch 42, Loss: 0.189\n",
      "Training: Epoch 33, Batch 43, Loss: 0.229\n",
      "Training: Epoch 33, Batch 44, Loss: 0.196\n",
      "Training: Epoch 33, Batch 45, Loss: 0.196\n",
      "Training: Epoch 33, Batch 46, Loss: 0.219\n",
      "Training: Epoch 33, Batch 47, Loss: 0.137\n",
      "Training: Epoch 33, Batch 48, Loss: 0.172\n",
      "Training: Epoch 33, Batch 49, Loss: 0.136\n",
      "Training: Epoch 33, Batch 50, Loss: 0.314\n",
      "Training: Epoch 33, Batch 51, Loss: 0.206\n",
      "Training: Epoch 33, Batch 52, Loss: 0.218\n",
      "Training: Epoch 33, Batch 53, Loss: 0.148\n",
      "Training: Epoch 33, Batch 54, Loss: 0.175\n",
      "Training: Epoch 33, Batch 55, Loss: 0.157\n",
      "Training: Epoch 33, Batch 56, Loss: 0.163\n",
      "Training: Epoch 33, Batch 57, Loss: 0.171\n",
      "Training: Epoch 33, Batch 58, Loss: 0.133\n",
      "Training: Epoch 33, Batch 59, Loss: 0.233\n",
      "Val: Epoch 33, Loss: 0.234\n",
      "Training: Epoch 34, Batch 0, Loss: 0.191\n",
      "Training: Epoch 34, Batch 1, Loss: 0.141\n",
      "Training: Epoch 34, Batch 2, Loss: 0.24\n",
      "Training: Epoch 34, Batch 3, Loss: 0.175\n",
      "Training: Epoch 34, Batch 4, Loss: 0.166\n",
      "Training: Epoch 34, Batch 5, Loss: 0.145\n",
      "Training: Epoch 34, Batch 6, Loss: 0.132\n",
      "Training: Epoch 34, Batch 7, Loss: 0.164\n",
      "Training: Epoch 34, Batch 8, Loss: 0.126\n",
      "Training: Epoch 34, Batch 9, Loss: 0.207\n",
      "Training: Epoch 34, Batch 10, Loss: 0.162\n",
      "Training: Epoch 34, Batch 11, Loss: 0.215\n",
      "Training: Epoch 34, Batch 12, Loss: 0.202\n",
      "Training: Epoch 34, Batch 13, Loss: 0.172\n",
      "Training: Epoch 34, Batch 14, Loss: 0.203\n",
      "Training: Epoch 34, Batch 15, Loss: 0.15\n",
      "Training: Epoch 34, Batch 16, Loss: 0.156\n",
      "Training: Epoch 34, Batch 17, Loss: 0.178\n",
      "Training: Epoch 34, Batch 18, Loss: 0.181\n",
      "Training: Epoch 34, Batch 19, Loss: 0.144\n",
      "Training: Epoch 34, Batch 20, Loss: 0.126\n",
      "Training: Epoch 34, Batch 21, Loss: 0.185\n",
      "Training: Epoch 34, Batch 22, Loss: 0.19\n",
      "Training: Epoch 34, Batch 23, Loss: 0.145\n",
      "Training: Epoch 34, Batch 24, Loss: 0.197\n",
      "Training: Epoch 34, Batch 25, Loss: 0.174\n",
      "Training: Epoch 34, Batch 26, Loss: 0.157\n",
      "Training: Epoch 34, Batch 27, Loss: 0.196\n",
      "Training: Epoch 34, Batch 28, Loss: 0.225\n",
      "Training: Epoch 34, Batch 29, Loss: 0.144\n",
      "Training: Epoch 34, Batch 30, Loss: 0.168\n",
      "Training: Epoch 34, Batch 31, Loss: 0.149\n",
      "Training: Epoch 34, Batch 32, Loss: 0.166\n",
      "Training: Epoch 34, Batch 33, Loss: 0.125\n",
      "Training: Epoch 34, Batch 34, Loss: 0.171\n",
      "Training: Epoch 34, Batch 35, Loss: 0.171\n",
      "Training: Epoch 34, Batch 36, Loss: 0.201\n",
      "Training: Epoch 34, Batch 37, Loss: 0.254\n",
      "Training: Epoch 34, Batch 38, Loss: 0.151\n",
      "Training: Epoch 34, Batch 39, Loss: 0.241\n",
      "Training: Epoch 34, Batch 40, Loss: 0.149\n",
      "Training: Epoch 34, Batch 41, Loss: 0.213\n",
      "Training: Epoch 34, Batch 42, Loss: 0.206\n",
      "Training: Epoch 34, Batch 43, Loss: 0.188\n",
      "Training: Epoch 34, Batch 44, Loss: 0.186\n",
      "Training: Epoch 34, Batch 45, Loss: 0.165\n",
      "Training: Epoch 34, Batch 46, Loss: 0.271\n",
      "Training: Epoch 34, Batch 47, Loss: 0.205\n",
      "Training: Epoch 34, Batch 48, Loss: 0.171\n",
      "Training: Epoch 34, Batch 49, Loss: 0.185\n",
      "Training: Epoch 34, Batch 50, Loss: 0.204\n",
      "Training: Epoch 34, Batch 51, Loss: 0.123\n",
      "Training: Epoch 34, Batch 52, Loss: 0.138\n",
      "Training: Epoch 34, Batch 53, Loss: 0.181\n",
      "Training: Epoch 34, Batch 54, Loss: 0.2\n",
      "Training: Epoch 34, Batch 55, Loss: 0.223\n",
      "Training: Epoch 34, Batch 56, Loss: 0.158\n",
      "Training: Epoch 34, Batch 57, Loss: 0.215\n",
      "Training: Epoch 34, Batch 58, Loss: 0.178\n",
      "Training: Epoch 34, Batch 59, Loss: 0.16\n",
      "Val: Epoch 34, Loss: 0.225\n",
      "Training: Epoch 35, Batch 0, Loss: 0.166\n",
      "Training: Epoch 35, Batch 1, Loss: 0.174\n",
      "Training: Epoch 35, Batch 2, Loss: 0.125\n",
      "Training: Epoch 35, Batch 3, Loss: 0.199\n",
      "Training: Epoch 35, Batch 4, Loss: 0.192\n",
      "Training: Epoch 35, Batch 5, Loss: 0.139\n",
      "Training: Epoch 35, Batch 6, Loss: 0.191\n",
      "Training: Epoch 35, Batch 7, Loss: 0.137\n",
      "Training: Epoch 35, Batch 8, Loss: 0.201\n",
      "Training: Epoch 35, Batch 9, Loss: 0.21\n",
      "Training: Epoch 35, Batch 10, Loss: 0.164\n",
      "Training: Epoch 35, Batch 11, Loss: 0.152\n",
      "Training: Epoch 35, Batch 12, Loss: 0.224\n",
      "Training: Epoch 35, Batch 13, Loss: 0.164\n",
      "Training: Epoch 35, Batch 14, Loss: 0.195\n",
      "Training: Epoch 35, Batch 15, Loss: 0.248\n",
      "Training: Epoch 35, Batch 16, Loss: 0.146\n",
      "Training: Epoch 35, Batch 17, Loss: 0.18\n",
      "Training: Epoch 35, Batch 18, Loss: 0.182\n",
      "Training: Epoch 35, Batch 19, Loss: 0.177\n",
      "Training: Epoch 35, Batch 20, Loss: 0.17\n",
      "Training: Epoch 35, Batch 21, Loss: 0.122\n",
      "Training: Epoch 35, Batch 22, Loss: 0.185\n",
      "Training: Epoch 35, Batch 23, Loss: 0.123\n",
      "Training: Epoch 35, Batch 24, Loss: 0.13\n",
      "Training: Epoch 35, Batch 25, Loss: 0.201\n",
      "Training: Epoch 35, Batch 26, Loss: 0.153\n",
      "Training: Epoch 35, Batch 27, Loss: 0.161\n",
      "Training: Epoch 35, Batch 28, Loss: 0.172\n",
      "Training: Epoch 35, Batch 29, Loss: 0.183\n",
      "Training: Epoch 35, Batch 30, Loss: 0.175\n",
      "Training: Epoch 35, Batch 31, Loss: 0.197\n",
      "Training: Epoch 35, Batch 32, Loss: 0.179\n",
      "Training: Epoch 35, Batch 33, Loss: 0.167\n",
      "Training: Epoch 35, Batch 34, Loss: 0.171\n",
      "Training: Epoch 35, Batch 35, Loss: 0.152\n",
      "Training: Epoch 35, Batch 36, Loss: 0.159\n",
      "Training: Epoch 35, Batch 37, Loss: 0.186\n",
      "Training: Epoch 35, Batch 38, Loss: 0.186\n",
      "Training: Epoch 35, Batch 39, Loss: 0.168\n",
      "Training: Epoch 35, Batch 40, Loss: 0.179\n",
      "Training: Epoch 35, Batch 41, Loss: 0.142\n",
      "Training: Epoch 35, Batch 42, Loss: 0.245\n",
      "Training: Epoch 35, Batch 43, Loss: 0.225\n",
      "Training: Epoch 35, Batch 44, Loss: 0.191\n",
      "Training: Epoch 35, Batch 45, Loss: 0.188\n",
      "Training: Epoch 35, Batch 46, Loss: 0.198\n",
      "Training: Epoch 35, Batch 47, Loss: 0.142\n",
      "Training: Epoch 35, Batch 48, Loss: 0.182\n",
      "Training: Epoch 35, Batch 49, Loss: 0.186\n",
      "Training: Epoch 35, Batch 50, Loss: 0.161\n",
      "Training: Epoch 35, Batch 51, Loss: 0.157\n",
      "Training: Epoch 35, Batch 52, Loss: 0.162\n",
      "Training: Epoch 35, Batch 53, Loss: 0.201\n",
      "Training: Epoch 35, Batch 54, Loss: 0.148\n",
      "Training: Epoch 35, Batch 55, Loss: 0.26\n",
      "Training: Epoch 35, Batch 56, Loss: 0.184\n",
      "Training: Epoch 35, Batch 57, Loss: 0.125\n",
      "Training: Epoch 35, Batch 58, Loss: 0.197\n",
      "Training: Epoch 35, Batch 59, Loss: 0.241\n",
      "Val: Epoch 35, Loss: 0.262\n",
      "Training: Epoch 36, Batch 0, Loss: 0.173\n",
      "Training: Epoch 36, Batch 1, Loss: 0.158\n",
      "Training: Epoch 36, Batch 2, Loss: 0.154\n",
      "Training: Epoch 36, Batch 3, Loss: 0.176\n",
      "Training: Epoch 36, Batch 4, Loss: 0.226\n",
      "Training: Epoch 36, Batch 5, Loss: 0.234\n",
      "Training: Epoch 36, Batch 6, Loss: 0.144\n",
      "Training: Epoch 36, Batch 7, Loss: 0.152\n",
      "Training: Epoch 36, Batch 8, Loss: 0.176\n",
      "Training: Epoch 36, Batch 9, Loss: 0.2\n",
      "Training: Epoch 36, Batch 10, Loss: 0.15\n",
      "Training: Epoch 36, Batch 11, Loss: 0.151\n",
      "Training: Epoch 36, Batch 12, Loss: 0.185\n",
      "Training: Epoch 36, Batch 13, Loss: 0.159\n",
      "Training: Epoch 36, Batch 14, Loss: 0.128\n",
      "Training: Epoch 36, Batch 15, Loss: 0.154\n",
      "Training: Epoch 36, Batch 16, Loss: 0.166\n",
      "Training: Epoch 36, Batch 17, Loss: 0.27\n",
      "Training: Epoch 36, Batch 18, Loss: 0.151\n",
      "Training: Epoch 36, Batch 19, Loss: 0.196\n",
      "Training: Epoch 36, Batch 20, Loss: 0.146\n",
      "Training: Epoch 36, Batch 21, Loss: 0.211\n",
      "Training: Epoch 36, Batch 22, Loss: 0.189\n",
      "Training: Epoch 36, Batch 23, Loss: 0.205\n",
      "Training: Epoch 36, Batch 24, Loss: 0.224\n",
      "Training: Epoch 36, Batch 25, Loss: 0.163\n",
      "Training: Epoch 36, Batch 26, Loss: 0.207\n",
      "Training: Epoch 36, Batch 27, Loss: 0.172\n",
      "Training: Epoch 36, Batch 28, Loss: 0.162\n",
      "Training: Epoch 36, Batch 29, Loss: 0.15\n",
      "Training: Epoch 36, Batch 30, Loss: 0.141\n",
      "Training: Epoch 36, Batch 31, Loss: 0.165\n",
      "Training: Epoch 36, Batch 32, Loss: 0.156\n",
      "Training: Epoch 36, Batch 33, Loss: 0.181\n",
      "Training: Epoch 36, Batch 34, Loss: 0.143\n",
      "Training: Epoch 36, Batch 35, Loss: 0.241\n",
      "Training: Epoch 36, Batch 36, Loss: 0.151\n",
      "Training: Epoch 36, Batch 37, Loss: 0.166\n",
      "Training: Epoch 36, Batch 38, Loss: 0.221\n",
      "Training: Epoch 36, Batch 39, Loss: 0.216\n",
      "Training: Epoch 36, Batch 40, Loss: 0.172\n",
      "Training: Epoch 36, Batch 41, Loss: 0.143\n",
      "Training: Epoch 36, Batch 42, Loss: 0.207\n",
      "Training: Epoch 36, Batch 43, Loss: 0.151\n",
      "Training: Epoch 36, Batch 44, Loss: 0.153\n",
      "Training: Epoch 36, Batch 45, Loss: 0.15\n",
      "Training: Epoch 36, Batch 46, Loss: 0.168\n",
      "Training: Epoch 36, Batch 47, Loss: 0.159\n",
      "Training: Epoch 36, Batch 48, Loss: 0.214\n",
      "Training: Epoch 36, Batch 49, Loss: 0.18\n",
      "Training: Epoch 36, Batch 50, Loss: 0.139\n",
      "Training: Epoch 36, Batch 51, Loss: 0.173\n",
      "Training: Epoch 36, Batch 52, Loss: 0.198\n",
      "Training: Epoch 36, Batch 53, Loss: 0.213\n",
      "Training: Epoch 36, Batch 54, Loss: 0.176\n",
      "Training: Epoch 36, Batch 55, Loss: 0.168\n",
      "Training: Epoch 36, Batch 56, Loss: 0.164\n",
      "Training: Epoch 36, Batch 57, Loss: 0.216\n",
      "Training: Epoch 36, Batch 58, Loss: 0.133\n",
      "Training: Epoch 36, Batch 59, Loss: 0.183\n",
      "Val: Epoch 36, Loss: 0.231\n",
      "Training: Epoch 37, Batch 0, Loss: 0.176\n",
      "Training: Epoch 37, Batch 1, Loss: 0.155\n",
      "Training: Epoch 37, Batch 2, Loss: 0.2\n",
      "Training: Epoch 37, Batch 3, Loss: 0.193\n",
      "Training: Epoch 37, Batch 4, Loss: 0.144\n",
      "Training: Epoch 37, Batch 5, Loss: 0.177\n",
      "Training: Epoch 37, Batch 6, Loss: 0.153\n",
      "Training: Epoch 37, Batch 7, Loss: 0.151\n",
      "Training: Epoch 37, Batch 8, Loss: 0.225\n",
      "Training: Epoch 37, Batch 9, Loss: 0.164\n",
      "Training: Epoch 37, Batch 10, Loss: 0.166\n",
      "Training: Epoch 37, Batch 11, Loss: 0.207\n",
      "Training: Epoch 37, Batch 12, Loss: 0.219\n",
      "Training: Epoch 37, Batch 13, Loss: 0.213\n",
      "Training: Epoch 37, Batch 14, Loss: 0.144\n",
      "Training: Epoch 37, Batch 15, Loss: 0.161\n",
      "Training: Epoch 37, Batch 16, Loss: 0.162\n",
      "Training: Epoch 37, Batch 17, Loss: 0.151\n",
      "Training: Epoch 37, Batch 18, Loss: 0.155\n",
      "Training: Epoch 37, Batch 19, Loss: 0.185\n",
      "Training: Epoch 37, Batch 20, Loss: 0.166\n",
      "Training: Epoch 37, Batch 21, Loss: 0.181\n",
      "Training: Epoch 37, Batch 22, Loss: 0.205\n",
      "Training: Epoch 37, Batch 23, Loss: 0.153\n",
      "Training: Epoch 37, Batch 24, Loss: 0.118\n",
      "Training: Epoch 37, Batch 25, Loss: 0.158\n",
      "Training: Epoch 37, Batch 26, Loss: 0.151\n",
      "Training: Epoch 37, Batch 27, Loss: 0.119\n",
      "Training: Epoch 37, Batch 28, Loss: 0.212\n",
      "Training: Epoch 37, Batch 29, Loss: 0.223\n",
      "Training: Epoch 37, Batch 30, Loss: 0.166\n",
      "Training: Epoch 37, Batch 31, Loss: 0.138\n",
      "Training: Epoch 37, Batch 32, Loss: 0.189\n",
      "Training: Epoch 37, Batch 33, Loss: 0.157\n",
      "Training: Epoch 37, Batch 34, Loss: 0.256\n",
      "Training: Epoch 37, Batch 35, Loss: 0.151\n",
      "Training: Epoch 37, Batch 36, Loss: 0.147\n",
      "Training: Epoch 37, Batch 37, Loss: 0.146\n",
      "Training: Epoch 37, Batch 38, Loss: 0.164\n",
      "Training: Epoch 37, Batch 39, Loss: 0.158\n",
      "Training: Epoch 37, Batch 40, Loss: 0.166\n",
      "Training: Epoch 37, Batch 41, Loss: 0.171\n",
      "Training: Epoch 37, Batch 42, Loss: 0.136\n",
      "Training: Epoch 37, Batch 43, Loss: 0.169\n",
      "Training: Epoch 37, Batch 44, Loss: 0.169\n",
      "Training: Epoch 37, Batch 45, Loss: 0.239\n",
      "Training: Epoch 37, Batch 46, Loss: 0.207\n",
      "Training: Epoch 37, Batch 47, Loss: 0.155\n",
      "Training: Epoch 37, Batch 48, Loss: 0.208\n",
      "Training: Epoch 37, Batch 49, Loss: 0.166\n",
      "Training: Epoch 37, Batch 50, Loss: 0.167\n",
      "Training: Epoch 37, Batch 51, Loss: 0.162\n",
      "Training: Epoch 37, Batch 52, Loss: 0.166\n",
      "Training: Epoch 37, Batch 53, Loss: 0.161\n",
      "Training: Epoch 37, Batch 54, Loss: 0.156\n",
      "Training: Epoch 37, Batch 55, Loss: 0.161\n",
      "Training: Epoch 37, Batch 56, Loss: 0.17\n",
      "Training: Epoch 37, Batch 57, Loss: 0.268\n",
      "Training: Epoch 37, Batch 58, Loss: 0.197\n",
      "Training: Epoch 37, Batch 59, Loss: 0.138\n",
      "Val: Epoch 37, Loss: 0.24\n",
      "Training: Epoch 38, Batch 0, Loss: 0.168\n",
      "Training: Epoch 38, Batch 1, Loss: 0.229\n",
      "Training: Epoch 38, Batch 2, Loss: 0.183\n",
      "Training: Epoch 38, Batch 3, Loss: 0.174\n",
      "Training: Epoch 38, Batch 4, Loss: 0.17\n",
      "Training: Epoch 38, Batch 5, Loss: 0.14\n",
      "Training: Epoch 38, Batch 6, Loss: 0.155\n",
      "Training: Epoch 38, Batch 7, Loss: 0.171\n",
      "Training: Epoch 38, Batch 8, Loss: 0.164\n",
      "Training: Epoch 38, Batch 9, Loss: 0.148\n",
      "Training: Epoch 38, Batch 10, Loss: 0.212\n",
      "Training: Epoch 38, Batch 11, Loss: 0.155\n",
      "Training: Epoch 38, Batch 12, Loss: 0.184\n",
      "Training: Epoch 38, Batch 13, Loss: 0.21\n",
      "Training: Epoch 38, Batch 14, Loss: 0.158\n",
      "Training: Epoch 38, Batch 15, Loss: 0.217\n",
      "Training: Epoch 38, Batch 16, Loss: 0.204\n",
      "Training: Epoch 38, Batch 17, Loss: 0.148\n",
      "Training: Epoch 38, Batch 18, Loss: 0.16\n",
      "Training: Epoch 38, Batch 19, Loss: 0.191\n",
      "Training: Epoch 38, Batch 20, Loss: 0.169\n",
      "Training: Epoch 38, Batch 21, Loss: 0.192\n",
      "Training: Epoch 38, Batch 22, Loss: 0.123\n",
      "Training: Epoch 38, Batch 23, Loss: 0.196\n",
      "Training: Epoch 38, Batch 24, Loss: 0.209\n",
      "Training: Epoch 38, Batch 25, Loss: 0.157\n",
      "Training: Epoch 38, Batch 26, Loss: 0.208\n",
      "Training: Epoch 38, Batch 27, Loss: 0.145\n",
      "Training: Epoch 38, Batch 28, Loss: 0.186\n",
      "Training: Epoch 38, Batch 29, Loss: 0.142\n",
      "Training: Epoch 38, Batch 30, Loss: 0.108\n",
      "Training: Epoch 38, Batch 31, Loss: 0.138\n",
      "Training: Epoch 38, Batch 32, Loss: 0.165\n",
      "Training: Epoch 38, Batch 33, Loss: 0.193\n",
      "Training: Epoch 38, Batch 34, Loss: 0.157\n",
      "Training: Epoch 38, Batch 35, Loss: 0.172\n",
      "Training: Epoch 38, Batch 36, Loss: 0.212\n",
      "Training: Epoch 38, Batch 37, Loss: 0.15\n",
      "Training: Epoch 38, Batch 38, Loss: 0.19\n",
      "Training: Epoch 38, Batch 39, Loss: 0.155\n",
      "Training: Epoch 38, Batch 40, Loss: 0.156\n",
      "Training: Epoch 38, Batch 41, Loss: 0.184\n",
      "Training: Epoch 38, Batch 42, Loss: 0.262\n",
      "Training: Epoch 38, Batch 43, Loss: 0.111\n",
      "Training: Epoch 38, Batch 44, Loss: 0.168\n",
      "Training: Epoch 38, Batch 45, Loss: 0.136\n",
      "Training: Epoch 38, Batch 46, Loss: 0.146\n",
      "Training: Epoch 38, Batch 47, Loss: 0.191\n",
      "Training: Epoch 38, Batch 48, Loss: 0.228\n",
      "Training: Epoch 38, Batch 49, Loss: 0.188\n",
      "Training: Epoch 38, Batch 50, Loss: 0.133\n",
      "Training: Epoch 38, Batch 51, Loss: 0.186\n",
      "Training: Epoch 38, Batch 52, Loss: 0.182\n",
      "Training: Epoch 38, Batch 53, Loss: 0.169\n",
      "Training: Epoch 38, Batch 54, Loss: 0.197\n",
      "Training: Epoch 38, Batch 55, Loss: 0.132\n",
      "Training: Epoch 38, Batch 56, Loss: 0.158\n",
      "Training: Epoch 38, Batch 57, Loss: 0.226\n",
      "Training: Epoch 38, Batch 58, Loss: 0.205\n",
      "Training: Epoch 38, Batch 59, Loss: 0.179\n",
      "Val: Epoch 38, Loss: 0.219\n",
      "Training: Epoch 39, Batch 0, Loss: 0.24\n",
      "Training: Epoch 39, Batch 1, Loss: 0.173\n",
      "Training: Epoch 39, Batch 2, Loss: 0.148\n",
      "Training: Epoch 39, Batch 3, Loss: 0.18\n",
      "Training: Epoch 39, Batch 4, Loss: 0.172\n",
      "Training: Epoch 39, Batch 5, Loss: 0.151\n",
      "Training: Epoch 39, Batch 6, Loss: 0.197\n",
      "Training: Epoch 39, Batch 7, Loss: 0.176\n",
      "Training: Epoch 39, Batch 8, Loss: 0.142\n",
      "Training: Epoch 39, Batch 9, Loss: 0.146\n",
      "Training: Epoch 39, Batch 10, Loss: 0.148\n",
      "Training: Epoch 39, Batch 11, Loss: 0.188\n",
      "Training: Epoch 39, Batch 12, Loss: 0.23\n",
      "Training: Epoch 39, Batch 13, Loss: 0.157\n",
      "Training: Epoch 39, Batch 14, Loss: 0.124\n",
      "Training: Epoch 39, Batch 15, Loss: 0.163\n",
      "Training: Epoch 39, Batch 16, Loss: 0.204\n",
      "Training: Epoch 39, Batch 17, Loss: 0.192\n",
      "Training: Epoch 39, Batch 18, Loss: 0.199\n",
      "Training: Epoch 39, Batch 19, Loss: 0.179\n",
      "Training: Epoch 39, Batch 20, Loss: 0.169\n",
      "Training: Epoch 39, Batch 21, Loss: 0.154\n",
      "Training: Epoch 39, Batch 22, Loss: 0.176\n",
      "Training: Epoch 39, Batch 23, Loss: 0.155\n",
      "Training: Epoch 39, Batch 24, Loss: 0.176\n",
      "Training: Epoch 39, Batch 25, Loss: 0.18\n",
      "Training: Epoch 39, Batch 26, Loss: 0.158\n",
      "Training: Epoch 39, Batch 27, Loss: 0.166\n",
      "Training: Epoch 39, Batch 28, Loss: 0.141\n",
      "Training: Epoch 39, Batch 29, Loss: 0.155\n",
      "Training: Epoch 39, Batch 30, Loss: 0.184\n",
      "Training: Epoch 39, Batch 31, Loss: 0.145\n",
      "Training: Epoch 39, Batch 32, Loss: 0.204\n",
      "Training: Epoch 39, Batch 33, Loss: 0.182\n",
      "Training: Epoch 39, Batch 34, Loss: 0.172\n",
      "Training: Epoch 39, Batch 35, Loss: 0.135\n",
      "Training: Epoch 39, Batch 36, Loss: 0.231\n",
      "Training: Epoch 39, Batch 37, Loss: 0.16\n",
      "Training: Epoch 39, Batch 38, Loss: 0.219\n",
      "Training: Epoch 39, Batch 39, Loss: 0.194\n",
      "Training: Epoch 39, Batch 40, Loss: 0.144\n",
      "Training: Epoch 39, Batch 41, Loss: 0.156\n",
      "Training: Epoch 39, Batch 42, Loss: 0.186\n",
      "Training: Epoch 39, Batch 43, Loss: 0.17\n",
      "Training: Epoch 39, Batch 44, Loss: 0.17\n",
      "Training: Epoch 39, Batch 45, Loss: 0.201\n",
      "Training: Epoch 39, Batch 46, Loss: 0.18\n",
      "Training: Epoch 39, Batch 47, Loss: 0.154\n",
      "Training: Epoch 39, Batch 48, Loss: 0.156\n",
      "Training: Epoch 39, Batch 49, Loss: 0.217\n",
      "Training: Epoch 39, Batch 50, Loss: 0.146\n",
      "Training: Epoch 39, Batch 51, Loss: 0.165\n",
      "Training: Epoch 39, Batch 52, Loss: 0.215\n",
      "Training: Epoch 39, Batch 53, Loss: 0.163\n",
      "Training: Epoch 39, Batch 54, Loss: 0.203\n",
      "Training: Epoch 39, Batch 55, Loss: 0.128\n",
      "Training: Epoch 39, Batch 56, Loss: 0.141\n",
      "Training: Epoch 39, Batch 57, Loss: 0.164\n",
      "Training: Epoch 39, Batch 58, Loss: 0.247\n",
      "Training: Epoch 39, Batch 59, Loss: 0.218\n",
      "Val: Epoch 39, Loss: 0.231\n",
      "Training: Epoch 40, Batch 0, Loss: 0.309\n",
      "Training: Epoch 40, Batch 1, Loss: 0.162\n",
      "Training: Epoch 40, Batch 2, Loss: 0.155\n",
      "Training: Epoch 40, Batch 3, Loss: 0.194\n",
      "Training: Epoch 40, Batch 4, Loss: 0.197\n",
      "Training: Epoch 40, Batch 5, Loss: 0.238\n",
      "Training: Epoch 40, Batch 6, Loss: 0.207\n",
      "Training: Epoch 40, Batch 7, Loss: 0.194\n",
      "Training: Epoch 40, Batch 8, Loss: 0.197\n",
      "Training: Epoch 40, Batch 9, Loss: 0.182\n",
      "Training: Epoch 40, Batch 10, Loss: 0.133\n",
      "Training: Epoch 40, Batch 11, Loss: 0.231\n",
      "Training: Epoch 40, Batch 12, Loss: 0.137\n",
      "Training: Epoch 40, Batch 13, Loss: 0.135\n",
      "Training: Epoch 40, Batch 14, Loss: 0.183\n",
      "Training: Epoch 40, Batch 15, Loss: 0.198\n",
      "Training: Epoch 40, Batch 16, Loss: 0.261\n",
      "Training: Epoch 40, Batch 17, Loss: 0.15\n",
      "Training: Epoch 40, Batch 18, Loss: 0.214\n",
      "Training: Epoch 40, Batch 19, Loss: 0.138\n",
      "Training: Epoch 40, Batch 20, Loss: 0.167\n",
      "Training: Epoch 40, Batch 21, Loss: 0.147\n",
      "Training: Epoch 40, Batch 22, Loss: 0.162\n",
      "Training: Epoch 40, Batch 23, Loss: 0.249\n",
      "Training: Epoch 40, Batch 24, Loss: 0.144\n",
      "Training: Epoch 40, Batch 25, Loss: 0.226\n",
      "Training: Epoch 40, Batch 26, Loss: 0.24\n",
      "Training: Epoch 40, Batch 27, Loss: 0.255\n",
      "Training: Epoch 40, Batch 28, Loss: 0.301\n",
      "Training: Epoch 40, Batch 29, Loss: 0.19\n",
      "Training: Epoch 40, Batch 30, Loss: 0.182\n",
      "Training: Epoch 40, Batch 31, Loss: 0.147\n",
      "Training: Epoch 40, Batch 32, Loss: 0.359\n",
      "Training: Epoch 40, Batch 33, Loss: 0.205\n",
      "Training: Epoch 40, Batch 34, Loss: 0.183\n",
      "Training: Epoch 40, Batch 35, Loss: 0.181\n",
      "Training: Epoch 40, Batch 36, Loss: 0.19\n",
      "Training: Epoch 40, Batch 37, Loss: 0.17\n",
      "Training: Epoch 40, Batch 38, Loss: 0.161\n",
      "Training: Epoch 40, Batch 39, Loss: 0.188\n",
      "Training: Epoch 40, Batch 40, Loss: 0.205\n",
      "Training: Epoch 40, Batch 41, Loss: 0.182\n",
      "Training: Epoch 40, Batch 42, Loss: 0.147\n",
      "Training: Epoch 40, Batch 43, Loss: 0.201\n",
      "Training: Epoch 40, Batch 44, Loss: 0.2\n",
      "Training: Epoch 40, Batch 45, Loss: 0.198\n",
      "Training: Epoch 40, Batch 46, Loss: 0.144\n",
      "Training: Epoch 40, Batch 47, Loss: 0.2\n",
      "Training: Epoch 40, Batch 48, Loss: 0.158\n",
      "Training: Epoch 40, Batch 49, Loss: 0.24\n",
      "Training: Epoch 40, Batch 50, Loss: 0.181\n",
      "Training: Epoch 40, Batch 51, Loss: 0.168\n",
      "Training: Epoch 40, Batch 52, Loss: 0.145\n",
      "Training: Epoch 40, Batch 53, Loss: 0.201\n",
      "Training: Epoch 40, Batch 54, Loss: 0.204\n",
      "Training: Epoch 40, Batch 55, Loss: 0.166\n",
      "Training: Epoch 40, Batch 56, Loss: 0.208\n",
      "Training: Epoch 40, Batch 57, Loss: 0.201\n",
      "Training: Epoch 40, Batch 58, Loss: 0.21\n",
      "Training: Epoch 40, Batch 59, Loss: 0.154\n",
      "Val: Epoch 40, Loss: 0.293\n",
      "Training: Epoch 41, Batch 0, Loss: 0.202\n",
      "Training: Epoch 41, Batch 1, Loss: 0.172\n",
      "Training: Epoch 41, Batch 2, Loss: 0.186\n",
      "Training: Epoch 41, Batch 3, Loss: 0.202\n",
      "Training: Epoch 41, Batch 4, Loss: 0.272\n",
      "Training: Epoch 41, Batch 5, Loss: 0.125\n",
      "Training: Epoch 41, Batch 6, Loss: 0.24\n",
      "Training: Epoch 41, Batch 7, Loss: 0.145\n",
      "Training: Epoch 41, Batch 8, Loss: 0.15\n",
      "Training: Epoch 41, Batch 9, Loss: 0.256\n",
      "Training: Epoch 41, Batch 10, Loss: 0.198\n",
      "Training: Epoch 41, Batch 11, Loss: 0.175\n",
      "Training: Epoch 41, Batch 12, Loss: 0.235\n",
      "Training: Epoch 41, Batch 13, Loss: 0.158\n",
      "Training: Epoch 41, Batch 14, Loss: 0.178\n",
      "Training: Epoch 41, Batch 15, Loss: 0.247\n",
      "Training: Epoch 41, Batch 16, Loss: 0.161\n",
      "Training: Epoch 41, Batch 17, Loss: 0.19\n",
      "Training: Epoch 41, Batch 18, Loss: 0.249\n",
      "Training: Epoch 41, Batch 19, Loss: 0.209\n",
      "Training: Epoch 41, Batch 20, Loss: 0.216\n",
      "Training: Epoch 41, Batch 21, Loss: 0.151\n",
      "Training: Epoch 41, Batch 22, Loss: 0.149\n",
      "Training: Epoch 41, Batch 23, Loss: 0.174\n",
      "Training: Epoch 41, Batch 24, Loss: 0.142\n",
      "Training: Epoch 41, Batch 25, Loss: 0.225\n",
      "Training: Epoch 41, Batch 26, Loss: 0.25\n",
      "Training: Epoch 41, Batch 27, Loss: 0.173\n",
      "Training: Epoch 41, Batch 28, Loss: 0.192\n",
      "Training: Epoch 41, Batch 29, Loss: 0.169\n",
      "Training: Epoch 41, Batch 30, Loss: 0.139\n",
      "Training: Epoch 41, Batch 31, Loss: 0.145\n",
      "Training: Epoch 41, Batch 32, Loss: 0.168\n",
      "Training: Epoch 41, Batch 33, Loss: 0.152\n",
      "Training: Epoch 41, Batch 34, Loss: 0.202\n",
      "Training: Epoch 41, Batch 35, Loss: 0.179\n",
      "Training: Epoch 41, Batch 36, Loss: 0.225\n",
      "Training: Epoch 41, Batch 37, Loss: 0.14\n",
      "Training: Epoch 41, Batch 38, Loss: 0.156\n",
      "Training: Epoch 41, Batch 39, Loss: 0.201\n",
      "Training: Epoch 41, Batch 40, Loss: 0.147\n",
      "Training: Epoch 41, Batch 41, Loss: 0.209\n",
      "Training: Epoch 41, Batch 42, Loss: 0.203\n",
      "Training: Epoch 41, Batch 43, Loss: 0.174\n",
      "Training: Epoch 41, Batch 44, Loss: 0.17\n",
      "Training: Epoch 41, Batch 45, Loss: 0.214\n",
      "Training: Epoch 41, Batch 46, Loss: 0.144\n",
      "Training: Epoch 41, Batch 47, Loss: 0.147\n",
      "Training: Epoch 41, Batch 48, Loss: 0.208\n",
      "Training: Epoch 41, Batch 49, Loss: 0.213\n",
      "Training: Epoch 41, Batch 50, Loss: 0.152\n",
      "Training: Epoch 41, Batch 51, Loss: 0.15\n",
      "Training: Epoch 41, Batch 52, Loss: 0.183\n",
      "Training: Epoch 41, Batch 53, Loss: 0.138\n",
      "Training: Epoch 41, Batch 54, Loss: 0.131\n",
      "Training: Epoch 41, Batch 55, Loss: 0.184\n",
      "Training: Epoch 41, Batch 56, Loss: 0.16\n",
      "Training: Epoch 41, Batch 57, Loss: 0.252\n",
      "Training: Epoch 41, Batch 58, Loss: 0.139\n",
      "Training: Epoch 41, Batch 59, Loss: 0.209\n",
      "Val: Epoch 41, Loss: 0.227\n",
      "Training: Epoch 42, Batch 0, Loss: 0.135\n",
      "Training: Epoch 42, Batch 1, Loss: 0.181\n",
      "Training: Epoch 42, Batch 2, Loss: 0.16\n",
      "Training: Epoch 42, Batch 3, Loss: 0.147\n",
      "Training: Epoch 42, Batch 4, Loss: 0.217\n",
      "Training: Epoch 42, Batch 5, Loss: 0.263\n",
      "Training: Epoch 42, Batch 6, Loss: 0.161\n",
      "Training: Epoch 42, Batch 7, Loss: 0.156\n",
      "Training: Epoch 42, Batch 8, Loss: 0.162\n",
      "Training: Epoch 42, Batch 9, Loss: 0.184\n",
      "Training: Epoch 42, Batch 10, Loss: 0.141\n",
      "Training: Epoch 42, Batch 11, Loss: 0.188\n",
      "Training: Epoch 42, Batch 12, Loss: 0.208\n",
      "Training: Epoch 42, Batch 13, Loss: 0.183\n",
      "Training: Epoch 42, Batch 14, Loss: 0.149\n",
      "Training: Epoch 42, Batch 15, Loss: 0.16\n",
      "Training: Epoch 42, Batch 16, Loss: 0.151\n",
      "Training: Epoch 42, Batch 17, Loss: 0.154\n",
      "Training: Epoch 42, Batch 18, Loss: 0.137\n",
      "Training: Epoch 42, Batch 19, Loss: 0.19\n",
      "Training: Epoch 42, Batch 20, Loss: 0.146\n",
      "Training: Epoch 42, Batch 21, Loss: 0.125\n",
      "Training: Epoch 42, Batch 22, Loss: 0.147\n",
      "Training: Epoch 42, Batch 23, Loss: 0.184\n",
      "Training: Epoch 42, Batch 24, Loss: 0.155\n",
      "Training: Epoch 42, Batch 25, Loss: 0.212\n",
      "Training: Epoch 42, Batch 26, Loss: 0.148\n",
      "Training: Epoch 42, Batch 27, Loss: 0.14\n",
      "Training: Epoch 42, Batch 28, Loss: 0.145\n",
      "Training: Epoch 42, Batch 29, Loss: 0.2\n",
      "Training: Epoch 42, Batch 30, Loss: 0.149\n",
      "Training: Epoch 42, Batch 31, Loss: 0.125\n",
      "Training: Epoch 42, Batch 32, Loss: 0.153\n",
      "Training: Epoch 42, Batch 33, Loss: 0.182\n",
      "Training: Epoch 42, Batch 34, Loss: 0.271\n",
      "Training: Epoch 42, Batch 35, Loss: 0.155\n",
      "Training: Epoch 42, Batch 36, Loss: 0.202\n",
      "Training: Epoch 42, Batch 37, Loss: 0.178\n",
      "Training: Epoch 42, Batch 38, Loss: 0.166\n",
      "Training: Epoch 42, Batch 39, Loss: 0.169\n",
      "Training: Epoch 42, Batch 40, Loss: 0.158\n",
      "Training: Epoch 42, Batch 41, Loss: 0.147\n",
      "Training: Epoch 42, Batch 42, Loss: 0.182\n",
      "Training: Epoch 42, Batch 43, Loss: 0.149\n",
      "Training: Epoch 42, Batch 44, Loss: 0.196\n",
      "Training: Epoch 42, Batch 45, Loss: 0.141\n",
      "Training: Epoch 42, Batch 46, Loss: 0.154\n",
      "Training: Epoch 42, Batch 47, Loss: 0.132\n",
      "Training: Epoch 42, Batch 48, Loss: 0.203\n",
      "Training: Epoch 42, Batch 49, Loss: 0.184\n",
      "Training: Epoch 42, Batch 50, Loss: 0.162\n",
      "Training: Epoch 42, Batch 51, Loss: 0.144\n",
      "Training: Epoch 42, Batch 52, Loss: 0.226\n",
      "Training: Epoch 42, Batch 53, Loss: 0.138\n",
      "Training: Epoch 42, Batch 54, Loss: 0.124\n",
      "Training: Epoch 42, Batch 55, Loss: 0.139\n",
      "Training: Epoch 42, Batch 56, Loss: 0.198\n",
      "Training: Epoch 42, Batch 57, Loss: 0.228\n",
      "Training: Epoch 42, Batch 58, Loss: 0.174\n",
      "Training: Epoch 42, Batch 59, Loss: 0.162\n",
      "Val: Epoch 42, Loss: 0.224\n",
      "Training: Epoch 43, Batch 0, Loss: 0.171\n",
      "Training: Epoch 43, Batch 1, Loss: 0.188\n",
      "Training: Epoch 43, Batch 2, Loss: 0.195\n",
      "Training: Epoch 43, Batch 3, Loss: 0.166\n",
      "Training: Epoch 43, Batch 4, Loss: 0.183\n",
      "Training: Epoch 43, Batch 5, Loss: 0.203\n",
      "Training: Epoch 43, Batch 6, Loss: 0.25\n",
      "Training: Epoch 43, Batch 7, Loss: 0.191\n",
      "Training: Epoch 43, Batch 8, Loss: 0.174\n",
      "Training: Epoch 43, Batch 9, Loss: 0.123\n",
      "Training: Epoch 43, Batch 10, Loss: 0.18\n",
      "Training: Epoch 43, Batch 11, Loss: 0.238\n",
      "Training: Epoch 43, Batch 12, Loss: 0.141\n",
      "Training: Epoch 43, Batch 13, Loss: 0.182\n",
      "Training: Epoch 43, Batch 14, Loss: 0.108\n",
      "Training: Epoch 43, Batch 15, Loss: 0.149\n",
      "Training: Epoch 43, Batch 16, Loss: 0.175\n",
      "Training: Epoch 43, Batch 17, Loss: 0.15\n",
      "Training: Epoch 43, Batch 18, Loss: 0.168\n",
      "Training: Epoch 43, Batch 19, Loss: 0.197\n",
      "Training: Epoch 43, Batch 20, Loss: 0.183\n",
      "Training: Epoch 43, Batch 21, Loss: 0.124\n",
      "Training: Epoch 43, Batch 22, Loss: 0.158\n",
      "Training: Epoch 43, Batch 23, Loss: 0.143\n",
      "Training: Epoch 43, Batch 24, Loss: 0.209\n",
      "Training: Epoch 43, Batch 25, Loss: 0.208\n",
      "Training: Epoch 43, Batch 26, Loss: 0.233\n",
      "Training: Epoch 43, Batch 27, Loss: 0.153\n",
      "Training: Epoch 43, Batch 28, Loss: 0.159\n",
      "Training: Epoch 43, Batch 29, Loss: 0.122\n",
      "Training: Epoch 43, Batch 30, Loss: 0.149\n",
      "Training: Epoch 43, Batch 31, Loss: 0.17\n",
      "Training: Epoch 43, Batch 32, Loss: 0.164\n",
      "Training: Epoch 43, Batch 33, Loss: 0.114\n",
      "Training: Epoch 43, Batch 34, Loss: 0.111\n",
      "Training: Epoch 43, Batch 35, Loss: 0.166\n",
      "Training: Epoch 43, Batch 36, Loss: 0.153\n",
      "Training: Epoch 43, Batch 37, Loss: 0.209\n",
      "Training: Epoch 43, Batch 38, Loss: 0.136\n",
      "Training: Epoch 43, Batch 39, Loss: 0.163\n",
      "Training: Epoch 43, Batch 40, Loss: 0.146\n",
      "Training: Epoch 43, Batch 41, Loss: 0.253\n",
      "Training: Epoch 43, Batch 42, Loss: 0.148\n",
      "Training: Epoch 43, Batch 43, Loss: 0.104\n",
      "Training: Epoch 43, Batch 44, Loss: 0.176\n",
      "Training: Epoch 43, Batch 45, Loss: 0.135\n",
      "Training: Epoch 43, Batch 46, Loss: 0.142\n",
      "Training: Epoch 43, Batch 47, Loss: 0.179\n",
      "Training: Epoch 43, Batch 48, Loss: 0.201\n",
      "Training: Epoch 43, Batch 49, Loss: 0.145\n",
      "Training: Epoch 43, Batch 50, Loss: 0.241\n",
      "Training: Epoch 43, Batch 51, Loss: 0.16\n",
      "Training: Epoch 43, Batch 52, Loss: 0.147\n",
      "Training: Epoch 43, Batch 53, Loss: 0.164\n",
      "Training: Epoch 43, Batch 54, Loss: 0.142\n",
      "Training: Epoch 43, Batch 55, Loss: 0.168\n",
      "Training: Epoch 43, Batch 56, Loss: 0.147\n",
      "Training: Epoch 43, Batch 57, Loss: 0.173\n",
      "Training: Epoch 43, Batch 58, Loss: 0.15\n",
      "Training: Epoch 43, Batch 59, Loss: 0.146\n",
      "Val: Epoch 43, Loss: 0.225\n",
      "Training: Epoch 44, Batch 0, Loss: 0.208\n",
      "Training: Epoch 44, Batch 1, Loss: 0.141\n",
      "Training: Epoch 44, Batch 2, Loss: 0.228\n",
      "Training: Epoch 44, Batch 3, Loss: 0.16\n",
      "Training: Epoch 44, Batch 4, Loss: 0.202\n",
      "Training: Epoch 44, Batch 5, Loss: 0.137\n",
      "Training: Epoch 44, Batch 6, Loss: 0.134\n",
      "Training: Epoch 44, Batch 7, Loss: 0.165\n",
      "Training: Epoch 44, Batch 8, Loss: 0.194\n",
      "Training: Epoch 44, Batch 9, Loss: 0.251\n",
      "Training: Epoch 44, Batch 10, Loss: 0.137\n",
      "Training: Epoch 44, Batch 11, Loss: 0.155\n",
      "Training: Epoch 44, Batch 12, Loss: 0.18\n",
      "Training: Epoch 44, Batch 13, Loss: 0.191\n",
      "Training: Epoch 44, Batch 14, Loss: 0.134\n",
      "Training: Epoch 44, Batch 15, Loss: 0.179\n",
      "Training: Epoch 44, Batch 16, Loss: 0.135\n",
      "Training: Epoch 44, Batch 17, Loss: 0.173\n",
      "Training: Epoch 44, Batch 18, Loss: 0.131\n",
      "Training: Epoch 44, Batch 19, Loss: 0.2\n",
      "Training: Epoch 44, Batch 20, Loss: 0.162\n",
      "Training: Epoch 44, Batch 21, Loss: 0.186\n",
      "Training: Epoch 44, Batch 22, Loss: 0.137\n",
      "Training: Epoch 44, Batch 23, Loss: 0.142\n",
      "Training: Epoch 44, Batch 24, Loss: 0.136\n",
      "Training: Epoch 44, Batch 25, Loss: 0.152\n",
      "Training: Epoch 44, Batch 26, Loss: 0.14\n",
      "Training: Epoch 44, Batch 27, Loss: 0.126\n",
      "Training: Epoch 44, Batch 28, Loss: 0.185\n",
      "Training: Epoch 44, Batch 29, Loss: 0.17\n",
      "Training: Epoch 44, Batch 30, Loss: 0.156\n",
      "Training: Epoch 44, Batch 31, Loss: 0.124\n",
      "Training: Epoch 44, Batch 32, Loss: 0.236\n",
      "Training: Epoch 44, Batch 33, Loss: 0.172\n",
      "Training: Epoch 44, Batch 34, Loss: 0.143\n",
      "Training: Epoch 44, Batch 35, Loss: 0.12\n",
      "Training: Epoch 44, Batch 36, Loss: 0.198\n",
      "Training: Epoch 44, Batch 37, Loss: 0.137\n",
      "Training: Epoch 44, Batch 38, Loss: 0.112\n",
      "Training: Epoch 44, Batch 39, Loss: 0.159\n",
      "Training: Epoch 44, Batch 40, Loss: 0.152\n",
      "Training: Epoch 44, Batch 41, Loss: 0.186\n",
      "Training: Epoch 44, Batch 42, Loss: 0.202\n",
      "Training: Epoch 44, Batch 43, Loss: 0.134\n",
      "Training: Epoch 44, Batch 44, Loss: 0.147\n",
      "Training: Epoch 44, Batch 45, Loss: 0.165\n",
      "Training: Epoch 44, Batch 46, Loss: 0.183\n",
      "Training: Epoch 44, Batch 47, Loss: 0.165\n",
      "Training: Epoch 44, Batch 48, Loss: 0.124\n",
      "Training: Epoch 44, Batch 49, Loss: 0.135\n",
      "Training: Epoch 44, Batch 50, Loss: 0.146\n",
      "Training: Epoch 44, Batch 51, Loss: 0.155\n",
      "Training: Epoch 44, Batch 52, Loss: 0.158\n",
      "Training: Epoch 44, Batch 53, Loss: 0.129\n",
      "Training: Epoch 44, Batch 54, Loss: 0.155\n",
      "Training: Epoch 44, Batch 55, Loss: 0.156\n",
      "Training: Epoch 44, Batch 56, Loss: 0.195\n",
      "Training: Epoch 44, Batch 57, Loss: 0.221\n",
      "Training: Epoch 44, Batch 58, Loss: 0.185\n",
      "Training: Epoch 44, Batch 59, Loss: 0.136\n",
      "Val: Epoch 44, Loss: 0.216\n",
      "Training: Epoch 45, Batch 0, Loss: 0.143\n",
      "Training: Epoch 45, Batch 1, Loss: 0.172\n",
      "Training: Epoch 45, Batch 2, Loss: 0.123\n",
      "Training: Epoch 45, Batch 3, Loss: 0.158\n",
      "Training: Epoch 45, Batch 4, Loss: 0.136\n",
      "Training: Epoch 45, Batch 5, Loss: 0.13\n",
      "Training: Epoch 45, Batch 6, Loss: 0.132\n",
      "Training: Epoch 45, Batch 7, Loss: 0.166\n",
      "Training: Epoch 45, Batch 8, Loss: 0.173\n",
      "Training: Epoch 45, Batch 9, Loss: 0.156\n",
      "Training: Epoch 45, Batch 10, Loss: 0.153\n",
      "Training: Epoch 45, Batch 11, Loss: 0.189\n",
      "Training: Epoch 45, Batch 12, Loss: 0.154\n",
      "Training: Epoch 45, Batch 13, Loss: 0.134\n",
      "Training: Epoch 45, Batch 14, Loss: 0.127\n",
      "Training: Epoch 45, Batch 15, Loss: 0.175\n",
      "Training: Epoch 45, Batch 16, Loss: 0.161\n",
      "Training: Epoch 45, Batch 17, Loss: 0.133\n",
      "Training: Epoch 45, Batch 18, Loss: 0.161\n",
      "Training: Epoch 45, Batch 19, Loss: 0.163\n",
      "Training: Epoch 45, Batch 20, Loss: 0.262\n",
      "Training: Epoch 45, Batch 21, Loss: 0.133\n",
      "Training: Epoch 45, Batch 22, Loss: 0.19\n",
      "Training: Epoch 45, Batch 23, Loss: 0.16\n",
      "Training: Epoch 45, Batch 24, Loss: 0.15\n",
      "Training: Epoch 45, Batch 25, Loss: 0.159\n",
      "Training: Epoch 45, Batch 26, Loss: 0.173\n",
      "Training: Epoch 45, Batch 27, Loss: 0.181\n",
      "Training: Epoch 45, Batch 28, Loss: 0.258\n",
      "Training: Epoch 45, Batch 29, Loss: 0.203\n",
      "Training: Epoch 45, Batch 30, Loss: 0.186\n",
      "Training: Epoch 45, Batch 31, Loss: 0.252\n",
      "Training: Epoch 45, Batch 32, Loss: 0.141\n",
      "Training: Epoch 45, Batch 33, Loss: 0.122\n",
      "Training: Epoch 45, Batch 34, Loss: 0.169\n",
      "Training: Epoch 45, Batch 35, Loss: 0.156\n",
      "Training: Epoch 45, Batch 36, Loss: 0.145\n",
      "Training: Epoch 45, Batch 37, Loss: 0.22\n",
      "Training: Epoch 45, Batch 38, Loss: 0.169\n",
      "Training: Epoch 45, Batch 39, Loss: 0.226\n",
      "Training: Epoch 45, Batch 40, Loss: 0.123\n",
      "Training: Epoch 45, Batch 41, Loss: 0.18\n",
      "Training: Epoch 45, Batch 42, Loss: 0.259\n",
      "Training: Epoch 45, Batch 43, Loss: 0.187\n",
      "Training: Epoch 45, Batch 44, Loss: 0.123\n",
      "Training: Epoch 45, Batch 45, Loss: 0.135\n",
      "Training: Epoch 45, Batch 46, Loss: 0.196\n",
      "Training: Epoch 45, Batch 47, Loss: 0.136\n",
      "Training: Epoch 45, Batch 48, Loss: 0.142\n",
      "Training: Epoch 45, Batch 49, Loss: 0.174\n",
      "Training: Epoch 45, Batch 50, Loss: 0.195\n",
      "Training: Epoch 45, Batch 51, Loss: 0.16\n",
      "Training: Epoch 45, Batch 52, Loss: 0.186\n",
      "Training: Epoch 45, Batch 53, Loss: 0.169\n",
      "Training: Epoch 45, Batch 54, Loss: 0.212\n",
      "Training: Epoch 45, Batch 55, Loss: 0.158\n",
      "Training: Epoch 45, Batch 56, Loss: 0.112\n",
      "Training: Epoch 45, Batch 57, Loss: 0.185\n",
      "Training: Epoch 45, Batch 58, Loss: 0.185\n",
      "Training: Epoch 45, Batch 59, Loss: 0.155\n",
      "Val: Epoch 45, Loss: 0.393\n",
      "Training: Epoch 46, Batch 0, Loss: 0.15\n",
      "Training: Epoch 46, Batch 1, Loss: 0.12\n",
      "Training: Epoch 46, Batch 2, Loss: 0.117\n",
      "Training: Epoch 46, Batch 3, Loss: 0.243\n",
      "Training: Epoch 46, Batch 4, Loss: 0.182\n",
      "Training: Epoch 46, Batch 5, Loss: 0.138\n",
      "Training: Epoch 46, Batch 6, Loss: 0.12\n",
      "Training: Epoch 46, Batch 7, Loss: 0.168\n",
      "Training: Epoch 46, Batch 8, Loss: 0.13\n",
      "Training: Epoch 46, Batch 9, Loss: 0.141\n",
      "Training: Epoch 46, Batch 10, Loss: 0.174\n",
      "Training: Epoch 46, Batch 11, Loss: 0.203\n",
      "Training: Epoch 46, Batch 12, Loss: 0.133\n",
      "Training: Epoch 46, Batch 13, Loss: 0.18\n",
      "Training: Epoch 46, Batch 14, Loss: 0.181\n",
      "Training: Epoch 46, Batch 15, Loss: 0.139\n",
      "Training: Epoch 46, Batch 16, Loss: 0.208\n",
      "Training: Epoch 46, Batch 17, Loss: 0.18\n",
      "Training: Epoch 46, Batch 18, Loss: 0.213\n",
      "Training: Epoch 46, Batch 19, Loss: 0.156\n",
      "Training: Epoch 46, Batch 20, Loss: 0.147\n",
      "Training: Epoch 46, Batch 21, Loss: 0.187\n",
      "Training: Epoch 46, Batch 22, Loss: 0.156\n",
      "Training: Epoch 46, Batch 23, Loss: 0.183\n",
      "Training: Epoch 46, Batch 24, Loss: 0.169\n",
      "Training: Epoch 46, Batch 25, Loss: 0.175\n",
      "Training: Epoch 46, Batch 26, Loss: 0.144\n",
      "Training: Epoch 46, Batch 27, Loss: 0.168\n",
      "Training: Epoch 46, Batch 28, Loss: 0.21\n",
      "Training: Epoch 46, Batch 29, Loss: 0.182\n",
      "Training: Epoch 46, Batch 30, Loss: 0.139\n",
      "Training: Epoch 46, Batch 31, Loss: 0.205\n",
      "Training: Epoch 46, Batch 32, Loss: 0.206\n",
      "Training: Epoch 46, Batch 33, Loss: 0.192\n",
      "Training: Epoch 46, Batch 34, Loss: 0.168\n",
      "Training: Epoch 46, Batch 35, Loss: 0.136\n",
      "Training: Epoch 46, Batch 36, Loss: 0.139\n",
      "Training: Epoch 46, Batch 37, Loss: 0.199\n",
      "Training: Epoch 46, Batch 38, Loss: 0.207\n",
      "Training: Epoch 46, Batch 39, Loss: 0.213\n",
      "Training: Epoch 46, Batch 40, Loss: 0.174\n",
      "Training: Epoch 46, Batch 41, Loss: 0.139\n",
      "Training: Epoch 46, Batch 42, Loss: 0.151\n",
      "Training: Epoch 46, Batch 43, Loss: 0.156\n",
      "Training: Epoch 46, Batch 44, Loss: 0.152\n",
      "Training: Epoch 46, Batch 45, Loss: 0.15\n",
      "Training: Epoch 46, Batch 46, Loss: 0.124\n",
      "Training: Epoch 46, Batch 47, Loss: 0.154\n",
      "Training: Epoch 46, Batch 48, Loss: 0.153\n",
      "Training: Epoch 46, Batch 49, Loss: 0.151\n",
      "Training: Epoch 46, Batch 50, Loss: 0.211\n",
      "Training: Epoch 46, Batch 51, Loss: 0.175\n",
      "Training: Epoch 46, Batch 52, Loss: 0.141\n",
      "Training: Epoch 46, Batch 53, Loss: 0.161\n",
      "Training: Epoch 46, Batch 54, Loss: 0.168\n",
      "Training: Epoch 46, Batch 55, Loss: 0.153\n",
      "Training: Epoch 46, Batch 56, Loss: 0.131\n",
      "Training: Epoch 46, Batch 57, Loss: 0.221\n",
      "Training: Epoch 46, Batch 58, Loss: 0.162\n",
      "Training: Epoch 46, Batch 59, Loss: 0.167\n",
      "Val: Epoch 46, Loss: 0.231\n",
      "Training: Epoch 47, Batch 0, Loss: 0.146\n",
      "Training: Epoch 47, Batch 1, Loss: 0.183\n",
      "Training: Epoch 47, Batch 2, Loss: 0.187\n",
      "Training: Epoch 47, Batch 3, Loss: 0.198\n",
      "Training: Epoch 47, Batch 4, Loss: 0.144\n",
      "Training: Epoch 47, Batch 5, Loss: 0.214\n",
      "Training: Epoch 47, Batch 6, Loss: 0.19\n",
      "Training: Epoch 47, Batch 7, Loss: 0.145\n",
      "Training: Epoch 47, Batch 8, Loss: 0.143\n",
      "Training: Epoch 47, Batch 9, Loss: 0.212\n",
      "Training: Epoch 47, Batch 10, Loss: 0.154\n",
      "Training: Epoch 47, Batch 11, Loss: 0.148\n",
      "Training: Epoch 47, Batch 12, Loss: 0.108\n",
      "Training: Epoch 47, Batch 13, Loss: 0.134\n",
      "Training: Epoch 47, Batch 14, Loss: 0.13\n",
      "Training: Epoch 47, Batch 15, Loss: 0.136\n",
      "Training: Epoch 47, Batch 16, Loss: 0.196\n",
      "Training: Epoch 47, Batch 17, Loss: 0.188\n",
      "Training: Epoch 47, Batch 18, Loss: 0.157\n",
      "Training: Epoch 47, Batch 19, Loss: 0.133\n",
      "Training: Epoch 47, Batch 20, Loss: 0.208\n",
      "Training: Epoch 47, Batch 21, Loss: 0.171\n",
      "Training: Epoch 47, Batch 22, Loss: 0.162\n",
      "Training: Epoch 47, Batch 23, Loss: 0.173\n",
      "Training: Epoch 47, Batch 24, Loss: 0.138\n",
      "Training: Epoch 47, Batch 25, Loss: 0.135\n",
      "Training: Epoch 47, Batch 26, Loss: 0.175\n",
      "Training: Epoch 47, Batch 27, Loss: 0.131\n",
      "Training: Epoch 47, Batch 28, Loss: 0.113\n",
      "Training: Epoch 47, Batch 29, Loss: 0.157\n",
      "Training: Epoch 47, Batch 30, Loss: 0.162\n",
      "Training: Epoch 47, Batch 31, Loss: 0.182\n",
      "Training: Epoch 47, Batch 32, Loss: 0.176\n",
      "Training: Epoch 47, Batch 33, Loss: 0.131\n",
      "Training: Epoch 47, Batch 34, Loss: 0.218\n",
      "Training: Epoch 47, Batch 35, Loss: 0.185\n",
      "Training: Epoch 47, Batch 36, Loss: 0.192\n",
      "Training: Epoch 47, Batch 37, Loss: 0.171\n",
      "Training: Epoch 47, Batch 38, Loss: 0.151\n",
      "Training: Epoch 47, Batch 39, Loss: 0.213\n",
      "Training: Epoch 47, Batch 40, Loss: 0.197\n",
      "Training: Epoch 47, Batch 41, Loss: 0.192\n",
      "Training: Epoch 47, Batch 42, Loss: 0.116\n",
      "Training: Epoch 47, Batch 43, Loss: 0.181\n",
      "Training: Epoch 47, Batch 44, Loss: 0.13\n",
      "Training: Epoch 47, Batch 45, Loss: 0.129\n",
      "Training: Epoch 47, Batch 46, Loss: 0.144\n",
      "Training: Epoch 47, Batch 47, Loss: 0.208\n",
      "Training: Epoch 47, Batch 48, Loss: 0.169\n",
      "Training: Epoch 47, Batch 49, Loss: 0.216\n",
      "Training: Epoch 47, Batch 50, Loss: 0.172\n",
      "Training: Epoch 47, Batch 51, Loss: 0.173\n",
      "Training: Epoch 47, Batch 52, Loss: 0.18\n",
      "Training: Epoch 47, Batch 53, Loss: 0.173\n",
      "Training: Epoch 47, Batch 54, Loss: 0.167\n",
      "Training: Epoch 47, Batch 55, Loss: 0.153\n",
      "Training: Epoch 47, Batch 56, Loss: 0.227\n",
      "Training: Epoch 47, Batch 57, Loss: 0.133\n",
      "Training: Epoch 47, Batch 58, Loss: 0.159\n",
      "Training: Epoch 47, Batch 59, Loss: 0.145\n",
      "Val: Epoch 47, Loss: 0.215\n",
      "Training: Epoch 48, Batch 0, Loss: 0.169\n",
      "Training: Epoch 48, Batch 1, Loss: 0.166\n",
      "Training: Epoch 48, Batch 2, Loss: 0.132\n",
      "Training: Epoch 48, Batch 3, Loss: 0.109\n",
      "Training: Epoch 48, Batch 4, Loss: 0.212\n",
      "Training: Epoch 48, Batch 5, Loss: 0.163\n",
      "Training: Epoch 48, Batch 6, Loss: 0.197\n",
      "Training: Epoch 48, Batch 7, Loss: 0.166\n",
      "Training: Epoch 48, Batch 8, Loss: 0.155\n",
      "Training: Epoch 48, Batch 9, Loss: 0.146\n",
      "Training: Epoch 48, Batch 10, Loss: 0.17\n",
      "Training: Epoch 48, Batch 11, Loss: 0.117\n",
      "Training: Epoch 48, Batch 12, Loss: 0.172\n",
      "Training: Epoch 48, Batch 13, Loss: 0.154\n",
      "Training: Epoch 48, Batch 14, Loss: 0.136\n",
      "Training: Epoch 48, Batch 15, Loss: 0.111\n",
      "Training: Epoch 48, Batch 16, Loss: 0.191\n",
      "Training: Epoch 48, Batch 17, Loss: 0.16\n",
      "Training: Epoch 48, Batch 18, Loss: 0.153\n",
      "Training: Epoch 48, Batch 19, Loss: 0.168\n",
      "Training: Epoch 48, Batch 20, Loss: 0.181\n",
      "Training: Epoch 48, Batch 21, Loss: 0.182\n",
      "Training: Epoch 48, Batch 22, Loss: 0.193\n",
      "Training: Epoch 48, Batch 23, Loss: 0.147\n",
      "Training: Epoch 48, Batch 24, Loss: 0.142\n",
      "Training: Epoch 48, Batch 25, Loss: 0.106\n",
      "Training: Epoch 48, Batch 26, Loss: 0.14\n",
      "Training: Epoch 48, Batch 27, Loss: 0.172\n",
      "Training: Epoch 48, Batch 28, Loss: 0.154\n",
      "Training: Epoch 48, Batch 29, Loss: 0.124\n",
      "Training: Epoch 48, Batch 30, Loss: 0.168\n",
      "Training: Epoch 48, Batch 31, Loss: 0.146\n",
      "Training: Epoch 48, Batch 32, Loss: 0.137\n",
      "Training: Epoch 48, Batch 33, Loss: 0.185\n",
      "Training: Epoch 48, Batch 34, Loss: 0.109\n",
      "Training: Epoch 48, Batch 35, Loss: 0.149\n",
      "Training: Epoch 48, Batch 36, Loss: 0.172\n",
      "Training: Epoch 48, Batch 37, Loss: 0.145\n",
      "Training: Epoch 48, Batch 38, Loss: 0.182\n",
      "Training: Epoch 48, Batch 39, Loss: 0.151\n",
      "Training: Epoch 48, Batch 40, Loss: 0.167\n",
      "Training: Epoch 48, Batch 41, Loss: 0.17\n",
      "Training: Epoch 48, Batch 42, Loss: 0.129\n",
      "Training: Epoch 48, Batch 43, Loss: 0.16\n",
      "Training: Epoch 48, Batch 44, Loss: 0.168\n",
      "Training: Epoch 48, Batch 45, Loss: 0.195\n",
      "Training: Epoch 48, Batch 46, Loss: 0.125\n",
      "Training: Epoch 48, Batch 47, Loss: 0.163\n",
      "Training: Epoch 48, Batch 48, Loss: 0.17\n",
      "Training: Epoch 48, Batch 49, Loss: 0.137\n",
      "Training: Epoch 48, Batch 50, Loss: 0.154\n",
      "Training: Epoch 48, Batch 51, Loss: 0.194\n",
      "Training: Epoch 48, Batch 52, Loss: 0.163\n",
      "Training: Epoch 48, Batch 53, Loss: 0.154\n",
      "Training: Epoch 48, Batch 54, Loss: 0.148\n",
      "Training: Epoch 48, Batch 55, Loss: 0.212\n",
      "Training: Epoch 48, Batch 56, Loss: 0.119\n",
      "Training: Epoch 48, Batch 57, Loss: 0.206\n",
      "Training: Epoch 48, Batch 58, Loss: 0.174\n",
      "Training: Epoch 48, Batch 59, Loss: 0.153\n",
      "Val: Epoch 48, Loss: 0.217\n",
      "Training: Epoch 49, Batch 0, Loss: 0.22\n",
      "Training: Epoch 49, Batch 1, Loss: 0.182\n",
      "Training: Epoch 49, Batch 2, Loss: 0.197\n",
      "Training: Epoch 49, Batch 3, Loss: 0.175\n",
      "Training: Epoch 49, Batch 4, Loss: 0.152\n",
      "Training: Epoch 49, Batch 5, Loss: 0.173\n",
      "Training: Epoch 49, Batch 6, Loss: 0.187\n",
      "Training: Epoch 49, Batch 7, Loss: 0.15\n",
      "Training: Epoch 49, Batch 8, Loss: 0.14\n",
      "Training: Epoch 49, Batch 9, Loss: 0.125\n",
      "Training: Epoch 49, Batch 10, Loss: 0.122\n",
      "Training: Epoch 49, Batch 11, Loss: 0.203\n",
      "Training: Epoch 49, Batch 12, Loss: 0.158\n",
      "Training: Epoch 49, Batch 13, Loss: 0.178\n",
      "Training: Epoch 49, Batch 14, Loss: 0.117\n",
      "Training: Epoch 49, Batch 15, Loss: 0.161\n",
      "Training: Epoch 49, Batch 16, Loss: 0.183\n",
      "Training: Epoch 49, Batch 17, Loss: 0.161\n",
      "Training: Epoch 49, Batch 18, Loss: 0.196\n",
      "Training: Epoch 49, Batch 19, Loss: 0.138\n",
      "Training: Epoch 49, Batch 20, Loss: 0.156\n",
      "Training: Epoch 49, Batch 21, Loss: 0.146\n",
      "Training: Epoch 49, Batch 22, Loss: 0.139\n",
      "Training: Epoch 49, Batch 23, Loss: 0.25\n",
      "Training: Epoch 49, Batch 24, Loss: 0.198\n",
      "Training: Epoch 49, Batch 25, Loss: 0.128\n",
      "Training: Epoch 49, Batch 26, Loss: 0.156\n",
      "Training: Epoch 49, Batch 27, Loss: 0.217\n",
      "Training: Epoch 49, Batch 28, Loss: 0.129\n",
      "Training: Epoch 49, Batch 29, Loss: 0.198\n",
      "Training: Epoch 49, Batch 30, Loss: 0.154\n",
      "Training: Epoch 49, Batch 31, Loss: 0.133\n",
      "Training: Epoch 49, Batch 32, Loss: 0.177\n",
      "Training: Epoch 49, Batch 33, Loss: 0.136\n",
      "Training: Epoch 49, Batch 34, Loss: 0.126\n",
      "Training: Epoch 49, Batch 35, Loss: 0.153\n",
      "Training: Epoch 49, Batch 36, Loss: 0.16\n",
      "Training: Epoch 49, Batch 37, Loss: 0.139\n",
      "Training: Epoch 49, Batch 38, Loss: 0.146\n",
      "Training: Epoch 49, Batch 39, Loss: 0.14\n",
      "Training: Epoch 49, Batch 40, Loss: 0.157\n",
      "Training: Epoch 49, Batch 41, Loss: 0.185\n",
      "Training: Epoch 49, Batch 42, Loss: 0.144\n",
      "Training: Epoch 49, Batch 43, Loss: 0.144\n",
      "Training: Epoch 49, Batch 44, Loss: 0.189\n",
      "Training: Epoch 49, Batch 45, Loss: 0.142\n",
      "Training: Epoch 49, Batch 46, Loss: 0.163\n",
      "Training: Epoch 49, Batch 47, Loss: 0.174\n",
      "Training: Epoch 49, Batch 48, Loss: 0.162\n",
      "Training: Epoch 49, Batch 49, Loss: 0.132\n",
      "Training: Epoch 49, Batch 50, Loss: 0.152\n",
      "Training: Epoch 49, Batch 51, Loss: 0.186\n",
      "Training: Epoch 49, Batch 52, Loss: 0.111\n",
      "Training: Epoch 49, Batch 53, Loss: 0.16\n",
      "Training: Epoch 49, Batch 54, Loss: 0.135\n",
      "Training: Epoch 49, Batch 55, Loss: 0.141\n",
      "Training: Epoch 49, Batch 56, Loss: 0.158\n",
      "Training: Epoch 49, Batch 57, Loss: 0.202\n",
      "Training: Epoch 49, Batch 58, Loss: 0.142\n",
      "Training: Epoch 49, Batch 59, Loss: 0.122\n",
      "Val: Epoch 49, Loss: 0.214\n",
      "Training: Epoch 50, Batch 0, Loss: 0.155\n",
      "Training: Epoch 50, Batch 1, Loss: 0.155\n",
      "Training: Epoch 50, Batch 2, Loss: 0.127\n",
      "Training: Epoch 50, Batch 3, Loss: 0.139\n",
      "Training: Epoch 50, Batch 4, Loss: 0.157\n",
      "Training: Epoch 50, Batch 5, Loss: 0.121\n",
      "Training: Epoch 50, Batch 6, Loss: 0.203\n",
      "Training: Epoch 50, Batch 7, Loss: 0.14\n",
      "Training: Epoch 50, Batch 8, Loss: 0.172\n",
      "Training: Epoch 50, Batch 9, Loss: 0.149\n",
      "Training: Epoch 50, Batch 10, Loss: 0.16\n",
      "Training: Epoch 50, Batch 11, Loss: 0.157\n",
      "Training: Epoch 50, Batch 12, Loss: 0.177\n",
      "Training: Epoch 50, Batch 13, Loss: 0.126\n",
      "Training: Epoch 50, Batch 14, Loss: 0.183\n",
      "Training: Epoch 50, Batch 15, Loss: 0.122\n",
      "Training: Epoch 50, Batch 16, Loss: 0.134\n",
      "Training: Epoch 50, Batch 17, Loss: 0.186\n",
      "Training: Epoch 50, Batch 18, Loss: 0.149\n",
      "Training: Epoch 50, Batch 19, Loss: 0.148\n",
      "Training: Epoch 50, Batch 20, Loss: 0.161\n",
      "Training: Epoch 50, Batch 21, Loss: 0.153\n",
      "Training: Epoch 50, Batch 22, Loss: 0.141\n",
      "Training: Epoch 50, Batch 23, Loss: 0.15\n",
      "Training: Epoch 50, Batch 24, Loss: 0.149\n",
      "Training: Epoch 50, Batch 25, Loss: 0.108\n",
      "Training: Epoch 50, Batch 26, Loss: 0.159\n",
      "Training: Epoch 50, Batch 27, Loss: 0.138\n",
      "Training: Epoch 50, Batch 28, Loss: 0.18\n",
      "Training: Epoch 50, Batch 29, Loss: 0.158\n",
      "Training: Epoch 50, Batch 30, Loss: 0.152\n",
      "Training: Epoch 50, Batch 31, Loss: 0.149\n",
      "Training: Epoch 50, Batch 32, Loss: 0.133\n",
      "Training: Epoch 50, Batch 33, Loss: 0.134\n",
      "Training: Epoch 50, Batch 34, Loss: 0.129\n",
      "Training: Epoch 50, Batch 35, Loss: 0.179\n",
      "Training: Epoch 50, Batch 36, Loss: 0.112\n",
      "Training: Epoch 50, Batch 37, Loss: 0.126\n",
      "Training: Epoch 50, Batch 38, Loss: 0.143\n",
      "Training: Epoch 50, Batch 39, Loss: 0.133\n",
      "Training: Epoch 50, Batch 40, Loss: 0.206\n",
      "Training: Epoch 50, Batch 41, Loss: 0.153\n",
      "Training: Epoch 50, Batch 42, Loss: 0.167\n",
      "Training: Epoch 50, Batch 43, Loss: 0.135\n",
      "Training: Epoch 50, Batch 44, Loss: 0.186\n",
      "Training: Epoch 50, Batch 45, Loss: 0.144\n",
      "Training: Epoch 50, Batch 46, Loss: 0.144\n",
      "Training: Epoch 50, Batch 47, Loss: 0.139\n",
      "Training: Epoch 50, Batch 48, Loss: 0.195\n",
      "Training: Epoch 50, Batch 49, Loss: 0.161\n",
      "Training: Epoch 50, Batch 50, Loss: 0.154\n",
      "Training: Epoch 50, Batch 51, Loss: 0.138\n",
      "Training: Epoch 50, Batch 52, Loss: 0.14\n",
      "Training: Epoch 50, Batch 53, Loss: 0.182\n",
      "Training: Epoch 50, Batch 54, Loss: 0.115\n",
      "Training: Epoch 50, Batch 55, Loss: 0.215\n",
      "Training: Epoch 50, Batch 56, Loss: 0.141\n",
      "Training: Epoch 50, Batch 57, Loss: 0.225\n",
      "Training: Epoch 50, Batch 58, Loss: 0.11\n",
      "Training: Epoch 50, Batch 59, Loss: 0.165\n",
      "Val: Epoch 50, Loss: 0.207\n",
      "Training: Epoch 51, Batch 0, Loss: 0.143\n",
      "Training: Epoch 51, Batch 1, Loss: 0.154\n",
      "Training: Epoch 51, Batch 2, Loss: 0.146\n",
      "Training: Epoch 51, Batch 3, Loss: 0.16\n",
      "Training: Epoch 51, Batch 4, Loss: 0.163\n",
      "Training: Epoch 51, Batch 5, Loss: 0.134\n",
      "Training: Epoch 51, Batch 6, Loss: 0.186\n",
      "Training: Epoch 51, Batch 7, Loss: 0.163\n",
      "Training: Epoch 51, Batch 8, Loss: 0.129\n",
      "Training: Epoch 51, Batch 9, Loss: 0.118\n",
      "Training: Epoch 51, Batch 10, Loss: 0.123\n",
      "Training: Epoch 51, Batch 11, Loss: 0.144\n",
      "Training: Epoch 51, Batch 12, Loss: 0.158\n",
      "Training: Epoch 51, Batch 13, Loss: 0.176\n",
      "Training: Epoch 51, Batch 14, Loss: 0.18\n",
      "Training: Epoch 51, Batch 15, Loss: 0.197\n",
      "Training: Epoch 51, Batch 16, Loss: 0.149\n",
      "Training: Epoch 51, Batch 17, Loss: 0.151\n",
      "Training: Epoch 51, Batch 18, Loss: 0.194\n",
      "Training: Epoch 51, Batch 19, Loss: 0.168\n",
      "Training: Epoch 51, Batch 20, Loss: 0.183\n",
      "Training: Epoch 51, Batch 21, Loss: 0.159\n",
      "Training: Epoch 51, Batch 22, Loss: 0.153\n",
      "Training: Epoch 51, Batch 23, Loss: 0.148\n",
      "Training: Epoch 51, Batch 24, Loss: 0.19\n",
      "Training: Epoch 51, Batch 25, Loss: 0.199\n",
      "Training: Epoch 51, Batch 26, Loss: 0.246\n",
      "Training: Epoch 51, Batch 27, Loss: 0.155\n",
      "Training: Epoch 51, Batch 28, Loss: 0.195\n",
      "Training: Epoch 51, Batch 29, Loss: 0.194\n",
      "Training: Epoch 51, Batch 30, Loss: 0.233\n",
      "Training: Epoch 51, Batch 31, Loss: 0.164\n",
      "Training: Epoch 51, Batch 32, Loss: 0.181\n",
      "Training: Epoch 51, Batch 33, Loss: 0.153\n",
      "Training: Epoch 51, Batch 34, Loss: 0.166\n",
      "Training: Epoch 51, Batch 35, Loss: 0.208\n",
      "Training: Epoch 51, Batch 36, Loss: 0.158\n",
      "Training: Epoch 51, Batch 37, Loss: 0.169\n",
      "Training: Epoch 51, Batch 38, Loss: 0.163\n",
      "Training: Epoch 51, Batch 39, Loss: 0.164\n",
      "Training: Epoch 51, Batch 40, Loss: 0.181\n",
      "Training: Epoch 51, Batch 41, Loss: 0.166\n",
      "Training: Epoch 51, Batch 42, Loss: 0.179\n",
      "Training: Epoch 51, Batch 43, Loss: 0.23\n",
      "Training: Epoch 51, Batch 44, Loss: 0.222\n",
      "Training: Epoch 51, Batch 45, Loss: 0.223\n",
      "Training: Epoch 51, Batch 46, Loss: 0.15\n",
      "Training: Epoch 51, Batch 47, Loss: 0.117\n",
      "Training: Epoch 51, Batch 48, Loss: 0.172\n",
      "Training: Epoch 51, Batch 49, Loss: 0.17\n",
      "Training: Epoch 51, Batch 50, Loss: 0.122\n",
      "Training: Epoch 51, Batch 51, Loss: 0.146\n",
      "Training: Epoch 51, Batch 52, Loss: 0.157\n",
      "Training: Epoch 51, Batch 53, Loss: 0.187\n",
      "Training: Epoch 51, Batch 54, Loss: 0.169\n",
      "Training: Epoch 51, Batch 55, Loss: 0.197\n",
      "Training: Epoch 51, Batch 56, Loss: 0.158\n",
      "Training: Epoch 51, Batch 57, Loss: 0.225\n",
      "Training: Epoch 51, Batch 58, Loss: 0.393\n",
      "Training: Epoch 51, Batch 59, Loss: 0.136\n",
      "Val: Epoch 51, Loss: 0.232\n",
      "Training: Epoch 52, Batch 0, Loss: 0.175\n",
      "Training: Epoch 52, Batch 1, Loss: 0.126\n",
      "Training: Epoch 52, Batch 2, Loss: 0.173\n",
      "Training: Epoch 52, Batch 3, Loss: 0.214\n",
      "Training: Epoch 52, Batch 4, Loss: 0.153\n",
      "Training: Epoch 52, Batch 5, Loss: 0.146\n",
      "Training: Epoch 52, Batch 6, Loss: 0.152\n",
      "Training: Epoch 52, Batch 7, Loss: 0.158\n",
      "Training: Epoch 52, Batch 8, Loss: 0.162\n",
      "Training: Epoch 52, Batch 9, Loss: 0.182\n",
      "Training: Epoch 52, Batch 10, Loss: 0.196\n",
      "Training: Epoch 52, Batch 11, Loss: 0.161\n",
      "Training: Epoch 52, Batch 12, Loss: 0.164\n",
      "Training: Epoch 52, Batch 13, Loss: 0.152\n",
      "Training: Epoch 52, Batch 14, Loss: 0.158\n",
      "Training: Epoch 52, Batch 15, Loss: 0.18\n",
      "Training: Epoch 52, Batch 16, Loss: 0.167\n",
      "Training: Epoch 52, Batch 17, Loss: 0.14\n",
      "Training: Epoch 52, Batch 18, Loss: 0.128\n",
      "Training: Epoch 52, Batch 19, Loss: 0.172\n",
      "Training: Epoch 52, Batch 20, Loss: 0.156\n",
      "Training: Epoch 52, Batch 21, Loss: 0.155\n",
      "Training: Epoch 52, Batch 22, Loss: 0.216\n",
      "Training: Epoch 52, Batch 23, Loss: 0.172\n",
      "Training: Epoch 52, Batch 24, Loss: 0.134\n",
      "Training: Epoch 52, Batch 25, Loss: 0.161\n",
      "Training: Epoch 52, Batch 26, Loss: 0.143\n",
      "Training: Epoch 52, Batch 27, Loss: 0.164\n",
      "Training: Epoch 52, Batch 28, Loss: 0.154\n",
      "Training: Epoch 52, Batch 29, Loss: 0.145\n",
      "Training: Epoch 52, Batch 30, Loss: 0.135\n",
      "Training: Epoch 52, Batch 31, Loss: 0.153\n",
      "Training: Epoch 52, Batch 32, Loss: 0.175\n",
      "Training: Epoch 52, Batch 33, Loss: 0.136\n",
      "Training: Epoch 52, Batch 34, Loss: 0.165\n",
      "Training: Epoch 52, Batch 35, Loss: 0.136\n",
      "Training: Epoch 52, Batch 36, Loss: 0.185\n",
      "Training: Epoch 52, Batch 37, Loss: 0.267\n",
      "Training: Epoch 52, Batch 38, Loss: 0.156\n",
      "Training: Epoch 52, Batch 39, Loss: 0.124\n",
      "Training: Epoch 52, Batch 40, Loss: 0.151\n",
      "Training: Epoch 52, Batch 41, Loss: 0.162\n",
      "Training: Epoch 52, Batch 42, Loss: 0.141\n",
      "Training: Epoch 52, Batch 43, Loss: 0.12\n",
      "Training: Epoch 52, Batch 44, Loss: 0.186\n",
      "Training: Epoch 52, Batch 45, Loss: 0.113\n",
      "Training: Epoch 52, Batch 46, Loss: 0.173\n",
      "Training: Epoch 52, Batch 47, Loss: 0.136\n",
      "Training: Epoch 52, Batch 48, Loss: 0.186\n",
      "Training: Epoch 52, Batch 49, Loss: 0.12\n",
      "Training: Epoch 52, Batch 50, Loss: 0.18\n",
      "Training: Epoch 52, Batch 51, Loss: 0.209\n",
      "Training: Epoch 52, Batch 52, Loss: 0.163\n",
      "Training: Epoch 52, Batch 53, Loss: 0.175\n",
      "Training: Epoch 52, Batch 54, Loss: 0.124\n",
      "Training: Epoch 52, Batch 55, Loss: 0.114\n",
      "Training: Epoch 52, Batch 56, Loss: 0.215\n",
      "Training: Epoch 52, Batch 57, Loss: 0.173\n",
      "Training: Epoch 52, Batch 58, Loss: 0.174\n",
      "Training: Epoch 52, Batch 59, Loss: 0.167\n",
      "Val: Epoch 52, Loss: 0.201\n",
      "Training: Epoch 53, Batch 0, Loss: 0.235\n",
      "Training: Epoch 53, Batch 1, Loss: 0.183\n",
      "Training: Epoch 53, Batch 2, Loss: 0.158\n",
      "Training: Epoch 53, Batch 3, Loss: 0.193\n",
      "Training: Epoch 53, Batch 4, Loss: 0.163\n",
      "Training: Epoch 53, Batch 5, Loss: 0.149\n",
      "Training: Epoch 53, Batch 6, Loss: 0.137\n",
      "Training: Epoch 53, Batch 7, Loss: 0.185\n",
      "Training: Epoch 53, Batch 8, Loss: 0.132\n",
      "Training: Epoch 53, Batch 9, Loss: 0.14\n",
      "Training: Epoch 53, Batch 10, Loss: 0.174\n",
      "Training: Epoch 53, Batch 11, Loss: 0.19\n",
      "Training: Epoch 53, Batch 12, Loss: 0.147\n",
      "Training: Epoch 53, Batch 13, Loss: 0.148\n",
      "Training: Epoch 53, Batch 14, Loss: 0.143\n",
      "Training: Epoch 53, Batch 15, Loss: 0.153\n",
      "Training: Epoch 53, Batch 16, Loss: 0.153\n",
      "Training: Epoch 53, Batch 17, Loss: 0.13\n",
      "Training: Epoch 53, Batch 18, Loss: 0.141\n",
      "Training: Epoch 53, Batch 19, Loss: 0.184\n",
      "Training: Epoch 53, Batch 20, Loss: 0.179\n",
      "Training: Epoch 53, Batch 21, Loss: 0.153\n",
      "Training: Epoch 53, Batch 22, Loss: 0.133\n",
      "Training: Epoch 53, Batch 23, Loss: 0.117\n",
      "Training: Epoch 53, Batch 24, Loss: 0.109\n",
      "Training: Epoch 53, Batch 25, Loss: 0.192\n",
      "Training: Epoch 53, Batch 26, Loss: 0.161\n",
      "Training: Epoch 53, Batch 27, Loss: 0.131\n",
      "Training: Epoch 53, Batch 28, Loss: 0.14\n",
      "Training: Epoch 53, Batch 29, Loss: 0.182\n",
      "Training: Epoch 53, Batch 30, Loss: 0.15\n",
      "Training: Epoch 53, Batch 31, Loss: 0.16\n",
      "Training: Epoch 53, Batch 32, Loss: 0.186\n",
      "Training: Epoch 53, Batch 33, Loss: 0.198\n",
      "Training: Epoch 53, Batch 34, Loss: 0.112\n",
      "Training: Epoch 53, Batch 35, Loss: 0.143\n",
      "Training: Epoch 53, Batch 36, Loss: 0.135\n",
      "Training: Epoch 53, Batch 37, Loss: 0.138\n",
      "Training: Epoch 53, Batch 38, Loss: 0.149\n",
      "Training: Epoch 53, Batch 39, Loss: 0.125\n",
      "Training: Epoch 53, Batch 40, Loss: 0.12\n",
      "Training: Epoch 53, Batch 41, Loss: 0.18\n",
      "Training: Epoch 53, Batch 42, Loss: 0.137\n",
      "Training: Epoch 53, Batch 43, Loss: 0.136\n",
      "Training: Epoch 53, Batch 44, Loss: 0.131\n",
      "Training: Epoch 53, Batch 45, Loss: 0.167\n",
      "Training: Epoch 53, Batch 46, Loss: 0.138\n",
      "Training: Epoch 53, Batch 47, Loss: 0.186\n",
      "Training: Epoch 53, Batch 48, Loss: 0.157\n",
      "Training: Epoch 53, Batch 49, Loss: 0.122\n",
      "Training: Epoch 53, Batch 50, Loss: 0.154\n",
      "Training: Epoch 53, Batch 51, Loss: 0.139\n",
      "Training: Epoch 53, Batch 52, Loss: 0.133\n",
      "Training: Epoch 53, Batch 53, Loss: 0.155\n",
      "Training: Epoch 53, Batch 54, Loss: 0.199\n",
      "Training: Epoch 53, Batch 55, Loss: 0.142\n",
      "Training: Epoch 53, Batch 56, Loss: 0.142\n",
      "Training: Epoch 53, Batch 57, Loss: 0.218\n",
      "Training: Epoch 53, Batch 58, Loss: 0.159\n",
      "Training: Epoch 53, Batch 59, Loss: 0.134\n",
      "Val: Epoch 53, Loss: 0.239\n",
      "Training: Epoch 54, Batch 0, Loss: 0.165\n",
      "Training: Epoch 54, Batch 1, Loss: 0.149\n",
      "Training: Epoch 54, Batch 2, Loss: 0.18\n",
      "Training: Epoch 54, Batch 3, Loss: 0.157\n",
      "Training: Epoch 54, Batch 4, Loss: 0.166\n",
      "Training: Epoch 54, Batch 5, Loss: 0.125\n",
      "Training: Epoch 54, Batch 6, Loss: 0.153\n",
      "Training: Epoch 54, Batch 7, Loss: 0.123\n",
      "Training: Epoch 54, Batch 8, Loss: 0.133\n",
      "Training: Epoch 54, Batch 9, Loss: 0.11\n",
      "Training: Epoch 54, Batch 10, Loss: 0.148\n",
      "Training: Epoch 54, Batch 11, Loss: 0.117\n",
      "Training: Epoch 54, Batch 12, Loss: 0.213\n",
      "Training: Epoch 54, Batch 13, Loss: 0.146\n",
      "Training: Epoch 54, Batch 14, Loss: 0.084\n",
      "Training: Epoch 54, Batch 15, Loss: 0.157\n",
      "Training: Epoch 54, Batch 16, Loss: 0.225\n",
      "Training: Epoch 54, Batch 17, Loss: 0.168\n",
      "Training: Epoch 54, Batch 18, Loss: 0.107\n",
      "Training: Epoch 54, Batch 19, Loss: 0.116\n",
      "Training: Epoch 54, Batch 20, Loss: 0.144\n",
      "Training: Epoch 54, Batch 21, Loss: 0.16\n",
      "Training: Epoch 54, Batch 22, Loss: 0.133\n",
      "Training: Epoch 54, Batch 23, Loss: 0.129\n",
      "Training: Epoch 54, Batch 24, Loss: 0.135\n",
      "Training: Epoch 54, Batch 25, Loss: 0.136\n",
      "Training: Epoch 54, Batch 26, Loss: 0.137\n",
      "Training: Epoch 54, Batch 27, Loss: 0.134\n",
      "Training: Epoch 54, Batch 28, Loss: 0.173\n",
      "Training: Epoch 54, Batch 29, Loss: 0.157\n",
      "Training: Epoch 54, Batch 30, Loss: 0.131\n",
      "Training: Epoch 54, Batch 31, Loss: 0.156\n",
      "Training: Epoch 54, Batch 32, Loss: 0.168\n",
      "Training: Epoch 54, Batch 33, Loss: 0.18\n",
      "Training: Epoch 54, Batch 34, Loss: 0.151\n",
      "Training: Epoch 54, Batch 35, Loss: 0.145\n",
      "Training: Epoch 54, Batch 36, Loss: 0.12\n",
      "Training: Epoch 54, Batch 37, Loss: 0.148\n",
      "Training: Epoch 54, Batch 38, Loss: 0.171\n",
      "Training: Epoch 54, Batch 39, Loss: 0.141\n",
      "Training: Epoch 54, Batch 40, Loss: 0.114\n",
      "Training: Epoch 54, Batch 41, Loss: 0.175\n",
      "Training: Epoch 54, Batch 42, Loss: 0.156\n",
      "Training: Epoch 54, Batch 43, Loss: 0.166\n",
      "Training: Epoch 54, Batch 44, Loss: 0.154\n",
      "Training: Epoch 54, Batch 45, Loss: 0.127\n",
      "Training: Epoch 54, Batch 46, Loss: 0.154\n",
      "Training: Epoch 54, Batch 47, Loss: 0.171\n",
      "Training: Epoch 54, Batch 48, Loss: 0.16\n",
      "Training: Epoch 54, Batch 49, Loss: 0.187\n",
      "Training: Epoch 54, Batch 50, Loss: 0.15\n",
      "Training: Epoch 54, Batch 51, Loss: 0.122\n",
      "Training: Epoch 54, Batch 52, Loss: 0.205\n",
      "Training: Epoch 54, Batch 53, Loss: 0.138\n",
      "Training: Epoch 54, Batch 54, Loss: 0.114\n",
      "Training: Epoch 54, Batch 55, Loss: 0.264\n",
      "Training: Epoch 54, Batch 56, Loss: 0.14\n",
      "Training: Epoch 54, Batch 57, Loss: 0.155\n",
      "Training: Epoch 54, Batch 58, Loss: 0.111\n",
      "Training: Epoch 54, Batch 59, Loss: 0.224\n",
      "Val: Epoch 54, Loss: 0.217\n",
      "Training: Epoch 55, Batch 0, Loss: 0.168\n",
      "Training: Epoch 55, Batch 1, Loss: 0.119\n",
      "Training: Epoch 55, Batch 2, Loss: 0.186\n",
      "Training: Epoch 55, Batch 3, Loss: 0.121\n",
      "Training: Epoch 55, Batch 4, Loss: 0.147\n",
      "Training: Epoch 55, Batch 5, Loss: 0.138\n",
      "Training: Epoch 55, Batch 6, Loss: 0.127\n",
      "Training: Epoch 55, Batch 7, Loss: 0.135\n",
      "Training: Epoch 55, Batch 8, Loss: 0.159\n",
      "Training: Epoch 55, Batch 9, Loss: 0.128\n",
      "Training: Epoch 55, Batch 10, Loss: 0.161\n",
      "Training: Epoch 55, Batch 11, Loss: 0.112\n",
      "Training: Epoch 55, Batch 12, Loss: 0.091\n",
      "Training: Epoch 55, Batch 13, Loss: 0.15\n",
      "Training: Epoch 55, Batch 14, Loss: 0.141\n",
      "Training: Epoch 55, Batch 15, Loss: 0.112\n",
      "Training: Epoch 55, Batch 16, Loss: 0.205\n",
      "Training: Epoch 55, Batch 17, Loss: 0.116\n",
      "Training: Epoch 55, Batch 18, Loss: 0.176\n",
      "Training: Epoch 55, Batch 19, Loss: 0.186\n",
      "Training: Epoch 55, Batch 20, Loss: 0.192\n",
      "Training: Epoch 55, Batch 21, Loss: 0.2\n",
      "Training: Epoch 55, Batch 22, Loss: 0.129\n",
      "Training: Epoch 55, Batch 23, Loss: 0.169\n",
      "Training: Epoch 55, Batch 24, Loss: 0.179\n",
      "Training: Epoch 55, Batch 25, Loss: 0.14\n",
      "Training: Epoch 55, Batch 26, Loss: 0.112\n",
      "Training: Epoch 55, Batch 27, Loss: 0.137\n",
      "Training: Epoch 55, Batch 28, Loss: 0.169\n",
      "Training: Epoch 55, Batch 29, Loss: 0.16\n",
      "Training: Epoch 55, Batch 30, Loss: 0.169\n",
      "Training: Epoch 55, Batch 31, Loss: 0.121\n",
      "Training: Epoch 55, Batch 32, Loss: 0.188\n",
      "Training: Epoch 55, Batch 33, Loss: 0.129\n",
      "Training: Epoch 55, Batch 34, Loss: 0.185\n",
      "Training: Epoch 55, Batch 35, Loss: 0.243\n",
      "Training: Epoch 55, Batch 36, Loss: 0.131\n",
      "Training: Epoch 55, Batch 37, Loss: 0.193\n",
      "Training: Epoch 55, Batch 38, Loss: 0.179\n",
      "Training: Epoch 55, Batch 39, Loss: 0.191\n",
      "Training: Epoch 55, Batch 40, Loss: 0.138\n",
      "Training: Epoch 55, Batch 41, Loss: 0.148\n",
      "Training: Epoch 55, Batch 42, Loss: 0.157\n",
      "Training: Epoch 55, Batch 43, Loss: 0.162\n",
      "Training: Epoch 55, Batch 44, Loss: 0.206\n",
      "Training: Epoch 55, Batch 45, Loss: 0.158\n",
      "Training: Epoch 55, Batch 46, Loss: 0.228\n",
      "Training: Epoch 55, Batch 47, Loss: 0.128\n",
      "Training: Epoch 55, Batch 48, Loss: 0.123\n",
      "Training: Epoch 55, Batch 49, Loss: 0.15\n",
      "Training: Epoch 55, Batch 50, Loss: 0.109\n",
      "Training: Epoch 55, Batch 51, Loss: 0.155\n",
      "Training: Epoch 55, Batch 52, Loss: 0.156\n",
      "Training: Epoch 55, Batch 53, Loss: 0.119\n",
      "Training: Epoch 55, Batch 54, Loss: 0.14\n",
      "Training: Epoch 55, Batch 55, Loss: 0.124\n",
      "Training: Epoch 55, Batch 56, Loss: 0.151\n",
      "Training: Epoch 55, Batch 57, Loss: 0.138\n",
      "Training: Epoch 55, Batch 58, Loss: 0.134\n",
      "Training: Epoch 55, Batch 59, Loss: 0.121\n",
      "Val: Epoch 55, Loss: 0.229\n",
      "Training: Epoch 56, Batch 0, Loss: 0.141\n",
      "Training: Epoch 56, Batch 1, Loss: 0.153\n",
      "Training: Epoch 56, Batch 2, Loss: 0.121\n",
      "Training: Epoch 56, Batch 3, Loss: 0.162\n",
      "Training: Epoch 56, Batch 4, Loss: 0.148\n",
      "Training: Epoch 56, Batch 5, Loss: 0.142\n",
      "Training: Epoch 56, Batch 6, Loss: 0.119\n",
      "Training: Epoch 56, Batch 7, Loss: 0.14\n",
      "Training: Epoch 56, Batch 8, Loss: 0.104\n",
      "Training: Epoch 56, Batch 9, Loss: 0.132\n",
      "Training: Epoch 56, Batch 10, Loss: 0.167\n",
      "Training: Epoch 56, Batch 11, Loss: 0.159\n",
      "Training: Epoch 56, Batch 12, Loss: 0.15\n",
      "Training: Epoch 56, Batch 13, Loss: 0.138\n",
      "Training: Epoch 56, Batch 14, Loss: 0.183\n",
      "Training: Epoch 56, Batch 15, Loss: 0.147\n",
      "Training: Epoch 56, Batch 16, Loss: 0.145\n",
      "Training: Epoch 56, Batch 17, Loss: 0.17\n",
      "Training: Epoch 56, Batch 18, Loss: 0.143\n",
      "Training: Epoch 56, Batch 19, Loss: 0.162\n",
      "Training: Epoch 56, Batch 20, Loss: 0.167\n",
      "Training: Epoch 56, Batch 21, Loss: 0.172\n",
      "Training: Epoch 56, Batch 22, Loss: 0.2\n",
      "Training: Epoch 56, Batch 23, Loss: 0.188\n",
      "Training: Epoch 56, Batch 24, Loss: 0.168\n",
      "Training: Epoch 56, Batch 25, Loss: 0.137\n",
      "Training: Epoch 56, Batch 26, Loss: 0.217\n",
      "Training: Epoch 56, Batch 27, Loss: 0.133\n",
      "Training: Epoch 56, Batch 28, Loss: 0.141\n",
      "Training: Epoch 56, Batch 29, Loss: 0.201\n",
      "Training: Epoch 56, Batch 30, Loss: 0.148\n",
      "Training: Epoch 56, Batch 31, Loss: 0.141\n",
      "Training: Epoch 56, Batch 32, Loss: 0.109\n",
      "Training: Epoch 56, Batch 33, Loss: 0.143\n",
      "Training: Epoch 56, Batch 34, Loss: 0.217\n",
      "Training: Epoch 56, Batch 35, Loss: 0.162\n",
      "Training: Epoch 56, Batch 36, Loss: 0.182\n",
      "Training: Epoch 56, Batch 37, Loss: 0.164\n",
      "Training: Epoch 56, Batch 38, Loss: 0.145\n",
      "Training: Epoch 56, Batch 39, Loss: 0.122\n",
      "Training: Epoch 56, Batch 40, Loss: 0.131\n",
      "Training: Epoch 56, Batch 41, Loss: 0.149\n",
      "Training: Epoch 56, Batch 42, Loss: 0.102\n",
      "Training: Epoch 56, Batch 43, Loss: 0.178\n",
      "Training: Epoch 56, Batch 44, Loss: 0.123\n",
      "Training: Epoch 56, Batch 45, Loss: 0.219\n",
      "Training: Epoch 56, Batch 46, Loss: 0.137\n",
      "Training: Epoch 56, Batch 47, Loss: 0.148\n",
      "Training: Epoch 56, Batch 48, Loss: 0.215\n",
      "Training: Epoch 56, Batch 49, Loss: 0.157\n",
      "Training: Epoch 56, Batch 50, Loss: 0.146\n",
      "Training: Epoch 56, Batch 51, Loss: 0.178\n",
      "Training: Epoch 56, Batch 52, Loss: 0.143\n",
      "Training: Epoch 56, Batch 53, Loss: 0.148\n",
      "Training: Epoch 56, Batch 54, Loss: 0.151\n",
      "Training: Epoch 56, Batch 55, Loss: 0.148\n",
      "Training: Epoch 56, Batch 56, Loss: 0.144\n",
      "Training: Epoch 56, Batch 57, Loss: 0.16\n",
      "Training: Epoch 56, Batch 58, Loss: 0.125\n",
      "Training: Epoch 56, Batch 59, Loss: 0.17\n",
      "Val: Epoch 56, Loss: 0.225\n",
      "Training: Epoch 57, Batch 0, Loss: 0.155\n",
      "Training: Epoch 57, Batch 1, Loss: 0.168\n",
      "Training: Epoch 57, Batch 2, Loss: 0.142\n",
      "Training: Epoch 57, Batch 3, Loss: 0.131\n",
      "Training: Epoch 57, Batch 4, Loss: 0.115\n",
      "Training: Epoch 57, Batch 5, Loss: 0.126\n",
      "Training: Epoch 57, Batch 6, Loss: 0.168\n",
      "Training: Epoch 57, Batch 7, Loss: 0.183\n",
      "Training: Epoch 57, Batch 8, Loss: 0.137\n",
      "Training: Epoch 57, Batch 9, Loss: 0.169\n",
      "Training: Epoch 57, Batch 10, Loss: 0.104\n",
      "Training: Epoch 57, Batch 11, Loss: 0.129\n",
      "Training: Epoch 57, Batch 12, Loss: 0.129\n",
      "Training: Epoch 57, Batch 13, Loss: 0.137\n",
      "Training: Epoch 57, Batch 14, Loss: 0.119\n",
      "Training: Epoch 57, Batch 15, Loss: 0.136\n",
      "Training: Epoch 57, Batch 16, Loss: 0.147\n",
      "Training: Epoch 57, Batch 17, Loss: 0.203\n",
      "Training: Epoch 57, Batch 18, Loss: 0.179\n",
      "Training: Epoch 57, Batch 19, Loss: 0.139\n",
      "Training: Epoch 57, Batch 20, Loss: 0.174\n",
      "Training: Epoch 57, Batch 21, Loss: 0.163\n",
      "Training: Epoch 57, Batch 22, Loss: 0.127\n",
      "Training: Epoch 57, Batch 23, Loss: 0.194\n",
      "Training: Epoch 57, Batch 24, Loss: 0.16\n",
      "Training: Epoch 57, Batch 25, Loss: 0.153\n",
      "Training: Epoch 57, Batch 26, Loss: 0.168\n",
      "Training: Epoch 57, Batch 27, Loss: 0.148\n",
      "Training: Epoch 57, Batch 28, Loss: 0.202\n",
      "Training: Epoch 57, Batch 29, Loss: 0.153\n",
      "Training: Epoch 57, Batch 30, Loss: 0.163\n",
      "Training: Epoch 57, Batch 31, Loss: 0.165\n",
      "Training: Epoch 57, Batch 32, Loss: 0.163\n",
      "Training: Epoch 57, Batch 33, Loss: 0.151\n",
      "Training: Epoch 57, Batch 34, Loss: 0.121\n",
      "Training: Epoch 57, Batch 35, Loss: 0.143\n",
      "Training: Epoch 57, Batch 36, Loss: 0.191\n",
      "Training: Epoch 57, Batch 37, Loss: 0.213\n",
      "Training: Epoch 57, Batch 38, Loss: 0.161\n",
      "Training: Epoch 57, Batch 39, Loss: 0.138\n",
      "Training: Epoch 57, Batch 40, Loss: 0.147\n",
      "Training: Epoch 57, Batch 41, Loss: 0.155\n",
      "Training: Epoch 57, Batch 42, Loss: 0.145\n",
      "Training: Epoch 57, Batch 43, Loss: 0.133\n",
      "Training: Epoch 57, Batch 44, Loss: 0.207\n",
      "Training: Epoch 57, Batch 45, Loss: 0.15\n",
      "Training: Epoch 57, Batch 46, Loss: 0.171\n",
      "Training: Epoch 57, Batch 47, Loss: 0.146\n",
      "Training: Epoch 57, Batch 48, Loss: 0.142\n",
      "Training: Epoch 57, Batch 49, Loss: 0.153\n",
      "Training: Epoch 57, Batch 50, Loss: 0.12\n",
      "Training: Epoch 57, Batch 51, Loss: 0.141\n",
      "Training: Epoch 57, Batch 52, Loss: 0.144\n",
      "Training: Epoch 57, Batch 53, Loss: 0.118\n",
      "Training: Epoch 57, Batch 54, Loss: 0.174\n",
      "Training: Epoch 57, Batch 55, Loss: 0.126\n",
      "Training: Epoch 57, Batch 56, Loss: 0.153\n",
      "Training: Epoch 57, Batch 57, Loss: 0.133\n",
      "Training: Epoch 57, Batch 58, Loss: 0.19\n",
      "Training: Epoch 57, Batch 59, Loss: 0.148\n",
      "Val: Epoch 57, Loss: 0.201\n",
      "Training: Epoch 58, Batch 0, Loss: 0.147\n",
      "Training: Epoch 58, Batch 1, Loss: 0.126\n",
      "Training: Epoch 58, Batch 2, Loss: 0.161\n",
      "Training: Epoch 58, Batch 3, Loss: 0.144\n",
      "Training: Epoch 58, Batch 4, Loss: 0.133\n",
      "Training: Epoch 58, Batch 5, Loss: 0.153\n",
      "Training: Epoch 58, Batch 6, Loss: 0.148\n",
      "Training: Epoch 58, Batch 7, Loss: 0.152\n",
      "Training: Epoch 58, Batch 8, Loss: 0.107\n",
      "Training: Epoch 58, Batch 9, Loss: 0.131\n",
      "Training: Epoch 58, Batch 10, Loss: 0.177\n",
      "Training: Epoch 58, Batch 11, Loss: 0.136\n",
      "Training: Epoch 58, Batch 12, Loss: 0.164\n",
      "Training: Epoch 58, Batch 13, Loss: 0.115\n",
      "Training: Epoch 58, Batch 14, Loss: 0.217\n",
      "Training: Epoch 58, Batch 15, Loss: 0.131\n",
      "Training: Epoch 58, Batch 16, Loss: 0.113\n",
      "Training: Epoch 58, Batch 17, Loss: 0.126\n",
      "Training: Epoch 58, Batch 18, Loss: 0.134\n",
      "Training: Epoch 58, Batch 19, Loss: 0.16\n",
      "Training: Epoch 58, Batch 20, Loss: 0.138\n",
      "Training: Epoch 58, Batch 21, Loss: 0.146\n",
      "Training: Epoch 58, Batch 22, Loss: 0.169\n",
      "Training: Epoch 58, Batch 23, Loss: 0.14\n",
      "Training: Epoch 58, Batch 24, Loss: 0.116\n",
      "Training: Epoch 58, Batch 25, Loss: 0.169\n",
      "Training: Epoch 58, Batch 26, Loss: 0.155\n",
      "Training: Epoch 58, Batch 27, Loss: 0.134\n",
      "Training: Epoch 58, Batch 28, Loss: 0.124\n",
      "Training: Epoch 58, Batch 29, Loss: 0.136\n",
      "Training: Epoch 58, Batch 30, Loss: 0.146\n",
      "Training: Epoch 58, Batch 31, Loss: 0.181\n",
      "Training: Epoch 58, Batch 32, Loss: 0.144\n",
      "Training: Epoch 58, Batch 33, Loss: 0.144\n",
      "Training: Epoch 58, Batch 34, Loss: 0.13\n",
      "Training: Epoch 58, Batch 35, Loss: 0.147\n",
      "Training: Epoch 58, Batch 36, Loss: 0.174\n",
      "Training: Epoch 58, Batch 37, Loss: 0.169\n",
      "Training: Epoch 58, Batch 38, Loss: 0.132\n",
      "Training: Epoch 58, Batch 39, Loss: 0.112\n",
      "Training: Epoch 58, Batch 40, Loss: 0.103\n",
      "Training: Epoch 58, Batch 41, Loss: 0.158\n",
      "Training: Epoch 58, Batch 42, Loss: 0.148\n",
      "Training: Epoch 58, Batch 43, Loss: 0.112\n",
      "Training: Epoch 58, Batch 44, Loss: 0.183\n",
      "Training: Epoch 58, Batch 45, Loss: 0.148\n",
      "Training: Epoch 58, Batch 46, Loss: 0.12\n",
      "Training: Epoch 58, Batch 47, Loss: 0.143\n",
      "Training: Epoch 58, Batch 48, Loss: 0.161\n",
      "Training: Epoch 58, Batch 49, Loss: 0.195\n",
      "Training: Epoch 58, Batch 50, Loss: 0.133\n",
      "Training: Epoch 58, Batch 51, Loss: 0.141\n",
      "Training: Epoch 58, Batch 52, Loss: 0.146\n",
      "Training: Epoch 58, Batch 53, Loss: 0.135\n",
      "Training: Epoch 58, Batch 54, Loss: 0.096\n",
      "Training: Epoch 58, Batch 55, Loss: 0.143\n",
      "Training: Epoch 58, Batch 56, Loss: 0.131\n",
      "Training: Epoch 58, Batch 57, Loss: 0.24\n",
      "Training: Epoch 58, Batch 58, Loss: 0.116\n",
      "Training: Epoch 58, Batch 59, Loss: 0.209\n",
      "Val: Epoch 58, Loss: 0.22\n",
      "Training: Epoch 59, Batch 0, Loss: 0.145\n",
      "Training: Epoch 59, Batch 1, Loss: 0.122\n",
      "Training: Epoch 59, Batch 2, Loss: 0.195\n",
      "Training: Epoch 59, Batch 3, Loss: 0.142\n",
      "Training: Epoch 59, Batch 4, Loss: 0.19\n",
      "Training: Epoch 59, Batch 5, Loss: 0.131\n",
      "Training: Epoch 59, Batch 6, Loss: 0.141\n",
      "Training: Epoch 59, Batch 7, Loss: 0.163\n",
      "Training: Epoch 59, Batch 8, Loss: 0.171\n",
      "Training: Epoch 59, Batch 9, Loss: 0.196\n",
      "Training: Epoch 59, Batch 10, Loss: 0.147\n",
      "Training: Epoch 59, Batch 11, Loss: 0.135\n",
      "Training: Epoch 59, Batch 12, Loss: 0.149\n",
      "Training: Epoch 59, Batch 13, Loss: 0.191\n",
      "Training: Epoch 59, Batch 14, Loss: 0.123\n",
      "Training: Epoch 59, Batch 15, Loss: 0.129\n",
      "Training: Epoch 59, Batch 16, Loss: 0.136\n",
      "Training: Epoch 59, Batch 17, Loss: 0.118\n",
      "Training: Epoch 59, Batch 18, Loss: 0.113\n",
      "Training: Epoch 59, Batch 19, Loss: 0.127\n",
      "Training: Epoch 59, Batch 20, Loss: 0.136\n",
      "Training: Epoch 59, Batch 21, Loss: 0.139\n",
      "Training: Epoch 59, Batch 22, Loss: 0.177\n",
      "Training: Epoch 59, Batch 23, Loss: 0.17\n",
      "Training: Epoch 59, Batch 24, Loss: 0.102\n",
      "Training: Epoch 59, Batch 25, Loss: 0.116\n",
      "Training: Epoch 59, Batch 26, Loss: 0.173\n",
      "Training: Epoch 59, Batch 27, Loss: 0.129\n",
      "Training: Epoch 59, Batch 28, Loss: 0.152\n",
      "Training: Epoch 59, Batch 29, Loss: 0.187\n",
      "Training: Epoch 59, Batch 30, Loss: 0.146\n",
      "Training: Epoch 59, Batch 31, Loss: 0.125\n",
      "Training: Epoch 59, Batch 32, Loss: 0.132\n",
      "Training: Epoch 59, Batch 33, Loss: 0.127\n",
      "Training: Epoch 59, Batch 34, Loss: 0.113\n",
      "Training: Epoch 59, Batch 35, Loss: 0.136\n",
      "Training: Epoch 59, Batch 36, Loss: 0.142\n",
      "Training: Epoch 59, Batch 37, Loss: 0.153\n",
      "Training: Epoch 59, Batch 38, Loss: 0.14\n",
      "Training: Epoch 59, Batch 39, Loss: 0.115\n",
      "Training: Epoch 59, Batch 40, Loss: 0.14\n",
      "Training: Epoch 59, Batch 41, Loss: 0.15\n",
      "Training: Epoch 59, Batch 42, Loss: 0.122\n",
      "Training: Epoch 59, Batch 43, Loss: 0.129\n",
      "Training: Epoch 59, Batch 44, Loss: 0.179\n",
      "Training: Epoch 59, Batch 45, Loss: 0.239\n",
      "Training: Epoch 59, Batch 46, Loss: 0.108\n",
      "Training: Epoch 59, Batch 47, Loss: 0.116\n",
      "Training: Epoch 59, Batch 48, Loss: 0.135\n",
      "Training: Epoch 59, Batch 49, Loss: 0.148\n",
      "Training: Epoch 59, Batch 50, Loss: 0.121\n",
      "Training: Epoch 59, Batch 51, Loss: 0.187\n",
      "Training: Epoch 59, Batch 52, Loss: 0.103\n",
      "Training: Epoch 59, Batch 53, Loss: 0.135\n",
      "Training: Epoch 59, Batch 54, Loss: 0.183\n",
      "Training: Epoch 59, Batch 55, Loss: 0.106\n",
      "Training: Epoch 59, Batch 56, Loss: 0.196\n",
      "Training: Epoch 59, Batch 57, Loss: 0.203\n",
      "Training: Epoch 59, Batch 58, Loss: 0.232\n",
      "Training: Epoch 59, Batch 59, Loss: 0.139\n",
      "Val: Epoch 59, Loss: 0.91\n",
      "Training: Epoch 60, Batch 0, Loss: 0.141\n",
      "Training: Epoch 60, Batch 1, Loss: 0.138\n",
      "Training: Epoch 60, Batch 2, Loss: 0.168\n",
      "Training: Epoch 60, Batch 3, Loss: 0.192\n",
      "Training: Epoch 60, Batch 4, Loss: 0.121\n",
      "Training: Epoch 60, Batch 5, Loss: 0.139\n",
      "Training: Epoch 60, Batch 6, Loss: 0.134\n",
      "Training: Epoch 60, Batch 7, Loss: 0.171\n",
      "Training: Epoch 60, Batch 8, Loss: 0.143\n",
      "Training: Epoch 60, Batch 9, Loss: 0.15\n",
      "Training: Epoch 60, Batch 10, Loss: 0.161\n",
      "Training: Epoch 60, Batch 11, Loss: 0.107\n",
      "Training: Epoch 60, Batch 12, Loss: 0.105\n",
      "Training: Epoch 60, Batch 13, Loss: 0.184\n",
      "Training: Epoch 60, Batch 14, Loss: 0.138\n",
      "Training: Epoch 60, Batch 15, Loss: 0.138\n",
      "Training: Epoch 60, Batch 16, Loss: 0.152\n",
      "Training: Epoch 60, Batch 17, Loss: 0.179\n",
      "Training: Epoch 60, Batch 18, Loss: 0.136\n",
      "Training: Epoch 60, Batch 19, Loss: 0.126\n",
      "Training: Epoch 60, Batch 20, Loss: 0.142\n",
      "Training: Epoch 60, Batch 21, Loss: 0.161\n",
      "Training: Epoch 60, Batch 22, Loss: 0.167\n",
      "Training: Epoch 60, Batch 23, Loss: 0.114\n",
      "Training: Epoch 60, Batch 24, Loss: 0.155\n",
      "Training: Epoch 60, Batch 25, Loss: 0.113\n",
      "Training: Epoch 60, Batch 26, Loss: 0.132\n",
      "Training: Epoch 60, Batch 27, Loss: 0.129\n",
      "Training: Epoch 60, Batch 28, Loss: 0.126\n",
      "Training: Epoch 60, Batch 29, Loss: 0.13\n",
      "Training: Epoch 60, Batch 30, Loss: 0.148\n",
      "Training: Epoch 60, Batch 31, Loss: 0.2\n",
      "Training: Epoch 60, Batch 32, Loss: 0.119\n",
      "Training: Epoch 60, Batch 33, Loss: 0.173\n",
      "Training: Epoch 60, Batch 34, Loss: 0.162\n",
      "Training: Epoch 60, Batch 35, Loss: 0.187\n",
      "Training: Epoch 60, Batch 36, Loss: 0.124\n",
      "Training: Epoch 60, Batch 37, Loss: 0.145\n",
      "Training: Epoch 60, Batch 38, Loss: 0.184\n",
      "Training: Epoch 60, Batch 39, Loss: 0.127\n",
      "Training: Epoch 60, Batch 40, Loss: 0.168\n",
      "Training: Epoch 60, Batch 41, Loss: 0.125\n",
      "Training: Epoch 60, Batch 42, Loss: 0.139\n",
      "Training: Epoch 60, Batch 43, Loss: 0.16\n",
      "Training: Epoch 60, Batch 44, Loss: 0.158\n",
      "Training: Epoch 60, Batch 45, Loss: 0.182\n",
      "Training: Epoch 60, Batch 46, Loss: 0.14\n",
      "Training: Epoch 60, Batch 47, Loss: 0.146\n",
      "Training: Epoch 60, Batch 48, Loss: 0.106\n",
      "Training: Epoch 60, Batch 49, Loss: 0.141\n",
      "Training: Epoch 60, Batch 50, Loss: 0.162\n",
      "Training: Epoch 60, Batch 51, Loss: 0.162\n",
      "Training: Epoch 60, Batch 52, Loss: 0.119\n",
      "Training: Epoch 60, Batch 53, Loss: 0.197\n",
      "Training: Epoch 60, Batch 54, Loss: 0.147\n",
      "Training: Epoch 60, Batch 55, Loss: 0.175\n",
      "Training: Epoch 60, Batch 56, Loss: 0.122\n",
      "Training: Epoch 60, Batch 57, Loss: 0.107\n",
      "Training: Epoch 60, Batch 58, Loss: 0.148\n",
      "Training: Epoch 60, Batch 59, Loss: 0.168\n",
      "Val: Epoch 60, Loss: 0.198\n",
      "Training: Epoch 61, Batch 0, Loss: 0.127\n",
      "Training: Epoch 61, Batch 1, Loss: 0.137\n",
      "Training: Epoch 61, Batch 2, Loss: 0.111\n",
      "Training: Epoch 61, Batch 3, Loss: 0.149\n",
      "Training: Epoch 61, Batch 4, Loss: 0.126\n",
      "Training: Epoch 61, Batch 5, Loss: 0.158\n",
      "Training: Epoch 61, Batch 6, Loss: 0.184\n",
      "Training: Epoch 61, Batch 7, Loss: 0.14\n",
      "Training: Epoch 61, Batch 8, Loss: 0.148\n",
      "Training: Epoch 61, Batch 9, Loss: 0.146\n",
      "Training: Epoch 61, Batch 10, Loss: 0.117\n",
      "Training: Epoch 61, Batch 11, Loss: 0.128\n",
      "Training: Epoch 61, Batch 12, Loss: 0.141\n",
      "Training: Epoch 61, Batch 13, Loss: 0.128\n",
      "Training: Epoch 61, Batch 14, Loss: 0.182\n",
      "Training: Epoch 61, Batch 15, Loss: 0.158\n",
      "Training: Epoch 61, Batch 16, Loss: 0.139\n",
      "Training: Epoch 61, Batch 17, Loss: 0.174\n",
      "Training: Epoch 61, Batch 18, Loss: 0.16\n",
      "Training: Epoch 61, Batch 19, Loss: 0.164\n",
      "Training: Epoch 61, Batch 20, Loss: 0.141\n",
      "Training: Epoch 61, Batch 21, Loss: 0.151\n",
      "Training: Epoch 61, Batch 22, Loss: 0.154\n",
      "Training: Epoch 61, Batch 23, Loss: 0.178\n",
      "Training: Epoch 61, Batch 24, Loss: 0.205\n",
      "Training: Epoch 61, Batch 25, Loss: 0.162\n",
      "Training: Epoch 61, Batch 26, Loss: 0.1\n",
      "Training: Epoch 61, Batch 27, Loss: 0.172\n",
      "Training: Epoch 61, Batch 28, Loss: 0.109\n",
      "Training: Epoch 61, Batch 29, Loss: 0.19\n",
      "Training: Epoch 61, Batch 30, Loss: 0.153\n",
      "Training: Epoch 61, Batch 31, Loss: 0.136\n",
      "Training: Epoch 61, Batch 32, Loss: 0.131\n",
      "Training: Epoch 61, Batch 33, Loss: 0.169\n",
      "Training: Epoch 61, Batch 34, Loss: 0.136\n",
      "Training: Epoch 61, Batch 35, Loss: 0.095\n",
      "Training: Epoch 61, Batch 36, Loss: 0.161\n",
      "Training: Epoch 61, Batch 37, Loss: 0.172\n",
      "Training: Epoch 61, Batch 38, Loss: 0.138\n",
      "Training: Epoch 61, Batch 39, Loss: 0.153\n",
      "Training: Epoch 61, Batch 40, Loss: 0.106\n",
      "Training: Epoch 61, Batch 41, Loss: 0.153\n",
      "Training: Epoch 61, Batch 42, Loss: 0.135\n",
      "Training: Epoch 61, Batch 43, Loss: 0.126\n",
      "Training: Epoch 61, Batch 44, Loss: 0.155\n",
      "Training: Epoch 61, Batch 45, Loss: 0.151\n",
      "Training: Epoch 61, Batch 46, Loss: 0.155\n",
      "Training: Epoch 61, Batch 47, Loss: 0.141\n",
      "Training: Epoch 61, Batch 48, Loss: 0.143\n",
      "Training: Epoch 61, Batch 49, Loss: 0.16\n",
      "Training: Epoch 61, Batch 50, Loss: 0.229\n",
      "Training: Epoch 61, Batch 51, Loss: 0.139\n",
      "Training: Epoch 61, Batch 52, Loss: 0.121\n",
      "Training: Epoch 61, Batch 53, Loss: 0.175\n",
      "Training: Epoch 61, Batch 54, Loss: 0.129\n",
      "Training: Epoch 61, Batch 55, Loss: 0.147\n",
      "Training: Epoch 61, Batch 56, Loss: 0.145\n",
      "Training: Epoch 61, Batch 57, Loss: 0.159\n",
      "Training: Epoch 61, Batch 58, Loss: 0.126\n",
      "Training: Epoch 61, Batch 59, Loss: 0.182\n",
      "Val: Epoch 61, Loss: 0.19\n",
      "Training: Epoch 62, Batch 0, Loss: 0.12\n",
      "Training: Epoch 62, Batch 1, Loss: 0.158\n",
      "Training: Epoch 62, Batch 2, Loss: 0.12\n",
      "Training: Epoch 62, Batch 3, Loss: 0.133\n",
      "Training: Epoch 62, Batch 4, Loss: 0.133\n",
      "Training: Epoch 62, Batch 5, Loss: 0.126\n",
      "Training: Epoch 62, Batch 6, Loss: 0.165\n",
      "Training: Epoch 62, Batch 7, Loss: 0.113\n",
      "Training: Epoch 62, Batch 8, Loss: 0.152\n",
      "Training: Epoch 62, Batch 9, Loss: 0.107\n",
      "Training: Epoch 62, Batch 10, Loss: 0.118\n",
      "Training: Epoch 62, Batch 11, Loss: 0.115\n",
      "Training: Epoch 62, Batch 12, Loss: 0.125\n",
      "Training: Epoch 62, Batch 13, Loss: 0.134\n",
      "Training: Epoch 62, Batch 14, Loss: 0.147\n",
      "Training: Epoch 62, Batch 15, Loss: 0.125\n",
      "Training: Epoch 62, Batch 16, Loss: 0.166\n",
      "Training: Epoch 62, Batch 17, Loss: 0.127\n",
      "Training: Epoch 62, Batch 18, Loss: 0.107\n",
      "Training: Epoch 62, Batch 19, Loss: 0.147\n",
      "Training: Epoch 62, Batch 20, Loss: 0.161\n",
      "Training: Epoch 62, Batch 21, Loss: 0.189\n",
      "Training: Epoch 62, Batch 22, Loss: 0.089\n",
      "Training: Epoch 62, Batch 23, Loss: 0.149\n",
      "Training: Epoch 62, Batch 24, Loss: 0.133\n",
      "Training: Epoch 62, Batch 25, Loss: 0.108\n",
      "Training: Epoch 62, Batch 26, Loss: 0.149\n",
      "Training: Epoch 62, Batch 27, Loss: 0.205\n",
      "Training: Epoch 62, Batch 28, Loss: 0.132\n",
      "Training: Epoch 62, Batch 29, Loss: 0.121\n",
      "Training: Epoch 62, Batch 30, Loss: 0.122\n",
      "Training: Epoch 62, Batch 31, Loss: 0.184\n",
      "Training: Epoch 62, Batch 32, Loss: 0.19\n",
      "Training: Epoch 62, Batch 33, Loss: 0.129\n",
      "Training: Epoch 62, Batch 34, Loss: 0.159\n",
      "Training: Epoch 62, Batch 35, Loss: 0.152\n",
      "Training: Epoch 62, Batch 36, Loss: 0.167\n",
      "Training: Epoch 62, Batch 37, Loss: 0.15\n",
      "Training: Epoch 62, Batch 38, Loss: 0.157\n",
      "Training: Epoch 62, Batch 39, Loss: 0.133\n",
      "Training: Epoch 62, Batch 40, Loss: 0.161\n",
      "Training: Epoch 62, Batch 41, Loss: 0.144\n",
      "Training: Epoch 62, Batch 42, Loss: 0.157\n",
      "Training: Epoch 62, Batch 43, Loss: 0.175\n",
      "Training: Epoch 62, Batch 44, Loss: 0.132\n",
      "Training: Epoch 62, Batch 45, Loss: 0.184\n",
      "Training: Epoch 62, Batch 46, Loss: 0.151\n",
      "Training: Epoch 62, Batch 47, Loss: 0.144\n",
      "Training: Epoch 62, Batch 48, Loss: 0.117\n",
      "Training: Epoch 62, Batch 49, Loss: 0.236\n",
      "Training: Epoch 62, Batch 50, Loss: 0.142\n",
      "Training: Epoch 62, Batch 51, Loss: 0.155\n",
      "Training: Epoch 62, Batch 52, Loss: 0.145\n",
      "Training: Epoch 62, Batch 53, Loss: 0.133\n",
      "Training: Epoch 62, Batch 54, Loss: 0.142\n",
      "Training: Epoch 62, Batch 55, Loss: 0.183\n",
      "Training: Epoch 62, Batch 56, Loss: 0.142\n",
      "Training: Epoch 62, Batch 57, Loss: 0.171\n",
      "Training: Epoch 62, Batch 58, Loss: 0.098\n",
      "Training: Epoch 62, Batch 59, Loss: 0.168\n",
      "Val: Epoch 62, Loss: 0.213\n",
      "Training: Epoch 63, Batch 0, Loss: 0.151\n",
      "Training: Epoch 63, Batch 1, Loss: 0.185\n",
      "Training: Epoch 63, Batch 2, Loss: 0.19\n",
      "Training: Epoch 63, Batch 3, Loss: 0.116\n",
      "Training: Epoch 63, Batch 4, Loss: 0.14\n",
      "Training: Epoch 63, Batch 5, Loss: 0.112\n",
      "Training: Epoch 63, Batch 6, Loss: 0.158\n",
      "Training: Epoch 63, Batch 7, Loss: 0.14\n",
      "Training: Epoch 63, Batch 8, Loss: 0.097\n",
      "Training: Epoch 63, Batch 9, Loss: 0.209\n",
      "Training: Epoch 63, Batch 10, Loss: 0.177\n",
      "Training: Epoch 63, Batch 11, Loss: 0.089\n",
      "Training: Epoch 63, Batch 12, Loss: 0.151\n",
      "Training: Epoch 63, Batch 13, Loss: 0.17\n",
      "Training: Epoch 63, Batch 14, Loss: 0.104\n",
      "Training: Epoch 63, Batch 15, Loss: 0.164\n",
      "Training: Epoch 63, Batch 16, Loss: 0.159\n",
      "Training: Epoch 63, Batch 17, Loss: 0.158\n",
      "Training: Epoch 63, Batch 18, Loss: 0.136\n",
      "Training: Epoch 63, Batch 19, Loss: 0.144\n",
      "Training: Epoch 63, Batch 20, Loss: 0.151\n",
      "Training: Epoch 63, Batch 21, Loss: 0.174\n",
      "Training: Epoch 63, Batch 22, Loss: 0.136\n",
      "Training: Epoch 63, Batch 23, Loss: 0.105\n",
      "Training: Epoch 63, Batch 24, Loss: 0.119\n",
      "Training: Epoch 63, Batch 25, Loss: 0.152\n",
      "Training: Epoch 63, Batch 26, Loss: 0.101\n",
      "Training: Epoch 63, Batch 27, Loss: 0.154\n",
      "Training: Epoch 63, Batch 28, Loss: 0.136\n",
      "Training: Epoch 63, Batch 29, Loss: 0.147\n",
      "Training: Epoch 63, Batch 30, Loss: 0.119\n",
      "Training: Epoch 63, Batch 31, Loss: 0.121\n",
      "Training: Epoch 63, Batch 32, Loss: 0.156\n",
      "Training: Epoch 63, Batch 33, Loss: 0.141\n",
      "Training: Epoch 63, Batch 34, Loss: 0.116\n",
      "Training: Epoch 63, Batch 35, Loss: 0.134\n",
      "Training: Epoch 63, Batch 36, Loss: 0.151\n",
      "Training: Epoch 63, Batch 37, Loss: 0.14\n",
      "Training: Epoch 63, Batch 38, Loss: 0.127\n",
      "Training: Epoch 63, Batch 39, Loss: 0.126\n",
      "Training: Epoch 63, Batch 40, Loss: 0.14\n",
      "Training: Epoch 63, Batch 41, Loss: 0.142\n",
      "Training: Epoch 63, Batch 42, Loss: 0.159\n",
      "Training: Epoch 63, Batch 43, Loss: 0.112\n",
      "Training: Epoch 63, Batch 44, Loss: 0.105\n",
      "Training: Epoch 63, Batch 45, Loss: 0.144\n",
      "Training: Epoch 63, Batch 46, Loss: 0.152\n",
      "Training: Epoch 63, Batch 47, Loss: 0.103\n",
      "Training: Epoch 63, Batch 48, Loss: 0.099\n",
      "Training: Epoch 63, Batch 49, Loss: 0.108\n",
      "Training: Epoch 63, Batch 50, Loss: 0.133\n",
      "Training: Epoch 63, Batch 51, Loss: 0.137\n",
      "Training: Epoch 63, Batch 52, Loss: 0.115\n",
      "Training: Epoch 63, Batch 53, Loss: 0.173\n",
      "Training: Epoch 63, Batch 54, Loss: 0.124\n",
      "Training: Epoch 63, Batch 55, Loss: 0.146\n",
      "Training: Epoch 63, Batch 56, Loss: 0.131\n",
      "Training: Epoch 63, Batch 57, Loss: 0.15\n",
      "Training: Epoch 63, Batch 58, Loss: 0.139\n",
      "Training: Epoch 63, Batch 59, Loss: 0.139\n",
      "Val: Epoch 63, Loss: 0.209\n",
      "Training: Epoch 64, Batch 0, Loss: 0.117\n",
      "Training: Epoch 64, Batch 1, Loss: 0.123\n",
      "Training: Epoch 64, Batch 2, Loss: 0.135\n",
      "Training: Epoch 64, Batch 3, Loss: 0.14\n",
      "Training: Epoch 64, Batch 4, Loss: 0.099\n",
      "Training: Epoch 64, Batch 5, Loss: 0.104\n",
      "Training: Epoch 64, Batch 6, Loss: 0.12\n",
      "Training: Epoch 64, Batch 7, Loss: 0.151\n",
      "Training: Epoch 64, Batch 8, Loss: 0.134\n",
      "Training: Epoch 64, Batch 9, Loss: 0.121\n",
      "Training: Epoch 64, Batch 10, Loss: 0.11\n",
      "Training: Epoch 64, Batch 11, Loss: 0.126\n",
      "Training: Epoch 64, Batch 12, Loss: 0.112\n",
      "Training: Epoch 64, Batch 13, Loss: 0.134\n",
      "Training: Epoch 64, Batch 14, Loss: 0.103\n",
      "Training: Epoch 64, Batch 15, Loss: 0.126\n",
      "Training: Epoch 64, Batch 16, Loss: 0.136\n",
      "Training: Epoch 64, Batch 17, Loss: 0.148\n",
      "Training: Epoch 64, Batch 18, Loss: 0.118\n",
      "Training: Epoch 64, Batch 19, Loss: 0.145\n",
      "Training: Epoch 64, Batch 20, Loss: 0.133\n",
      "Training: Epoch 64, Batch 21, Loss: 0.153\n",
      "Training: Epoch 64, Batch 22, Loss: 0.123\n",
      "Training: Epoch 64, Batch 23, Loss: 0.151\n",
      "Training: Epoch 64, Batch 24, Loss: 0.183\n",
      "Training: Epoch 64, Batch 25, Loss: 0.091\n",
      "Training: Epoch 64, Batch 26, Loss: 0.145\n",
      "Training: Epoch 64, Batch 27, Loss: 0.132\n",
      "Training: Epoch 64, Batch 28, Loss: 0.166\n",
      "Training: Epoch 64, Batch 29, Loss: 0.132\n",
      "Training: Epoch 64, Batch 30, Loss: 0.133\n",
      "Training: Epoch 64, Batch 31, Loss: 0.167\n",
      "Training: Epoch 64, Batch 32, Loss: 0.122\n",
      "Training: Epoch 64, Batch 33, Loss: 0.144\n",
      "Training: Epoch 64, Batch 34, Loss: 0.194\n",
      "Training: Epoch 64, Batch 35, Loss: 0.116\n",
      "Training: Epoch 64, Batch 36, Loss: 0.125\n",
      "Training: Epoch 64, Batch 37, Loss: 0.148\n",
      "Training: Epoch 64, Batch 38, Loss: 0.186\n",
      "Training: Epoch 64, Batch 39, Loss: 0.16\n",
      "Training: Epoch 64, Batch 40, Loss: 0.114\n",
      "Training: Epoch 64, Batch 41, Loss: 0.143\n",
      "Training: Epoch 64, Batch 42, Loss: 0.124\n",
      "Training: Epoch 64, Batch 43, Loss: 0.182\n",
      "Training: Epoch 64, Batch 44, Loss: 0.116\n",
      "Training: Epoch 64, Batch 45, Loss: 0.128\n",
      "Training: Epoch 64, Batch 46, Loss: 0.152\n",
      "Training: Epoch 64, Batch 47, Loss: 0.137\n",
      "Training: Epoch 64, Batch 48, Loss: 0.143\n",
      "Training: Epoch 64, Batch 49, Loss: 0.13\n",
      "Training: Epoch 64, Batch 50, Loss: 0.156\n",
      "Training: Epoch 64, Batch 51, Loss: 0.136\n",
      "Training: Epoch 64, Batch 52, Loss: 0.129\n",
      "Training: Epoch 64, Batch 53, Loss: 0.117\n",
      "Training: Epoch 64, Batch 54, Loss: 0.117\n",
      "Training: Epoch 64, Batch 55, Loss: 0.122\n",
      "Training: Epoch 64, Batch 56, Loss: 0.177\n",
      "Training: Epoch 64, Batch 57, Loss: 0.166\n",
      "Training: Epoch 64, Batch 58, Loss: 0.109\n",
      "Training: Epoch 64, Batch 59, Loss: 0.14\n",
      "Val: Epoch 64, Loss: 0.238\n",
      "Training: Epoch 65, Batch 0, Loss: 0.137\n",
      "Training: Epoch 65, Batch 1, Loss: 0.144\n",
      "Training: Epoch 65, Batch 2, Loss: 0.139\n",
      "Training: Epoch 65, Batch 3, Loss: 0.14\n",
      "Training: Epoch 65, Batch 4, Loss: 0.122\n",
      "Training: Epoch 65, Batch 5, Loss: 0.139\n",
      "Training: Epoch 65, Batch 6, Loss: 0.13\n",
      "Training: Epoch 65, Batch 7, Loss: 0.128\n",
      "Training: Epoch 65, Batch 8, Loss: 0.118\n",
      "Training: Epoch 65, Batch 9, Loss: 0.149\n",
      "Training: Epoch 65, Batch 10, Loss: 0.128\n",
      "Training: Epoch 65, Batch 11, Loss: 0.119\n",
      "Training: Epoch 65, Batch 12, Loss: 0.124\n",
      "Training: Epoch 65, Batch 13, Loss: 0.129\n",
      "Training: Epoch 65, Batch 14, Loss: 0.118\n",
      "Training: Epoch 65, Batch 15, Loss: 0.128\n",
      "Training: Epoch 65, Batch 16, Loss: 0.186\n",
      "Training: Epoch 65, Batch 17, Loss: 0.107\n",
      "Training: Epoch 65, Batch 18, Loss: 0.133\n",
      "Training: Epoch 65, Batch 19, Loss: 0.138\n",
      "Training: Epoch 65, Batch 20, Loss: 0.165\n",
      "Training: Epoch 65, Batch 21, Loss: 0.131\n",
      "Training: Epoch 65, Batch 22, Loss: 0.13\n",
      "Training: Epoch 65, Batch 23, Loss: 0.126\n",
      "Training: Epoch 65, Batch 24, Loss: 0.146\n",
      "Training: Epoch 65, Batch 25, Loss: 0.156\n",
      "Training: Epoch 65, Batch 26, Loss: 0.132\n",
      "Training: Epoch 65, Batch 27, Loss: 0.138\n",
      "Training: Epoch 65, Batch 28, Loss: 0.111\n",
      "Training: Epoch 65, Batch 29, Loss: 0.129\n",
      "Training: Epoch 65, Batch 30, Loss: 0.127\n",
      "Training: Epoch 65, Batch 31, Loss: 0.139\n",
      "Training: Epoch 65, Batch 32, Loss: 0.107\n",
      "Training: Epoch 65, Batch 33, Loss: 0.139\n",
      "Training: Epoch 65, Batch 34, Loss: 0.123\n",
      "Training: Epoch 65, Batch 35, Loss: 0.156\n",
      "Training: Epoch 65, Batch 36, Loss: 0.101\n",
      "Training: Epoch 65, Batch 37, Loss: 0.106\n",
      "Training: Epoch 65, Batch 38, Loss: 0.147\n",
      "Training: Epoch 65, Batch 39, Loss: 0.139\n",
      "Training: Epoch 65, Batch 40, Loss: 0.143\n",
      "Training: Epoch 65, Batch 41, Loss: 0.096\n",
      "Training: Epoch 65, Batch 42, Loss: 0.11\n",
      "Training: Epoch 65, Batch 43, Loss: 0.122\n",
      "Training: Epoch 65, Batch 44, Loss: 0.153\n",
      "Training: Epoch 65, Batch 45, Loss: 0.135\n",
      "Training: Epoch 65, Batch 46, Loss: 0.13\n",
      "Training: Epoch 65, Batch 47, Loss: 0.147\n",
      "Training: Epoch 65, Batch 48, Loss: 0.11\n",
      "Training: Epoch 65, Batch 49, Loss: 0.136\n",
      "Training: Epoch 65, Batch 50, Loss: 0.107\n",
      "Training: Epoch 65, Batch 51, Loss: 0.123\n",
      "Training: Epoch 65, Batch 52, Loss: 0.16\n",
      "Training: Epoch 65, Batch 53, Loss: 0.12\n",
      "Training: Epoch 65, Batch 54, Loss: 0.13\n",
      "Training: Epoch 65, Batch 55, Loss: 0.155\n",
      "Training: Epoch 65, Batch 56, Loss: 0.148\n",
      "Training: Epoch 65, Batch 57, Loss: 0.111\n",
      "Training: Epoch 65, Batch 58, Loss: 0.157\n",
      "Training: Epoch 65, Batch 59, Loss: 0.108\n",
      "Val: Epoch 65, Loss: 0.229\n",
      "Training: Epoch 66, Batch 0, Loss: 0.13\n",
      "Training: Epoch 66, Batch 1, Loss: 0.14\n",
      "Training: Epoch 66, Batch 2, Loss: 0.118\n",
      "Training: Epoch 66, Batch 3, Loss: 0.127\n",
      "Training: Epoch 66, Batch 4, Loss: 0.128\n",
      "Training: Epoch 66, Batch 5, Loss: 0.165\n",
      "Training: Epoch 66, Batch 6, Loss: 0.125\n",
      "Training: Epoch 66, Batch 7, Loss: 0.138\n",
      "Training: Epoch 66, Batch 8, Loss: 0.122\n",
      "Training: Epoch 66, Batch 9, Loss: 0.147\n",
      "Training: Epoch 66, Batch 10, Loss: 0.137\n",
      "Training: Epoch 66, Batch 11, Loss: 0.125\n",
      "Training: Epoch 66, Batch 12, Loss: 0.143\n",
      "Training: Epoch 66, Batch 13, Loss: 0.131\n",
      "Training: Epoch 66, Batch 14, Loss: 0.189\n",
      "Training: Epoch 66, Batch 15, Loss: 0.147\n",
      "Training: Epoch 66, Batch 16, Loss: 0.198\n",
      "Training: Epoch 66, Batch 17, Loss: 0.122\n",
      "Training: Epoch 66, Batch 18, Loss: 0.129\n",
      "Training: Epoch 66, Batch 19, Loss: 0.151\n",
      "Training: Epoch 66, Batch 20, Loss: 0.172\n",
      "Training: Epoch 66, Batch 21, Loss: 0.167\n",
      "Training: Epoch 66, Batch 22, Loss: 0.126\n",
      "Training: Epoch 66, Batch 23, Loss: 0.132\n",
      "Training: Epoch 66, Batch 24, Loss: 0.129\n",
      "Training: Epoch 66, Batch 25, Loss: 0.127\n",
      "Training: Epoch 66, Batch 26, Loss: 0.121\n",
      "Training: Epoch 66, Batch 27, Loss: 0.22\n",
      "Training: Epoch 66, Batch 28, Loss: 0.115\n",
      "Training: Epoch 66, Batch 29, Loss: 0.127\n",
      "Training: Epoch 66, Batch 30, Loss: 0.113\n",
      "Training: Epoch 66, Batch 31, Loss: 0.123\n",
      "Training: Epoch 66, Batch 32, Loss: 0.126\n",
      "Training: Epoch 66, Batch 33, Loss: 0.134\n",
      "Training: Epoch 66, Batch 34, Loss: 0.164\n",
      "Training: Epoch 66, Batch 35, Loss: 0.162\n",
      "Training: Epoch 66, Batch 36, Loss: 0.139\n",
      "Training: Epoch 66, Batch 37, Loss: 0.155\n",
      "Training: Epoch 66, Batch 38, Loss: 0.129\n",
      "Training: Epoch 66, Batch 39, Loss: 0.122\n",
      "Training: Epoch 66, Batch 40, Loss: 0.137\n",
      "Training: Epoch 66, Batch 41, Loss: 0.141\n",
      "Training: Epoch 66, Batch 42, Loss: 0.111\n",
      "Training: Epoch 66, Batch 43, Loss: 0.135\n",
      "Training: Epoch 66, Batch 44, Loss: 0.162\n",
      "Training: Epoch 66, Batch 45, Loss: 0.135\n",
      "Training: Epoch 66, Batch 46, Loss: 0.144\n",
      "Training: Epoch 66, Batch 47, Loss: 0.116\n",
      "Training: Epoch 66, Batch 48, Loss: 0.136\n",
      "Training: Epoch 66, Batch 49, Loss: 0.106\n",
      "Training: Epoch 66, Batch 50, Loss: 0.153\n",
      "Training: Epoch 66, Batch 51, Loss: 0.153\n",
      "Training: Epoch 66, Batch 52, Loss: 0.133\n",
      "Training: Epoch 66, Batch 53, Loss: 0.141\n",
      "Training: Epoch 66, Batch 54, Loss: 0.135\n",
      "Training: Epoch 66, Batch 55, Loss: 0.164\n",
      "Training: Epoch 66, Batch 56, Loss: 0.124\n",
      "Training: Epoch 66, Batch 57, Loss: 0.188\n",
      "Training: Epoch 66, Batch 58, Loss: 0.1\n",
      "Training: Epoch 66, Batch 59, Loss: 0.115\n",
      "Val: Epoch 66, Loss: 0.202\n",
      "Training: Epoch 67, Batch 0, Loss: 0.106\n",
      "Training: Epoch 67, Batch 1, Loss: 0.122\n",
      "Training: Epoch 67, Batch 2, Loss: 0.163\n",
      "Training: Epoch 67, Batch 3, Loss: 0.122\n",
      "Training: Epoch 67, Batch 4, Loss: 0.092\n",
      "Training: Epoch 67, Batch 5, Loss: 0.104\n",
      "Training: Epoch 67, Batch 6, Loss: 0.131\n",
      "Training: Epoch 67, Batch 7, Loss: 0.148\n",
      "Training: Epoch 67, Batch 8, Loss: 0.159\n",
      "Training: Epoch 67, Batch 9, Loss: 0.122\n",
      "Training: Epoch 67, Batch 10, Loss: 0.097\n",
      "Training: Epoch 67, Batch 11, Loss: 0.121\n",
      "Training: Epoch 67, Batch 12, Loss: 0.127\n",
      "Training: Epoch 67, Batch 13, Loss: 0.133\n",
      "Training: Epoch 67, Batch 14, Loss: 0.131\n",
      "Training: Epoch 67, Batch 15, Loss: 0.099\n",
      "Training: Epoch 67, Batch 16, Loss: 0.128\n",
      "Training: Epoch 67, Batch 17, Loss: 0.142\n",
      "Training: Epoch 67, Batch 18, Loss: 0.096\n",
      "Training: Epoch 67, Batch 19, Loss: 0.104\n",
      "Training: Epoch 67, Batch 20, Loss: 0.139\n",
      "Training: Epoch 67, Batch 21, Loss: 0.126\n",
      "Training: Epoch 67, Batch 22, Loss: 0.132\n",
      "Training: Epoch 67, Batch 23, Loss: 0.131\n",
      "Training: Epoch 67, Batch 24, Loss: 0.129\n",
      "Training: Epoch 67, Batch 25, Loss: 0.107\n",
      "Training: Epoch 67, Batch 26, Loss: 0.1\n",
      "Training: Epoch 67, Batch 27, Loss: 0.12\n",
      "Training: Epoch 67, Batch 28, Loss: 0.134\n",
      "Training: Epoch 67, Batch 29, Loss: 0.142\n",
      "Training: Epoch 67, Batch 30, Loss: 0.113\n",
      "Training: Epoch 67, Batch 31, Loss: 0.13\n",
      "Training: Epoch 67, Batch 32, Loss: 0.132\n",
      "Training: Epoch 67, Batch 33, Loss: 0.111\n",
      "Training: Epoch 67, Batch 34, Loss: 0.143\n",
      "Training: Epoch 67, Batch 35, Loss: 0.103\n",
      "Training: Epoch 67, Batch 36, Loss: 0.115\n",
      "Training: Epoch 67, Batch 37, Loss: 0.106\n",
      "Training: Epoch 67, Batch 38, Loss: 0.122\n",
      "Training: Epoch 67, Batch 39, Loss: 0.11\n",
      "Training: Epoch 67, Batch 40, Loss: 0.118\n",
      "Training: Epoch 67, Batch 41, Loss: 0.107\n",
      "Training: Epoch 67, Batch 42, Loss: 0.111\n",
      "Training: Epoch 67, Batch 43, Loss: 0.116\n",
      "Training: Epoch 67, Batch 44, Loss: 0.109\n",
      "Training: Epoch 67, Batch 45, Loss: 0.12\n",
      "Training: Epoch 67, Batch 46, Loss: 0.145\n",
      "Training: Epoch 67, Batch 47, Loss: 0.121\n",
      "Training: Epoch 67, Batch 48, Loss: 0.127\n",
      "Training: Epoch 67, Batch 49, Loss: 0.1\n",
      "Training: Epoch 67, Batch 50, Loss: 0.136\n",
      "Training: Epoch 67, Batch 51, Loss: 0.105\n",
      "Training: Epoch 67, Batch 52, Loss: 0.1\n",
      "Training: Epoch 67, Batch 53, Loss: 0.109\n",
      "Training: Epoch 67, Batch 54, Loss: 0.135\n",
      "Training: Epoch 67, Batch 55, Loss: 0.133\n",
      "Training: Epoch 67, Batch 56, Loss: 0.143\n",
      "Training: Epoch 67, Batch 57, Loss: 0.135\n",
      "Training: Epoch 67, Batch 58, Loss: 0.163\n",
      "Training: Epoch 67, Batch 59, Loss: 0.132\n",
      "Val: Epoch 67, Loss: 0.239\n",
      "Training: Epoch 68, Batch 0, Loss: 0.116\n",
      "Training: Epoch 68, Batch 1, Loss: 0.126\n",
      "Training: Epoch 68, Batch 2, Loss: 0.094\n",
      "Training: Epoch 68, Batch 3, Loss: 0.115\n",
      "Training: Epoch 68, Batch 4, Loss: 0.11\n",
      "Training: Epoch 68, Batch 5, Loss: 0.127\n",
      "Training: Epoch 68, Batch 6, Loss: 0.107\n",
      "Training: Epoch 68, Batch 7, Loss: 0.134\n",
      "Training: Epoch 68, Batch 8, Loss: 0.138\n",
      "Training: Epoch 68, Batch 9, Loss: 0.146\n",
      "Training: Epoch 68, Batch 10, Loss: 0.132\n",
      "Training: Epoch 68, Batch 11, Loss: 0.126\n",
      "Training: Epoch 68, Batch 12, Loss: 0.104\n",
      "Training: Epoch 68, Batch 13, Loss: 0.119\n",
      "Training: Epoch 68, Batch 14, Loss: 0.123\n",
      "Training: Epoch 68, Batch 15, Loss: 0.183\n",
      "Training: Epoch 68, Batch 16, Loss: 0.117\n",
      "Training: Epoch 68, Batch 17, Loss: 0.16\n",
      "Training: Epoch 68, Batch 18, Loss: 0.129\n",
      "Training: Epoch 68, Batch 19, Loss: 0.124\n",
      "Training: Epoch 68, Batch 20, Loss: 0.115\n",
      "Training: Epoch 68, Batch 21, Loss: 0.112\n",
      "Training: Epoch 68, Batch 22, Loss: 0.189\n",
      "Training: Epoch 68, Batch 23, Loss: 0.13\n",
      "Training: Epoch 68, Batch 24, Loss: 0.125\n",
      "Training: Epoch 68, Batch 25, Loss: 0.119\n",
      "Training: Epoch 68, Batch 26, Loss: 0.101\n",
      "Training: Epoch 68, Batch 27, Loss: 0.126\n",
      "Training: Epoch 68, Batch 28, Loss: 0.103\n",
      "Training: Epoch 68, Batch 29, Loss: 0.157\n",
      "Training: Epoch 68, Batch 30, Loss: 0.136\n",
      "Training: Epoch 68, Batch 31, Loss: 0.112\n",
      "Training: Epoch 68, Batch 32, Loss: 0.137\n",
      "Training: Epoch 68, Batch 33, Loss: 0.103\n",
      "Training: Epoch 68, Batch 34, Loss: 0.098\n",
      "Training: Epoch 68, Batch 35, Loss: 0.119\n",
      "Training: Epoch 68, Batch 36, Loss: 0.104\n",
      "Training: Epoch 68, Batch 37, Loss: 0.111\n",
      "Training: Epoch 68, Batch 38, Loss: 0.116\n",
      "Training: Epoch 68, Batch 39, Loss: 0.139\n",
      "Training: Epoch 68, Batch 40, Loss: 0.131\n",
      "Training: Epoch 68, Batch 41, Loss: 0.164\n",
      "Training: Epoch 68, Batch 42, Loss: 0.114\n",
      "Training: Epoch 68, Batch 43, Loss: 0.158\n",
      "Training: Epoch 68, Batch 44, Loss: 0.11\n",
      "Training: Epoch 68, Batch 45, Loss: 0.138\n",
      "Training: Epoch 68, Batch 46, Loss: 0.091\n",
      "Training: Epoch 68, Batch 47, Loss: 0.111\n",
      "Training: Epoch 68, Batch 48, Loss: 0.139\n",
      "Training: Epoch 68, Batch 49, Loss: 0.14\n",
      "Training: Epoch 68, Batch 50, Loss: 0.151\n",
      "Training: Epoch 68, Batch 51, Loss: 0.112\n",
      "Training: Epoch 68, Batch 52, Loss: 0.1\n",
      "Training: Epoch 68, Batch 53, Loss: 0.11\n",
      "Training: Epoch 68, Batch 54, Loss: 0.115\n",
      "Training: Epoch 68, Batch 55, Loss: 0.111\n",
      "Training: Epoch 68, Batch 56, Loss: 0.123\n",
      "Training: Epoch 68, Batch 57, Loss: 0.136\n",
      "Training: Epoch 68, Batch 58, Loss: 0.123\n",
      "Training: Epoch 68, Batch 59, Loss: 0.093\n",
      "Val: Epoch 68, Loss: 0.281\n",
      "Training: Epoch 69, Batch 0, Loss: 0.12\n",
      "Training: Epoch 69, Batch 1, Loss: 0.127\n",
      "Training: Epoch 69, Batch 2, Loss: 0.141\n",
      "Training: Epoch 69, Batch 3, Loss: 0.105\n",
      "Training: Epoch 69, Batch 4, Loss: 0.137\n",
      "Training: Epoch 69, Batch 5, Loss: 0.123\n",
      "Training: Epoch 69, Batch 6, Loss: 0.109\n",
      "Training: Epoch 69, Batch 7, Loss: 0.128\n",
      "Training: Epoch 69, Batch 8, Loss: 0.154\n",
      "Training: Epoch 69, Batch 9, Loss: 0.11\n",
      "Training: Epoch 69, Batch 10, Loss: 0.083\n",
      "Training: Epoch 69, Batch 11, Loss: 0.148\n",
      "Training: Epoch 69, Batch 12, Loss: 0.13\n",
      "Training: Epoch 69, Batch 13, Loss: 0.132\n",
      "Training: Epoch 69, Batch 14, Loss: 0.122\n",
      "Training: Epoch 69, Batch 15, Loss: 0.089\n",
      "Training: Epoch 69, Batch 16, Loss: 0.107\n",
      "Training: Epoch 69, Batch 17, Loss: 0.141\n",
      "Training: Epoch 69, Batch 18, Loss: 0.111\n",
      "Training: Epoch 69, Batch 19, Loss: 0.169\n",
      "Training: Epoch 69, Batch 20, Loss: 0.133\n",
      "Training: Epoch 69, Batch 21, Loss: 0.146\n",
      "Training: Epoch 69, Batch 22, Loss: 0.16\n",
      "Training: Epoch 69, Batch 23, Loss: 0.094\n",
      "Training: Epoch 69, Batch 24, Loss: 0.114\n",
      "Training: Epoch 69, Batch 25, Loss: 0.115\n",
      "Training: Epoch 69, Batch 26, Loss: 0.103\n",
      "Training: Epoch 69, Batch 27, Loss: 0.114\n",
      "Training: Epoch 69, Batch 28, Loss: 0.14\n",
      "Training: Epoch 69, Batch 29, Loss: 0.128\n",
      "Training: Epoch 69, Batch 30, Loss: 0.137\n",
      "Training: Epoch 69, Batch 31, Loss: 0.148\n",
      "Training: Epoch 69, Batch 32, Loss: 0.131\n",
      "Training: Epoch 69, Batch 33, Loss: 0.119\n",
      "Training: Epoch 69, Batch 34, Loss: 0.143\n",
      "Training: Epoch 69, Batch 35, Loss: 0.117\n",
      "Training: Epoch 69, Batch 36, Loss: 0.12\n",
      "Training: Epoch 69, Batch 37, Loss: 0.135\n",
      "Training: Epoch 69, Batch 38, Loss: 0.117\n",
      "Training: Epoch 69, Batch 39, Loss: 0.104\n",
      "Training: Epoch 69, Batch 40, Loss: 0.091\n",
      "Training: Epoch 69, Batch 41, Loss: 0.147\n",
      "Training: Epoch 69, Batch 42, Loss: 0.134\n",
      "Training: Epoch 69, Batch 43, Loss: 0.113\n",
      "Training: Epoch 69, Batch 44, Loss: 0.091\n",
      "Training: Epoch 69, Batch 45, Loss: 0.104\n",
      "Training: Epoch 69, Batch 46, Loss: 0.167\n",
      "Training: Epoch 69, Batch 47, Loss: 0.114\n",
      "Training: Epoch 69, Batch 48, Loss: 0.096\n",
      "Training: Epoch 69, Batch 49, Loss: 0.129\n",
      "Training: Epoch 69, Batch 50, Loss: 0.112\n",
      "Training: Epoch 69, Batch 51, Loss: 0.114\n",
      "Training: Epoch 69, Batch 52, Loss: 0.109\n",
      "Training: Epoch 69, Batch 53, Loss: 0.127\n",
      "Training: Epoch 69, Batch 54, Loss: 0.106\n",
      "Training: Epoch 69, Batch 55, Loss: 0.097\n",
      "Training: Epoch 69, Batch 56, Loss: 0.153\n",
      "Training: Epoch 69, Batch 57, Loss: 0.132\n",
      "Training: Epoch 69, Batch 58, Loss: 0.104\n",
      "Training: Epoch 69, Batch 59, Loss: 0.12\n",
      "Val: Epoch 69, Loss: 0.215\n",
      "Training: Epoch 70, Batch 0, Loss: 0.104\n",
      "Training: Epoch 70, Batch 1, Loss: 0.171\n",
      "Training: Epoch 70, Batch 2, Loss: 0.126\n",
      "Training: Epoch 70, Batch 3, Loss: 0.127\n",
      "Training: Epoch 70, Batch 4, Loss: 0.123\n",
      "Training: Epoch 70, Batch 5, Loss: 0.123\n",
      "Training: Epoch 70, Batch 6, Loss: 0.16\n",
      "Training: Epoch 70, Batch 7, Loss: 0.098\n",
      "Training: Epoch 70, Batch 8, Loss: 0.155\n",
      "Training: Epoch 70, Batch 9, Loss: 0.142\n",
      "Training: Epoch 70, Batch 10, Loss: 0.108\n",
      "Training: Epoch 70, Batch 11, Loss: 0.108\n",
      "Training: Epoch 70, Batch 12, Loss: 0.165\n",
      "Training: Epoch 70, Batch 13, Loss: 0.119\n",
      "Training: Epoch 70, Batch 14, Loss: 0.116\n",
      "Training: Epoch 70, Batch 15, Loss: 0.103\n",
      "Training: Epoch 70, Batch 16, Loss: 0.13\n",
      "Training: Epoch 70, Batch 17, Loss: 0.179\n",
      "Training: Epoch 70, Batch 18, Loss: 0.113\n",
      "Training: Epoch 70, Batch 19, Loss: 0.138\n",
      "Training: Epoch 70, Batch 20, Loss: 0.201\n",
      "Training: Epoch 70, Batch 21, Loss: 0.124\n",
      "Training: Epoch 70, Batch 22, Loss: 0.172\n",
      "Training: Epoch 70, Batch 23, Loss: 0.16\n",
      "Training: Epoch 70, Batch 24, Loss: 0.146\n",
      "Training: Epoch 70, Batch 25, Loss: 0.113\n",
      "Training: Epoch 70, Batch 26, Loss: 0.16\n",
      "Training: Epoch 70, Batch 27, Loss: 0.147\n",
      "Training: Epoch 70, Batch 28, Loss: 0.113\n",
      "Training: Epoch 70, Batch 29, Loss: 0.111\n",
      "Training: Epoch 70, Batch 30, Loss: 0.145\n",
      "Training: Epoch 70, Batch 31, Loss: 0.204\n",
      "Training: Epoch 70, Batch 32, Loss: 0.133\n",
      "Training: Epoch 70, Batch 33, Loss: 0.109\n",
      "Training: Epoch 70, Batch 34, Loss: 0.122\n",
      "Training: Epoch 70, Batch 35, Loss: 0.143\n",
      "Training: Epoch 70, Batch 36, Loss: 0.117\n",
      "Training: Epoch 70, Batch 37, Loss: 0.144\n",
      "Training: Epoch 70, Batch 38, Loss: 0.122\n",
      "Training: Epoch 70, Batch 39, Loss: 0.113\n",
      "Training: Epoch 70, Batch 40, Loss: 0.114\n",
      "Training: Epoch 70, Batch 41, Loss: 0.15\n",
      "Training: Epoch 70, Batch 42, Loss: 0.166\n",
      "Training: Epoch 70, Batch 43, Loss: 0.115\n",
      "Training: Epoch 70, Batch 44, Loss: 0.112\n",
      "Training: Epoch 70, Batch 45, Loss: 0.111\n",
      "Training: Epoch 70, Batch 46, Loss: 0.12\n",
      "Training: Epoch 70, Batch 47, Loss: 0.113\n",
      "Training: Epoch 70, Batch 48, Loss: 0.123\n",
      "Training: Epoch 70, Batch 49, Loss: 0.126\n",
      "Training: Epoch 70, Batch 50, Loss: 0.103\n",
      "Training: Epoch 70, Batch 51, Loss: 0.169\n",
      "Training: Epoch 70, Batch 52, Loss: 0.12\n",
      "Training: Epoch 70, Batch 53, Loss: 0.107\n",
      "Training: Epoch 70, Batch 54, Loss: 0.121\n",
      "Training: Epoch 70, Batch 55, Loss: 0.149\n",
      "Training: Epoch 70, Batch 56, Loss: 0.083\n",
      "Training: Epoch 70, Batch 57, Loss: 0.128\n",
      "Training: Epoch 70, Batch 58, Loss: 0.112\n",
      "Training: Epoch 70, Batch 59, Loss: 0.125\n",
      "Val: Epoch 70, Loss: 0.223\n",
      "Training: Epoch 71, Batch 0, Loss: 0.133\n",
      "Training: Epoch 71, Batch 1, Loss: 0.146\n",
      "Training: Epoch 71, Batch 2, Loss: 0.121\n",
      "Training: Epoch 71, Batch 3, Loss: 0.124\n",
      "Training: Epoch 71, Batch 4, Loss: 0.116\n",
      "Training: Epoch 71, Batch 5, Loss: 0.106\n",
      "Training: Epoch 71, Batch 6, Loss: 0.131\n",
      "Training: Epoch 71, Batch 7, Loss: 0.135\n",
      "Training: Epoch 71, Batch 8, Loss: 0.09\n",
      "Training: Epoch 71, Batch 9, Loss: 0.112\n",
      "Training: Epoch 71, Batch 10, Loss: 0.131\n",
      "Training: Epoch 71, Batch 11, Loss: 0.109\n",
      "Training: Epoch 71, Batch 12, Loss: 0.142\n",
      "Training: Epoch 71, Batch 13, Loss: 0.13\n",
      "Training: Epoch 71, Batch 14, Loss: 0.118\n",
      "Training: Epoch 71, Batch 15, Loss: 0.152\n",
      "Training: Epoch 71, Batch 16, Loss: 0.121\n",
      "Training: Epoch 71, Batch 17, Loss: 0.106\n",
      "Training: Epoch 71, Batch 18, Loss: 0.085\n",
      "Training: Epoch 71, Batch 19, Loss: 0.134\n",
      "Training: Epoch 71, Batch 20, Loss: 0.113\n",
      "Training: Epoch 71, Batch 21, Loss: 0.132\n",
      "Training: Epoch 71, Batch 22, Loss: 0.102\n",
      "Training: Epoch 71, Batch 23, Loss: 0.113\n",
      "Training: Epoch 71, Batch 24, Loss: 0.116\n",
      "Training: Epoch 71, Batch 25, Loss: 0.113\n",
      "Training: Epoch 71, Batch 26, Loss: 0.152\n",
      "Training: Epoch 71, Batch 27, Loss: 0.123\n",
      "Training: Epoch 71, Batch 28, Loss: 0.126\n",
      "Training: Epoch 71, Batch 29, Loss: 0.123\n",
      "Training: Epoch 71, Batch 30, Loss: 0.118\n",
      "Training: Epoch 71, Batch 31, Loss: 0.15\n",
      "Training: Epoch 71, Batch 32, Loss: 0.129\n",
      "Training: Epoch 71, Batch 33, Loss: 0.129\n",
      "Training: Epoch 71, Batch 34, Loss: 0.118\n",
      "Training: Epoch 71, Batch 35, Loss: 0.119\n",
      "Training: Epoch 71, Batch 36, Loss: 0.115\n",
      "Training: Epoch 71, Batch 37, Loss: 0.116\n",
      "Training: Epoch 71, Batch 38, Loss: 0.117\n",
      "Training: Epoch 71, Batch 39, Loss: 0.118\n",
      "Training: Epoch 71, Batch 40, Loss: 0.134\n",
      "Training: Epoch 71, Batch 41, Loss: 0.113\n",
      "Training: Epoch 71, Batch 42, Loss: 0.097\n",
      "Training: Epoch 71, Batch 43, Loss: 0.117\n",
      "Training: Epoch 71, Batch 44, Loss: 0.142\n",
      "Training: Epoch 71, Batch 45, Loss: 0.12\n",
      "Training: Epoch 71, Batch 46, Loss: 0.116\n",
      "Training: Epoch 71, Batch 47, Loss: 0.114\n",
      "Training: Epoch 71, Batch 48, Loss: 0.111\n",
      "Training: Epoch 71, Batch 49, Loss: 0.11\n",
      "Training: Epoch 71, Batch 50, Loss: 0.135\n",
      "Training: Epoch 71, Batch 51, Loss: 0.108\n",
      "Training: Epoch 71, Batch 52, Loss: 0.143\n",
      "Training: Epoch 71, Batch 53, Loss: 0.119\n",
      "Training: Epoch 71, Batch 54, Loss: 0.132\n",
      "Training: Epoch 71, Batch 55, Loss: 0.104\n",
      "Training: Epoch 71, Batch 56, Loss: 0.103\n",
      "Training: Epoch 71, Batch 57, Loss: 0.12\n",
      "Training: Epoch 71, Batch 58, Loss: 0.084\n",
      "Training: Epoch 71, Batch 59, Loss: 0.119\n",
      "Val: Epoch 71, Loss: 0.204\n",
      "Training: Epoch 72, Batch 0, Loss: 0.099\n",
      "Training: Epoch 72, Batch 1, Loss: 0.087\n",
      "Training: Epoch 72, Batch 2, Loss: 0.112\n",
      "Training: Epoch 72, Batch 3, Loss: 0.127\n",
      "Training: Epoch 72, Batch 4, Loss: 0.087\n",
      "Training: Epoch 72, Batch 5, Loss: 0.11\n",
      "Training: Epoch 72, Batch 6, Loss: 0.106\n",
      "Training: Epoch 72, Batch 7, Loss: 0.118\n",
      "Training: Epoch 72, Batch 8, Loss: 0.097\n",
      "Training: Epoch 72, Batch 9, Loss: 0.102\n",
      "Training: Epoch 72, Batch 10, Loss: 0.11\n",
      "Training: Epoch 72, Batch 11, Loss: 0.118\n",
      "Training: Epoch 72, Batch 12, Loss: 0.12\n",
      "Training: Epoch 72, Batch 13, Loss: 0.121\n",
      "Training: Epoch 72, Batch 14, Loss: 0.117\n",
      "Training: Epoch 72, Batch 15, Loss: 0.091\n",
      "Training: Epoch 72, Batch 16, Loss: 0.12\n",
      "Training: Epoch 72, Batch 17, Loss: 0.107\n",
      "Training: Epoch 72, Batch 18, Loss: 0.104\n",
      "Training: Epoch 72, Batch 19, Loss: 0.115\n",
      "Training: Epoch 72, Batch 20, Loss: 0.123\n",
      "Training: Epoch 72, Batch 21, Loss: 0.132\n",
      "Training: Epoch 72, Batch 22, Loss: 0.093\n",
      "Training: Epoch 72, Batch 23, Loss: 0.102\n",
      "Training: Epoch 72, Batch 24, Loss: 0.095\n",
      "Training: Epoch 72, Batch 25, Loss: 0.169\n",
      "Training: Epoch 72, Batch 26, Loss: 0.115\n",
      "Training: Epoch 72, Batch 27, Loss: 0.115\n",
      "Training: Epoch 72, Batch 28, Loss: 0.112\n",
      "Training: Epoch 72, Batch 29, Loss: 0.14\n",
      "Training: Epoch 72, Batch 30, Loss: 0.118\n",
      "Training: Epoch 72, Batch 31, Loss: 0.12\n",
      "Training: Epoch 72, Batch 32, Loss: 0.103\n",
      "Training: Epoch 72, Batch 33, Loss: 0.093\n",
      "Training: Epoch 72, Batch 34, Loss: 0.125\n",
      "Training: Epoch 72, Batch 35, Loss: 0.137\n",
      "Training: Epoch 72, Batch 36, Loss: 0.108\n",
      "Training: Epoch 72, Batch 37, Loss: 0.109\n",
      "Training: Epoch 72, Batch 38, Loss: 0.142\n",
      "Training: Epoch 72, Batch 39, Loss: 0.107\n",
      "Training: Epoch 72, Batch 40, Loss: 0.088\n",
      "Training: Epoch 72, Batch 41, Loss: 0.096\n",
      "Training: Epoch 72, Batch 42, Loss: 0.116\n",
      "Training: Epoch 72, Batch 43, Loss: 0.132\n",
      "Training: Epoch 72, Batch 44, Loss: 0.112\n",
      "Training: Epoch 72, Batch 45, Loss: 0.088\n",
      "Training: Epoch 72, Batch 46, Loss: 0.122\n",
      "Training: Epoch 72, Batch 47, Loss: 0.12\n",
      "Training: Epoch 72, Batch 48, Loss: 0.135\n",
      "Training: Epoch 72, Batch 49, Loss: 0.133\n",
      "Training: Epoch 72, Batch 50, Loss: 0.129\n",
      "Training: Epoch 72, Batch 51, Loss: 0.103\n",
      "Training: Epoch 72, Batch 52, Loss: 0.113\n",
      "Training: Epoch 72, Batch 53, Loss: 0.103\n",
      "Training: Epoch 72, Batch 54, Loss: 0.098\n",
      "Training: Epoch 72, Batch 55, Loss: 0.124\n",
      "Training: Epoch 72, Batch 56, Loss: 0.098\n",
      "Training: Epoch 72, Batch 57, Loss: 0.206\n",
      "Training: Epoch 72, Batch 58, Loss: 0.146\n",
      "Training: Epoch 72, Batch 59, Loss: 0.162\n",
      "Val: Epoch 72, Loss: 0.272\n",
      "Training: Epoch 73, Batch 0, Loss: 0.157\n",
      "Training: Epoch 73, Batch 1, Loss: 0.109\n",
      "Training: Epoch 73, Batch 2, Loss: 0.111\n",
      "Training: Epoch 73, Batch 3, Loss: 0.188\n",
      "Training: Epoch 73, Batch 4, Loss: 0.111\n",
      "Training: Epoch 73, Batch 5, Loss: 0.115\n",
      "Training: Epoch 73, Batch 6, Loss: 0.121\n",
      "Training: Epoch 73, Batch 7, Loss: 0.127\n",
      "Training: Epoch 73, Batch 8, Loss: 0.125\n",
      "Training: Epoch 73, Batch 9, Loss: 0.105\n",
      "Training: Epoch 73, Batch 10, Loss: 0.112\n",
      "Training: Epoch 73, Batch 11, Loss: 0.135\n",
      "Training: Epoch 73, Batch 12, Loss: 0.105\n",
      "Training: Epoch 73, Batch 13, Loss: 0.153\n",
      "Training: Epoch 73, Batch 14, Loss: 0.099\n",
      "Training: Epoch 73, Batch 15, Loss: 0.103\n",
      "Training: Epoch 73, Batch 16, Loss: 0.096\n",
      "Training: Epoch 73, Batch 17, Loss: 0.105\n",
      "Training: Epoch 73, Batch 18, Loss: 0.172\n",
      "Training: Epoch 73, Batch 19, Loss: 0.114\n",
      "Training: Epoch 73, Batch 20, Loss: 0.129\n",
      "Training: Epoch 73, Batch 21, Loss: 0.127\n",
      "Training: Epoch 73, Batch 22, Loss: 0.091\n",
      "Training: Epoch 73, Batch 23, Loss: 0.086\n",
      "Training: Epoch 73, Batch 24, Loss: 0.129\n",
      "Training: Epoch 73, Batch 25, Loss: 0.118\n",
      "Training: Epoch 73, Batch 26, Loss: 0.116\n",
      "Training: Epoch 73, Batch 27, Loss: 0.121\n",
      "Training: Epoch 73, Batch 28, Loss: 0.089\n",
      "Training: Epoch 73, Batch 29, Loss: 0.1\n",
      "Training: Epoch 73, Batch 30, Loss: 0.111\n",
      "Training: Epoch 73, Batch 31, Loss: 0.11\n",
      "Training: Epoch 73, Batch 32, Loss: 0.19\n",
      "Training: Epoch 73, Batch 33, Loss: 0.091\n",
      "Training: Epoch 73, Batch 34, Loss: 0.142\n",
      "Training: Epoch 73, Batch 35, Loss: 0.156\n",
      "Training: Epoch 73, Batch 36, Loss: 0.135\n",
      "Training: Epoch 73, Batch 37, Loss: 0.116\n",
      "Training: Epoch 73, Batch 38, Loss: 0.125\n",
      "Training: Epoch 73, Batch 39, Loss: 0.099\n",
      "Training: Epoch 73, Batch 40, Loss: 0.104\n",
      "Training: Epoch 73, Batch 41, Loss: 0.096\n",
      "Training: Epoch 73, Batch 42, Loss: 0.109\n",
      "Training: Epoch 73, Batch 43, Loss: 0.11\n",
      "Training: Epoch 73, Batch 44, Loss: 0.14\n",
      "Training: Epoch 73, Batch 45, Loss: 0.115\n",
      "Training: Epoch 73, Batch 46, Loss: 0.107\n",
      "Training: Epoch 73, Batch 47, Loss: 0.144\n",
      "Training: Epoch 73, Batch 48, Loss: 0.124\n",
      "Training: Epoch 73, Batch 49, Loss: 0.117\n",
      "Training: Epoch 73, Batch 50, Loss: 0.096\n",
      "Training: Epoch 73, Batch 51, Loss: 0.105\n",
      "Training: Epoch 73, Batch 52, Loss: 0.102\n",
      "Training: Epoch 73, Batch 53, Loss: 0.125\n",
      "Training: Epoch 73, Batch 54, Loss: 0.121\n",
      "Training: Epoch 73, Batch 55, Loss: 0.108\n",
      "Training: Epoch 73, Batch 56, Loss: 0.113\n",
      "Training: Epoch 73, Batch 57, Loss: 0.104\n",
      "Training: Epoch 73, Batch 58, Loss: 0.109\n",
      "Training: Epoch 73, Batch 59, Loss: 0.094\n",
      "Val: Epoch 73, Loss: 0.201\n",
      "Training: Epoch 74, Batch 0, Loss: 0.119\n",
      "Training: Epoch 74, Batch 1, Loss: 0.106\n",
      "Training: Epoch 74, Batch 2, Loss: 0.139\n",
      "Training: Epoch 74, Batch 3, Loss: 0.098\n",
      "Training: Epoch 74, Batch 4, Loss: 0.145\n",
      "Training: Epoch 74, Batch 5, Loss: 0.103\n",
      "Training: Epoch 74, Batch 6, Loss: 0.096\n",
      "Training: Epoch 74, Batch 7, Loss: 0.113\n",
      "Training: Epoch 74, Batch 8, Loss: 0.125\n",
      "Training: Epoch 74, Batch 9, Loss: 0.154\n",
      "Training: Epoch 74, Batch 10, Loss: 0.096\n",
      "Training: Epoch 74, Batch 11, Loss: 0.088\n",
      "Training: Epoch 74, Batch 12, Loss: 0.118\n",
      "Training: Epoch 74, Batch 13, Loss: 0.111\n",
      "Training: Epoch 74, Batch 14, Loss: 0.122\n",
      "Training: Epoch 74, Batch 15, Loss: 0.073\n",
      "Training: Epoch 74, Batch 16, Loss: 0.107\n",
      "Training: Epoch 74, Batch 17, Loss: 0.112\n",
      "Training: Epoch 74, Batch 18, Loss: 0.106\n",
      "Training: Epoch 74, Batch 19, Loss: 0.131\n",
      "Training: Epoch 74, Batch 20, Loss: 0.11\n",
      "Training: Epoch 74, Batch 21, Loss: 0.117\n",
      "Training: Epoch 74, Batch 22, Loss: 0.137\n",
      "Training: Epoch 74, Batch 23, Loss: 0.133\n",
      "Training: Epoch 74, Batch 24, Loss: 0.099\n",
      "Training: Epoch 74, Batch 25, Loss: 0.097\n",
      "Training: Epoch 74, Batch 26, Loss: 0.128\n",
      "Training: Epoch 74, Batch 27, Loss: 0.1\n",
      "Training: Epoch 74, Batch 28, Loss: 0.12\n",
      "Training: Epoch 74, Batch 29, Loss: 0.123\n",
      "Training: Epoch 74, Batch 30, Loss: 0.139\n",
      "Training: Epoch 74, Batch 31, Loss: 0.155\n",
      "Training: Epoch 74, Batch 32, Loss: 0.094\n",
      "Training: Epoch 74, Batch 33, Loss: 0.107\n",
      "Training: Epoch 74, Batch 34, Loss: 0.11\n",
      "Training: Epoch 74, Batch 35, Loss: 0.108\n",
      "Training: Epoch 74, Batch 36, Loss: 0.118\n",
      "Training: Epoch 74, Batch 37, Loss: 0.153\n",
      "Training: Epoch 74, Batch 38, Loss: 0.105\n",
      "Training: Epoch 74, Batch 39, Loss: 0.111\n",
      "Training: Epoch 74, Batch 40, Loss: 0.153\n",
      "Training: Epoch 74, Batch 41, Loss: 0.13\n",
      "Training: Epoch 74, Batch 42, Loss: 0.114\n",
      "Training: Epoch 74, Batch 43, Loss: 0.106\n",
      "Training: Epoch 74, Batch 44, Loss: 0.136\n",
      "Training: Epoch 74, Batch 45, Loss: 0.109\n",
      "Training: Epoch 74, Batch 46, Loss: 0.118\n",
      "Training: Epoch 74, Batch 47, Loss: 0.117\n",
      "Training: Epoch 74, Batch 48, Loss: 0.101\n",
      "Training: Epoch 74, Batch 49, Loss: 0.212\n",
      "Training: Epoch 74, Batch 50, Loss: 0.086\n",
      "Training: Epoch 74, Batch 51, Loss: 0.127\n",
      "Training: Epoch 74, Batch 52, Loss: 0.078\n",
      "Training: Epoch 74, Batch 53, Loss: 0.124\n",
      "Training: Epoch 74, Batch 54, Loss: 0.098\n",
      "Training: Epoch 74, Batch 55, Loss: 0.117\n",
      "Training: Epoch 74, Batch 56, Loss: 0.121\n",
      "Training: Epoch 74, Batch 57, Loss: 0.133\n",
      "Training: Epoch 74, Batch 58, Loss: 0.096\n",
      "Training: Epoch 74, Batch 59, Loss: 0.106\n",
      "Val: Epoch 74, Loss: 0.218\n",
      "Training: Epoch 75, Batch 0, Loss: 0.094\n",
      "Training: Epoch 75, Batch 1, Loss: 0.101\n",
      "Training: Epoch 75, Batch 2, Loss: 0.128\n",
      "Training: Epoch 75, Batch 3, Loss: 0.091\n",
      "Training: Epoch 75, Batch 4, Loss: 0.112\n",
      "Training: Epoch 75, Batch 5, Loss: 0.088\n",
      "Training: Epoch 75, Batch 6, Loss: 0.114\n",
      "Training: Epoch 75, Batch 7, Loss: 0.078\n",
      "Training: Epoch 75, Batch 8, Loss: 0.113\n",
      "Training: Epoch 75, Batch 9, Loss: 0.109\n",
      "Training: Epoch 75, Batch 10, Loss: 0.123\n",
      "Training: Epoch 75, Batch 11, Loss: 0.093\n",
      "Training: Epoch 75, Batch 12, Loss: 0.115\n",
      "Training: Epoch 75, Batch 13, Loss: 0.113\n",
      "Training: Epoch 75, Batch 14, Loss: 0.106\n",
      "Training: Epoch 75, Batch 15, Loss: 0.109\n",
      "Training: Epoch 75, Batch 16, Loss: 0.09\n",
      "Training: Epoch 75, Batch 17, Loss: 0.101\n",
      "Training: Epoch 75, Batch 18, Loss: 0.115\n",
      "Training: Epoch 75, Batch 19, Loss: 0.109\n",
      "Training: Epoch 75, Batch 20, Loss: 0.124\n",
      "Training: Epoch 75, Batch 21, Loss: 0.125\n",
      "Training: Epoch 75, Batch 22, Loss: 0.102\n",
      "Training: Epoch 75, Batch 23, Loss: 0.096\n",
      "Training: Epoch 75, Batch 24, Loss: 0.135\n",
      "Training: Epoch 75, Batch 25, Loss: 0.136\n",
      "Training: Epoch 75, Batch 26, Loss: 0.134\n",
      "Training: Epoch 75, Batch 27, Loss: 0.116\n",
      "Training: Epoch 75, Batch 28, Loss: 0.109\n",
      "Training: Epoch 75, Batch 29, Loss: 0.123\n",
      "Training: Epoch 75, Batch 30, Loss: 0.091\n",
      "Training: Epoch 75, Batch 31, Loss: 0.103\n",
      "Training: Epoch 75, Batch 32, Loss: 0.125\n",
      "Training: Epoch 75, Batch 33, Loss: 0.105\n",
      "Training: Epoch 75, Batch 34, Loss: 0.138\n",
      "Training: Epoch 75, Batch 35, Loss: 0.116\n",
      "Training: Epoch 75, Batch 36, Loss: 0.108\n",
      "Training: Epoch 75, Batch 37, Loss: 0.111\n",
      "Training: Epoch 75, Batch 38, Loss: 0.149\n",
      "Training: Epoch 75, Batch 39, Loss: 0.106\n",
      "Training: Epoch 75, Batch 40, Loss: 0.102\n",
      "Training: Epoch 75, Batch 41, Loss: 0.114\n",
      "Training: Epoch 75, Batch 42, Loss: 0.11\n",
      "Training: Epoch 75, Batch 43, Loss: 0.107\n",
      "Training: Epoch 75, Batch 44, Loss: 0.111\n",
      "Training: Epoch 75, Batch 45, Loss: 0.095\n",
      "Training: Epoch 75, Batch 46, Loss: 0.106\n",
      "Training: Epoch 75, Batch 47, Loss: 0.127\n",
      "Training: Epoch 75, Batch 48, Loss: 0.109\n",
      "Training: Epoch 75, Batch 49, Loss: 0.105\n",
      "Training: Epoch 75, Batch 50, Loss: 0.119\n",
      "Training: Epoch 75, Batch 51, Loss: 0.108\n",
      "Training: Epoch 75, Batch 52, Loss: 0.128\n",
      "Training: Epoch 75, Batch 53, Loss: 0.097\n",
      "Training: Epoch 75, Batch 54, Loss: 0.099\n",
      "Training: Epoch 75, Batch 55, Loss: 0.108\n",
      "Training: Epoch 75, Batch 56, Loss: 0.11\n",
      "Training: Epoch 75, Batch 57, Loss: 0.119\n",
      "Training: Epoch 75, Batch 58, Loss: 0.129\n",
      "Training: Epoch 75, Batch 59, Loss: 0.141\n",
      "Val: Epoch 75, Loss: 0.216\n",
      "Training: Epoch 76, Batch 0, Loss: 0.112\n",
      "Training: Epoch 76, Batch 1, Loss: 0.137\n",
      "Training: Epoch 76, Batch 2, Loss: 0.103\n",
      "Training: Epoch 76, Batch 3, Loss: 0.113\n",
      "Training: Epoch 76, Batch 4, Loss: 0.115\n",
      "Training: Epoch 76, Batch 5, Loss: 0.097\n",
      "Training: Epoch 76, Batch 6, Loss: 0.134\n",
      "Training: Epoch 76, Batch 7, Loss: 0.1\n",
      "Training: Epoch 76, Batch 8, Loss: 0.1\n",
      "Training: Epoch 76, Batch 9, Loss: 0.106\n",
      "Training: Epoch 76, Batch 10, Loss: 0.131\n",
      "Training: Epoch 76, Batch 11, Loss: 0.1\n",
      "Training: Epoch 76, Batch 12, Loss: 0.095\n",
      "Training: Epoch 76, Batch 13, Loss: 0.08\n",
      "Training: Epoch 76, Batch 14, Loss: 0.153\n",
      "Training: Epoch 76, Batch 15, Loss: 0.106\n",
      "Training: Epoch 76, Batch 16, Loss: 0.115\n",
      "Training: Epoch 76, Batch 17, Loss: 0.128\n",
      "Training: Epoch 76, Batch 18, Loss: 0.112\n",
      "Training: Epoch 76, Batch 19, Loss: 0.124\n",
      "Training: Epoch 76, Batch 20, Loss: 0.113\n",
      "Training: Epoch 76, Batch 21, Loss: 0.099\n",
      "Training: Epoch 76, Batch 22, Loss: 0.104\n",
      "Training: Epoch 76, Batch 23, Loss: 0.096\n",
      "Training: Epoch 76, Batch 24, Loss: 0.097\n",
      "Training: Epoch 76, Batch 25, Loss: 0.113\n",
      "Training: Epoch 76, Batch 26, Loss: 0.098\n",
      "Training: Epoch 76, Batch 27, Loss: 0.12\n",
      "Training: Epoch 76, Batch 28, Loss: 0.104\n",
      "Training: Epoch 76, Batch 29, Loss: 0.105\n",
      "Training: Epoch 76, Batch 30, Loss: 0.107\n",
      "Training: Epoch 76, Batch 31, Loss: 0.096\n",
      "Training: Epoch 76, Batch 32, Loss: 0.08\n",
      "Training: Epoch 76, Batch 33, Loss: 0.144\n",
      "Training: Epoch 76, Batch 34, Loss: 0.126\n",
      "Training: Epoch 76, Batch 35, Loss: 0.1\n",
      "Training: Epoch 76, Batch 36, Loss: 0.108\n",
      "Training: Epoch 76, Batch 37, Loss: 0.101\n",
      "Training: Epoch 76, Batch 38, Loss: 0.096\n",
      "Training: Epoch 76, Batch 39, Loss: 0.136\n",
      "Training: Epoch 76, Batch 40, Loss: 0.107\n",
      "Training: Epoch 76, Batch 41, Loss: 0.12\n",
      "Training: Epoch 76, Batch 42, Loss: 0.097\n",
      "Training: Epoch 76, Batch 43, Loss: 0.088\n",
      "Training: Epoch 76, Batch 44, Loss: 0.115\n",
      "Training: Epoch 76, Batch 45, Loss: 0.118\n",
      "Training: Epoch 76, Batch 46, Loss: 0.109\n",
      "Training: Epoch 76, Batch 47, Loss: 0.097\n",
      "Training: Epoch 76, Batch 48, Loss: 0.097\n",
      "Training: Epoch 76, Batch 49, Loss: 0.109\n",
      "Training: Epoch 76, Batch 50, Loss: 0.099\n",
      "Training: Epoch 76, Batch 51, Loss: 0.101\n",
      "Training: Epoch 76, Batch 52, Loss: 0.117\n",
      "Training: Epoch 76, Batch 53, Loss: 0.1\n",
      "Training: Epoch 76, Batch 54, Loss: 0.123\n",
      "Training: Epoch 76, Batch 55, Loss: 0.099\n",
      "Training: Epoch 76, Batch 56, Loss: 0.105\n",
      "Training: Epoch 76, Batch 57, Loss: 0.085\n",
      "Training: Epoch 76, Batch 58, Loss: 0.11\n",
      "Training: Epoch 76, Batch 59, Loss: 0.126\n",
      "Val: Epoch 76, Loss: 0.228\n",
      "Training: Epoch 77, Batch 0, Loss: 0.092\n",
      "Training: Epoch 77, Batch 1, Loss: 0.101\n",
      "Training: Epoch 77, Batch 2, Loss: 0.107\n",
      "Training: Epoch 77, Batch 3, Loss: 0.094\n",
      "Training: Epoch 77, Batch 4, Loss: 0.105\n",
      "Training: Epoch 77, Batch 5, Loss: 0.086\n",
      "Training: Epoch 77, Batch 6, Loss: 0.114\n",
      "Training: Epoch 77, Batch 7, Loss: 0.093\n",
      "Training: Epoch 77, Batch 8, Loss: 0.116\n",
      "Training: Epoch 77, Batch 9, Loss: 0.1\n",
      "Training: Epoch 77, Batch 10, Loss: 0.139\n",
      "Training: Epoch 77, Batch 11, Loss: 0.107\n",
      "Training: Epoch 77, Batch 12, Loss: 0.116\n",
      "Training: Epoch 77, Batch 13, Loss: 0.109\n",
      "Training: Epoch 77, Batch 14, Loss: 0.088\n",
      "Training: Epoch 77, Batch 15, Loss: 0.107\n",
      "Training: Epoch 77, Batch 16, Loss: 0.111\n",
      "Training: Epoch 77, Batch 17, Loss: 0.091\n",
      "Training: Epoch 77, Batch 18, Loss: 0.115\n",
      "Training: Epoch 77, Batch 19, Loss: 0.107\n",
      "Training: Epoch 77, Batch 20, Loss: 0.097\n",
      "Training: Epoch 77, Batch 21, Loss: 0.117\n",
      "Training: Epoch 77, Batch 22, Loss: 0.08\n",
      "Training: Epoch 77, Batch 23, Loss: 0.103\n",
      "Training: Epoch 77, Batch 24, Loss: 0.118\n",
      "Training: Epoch 77, Batch 25, Loss: 0.131\n",
      "Training: Epoch 77, Batch 26, Loss: 0.128\n",
      "Training: Epoch 77, Batch 27, Loss: 0.104\n",
      "Training: Epoch 77, Batch 28, Loss: 0.11\n",
      "Training: Epoch 77, Batch 29, Loss: 0.091\n",
      "Training: Epoch 77, Batch 30, Loss: 0.103\n",
      "Training: Epoch 77, Batch 31, Loss: 0.093\n",
      "Training: Epoch 77, Batch 32, Loss: 0.116\n",
      "Training: Epoch 77, Batch 33, Loss: 0.105\n",
      "Training: Epoch 77, Batch 34, Loss: 0.087\n",
      "Training: Epoch 77, Batch 35, Loss: 0.095\n",
      "Training: Epoch 77, Batch 36, Loss: 0.12\n",
      "Training: Epoch 77, Batch 37, Loss: 0.14\n",
      "Training: Epoch 77, Batch 38, Loss: 0.119\n",
      "Training: Epoch 77, Batch 39, Loss: 0.092\n",
      "Training: Epoch 77, Batch 40, Loss: 0.143\n",
      "Training: Epoch 77, Batch 41, Loss: 0.104\n",
      "Training: Epoch 77, Batch 42, Loss: 0.098\n",
      "Training: Epoch 77, Batch 43, Loss: 0.087\n",
      "Training: Epoch 77, Batch 44, Loss: 0.099\n",
      "Training: Epoch 77, Batch 45, Loss: 0.125\n",
      "Training: Epoch 77, Batch 46, Loss: 0.111\n",
      "Training: Epoch 77, Batch 47, Loss: 0.091\n",
      "Training: Epoch 77, Batch 48, Loss: 0.145\n",
      "Training: Epoch 77, Batch 49, Loss: 0.128\n",
      "Training: Epoch 77, Batch 50, Loss: 0.092\n",
      "Training: Epoch 77, Batch 51, Loss: 0.139\n",
      "Training: Epoch 77, Batch 52, Loss: 0.092\n",
      "Training: Epoch 77, Batch 53, Loss: 0.142\n",
      "Training: Epoch 77, Batch 54, Loss: 0.108\n",
      "Training: Epoch 77, Batch 55, Loss: 0.1\n",
      "Training: Epoch 77, Batch 56, Loss: 0.103\n",
      "Training: Epoch 77, Batch 57, Loss: 0.096\n",
      "Training: Epoch 77, Batch 58, Loss: 0.128\n",
      "Training: Epoch 77, Batch 59, Loss: 0.108\n",
      "Val: Epoch 77, Loss: 0.215\n",
      "Training: Epoch 78, Batch 0, Loss: 0.135\n",
      "Training: Epoch 78, Batch 1, Loss: 0.119\n",
      "Training: Epoch 78, Batch 2, Loss: 0.113\n",
      "Training: Epoch 78, Batch 3, Loss: 0.097\n",
      "Training: Epoch 78, Batch 4, Loss: 0.125\n",
      "Training: Epoch 78, Batch 5, Loss: 0.134\n",
      "Training: Epoch 78, Batch 6, Loss: 0.109\n",
      "Training: Epoch 78, Batch 7, Loss: 0.114\n",
      "Training: Epoch 78, Batch 8, Loss: 0.102\n",
      "Training: Epoch 78, Batch 9, Loss: 0.12\n",
      "Training: Epoch 78, Batch 10, Loss: 0.086\n",
      "Training: Epoch 78, Batch 11, Loss: 0.095\n",
      "Training: Epoch 78, Batch 12, Loss: 0.127\n",
      "Training: Epoch 78, Batch 13, Loss: 0.13\n",
      "Training: Epoch 78, Batch 14, Loss: 0.076\n",
      "Training: Epoch 78, Batch 15, Loss: 0.093\n",
      "Training: Epoch 78, Batch 16, Loss: 0.126\n",
      "Training: Epoch 78, Batch 17, Loss: 0.125\n",
      "Training: Epoch 78, Batch 18, Loss: 0.103\n",
      "Training: Epoch 78, Batch 19, Loss: 0.102\n",
      "Training: Epoch 78, Batch 20, Loss: 0.112\n",
      "Training: Epoch 78, Batch 21, Loss: 0.084\n",
      "Training: Epoch 78, Batch 22, Loss: 0.105\n",
      "Training: Epoch 78, Batch 23, Loss: 0.089\n",
      "Training: Epoch 78, Batch 24, Loss: 0.098\n",
      "Training: Epoch 78, Batch 25, Loss: 0.093\n",
      "Training: Epoch 78, Batch 26, Loss: 0.115\n",
      "Training: Epoch 78, Batch 27, Loss: 0.104\n",
      "Training: Epoch 78, Batch 28, Loss: 0.097\n",
      "Training: Epoch 78, Batch 29, Loss: 0.092\n",
      "Training: Epoch 78, Batch 30, Loss: 0.122\n",
      "Training: Epoch 78, Batch 31, Loss: 0.099\n",
      "Training: Epoch 78, Batch 32, Loss: 0.102\n",
      "Training: Epoch 78, Batch 33, Loss: 0.107\n",
      "Training: Epoch 78, Batch 34, Loss: 0.105\n",
      "Training: Epoch 78, Batch 35, Loss: 0.109\n",
      "Training: Epoch 78, Batch 36, Loss: 0.085\n",
      "Training: Epoch 78, Batch 37, Loss: 0.101\n",
      "Training: Epoch 78, Batch 38, Loss: 0.088\n",
      "Training: Epoch 78, Batch 39, Loss: 0.093\n",
      "Training: Epoch 78, Batch 40, Loss: 0.098\n",
      "Training: Epoch 78, Batch 41, Loss: 0.121\n",
      "Training: Epoch 78, Batch 42, Loss: 0.115\n",
      "Training: Epoch 78, Batch 43, Loss: 0.124\n",
      "Training: Epoch 78, Batch 44, Loss: 0.103\n",
      "Training: Epoch 78, Batch 45, Loss: 0.083\n",
      "Training: Epoch 78, Batch 46, Loss: 0.119\n",
      "Training: Epoch 78, Batch 47, Loss: 0.113\n",
      "Training: Epoch 78, Batch 48, Loss: 0.103\n",
      "Training: Epoch 78, Batch 49, Loss: 0.119\n",
      "Training: Epoch 78, Batch 50, Loss: 0.135\n",
      "Training: Epoch 78, Batch 51, Loss: 0.118\n",
      "Training: Epoch 78, Batch 52, Loss: 0.092\n",
      "Training: Epoch 78, Batch 53, Loss: 0.078\n",
      "Training: Epoch 78, Batch 54, Loss: 0.08\n",
      "Training: Epoch 78, Batch 55, Loss: 0.109\n",
      "Training: Epoch 78, Batch 56, Loss: 0.114\n",
      "Training: Epoch 78, Batch 57, Loss: 0.104\n",
      "Training: Epoch 78, Batch 58, Loss: 0.111\n",
      "Training: Epoch 78, Batch 59, Loss: 0.112\n",
      "Val: Epoch 78, Loss: 0.209\n",
      "Training: Epoch 79, Batch 0, Loss: 0.101\n",
      "Training: Epoch 79, Batch 1, Loss: 0.077\n",
      "Training: Epoch 79, Batch 2, Loss: 0.098\n",
      "Training: Epoch 79, Batch 3, Loss: 0.115\n",
      "Training: Epoch 79, Batch 4, Loss: 0.106\n",
      "Training: Epoch 79, Batch 5, Loss: 0.098\n",
      "Training: Epoch 79, Batch 6, Loss: 0.091\n",
      "Training: Epoch 79, Batch 7, Loss: 0.09\n",
      "Training: Epoch 79, Batch 8, Loss: 0.105\n",
      "Training: Epoch 79, Batch 9, Loss: 0.096\n",
      "Training: Epoch 79, Batch 10, Loss: 0.097\n",
      "Training: Epoch 79, Batch 11, Loss: 0.101\n",
      "Training: Epoch 79, Batch 12, Loss: 0.094\n",
      "Training: Epoch 79, Batch 13, Loss: 0.111\n",
      "Training: Epoch 79, Batch 14, Loss: 0.109\n",
      "Training: Epoch 79, Batch 15, Loss: 0.103\n",
      "Training: Epoch 79, Batch 16, Loss: 0.104\n",
      "Training: Epoch 79, Batch 17, Loss: 0.108\n",
      "Training: Epoch 79, Batch 18, Loss: 0.136\n",
      "Training: Epoch 79, Batch 19, Loss: 0.082\n",
      "Training: Epoch 79, Batch 20, Loss: 0.098\n",
      "Training: Epoch 79, Batch 21, Loss: 0.097\n",
      "Training: Epoch 79, Batch 22, Loss: 0.098\n",
      "Training: Epoch 79, Batch 23, Loss: 0.106\n",
      "Training: Epoch 79, Batch 24, Loss: 0.081\n",
      "Training: Epoch 79, Batch 25, Loss: 0.108\n",
      "Training: Epoch 79, Batch 26, Loss: 0.12\n",
      "Training: Epoch 79, Batch 27, Loss: 0.1\n",
      "Training: Epoch 79, Batch 28, Loss: 0.098\n",
      "Training: Epoch 79, Batch 29, Loss: 0.152\n",
      "Training: Epoch 79, Batch 30, Loss: 0.11\n",
      "Training: Epoch 79, Batch 31, Loss: 0.094\n",
      "Training: Epoch 79, Batch 32, Loss: 0.092\n",
      "Training: Epoch 79, Batch 33, Loss: 0.117\n",
      "Training: Epoch 79, Batch 34, Loss: 0.091\n",
      "Training: Epoch 79, Batch 35, Loss: 0.092\n",
      "Training: Epoch 79, Batch 36, Loss: 0.091\n",
      "Training: Epoch 79, Batch 37, Loss: 0.099\n",
      "Training: Epoch 79, Batch 38, Loss: 0.089\n",
      "Training: Epoch 79, Batch 39, Loss: 0.088\n",
      "Training: Epoch 79, Batch 40, Loss: 0.097\n",
      "Training: Epoch 79, Batch 41, Loss: 0.085\n",
      "Training: Epoch 79, Batch 42, Loss: 0.113\n",
      "Training: Epoch 79, Batch 43, Loss: 0.113\n",
      "Training: Epoch 79, Batch 44, Loss: 0.136\n",
      "Training: Epoch 79, Batch 45, Loss: 0.097\n",
      "Training: Epoch 79, Batch 46, Loss: 0.119\n",
      "Training: Epoch 79, Batch 47, Loss: 0.111\n",
      "Training: Epoch 79, Batch 48, Loss: 0.12\n",
      "Training: Epoch 79, Batch 49, Loss: 0.091\n",
      "Training: Epoch 79, Batch 50, Loss: 0.123\n",
      "Training: Epoch 79, Batch 51, Loss: 0.107\n",
      "Training: Epoch 79, Batch 52, Loss: 0.096\n",
      "Training: Epoch 79, Batch 53, Loss: 0.113\n",
      "Training: Epoch 79, Batch 54, Loss: 0.098\n",
      "Training: Epoch 79, Batch 55, Loss: 0.09\n",
      "Training: Epoch 79, Batch 56, Loss: 0.098\n",
      "Training: Epoch 79, Batch 57, Loss: 0.095\n",
      "Training: Epoch 79, Batch 58, Loss: 0.101\n",
      "Training: Epoch 79, Batch 59, Loss: 0.141\n",
      "Val: Epoch 79, Loss: 0.218\n",
      "Training: Epoch 80, Batch 0, Loss: 0.099\n",
      "Training: Epoch 80, Batch 1, Loss: 0.095\n",
      "Training: Epoch 80, Batch 2, Loss: 0.091\n",
      "Training: Epoch 80, Batch 3, Loss: 0.106\n",
      "Training: Epoch 80, Batch 4, Loss: 0.078\n",
      "Training: Epoch 80, Batch 5, Loss: 0.121\n",
      "Training: Epoch 80, Batch 6, Loss: 0.109\n",
      "Training: Epoch 80, Batch 7, Loss: 0.102\n",
      "Training: Epoch 80, Batch 8, Loss: 0.108\n",
      "Training: Epoch 80, Batch 9, Loss: 0.099\n",
      "Training: Epoch 80, Batch 10, Loss: 0.122\n",
      "Training: Epoch 80, Batch 11, Loss: 0.086\n",
      "Training: Epoch 80, Batch 12, Loss: 0.111\n",
      "Training: Epoch 80, Batch 13, Loss: 0.094\n",
      "Training: Epoch 80, Batch 14, Loss: 0.096\n",
      "Training: Epoch 80, Batch 15, Loss: 0.116\n",
      "Training: Epoch 80, Batch 16, Loss: 0.085\n",
      "Training: Epoch 80, Batch 17, Loss: 0.08\n",
      "Training: Epoch 80, Batch 18, Loss: 0.113\n",
      "Training: Epoch 80, Batch 19, Loss: 0.106\n",
      "Training: Epoch 80, Batch 20, Loss: 0.102\n",
      "Training: Epoch 80, Batch 21, Loss: 0.1\n",
      "Training: Epoch 80, Batch 22, Loss: 0.086\n",
      "Training: Epoch 80, Batch 23, Loss: 0.114\n",
      "Training: Epoch 80, Batch 24, Loss: 0.117\n",
      "Training: Epoch 80, Batch 25, Loss: 0.085\n",
      "Training: Epoch 80, Batch 26, Loss: 0.099\n",
      "Training: Epoch 80, Batch 27, Loss: 0.109\n",
      "Training: Epoch 80, Batch 28, Loss: 0.118\n",
      "Training: Epoch 80, Batch 29, Loss: 0.093\n",
      "Training: Epoch 80, Batch 30, Loss: 0.125\n",
      "Training: Epoch 80, Batch 31, Loss: 0.097\n",
      "Training: Epoch 80, Batch 32, Loss: 0.109\n",
      "Training: Epoch 80, Batch 33, Loss: 0.115\n",
      "Training: Epoch 80, Batch 34, Loss: 0.109\n",
      "Training: Epoch 80, Batch 35, Loss: 0.112\n",
      "Training: Epoch 80, Batch 36, Loss: 0.095\n",
      "Training: Epoch 80, Batch 37, Loss: 0.084\n",
      "Training: Epoch 80, Batch 38, Loss: 0.107\n",
      "Training: Epoch 80, Batch 39, Loss: 0.107\n",
      "Training: Epoch 80, Batch 40, Loss: 0.099\n",
      "Training: Epoch 80, Batch 41, Loss: 0.103\n",
      "Training: Epoch 80, Batch 42, Loss: 0.107\n",
      "Training: Epoch 80, Batch 43, Loss: 0.131\n",
      "Training: Epoch 80, Batch 44, Loss: 0.077\n",
      "Training: Epoch 80, Batch 45, Loss: 0.126\n",
      "Training: Epoch 80, Batch 46, Loss: 0.079\n",
      "Training: Epoch 80, Batch 47, Loss: 0.088\n",
      "Training: Epoch 80, Batch 48, Loss: 0.105\n",
      "Training: Epoch 80, Batch 49, Loss: 0.114\n",
      "Training: Epoch 80, Batch 50, Loss: 0.093\n",
      "Training: Epoch 80, Batch 51, Loss: 0.103\n",
      "Training: Epoch 80, Batch 52, Loss: 0.115\n",
      "Training: Epoch 80, Batch 53, Loss: 0.088\n",
      "Training: Epoch 80, Batch 54, Loss: 0.121\n",
      "Training: Epoch 80, Batch 55, Loss: 0.137\n",
      "Training: Epoch 80, Batch 56, Loss: 0.101\n",
      "Training: Epoch 80, Batch 57, Loss: 0.084\n",
      "Training: Epoch 80, Batch 58, Loss: 0.1\n",
      "Training: Epoch 80, Batch 59, Loss: 0.126\n",
      "Val: Epoch 80, Loss: 0.201\n",
      "Training: Epoch 81, Batch 0, Loss: 0.162\n",
      "Training: Epoch 81, Batch 1, Loss: 0.09\n",
      "Training: Epoch 81, Batch 2, Loss: 0.118\n",
      "Training: Epoch 81, Batch 3, Loss: 0.097\n",
      "Training: Epoch 81, Batch 4, Loss: 0.14\n",
      "Training: Epoch 81, Batch 5, Loss: 0.066\n",
      "Training: Epoch 81, Batch 6, Loss: 0.09\n",
      "Training: Epoch 81, Batch 7, Loss: 0.129\n",
      "Training: Epoch 81, Batch 8, Loss: 0.097\n",
      "Training: Epoch 81, Batch 9, Loss: 0.103\n",
      "Training: Epoch 81, Batch 10, Loss: 0.073\n",
      "Training: Epoch 81, Batch 11, Loss: 0.104\n",
      "Training: Epoch 81, Batch 12, Loss: 0.151\n",
      "Training: Epoch 81, Batch 13, Loss: 0.131\n",
      "Training: Epoch 81, Batch 14, Loss: 0.117\n",
      "Training: Epoch 81, Batch 15, Loss: 0.111\n",
      "Training: Epoch 81, Batch 16, Loss: 0.084\n",
      "Training: Epoch 81, Batch 17, Loss: 0.101\n",
      "Training: Epoch 81, Batch 18, Loss: 0.097\n",
      "Training: Epoch 81, Batch 19, Loss: 0.102\n",
      "Training: Epoch 81, Batch 20, Loss: 0.109\n",
      "Training: Epoch 81, Batch 21, Loss: 0.099\n",
      "Training: Epoch 81, Batch 22, Loss: 0.092\n",
      "Training: Epoch 81, Batch 23, Loss: 0.098\n",
      "Training: Epoch 81, Batch 24, Loss: 0.112\n",
      "Training: Epoch 81, Batch 25, Loss: 0.087\n",
      "Training: Epoch 81, Batch 26, Loss: 0.121\n",
      "Training: Epoch 81, Batch 27, Loss: 0.095\n",
      "Training: Epoch 81, Batch 28, Loss: 0.092\n",
      "Training: Epoch 81, Batch 29, Loss: 0.081\n",
      "Training: Epoch 81, Batch 30, Loss: 0.121\n",
      "Training: Epoch 81, Batch 31, Loss: 0.09\n",
      "Training: Epoch 81, Batch 32, Loss: 0.101\n",
      "Training: Epoch 81, Batch 33, Loss: 0.098\n",
      "Training: Epoch 81, Batch 34, Loss: 0.105\n",
      "Training: Epoch 81, Batch 35, Loss: 0.112\n",
      "Training: Epoch 81, Batch 36, Loss: 0.101\n",
      "Training: Epoch 81, Batch 37, Loss: 0.095\n",
      "Training: Epoch 81, Batch 38, Loss: 0.122\n",
      "Training: Epoch 81, Batch 39, Loss: 0.116\n",
      "Training: Epoch 81, Batch 40, Loss: 0.103\n",
      "Training: Epoch 81, Batch 41, Loss: 0.097\n",
      "Training: Epoch 81, Batch 42, Loss: 0.088\n",
      "Training: Epoch 81, Batch 43, Loss: 0.11\n",
      "Training: Epoch 81, Batch 44, Loss: 0.083\n",
      "Training: Epoch 81, Batch 45, Loss: 0.102\n",
      "Training: Epoch 81, Batch 46, Loss: 0.123\n",
      "Training: Epoch 81, Batch 47, Loss: 0.095\n",
      "Training: Epoch 81, Batch 48, Loss: 0.105\n",
      "Training: Epoch 81, Batch 49, Loss: 0.092\n",
      "Training: Epoch 81, Batch 50, Loss: 0.133\n",
      "Training: Epoch 81, Batch 51, Loss: 0.134\n",
      "Training: Epoch 81, Batch 52, Loss: 0.102\n",
      "Training: Epoch 81, Batch 53, Loss: 0.098\n",
      "Training: Epoch 81, Batch 54, Loss: 0.098\n",
      "Training: Epoch 81, Batch 55, Loss: 0.108\n",
      "Training: Epoch 81, Batch 56, Loss: 0.077\n",
      "Training: Epoch 81, Batch 57, Loss: 0.09\n",
      "Training: Epoch 81, Batch 58, Loss: 0.114\n",
      "Training: Epoch 81, Batch 59, Loss: 0.091\n",
      "Val: Epoch 81, Loss: 0.239\n",
      "Training: Epoch 82, Batch 0, Loss: 0.105\n",
      "Training: Epoch 82, Batch 1, Loss: 0.111\n",
      "Training: Epoch 82, Batch 2, Loss: 0.085\n",
      "Training: Epoch 82, Batch 3, Loss: 0.097\n",
      "Training: Epoch 82, Batch 4, Loss: 0.09\n",
      "Training: Epoch 82, Batch 5, Loss: 0.105\n",
      "Training: Epoch 82, Batch 6, Loss: 0.122\n",
      "Training: Epoch 82, Batch 7, Loss: 0.1\n",
      "Training: Epoch 82, Batch 8, Loss: 0.086\n",
      "Training: Epoch 82, Batch 9, Loss: 0.092\n",
      "Training: Epoch 82, Batch 10, Loss: 0.094\n",
      "Training: Epoch 82, Batch 11, Loss: 0.109\n",
      "Training: Epoch 82, Batch 12, Loss: 0.095\n",
      "Training: Epoch 82, Batch 13, Loss: 0.095\n",
      "Training: Epoch 82, Batch 14, Loss: 0.085\n",
      "Training: Epoch 82, Batch 15, Loss: 0.093\n",
      "Training: Epoch 82, Batch 16, Loss: 0.109\n",
      "Training: Epoch 82, Batch 17, Loss: 0.098\n",
      "Training: Epoch 82, Batch 18, Loss: 0.1\n",
      "Training: Epoch 82, Batch 19, Loss: 0.104\n",
      "Training: Epoch 82, Batch 20, Loss: 0.11\n",
      "Training: Epoch 82, Batch 21, Loss: 0.098\n",
      "Training: Epoch 82, Batch 22, Loss: 0.084\n",
      "Training: Epoch 82, Batch 23, Loss: 0.094\n",
      "Training: Epoch 82, Batch 24, Loss: 0.093\n",
      "Training: Epoch 82, Batch 25, Loss: 0.091\n",
      "Training: Epoch 82, Batch 26, Loss: 0.096\n",
      "Training: Epoch 82, Batch 27, Loss: 0.102\n",
      "Training: Epoch 82, Batch 28, Loss: 0.132\n",
      "Training: Epoch 82, Batch 29, Loss: 0.104\n",
      "Training: Epoch 82, Batch 30, Loss: 0.127\n",
      "Training: Epoch 82, Batch 31, Loss: 0.11\n",
      "Training: Epoch 82, Batch 32, Loss: 0.1\n",
      "Training: Epoch 82, Batch 33, Loss: 0.119\n",
      "Training: Epoch 82, Batch 34, Loss: 0.094\n",
      "Training: Epoch 82, Batch 35, Loss: 0.089\n",
      "Training: Epoch 82, Batch 36, Loss: 0.093\n",
      "Training: Epoch 82, Batch 37, Loss: 0.1\n",
      "Training: Epoch 82, Batch 38, Loss: 0.078\n",
      "Training: Epoch 82, Batch 39, Loss: 0.091\n",
      "Training: Epoch 82, Batch 40, Loss: 0.1\n",
      "Training: Epoch 82, Batch 41, Loss: 0.126\n",
      "Training: Epoch 82, Batch 42, Loss: 0.099\n",
      "Training: Epoch 82, Batch 43, Loss: 0.095\n",
      "Training: Epoch 82, Batch 44, Loss: 0.097\n",
      "Training: Epoch 82, Batch 45, Loss: 0.095\n",
      "Training: Epoch 82, Batch 46, Loss: 0.102\n",
      "Training: Epoch 82, Batch 47, Loss: 0.097\n",
      "Training: Epoch 82, Batch 48, Loss: 0.088\n",
      "Training: Epoch 82, Batch 49, Loss: 0.083\n",
      "Training: Epoch 82, Batch 50, Loss: 0.114\n",
      "Training: Epoch 82, Batch 51, Loss: 0.109\n",
      "Training: Epoch 82, Batch 52, Loss: 0.119\n",
      "Training: Epoch 82, Batch 53, Loss: 0.106\n",
      "Training: Epoch 82, Batch 54, Loss: 0.122\n",
      "Training: Epoch 82, Batch 55, Loss: 0.086\n",
      "Training: Epoch 82, Batch 56, Loss: 0.106\n",
      "Training: Epoch 82, Batch 57, Loss: 0.096\n",
      "Training: Epoch 82, Batch 58, Loss: 0.088\n",
      "Training: Epoch 82, Batch 59, Loss: 0.11\n",
      "Val: Epoch 82, Loss: 0.215\n",
      "Training: Epoch 83, Batch 0, Loss: 0.109\n",
      "Training: Epoch 83, Batch 1, Loss: 0.101\n",
      "Training: Epoch 83, Batch 2, Loss: 0.1\n",
      "Training: Epoch 83, Batch 3, Loss: 0.129\n",
      "Training: Epoch 83, Batch 4, Loss: 0.085\n",
      "Training: Epoch 83, Batch 5, Loss: 0.103\n",
      "Training: Epoch 83, Batch 6, Loss: 0.109\n",
      "Training: Epoch 83, Batch 7, Loss: 0.129\n",
      "Training: Epoch 83, Batch 8, Loss: 0.102\n",
      "Training: Epoch 83, Batch 9, Loss: 0.097\n",
      "Training: Epoch 83, Batch 10, Loss: 0.1\n",
      "Training: Epoch 83, Batch 11, Loss: 0.126\n",
      "Training: Epoch 83, Batch 12, Loss: 0.106\n",
      "Training: Epoch 83, Batch 13, Loss: 0.11\n",
      "Training: Epoch 83, Batch 14, Loss: 0.135\n",
      "Training: Epoch 83, Batch 15, Loss: 0.098\n",
      "Training: Epoch 83, Batch 16, Loss: 0.098\n",
      "Training: Epoch 83, Batch 17, Loss: 0.099\n",
      "Training: Epoch 83, Batch 18, Loss: 0.134\n",
      "Training: Epoch 83, Batch 19, Loss: 0.095\n",
      "Training: Epoch 83, Batch 20, Loss: 0.112\n",
      "Training: Epoch 83, Batch 21, Loss: 0.072\n",
      "Training: Epoch 83, Batch 22, Loss: 0.105\n",
      "Training: Epoch 83, Batch 23, Loss: 0.102\n",
      "Training: Epoch 83, Batch 24, Loss: 0.093\n",
      "Training: Epoch 83, Batch 25, Loss: 0.111\n",
      "Training: Epoch 83, Batch 26, Loss: 0.093\n",
      "Training: Epoch 83, Batch 27, Loss: 0.099\n",
      "Training: Epoch 83, Batch 28, Loss: 0.116\n",
      "Training: Epoch 83, Batch 29, Loss: 0.093\n",
      "Training: Epoch 83, Batch 30, Loss: 0.116\n",
      "Training: Epoch 83, Batch 31, Loss: 0.092\n",
      "Training: Epoch 83, Batch 32, Loss: 0.131\n",
      "Training: Epoch 83, Batch 33, Loss: 0.089\n",
      "Training: Epoch 83, Batch 34, Loss: 0.098\n",
      "Training: Epoch 83, Batch 35, Loss: 0.091\n",
      "Training: Epoch 83, Batch 36, Loss: 0.102\n",
      "Training: Epoch 83, Batch 37, Loss: 0.097\n",
      "Training: Epoch 83, Batch 38, Loss: 0.099\n",
      "Training: Epoch 83, Batch 39, Loss: 0.079\n",
      "Training: Epoch 83, Batch 40, Loss: 0.076\n",
      "Training: Epoch 83, Batch 41, Loss: 0.098\n",
      "Training: Epoch 83, Batch 42, Loss: 0.078\n",
      "Training: Epoch 83, Batch 43, Loss: 0.103\n",
      "Training: Epoch 83, Batch 44, Loss: 0.088\n",
      "Training: Epoch 83, Batch 45, Loss: 0.08\n",
      "Training: Epoch 83, Batch 46, Loss: 0.101\n",
      "Training: Epoch 83, Batch 47, Loss: 0.126\n",
      "Training: Epoch 83, Batch 48, Loss: 0.099\n",
      "Training: Epoch 83, Batch 49, Loss: 0.073\n",
      "Training: Epoch 83, Batch 50, Loss: 0.106\n",
      "Training: Epoch 83, Batch 51, Loss: 0.082\n",
      "Training: Epoch 83, Batch 52, Loss: 0.074\n",
      "Training: Epoch 83, Batch 53, Loss: 0.105\n",
      "Training: Epoch 83, Batch 54, Loss: 0.094\n",
      "Training: Epoch 83, Batch 55, Loss: 0.073\n",
      "Training: Epoch 83, Batch 56, Loss: 0.109\n",
      "Training: Epoch 83, Batch 57, Loss: 0.091\n",
      "Training: Epoch 83, Batch 58, Loss: 0.096\n",
      "Training: Epoch 83, Batch 59, Loss: 0.112\n",
      "Val: Epoch 83, Loss: 0.219\n",
      "Training: Epoch 84, Batch 0, Loss: 0.086\n",
      "Training: Epoch 84, Batch 1, Loss: 0.091\n",
      "Training: Epoch 84, Batch 2, Loss: 0.108\n",
      "Training: Epoch 84, Batch 3, Loss: 0.087\n",
      "Training: Epoch 84, Batch 4, Loss: 0.085\n",
      "Training: Epoch 84, Batch 5, Loss: 0.097\n",
      "Training: Epoch 84, Batch 6, Loss: 0.089\n",
      "Training: Epoch 84, Batch 7, Loss: 0.134\n",
      "Training: Epoch 84, Batch 8, Loss: 0.113\n",
      "Training: Epoch 84, Batch 9, Loss: 0.092\n",
      "Training: Epoch 84, Batch 10, Loss: 0.091\n",
      "Training: Epoch 84, Batch 11, Loss: 0.105\n",
      "Training: Epoch 84, Batch 12, Loss: 0.115\n",
      "Training: Epoch 84, Batch 13, Loss: 0.08\n",
      "Training: Epoch 84, Batch 14, Loss: 0.089\n",
      "Training: Epoch 84, Batch 15, Loss: 0.117\n",
      "Training: Epoch 84, Batch 16, Loss: 0.111\n",
      "Training: Epoch 84, Batch 17, Loss: 0.092\n",
      "Training: Epoch 84, Batch 18, Loss: 0.094\n",
      "Training: Epoch 84, Batch 19, Loss: 0.101\n",
      "Training: Epoch 84, Batch 20, Loss: 0.106\n",
      "Training: Epoch 84, Batch 21, Loss: 0.129\n",
      "Training: Epoch 84, Batch 22, Loss: 0.077\n",
      "Training: Epoch 84, Batch 23, Loss: 0.09\n",
      "Training: Epoch 84, Batch 24, Loss: 0.086\n",
      "Training: Epoch 84, Batch 25, Loss: 0.098\n",
      "Training: Epoch 84, Batch 26, Loss: 0.085\n",
      "Training: Epoch 84, Batch 27, Loss: 0.106\n",
      "Training: Epoch 84, Batch 28, Loss: 0.084\n",
      "Training: Epoch 84, Batch 29, Loss: 0.079\n",
      "Training: Epoch 84, Batch 30, Loss: 0.086\n",
      "Training: Epoch 84, Batch 31, Loss: 0.098\n",
      "Training: Epoch 84, Batch 32, Loss: 0.102\n",
      "Training: Epoch 84, Batch 33, Loss: 0.089\n",
      "Training: Epoch 84, Batch 34, Loss: 0.107\n",
      "Training: Epoch 84, Batch 35, Loss: 0.09\n",
      "Training: Epoch 84, Batch 36, Loss: 0.104\n",
      "Training: Epoch 84, Batch 37, Loss: 0.09\n",
      "Training: Epoch 84, Batch 38, Loss: 0.095\n",
      "Training: Epoch 84, Batch 39, Loss: 0.092\n",
      "Training: Epoch 84, Batch 40, Loss: 0.093\n",
      "Training: Epoch 84, Batch 41, Loss: 0.095\n",
      "Training: Epoch 84, Batch 42, Loss: 0.089\n",
      "Training: Epoch 84, Batch 43, Loss: 0.077\n",
      "Training: Epoch 84, Batch 44, Loss: 0.089\n",
      "Training: Epoch 84, Batch 45, Loss: 0.094\n",
      "Training: Epoch 84, Batch 46, Loss: 0.103\n",
      "Training: Epoch 84, Batch 47, Loss: 0.091\n",
      "Training: Epoch 84, Batch 48, Loss: 0.087\n",
      "Training: Epoch 84, Batch 49, Loss: 0.094\n",
      "Training: Epoch 84, Batch 50, Loss: 0.114\n",
      "Training: Epoch 84, Batch 51, Loss: 0.131\n",
      "Training: Epoch 84, Batch 52, Loss: 0.1\n",
      "Training: Epoch 84, Batch 53, Loss: 0.119\n",
      "Training: Epoch 84, Batch 54, Loss: 0.099\n",
      "Training: Epoch 84, Batch 55, Loss: 0.094\n",
      "Training: Epoch 84, Batch 56, Loss: 0.133\n",
      "Training: Epoch 84, Batch 57, Loss: 0.098\n",
      "Training: Epoch 84, Batch 58, Loss: 0.09\n",
      "Training: Epoch 84, Batch 59, Loss: 0.1\n",
      "Val: Epoch 84, Loss: 0.235\n",
      "Training: Epoch 85, Batch 0, Loss: 0.081\n",
      "Training: Epoch 85, Batch 1, Loss: 0.111\n",
      "Training: Epoch 85, Batch 2, Loss: 0.101\n",
      "Training: Epoch 85, Batch 3, Loss: 0.103\n",
      "Training: Epoch 85, Batch 4, Loss: 0.126\n",
      "Training: Epoch 85, Batch 5, Loss: 0.097\n",
      "Training: Epoch 85, Batch 6, Loss: 0.105\n",
      "Training: Epoch 85, Batch 7, Loss: 0.11\n",
      "Training: Epoch 85, Batch 8, Loss: 0.088\n",
      "Training: Epoch 85, Batch 9, Loss: 0.12\n",
      "Training: Epoch 85, Batch 10, Loss: 0.086\n",
      "Training: Epoch 85, Batch 11, Loss: 0.103\n",
      "Training: Epoch 85, Batch 12, Loss: 0.107\n",
      "Training: Epoch 85, Batch 13, Loss: 0.087\n",
      "Training: Epoch 85, Batch 14, Loss: 0.102\n",
      "Training: Epoch 85, Batch 15, Loss: 0.113\n",
      "Training: Epoch 85, Batch 16, Loss: 0.122\n",
      "Training: Epoch 85, Batch 17, Loss: 0.098\n",
      "Training: Epoch 85, Batch 18, Loss: 0.098\n",
      "Training: Epoch 85, Batch 19, Loss: 0.087\n",
      "Training: Epoch 85, Batch 20, Loss: 0.088\n",
      "Training: Epoch 85, Batch 21, Loss: 0.097\n",
      "Training: Epoch 85, Batch 22, Loss: 0.08\n",
      "Training: Epoch 85, Batch 23, Loss: 0.105\n",
      "Training: Epoch 85, Batch 24, Loss: 0.139\n",
      "Training: Epoch 85, Batch 25, Loss: 0.102\n",
      "Training: Epoch 85, Batch 26, Loss: 0.097\n",
      "Training: Epoch 85, Batch 27, Loss: 0.107\n",
      "Training: Epoch 85, Batch 28, Loss: 0.114\n",
      "Training: Epoch 85, Batch 29, Loss: 0.1\n",
      "Training: Epoch 85, Batch 30, Loss: 0.114\n",
      "Training: Epoch 85, Batch 31, Loss: 0.084\n",
      "Training: Epoch 85, Batch 32, Loss: 0.1\n",
      "Training: Epoch 85, Batch 33, Loss: 0.128\n",
      "Training: Epoch 85, Batch 34, Loss: 0.087\n",
      "Training: Epoch 85, Batch 35, Loss: 0.077\n",
      "Training: Epoch 85, Batch 36, Loss: 0.082\n",
      "Training: Epoch 85, Batch 37, Loss: 0.09\n",
      "Training: Epoch 85, Batch 38, Loss: 0.1\n",
      "Training: Epoch 85, Batch 39, Loss: 0.085\n",
      "Training: Epoch 85, Batch 40, Loss: 0.091\n",
      "Training: Epoch 85, Batch 41, Loss: 0.113\n",
      "Training: Epoch 85, Batch 42, Loss: 0.111\n",
      "Training: Epoch 85, Batch 43, Loss: 0.089\n",
      "Training: Epoch 85, Batch 44, Loss: 0.094\n",
      "Training: Epoch 85, Batch 45, Loss: 0.092\n",
      "Training: Epoch 85, Batch 46, Loss: 0.124\n",
      "Training: Epoch 85, Batch 47, Loss: 0.073\n",
      "Training: Epoch 85, Batch 48, Loss: 0.093\n",
      "Training: Epoch 85, Batch 49, Loss: 0.087\n",
      "Training: Epoch 85, Batch 50, Loss: 0.099\n",
      "Training: Epoch 85, Batch 51, Loss: 0.095\n",
      "Training: Epoch 85, Batch 52, Loss: 0.11\n",
      "Training: Epoch 85, Batch 53, Loss: 0.089\n",
      "Training: Epoch 85, Batch 54, Loss: 0.095\n",
      "Training: Epoch 85, Batch 55, Loss: 0.101\n",
      "Training: Epoch 85, Batch 56, Loss: 0.109\n",
      "Training: Epoch 85, Batch 57, Loss: 0.123\n",
      "Training: Epoch 85, Batch 58, Loss: 0.082\n",
      "Training: Epoch 85, Batch 59, Loss: 0.088\n",
      "Val: Epoch 85, Loss: 0.237\n",
      "Training: Epoch 86, Batch 0, Loss: 0.125\n",
      "Training: Epoch 86, Batch 1, Loss: 0.1\n",
      "Training: Epoch 86, Batch 2, Loss: 0.118\n",
      "Training: Epoch 86, Batch 3, Loss: 0.093\n",
      "Training: Epoch 86, Batch 4, Loss: 0.083\n",
      "Training: Epoch 86, Batch 5, Loss: 0.127\n",
      "Training: Epoch 86, Batch 6, Loss: 0.098\n",
      "Training: Epoch 86, Batch 7, Loss: 0.114\n",
      "Training: Epoch 86, Batch 8, Loss: 0.085\n",
      "Training: Epoch 86, Batch 9, Loss: 0.101\n",
      "Training: Epoch 86, Batch 10, Loss: 0.107\n",
      "Training: Epoch 86, Batch 11, Loss: 0.093\n",
      "Training: Epoch 86, Batch 12, Loss: 0.092\n",
      "Training: Epoch 86, Batch 13, Loss: 0.11\n",
      "Training: Epoch 86, Batch 14, Loss: 0.083\n",
      "Training: Epoch 86, Batch 15, Loss: 0.106\n",
      "Training: Epoch 86, Batch 16, Loss: 0.077\n",
      "Training: Epoch 86, Batch 17, Loss: 0.09\n",
      "Training: Epoch 86, Batch 18, Loss: 0.069\n",
      "Training: Epoch 86, Batch 19, Loss: 0.09\n",
      "Training: Epoch 86, Batch 20, Loss: 0.12\n",
      "Training: Epoch 86, Batch 21, Loss: 0.09\n",
      "Training: Epoch 86, Batch 22, Loss: 0.065\n",
      "Training: Epoch 86, Batch 23, Loss: 0.096\n",
      "Training: Epoch 86, Batch 24, Loss: 0.115\n",
      "Training: Epoch 86, Batch 25, Loss: 0.073\n",
      "Training: Epoch 86, Batch 26, Loss: 0.104\n",
      "Training: Epoch 86, Batch 27, Loss: 0.113\n",
      "Training: Epoch 86, Batch 28, Loss: 0.087\n",
      "Training: Epoch 86, Batch 29, Loss: 0.097\n",
      "Training: Epoch 86, Batch 30, Loss: 0.094\n",
      "Training: Epoch 86, Batch 31, Loss: 0.109\n",
      "Training: Epoch 86, Batch 32, Loss: 0.095\n",
      "Training: Epoch 86, Batch 33, Loss: 0.108\n",
      "Training: Epoch 86, Batch 34, Loss: 0.132\n",
      "Training: Epoch 86, Batch 35, Loss: 0.091\n",
      "Training: Epoch 86, Batch 36, Loss: 0.122\n",
      "Training: Epoch 86, Batch 37, Loss: 0.085\n",
      "Training: Epoch 86, Batch 38, Loss: 0.083\n",
      "Training: Epoch 86, Batch 39, Loss: 0.083\n",
      "Training: Epoch 86, Batch 40, Loss: 0.101\n",
      "Training: Epoch 86, Batch 41, Loss: 0.105\n",
      "Training: Epoch 86, Batch 42, Loss: 0.099\n",
      "Training: Epoch 86, Batch 43, Loss: 0.083\n",
      "Training: Epoch 86, Batch 44, Loss: 0.103\n",
      "Training: Epoch 86, Batch 45, Loss: 0.11\n",
      "Training: Epoch 86, Batch 46, Loss: 0.1\n",
      "Training: Epoch 86, Batch 47, Loss: 0.086\n",
      "Training: Epoch 86, Batch 48, Loss: 0.078\n",
      "Training: Epoch 86, Batch 49, Loss: 0.094\n",
      "Training: Epoch 86, Batch 50, Loss: 0.103\n",
      "Training: Epoch 86, Batch 51, Loss: 0.092\n",
      "Training: Epoch 86, Batch 52, Loss: 0.088\n",
      "Training: Epoch 86, Batch 53, Loss: 0.113\n",
      "Training: Epoch 86, Batch 54, Loss: 0.102\n",
      "Training: Epoch 86, Batch 55, Loss: 0.116\n",
      "Training: Epoch 86, Batch 56, Loss: 0.077\n",
      "Training: Epoch 86, Batch 57, Loss: 0.117\n",
      "Training: Epoch 86, Batch 58, Loss: 0.096\n",
      "Training: Epoch 86, Batch 59, Loss: 0.075\n",
      "Val: Epoch 86, Loss: 0.882\n",
      "Training: Epoch 87, Batch 0, Loss: 0.083\n",
      "Training: Epoch 87, Batch 1, Loss: 0.084\n",
      "Training: Epoch 87, Batch 2, Loss: 0.085\n",
      "Training: Epoch 87, Batch 3, Loss: 0.083\n",
      "Training: Epoch 87, Batch 4, Loss: 0.084\n",
      "Training: Epoch 87, Batch 5, Loss: 0.091\n",
      "Training: Epoch 87, Batch 6, Loss: 0.084\n",
      "Training: Epoch 87, Batch 7, Loss: 0.096\n",
      "Training: Epoch 87, Batch 8, Loss: 0.095\n",
      "Training: Epoch 87, Batch 9, Loss: 0.081\n",
      "Training: Epoch 87, Batch 10, Loss: 0.105\n",
      "Training: Epoch 87, Batch 11, Loss: 0.113\n",
      "Training: Epoch 87, Batch 12, Loss: 0.097\n",
      "Training: Epoch 87, Batch 13, Loss: 0.093\n",
      "Training: Epoch 87, Batch 14, Loss: 0.078\n",
      "Training: Epoch 87, Batch 15, Loss: 0.093\n",
      "Training: Epoch 87, Batch 16, Loss: 0.081\n",
      "Training: Epoch 87, Batch 17, Loss: 0.097\n",
      "Training: Epoch 87, Batch 18, Loss: 0.093\n",
      "Training: Epoch 87, Batch 19, Loss: 0.088\n",
      "Training: Epoch 87, Batch 20, Loss: 0.105\n",
      "Training: Epoch 87, Batch 21, Loss: 0.068\n",
      "Training: Epoch 87, Batch 22, Loss: 0.107\n",
      "Training: Epoch 87, Batch 23, Loss: 0.112\n",
      "Training: Epoch 87, Batch 24, Loss: 0.099\n",
      "Training: Epoch 87, Batch 25, Loss: 0.099\n",
      "Training: Epoch 87, Batch 26, Loss: 0.098\n",
      "Training: Epoch 87, Batch 27, Loss: 0.095\n",
      "Training: Epoch 87, Batch 28, Loss: 0.109\n",
      "Training: Epoch 87, Batch 29, Loss: 0.089\n",
      "Training: Epoch 87, Batch 30, Loss: 0.103\n",
      "Training: Epoch 87, Batch 31, Loss: 0.097\n",
      "Training: Epoch 87, Batch 32, Loss: 0.089\n",
      "Training: Epoch 87, Batch 33, Loss: 0.109\n",
      "Training: Epoch 87, Batch 34, Loss: 0.108\n",
      "Training: Epoch 87, Batch 35, Loss: 0.098\n",
      "Training: Epoch 87, Batch 36, Loss: 0.09\n",
      "Training: Epoch 87, Batch 37, Loss: 0.097\n",
      "Training: Epoch 87, Batch 38, Loss: 0.083\n",
      "Training: Epoch 87, Batch 39, Loss: 0.101\n",
      "Training: Epoch 87, Batch 40, Loss: 0.098\n",
      "Training: Epoch 87, Batch 41, Loss: 0.112\n",
      "Training: Epoch 87, Batch 42, Loss: 0.106\n",
      "Training: Epoch 87, Batch 43, Loss: 0.102\n",
      "Training: Epoch 87, Batch 44, Loss: 0.108\n",
      "Training: Epoch 87, Batch 45, Loss: 0.074\n",
      "Training: Epoch 87, Batch 46, Loss: 0.103\n",
      "Training: Epoch 87, Batch 47, Loss: 0.109\n",
      "Training: Epoch 87, Batch 48, Loss: 0.105\n",
      "Training: Epoch 87, Batch 49, Loss: 0.109\n",
      "Training: Epoch 87, Batch 50, Loss: 0.086\n",
      "Training: Epoch 87, Batch 51, Loss: 0.106\n",
      "Training: Epoch 87, Batch 52, Loss: 0.092\n",
      "Training: Epoch 87, Batch 53, Loss: 0.094\n",
      "Training: Epoch 87, Batch 54, Loss: 0.086\n",
      "Training: Epoch 87, Batch 55, Loss: 0.076\n",
      "Training: Epoch 87, Batch 56, Loss: 0.078\n",
      "Training: Epoch 87, Batch 57, Loss: 0.099\n",
      "Training: Epoch 87, Batch 58, Loss: 0.105\n",
      "Training: Epoch 87, Batch 59, Loss: 0.12\n",
      "Val: Epoch 87, Loss: 0.216\n",
      "Training: Epoch 88, Batch 0, Loss: 0.093\n",
      "Training: Epoch 88, Batch 1, Loss: 0.078\n",
      "Training: Epoch 88, Batch 2, Loss: 0.11\n",
      "Training: Epoch 88, Batch 3, Loss: 0.087\n",
      "Training: Epoch 88, Batch 4, Loss: 0.102\n",
      "Training: Epoch 88, Batch 5, Loss: 0.107\n",
      "Training: Epoch 88, Batch 6, Loss: 0.097\n",
      "Training: Epoch 88, Batch 7, Loss: 0.079\n",
      "Training: Epoch 88, Batch 8, Loss: 0.089\n",
      "Training: Epoch 88, Batch 9, Loss: 0.087\n",
      "Training: Epoch 88, Batch 10, Loss: 0.103\n",
      "Training: Epoch 88, Batch 11, Loss: 0.111\n",
      "Training: Epoch 88, Batch 12, Loss: 0.12\n",
      "Training: Epoch 88, Batch 13, Loss: 0.106\n",
      "Training: Epoch 88, Batch 14, Loss: 0.108\n",
      "Training: Epoch 88, Batch 15, Loss: 0.107\n",
      "Training: Epoch 88, Batch 16, Loss: 0.105\n",
      "Training: Epoch 88, Batch 17, Loss: 0.08\n",
      "Training: Epoch 88, Batch 18, Loss: 0.097\n",
      "Training: Epoch 88, Batch 19, Loss: 0.091\n",
      "Training: Epoch 88, Batch 20, Loss: 0.087\n",
      "Training: Epoch 88, Batch 21, Loss: 0.103\n",
      "Training: Epoch 88, Batch 22, Loss: 0.119\n",
      "Training: Epoch 88, Batch 23, Loss: 0.098\n",
      "Training: Epoch 88, Batch 24, Loss: 0.091\n",
      "Training: Epoch 88, Batch 25, Loss: 0.08\n",
      "Training: Epoch 88, Batch 26, Loss: 0.081\n",
      "Training: Epoch 88, Batch 27, Loss: 0.082\n",
      "Training: Epoch 88, Batch 28, Loss: 0.114\n",
      "Training: Epoch 88, Batch 29, Loss: 0.075\n",
      "Training: Epoch 88, Batch 30, Loss: 0.109\n",
      "Training: Epoch 88, Batch 31, Loss: 0.1\n",
      "Training: Epoch 88, Batch 32, Loss: 0.107\n",
      "Training: Epoch 88, Batch 33, Loss: 0.097\n",
      "Training: Epoch 88, Batch 34, Loss: 0.113\n",
      "Training: Epoch 88, Batch 35, Loss: 0.088\n",
      "Training: Epoch 88, Batch 36, Loss: 0.106\n",
      "Training: Epoch 88, Batch 37, Loss: 0.116\n",
      "Training: Epoch 88, Batch 38, Loss: 0.115\n",
      "Training: Epoch 88, Batch 39, Loss: 0.091\n",
      "Training: Epoch 88, Batch 40, Loss: 0.106\n",
      "Training: Epoch 88, Batch 41, Loss: 0.079\n",
      "Training: Epoch 88, Batch 42, Loss: 0.11\n",
      "Training: Epoch 88, Batch 43, Loss: 0.082\n",
      "Training: Epoch 88, Batch 44, Loss: 0.105\n",
      "Training: Epoch 88, Batch 45, Loss: 0.077\n",
      "Training: Epoch 88, Batch 46, Loss: 0.128\n",
      "Training: Epoch 88, Batch 47, Loss: 0.098\n",
      "Training: Epoch 88, Batch 48, Loss: 0.092\n",
      "Training: Epoch 88, Batch 49, Loss: 0.089\n",
      "Training: Epoch 88, Batch 50, Loss: 0.099\n",
      "Training: Epoch 88, Batch 51, Loss: 0.085\n",
      "Training: Epoch 88, Batch 52, Loss: 0.11\n",
      "Training: Epoch 88, Batch 53, Loss: 0.102\n",
      "Training: Epoch 88, Batch 54, Loss: 0.094\n",
      "Training: Epoch 88, Batch 55, Loss: 0.097\n",
      "Training: Epoch 88, Batch 56, Loss: 0.07\n",
      "Training: Epoch 88, Batch 57, Loss: 0.098\n",
      "Training: Epoch 88, Batch 58, Loss: 0.107\n",
      "Training: Epoch 88, Batch 59, Loss: 0.09\n",
      "Val: Epoch 88, Loss: 0.226\n",
      "Training: Epoch 89, Batch 0, Loss: 0.09\n",
      "Training: Epoch 89, Batch 1, Loss: 0.1\n",
      "Training: Epoch 89, Batch 2, Loss: 0.095\n",
      "Training: Epoch 89, Batch 3, Loss: 0.106\n",
      "Training: Epoch 89, Batch 4, Loss: 0.099\n",
      "Training: Epoch 89, Batch 5, Loss: 0.096\n",
      "Training: Epoch 89, Batch 6, Loss: 0.079\n",
      "Training: Epoch 89, Batch 7, Loss: 0.125\n",
      "Training: Epoch 89, Batch 8, Loss: 0.091\n",
      "Training: Epoch 89, Batch 9, Loss: 0.099\n",
      "Training: Epoch 89, Batch 10, Loss: 0.087\n",
      "Training: Epoch 89, Batch 11, Loss: 0.095\n",
      "Training: Epoch 89, Batch 12, Loss: 0.082\n",
      "Training: Epoch 89, Batch 13, Loss: 0.097\n",
      "Training: Epoch 89, Batch 14, Loss: 0.105\n",
      "Training: Epoch 89, Batch 15, Loss: 0.08\n",
      "Training: Epoch 89, Batch 16, Loss: 0.088\n",
      "Training: Epoch 89, Batch 17, Loss: 0.091\n",
      "Training: Epoch 89, Batch 18, Loss: 0.1\n",
      "Training: Epoch 89, Batch 19, Loss: 0.085\n",
      "Training: Epoch 89, Batch 20, Loss: 0.112\n",
      "Training: Epoch 89, Batch 21, Loss: 0.091\n",
      "Training: Epoch 89, Batch 22, Loss: 0.077\n",
      "Training: Epoch 89, Batch 23, Loss: 0.085\n",
      "Training: Epoch 89, Batch 24, Loss: 0.117\n",
      "Training: Epoch 89, Batch 25, Loss: 0.099\n",
      "Training: Epoch 89, Batch 26, Loss: 0.104\n",
      "Training: Epoch 89, Batch 27, Loss: 0.104\n",
      "Training: Epoch 89, Batch 28, Loss: 0.074\n",
      "Training: Epoch 89, Batch 29, Loss: 0.096\n",
      "Training: Epoch 89, Batch 30, Loss: 0.093\n",
      "Training: Epoch 89, Batch 31, Loss: 0.097\n",
      "Training: Epoch 89, Batch 32, Loss: 0.084\n",
      "Training: Epoch 89, Batch 33, Loss: 0.09\n",
      "Training: Epoch 89, Batch 34, Loss: 0.089\n",
      "Training: Epoch 89, Batch 35, Loss: 0.094\n",
      "Training: Epoch 89, Batch 36, Loss: 0.093\n",
      "Training: Epoch 89, Batch 37, Loss: 0.085\n",
      "Training: Epoch 89, Batch 38, Loss: 0.092\n",
      "Training: Epoch 89, Batch 39, Loss: 0.083\n",
      "Training: Epoch 89, Batch 40, Loss: 0.116\n",
      "Training: Epoch 89, Batch 41, Loss: 0.089\n",
      "Training: Epoch 89, Batch 42, Loss: 0.09\n",
      "Training: Epoch 89, Batch 43, Loss: 0.1\n",
      "Training: Epoch 89, Batch 44, Loss: 0.091\n",
      "Training: Epoch 89, Batch 45, Loss: 0.074\n",
      "Training: Epoch 89, Batch 46, Loss: 0.089\n",
      "Training: Epoch 89, Batch 47, Loss: 0.097\n",
      "Training: Epoch 89, Batch 48, Loss: 0.117\n",
      "Training: Epoch 89, Batch 49, Loss: 0.104\n",
      "Training: Epoch 89, Batch 50, Loss: 0.089\n",
      "Training: Epoch 89, Batch 51, Loss: 0.09\n",
      "Training: Epoch 89, Batch 52, Loss: 0.088\n",
      "Training: Epoch 89, Batch 53, Loss: 0.103\n",
      "Training: Epoch 89, Batch 54, Loss: 0.081\n",
      "Training: Epoch 89, Batch 55, Loss: 0.114\n",
      "Training: Epoch 89, Batch 56, Loss: 0.067\n",
      "Training: Epoch 89, Batch 57, Loss: 0.095\n",
      "Training: Epoch 89, Batch 58, Loss: 0.099\n",
      "Training: Epoch 89, Batch 59, Loss: 0.086\n",
      "Val: Epoch 89, Loss: 0.606\n",
      "Training: Epoch 90, Batch 0, Loss: 0.076\n",
      "Training: Epoch 90, Batch 1, Loss: 0.083\n",
      "Training: Epoch 90, Batch 2, Loss: 0.105\n",
      "Training: Epoch 90, Batch 3, Loss: 0.083\n",
      "Training: Epoch 90, Batch 4, Loss: 0.106\n",
      "Training: Epoch 90, Batch 5, Loss: 0.107\n",
      "Training: Epoch 90, Batch 6, Loss: 0.083\n",
      "Training: Epoch 90, Batch 7, Loss: 0.082\n",
      "Training: Epoch 90, Batch 8, Loss: 0.093\n",
      "Training: Epoch 90, Batch 9, Loss: 0.088\n",
      "Training: Epoch 90, Batch 10, Loss: 0.1\n",
      "Training: Epoch 90, Batch 11, Loss: 0.069\n",
      "Training: Epoch 90, Batch 12, Loss: 0.093\n",
      "Training: Epoch 90, Batch 13, Loss: 0.092\n",
      "Training: Epoch 90, Batch 14, Loss: 0.109\n",
      "Training: Epoch 90, Batch 15, Loss: 0.09\n",
      "Training: Epoch 90, Batch 16, Loss: 0.075\n",
      "Training: Epoch 90, Batch 17, Loss: 0.095\n",
      "Training: Epoch 90, Batch 18, Loss: 0.073\n",
      "Training: Epoch 90, Batch 19, Loss: 0.094\n",
      "Training: Epoch 90, Batch 20, Loss: 0.096\n",
      "Training: Epoch 90, Batch 21, Loss: 0.081\n",
      "Training: Epoch 90, Batch 22, Loss: 0.115\n",
      "Training: Epoch 90, Batch 23, Loss: 0.088\n",
      "Training: Epoch 90, Batch 24, Loss: 0.1\n",
      "Training: Epoch 90, Batch 25, Loss: 0.09\n",
      "Training: Epoch 90, Batch 26, Loss: 0.118\n",
      "Training: Epoch 90, Batch 27, Loss: 0.094\n",
      "Training: Epoch 90, Batch 28, Loss: 0.064\n",
      "Training: Epoch 90, Batch 29, Loss: 0.084\n",
      "Training: Epoch 90, Batch 30, Loss: 0.087\n",
      "Training: Epoch 90, Batch 31, Loss: 0.091\n",
      "Training: Epoch 90, Batch 32, Loss: 0.099\n",
      "Training: Epoch 90, Batch 33, Loss: 0.095\n",
      "Training: Epoch 90, Batch 34, Loss: 0.071\n",
      "Training: Epoch 90, Batch 35, Loss: 0.101\n",
      "Training: Epoch 90, Batch 36, Loss: 0.088\n",
      "Training: Epoch 90, Batch 37, Loss: 0.11\n",
      "Training: Epoch 90, Batch 38, Loss: 0.081\n",
      "Training: Epoch 90, Batch 39, Loss: 0.086\n",
      "Training: Epoch 90, Batch 40, Loss: 0.09\n",
      "Training: Epoch 90, Batch 41, Loss: 0.097\n",
      "Training: Epoch 90, Batch 42, Loss: 0.071\n",
      "Training: Epoch 90, Batch 43, Loss: 0.091\n",
      "Training: Epoch 90, Batch 44, Loss: 0.076\n",
      "Training: Epoch 90, Batch 45, Loss: 0.09\n",
      "Training: Epoch 90, Batch 46, Loss: 0.089\n",
      "Training: Epoch 90, Batch 47, Loss: 0.101\n",
      "Training: Epoch 90, Batch 48, Loss: 0.095\n",
      "Training: Epoch 90, Batch 49, Loss: 0.07\n",
      "Training: Epoch 90, Batch 50, Loss: 0.088\n",
      "Training: Epoch 90, Batch 51, Loss: 0.083\n",
      "Training: Epoch 90, Batch 52, Loss: 0.088\n",
      "Training: Epoch 90, Batch 53, Loss: 0.108\n",
      "Training: Epoch 90, Batch 54, Loss: 0.089\n",
      "Training: Epoch 90, Batch 55, Loss: 0.082\n",
      "Training: Epoch 90, Batch 56, Loss: 0.093\n",
      "Training: Epoch 90, Batch 57, Loss: 0.093\n",
      "Training: Epoch 90, Batch 58, Loss: 0.073\n",
      "Training: Epoch 90, Batch 59, Loss: 0.073\n",
      "Val: Epoch 90, Loss: 0.23\n",
      "Training: Epoch 91, Batch 0, Loss: 0.077\n",
      "Training: Epoch 91, Batch 1, Loss: 0.097\n",
      "Training: Epoch 91, Batch 2, Loss: 0.089\n",
      "Training: Epoch 91, Batch 3, Loss: 0.085\n",
      "Training: Epoch 91, Batch 4, Loss: 0.088\n",
      "Training: Epoch 91, Batch 5, Loss: 0.084\n",
      "Training: Epoch 91, Batch 6, Loss: 0.094\n",
      "Training: Epoch 91, Batch 7, Loss: 0.097\n",
      "Training: Epoch 91, Batch 8, Loss: 0.076\n",
      "Training: Epoch 91, Batch 9, Loss: 0.092\n",
      "Training: Epoch 91, Batch 10, Loss: 0.108\n",
      "Training: Epoch 91, Batch 11, Loss: 0.097\n",
      "Training: Epoch 91, Batch 12, Loss: 0.087\n",
      "Training: Epoch 91, Batch 13, Loss: 0.078\n",
      "Training: Epoch 91, Batch 14, Loss: 0.097\n",
      "Training: Epoch 91, Batch 15, Loss: 0.089\n",
      "Training: Epoch 91, Batch 16, Loss: 0.098\n",
      "Training: Epoch 91, Batch 17, Loss: 0.095\n",
      "Training: Epoch 91, Batch 18, Loss: 0.078\n",
      "Training: Epoch 91, Batch 19, Loss: 0.092\n",
      "Training: Epoch 91, Batch 20, Loss: 0.081\n",
      "Training: Epoch 91, Batch 21, Loss: 0.085\n",
      "Training: Epoch 91, Batch 22, Loss: 0.081\n",
      "Training: Epoch 91, Batch 23, Loss: 0.11\n",
      "Training: Epoch 91, Batch 24, Loss: 0.084\n",
      "Training: Epoch 91, Batch 25, Loss: 0.093\n",
      "Training: Epoch 91, Batch 26, Loss: 0.093\n",
      "Training: Epoch 91, Batch 27, Loss: 0.098\n",
      "Training: Epoch 91, Batch 28, Loss: 0.077\n",
      "Training: Epoch 91, Batch 29, Loss: 0.091\n",
      "Training: Epoch 91, Batch 30, Loss: 0.101\n",
      "Training: Epoch 91, Batch 31, Loss: 0.086\n",
      "Training: Epoch 91, Batch 32, Loss: 0.096\n",
      "Training: Epoch 91, Batch 33, Loss: 0.074\n",
      "Training: Epoch 91, Batch 34, Loss: 0.082\n",
      "Training: Epoch 91, Batch 35, Loss: 0.07\n",
      "Training: Epoch 91, Batch 36, Loss: 0.074\n",
      "Training: Epoch 91, Batch 37, Loss: 0.086\n",
      "Training: Epoch 91, Batch 38, Loss: 0.095\n",
      "Training: Epoch 91, Batch 39, Loss: 0.094\n",
      "Training: Epoch 91, Batch 40, Loss: 0.103\n",
      "Training: Epoch 91, Batch 41, Loss: 0.107\n",
      "Training: Epoch 91, Batch 42, Loss: 0.078\n",
      "Training: Epoch 91, Batch 43, Loss: 0.101\n",
      "Training: Epoch 91, Batch 44, Loss: 0.116\n",
      "Training: Epoch 91, Batch 45, Loss: 0.095\n",
      "Training: Epoch 91, Batch 46, Loss: 0.095\n",
      "Training: Epoch 91, Batch 47, Loss: 0.093\n",
      "Training: Epoch 91, Batch 48, Loss: 0.101\n",
      "Training: Epoch 91, Batch 49, Loss: 0.09\n",
      "Training: Epoch 91, Batch 50, Loss: 0.078\n",
      "Training: Epoch 91, Batch 51, Loss: 0.085\n",
      "Training: Epoch 91, Batch 52, Loss: 0.086\n",
      "Training: Epoch 91, Batch 53, Loss: 0.077\n",
      "Training: Epoch 91, Batch 54, Loss: 0.08\n",
      "Training: Epoch 91, Batch 55, Loss: 0.097\n",
      "Training: Epoch 91, Batch 56, Loss: 0.087\n",
      "Training: Epoch 91, Batch 57, Loss: 0.074\n",
      "Training: Epoch 91, Batch 58, Loss: 0.1\n",
      "Training: Epoch 91, Batch 59, Loss: 0.084\n",
      "Val: Epoch 91, Loss: 0.236\n",
      "Training: Epoch 92, Batch 0, Loss: 0.114\n",
      "Training: Epoch 92, Batch 1, Loss: 0.092\n",
      "Training: Epoch 92, Batch 2, Loss: 0.098\n",
      "Training: Epoch 92, Batch 3, Loss: 0.089\n",
      "Training: Epoch 92, Batch 4, Loss: 0.09\n",
      "Training: Epoch 92, Batch 5, Loss: 0.089\n",
      "Training: Epoch 92, Batch 6, Loss: 0.079\n",
      "Training: Epoch 92, Batch 7, Loss: 0.082\n",
      "Training: Epoch 92, Batch 8, Loss: 0.091\n",
      "Training: Epoch 92, Batch 9, Loss: 0.107\n",
      "Training: Epoch 92, Batch 10, Loss: 0.093\n",
      "Training: Epoch 92, Batch 11, Loss: 0.082\n",
      "Training: Epoch 92, Batch 12, Loss: 0.087\n",
      "Training: Epoch 92, Batch 13, Loss: 0.082\n",
      "Training: Epoch 92, Batch 14, Loss: 0.099\n",
      "Training: Epoch 92, Batch 15, Loss: 0.131\n",
      "Training: Epoch 92, Batch 16, Loss: 0.08\n",
      "Training: Epoch 92, Batch 17, Loss: 0.083\n",
      "Training: Epoch 92, Batch 18, Loss: 0.08\n",
      "Training: Epoch 92, Batch 19, Loss: 0.09\n",
      "Training: Epoch 92, Batch 20, Loss: 0.09\n",
      "Training: Epoch 92, Batch 21, Loss: 0.081\n",
      "Training: Epoch 92, Batch 22, Loss: 0.08\n",
      "Training: Epoch 92, Batch 23, Loss: 0.075\n",
      "Training: Epoch 92, Batch 24, Loss: 0.071\n",
      "Training: Epoch 92, Batch 25, Loss: 0.083\n",
      "Training: Epoch 92, Batch 26, Loss: 0.072\n",
      "Training: Epoch 92, Batch 27, Loss: 0.092\n",
      "Training: Epoch 92, Batch 28, Loss: 0.096\n",
      "Training: Epoch 92, Batch 29, Loss: 0.085\n",
      "Training: Epoch 92, Batch 30, Loss: 0.103\n",
      "Training: Epoch 92, Batch 31, Loss: 0.096\n",
      "Training: Epoch 92, Batch 32, Loss: 0.08\n",
      "Training: Epoch 92, Batch 33, Loss: 0.085\n",
      "Training: Epoch 92, Batch 34, Loss: 0.099\n",
      "Training: Epoch 92, Batch 35, Loss: 0.085\n",
      "Training: Epoch 92, Batch 36, Loss: 0.083\n",
      "Training: Epoch 92, Batch 37, Loss: 0.089\n",
      "Training: Epoch 92, Batch 38, Loss: 0.106\n",
      "Training: Epoch 92, Batch 39, Loss: 0.092\n",
      "Training: Epoch 92, Batch 40, Loss: 0.08\n",
      "Training: Epoch 92, Batch 41, Loss: 0.115\n",
      "Training: Epoch 92, Batch 42, Loss: 0.089\n",
      "Training: Epoch 92, Batch 43, Loss: 0.09\n",
      "Training: Epoch 92, Batch 44, Loss: 0.085\n",
      "Training: Epoch 92, Batch 45, Loss: 0.091\n",
      "Training: Epoch 92, Batch 46, Loss: 0.073\n",
      "Training: Epoch 92, Batch 47, Loss: 0.089\n",
      "Training: Epoch 92, Batch 48, Loss: 0.093\n",
      "Training: Epoch 92, Batch 49, Loss: 0.082\n",
      "Training: Epoch 92, Batch 50, Loss: 0.097\n",
      "Training: Epoch 92, Batch 51, Loss: 0.092\n",
      "Training: Epoch 92, Batch 52, Loss: 0.07\n",
      "Training: Epoch 92, Batch 53, Loss: 0.085\n",
      "Training: Epoch 92, Batch 54, Loss: 0.104\n",
      "Training: Epoch 92, Batch 55, Loss: 0.092\n",
      "Training: Epoch 92, Batch 56, Loss: 0.099\n",
      "Training: Epoch 92, Batch 57, Loss: 0.097\n",
      "Training: Epoch 92, Batch 58, Loss: 0.092\n",
      "Training: Epoch 92, Batch 59, Loss: 0.091\n",
      "Val: Epoch 92, Loss: 0.24\n",
      "Training: Epoch 93, Batch 0, Loss: 0.126\n",
      "Training: Epoch 93, Batch 1, Loss: 0.077\n",
      "Training: Epoch 93, Batch 2, Loss: 0.087\n",
      "Training: Epoch 93, Batch 3, Loss: 0.103\n",
      "Training: Epoch 93, Batch 4, Loss: 0.076\n",
      "Training: Epoch 93, Batch 5, Loss: 0.103\n",
      "Training: Epoch 93, Batch 6, Loss: 0.079\n",
      "Training: Epoch 93, Batch 7, Loss: 0.095\n",
      "Training: Epoch 93, Batch 8, Loss: 0.091\n",
      "Training: Epoch 93, Batch 9, Loss: 0.088\n",
      "Training: Epoch 93, Batch 10, Loss: 0.082\n",
      "Training: Epoch 93, Batch 11, Loss: 0.085\n",
      "Training: Epoch 93, Batch 12, Loss: 0.094\n",
      "Training: Epoch 93, Batch 13, Loss: 0.097\n",
      "Training: Epoch 93, Batch 14, Loss: 0.078\n",
      "Training: Epoch 93, Batch 15, Loss: 0.077\n",
      "Training: Epoch 93, Batch 16, Loss: 0.088\n",
      "Training: Epoch 93, Batch 17, Loss: 0.075\n",
      "Training: Epoch 93, Batch 18, Loss: 0.085\n",
      "Training: Epoch 93, Batch 19, Loss: 0.073\n",
      "Training: Epoch 93, Batch 20, Loss: 0.093\n",
      "Training: Epoch 93, Batch 21, Loss: 0.106\n",
      "Training: Epoch 93, Batch 22, Loss: 0.116\n",
      "Training: Epoch 93, Batch 23, Loss: 0.105\n",
      "Training: Epoch 93, Batch 24, Loss: 0.102\n",
      "Training: Epoch 93, Batch 25, Loss: 0.097\n",
      "Training: Epoch 93, Batch 26, Loss: 0.082\n",
      "Training: Epoch 93, Batch 27, Loss: 0.081\n",
      "Training: Epoch 93, Batch 28, Loss: 0.09\n",
      "Training: Epoch 93, Batch 29, Loss: 0.093\n",
      "Training: Epoch 93, Batch 30, Loss: 0.082\n",
      "Training: Epoch 93, Batch 31, Loss: 0.073\n",
      "Training: Epoch 93, Batch 32, Loss: 0.089\n",
      "Training: Epoch 93, Batch 33, Loss: 0.09\n",
      "Training: Epoch 93, Batch 34, Loss: 0.073\n",
      "Training: Epoch 93, Batch 35, Loss: 0.084\n",
      "Training: Epoch 93, Batch 36, Loss: 0.098\n",
      "Training: Epoch 93, Batch 37, Loss: 0.101\n",
      "Training: Epoch 93, Batch 38, Loss: 0.075\n",
      "Training: Epoch 93, Batch 39, Loss: 0.112\n",
      "Training: Epoch 93, Batch 40, Loss: 0.091\n",
      "Training: Epoch 93, Batch 41, Loss: 0.101\n",
      "Training: Epoch 93, Batch 42, Loss: 0.106\n",
      "Training: Epoch 93, Batch 43, Loss: 0.092\n",
      "Training: Epoch 93, Batch 44, Loss: 0.096\n",
      "Training: Epoch 93, Batch 45, Loss: 0.09\n",
      "Training: Epoch 93, Batch 46, Loss: 0.077\n",
      "Training: Epoch 93, Batch 47, Loss: 0.082\n",
      "Training: Epoch 93, Batch 48, Loss: 0.113\n",
      "Training: Epoch 93, Batch 49, Loss: 0.093\n",
      "Training: Epoch 93, Batch 50, Loss: 0.098\n",
      "Training: Epoch 93, Batch 51, Loss: 0.082\n",
      "Training: Epoch 93, Batch 52, Loss: 0.118\n",
      "Training: Epoch 93, Batch 53, Loss: 0.079\n",
      "Training: Epoch 93, Batch 54, Loss: 0.068\n",
      "Training: Epoch 93, Batch 55, Loss: 0.086\n",
      "Training: Epoch 93, Batch 56, Loss: 0.081\n",
      "Training: Epoch 93, Batch 57, Loss: 0.1\n",
      "Training: Epoch 93, Batch 58, Loss: 0.101\n",
      "Training: Epoch 93, Batch 59, Loss: 0.08\n",
      "Val: Epoch 93, Loss: 0.359\n",
      "Training: Epoch 94, Batch 0, Loss: 0.094\n",
      "Training: Epoch 94, Batch 1, Loss: 0.137\n",
      "Training: Epoch 94, Batch 2, Loss: 0.136\n",
      "Training: Epoch 94, Batch 3, Loss: 0.109\n",
      "Training: Epoch 94, Batch 4, Loss: 0.093\n",
      "Training: Epoch 94, Batch 5, Loss: 0.096\n",
      "Training: Epoch 94, Batch 6, Loss: 0.097\n",
      "Training: Epoch 94, Batch 7, Loss: 0.093\n",
      "Training: Epoch 94, Batch 8, Loss: 0.131\n",
      "Training: Epoch 94, Batch 9, Loss: 0.113\n",
      "Training: Epoch 94, Batch 10, Loss: 0.116\n",
      "Training: Epoch 94, Batch 11, Loss: 0.098\n",
      "Training: Epoch 94, Batch 12, Loss: 0.083\n",
      "Training: Epoch 94, Batch 13, Loss: 0.091\n",
      "Training: Epoch 94, Batch 14, Loss: 0.096\n",
      "Training: Epoch 94, Batch 15, Loss: 0.126\n",
      "Training: Epoch 94, Batch 16, Loss: 0.104\n",
      "Training: Epoch 94, Batch 17, Loss: 0.1\n",
      "Training: Epoch 94, Batch 18, Loss: 0.1\n",
      "Training: Epoch 94, Batch 19, Loss: 0.103\n",
      "Training: Epoch 94, Batch 20, Loss: 0.088\n",
      "Training: Epoch 94, Batch 21, Loss: 0.118\n",
      "Training: Epoch 94, Batch 22, Loss: 0.108\n",
      "Training: Epoch 94, Batch 23, Loss: 0.093\n",
      "Training: Epoch 94, Batch 24, Loss: 0.117\n",
      "Training: Epoch 94, Batch 25, Loss: 0.093\n",
      "Training: Epoch 94, Batch 26, Loss: 0.129\n",
      "Training: Epoch 94, Batch 27, Loss: 0.092\n",
      "Training: Epoch 94, Batch 28, Loss: 0.073\n",
      "Training: Epoch 94, Batch 29, Loss: 0.092\n",
      "Training: Epoch 94, Batch 30, Loss: 0.092\n",
      "Training: Epoch 94, Batch 31, Loss: 0.078\n",
      "Training: Epoch 94, Batch 32, Loss: 0.107\n",
      "Training: Epoch 94, Batch 33, Loss: 0.098\n",
      "Training: Epoch 94, Batch 34, Loss: 0.104\n",
      "Training: Epoch 94, Batch 35, Loss: 0.09\n",
      "Training: Epoch 94, Batch 36, Loss: 0.107\n",
      "Training: Epoch 94, Batch 37, Loss: 0.119\n",
      "Training: Epoch 94, Batch 38, Loss: 0.077\n",
      "Training: Epoch 94, Batch 39, Loss: 0.078\n",
      "Training: Epoch 94, Batch 40, Loss: 0.094\n",
      "Training: Epoch 94, Batch 41, Loss: 0.076\n",
      "Training: Epoch 94, Batch 42, Loss: 0.077\n",
      "Training: Epoch 94, Batch 43, Loss: 0.101\n",
      "Training: Epoch 94, Batch 44, Loss: 0.102\n",
      "Training: Epoch 94, Batch 45, Loss: 0.098\n",
      "Training: Epoch 94, Batch 46, Loss: 0.086\n",
      "Training: Epoch 94, Batch 47, Loss: 0.102\n",
      "Training: Epoch 94, Batch 48, Loss: 0.106\n",
      "Training: Epoch 94, Batch 49, Loss: 0.081\n",
      "Training: Epoch 94, Batch 50, Loss: 0.094\n",
      "Training: Epoch 94, Batch 51, Loss: 0.094\n",
      "Training: Epoch 94, Batch 52, Loss: 0.101\n",
      "Training: Epoch 94, Batch 53, Loss: 0.096\n",
      "Training: Epoch 94, Batch 54, Loss: 0.088\n",
      "Training: Epoch 94, Batch 55, Loss: 0.113\n",
      "Training: Epoch 94, Batch 56, Loss: 0.116\n",
      "Training: Epoch 94, Batch 57, Loss: 0.085\n",
      "Training: Epoch 94, Batch 58, Loss: 0.104\n",
      "Training: Epoch 94, Batch 59, Loss: 0.091\n",
      "Val: Epoch 94, Loss: 0.22\n",
      "Training: Epoch 95, Batch 0, Loss: 0.097\n",
      "Training: Epoch 95, Batch 1, Loss: 0.102\n",
      "Training: Epoch 95, Batch 2, Loss: 0.086\n",
      "Training: Epoch 95, Batch 3, Loss: 0.086\n",
      "Training: Epoch 95, Batch 4, Loss: 0.094\n",
      "Training: Epoch 95, Batch 5, Loss: 0.094\n",
      "Training: Epoch 95, Batch 6, Loss: 0.094\n",
      "Training: Epoch 95, Batch 7, Loss: 0.097\n",
      "Training: Epoch 95, Batch 8, Loss: 0.106\n",
      "Training: Epoch 95, Batch 9, Loss: 0.11\n",
      "Training: Epoch 95, Batch 10, Loss: 0.082\n",
      "Training: Epoch 95, Batch 11, Loss: 0.085\n",
      "Training: Epoch 95, Batch 12, Loss: 0.094\n",
      "Training: Epoch 95, Batch 13, Loss: 0.084\n",
      "Training: Epoch 95, Batch 14, Loss: 0.103\n",
      "Training: Epoch 95, Batch 15, Loss: 0.101\n",
      "Training: Epoch 95, Batch 16, Loss: 0.094\n",
      "Training: Epoch 95, Batch 17, Loss: 0.088\n",
      "Training: Epoch 95, Batch 18, Loss: 0.078\n",
      "Training: Epoch 95, Batch 19, Loss: 0.085\n",
      "Training: Epoch 95, Batch 20, Loss: 0.087\n",
      "Training: Epoch 95, Batch 21, Loss: 0.097\n",
      "Training: Epoch 95, Batch 22, Loss: 0.106\n",
      "Training: Epoch 95, Batch 23, Loss: 0.082\n",
      "Training: Epoch 95, Batch 24, Loss: 0.088\n",
      "Training: Epoch 95, Batch 25, Loss: 0.076\n",
      "Training: Epoch 95, Batch 26, Loss: 0.09\n",
      "Training: Epoch 95, Batch 27, Loss: 0.077\n",
      "Training: Epoch 95, Batch 28, Loss: 0.103\n",
      "Training: Epoch 95, Batch 29, Loss: 0.08\n",
      "Training: Epoch 95, Batch 30, Loss: 0.096\n",
      "Training: Epoch 95, Batch 31, Loss: 0.106\n",
      "Training: Epoch 95, Batch 32, Loss: 0.081\n",
      "Training: Epoch 95, Batch 33, Loss: 0.079\n",
      "Training: Epoch 95, Batch 34, Loss: 0.084\n",
      "Training: Epoch 95, Batch 35, Loss: 0.069\n",
      "Training: Epoch 95, Batch 36, Loss: 0.069\n",
      "Training: Epoch 95, Batch 37, Loss: 0.082\n",
      "Training: Epoch 95, Batch 38, Loss: 0.126\n",
      "Training: Epoch 95, Batch 39, Loss: 0.088\n",
      "Training: Epoch 95, Batch 40, Loss: 0.076\n",
      "Training: Epoch 95, Batch 41, Loss: 0.078\n",
      "Training: Epoch 95, Batch 42, Loss: 0.12\n",
      "Training: Epoch 95, Batch 43, Loss: 0.142\n",
      "Training: Epoch 95, Batch 44, Loss: 0.093\n",
      "Training: Epoch 95, Batch 45, Loss: 0.072\n",
      "Training: Epoch 95, Batch 46, Loss: 0.12\n",
      "Training: Epoch 95, Batch 47, Loss: 0.084\n",
      "Training: Epoch 95, Batch 48, Loss: 0.07\n",
      "Training: Epoch 95, Batch 49, Loss: 0.09\n",
      "Training: Epoch 95, Batch 50, Loss: 0.094\n",
      "Training: Epoch 95, Batch 51, Loss: 0.116\n",
      "Training: Epoch 95, Batch 52, Loss: 0.1\n",
      "Training: Epoch 95, Batch 53, Loss: 0.072\n",
      "Training: Epoch 95, Batch 54, Loss: 0.098\n",
      "Training: Epoch 95, Batch 55, Loss: 0.093\n",
      "Training: Epoch 95, Batch 56, Loss: 0.087\n",
      "Training: Epoch 95, Batch 57, Loss: 0.094\n",
      "Training: Epoch 95, Batch 58, Loss: 0.081\n",
      "Training: Epoch 95, Batch 59, Loss: 0.089\n",
      "Val: Epoch 95, Loss: 0.225\n",
      "Training: Epoch 96, Batch 0, Loss: 0.105\n",
      "Training: Epoch 96, Batch 1, Loss: 0.099\n",
      "Training: Epoch 96, Batch 2, Loss: 0.099\n",
      "Training: Epoch 96, Batch 3, Loss: 0.085\n",
      "Training: Epoch 96, Batch 4, Loss: 0.101\n",
      "Training: Epoch 96, Batch 5, Loss: 0.1\n",
      "Training: Epoch 96, Batch 6, Loss: 0.088\n",
      "Training: Epoch 96, Batch 7, Loss: 0.095\n",
      "Training: Epoch 96, Batch 8, Loss: 0.093\n",
      "Training: Epoch 96, Batch 9, Loss: 0.084\n",
      "Training: Epoch 96, Batch 10, Loss: 0.082\n",
      "Training: Epoch 96, Batch 11, Loss: 0.088\n",
      "Training: Epoch 96, Batch 12, Loss: 0.074\n",
      "Training: Epoch 96, Batch 13, Loss: 0.079\n",
      "Training: Epoch 96, Batch 14, Loss: 0.061\n",
      "Training: Epoch 96, Batch 15, Loss: 0.081\n",
      "Training: Epoch 96, Batch 16, Loss: 0.087\n",
      "Training: Epoch 96, Batch 17, Loss: 0.101\n",
      "Training: Epoch 96, Batch 18, Loss: 0.08\n",
      "Training: Epoch 96, Batch 19, Loss: 0.085\n",
      "Training: Epoch 96, Batch 20, Loss: 0.127\n",
      "Training: Epoch 96, Batch 21, Loss: 0.104\n",
      "Training: Epoch 96, Batch 22, Loss: 0.076\n",
      "Training: Epoch 96, Batch 23, Loss: 0.087\n",
      "Training: Epoch 96, Batch 24, Loss: 0.09\n",
      "Training: Epoch 96, Batch 25, Loss: 0.084\n",
      "Training: Epoch 96, Batch 26, Loss: 0.096\n",
      "Training: Epoch 96, Batch 27, Loss: 0.097\n",
      "Training: Epoch 96, Batch 28, Loss: 0.109\n",
      "Training: Epoch 96, Batch 29, Loss: 0.087\n",
      "Training: Epoch 96, Batch 30, Loss: 0.086\n",
      "Training: Epoch 96, Batch 31, Loss: 0.102\n",
      "Training: Epoch 96, Batch 32, Loss: 0.113\n",
      "Training: Epoch 96, Batch 33, Loss: 0.095\n",
      "Training: Epoch 96, Batch 34, Loss: 0.091\n",
      "Training: Epoch 96, Batch 35, Loss: 0.086\n",
      "Training: Epoch 96, Batch 36, Loss: 0.09\n",
      "Training: Epoch 96, Batch 37, Loss: 0.11\n",
      "Training: Epoch 96, Batch 38, Loss: 0.096\n",
      "Training: Epoch 96, Batch 39, Loss: 0.09\n",
      "Training: Epoch 96, Batch 40, Loss: 0.09\n",
      "Training: Epoch 96, Batch 41, Loss: 0.075\n",
      "Training: Epoch 96, Batch 42, Loss: 0.105\n",
      "Training: Epoch 96, Batch 43, Loss: 0.097\n",
      "Training: Epoch 96, Batch 44, Loss: 0.071\n",
      "Training: Epoch 96, Batch 45, Loss: 0.086\n",
      "Training: Epoch 96, Batch 46, Loss: 0.078\n",
      "Training: Epoch 96, Batch 47, Loss: 0.084\n",
      "Training: Epoch 96, Batch 48, Loss: 0.083\n",
      "Training: Epoch 96, Batch 49, Loss: 0.067\n",
      "Training: Epoch 96, Batch 50, Loss: 0.089\n",
      "Training: Epoch 96, Batch 51, Loss: 0.086\n",
      "Training: Epoch 96, Batch 52, Loss: 0.089\n",
      "Training: Epoch 96, Batch 53, Loss: 0.099\n",
      "Training: Epoch 96, Batch 54, Loss: 0.107\n",
      "Training: Epoch 96, Batch 55, Loss: 0.063\n",
      "Training: Epoch 96, Batch 56, Loss: 0.09\n",
      "Training: Epoch 96, Batch 57, Loss: 0.058\n",
      "Training: Epoch 96, Batch 58, Loss: 0.081\n",
      "Training: Epoch 96, Batch 59, Loss: 0.083\n",
      "Val: Epoch 96, Loss: 0.244\n",
      "Training: Epoch 97, Batch 0, Loss: 0.094\n",
      "Training: Epoch 97, Batch 1, Loss: 0.081\n",
      "Training: Epoch 97, Batch 2, Loss: 0.095\n",
      "Training: Epoch 97, Batch 3, Loss: 0.105\n",
      "Training: Epoch 97, Batch 4, Loss: 0.082\n",
      "Training: Epoch 97, Batch 5, Loss: 0.085\n",
      "Training: Epoch 97, Batch 6, Loss: 0.105\n",
      "Training: Epoch 97, Batch 7, Loss: 0.101\n",
      "Training: Epoch 97, Batch 8, Loss: 0.071\n",
      "Training: Epoch 97, Batch 9, Loss: 0.095\n",
      "Training: Epoch 97, Batch 10, Loss: 0.091\n",
      "Training: Epoch 97, Batch 11, Loss: 0.086\n",
      "Training: Epoch 97, Batch 12, Loss: 0.115\n",
      "Training: Epoch 97, Batch 13, Loss: 0.088\n",
      "Training: Epoch 97, Batch 14, Loss: 0.084\n",
      "Training: Epoch 97, Batch 15, Loss: 0.069\n",
      "Training: Epoch 97, Batch 16, Loss: 0.087\n",
      "Training: Epoch 97, Batch 17, Loss: 0.084\n",
      "Training: Epoch 97, Batch 18, Loss: 0.076\n",
      "Training: Epoch 97, Batch 19, Loss: 0.086\n",
      "Training: Epoch 97, Batch 20, Loss: 0.081\n",
      "Training: Epoch 97, Batch 21, Loss: 0.097\n",
      "Training: Epoch 97, Batch 22, Loss: 0.07\n",
      "Training: Epoch 97, Batch 23, Loss: 0.088\n",
      "Training: Epoch 97, Batch 24, Loss: 0.07\n",
      "Training: Epoch 97, Batch 25, Loss: 0.084\n",
      "Training: Epoch 97, Batch 26, Loss: 0.081\n",
      "Training: Epoch 97, Batch 27, Loss: 0.085\n",
      "Training: Epoch 97, Batch 28, Loss: 0.094\n",
      "Training: Epoch 97, Batch 29, Loss: 0.075\n",
      "Training: Epoch 97, Batch 30, Loss: 0.081\n",
      "Training: Epoch 97, Batch 31, Loss: 0.096\n",
      "Training: Epoch 97, Batch 32, Loss: 0.087\n",
      "Training: Epoch 97, Batch 33, Loss: 0.094\n",
      "Training: Epoch 97, Batch 34, Loss: 0.082\n",
      "Training: Epoch 97, Batch 35, Loss: 0.083\n",
      "Training: Epoch 97, Batch 36, Loss: 0.086\n",
      "Training: Epoch 97, Batch 37, Loss: 0.095\n",
      "Training: Epoch 97, Batch 38, Loss: 0.086\n",
      "Training: Epoch 97, Batch 39, Loss: 0.098\n",
      "Training: Epoch 97, Batch 40, Loss: 0.073\n",
      "Training: Epoch 97, Batch 41, Loss: 0.079\n",
      "Training: Epoch 97, Batch 42, Loss: 0.071\n",
      "Training: Epoch 97, Batch 43, Loss: 0.076\n",
      "Training: Epoch 97, Batch 44, Loss: 0.091\n",
      "Training: Epoch 97, Batch 45, Loss: 0.094\n",
      "Training: Epoch 97, Batch 46, Loss: 0.1\n",
      "Training: Epoch 97, Batch 47, Loss: 0.084\n",
      "Training: Epoch 97, Batch 48, Loss: 0.094\n",
      "Training: Epoch 97, Batch 49, Loss: 0.094\n",
      "Training: Epoch 97, Batch 50, Loss: 0.084\n",
      "Training: Epoch 97, Batch 51, Loss: 0.073\n",
      "Training: Epoch 97, Batch 52, Loss: 0.076\n",
      "Training: Epoch 97, Batch 53, Loss: 0.073\n",
      "Training: Epoch 97, Batch 54, Loss: 0.071\n",
      "Training: Epoch 97, Batch 55, Loss: 0.08\n",
      "Training: Epoch 97, Batch 56, Loss: 0.114\n",
      "Training: Epoch 97, Batch 57, Loss: 0.089\n",
      "Training: Epoch 97, Batch 58, Loss: 0.082\n",
      "Training: Epoch 97, Batch 59, Loss: 0.07\n",
      "Val: Epoch 97, Loss: 0.237\n",
      "Training: Epoch 98, Batch 0, Loss: 0.084\n",
      "Training: Epoch 98, Batch 1, Loss: 0.078\n",
      "Training: Epoch 98, Batch 2, Loss: 0.08\n",
      "Training: Epoch 98, Batch 3, Loss: 0.098\n",
      "Training: Epoch 98, Batch 4, Loss: 0.075\n",
      "Training: Epoch 98, Batch 5, Loss: 0.081\n",
      "Training: Epoch 98, Batch 6, Loss: 0.088\n",
      "Training: Epoch 98, Batch 7, Loss: 0.082\n",
      "Training: Epoch 98, Batch 8, Loss: 0.102\n",
      "Training: Epoch 98, Batch 9, Loss: 0.081\n",
      "Training: Epoch 98, Batch 10, Loss: 0.079\n",
      "Training: Epoch 98, Batch 11, Loss: 0.076\n",
      "Training: Epoch 98, Batch 12, Loss: 0.067\n",
      "Training: Epoch 98, Batch 13, Loss: 0.089\n",
      "Training: Epoch 98, Batch 14, Loss: 0.081\n",
      "Training: Epoch 98, Batch 15, Loss: 0.073\n",
      "Training: Epoch 98, Batch 16, Loss: 0.099\n",
      "Training: Epoch 98, Batch 17, Loss: 0.088\n",
      "Training: Epoch 98, Batch 18, Loss: 0.079\n",
      "Training: Epoch 98, Batch 19, Loss: 0.104\n",
      "Training: Epoch 98, Batch 20, Loss: 0.087\n",
      "Training: Epoch 98, Batch 21, Loss: 0.097\n",
      "Training: Epoch 98, Batch 22, Loss: 0.077\n",
      "Training: Epoch 98, Batch 23, Loss: 0.067\n",
      "Training: Epoch 98, Batch 24, Loss: 0.081\n",
      "Training: Epoch 98, Batch 25, Loss: 0.092\n",
      "Training: Epoch 98, Batch 26, Loss: 0.098\n",
      "Training: Epoch 98, Batch 27, Loss: 0.08\n",
      "Training: Epoch 98, Batch 28, Loss: 0.096\n",
      "Training: Epoch 98, Batch 29, Loss: 0.103\n",
      "Training: Epoch 98, Batch 30, Loss: 0.082\n",
      "Training: Epoch 98, Batch 31, Loss: 0.07\n",
      "Training: Epoch 98, Batch 32, Loss: 0.083\n",
      "Training: Epoch 98, Batch 33, Loss: 0.097\n",
      "Training: Epoch 98, Batch 34, Loss: 0.073\n",
      "Training: Epoch 98, Batch 35, Loss: 0.089\n",
      "Training: Epoch 98, Batch 36, Loss: 0.101\n",
      "Training: Epoch 98, Batch 37, Loss: 0.091\n",
      "Training: Epoch 98, Batch 38, Loss: 0.078\n",
      "Training: Epoch 98, Batch 39, Loss: 0.097\n",
      "Training: Epoch 98, Batch 40, Loss: 0.081\n",
      "Training: Epoch 98, Batch 41, Loss: 0.09\n",
      "Training: Epoch 98, Batch 42, Loss: 0.087\n",
      "Training: Epoch 98, Batch 43, Loss: 0.079\n",
      "Training: Epoch 98, Batch 44, Loss: 0.096\n",
      "Training: Epoch 98, Batch 45, Loss: 0.084\n",
      "Training: Epoch 98, Batch 46, Loss: 0.077\n",
      "Training: Epoch 98, Batch 47, Loss: 0.088\n",
      "Training: Epoch 98, Batch 48, Loss: 0.075\n",
      "Training: Epoch 98, Batch 49, Loss: 0.08\n",
      "Training: Epoch 98, Batch 50, Loss: 0.091\n",
      "Training: Epoch 98, Batch 51, Loss: 0.082\n",
      "Training: Epoch 98, Batch 52, Loss: 0.091\n",
      "Training: Epoch 98, Batch 53, Loss: 0.111\n",
      "Training: Epoch 98, Batch 54, Loss: 0.081\n",
      "Training: Epoch 98, Batch 55, Loss: 0.074\n",
      "Training: Epoch 98, Batch 56, Loss: 0.068\n",
      "Training: Epoch 98, Batch 57, Loss: 0.087\n",
      "Training: Epoch 98, Batch 58, Loss: 0.061\n",
      "Training: Epoch 98, Batch 59, Loss: 0.068\n",
      "Val: Epoch 98, Loss: 0.241\n",
      "Training: Epoch 99, Batch 0, Loss: 0.076\n",
      "Training: Epoch 99, Batch 1, Loss: 0.066\n",
      "Training: Epoch 99, Batch 2, Loss: 0.086\n",
      "Training: Epoch 99, Batch 3, Loss: 0.098\n",
      "Training: Epoch 99, Batch 4, Loss: 0.073\n",
      "Training: Epoch 99, Batch 5, Loss: 0.063\n",
      "Training: Epoch 99, Batch 6, Loss: 0.096\n",
      "Training: Epoch 99, Batch 7, Loss: 0.101\n",
      "Training: Epoch 99, Batch 8, Loss: 0.074\n",
      "Training: Epoch 99, Batch 9, Loss: 0.079\n",
      "Training: Epoch 99, Batch 10, Loss: 0.113\n",
      "Training: Epoch 99, Batch 11, Loss: 0.089\n",
      "Training: Epoch 99, Batch 12, Loss: 0.07\n",
      "Training: Epoch 99, Batch 13, Loss: 0.081\n",
      "Training: Epoch 99, Batch 14, Loss: 0.074\n",
      "Training: Epoch 99, Batch 15, Loss: 0.07\n",
      "Training: Epoch 99, Batch 16, Loss: 0.091\n",
      "Training: Epoch 99, Batch 17, Loss: 0.083\n",
      "Training: Epoch 99, Batch 18, Loss: 0.103\n",
      "Training: Epoch 99, Batch 19, Loss: 0.088\n",
      "Training: Epoch 99, Batch 20, Loss: 0.094\n",
      "Training: Epoch 99, Batch 21, Loss: 0.071\n",
      "Training: Epoch 99, Batch 22, Loss: 0.078\n",
      "Training: Epoch 99, Batch 23, Loss: 0.1\n",
      "Training: Epoch 99, Batch 24, Loss: 0.077\n",
      "Training: Epoch 99, Batch 25, Loss: 0.075\n",
      "Training: Epoch 99, Batch 26, Loss: 0.069\n",
      "Training: Epoch 99, Batch 27, Loss: 0.094\n",
      "Training: Epoch 99, Batch 28, Loss: 0.088\n",
      "Training: Epoch 99, Batch 29, Loss: 0.104\n",
      "Training: Epoch 99, Batch 30, Loss: 0.086\n",
      "Training: Epoch 99, Batch 31, Loss: 0.084\n",
      "Training: Epoch 99, Batch 32, Loss: 0.087\n",
      "Training: Epoch 99, Batch 33, Loss: 0.072\n",
      "Training: Epoch 99, Batch 34, Loss: 0.084\n",
      "Training: Epoch 99, Batch 35, Loss: 0.093\n",
      "Training: Epoch 99, Batch 36, Loss: 0.074\n",
      "Training: Epoch 99, Batch 37, Loss: 0.088\n",
      "Training: Epoch 99, Batch 38, Loss: 0.079\n",
      "Training: Epoch 99, Batch 39, Loss: 0.074\n",
      "Training: Epoch 99, Batch 40, Loss: 0.074\n",
      "Training: Epoch 99, Batch 41, Loss: 0.068\n",
      "Training: Epoch 99, Batch 42, Loss: 0.093\n",
      "Training: Epoch 99, Batch 43, Loss: 0.096\n",
      "Training: Epoch 99, Batch 44, Loss: 0.086\n",
      "Training: Epoch 99, Batch 45, Loss: 0.115\n",
      "Training: Epoch 99, Batch 46, Loss: 0.096\n",
      "Training: Epoch 99, Batch 47, Loss: 0.086\n",
      "Training: Epoch 99, Batch 48, Loss: 0.09\n",
      "Training: Epoch 99, Batch 49, Loss: 0.083\n",
      "Training: Epoch 99, Batch 50, Loss: 0.094\n",
      "Training: Epoch 99, Batch 51, Loss: 0.094\n",
      "Training: Epoch 99, Batch 52, Loss: 0.102\n",
      "Training: Epoch 99, Batch 53, Loss: 0.087\n",
      "Training: Epoch 99, Batch 54, Loss: 0.081\n",
      "Training: Epoch 99, Batch 55, Loss: 0.072\n",
      "Training: Epoch 99, Batch 56, Loss: 0.108\n",
      "Training: Epoch 99, Batch 57, Loss: 0.074\n",
      "Training: Epoch 99, Batch 58, Loss: 0.082\n",
      "Training: Epoch 99, Batch 59, Loss: 0.088\n",
      "Val: Epoch 99, Loss: 0.231\n",
      "Training: Epoch 100, Batch 0, Loss: 0.083\n",
      "Training: Epoch 100, Batch 1, Loss: 0.091\n",
      "Training: Epoch 100, Batch 2, Loss: 0.075\n",
      "Training: Epoch 100, Batch 3, Loss: 0.09\n",
      "Training: Epoch 100, Batch 4, Loss: 0.098\n",
      "Training: Epoch 100, Batch 5, Loss: 0.098\n",
      "Training: Epoch 100, Batch 6, Loss: 0.081\n",
      "Training: Epoch 100, Batch 7, Loss: 0.079\n",
      "Training: Epoch 100, Batch 8, Loss: 0.097\n",
      "Training: Epoch 100, Batch 9, Loss: 0.084\n",
      "Training: Epoch 100, Batch 10, Loss: 0.078\n",
      "Training: Epoch 100, Batch 11, Loss: 0.094\n",
      "Training: Epoch 100, Batch 12, Loss: 0.073\n",
      "Training: Epoch 100, Batch 13, Loss: 0.083\n",
      "Training: Epoch 100, Batch 14, Loss: 0.089\n",
      "Training: Epoch 100, Batch 15, Loss: 0.07\n",
      "Training: Epoch 100, Batch 16, Loss: 0.077\n",
      "Training: Epoch 100, Batch 17, Loss: 0.078\n",
      "Training: Epoch 100, Batch 18, Loss: 0.079\n",
      "Training: Epoch 100, Batch 19, Loss: 0.094\n",
      "Training: Epoch 100, Batch 20, Loss: 0.077\n",
      "Training: Epoch 100, Batch 21, Loss: 0.077\n",
      "Training: Epoch 100, Batch 22, Loss: 0.084\n",
      "Training: Epoch 100, Batch 23, Loss: 0.1\n",
      "Training: Epoch 100, Batch 24, Loss: 0.09\n",
      "Training: Epoch 100, Batch 25, Loss: 0.102\n",
      "Training: Epoch 100, Batch 26, Loss: 0.08\n",
      "Training: Epoch 100, Batch 27, Loss: 0.069\n",
      "Training: Epoch 100, Batch 28, Loss: 0.083\n",
      "Training: Epoch 100, Batch 29, Loss: 0.073\n",
      "Training: Epoch 100, Batch 30, Loss: 0.093\n",
      "Training: Epoch 100, Batch 31, Loss: 0.087\n",
      "Training: Epoch 100, Batch 32, Loss: 0.081\n",
      "Training: Epoch 100, Batch 33, Loss: 0.092\n",
      "Training: Epoch 100, Batch 34, Loss: 0.087\n",
      "Training: Epoch 100, Batch 35, Loss: 0.088\n",
      "Training: Epoch 100, Batch 36, Loss: 0.074\n",
      "Training: Epoch 100, Batch 37, Loss: 0.091\n",
      "Training: Epoch 100, Batch 38, Loss: 0.065\n",
      "Training: Epoch 100, Batch 39, Loss: 0.112\n",
      "Training: Epoch 100, Batch 40, Loss: 0.082\n",
      "Training: Epoch 100, Batch 41, Loss: 0.088\n",
      "Training: Epoch 100, Batch 42, Loss: 0.076\n",
      "Training: Epoch 100, Batch 43, Loss: 0.081\n",
      "Training: Epoch 100, Batch 44, Loss: 0.09\n",
      "Training: Epoch 100, Batch 45, Loss: 0.077\n",
      "Training: Epoch 100, Batch 46, Loss: 0.08\n",
      "Training: Epoch 100, Batch 47, Loss: 0.07\n",
      "Training: Epoch 100, Batch 48, Loss: 0.089\n",
      "Training: Epoch 100, Batch 49, Loss: 0.087\n",
      "Training: Epoch 100, Batch 50, Loss: 0.095\n",
      "Training: Epoch 100, Batch 51, Loss: 0.108\n",
      "Training: Epoch 100, Batch 52, Loss: 0.077\n",
      "Training: Epoch 100, Batch 53, Loss: 0.087\n",
      "Training: Epoch 100, Batch 54, Loss: 0.073\n",
      "Training: Epoch 100, Batch 55, Loss: 0.086\n",
      "Training: Epoch 100, Batch 56, Loss: 0.071\n",
      "Training: Epoch 100, Batch 57, Loss: 0.115\n",
      "Training: Epoch 100, Batch 58, Loss: 0.074\n",
      "Training: Epoch 100, Batch 59, Loss: 0.079\n",
      "Val: Epoch 100, Loss: 0.266\n",
      "Training: Epoch 101, Batch 0, Loss: 0.063\n",
      "Training: Epoch 101, Batch 1, Loss: 0.107\n",
      "Training: Epoch 101, Batch 2, Loss: 0.081\n",
      "Training: Epoch 101, Batch 3, Loss: 0.075\n",
      "Training: Epoch 101, Batch 4, Loss: 0.07\n",
      "Training: Epoch 101, Batch 5, Loss: 0.091\n",
      "Training: Epoch 101, Batch 6, Loss: 0.091\n",
      "Training: Epoch 101, Batch 7, Loss: 0.082\n",
      "Training: Epoch 101, Batch 8, Loss: 0.081\n",
      "Training: Epoch 101, Batch 9, Loss: 0.096\n",
      "Training: Epoch 101, Batch 10, Loss: 0.081\n",
      "Training: Epoch 101, Batch 11, Loss: 0.084\n",
      "Training: Epoch 101, Batch 12, Loss: 0.077\n",
      "Training: Epoch 101, Batch 13, Loss: 0.077\n",
      "Training: Epoch 101, Batch 14, Loss: 0.099\n",
      "Training: Epoch 101, Batch 15, Loss: 0.095\n",
      "Training: Epoch 101, Batch 16, Loss: 0.106\n",
      "Training: Epoch 101, Batch 17, Loss: 0.084\n",
      "Training: Epoch 101, Batch 18, Loss: 0.09\n",
      "Training: Epoch 101, Batch 19, Loss: 0.073\n",
      "Training: Epoch 101, Batch 20, Loss: 0.082\n",
      "Training: Epoch 101, Batch 21, Loss: 0.077\n",
      "Training: Epoch 101, Batch 22, Loss: 0.08\n",
      "Training: Epoch 101, Batch 23, Loss: 0.088\n",
      "Training: Epoch 101, Batch 24, Loss: 0.078\n",
      "Training: Epoch 101, Batch 25, Loss: 0.072\n",
      "Training: Epoch 101, Batch 26, Loss: 0.069\n",
      "Training: Epoch 101, Batch 27, Loss: 0.079\n",
      "Training: Epoch 101, Batch 28, Loss: 0.09\n",
      "Training: Epoch 101, Batch 29, Loss: 0.1\n",
      "Training: Epoch 101, Batch 30, Loss: 0.099\n",
      "Training: Epoch 101, Batch 31, Loss: 0.079\n",
      "Training: Epoch 101, Batch 32, Loss: 0.084\n",
      "Training: Epoch 101, Batch 33, Loss: 0.089\n",
      "Training: Epoch 101, Batch 34, Loss: 0.106\n",
      "Training: Epoch 101, Batch 35, Loss: 0.093\n",
      "Training: Epoch 101, Batch 36, Loss: 0.068\n",
      "Training: Epoch 101, Batch 37, Loss: 0.073\n",
      "Training: Epoch 101, Batch 38, Loss: 0.069\n",
      "Training: Epoch 101, Batch 39, Loss: 0.079\n",
      "Training: Epoch 101, Batch 40, Loss: 0.097\n",
      "Training: Epoch 101, Batch 41, Loss: 0.081\n",
      "Training: Epoch 101, Batch 42, Loss: 0.081\n",
      "Training: Epoch 101, Batch 43, Loss: 0.086\n",
      "Training: Epoch 101, Batch 44, Loss: 0.082\n",
      "Training: Epoch 101, Batch 45, Loss: 0.075\n",
      "Training: Epoch 101, Batch 46, Loss: 0.087\n",
      "Training: Epoch 101, Batch 47, Loss: 0.075\n",
      "Training: Epoch 101, Batch 48, Loss: 0.086\n",
      "Training: Epoch 101, Batch 49, Loss: 0.084\n",
      "Training: Epoch 101, Batch 50, Loss: 0.08\n",
      "Training: Epoch 101, Batch 51, Loss: 0.098\n",
      "Training: Epoch 101, Batch 52, Loss: 0.073\n",
      "Training: Epoch 101, Batch 53, Loss: 0.099\n",
      "Training: Epoch 101, Batch 54, Loss: 0.09\n",
      "Training: Epoch 101, Batch 55, Loss: 0.074\n",
      "Training: Epoch 101, Batch 56, Loss: 0.087\n",
      "Training: Epoch 101, Batch 57, Loss: 0.083\n",
      "Training: Epoch 101, Batch 58, Loss: 0.076\n",
      "Training: Epoch 101, Batch 59, Loss: 0.118\n",
      "Val: Epoch 101, Loss: 0.242\n",
      "Training: Epoch 102, Batch 0, Loss: 0.085\n",
      "Training: Epoch 102, Batch 1, Loss: 0.083\n",
      "Training: Epoch 102, Batch 2, Loss: 0.086\n",
      "Training: Epoch 102, Batch 3, Loss: 0.11\n",
      "Training: Epoch 102, Batch 4, Loss: 0.075\n",
      "Training: Epoch 102, Batch 5, Loss: 0.098\n",
      "Training: Epoch 102, Batch 6, Loss: 0.082\n",
      "Training: Epoch 102, Batch 7, Loss: 0.087\n",
      "Training: Epoch 102, Batch 8, Loss: 0.117\n",
      "Training: Epoch 102, Batch 9, Loss: 0.093\n",
      "Training: Epoch 102, Batch 10, Loss: 0.121\n",
      "Training: Epoch 102, Batch 11, Loss: 0.096\n",
      "Training: Epoch 102, Batch 12, Loss: 0.095\n",
      "Training: Epoch 102, Batch 13, Loss: 0.084\n",
      "Training: Epoch 102, Batch 14, Loss: 0.078\n",
      "Training: Epoch 102, Batch 15, Loss: 0.08\n",
      "Training: Epoch 102, Batch 16, Loss: 0.087\n",
      "Training: Epoch 102, Batch 17, Loss: 0.064\n",
      "Training: Epoch 102, Batch 18, Loss: 0.073\n",
      "Training: Epoch 102, Batch 19, Loss: 0.077\n",
      "Training: Epoch 102, Batch 20, Loss: 0.092\n",
      "Training: Epoch 102, Batch 21, Loss: 0.089\n",
      "Training: Epoch 102, Batch 22, Loss: 0.112\n",
      "Training: Epoch 102, Batch 23, Loss: 0.094\n",
      "Training: Epoch 102, Batch 24, Loss: 0.074\n",
      "Training: Epoch 102, Batch 25, Loss: 0.081\n",
      "Training: Epoch 102, Batch 26, Loss: 0.085\n",
      "Training: Epoch 102, Batch 27, Loss: 0.08\n",
      "Training: Epoch 102, Batch 28, Loss: 0.082\n",
      "Training: Epoch 102, Batch 29, Loss: 0.085\n",
      "Training: Epoch 102, Batch 30, Loss: 0.084\n",
      "Training: Epoch 102, Batch 31, Loss: 0.092\n",
      "Training: Epoch 102, Batch 32, Loss: 0.079\n",
      "Training: Epoch 102, Batch 33, Loss: 0.101\n",
      "Training: Epoch 102, Batch 34, Loss: 0.095\n",
      "Training: Epoch 102, Batch 35, Loss: 0.083\n",
      "Training: Epoch 102, Batch 36, Loss: 0.092\n",
      "Training: Epoch 102, Batch 37, Loss: 0.092\n",
      "Training: Epoch 102, Batch 38, Loss: 0.083\n",
      "Training: Epoch 102, Batch 39, Loss: 0.077\n",
      "Training: Epoch 102, Batch 40, Loss: 0.068\n",
      "Training: Epoch 102, Batch 41, Loss: 0.075\n",
      "Training: Epoch 102, Batch 42, Loss: 0.086\n",
      "Training: Epoch 102, Batch 43, Loss: 0.071\n",
      "Training: Epoch 102, Batch 44, Loss: 0.075\n",
      "Training: Epoch 102, Batch 45, Loss: 0.088\n",
      "Training: Epoch 102, Batch 46, Loss: 0.091\n",
      "Training: Epoch 102, Batch 47, Loss: 0.099\n",
      "Training: Epoch 102, Batch 48, Loss: 0.091\n",
      "Training: Epoch 102, Batch 49, Loss: 0.084\n",
      "Training: Epoch 102, Batch 50, Loss: 0.08\n",
      "Training: Epoch 102, Batch 51, Loss: 0.079\n",
      "Training: Epoch 102, Batch 52, Loss: 0.07\n",
      "Training: Epoch 102, Batch 53, Loss: 0.075\n",
      "Training: Epoch 102, Batch 54, Loss: 0.099\n",
      "Training: Epoch 102, Batch 55, Loss: 0.065\n",
      "Training: Epoch 102, Batch 56, Loss: 0.084\n",
      "Training: Epoch 102, Batch 57, Loss: 0.078\n",
      "Training: Epoch 102, Batch 58, Loss: 0.077\n",
      "Training: Epoch 102, Batch 59, Loss: 0.071\n",
      "Val: Epoch 102, Loss: 0.241\n",
      "Training: Epoch 103, Batch 0, Loss: 0.094\n",
      "Training: Epoch 103, Batch 1, Loss: 0.091\n",
      "Training: Epoch 103, Batch 2, Loss: 0.09\n",
      "Training: Epoch 103, Batch 3, Loss: 0.083\n",
      "Training: Epoch 103, Batch 4, Loss: 0.1\n",
      "Training: Epoch 103, Batch 5, Loss: 0.067\n",
      "Training: Epoch 103, Batch 6, Loss: 0.11\n",
      "Training: Epoch 103, Batch 7, Loss: 0.079\n",
      "Training: Epoch 103, Batch 8, Loss: 0.081\n",
      "Training: Epoch 103, Batch 9, Loss: 0.078\n",
      "Training: Epoch 103, Batch 10, Loss: 0.083\n",
      "Training: Epoch 103, Batch 11, Loss: 0.076\n",
      "Training: Epoch 103, Batch 12, Loss: 0.077\n",
      "Training: Epoch 103, Batch 13, Loss: 0.076\n",
      "Training: Epoch 103, Batch 14, Loss: 0.076\n",
      "Training: Epoch 103, Batch 15, Loss: 0.087\n",
      "Training: Epoch 103, Batch 16, Loss: 0.079\n",
      "Training: Epoch 103, Batch 17, Loss: 0.062\n",
      "Training: Epoch 103, Batch 18, Loss: 0.073\n",
      "Training: Epoch 103, Batch 19, Loss: 0.11\n",
      "Training: Epoch 103, Batch 20, Loss: 0.081\n",
      "Training: Epoch 103, Batch 21, Loss: 0.072\n",
      "Training: Epoch 103, Batch 22, Loss: 0.095\n",
      "Training: Epoch 103, Batch 23, Loss: 0.084\n",
      "Training: Epoch 103, Batch 24, Loss: 0.071\n",
      "Training: Epoch 103, Batch 25, Loss: 0.091\n",
      "Training: Epoch 103, Batch 26, Loss: 0.073\n",
      "Training: Epoch 103, Batch 27, Loss: 0.084\n",
      "Training: Epoch 103, Batch 28, Loss: 0.084\n",
      "Training: Epoch 103, Batch 29, Loss: 0.098\n",
      "Training: Epoch 103, Batch 30, Loss: 0.104\n",
      "Training: Epoch 103, Batch 31, Loss: 0.087\n",
      "Training: Epoch 103, Batch 32, Loss: 0.069\n",
      "Training: Epoch 103, Batch 33, Loss: 0.101\n",
      "Training: Epoch 103, Batch 34, Loss: 0.08\n",
      "Training: Epoch 103, Batch 35, Loss: 0.073\n",
      "Training: Epoch 103, Batch 36, Loss: 0.077\n",
      "Training: Epoch 103, Batch 37, Loss: 0.074\n",
      "Training: Epoch 103, Batch 38, Loss: 0.08\n",
      "Training: Epoch 103, Batch 39, Loss: 0.071\n",
      "Training: Epoch 103, Batch 40, Loss: 0.072\n",
      "Training: Epoch 103, Batch 41, Loss: 0.081\n",
      "Training: Epoch 103, Batch 42, Loss: 0.085\n",
      "Training: Epoch 103, Batch 43, Loss: 0.062\n",
      "Training: Epoch 103, Batch 44, Loss: 0.08\n",
      "Training: Epoch 103, Batch 45, Loss: 0.086\n",
      "Training: Epoch 103, Batch 46, Loss: 0.1\n",
      "Training: Epoch 103, Batch 47, Loss: 0.091\n",
      "Training: Epoch 103, Batch 48, Loss: 0.074\n",
      "Training: Epoch 103, Batch 49, Loss: 0.091\n",
      "Training: Epoch 103, Batch 50, Loss: 0.088\n",
      "Training: Epoch 103, Batch 51, Loss: 0.081\n",
      "Training: Epoch 103, Batch 52, Loss: 0.081\n",
      "Training: Epoch 103, Batch 53, Loss: 0.085\n",
      "Training: Epoch 103, Batch 54, Loss: 0.09\n",
      "Training: Epoch 103, Batch 55, Loss: 0.086\n",
      "Training: Epoch 103, Batch 56, Loss: 0.087\n",
      "Training: Epoch 103, Batch 57, Loss: 0.08\n",
      "Training: Epoch 103, Batch 58, Loss: 0.077\n",
      "Training: Epoch 103, Batch 59, Loss: 0.077\n",
      "Val: Epoch 103, Loss: 0.273\n",
      "Training: Epoch 104, Batch 0, Loss: 0.086\n",
      "Training: Epoch 104, Batch 1, Loss: 0.084\n",
      "Training: Epoch 104, Batch 2, Loss: 0.071\n",
      "Training: Epoch 104, Batch 3, Loss: 0.093\n",
      "Training: Epoch 104, Batch 4, Loss: 0.07\n",
      "Training: Epoch 104, Batch 5, Loss: 0.087\n",
      "Training: Epoch 104, Batch 6, Loss: 0.094\n",
      "Training: Epoch 104, Batch 7, Loss: 0.092\n",
      "Training: Epoch 104, Batch 8, Loss: 0.078\n",
      "Training: Epoch 104, Batch 9, Loss: 0.09\n",
      "Training: Epoch 104, Batch 10, Loss: 0.083\n",
      "Training: Epoch 104, Batch 11, Loss: 0.071\n",
      "Training: Epoch 104, Batch 12, Loss: 0.088\n",
      "Training: Epoch 104, Batch 13, Loss: 0.082\n",
      "Training: Epoch 104, Batch 14, Loss: 0.096\n",
      "Training: Epoch 104, Batch 15, Loss: 0.085\n",
      "Training: Epoch 104, Batch 16, Loss: 0.081\n",
      "Training: Epoch 104, Batch 17, Loss: 0.07\n",
      "Training: Epoch 104, Batch 18, Loss: 0.078\n",
      "Training: Epoch 104, Batch 19, Loss: 0.064\n",
      "Training: Epoch 104, Batch 20, Loss: 0.075\n",
      "Training: Epoch 104, Batch 21, Loss: 0.12\n",
      "Training: Epoch 104, Batch 22, Loss: 0.082\n",
      "Training: Epoch 104, Batch 23, Loss: 0.104\n",
      "Training: Epoch 104, Batch 24, Loss: 0.079\n",
      "Training: Epoch 104, Batch 25, Loss: 0.088\n",
      "Training: Epoch 104, Batch 26, Loss: 0.091\n",
      "Training: Epoch 104, Batch 27, Loss: 0.082\n",
      "Training: Epoch 104, Batch 28, Loss: 0.096\n",
      "Training: Epoch 104, Batch 29, Loss: 0.079\n",
      "Training: Epoch 104, Batch 30, Loss: 0.079\n",
      "Training: Epoch 104, Batch 31, Loss: 0.109\n",
      "Training: Epoch 104, Batch 32, Loss: 0.091\n",
      "Training: Epoch 104, Batch 33, Loss: 0.091\n",
      "Training: Epoch 104, Batch 34, Loss: 0.088\n",
      "Training: Epoch 104, Batch 35, Loss: 0.108\n",
      "Training: Epoch 104, Batch 36, Loss: 0.066\n",
      "Training: Epoch 104, Batch 37, Loss: 0.077\n",
      "Training: Epoch 104, Batch 38, Loss: 0.087\n",
      "Training: Epoch 104, Batch 39, Loss: 0.07\n",
      "Training: Epoch 104, Batch 40, Loss: 0.097\n",
      "Training: Epoch 104, Batch 41, Loss: 0.082\n",
      "Training: Epoch 104, Batch 42, Loss: 0.086\n",
      "Training: Epoch 104, Batch 43, Loss: 0.078\n",
      "Training: Epoch 104, Batch 44, Loss: 0.089\n",
      "Training: Epoch 104, Batch 45, Loss: 0.067\n",
      "Training: Epoch 104, Batch 46, Loss: 0.075\n",
      "Training: Epoch 104, Batch 47, Loss: 0.076\n",
      "Training: Epoch 104, Batch 48, Loss: 0.067\n",
      "Training: Epoch 104, Batch 49, Loss: 0.076\n",
      "Training: Epoch 104, Batch 50, Loss: 0.101\n",
      "Training: Epoch 104, Batch 51, Loss: 0.087\n",
      "Training: Epoch 104, Batch 52, Loss: 0.061\n",
      "Training: Epoch 104, Batch 53, Loss: 0.085\n",
      "Training: Epoch 104, Batch 54, Loss: 0.083\n",
      "Training: Epoch 104, Batch 55, Loss: 0.08\n",
      "Training: Epoch 104, Batch 56, Loss: 0.081\n",
      "Training: Epoch 104, Batch 57, Loss: 0.083\n",
      "Training: Epoch 104, Batch 58, Loss: 0.097\n",
      "Training: Epoch 104, Batch 59, Loss: 0.096\n",
      "Val: Epoch 104, Loss: 0.242\n",
      "Training: Epoch 105, Batch 0, Loss: 0.082\n",
      "Training: Epoch 105, Batch 1, Loss: 0.083\n",
      "Training: Epoch 105, Batch 2, Loss: 0.071\n",
      "Training: Epoch 105, Batch 3, Loss: 0.082\n",
      "Training: Epoch 105, Batch 4, Loss: 0.072\n",
      "Training: Epoch 105, Batch 5, Loss: 0.076\n",
      "Training: Epoch 105, Batch 6, Loss: 0.1\n",
      "Training: Epoch 105, Batch 7, Loss: 0.076\n",
      "Training: Epoch 105, Batch 8, Loss: 0.054\n",
      "Training: Epoch 105, Batch 9, Loss: 0.077\n",
      "Training: Epoch 105, Batch 10, Loss: 0.075\n",
      "Training: Epoch 105, Batch 11, Loss: 0.087\n",
      "Training: Epoch 105, Batch 12, Loss: 0.091\n",
      "Training: Epoch 105, Batch 13, Loss: 0.087\n",
      "Training: Epoch 105, Batch 14, Loss: 0.11\n",
      "Training: Epoch 105, Batch 15, Loss: 0.092\n",
      "Training: Epoch 105, Batch 16, Loss: 0.082\n",
      "Training: Epoch 105, Batch 17, Loss: 0.064\n",
      "Training: Epoch 105, Batch 18, Loss: 0.087\n",
      "Training: Epoch 105, Batch 19, Loss: 0.069\n",
      "Training: Epoch 105, Batch 20, Loss: 0.078\n",
      "Training: Epoch 105, Batch 21, Loss: 0.078\n",
      "Training: Epoch 105, Batch 22, Loss: 0.083\n",
      "Training: Epoch 105, Batch 23, Loss: 0.063\n",
      "Training: Epoch 105, Batch 24, Loss: 0.08\n",
      "Training: Epoch 105, Batch 25, Loss: 0.093\n",
      "Training: Epoch 105, Batch 26, Loss: 0.083\n",
      "Training: Epoch 105, Batch 27, Loss: 0.081\n",
      "Training: Epoch 105, Batch 28, Loss: 0.121\n",
      "Training: Epoch 105, Batch 29, Loss: 0.078\n",
      "Training: Epoch 105, Batch 30, Loss: 0.072\n",
      "Training: Epoch 105, Batch 31, Loss: 0.091\n",
      "Training: Epoch 105, Batch 32, Loss: 0.096\n",
      "Training: Epoch 105, Batch 33, Loss: 0.095\n",
      "Training: Epoch 105, Batch 34, Loss: 0.074\n",
      "Training: Epoch 105, Batch 35, Loss: 0.081\n",
      "Training: Epoch 105, Batch 36, Loss: 0.065\n",
      "Training: Epoch 105, Batch 37, Loss: 0.089\n",
      "Training: Epoch 105, Batch 38, Loss: 0.07\n",
      "Training: Epoch 105, Batch 39, Loss: 0.094\n",
      "Training: Epoch 105, Batch 40, Loss: 0.105\n",
      "Training: Epoch 105, Batch 41, Loss: 0.072\n",
      "Training: Epoch 105, Batch 42, Loss: 0.072\n",
      "Training: Epoch 105, Batch 43, Loss: 0.096\n",
      "Training: Epoch 105, Batch 44, Loss: 0.075\n",
      "Training: Epoch 105, Batch 45, Loss: 0.093\n",
      "Training: Epoch 105, Batch 46, Loss: 0.092\n",
      "Training: Epoch 105, Batch 47, Loss: 0.076\n",
      "Training: Epoch 105, Batch 48, Loss: 0.096\n",
      "Training: Epoch 105, Batch 49, Loss: 0.068\n",
      "Training: Epoch 105, Batch 50, Loss: 0.072\n",
      "Training: Epoch 105, Batch 51, Loss: 0.084\n",
      "Training: Epoch 105, Batch 52, Loss: 0.093\n",
      "Training: Epoch 105, Batch 53, Loss: 0.089\n",
      "Training: Epoch 105, Batch 54, Loss: 0.064\n",
      "Training: Epoch 105, Batch 55, Loss: 0.095\n",
      "Training: Epoch 105, Batch 56, Loss: 0.073\n",
      "Training: Epoch 105, Batch 57, Loss: 0.087\n",
      "Training: Epoch 105, Batch 58, Loss: 0.072\n",
      "Training: Epoch 105, Batch 59, Loss: 0.083\n",
      "Val: Epoch 105, Loss: 0.273\n",
      "Training: Epoch 106, Batch 0, Loss: 0.088\n",
      "Training: Epoch 106, Batch 1, Loss: 0.077\n",
      "Training: Epoch 106, Batch 2, Loss: 0.092\n",
      "Training: Epoch 106, Batch 3, Loss: 0.08\n",
      "Training: Epoch 106, Batch 4, Loss: 0.074\n",
      "Training: Epoch 106, Batch 5, Loss: 0.072\n",
      "Training: Epoch 106, Batch 6, Loss: 0.093\n",
      "Training: Epoch 106, Batch 7, Loss: 0.093\n",
      "Training: Epoch 106, Batch 8, Loss: 0.088\n",
      "Training: Epoch 106, Batch 9, Loss: 0.079\n",
      "Training: Epoch 106, Batch 10, Loss: 0.068\n",
      "Training: Epoch 106, Batch 11, Loss: 0.078\n",
      "Training: Epoch 106, Batch 12, Loss: 0.089\n",
      "Training: Epoch 106, Batch 13, Loss: 0.096\n",
      "Training: Epoch 106, Batch 14, Loss: 0.087\n",
      "Training: Epoch 106, Batch 15, Loss: 0.085\n",
      "Training: Epoch 106, Batch 16, Loss: 0.08\n",
      "Training: Epoch 106, Batch 17, Loss: 0.065\n",
      "Training: Epoch 106, Batch 18, Loss: 0.08\n",
      "Training: Epoch 106, Batch 19, Loss: 0.089\n",
      "Training: Epoch 106, Batch 20, Loss: 0.075\n",
      "Training: Epoch 106, Batch 21, Loss: 0.086\n",
      "Training: Epoch 106, Batch 22, Loss: 0.095\n",
      "Training: Epoch 106, Batch 23, Loss: 0.067\n",
      "Training: Epoch 106, Batch 24, Loss: 0.072\n",
      "Training: Epoch 106, Batch 25, Loss: 0.064\n",
      "Training: Epoch 106, Batch 26, Loss: 0.086\n",
      "Training: Epoch 106, Batch 27, Loss: 0.087\n",
      "Training: Epoch 106, Batch 28, Loss: 0.077\n",
      "Training: Epoch 106, Batch 29, Loss: 0.091\n",
      "Training: Epoch 106, Batch 30, Loss: 0.082\n",
      "Training: Epoch 106, Batch 31, Loss: 0.081\n",
      "Training: Epoch 106, Batch 32, Loss: 0.087\n",
      "Training: Epoch 106, Batch 33, Loss: 0.083\n",
      "Training: Epoch 106, Batch 34, Loss: 0.079\n",
      "Training: Epoch 106, Batch 35, Loss: 0.08\n",
      "Training: Epoch 106, Batch 36, Loss: 0.071\n",
      "Training: Epoch 106, Batch 37, Loss: 0.067\n",
      "Training: Epoch 106, Batch 38, Loss: 0.091\n",
      "Training: Epoch 106, Batch 39, Loss: 0.079\n",
      "Training: Epoch 106, Batch 40, Loss: 0.078\n",
      "Training: Epoch 106, Batch 41, Loss: 0.085\n",
      "Training: Epoch 106, Batch 42, Loss: 0.096\n",
      "Training: Epoch 106, Batch 43, Loss: 0.096\n",
      "Training: Epoch 106, Batch 44, Loss: 0.083\n",
      "Training: Epoch 106, Batch 45, Loss: 0.082\n",
      "Training: Epoch 106, Batch 46, Loss: 0.089\n",
      "Training: Epoch 106, Batch 47, Loss: 0.076\n",
      "Training: Epoch 106, Batch 48, Loss: 0.059\n",
      "Training: Epoch 106, Batch 49, Loss: 0.081\n",
      "Training: Epoch 106, Batch 50, Loss: 0.084\n",
      "Training: Epoch 106, Batch 51, Loss: 0.065\n",
      "Training: Epoch 106, Batch 52, Loss: 0.079\n",
      "Training: Epoch 106, Batch 53, Loss: 0.1\n",
      "Training: Epoch 106, Batch 54, Loss: 0.083\n",
      "Training: Epoch 106, Batch 55, Loss: 0.076\n",
      "Training: Epoch 106, Batch 56, Loss: 0.054\n",
      "Training: Epoch 106, Batch 57, Loss: 0.07\n",
      "Training: Epoch 106, Batch 58, Loss: 0.095\n",
      "Training: Epoch 106, Batch 59, Loss: 0.073\n",
      "Val: Epoch 106, Loss: 0.271\n",
      "Training: Epoch 107, Batch 0, Loss: 0.09\n",
      "Training: Epoch 107, Batch 1, Loss: 0.071\n",
      "Training: Epoch 107, Batch 2, Loss: 0.087\n",
      "Training: Epoch 107, Batch 3, Loss: 0.081\n",
      "Training: Epoch 107, Batch 4, Loss: 0.078\n",
      "Training: Epoch 107, Batch 5, Loss: 0.061\n",
      "Training: Epoch 107, Batch 6, Loss: 0.119\n",
      "Training: Epoch 107, Batch 7, Loss: 0.086\n",
      "Training: Epoch 107, Batch 8, Loss: 0.114\n",
      "Training: Epoch 107, Batch 9, Loss: 0.076\n",
      "Training: Epoch 107, Batch 10, Loss: 0.077\n",
      "Training: Epoch 107, Batch 11, Loss: 0.087\n",
      "Training: Epoch 107, Batch 12, Loss: 0.074\n",
      "Training: Epoch 107, Batch 13, Loss: 0.069\n",
      "Training: Epoch 107, Batch 14, Loss: 0.081\n",
      "Training: Epoch 107, Batch 15, Loss: 0.075\n",
      "Training: Epoch 107, Batch 16, Loss: 0.085\n",
      "Training: Epoch 107, Batch 17, Loss: 0.079\n",
      "Training: Epoch 107, Batch 18, Loss: 0.078\n",
      "Training: Epoch 107, Batch 19, Loss: 0.099\n",
      "Training: Epoch 107, Batch 20, Loss: 0.087\n",
      "Training: Epoch 107, Batch 21, Loss: 0.086\n",
      "Training: Epoch 107, Batch 22, Loss: 0.088\n",
      "Training: Epoch 107, Batch 23, Loss: 0.089\n",
      "Training: Epoch 107, Batch 24, Loss: 0.078\n",
      "Training: Epoch 107, Batch 25, Loss: 0.077\n",
      "Training: Epoch 107, Batch 26, Loss: 0.077\n",
      "Training: Epoch 107, Batch 27, Loss: 0.08\n",
      "Training: Epoch 107, Batch 28, Loss: 0.076\n",
      "Training: Epoch 107, Batch 29, Loss: 0.084\n",
      "Training: Epoch 107, Batch 30, Loss: 0.076\n",
      "Training: Epoch 107, Batch 31, Loss: 0.083\n",
      "Training: Epoch 107, Batch 32, Loss: 0.084\n",
      "Training: Epoch 107, Batch 33, Loss: 0.069\n",
      "Training: Epoch 107, Batch 34, Loss: 0.072\n",
      "Training: Epoch 107, Batch 35, Loss: 0.088\n",
      "Training: Epoch 107, Batch 36, Loss: 0.092\n",
      "Training: Epoch 107, Batch 37, Loss: 0.092\n",
      "Training: Epoch 107, Batch 38, Loss: 0.07\n",
      "Training: Epoch 107, Batch 39, Loss: 0.084\n",
      "Training: Epoch 107, Batch 40, Loss: 0.078\n",
      "Training: Epoch 107, Batch 41, Loss: 0.07\n",
      "Training: Epoch 107, Batch 42, Loss: 0.085\n",
      "Training: Epoch 107, Batch 43, Loss: 0.074\n",
      "Training: Epoch 107, Batch 44, Loss: 0.077\n",
      "Training: Epoch 107, Batch 45, Loss: 0.071\n",
      "Training: Epoch 107, Batch 46, Loss: 0.086\n",
      "Training: Epoch 107, Batch 47, Loss: 0.08\n",
      "Training: Epoch 107, Batch 48, Loss: 0.068\n",
      "Training: Epoch 107, Batch 49, Loss: 0.097\n",
      "Training: Epoch 107, Batch 50, Loss: 0.073\n",
      "Training: Epoch 107, Batch 51, Loss: 0.083\n",
      "Training: Epoch 107, Batch 52, Loss: 0.084\n",
      "Training: Epoch 107, Batch 53, Loss: 0.078\n",
      "Training: Epoch 107, Batch 54, Loss: 0.075\n",
      "Training: Epoch 107, Batch 55, Loss: 0.076\n",
      "Training: Epoch 107, Batch 56, Loss: 0.082\n",
      "Training: Epoch 107, Batch 57, Loss: 0.075\n",
      "Training: Epoch 107, Batch 58, Loss: 0.083\n",
      "Training: Epoch 107, Batch 59, Loss: 0.097\n",
      "Val: Epoch 107, Loss: 0.267\n",
      "Training: Epoch 108, Batch 0, Loss: 0.081\n",
      "Training: Epoch 108, Batch 1, Loss: 0.077\n",
      "Training: Epoch 108, Batch 2, Loss: 0.096\n",
      "Training: Epoch 108, Batch 3, Loss: 0.108\n",
      "Training: Epoch 108, Batch 4, Loss: 0.088\n",
      "Training: Epoch 108, Batch 5, Loss: 0.064\n",
      "Training: Epoch 108, Batch 6, Loss: 0.086\n",
      "Training: Epoch 108, Batch 7, Loss: 0.091\n",
      "Training: Epoch 108, Batch 8, Loss: 0.075\n",
      "Training: Epoch 108, Batch 9, Loss: 0.094\n",
      "Training: Epoch 108, Batch 10, Loss: 0.084\n",
      "Training: Epoch 108, Batch 11, Loss: 0.082\n",
      "Training: Epoch 108, Batch 12, Loss: 0.096\n",
      "Training: Epoch 108, Batch 13, Loss: 0.077\n",
      "Training: Epoch 108, Batch 14, Loss: 0.093\n",
      "Training: Epoch 108, Batch 15, Loss: 0.075\n",
      "Training: Epoch 108, Batch 16, Loss: 0.081\n",
      "Training: Epoch 108, Batch 17, Loss: 0.072\n",
      "Training: Epoch 108, Batch 18, Loss: 0.077\n",
      "Training: Epoch 108, Batch 19, Loss: 0.074\n",
      "Training: Epoch 108, Batch 20, Loss: 0.064\n",
      "Training: Epoch 108, Batch 21, Loss: 0.073\n",
      "Training: Epoch 108, Batch 22, Loss: 0.089\n",
      "Training: Epoch 108, Batch 23, Loss: 0.093\n",
      "Training: Epoch 108, Batch 24, Loss: 0.096\n",
      "Training: Epoch 108, Batch 25, Loss: 0.092\n",
      "Training: Epoch 108, Batch 26, Loss: 0.101\n",
      "Training: Epoch 108, Batch 27, Loss: 0.085\n",
      "Training: Epoch 108, Batch 28, Loss: 0.086\n",
      "Training: Epoch 108, Batch 29, Loss: 0.085\n",
      "Training: Epoch 108, Batch 30, Loss: 0.086\n",
      "Training: Epoch 108, Batch 31, Loss: 0.083\n",
      "Training: Epoch 108, Batch 32, Loss: 0.063\n",
      "Training: Epoch 108, Batch 33, Loss: 0.083\n",
      "Training: Epoch 108, Batch 34, Loss: 0.056\n",
      "Training: Epoch 108, Batch 35, Loss: 0.066\n",
      "Training: Epoch 108, Batch 36, Loss: 0.095\n",
      "Training: Epoch 108, Batch 37, Loss: 0.088\n",
      "Training: Epoch 108, Batch 38, Loss: 0.075\n",
      "Training: Epoch 108, Batch 39, Loss: 0.08\n",
      "Training: Epoch 108, Batch 40, Loss: 0.077\n",
      "Training: Epoch 108, Batch 41, Loss: 0.083\n",
      "Training: Epoch 108, Batch 42, Loss: 0.072\n",
      "Training: Epoch 108, Batch 43, Loss: 0.097\n",
      "Training: Epoch 108, Batch 44, Loss: 0.077\n",
      "Training: Epoch 108, Batch 45, Loss: 0.094\n",
      "Training: Epoch 108, Batch 46, Loss: 0.071\n",
      "Training: Epoch 108, Batch 47, Loss: 0.08\n",
      "Training: Epoch 108, Batch 48, Loss: 0.07\n",
      "Training: Epoch 108, Batch 49, Loss: 0.068\n",
      "Training: Epoch 108, Batch 50, Loss: 0.1\n",
      "Training: Epoch 108, Batch 51, Loss: 0.09\n",
      "Training: Epoch 108, Batch 52, Loss: 0.082\n",
      "Training: Epoch 108, Batch 53, Loss: 0.085\n",
      "Training: Epoch 108, Batch 54, Loss: 0.07\n",
      "Training: Epoch 108, Batch 55, Loss: 0.109\n",
      "Training: Epoch 108, Batch 56, Loss: 0.084\n",
      "Training: Epoch 108, Batch 57, Loss: 0.079\n",
      "Training: Epoch 108, Batch 58, Loss: 0.062\n",
      "Training: Epoch 108, Batch 59, Loss: 0.077\n",
      "Val: Epoch 108, Loss: 0.257\n",
      "Training: Epoch 109, Batch 0, Loss: 0.074\n",
      "Training: Epoch 109, Batch 1, Loss: 0.082\n",
      "Training: Epoch 109, Batch 2, Loss: 0.104\n",
      "Training: Epoch 109, Batch 3, Loss: 0.077\n",
      "Training: Epoch 109, Batch 4, Loss: 0.073\n",
      "Training: Epoch 109, Batch 5, Loss: 0.096\n",
      "Training: Epoch 109, Batch 6, Loss: 0.074\n",
      "Training: Epoch 109, Batch 7, Loss: 0.063\n",
      "Training: Epoch 109, Batch 8, Loss: 0.089\n",
      "Training: Epoch 109, Batch 9, Loss: 0.073\n",
      "Training: Epoch 109, Batch 10, Loss: 0.102\n",
      "Training: Epoch 109, Batch 11, Loss: 0.084\n",
      "Training: Epoch 109, Batch 12, Loss: 0.078\n",
      "Training: Epoch 109, Batch 13, Loss: 0.102\n",
      "Training: Epoch 109, Batch 14, Loss: 0.076\n",
      "Training: Epoch 109, Batch 15, Loss: 0.072\n",
      "Training: Epoch 109, Batch 16, Loss: 0.098\n",
      "Training: Epoch 109, Batch 17, Loss: 0.074\n",
      "Training: Epoch 109, Batch 18, Loss: 0.085\n",
      "Training: Epoch 109, Batch 19, Loss: 0.075\n",
      "Training: Epoch 109, Batch 20, Loss: 0.06\n",
      "Training: Epoch 109, Batch 21, Loss: 0.093\n",
      "Training: Epoch 109, Batch 22, Loss: 0.065\n",
      "Training: Epoch 109, Batch 23, Loss: 0.088\n",
      "Training: Epoch 109, Batch 24, Loss: 0.072\n",
      "Training: Epoch 109, Batch 25, Loss: 0.09\n",
      "Training: Epoch 109, Batch 26, Loss: 0.072\n",
      "Training: Epoch 109, Batch 27, Loss: 0.094\n",
      "Training: Epoch 109, Batch 28, Loss: 0.073\n",
      "Training: Epoch 109, Batch 29, Loss: 0.075\n",
      "Training: Epoch 109, Batch 30, Loss: 0.074\n",
      "Training: Epoch 109, Batch 31, Loss: 0.078\n",
      "Training: Epoch 109, Batch 32, Loss: 0.074\n",
      "Training: Epoch 109, Batch 33, Loss: 0.072\n",
      "Training: Epoch 109, Batch 34, Loss: 0.08\n",
      "Training: Epoch 109, Batch 35, Loss: 0.093\n",
      "Training: Epoch 109, Batch 36, Loss: 0.089\n",
      "Training: Epoch 109, Batch 37, Loss: 0.085\n",
      "Training: Epoch 109, Batch 38, Loss: 0.073\n",
      "Training: Epoch 109, Batch 39, Loss: 0.101\n",
      "Training: Epoch 109, Batch 40, Loss: 0.075\n",
      "Training: Epoch 109, Batch 41, Loss: 0.084\n",
      "Training: Epoch 109, Batch 42, Loss: 0.075\n",
      "Training: Epoch 109, Batch 43, Loss: 0.078\n",
      "Training: Epoch 109, Batch 44, Loss: 0.077\n",
      "Training: Epoch 109, Batch 45, Loss: 0.094\n",
      "Training: Epoch 109, Batch 46, Loss: 0.075\n",
      "Training: Epoch 109, Batch 47, Loss: 0.087\n",
      "Training: Epoch 109, Batch 48, Loss: 0.087\n",
      "Training: Epoch 109, Batch 49, Loss: 0.083\n",
      "Training: Epoch 109, Batch 50, Loss: 0.07\n",
      "Training: Epoch 109, Batch 51, Loss: 0.074\n",
      "Training: Epoch 109, Batch 52, Loss: 0.103\n",
      "Training: Epoch 109, Batch 53, Loss: 0.079\n",
      "Training: Epoch 109, Batch 54, Loss: 0.089\n",
      "Training: Epoch 109, Batch 55, Loss: 0.096\n",
      "Training: Epoch 109, Batch 56, Loss: 0.088\n",
      "Training: Epoch 109, Batch 57, Loss: 0.09\n",
      "Training: Epoch 109, Batch 58, Loss: 0.081\n",
      "Training: Epoch 109, Batch 59, Loss: 0.08\n",
      "Val: Epoch 109, Loss: 0.249\n",
      "Training: Epoch 110, Batch 0, Loss: 0.051\n",
      "Training: Epoch 110, Batch 1, Loss: 0.085\n",
      "Training: Epoch 110, Batch 2, Loss: 0.065\n",
      "Training: Epoch 110, Batch 3, Loss: 0.093\n",
      "Training: Epoch 110, Batch 4, Loss: 0.072\n",
      "Training: Epoch 110, Batch 5, Loss: 0.085\n",
      "Training: Epoch 110, Batch 6, Loss: 0.071\n",
      "Training: Epoch 110, Batch 7, Loss: 0.072\n",
      "Training: Epoch 110, Batch 8, Loss: 0.087\n",
      "Training: Epoch 110, Batch 9, Loss: 0.069\n",
      "Training: Epoch 110, Batch 10, Loss: 0.074\n",
      "Training: Epoch 110, Batch 11, Loss: 0.081\n",
      "Training: Epoch 110, Batch 12, Loss: 0.06\n",
      "Training: Epoch 110, Batch 13, Loss: 0.079\n",
      "Training: Epoch 110, Batch 14, Loss: 0.091\n",
      "Training: Epoch 110, Batch 15, Loss: 0.077\n",
      "Training: Epoch 110, Batch 16, Loss: 0.096\n",
      "Training: Epoch 110, Batch 17, Loss: 0.077\n",
      "Training: Epoch 110, Batch 18, Loss: 0.081\n",
      "Training: Epoch 110, Batch 19, Loss: 0.078\n",
      "Training: Epoch 110, Batch 20, Loss: 0.071\n",
      "Training: Epoch 110, Batch 21, Loss: 0.075\n",
      "Training: Epoch 110, Batch 22, Loss: 0.082\n",
      "Training: Epoch 110, Batch 23, Loss: 0.087\n",
      "Training: Epoch 110, Batch 24, Loss: 0.071\n",
      "Training: Epoch 110, Batch 25, Loss: 0.083\n",
      "Training: Epoch 110, Batch 26, Loss: 0.09\n",
      "Training: Epoch 110, Batch 27, Loss: 0.09\n",
      "Training: Epoch 110, Batch 28, Loss: 0.082\n",
      "Training: Epoch 110, Batch 29, Loss: 0.082\n",
      "Training: Epoch 110, Batch 30, Loss: 0.077\n",
      "Training: Epoch 110, Batch 31, Loss: 0.065\n",
      "Training: Epoch 110, Batch 32, Loss: 0.072\n",
      "Training: Epoch 110, Batch 33, Loss: 0.075\n",
      "Training: Epoch 110, Batch 34, Loss: 0.085\n",
      "Training: Epoch 110, Batch 35, Loss: 0.062\n",
      "Training: Epoch 110, Batch 36, Loss: 0.084\n",
      "Training: Epoch 110, Batch 37, Loss: 0.085\n",
      "Training: Epoch 110, Batch 38, Loss: 0.108\n",
      "Training: Epoch 110, Batch 39, Loss: 0.069\n",
      "Training: Epoch 110, Batch 40, Loss: 0.079\n",
      "Training: Epoch 110, Batch 41, Loss: 0.071\n",
      "Training: Epoch 110, Batch 42, Loss: 0.088\n",
      "Training: Epoch 110, Batch 43, Loss: 0.082\n",
      "Training: Epoch 110, Batch 44, Loss: 0.096\n",
      "Training: Epoch 110, Batch 45, Loss: 0.076\n",
      "Training: Epoch 110, Batch 46, Loss: 0.09\n",
      "Training: Epoch 110, Batch 47, Loss: 0.08\n",
      "Training: Epoch 110, Batch 48, Loss: 0.095\n",
      "Training: Epoch 110, Batch 49, Loss: 0.064\n",
      "Training: Epoch 110, Batch 50, Loss: 0.067\n",
      "Training: Epoch 110, Batch 51, Loss: 0.064\n",
      "Training: Epoch 110, Batch 52, Loss: 0.071\n",
      "Training: Epoch 110, Batch 53, Loss: 0.067\n",
      "Training: Epoch 110, Batch 54, Loss: 0.063\n",
      "Training: Epoch 110, Batch 55, Loss: 0.081\n",
      "Training: Epoch 110, Batch 56, Loss: 0.112\n",
      "Training: Epoch 110, Batch 57, Loss: 0.072\n",
      "Training: Epoch 110, Batch 58, Loss: 0.09\n",
      "Training: Epoch 110, Batch 59, Loss: 0.081\n",
      "Val: Epoch 110, Loss: 0.256\n",
      "Training: Epoch 111, Batch 0, Loss: 0.07\n",
      "Training: Epoch 111, Batch 1, Loss: 0.06\n",
      "Training: Epoch 111, Batch 2, Loss: 0.086\n",
      "Training: Epoch 111, Batch 3, Loss: 0.07\n",
      "Training: Epoch 111, Batch 4, Loss: 0.105\n",
      "Training: Epoch 111, Batch 5, Loss: 0.072\n",
      "Training: Epoch 111, Batch 6, Loss: 0.077\n",
      "Training: Epoch 111, Batch 7, Loss: 0.059\n",
      "Training: Epoch 111, Batch 8, Loss: 0.071\n",
      "Training: Epoch 111, Batch 9, Loss: 0.097\n",
      "Training: Epoch 111, Batch 10, Loss: 0.065\n",
      "Training: Epoch 111, Batch 11, Loss: 0.08\n",
      "Training: Epoch 111, Batch 12, Loss: 0.084\n",
      "Training: Epoch 111, Batch 13, Loss: 0.07\n",
      "Training: Epoch 111, Batch 14, Loss: 0.075\n",
      "Training: Epoch 111, Batch 15, Loss: 0.082\n",
      "Training: Epoch 111, Batch 16, Loss: 0.071\n",
      "Training: Epoch 111, Batch 17, Loss: 0.082\n",
      "Training: Epoch 111, Batch 18, Loss: 0.069\n",
      "Training: Epoch 111, Batch 19, Loss: 0.093\n",
      "Training: Epoch 111, Batch 20, Loss: 0.097\n",
      "Training: Epoch 111, Batch 21, Loss: 0.071\n",
      "Training: Epoch 111, Batch 22, Loss: 0.078\n",
      "Training: Epoch 111, Batch 23, Loss: 0.072\n",
      "Training: Epoch 111, Batch 24, Loss: 0.076\n",
      "Training: Epoch 111, Batch 25, Loss: 0.071\n",
      "Training: Epoch 111, Batch 26, Loss: 0.091\n",
      "Training: Epoch 111, Batch 27, Loss: 0.069\n",
      "Training: Epoch 111, Batch 28, Loss: 0.079\n",
      "Training: Epoch 111, Batch 29, Loss: 0.074\n",
      "Training: Epoch 111, Batch 30, Loss: 0.078\n",
      "Training: Epoch 111, Batch 31, Loss: 0.071\n",
      "Training: Epoch 111, Batch 32, Loss: 0.083\n",
      "Training: Epoch 111, Batch 33, Loss: 0.088\n",
      "Training: Epoch 111, Batch 34, Loss: 0.087\n",
      "Training: Epoch 111, Batch 35, Loss: 0.092\n",
      "Training: Epoch 111, Batch 36, Loss: 0.069\n",
      "Training: Epoch 111, Batch 37, Loss: 0.071\n",
      "Training: Epoch 111, Batch 38, Loss: 0.078\n",
      "Training: Epoch 111, Batch 39, Loss: 0.087\n",
      "Training: Epoch 111, Batch 40, Loss: 0.072\n",
      "Training: Epoch 111, Batch 41, Loss: 0.098\n",
      "Training: Epoch 111, Batch 42, Loss: 0.079\n",
      "Training: Epoch 111, Batch 43, Loss: 0.063\n",
      "Training: Epoch 111, Batch 44, Loss: 0.088\n",
      "Training: Epoch 111, Batch 45, Loss: 0.074\n",
      "Training: Epoch 111, Batch 46, Loss: 0.089\n",
      "Training: Epoch 111, Batch 47, Loss: 0.085\n",
      "Training: Epoch 111, Batch 48, Loss: 0.064\n",
      "Training: Epoch 111, Batch 49, Loss: 0.088\n",
      "Training: Epoch 111, Batch 50, Loss: 0.082\n",
      "Training: Epoch 111, Batch 51, Loss: 0.074\n",
      "Training: Epoch 111, Batch 52, Loss: 0.074\n",
      "Training: Epoch 111, Batch 53, Loss: 0.068\n",
      "Training: Epoch 111, Batch 54, Loss: 0.073\n",
      "Training: Epoch 111, Batch 55, Loss: 0.081\n",
      "Training: Epoch 111, Batch 56, Loss: 0.074\n",
      "Training: Epoch 111, Batch 57, Loss: 0.077\n",
      "Training: Epoch 111, Batch 58, Loss: 0.074\n",
      "Training: Epoch 111, Batch 59, Loss: 0.084\n",
      "Val: Epoch 111, Loss: 0.273\n",
      "Training: Epoch 112, Batch 0, Loss: 0.066\n",
      "Training: Epoch 112, Batch 1, Loss: 0.069\n",
      "Training: Epoch 112, Batch 2, Loss: 0.08\n",
      "Training: Epoch 112, Batch 3, Loss: 0.066\n",
      "Training: Epoch 112, Batch 4, Loss: 0.064\n",
      "Training: Epoch 112, Batch 5, Loss: 0.053\n",
      "Training: Epoch 112, Batch 6, Loss: 0.084\n",
      "Training: Epoch 112, Batch 7, Loss: 0.07\n",
      "Training: Epoch 112, Batch 8, Loss: 0.081\n",
      "Training: Epoch 112, Batch 9, Loss: 0.075\n",
      "Training: Epoch 112, Batch 10, Loss: 0.071\n",
      "Training: Epoch 112, Batch 11, Loss: 0.08\n",
      "Training: Epoch 112, Batch 12, Loss: 0.084\n",
      "Training: Epoch 112, Batch 13, Loss: 0.073\n",
      "Training: Epoch 112, Batch 14, Loss: 0.075\n",
      "Training: Epoch 112, Batch 15, Loss: 0.08\n",
      "Training: Epoch 112, Batch 16, Loss: 0.08\n",
      "Training: Epoch 112, Batch 17, Loss: 0.088\n",
      "Training: Epoch 112, Batch 18, Loss: 0.074\n",
      "Training: Epoch 112, Batch 19, Loss: 0.067\n",
      "Training: Epoch 112, Batch 20, Loss: 0.073\n",
      "Training: Epoch 112, Batch 21, Loss: 0.059\n",
      "Training: Epoch 112, Batch 22, Loss: 0.082\n",
      "Training: Epoch 112, Batch 23, Loss: 0.073\n",
      "Training: Epoch 112, Batch 24, Loss: 0.066\n",
      "Training: Epoch 112, Batch 25, Loss: 0.072\n",
      "Training: Epoch 112, Batch 26, Loss: 0.077\n",
      "Training: Epoch 112, Batch 27, Loss: 0.085\n",
      "Training: Epoch 112, Batch 28, Loss: 0.083\n",
      "Training: Epoch 112, Batch 29, Loss: 0.074\n",
      "Training: Epoch 112, Batch 30, Loss: 0.067\n",
      "Training: Epoch 112, Batch 31, Loss: 0.063\n",
      "Training: Epoch 112, Batch 32, Loss: 0.08\n",
      "Training: Epoch 112, Batch 33, Loss: 0.086\n",
      "Training: Epoch 112, Batch 34, Loss: 0.064\n",
      "Training: Epoch 112, Batch 35, Loss: 0.095\n",
      "Training: Epoch 112, Batch 36, Loss: 0.076\n",
      "Training: Epoch 112, Batch 37, Loss: 0.088\n",
      "Training: Epoch 112, Batch 38, Loss: 0.078\n",
      "Training: Epoch 112, Batch 39, Loss: 0.071\n",
      "Training: Epoch 112, Batch 40, Loss: 0.076\n",
      "Training: Epoch 112, Batch 41, Loss: 0.075\n",
      "Training: Epoch 112, Batch 42, Loss: 0.079\n",
      "Training: Epoch 112, Batch 43, Loss: 0.066\n",
      "Training: Epoch 112, Batch 44, Loss: 0.071\n",
      "Training: Epoch 112, Batch 45, Loss: 0.083\n",
      "Training: Epoch 112, Batch 46, Loss: 0.099\n",
      "Training: Epoch 112, Batch 47, Loss: 0.098\n",
      "Training: Epoch 112, Batch 48, Loss: 0.078\n",
      "Training: Epoch 112, Batch 49, Loss: 0.076\n",
      "Training: Epoch 112, Batch 50, Loss: 0.1\n",
      "Training: Epoch 112, Batch 51, Loss: 0.098\n",
      "Training: Epoch 112, Batch 52, Loss: 0.096\n",
      "Training: Epoch 112, Batch 53, Loss: 0.075\n",
      "Training: Epoch 112, Batch 54, Loss: 0.07\n",
      "Training: Epoch 112, Batch 55, Loss: 0.084\n",
      "Training: Epoch 112, Batch 56, Loss: 0.089\n",
      "Training: Epoch 112, Batch 57, Loss: 0.073\n",
      "Training: Epoch 112, Batch 58, Loss: 0.09\n",
      "Training: Epoch 112, Batch 59, Loss: 0.077\n",
      "Val: Epoch 112, Loss: 0.274\n",
      "Training: Epoch 113, Batch 0, Loss: 0.09\n",
      "Training: Epoch 113, Batch 1, Loss: 0.085\n",
      "Training: Epoch 113, Batch 2, Loss: 0.081\n",
      "Training: Epoch 113, Batch 3, Loss: 0.075\n",
      "Training: Epoch 113, Batch 4, Loss: 0.075\n",
      "Training: Epoch 113, Batch 5, Loss: 0.091\n",
      "Training: Epoch 113, Batch 6, Loss: 0.067\n",
      "Training: Epoch 113, Batch 7, Loss: 0.073\n",
      "Training: Epoch 113, Batch 8, Loss: 0.082\n",
      "Training: Epoch 113, Batch 9, Loss: 0.083\n",
      "Training: Epoch 113, Batch 10, Loss: 0.087\n",
      "Training: Epoch 113, Batch 11, Loss: 0.065\n",
      "Training: Epoch 113, Batch 12, Loss: 0.078\n",
      "Training: Epoch 113, Batch 13, Loss: 0.061\n",
      "Training: Epoch 113, Batch 14, Loss: 0.072\n",
      "Training: Epoch 113, Batch 15, Loss: 0.068\n",
      "Training: Epoch 113, Batch 16, Loss: 0.066\n",
      "Training: Epoch 113, Batch 17, Loss: 0.073\n",
      "Training: Epoch 113, Batch 18, Loss: 0.061\n",
      "Training: Epoch 113, Batch 19, Loss: 0.066\n",
      "Training: Epoch 113, Batch 20, Loss: 0.079\n",
      "Training: Epoch 113, Batch 21, Loss: 0.067\n",
      "Training: Epoch 113, Batch 22, Loss: 0.087\n",
      "Training: Epoch 113, Batch 23, Loss: 0.07\n",
      "Training: Epoch 113, Batch 24, Loss: 0.09\n",
      "Training: Epoch 113, Batch 25, Loss: 0.083\n",
      "Training: Epoch 113, Batch 26, Loss: 0.073\n",
      "Training: Epoch 113, Batch 27, Loss: 0.075\n",
      "Training: Epoch 113, Batch 28, Loss: 0.094\n",
      "Training: Epoch 113, Batch 29, Loss: 0.082\n",
      "Training: Epoch 113, Batch 30, Loss: 0.068\n",
      "Training: Epoch 113, Batch 31, Loss: 0.068\n",
      "Training: Epoch 113, Batch 32, Loss: 0.068\n",
      "Training: Epoch 113, Batch 33, Loss: 0.078\n",
      "Training: Epoch 113, Batch 34, Loss: 0.084\n",
      "Training: Epoch 113, Batch 35, Loss: 0.076\n",
      "Training: Epoch 113, Batch 36, Loss: 0.082\n",
      "Training: Epoch 113, Batch 37, Loss: 0.095\n",
      "Training: Epoch 113, Batch 38, Loss: 0.074\n",
      "Training: Epoch 113, Batch 39, Loss: 0.072\n",
      "Training: Epoch 113, Batch 40, Loss: 0.077\n",
      "Training: Epoch 113, Batch 41, Loss: 0.065\n",
      "Training: Epoch 113, Batch 42, Loss: 0.077\n",
      "Training: Epoch 113, Batch 43, Loss: 0.075\n",
      "Training: Epoch 113, Batch 44, Loss: 0.075\n",
      "Training: Epoch 113, Batch 45, Loss: 0.084\n",
      "Training: Epoch 113, Batch 46, Loss: 0.078\n",
      "Training: Epoch 113, Batch 47, Loss: 0.084\n",
      "Training: Epoch 113, Batch 48, Loss: 0.111\n",
      "Training: Epoch 113, Batch 49, Loss: 0.07\n",
      "Training: Epoch 113, Batch 50, Loss: 0.068\n",
      "Training: Epoch 113, Batch 51, Loss: 0.062\n",
      "Training: Epoch 113, Batch 52, Loss: 0.117\n",
      "Training: Epoch 113, Batch 53, Loss: 0.08\n",
      "Training: Epoch 113, Batch 54, Loss: 0.087\n",
      "Training: Epoch 113, Batch 55, Loss: 0.095\n",
      "Training: Epoch 113, Batch 56, Loss: 0.096\n",
      "Training: Epoch 113, Batch 57, Loss: 0.071\n",
      "Training: Epoch 113, Batch 58, Loss: 0.079\n",
      "Training: Epoch 113, Batch 59, Loss: 0.072\n",
      "Val: Epoch 113, Loss: 0.329\n",
      "Training: Epoch 114, Batch 0, Loss: 0.073\n",
      "Training: Epoch 114, Batch 1, Loss: 0.091\n",
      "Training: Epoch 114, Batch 2, Loss: 0.084\n",
      "Training: Epoch 114, Batch 3, Loss: 0.084\n",
      "Training: Epoch 114, Batch 4, Loss: 0.076\n",
      "Training: Epoch 114, Batch 5, Loss: 0.079\n",
      "Training: Epoch 114, Batch 6, Loss: 0.07\n",
      "Training: Epoch 114, Batch 7, Loss: 0.083\n",
      "Training: Epoch 114, Batch 8, Loss: 0.068\n",
      "Training: Epoch 114, Batch 9, Loss: 0.085\n",
      "Training: Epoch 114, Batch 10, Loss: 0.081\n",
      "Training: Epoch 114, Batch 11, Loss: 0.086\n",
      "Training: Epoch 114, Batch 12, Loss: 0.069\n",
      "Training: Epoch 114, Batch 13, Loss: 0.067\n",
      "Training: Epoch 114, Batch 14, Loss: 0.074\n",
      "Training: Epoch 114, Batch 15, Loss: 0.079\n",
      "Training: Epoch 114, Batch 16, Loss: 0.057\n",
      "Training: Epoch 114, Batch 17, Loss: 0.08\n",
      "Training: Epoch 114, Batch 18, Loss: 0.075\n",
      "Training: Epoch 114, Batch 19, Loss: 0.069\n",
      "Training: Epoch 114, Batch 20, Loss: 0.08\n",
      "Training: Epoch 114, Batch 21, Loss: 0.086\n",
      "Training: Epoch 114, Batch 22, Loss: 0.075\n",
      "Training: Epoch 114, Batch 23, Loss: 0.093\n",
      "Training: Epoch 114, Batch 24, Loss: 0.071\n",
      "Training: Epoch 114, Batch 25, Loss: 0.063\n",
      "Training: Epoch 114, Batch 26, Loss: 0.071\n",
      "Training: Epoch 114, Batch 27, Loss: 0.075\n",
      "Training: Epoch 114, Batch 28, Loss: 0.067\n",
      "Training: Epoch 114, Batch 29, Loss: 0.053\n",
      "Training: Epoch 114, Batch 30, Loss: 0.109\n",
      "Training: Epoch 114, Batch 31, Loss: 0.08\n",
      "Training: Epoch 114, Batch 32, Loss: 0.077\n",
      "Training: Epoch 114, Batch 33, Loss: 0.072\n",
      "Training: Epoch 114, Batch 34, Loss: 0.081\n",
      "Training: Epoch 114, Batch 35, Loss: 0.082\n",
      "Training: Epoch 114, Batch 36, Loss: 0.062\n",
      "Training: Epoch 114, Batch 37, Loss: 0.093\n",
      "Training: Epoch 114, Batch 38, Loss: 0.086\n",
      "Training: Epoch 114, Batch 39, Loss: 0.093\n",
      "Training: Epoch 114, Batch 40, Loss: 0.105\n",
      "Training: Epoch 114, Batch 41, Loss: 0.071\n",
      "Training: Epoch 114, Batch 42, Loss: 0.073\n",
      "Training: Epoch 114, Batch 43, Loss: 0.067\n",
      "Training: Epoch 114, Batch 44, Loss: 0.08\n",
      "Training: Epoch 114, Batch 45, Loss: 0.066\n",
      "Training: Epoch 114, Batch 46, Loss: 0.083\n",
      "Training: Epoch 114, Batch 47, Loss: 0.072\n",
      "Training: Epoch 114, Batch 48, Loss: 0.085\n",
      "Training: Epoch 114, Batch 49, Loss: 0.084\n",
      "Training: Epoch 114, Batch 50, Loss: 0.09\n",
      "Training: Epoch 114, Batch 51, Loss: 0.062\n",
      "Training: Epoch 114, Batch 52, Loss: 0.085\n",
      "Training: Epoch 114, Batch 53, Loss: 0.073\n",
      "Training: Epoch 114, Batch 54, Loss: 0.077\n",
      "Training: Epoch 114, Batch 55, Loss: 0.087\n",
      "Training: Epoch 114, Batch 56, Loss: 0.091\n",
      "Training: Epoch 114, Batch 57, Loss: 0.078\n",
      "Training: Epoch 114, Batch 58, Loss: 0.069\n",
      "Training: Epoch 114, Batch 59, Loss: 0.073\n",
      "Val: Epoch 114, Loss: 0.269\n",
      "Training: Epoch 115, Batch 0, Loss: 0.093\n",
      "Training: Epoch 115, Batch 1, Loss: 0.081\n",
      "Training: Epoch 115, Batch 2, Loss: 0.078\n",
      "Training: Epoch 115, Batch 3, Loss: 0.077\n",
      "Training: Epoch 115, Batch 4, Loss: 0.075\n",
      "Training: Epoch 115, Batch 5, Loss: 0.093\n",
      "Training: Epoch 115, Batch 6, Loss: 0.077\n",
      "Training: Epoch 115, Batch 7, Loss: 0.075\n",
      "Training: Epoch 115, Batch 8, Loss: 0.091\n",
      "Training: Epoch 115, Batch 9, Loss: 0.074\n",
      "Training: Epoch 115, Batch 10, Loss: 0.065\n",
      "Training: Epoch 115, Batch 11, Loss: 0.078\n",
      "Training: Epoch 115, Batch 12, Loss: 0.062\n",
      "Training: Epoch 115, Batch 13, Loss: 0.081\n",
      "Training: Epoch 115, Batch 14, Loss: 0.076\n",
      "Training: Epoch 115, Batch 15, Loss: 0.105\n",
      "Training: Epoch 115, Batch 16, Loss: 0.064\n",
      "Training: Epoch 115, Batch 17, Loss: 0.072\n",
      "Training: Epoch 115, Batch 18, Loss: 0.068\n",
      "Training: Epoch 115, Batch 19, Loss: 0.077\n",
      "Training: Epoch 115, Batch 20, Loss: 0.078\n",
      "Training: Epoch 115, Batch 21, Loss: 0.084\n",
      "Training: Epoch 115, Batch 22, Loss: 0.081\n",
      "Training: Epoch 115, Batch 23, Loss: 0.074\n",
      "Training: Epoch 115, Batch 24, Loss: 0.08\n",
      "Training: Epoch 115, Batch 25, Loss: 0.064\n",
      "Training: Epoch 115, Batch 26, Loss: 0.069\n",
      "Training: Epoch 115, Batch 27, Loss: 0.078\n",
      "Training: Epoch 115, Batch 28, Loss: 0.085\n",
      "Training: Epoch 115, Batch 29, Loss: 0.082\n",
      "Training: Epoch 115, Batch 30, Loss: 0.061\n",
      "Training: Epoch 115, Batch 31, Loss: 0.063\n",
      "Training: Epoch 115, Batch 32, Loss: 0.067\n",
      "Training: Epoch 115, Batch 33, Loss: 0.086\n",
      "Training: Epoch 115, Batch 34, Loss: 0.088\n",
      "Training: Epoch 115, Batch 35, Loss: 0.081\n",
      "Training: Epoch 115, Batch 36, Loss: 0.059\n",
      "Training: Epoch 115, Batch 37, Loss: 0.071\n",
      "Training: Epoch 115, Batch 38, Loss: 0.089\n",
      "Training: Epoch 115, Batch 39, Loss: 0.079\n",
      "Training: Epoch 115, Batch 40, Loss: 0.067\n",
      "Training: Epoch 115, Batch 41, Loss: 0.095\n",
      "Training: Epoch 115, Batch 42, Loss: 0.071\n",
      "Training: Epoch 115, Batch 43, Loss: 0.072\n",
      "Training: Epoch 115, Batch 44, Loss: 0.075\n",
      "Training: Epoch 115, Batch 45, Loss: 0.074\n",
      "Training: Epoch 115, Batch 46, Loss: 0.079\n",
      "Training: Epoch 115, Batch 47, Loss: 0.078\n",
      "Training: Epoch 115, Batch 48, Loss: 0.097\n",
      "Training: Epoch 115, Batch 49, Loss: 0.074\n",
      "Training: Epoch 115, Batch 50, Loss: 0.087\n",
      "Training: Epoch 115, Batch 51, Loss: 0.065\n",
      "Training: Epoch 115, Batch 52, Loss: 0.078\n",
      "Training: Epoch 115, Batch 53, Loss: 0.097\n",
      "Training: Epoch 115, Batch 54, Loss: 0.084\n",
      "Training: Epoch 115, Batch 55, Loss: 0.09\n",
      "Training: Epoch 115, Batch 56, Loss: 0.09\n",
      "Training: Epoch 115, Batch 57, Loss: 0.092\n",
      "Training: Epoch 115, Batch 58, Loss: 0.079\n",
      "Training: Epoch 115, Batch 59, Loss: 0.075\n",
      "Val: Epoch 115, Loss: 0.254\n",
      "Training: Epoch 116, Batch 0, Loss: 0.069\n",
      "Training: Epoch 116, Batch 1, Loss: 0.089\n",
      "Training: Epoch 116, Batch 2, Loss: 0.082\n",
      "Training: Epoch 116, Batch 3, Loss: 0.068\n",
      "Training: Epoch 116, Batch 4, Loss: 0.084\n",
      "Training: Epoch 116, Batch 5, Loss: 0.064\n",
      "Training: Epoch 116, Batch 6, Loss: 0.069\n",
      "Training: Epoch 116, Batch 7, Loss: 0.082\n",
      "Training: Epoch 116, Batch 8, Loss: 0.067\n",
      "Training: Epoch 116, Batch 9, Loss: 0.084\n",
      "Training: Epoch 116, Batch 10, Loss: 0.062\n",
      "Training: Epoch 116, Batch 11, Loss: 0.088\n",
      "Training: Epoch 116, Batch 12, Loss: 0.062\n",
      "Training: Epoch 116, Batch 13, Loss: 0.074\n",
      "Training: Epoch 116, Batch 14, Loss: 0.081\n",
      "Training: Epoch 116, Batch 15, Loss: 0.075\n",
      "Training: Epoch 116, Batch 16, Loss: 0.072\n",
      "Training: Epoch 116, Batch 17, Loss: 0.073\n",
      "Training: Epoch 116, Batch 18, Loss: 0.083\n",
      "Training: Epoch 116, Batch 19, Loss: 0.068\n",
      "Training: Epoch 116, Batch 20, Loss: 0.066\n",
      "Training: Epoch 116, Batch 21, Loss: 0.07\n",
      "Training: Epoch 116, Batch 22, Loss: 0.077\n",
      "Training: Epoch 116, Batch 23, Loss: 0.064\n",
      "Training: Epoch 116, Batch 24, Loss: 0.076\n",
      "Training: Epoch 116, Batch 25, Loss: 0.069\n",
      "Training: Epoch 116, Batch 26, Loss: 0.076\n",
      "Training: Epoch 116, Batch 27, Loss: 0.082\n",
      "Training: Epoch 116, Batch 28, Loss: 0.059\n",
      "Training: Epoch 116, Batch 29, Loss: 0.08\n",
      "Training: Epoch 116, Batch 30, Loss: 0.081\n",
      "Training: Epoch 116, Batch 31, Loss: 0.084\n",
      "Training: Epoch 116, Batch 32, Loss: 0.086\n",
      "Training: Epoch 116, Batch 33, Loss: 0.111\n",
      "Training: Epoch 116, Batch 34, Loss: 0.067\n",
      "Training: Epoch 116, Batch 35, Loss: 0.063\n",
      "Training: Epoch 116, Batch 36, Loss: 0.076\n",
      "Training: Epoch 116, Batch 37, Loss: 0.052\n",
      "Training: Epoch 116, Batch 38, Loss: 0.065\n",
      "Training: Epoch 116, Batch 39, Loss: 0.12\n",
      "Training: Epoch 116, Batch 40, Loss: 0.074\n",
      "Training: Epoch 116, Batch 41, Loss: 0.09\n",
      "Training: Epoch 116, Batch 42, Loss: 0.077\n",
      "Training: Epoch 116, Batch 43, Loss: 0.068\n",
      "Training: Epoch 116, Batch 44, Loss: 0.079\n",
      "Training: Epoch 116, Batch 45, Loss: 0.084\n",
      "Training: Epoch 116, Batch 46, Loss: 0.075\n",
      "Training: Epoch 116, Batch 47, Loss: 0.076\n",
      "Training: Epoch 116, Batch 48, Loss: 0.063\n",
      "Training: Epoch 116, Batch 49, Loss: 0.067\n",
      "Training: Epoch 116, Batch 50, Loss: 0.076\n",
      "Training: Epoch 116, Batch 51, Loss: 0.091\n",
      "Training: Epoch 116, Batch 52, Loss: 0.077\n",
      "Training: Epoch 116, Batch 53, Loss: 0.084\n",
      "Training: Epoch 116, Batch 54, Loss: 0.095\n",
      "Training: Epoch 116, Batch 55, Loss: 0.074\n",
      "Training: Epoch 116, Batch 56, Loss: 0.073\n",
      "Training: Epoch 116, Batch 57, Loss: 0.076\n",
      "Training: Epoch 116, Batch 58, Loss: 0.089\n",
      "Training: Epoch 116, Batch 59, Loss: 0.076\n",
      "Val: Epoch 116, Loss: 0.273\n",
      "Training: Epoch 117, Batch 0, Loss: 0.091\n",
      "Training: Epoch 117, Batch 1, Loss: 0.083\n",
      "Training: Epoch 117, Batch 2, Loss: 0.068\n",
      "Training: Epoch 117, Batch 3, Loss: 0.083\n",
      "Training: Epoch 117, Batch 4, Loss: 0.088\n",
      "Training: Epoch 117, Batch 5, Loss: 0.084\n",
      "Training: Epoch 117, Batch 6, Loss: 0.07\n",
      "Training: Epoch 117, Batch 7, Loss: 0.086\n",
      "Training: Epoch 117, Batch 8, Loss: 0.064\n",
      "Training: Epoch 117, Batch 9, Loss: 0.059\n",
      "Training: Epoch 117, Batch 10, Loss: 0.073\n",
      "Training: Epoch 117, Batch 11, Loss: 0.073\n",
      "Training: Epoch 117, Batch 12, Loss: 0.069\n",
      "Training: Epoch 117, Batch 13, Loss: 0.08\n",
      "Training: Epoch 117, Batch 14, Loss: 0.086\n",
      "Training: Epoch 117, Batch 15, Loss: 0.076\n",
      "Training: Epoch 117, Batch 16, Loss: 0.07\n",
      "Training: Epoch 117, Batch 17, Loss: 0.081\n",
      "Training: Epoch 117, Batch 18, Loss: 0.088\n",
      "Training: Epoch 117, Batch 19, Loss: 0.07\n",
      "Training: Epoch 117, Batch 20, Loss: 0.067\n",
      "Training: Epoch 117, Batch 21, Loss: 0.093\n",
      "Training: Epoch 117, Batch 22, Loss: 0.079\n",
      "Training: Epoch 117, Batch 23, Loss: 0.087\n",
      "Training: Epoch 117, Batch 24, Loss: 0.07\n",
      "Training: Epoch 117, Batch 25, Loss: 0.068\n",
      "Training: Epoch 117, Batch 26, Loss: 0.071\n",
      "Training: Epoch 117, Batch 27, Loss: 0.084\n",
      "Training: Epoch 117, Batch 28, Loss: 0.09\n",
      "Training: Epoch 117, Batch 29, Loss: 0.077\n",
      "Training: Epoch 117, Batch 30, Loss: 0.096\n",
      "Training: Epoch 117, Batch 31, Loss: 0.086\n",
      "Training: Epoch 117, Batch 32, Loss: 0.07\n",
      "Training: Epoch 117, Batch 33, Loss: 0.09\n",
      "Training: Epoch 117, Batch 34, Loss: 0.075\n",
      "Training: Epoch 117, Batch 35, Loss: 0.095\n",
      "Training: Epoch 117, Batch 36, Loss: 0.071\n",
      "Training: Epoch 117, Batch 37, Loss: 0.082\n",
      "Training: Epoch 117, Batch 38, Loss: 0.085\n",
      "Training: Epoch 117, Batch 39, Loss: 0.069\n",
      "Training: Epoch 117, Batch 40, Loss: 0.075\n",
      "Training: Epoch 117, Batch 41, Loss: 0.072\n",
      "Training: Epoch 117, Batch 42, Loss: 0.083\n",
      "Training: Epoch 117, Batch 43, Loss: 0.073\n",
      "Training: Epoch 117, Batch 44, Loss: 0.078\n",
      "Training: Epoch 117, Batch 45, Loss: 0.097\n",
      "Training: Epoch 117, Batch 46, Loss: 0.078\n",
      "Training: Epoch 117, Batch 47, Loss: 0.072\n",
      "Training: Epoch 117, Batch 48, Loss: 0.066\n",
      "Training: Epoch 117, Batch 49, Loss: 0.079\n",
      "Training: Epoch 117, Batch 50, Loss: 0.068\n",
      "Training: Epoch 117, Batch 51, Loss: 0.071\n",
      "Training: Epoch 117, Batch 52, Loss: 0.081\n",
      "Training: Epoch 117, Batch 53, Loss: 0.065\n",
      "Training: Epoch 117, Batch 54, Loss: 0.072\n",
      "Training: Epoch 117, Batch 55, Loss: 0.08\n",
      "Training: Epoch 117, Batch 56, Loss: 0.068\n",
      "Training: Epoch 117, Batch 57, Loss: 0.072\n",
      "Training: Epoch 117, Batch 58, Loss: 0.075\n",
      "Training: Epoch 117, Batch 59, Loss: 0.075\n",
      "Val: Epoch 117, Loss: 0.262\n",
      "Training: Epoch 118, Batch 0, Loss: 0.071\n",
      "Training: Epoch 118, Batch 1, Loss: 0.09\n",
      "Training: Epoch 118, Batch 2, Loss: 0.071\n",
      "Training: Epoch 118, Batch 3, Loss: 0.089\n",
      "Training: Epoch 118, Batch 4, Loss: 0.067\n",
      "Training: Epoch 118, Batch 5, Loss: 0.076\n",
      "Training: Epoch 118, Batch 6, Loss: 0.087\n",
      "Training: Epoch 118, Batch 7, Loss: 0.07\n",
      "Training: Epoch 118, Batch 8, Loss: 0.071\n",
      "Training: Epoch 118, Batch 9, Loss: 0.08\n",
      "Training: Epoch 118, Batch 10, Loss: 0.065\n",
      "Training: Epoch 118, Batch 11, Loss: 0.092\n",
      "Training: Epoch 118, Batch 12, Loss: 0.068\n",
      "Training: Epoch 118, Batch 13, Loss: 0.078\n",
      "Training: Epoch 118, Batch 14, Loss: 0.077\n",
      "Training: Epoch 118, Batch 15, Loss: 0.076\n",
      "Training: Epoch 118, Batch 16, Loss: 0.054\n",
      "Training: Epoch 118, Batch 17, Loss: 0.072\n",
      "Training: Epoch 118, Batch 18, Loss: 0.091\n",
      "Training: Epoch 118, Batch 19, Loss: 0.069\n",
      "Training: Epoch 118, Batch 20, Loss: 0.074\n",
      "Training: Epoch 118, Batch 21, Loss: 0.081\n",
      "Training: Epoch 118, Batch 22, Loss: 0.101\n",
      "Training: Epoch 118, Batch 23, Loss: 0.071\n",
      "Training: Epoch 118, Batch 24, Loss: 0.077\n",
      "Training: Epoch 118, Batch 25, Loss: 0.069\n",
      "Training: Epoch 118, Batch 26, Loss: 0.068\n",
      "Training: Epoch 118, Batch 27, Loss: 0.071\n",
      "Training: Epoch 118, Batch 28, Loss: 0.063\n",
      "Training: Epoch 118, Batch 29, Loss: 0.083\n",
      "Training: Epoch 118, Batch 30, Loss: 0.08\n",
      "Training: Epoch 118, Batch 31, Loss: 0.085\n",
      "Training: Epoch 118, Batch 32, Loss: 0.076\n",
      "Training: Epoch 118, Batch 33, Loss: 0.086\n",
      "Training: Epoch 118, Batch 34, Loss: 0.071\n",
      "Training: Epoch 118, Batch 35, Loss: 0.074\n",
      "Training: Epoch 118, Batch 36, Loss: 0.08\n",
      "Training: Epoch 118, Batch 37, Loss: 0.082\n",
      "Training: Epoch 118, Batch 38, Loss: 0.087\n",
      "Training: Epoch 118, Batch 39, Loss: 0.081\n",
      "Training: Epoch 118, Batch 40, Loss: 0.079\n",
      "Training: Epoch 118, Batch 41, Loss: 0.06\n",
      "Training: Epoch 118, Batch 42, Loss: 0.075\n",
      "Training: Epoch 118, Batch 43, Loss: 0.091\n",
      "Training: Epoch 118, Batch 44, Loss: 0.086\n",
      "Training: Epoch 118, Batch 45, Loss: 0.078\n",
      "Training: Epoch 118, Batch 46, Loss: 0.075\n",
      "Training: Epoch 118, Batch 47, Loss: 0.071\n",
      "Training: Epoch 118, Batch 48, Loss: 0.1\n",
      "Training: Epoch 118, Batch 49, Loss: 0.07\n",
      "Training: Epoch 118, Batch 50, Loss: 0.087\n",
      "Training: Epoch 118, Batch 51, Loss: 0.064\n",
      "Training: Epoch 118, Batch 52, Loss: 0.085\n",
      "Training: Epoch 118, Batch 53, Loss: 0.068\n",
      "Training: Epoch 118, Batch 54, Loss: 0.074\n",
      "Training: Epoch 118, Batch 55, Loss: 0.078\n",
      "Training: Epoch 118, Batch 56, Loss: 0.075\n",
      "Training: Epoch 118, Batch 57, Loss: 0.082\n",
      "Training: Epoch 118, Batch 58, Loss: 0.073\n",
      "Training: Epoch 118, Batch 59, Loss: 0.076\n",
      "Val: Epoch 118, Loss: 0.253\n",
      "Training: Epoch 119, Batch 0, Loss: 0.069\n",
      "Training: Epoch 119, Batch 1, Loss: 0.082\n",
      "Training: Epoch 119, Batch 2, Loss: 0.093\n",
      "Training: Epoch 119, Batch 3, Loss: 0.067\n",
      "Training: Epoch 119, Batch 4, Loss: 0.088\n",
      "Training: Epoch 119, Batch 5, Loss: 0.07\n",
      "Training: Epoch 119, Batch 6, Loss: 0.092\n",
      "Training: Epoch 119, Batch 7, Loss: 0.09\n",
      "Training: Epoch 119, Batch 8, Loss: 0.059\n",
      "Training: Epoch 119, Batch 9, Loss: 0.094\n",
      "Training: Epoch 119, Batch 10, Loss: 0.068\n",
      "Training: Epoch 119, Batch 11, Loss: 0.072\n",
      "Training: Epoch 119, Batch 12, Loss: 0.071\n",
      "Training: Epoch 119, Batch 13, Loss: 0.086\n",
      "Training: Epoch 119, Batch 14, Loss: 0.068\n",
      "Training: Epoch 119, Batch 15, Loss: 0.081\n",
      "Training: Epoch 119, Batch 16, Loss: 0.092\n",
      "Training: Epoch 119, Batch 17, Loss: 0.054\n",
      "Training: Epoch 119, Batch 18, Loss: 0.092\n",
      "Training: Epoch 119, Batch 19, Loss: 0.075\n",
      "Training: Epoch 119, Batch 20, Loss: 0.065\n",
      "Training: Epoch 119, Batch 21, Loss: 0.087\n",
      "Training: Epoch 119, Batch 22, Loss: 0.068\n",
      "Training: Epoch 119, Batch 23, Loss: 0.077\n",
      "Training: Epoch 119, Batch 24, Loss: 0.073\n",
      "Training: Epoch 119, Batch 25, Loss: 0.089\n",
      "Training: Epoch 119, Batch 26, Loss: 0.086\n",
      "Training: Epoch 119, Batch 27, Loss: 0.063\n",
      "Training: Epoch 119, Batch 28, Loss: 0.069\n",
      "Training: Epoch 119, Batch 29, Loss: 0.07\n",
      "Training: Epoch 119, Batch 30, Loss: 0.085\n",
      "Training: Epoch 119, Batch 31, Loss: 0.07\n",
      "Training: Epoch 119, Batch 32, Loss: 0.083\n",
      "Training: Epoch 119, Batch 33, Loss: 0.084\n",
      "Training: Epoch 119, Batch 34, Loss: 0.063\n",
      "Training: Epoch 119, Batch 35, Loss: 0.087\n",
      "Training: Epoch 119, Batch 36, Loss: 0.082\n",
      "Training: Epoch 119, Batch 37, Loss: 0.079\n",
      "Training: Epoch 119, Batch 38, Loss: 0.066\n",
      "Training: Epoch 119, Batch 39, Loss: 0.087\n",
      "Training: Epoch 119, Batch 40, Loss: 0.07\n",
      "Training: Epoch 119, Batch 41, Loss: 0.07\n",
      "Training: Epoch 119, Batch 42, Loss: 0.075\n",
      "Training: Epoch 119, Batch 43, Loss: 0.089\n",
      "Training: Epoch 119, Batch 44, Loss: 0.081\n",
      "Training: Epoch 119, Batch 45, Loss: 0.064\n",
      "Training: Epoch 119, Batch 46, Loss: 0.075\n",
      "Training: Epoch 119, Batch 47, Loss: 0.076\n",
      "Training: Epoch 119, Batch 48, Loss: 0.076\n",
      "Training: Epoch 119, Batch 49, Loss: 0.077\n",
      "Training: Epoch 119, Batch 50, Loss: 0.075\n",
      "Training: Epoch 119, Batch 51, Loss: 0.06\n",
      "Training: Epoch 119, Batch 52, Loss: 0.068\n",
      "Training: Epoch 119, Batch 53, Loss: 0.066\n",
      "Training: Epoch 119, Batch 54, Loss: 0.066\n",
      "Training: Epoch 119, Batch 55, Loss: 0.094\n",
      "Training: Epoch 119, Batch 56, Loss: 0.076\n",
      "Training: Epoch 119, Batch 57, Loss: 0.094\n",
      "Training: Epoch 119, Batch 58, Loss: 0.053\n",
      "Training: Epoch 119, Batch 59, Loss: 0.067\n",
      "Val: Epoch 119, Loss: 0.272\n",
      "Training: Epoch 120, Batch 0, Loss: 0.075\n",
      "Training: Epoch 120, Batch 1, Loss: 0.069\n",
      "Training: Epoch 120, Batch 2, Loss: 0.091\n",
      "Training: Epoch 120, Batch 3, Loss: 0.068\n",
      "Training: Epoch 120, Batch 4, Loss: 0.065\n",
      "Training: Epoch 120, Batch 5, Loss: 0.068\n",
      "Training: Epoch 120, Batch 6, Loss: 0.077\n",
      "Training: Epoch 120, Batch 7, Loss: 0.097\n",
      "Training: Epoch 120, Batch 8, Loss: 0.063\n",
      "Training: Epoch 120, Batch 9, Loss: 0.094\n",
      "Training: Epoch 120, Batch 10, Loss: 0.071\n",
      "Training: Epoch 120, Batch 11, Loss: 0.081\n",
      "Training: Epoch 120, Batch 12, Loss: 0.072\n",
      "Training: Epoch 120, Batch 13, Loss: 0.077\n",
      "Training: Epoch 120, Batch 14, Loss: 0.066\n",
      "Training: Epoch 120, Batch 15, Loss: 0.082\n",
      "Training: Epoch 120, Batch 16, Loss: 0.054\n",
      "Training: Epoch 120, Batch 17, Loss: 0.085\n",
      "Training: Epoch 120, Batch 18, Loss: 0.075\n",
      "Training: Epoch 120, Batch 19, Loss: 0.068\n",
      "Training: Epoch 120, Batch 20, Loss: 0.061\n",
      "Training: Epoch 120, Batch 21, Loss: 0.081\n",
      "Training: Epoch 120, Batch 22, Loss: 0.07\n",
      "Training: Epoch 120, Batch 23, Loss: 0.071\n",
      "Training: Epoch 120, Batch 24, Loss: 0.107\n",
      "Training: Epoch 120, Batch 25, Loss: 0.058\n",
      "Training: Epoch 120, Batch 26, Loss: 0.078\n",
      "Training: Epoch 120, Batch 27, Loss: 0.087\n",
      "Training: Epoch 120, Batch 28, Loss: 0.07\n",
      "Training: Epoch 120, Batch 29, Loss: 0.089\n",
      "Training: Epoch 120, Batch 30, Loss: 0.088\n",
      "Training: Epoch 120, Batch 31, Loss: 0.086\n",
      "Training: Epoch 120, Batch 32, Loss: 0.074\n",
      "Training: Epoch 120, Batch 33, Loss: 0.072\n",
      "Training: Epoch 120, Batch 34, Loss: 0.101\n",
      "Training: Epoch 120, Batch 35, Loss: 0.079\n",
      "Training: Epoch 120, Batch 36, Loss: 0.066\n",
      "Training: Epoch 120, Batch 37, Loss: 0.073\n",
      "Training: Epoch 120, Batch 38, Loss: 0.073\n",
      "Training: Epoch 120, Batch 39, Loss: 0.077\n",
      "Training: Epoch 120, Batch 40, Loss: 0.069\n",
      "Training: Epoch 120, Batch 41, Loss: 0.087\n",
      "Training: Epoch 120, Batch 42, Loss: 0.081\n",
      "Training: Epoch 120, Batch 43, Loss: 0.07\n",
      "Training: Epoch 120, Batch 44, Loss: 0.074\n",
      "Training: Epoch 120, Batch 45, Loss: 0.077\n",
      "Training: Epoch 120, Batch 46, Loss: 0.072\n",
      "Training: Epoch 120, Batch 47, Loss: 0.077\n",
      "Training: Epoch 120, Batch 48, Loss: 0.087\n",
      "Training: Epoch 120, Batch 49, Loss: 0.08\n",
      "Training: Epoch 120, Batch 50, Loss: 0.077\n",
      "Training: Epoch 120, Batch 51, Loss: 0.07\n",
      "Training: Epoch 120, Batch 52, Loss: 0.073\n",
      "Training: Epoch 120, Batch 53, Loss: 0.07\n",
      "Training: Epoch 120, Batch 54, Loss: 0.075\n",
      "Training: Epoch 120, Batch 55, Loss: 0.082\n",
      "Training: Epoch 120, Batch 56, Loss: 0.064\n",
      "Training: Epoch 120, Batch 57, Loss: 0.067\n",
      "Training: Epoch 120, Batch 58, Loss: 0.061\n",
      "Training: Epoch 120, Batch 59, Loss: 0.087\n",
      "Val: Epoch 120, Loss: 0.276\n",
      "Training: Epoch 121, Batch 0, Loss: 0.069\n",
      "Training: Epoch 121, Batch 1, Loss: 0.081\n",
      "Training: Epoch 121, Batch 2, Loss: 0.071\n",
      "Training: Epoch 121, Batch 3, Loss: 0.068\n",
      "Training: Epoch 121, Batch 4, Loss: 0.082\n",
      "Training: Epoch 121, Batch 5, Loss: 0.079\n",
      "Training: Epoch 121, Batch 6, Loss: 0.071\n",
      "Training: Epoch 121, Batch 7, Loss: 0.075\n",
      "Training: Epoch 121, Batch 8, Loss: 0.068\n",
      "Training: Epoch 121, Batch 9, Loss: 0.069\n",
      "Training: Epoch 121, Batch 10, Loss: 0.066\n",
      "Training: Epoch 121, Batch 11, Loss: 0.094\n",
      "Training: Epoch 121, Batch 12, Loss: 0.067\n",
      "Training: Epoch 121, Batch 13, Loss: 0.07\n",
      "Training: Epoch 121, Batch 14, Loss: 0.089\n",
      "Training: Epoch 121, Batch 15, Loss: 0.075\n",
      "Training: Epoch 121, Batch 16, Loss: 0.074\n",
      "Training: Epoch 121, Batch 17, Loss: 0.067\n",
      "Training: Epoch 121, Batch 18, Loss: 0.08\n",
      "Training: Epoch 121, Batch 19, Loss: 0.081\n",
      "Training: Epoch 121, Batch 20, Loss: 0.088\n",
      "Training: Epoch 121, Batch 21, Loss: 0.071\n",
      "Training: Epoch 121, Batch 22, Loss: 0.085\n",
      "Training: Epoch 121, Batch 23, Loss: 0.07\n",
      "Training: Epoch 121, Batch 24, Loss: 0.062\n",
      "Training: Epoch 121, Batch 25, Loss: 0.065\n",
      "Training: Epoch 121, Batch 26, Loss: 0.084\n",
      "Training: Epoch 121, Batch 27, Loss: 0.077\n",
      "Training: Epoch 121, Batch 28, Loss: 0.085\n",
      "Training: Epoch 121, Batch 29, Loss: 0.059\n",
      "Training: Epoch 121, Batch 30, Loss: 0.087\n",
      "Training: Epoch 121, Batch 31, Loss: 0.071\n",
      "Training: Epoch 121, Batch 32, Loss: 0.06\n",
      "Training: Epoch 121, Batch 33, Loss: 0.069\n",
      "Training: Epoch 121, Batch 34, Loss: 0.064\n",
      "Training: Epoch 121, Batch 35, Loss: 0.065\n",
      "Training: Epoch 121, Batch 36, Loss: 0.081\n",
      "Training: Epoch 121, Batch 37, Loss: 0.082\n",
      "Training: Epoch 121, Batch 38, Loss: 0.077\n",
      "Training: Epoch 121, Batch 39, Loss: 0.07\n",
      "Training: Epoch 121, Batch 40, Loss: 0.077\n",
      "Training: Epoch 121, Batch 41, Loss: 0.07\n",
      "Training: Epoch 121, Batch 42, Loss: 0.065\n",
      "Training: Epoch 121, Batch 43, Loss: 0.066\n",
      "Training: Epoch 121, Batch 44, Loss: 0.065\n",
      "Training: Epoch 121, Batch 45, Loss: 0.061\n",
      "Training: Epoch 121, Batch 46, Loss: 0.077\n",
      "Training: Epoch 121, Batch 47, Loss: 0.059\n",
      "Training: Epoch 121, Batch 48, Loss: 0.085\n",
      "Training: Epoch 121, Batch 49, Loss: 0.059\n",
      "Training: Epoch 121, Batch 50, Loss: 0.091\n",
      "Training: Epoch 121, Batch 51, Loss: 0.072\n",
      "Training: Epoch 121, Batch 52, Loss: 0.078\n",
      "Training: Epoch 121, Batch 53, Loss: 0.077\n",
      "Training: Epoch 121, Batch 54, Loss: 0.059\n",
      "Training: Epoch 121, Batch 55, Loss: 0.078\n",
      "Training: Epoch 121, Batch 56, Loss: 0.069\n",
      "Training: Epoch 121, Batch 57, Loss: 0.076\n",
      "Training: Epoch 121, Batch 58, Loss: 0.088\n",
      "Training: Epoch 121, Batch 59, Loss: 0.09\n",
      "Val: Epoch 121, Loss: 0.284\n",
      "Training: Epoch 122, Batch 0, Loss: 0.071\n",
      "Training: Epoch 122, Batch 1, Loss: 0.07\n",
      "Training: Epoch 122, Batch 2, Loss: 0.075\n",
      "Training: Epoch 122, Batch 3, Loss: 0.076\n",
      "Training: Epoch 122, Batch 4, Loss: 0.092\n",
      "Training: Epoch 122, Batch 5, Loss: 0.058\n",
      "Training: Epoch 122, Batch 6, Loss: 0.085\n",
      "Training: Epoch 122, Batch 7, Loss: 0.069\n",
      "Training: Epoch 122, Batch 8, Loss: 0.06\n",
      "Training: Epoch 122, Batch 9, Loss: 0.08\n",
      "Training: Epoch 122, Batch 10, Loss: 0.073\n",
      "Training: Epoch 122, Batch 11, Loss: 0.076\n",
      "Training: Epoch 122, Batch 12, Loss: 0.073\n",
      "Training: Epoch 122, Batch 13, Loss: 0.071\n",
      "Training: Epoch 122, Batch 14, Loss: 0.067\n",
      "Training: Epoch 122, Batch 15, Loss: 0.062\n",
      "Training: Epoch 122, Batch 16, Loss: 0.056\n",
      "Training: Epoch 122, Batch 17, Loss: 0.071\n",
      "Training: Epoch 122, Batch 18, Loss: 0.072\n",
      "Training: Epoch 122, Batch 19, Loss: 0.072\n",
      "Training: Epoch 122, Batch 20, Loss: 0.063\n",
      "Training: Epoch 122, Batch 21, Loss: 0.067\n",
      "Training: Epoch 122, Batch 22, Loss: 0.069\n",
      "Training: Epoch 122, Batch 23, Loss: 0.074\n",
      "Training: Epoch 122, Batch 24, Loss: 0.076\n",
      "Training: Epoch 122, Batch 25, Loss: 0.069\n",
      "Training: Epoch 122, Batch 26, Loss: 0.062\n",
      "Training: Epoch 122, Batch 27, Loss: 0.067\n",
      "Training: Epoch 122, Batch 28, Loss: 0.077\n",
      "Training: Epoch 122, Batch 29, Loss: 0.08\n",
      "Training: Epoch 122, Batch 30, Loss: 0.081\n",
      "Training: Epoch 122, Batch 31, Loss: 0.081\n",
      "Training: Epoch 122, Batch 32, Loss: 0.077\n",
      "Training: Epoch 122, Batch 33, Loss: 0.06\n",
      "Training: Epoch 122, Batch 34, Loss: 0.064\n",
      "Training: Epoch 122, Batch 35, Loss: 0.069\n",
      "Training: Epoch 122, Batch 36, Loss: 0.081\n",
      "Training: Epoch 122, Batch 37, Loss: 0.062\n",
      "Training: Epoch 122, Batch 38, Loss: 0.076\n",
      "Training: Epoch 122, Batch 39, Loss: 0.087\n",
      "Training: Epoch 122, Batch 40, Loss: 0.087\n",
      "Training: Epoch 122, Batch 41, Loss: 0.074\n",
      "Training: Epoch 122, Batch 42, Loss: 0.069\n",
      "Training: Epoch 122, Batch 43, Loss: 0.082\n",
      "Training: Epoch 122, Batch 44, Loss: 0.067\n",
      "Training: Epoch 122, Batch 45, Loss: 0.074\n",
      "Training: Epoch 122, Batch 46, Loss: 0.068\n",
      "Training: Epoch 122, Batch 47, Loss: 0.069\n",
      "Training: Epoch 122, Batch 48, Loss: 0.068\n",
      "Training: Epoch 122, Batch 49, Loss: 0.077\n",
      "Training: Epoch 122, Batch 50, Loss: 0.087\n",
      "Training: Epoch 122, Batch 51, Loss: 0.081\n",
      "Training: Epoch 122, Batch 52, Loss: 0.067\n",
      "Training: Epoch 122, Batch 53, Loss: 0.057\n",
      "Training: Epoch 122, Batch 54, Loss: 0.073\n",
      "Training: Epoch 122, Batch 55, Loss: 0.079\n",
      "Training: Epoch 122, Batch 56, Loss: 0.083\n",
      "Training: Epoch 122, Batch 57, Loss: 0.074\n",
      "Training: Epoch 122, Batch 58, Loss: 0.075\n",
      "Training: Epoch 122, Batch 59, Loss: 0.09\n",
      "Val: Epoch 122, Loss: 0.283\n",
      "Training: Epoch 123, Batch 0, Loss: 0.089\n",
      "Training: Epoch 123, Batch 1, Loss: 0.058\n",
      "Training: Epoch 123, Batch 2, Loss: 0.088\n",
      "Training: Epoch 123, Batch 3, Loss: 0.075\n",
      "Training: Epoch 123, Batch 4, Loss: 0.095\n",
      "Training: Epoch 123, Batch 5, Loss: 0.076\n",
      "Training: Epoch 123, Batch 6, Loss: 0.066\n",
      "Training: Epoch 123, Batch 7, Loss: 0.063\n",
      "Training: Epoch 123, Batch 8, Loss: 0.071\n",
      "Training: Epoch 123, Batch 9, Loss: 0.072\n",
      "Training: Epoch 123, Batch 10, Loss: 0.075\n",
      "Training: Epoch 123, Batch 11, Loss: 0.073\n",
      "Training: Epoch 123, Batch 12, Loss: 0.076\n",
      "Training: Epoch 123, Batch 13, Loss: 0.078\n",
      "Training: Epoch 123, Batch 14, Loss: 0.086\n",
      "Training: Epoch 123, Batch 15, Loss: 0.076\n",
      "Training: Epoch 123, Batch 16, Loss: 0.076\n",
      "Training: Epoch 123, Batch 17, Loss: 0.064\n",
      "Training: Epoch 123, Batch 18, Loss: 0.073\n",
      "Training: Epoch 123, Batch 19, Loss: 0.084\n",
      "Training: Epoch 123, Batch 20, Loss: 0.076\n",
      "Training: Epoch 123, Batch 21, Loss: 0.064\n",
      "Training: Epoch 123, Batch 22, Loss: 0.062\n",
      "Training: Epoch 123, Batch 23, Loss: 0.063\n",
      "Training: Epoch 123, Batch 24, Loss: 0.079\n",
      "Training: Epoch 123, Batch 25, Loss: 0.082\n",
      "Training: Epoch 123, Batch 26, Loss: 0.068\n",
      "Training: Epoch 123, Batch 27, Loss: 0.087\n",
      "Training: Epoch 123, Batch 28, Loss: 0.075\n",
      "Training: Epoch 123, Batch 29, Loss: 0.069\n",
      "Training: Epoch 123, Batch 30, Loss: 0.074\n",
      "Training: Epoch 123, Batch 31, Loss: 0.077\n",
      "Training: Epoch 123, Batch 32, Loss: 0.059\n",
      "Training: Epoch 123, Batch 33, Loss: 0.06\n",
      "Training: Epoch 123, Batch 34, Loss: 0.073\n",
      "Training: Epoch 123, Batch 35, Loss: 0.067\n",
      "Training: Epoch 123, Batch 36, Loss: 0.064\n",
      "Training: Epoch 123, Batch 37, Loss: 0.065\n",
      "Training: Epoch 123, Batch 38, Loss: 0.08\n",
      "Training: Epoch 123, Batch 39, Loss: 0.086\n",
      "Training: Epoch 123, Batch 40, Loss: 0.072\n",
      "Training: Epoch 123, Batch 41, Loss: 0.078\n",
      "Training: Epoch 123, Batch 42, Loss: 0.075\n",
      "Training: Epoch 123, Batch 43, Loss: 0.07\n",
      "Training: Epoch 123, Batch 44, Loss: 0.065\n",
      "Training: Epoch 123, Batch 45, Loss: 0.071\n",
      "Training: Epoch 123, Batch 46, Loss: 0.071\n",
      "Training: Epoch 123, Batch 47, Loss: 0.083\n",
      "Training: Epoch 123, Batch 48, Loss: 0.062\n",
      "Training: Epoch 123, Batch 49, Loss: 0.075\n",
      "Training: Epoch 123, Batch 50, Loss: 0.06\n",
      "Training: Epoch 123, Batch 51, Loss: 0.069\n",
      "Training: Epoch 123, Batch 52, Loss: 0.077\n",
      "Training: Epoch 123, Batch 53, Loss: 0.063\n",
      "Training: Epoch 123, Batch 54, Loss: 0.078\n",
      "Training: Epoch 123, Batch 55, Loss: 0.063\n",
      "Training: Epoch 123, Batch 56, Loss: 0.075\n",
      "Training: Epoch 123, Batch 57, Loss: 0.066\n",
      "Training: Epoch 123, Batch 58, Loss: 0.104\n",
      "Training: Epoch 123, Batch 59, Loss: 0.074\n",
      "Val: Epoch 123, Loss: 0.28\n",
      "Training: Epoch 124, Batch 0, Loss: 0.068\n",
      "Training: Epoch 124, Batch 1, Loss: 0.076\n",
      "Training: Epoch 124, Batch 2, Loss: 0.072\n",
      "Training: Epoch 124, Batch 3, Loss: 0.082\n",
      "Training: Epoch 124, Batch 4, Loss: 0.077\n",
      "Training: Epoch 124, Batch 5, Loss: 0.076\n",
      "Training: Epoch 124, Batch 6, Loss: 0.063\n",
      "Training: Epoch 124, Batch 7, Loss: 0.078\n",
      "Training: Epoch 124, Batch 8, Loss: 0.065\n",
      "Training: Epoch 124, Batch 9, Loss: 0.052\n",
      "Training: Epoch 124, Batch 10, Loss: 0.069\n",
      "Training: Epoch 124, Batch 11, Loss: 0.067\n",
      "Training: Epoch 124, Batch 12, Loss: 0.07\n",
      "Training: Epoch 124, Batch 13, Loss: 0.081\n",
      "Training: Epoch 124, Batch 14, Loss: 0.063\n",
      "Training: Epoch 124, Batch 15, Loss: 0.078\n",
      "Training: Epoch 124, Batch 16, Loss: 0.074\n",
      "Training: Epoch 124, Batch 17, Loss: 0.061\n",
      "Training: Epoch 124, Batch 18, Loss: 0.069\n",
      "Training: Epoch 124, Batch 19, Loss: 0.079\n",
      "Training: Epoch 124, Batch 20, Loss: 0.075\n",
      "Training: Epoch 124, Batch 21, Loss: 0.095\n",
      "Training: Epoch 124, Batch 22, Loss: 0.07\n",
      "Training: Epoch 124, Batch 23, Loss: 0.08\n",
      "Training: Epoch 124, Batch 24, Loss: 0.084\n",
      "Training: Epoch 124, Batch 25, Loss: 0.1\n",
      "Training: Epoch 124, Batch 26, Loss: 0.056\n",
      "Training: Epoch 124, Batch 27, Loss: 0.091\n",
      "Training: Epoch 124, Batch 28, Loss: 0.063\n",
      "Training: Epoch 124, Batch 29, Loss: 0.069\n",
      "Training: Epoch 124, Batch 30, Loss: 0.075\n",
      "Training: Epoch 124, Batch 31, Loss: 0.093\n",
      "Training: Epoch 124, Batch 32, Loss: 0.079\n",
      "Training: Epoch 124, Batch 33, Loss: 0.085\n",
      "Training: Epoch 124, Batch 34, Loss: 0.071\n",
      "Training: Epoch 124, Batch 35, Loss: 0.104\n",
      "Training: Epoch 124, Batch 36, Loss: 0.077\n",
      "Training: Epoch 124, Batch 37, Loss: 0.07\n",
      "Training: Epoch 124, Batch 38, Loss: 0.071\n",
      "Training: Epoch 124, Batch 39, Loss: 0.089\n",
      "Training: Epoch 124, Batch 40, Loss: 0.086\n",
      "Training: Epoch 124, Batch 41, Loss: 0.066\n",
      "Training: Epoch 124, Batch 42, Loss: 0.067\n",
      "Training: Epoch 124, Batch 43, Loss: 0.084\n",
      "Training: Epoch 124, Batch 44, Loss: 0.074\n",
      "Training: Epoch 124, Batch 45, Loss: 0.082\n",
      "Training: Epoch 124, Batch 46, Loss: 0.083\n",
      "Training: Epoch 124, Batch 47, Loss: 0.063\n",
      "Training: Epoch 124, Batch 48, Loss: 0.064\n",
      "Training: Epoch 124, Batch 49, Loss: 0.086\n",
      "Training: Epoch 124, Batch 50, Loss: 0.092\n",
      "Training: Epoch 124, Batch 51, Loss: 0.062\n",
      "Training: Epoch 124, Batch 52, Loss: 0.082\n",
      "Training: Epoch 124, Batch 53, Loss: 0.068\n",
      "Training: Epoch 124, Batch 54, Loss: 0.061\n",
      "Training: Epoch 124, Batch 55, Loss: 0.055\n",
      "Training: Epoch 124, Batch 56, Loss: 0.062\n",
      "Training: Epoch 124, Batch 57, Loss: 0.064\n",
      "Training: Epoch 124, Batch 58, Loss: 0.069\n",
      "Training: Epoch 124, Batch 59, Loss: 0.062\n",
      "Val: Epoch 124, Loss: 0.272\n",
      "Training: Epoch 125, Batch 0, Loss: 0.072\n",
      "Training: Epoch 125, Batch 1, Loss: 0.068\n",
      "Training: Epoch 125, Batch 2, Loss: 0.07\n",
      "Training: Epoch 125, Batch 3, Loss: 0.072\n",
      "Training: Epoch 125, Batch 4, Loss: 0.067\n",
      "Training: Epoch 125, Batch 5, Loss: 0.062\n",
      "Training: Epoch 125, Batch 6, Loss: 0.067\n",
      "Training: Epoch 125, Batch 7, Loss: 0.083\n",
      "Training: Epoch 125, Batch 8, Loss: 0.063\n",
      "Training: Epoch 125, Batch 9, Loss: 0.07\n",
      "Training: Epoch 125, Batch 10, Loss: 0.088\n",
      "Training: Epoch 125, Batch 11, Loss: 0.066\n",
      "Training: Epoch 125, Batch 12, Loss: 0.086\n",
      "Training: Epoch 125, Batch 13, Loss: 0.092\n",
      "Training: Epoch 125, Batch 14, Loss: 0.075\n",
      "Training: Epoch 125, Batch 15, Loss: 0.087\n",
      "Training: Epoch 125, Batch 16, Loss: 0.096\n",
      "Training: Epoch 125, Batch 17, Loss: 0.095\n",
      "Training: Epoch 125, Batch 18, Loss: 0.084\n",
      "Training: Epoch 125, Batch 19, Loss: 0.074\n",
      "Training: Epoch 125, Batch 20, Loss: 0.088\n",
      "Training: Epoch 125, Batch 21, Loss: 0.101\n",
      "Training: Epoch 125, Batch 22, Loss: 0.063\n",
      "Training: Epoch 125, Batch 23, Loss: 0.068\n",
      "Training: Epoch 125, Batch 24, Loss: 0.082\n",
      "Training: Epoch 125, Batch 25, Loss: 0.078\n",
      "Training: Epoch 125, Batch 26, Loss: 0.07\n",
      "Training: Epoch 125, Batch 27, Loss: 0.068\n",
      "Training: Epoch 125, Batch 28, Loss: 0.073\n",
      "Training: Epoch 125, Batch 29, Loss: 0.07\n",
      "Training: Epoch 125, Batch 30, Loss: 0.063\n",
      "Training: Epoch 125, Batch 31, Loss: 0.064\n",
      "Training: Epoch 125, Batch 32, Loss: 0.062\n",
      "Training: Epoch 125, Batch 33, Loss: 0.069\n",
      "Training: Epoch 125, Batch 34, Loss: 0.077\n",
      "Training: Epoch 125, Batch 35, Loss: 0.057\n",
      "Training: Epoch 125, Batch 36, Loss: 0.088\n",
      "Training: Epoch 125, Batch 37, Loss: 0.066\n",
      "Training: Epoch 125, Batch 38, Loss: 0.079\n",
      "Training: Epoch 125, Batch 39, Loss: 0.065\n",
      "Training: Epoch 125, Batch 40, Loss: 0.076\n",
      "Training: Epoch 125, Batch 41, Loss: 0.071\n",
      "Training: Epoch 125, Batch 42, Loss: 0.074\n",
      "Training: Epoch 125, Batch 43, Loss: 0.061\n",
      "Training: Epoch 125, Batch 44, Loss: 0.07\n",
      "Training: Epoch 125, Batch 45, Loss: 0.058\n",
      "Training: Epoch 125, Batch 46, Loss: 0.075\n",
      "Training: Epoch 125, Batch 47, Loss: 0.085\n",
      "Training: Epoch 125, Batch 48, Loss: 0.067\n",
      "Training: Epoch 125, Batch 49, Loss: 0.078\n",
      "Training: Epoch 125, Batch 50, Loss: 0.069\n",
      "Training: Epoch 125, Batch 51, Loss: 0.069\n",
      "Training: Epoch 125, Batch 52, Loss: 0.067\n",
      "Training: Epoch 125, Batch 53, Loss: 0.089\n",
      "Training: Epoch 125, Batch 54, Loss: 0.067\n",
      "Training: Epoch 125, Batch 55, Loss: 0.072\n",
      "Training: Epoch 125, Batch 56, Loss: 0.087\n",
      "Training: Epoch 125, Batch 57, Loss: 0.062\n",
      "Training: Epoch 125, Batch 58, Loss: 0.074\n",
      "Training: Epoch 125, Batch 59, Loss: 0.089\n",
      "Val: Epoch 125, Loss: 0.285\n",
      "Training: Epoch 126, Batch 0, Loss: 0.077\n",
      "Training: Epoch 126, Batch 1, Loss: 0.071\n",
      "Training: Epoch 126, Batch 2, Loss: 0.055\n",
      "Training: Epoch 126, Batch 3, Loss: 0.082\n",
      "Training: Epoch 126, Batch 4, Loss: 0.07\n",
      "Training: Epoch 126, Batch 5, Loss: 0.079\n",
      "Training: Epoch 126, Batch 6, Loss: 0.073\n",
      "Training: Epoch 126, Batch 7, Loss: 0.066\n",
      "Training: Epoch 126, Batch 8, Loss: 0.053\n",
      "Training: Epoch 126, Batch 9, Loss: 0.075\n",
      "Training: Epoch 126, Batch 10, Loss: 0.067\n",
      "Training: Epoch 126, Batch 11, Loss: 0.077\n",
      "Training: Epoch 126, Batch 12, Loss: 0.067\n",
      "Training: Epoch 126, Batch 13, Loss: 0.071\n",
      "Training: Epoch 126, Batch 14, Loss: 0.062\n",
      "Training: Epoch 126, Batch 15, Loss: 0.072\n",
      "Training: Epoch 126, Batch 16, Loss: 0.093\n",
      "Training: Epoch 126, Batch 17, Loss: 0.076\n",
      "Training: Epoch 126, Batch 18, Loss: 0.069\n",
      "Training: Epoch 126, Batch 19, Loss: 0.072\n",
      "Training: Epoch 126, Batch 20, Loss: 0.077\n",
      "Training: Epoch 126, Batch 21, Loss: 0.055\n",
      "Training: Epoch 126, Batch 22, Loss: 0.067\n",
      "Training: Epoch 126, Batch 23, Loss: 0.061\n",
      "Training: Epoch 126, Batch 24, Loss: 0.063\n",
      "Training: Epoch 126, Batch 25, Loss: 0.066\n",
      "Training: Epoch 126, Batch 26, Loss: 0.065\n",
      "Training: Epoch 126, Batch 27, Loss: 0.071\n",
      "Training: Epoch 126, Batch 28, Loss: 0.077\n",
      "Training: Epoch 126, Batch 29, Loss: 0.079\n",
      "Training: Epoch 126, Batch 30, Loss: 0.069\n",
      "Training: Epoch 126, Batch 31, Loss: 0.078\n",
      "Training: Epoch 126, Batch 32, Loss: 0.065\n",
      "Training: Epoch 126, Batch 33, Loss: 0.061\n",
      "Training: Epoch 126, Batch 34, Loss: 0.079\n",
      "Training: Epoch 126, Batch 35, Loss: 0.079\n",
      "Training: Epoch 126, Batch 36, Loss: 0.06\n",
      "Training: Epoch 126, Batch 37, Loss: 0.085\n",
      "Training: Epoch 126, Batch 38, Loss: 0.079\n",
      "Training: Epoch 126, Batch 39, Loss: 0.062\n",
      "Training: Epoch 126, Batch 40, Loss: 0.064\n",
      "Training: Epoch 126, Batch 41, Loss: 0.071\n",
      "Training: Epoch 126, Batch 42, Loss: 0.079\n",
      "Training: Epoch 126, Batch 43, Loss: 0.072\n",
      "Training: Epoch 126, Batch 44, Loss: 0.072\n",
      "Training: Epoch 126, Batch 45, Loss: 0.07\n",
      "Training: Epoch 126, Batch 46, Loss: 0.103\n",
      "Training: Epoch 126, Batch 47, Loss: 0.07\n",
      "Training: Epoch 126, Batch 48, Loss: 0.061\n",
      "Training: Epoch 126, Batch 49, Loss: 0.08\n",
      "Training: Epoch 126, Batch 50, Loss: 0.086\n",
      "Training: Epoch 126, Batch 51, Loss: 0.076\n",
      "Training: Epoch 126, Batch 52, Loss: 0.068\n",
      "Training: Epoch 126, Batch 53, Loss: 0.071\n",
      "Training: Epoch 126, Batch 54, Loss: 0.072\n",
      "Training: Epoch 126, Batch 55, Loss: 0.079\n",
      "Training: Epoch 126, Batch 56, Loss: 0.106\n",
      "Training: Epoch 126, Batch 57, Loss: 0.073\n",
      "Training: Epoch 126, Batch 58, Loss: 0.058\n",
      "Training: Epoch 126, Batch 59, Loss: 0.072\n",
      "Val: Epoch 126, Loss: 0.295\n",
      "Training: Epoch 127, Batch 0, Loss: 0.085\n",
      "Training: Epoch 127, Batch 1, Loss: 0.061\n",
      "Training: Epoch 127, Batch 2, Loss: 0.064\n",
      "Training: Epoch 127, Batch 3, Loss: 0.067\n",
      "Training: Epoch 127, Batch 4, Loss: 0.085\n",
      "Training: Epoch 127, Batch 5, Loss: 0.07\n",
      "Training: Epoch 127, Batch 6, Loss: 0.063\n",
      "Training: Epoch 127, Batch 7, Loss: 0.067\n",
      "Training: Epoch 127, Batch 8, Loss: 0.061\n",
      "Training: Epoch 127, Batch 9, Loss: 0.068\n",
      "Training: Epoch 127, Batch 10, Loss: 0.067\n",
      "Training: Epoch 127, Batch 11, Loss: 0.057\n",
      "Training: Epoch 127, Batch 12, Loss: 0.07\n",
      "Training: Epoch 127, Batch 13, Loss: 0.068\n",
      "Training: Epoch 127, Batch 14, Loss: 0.077\n",
      "Training: Epoch 127, Batch 15, Loss: 0.068\n",
      "Training: Epoch 127, Batch 16, Loss: 0.081\n",
      "Training: Epoch 127, Batch 17, Loss: 0.07\n",
      "Training: Epoch 127, Batch 18, Loss: 0.074\n",
      "Training: Epoch 127, Batch 19, Loss: 0.064\n",
      "Training: Epoch 127, Batch 20, Loss: 0.073\n",
      "Training: Epoch 127, Batch 21, Loss: 0.07\n",
      "Training: Epoch 127, Batch 22, Loss: 0.076\n",
      "Training: Epoch 127, Batch 23, Loss: 0.062\n",
      "Training: Epoch 127, Batch 24, Loss: 0.075\n",
      "Training: Epoch 127, Batch 25, Loss: 0.062\n",
      "Training: Epoch 127, Batch 26, Loss: 0.067\n",
      "Training: Epoch 127, Batch 27, Loss: 0.084\n",
      "Training: Epoch 127, Batch 28, Loss: 0.059\n",
      "Training: Epoch 127, Batch 29, Loss: 0.087\n",
      "Training: Epoch 127, Batch 30, Loss: 0.093\n",
      "Training: Epoch 127, Batch 31, Loss: 0.068\n",
      "Training: Epoch 127, Batch 32, Loss: 0.074\n",
      "Training: Epoch 127, Batch 33, Loss: 0.074\n",
      "Training: Epoch 127, Batch 34, Loss: 0.08\n",
      "Training: Epoch 127, Batch 35, Loss: 0.062\n",
      "Training: Epoch 127, Batch 36, Loss: 0.063\n",
      "Training: Epoch 127, Batch 37, Loss: 0.07\n",
      "Training: Epoch 127, Batch 38, Loss: 0.078\n",
      "Training: Epoch 127, Batch 39, Loss: 0.072\n",
      "Training: Epoch 127, Batch 40, Loss: 0.077\n",
      "Training: Epoch 127, Batch 41, Loss: 0.094\n",
      "Training: Epoch 127, Batch 42, Loss: 0.059\n",
      "Training: Epoch 127, Batch 43, Loss: 0.068\n",
      "Training: Epoch 127, Batch 44, Loss: 0.081\n",
      "Training: Epoch 127, Batch 45, Loss: 0.071\n",
      "Training: Epoch 127, Batch 46, Loss: 0.07\n",
      "Training: Epoch 127, Batch 47, Loss: 0.067\n",
      "Training: Epoch 127, Batch 48, Loss: 0.069\n",
      "Training: Epoch 127, Batch 49, Loss: 0.082\n",
      "Training: Epoch 127, Batch 50, Loss: 0.069\n",
      "Training: Epoch 127, Batch 51, Loss: 0.079\n",
      "Training: Epoch 127, Batch 52, Loss: 0.08\n",
      "Training: Epoch 127, Batch 53, Loss: 0.077\n",
      "Training: Epoch 127, Batch 54, Loss: 0.061\n",
      "Training: Epoch 127, Batch 55, Loss: 0.072\n",
      "Training: Epoch 127, Batch 56, Loss: 0.075\n",
      "Training: Epoch 127, Batch 57, Loss: 0.064\n",
      "Training: Epoch 127, Batch 58, Loss: 0.067\n",
      "Training: Epoch 127, Batch 59, Loss: 0.075\n",
      "Val: Epoch 127, Loss: 0.28\n",
      "Training: Epoch 128, Batch 0, Loss: 0.067\n",
      "Training: Epoch 128, Batch 1, Loss: 0.072\n",
      "Training: Epoch 128, Batch 2, Loss: 0.085\n",
      "Training: Epoch 128, Batch 3, Loss: 0.061\n",
      "Training: Epoch 128, Batch 4, Loss: 0.062\n",
      "Training: Epoch 128, Batch 5, Loss: 0.071\n",
      "Training: Epoch 128, Batch 6, Loss: 0.055\n",
      "Training: Epoch 128, Batch 7, Loss: 0.077\n",
      "Training: Epoch 128, Batch 8, Loss: 0.07\n",
      "Training: Epoch 128, Batch 9, Loss: 0.06\n",
      "Training: Epoch 128, Batch 10, Loss: 0.069\n",
      "Training: Epoch 128, Batch 11, Loss: 0.074\n",
      "Training: Epoch 128, Batch 12, Loss: 0.069\n",
      "Training: Epoch 128, Batch 13, Loss: 0.079\n",
      "Training: Epoch 128, Batch 14, Loss: 0.059\n",
      "Training: Epoch 128, Batch 15, Loss: 0.062\n",
      "Training: Epoch 128, Batch 16, Loss: 0.081\n",
      "Training: Epoch 128, Batch 17, Loss: 0.065\n",
      "Training: Epoch 128, Batch 18, Loss: 0.067\n",
      "Training: Epoch 128, Batch 19, Loss: 0.083\n",
      "Training: Epoch 128, Batch 20, Loss: 0.06\n",
      "Training: Epoch 128, Batch 21, Loss: 0.065\n",
      "Training: Epoch 128, Batch 22, Loss: 0.082\n",
      "Training: Epoch 128, Batch 23, Loss: 0.075\n",
      "Training: Epoch 128, Batch 24, Loss: 0.081\n",
      "Training: Epoch 128, Batch 25, Loss: 0.074\n",
      "Training: Epoch 128, Batch 26, Loss: 0.071\n",
      "Training: Epoch 128, Batch 27, Loss: 0.08\n",
      "Training: Epoch 128, Batch 28, Loss: 0.073\n",
      "Training: Epoch 128, Batch 29, Loss: 0.063\n",
      "Training: Epoch 128, Batch 30, Loss: 0.061\n",
      "Training: Epoch 128, Batch 31, Loss: 0.067\n",
      "Training: Epoch 128, Batch 32, Loss: 0.058\n",
      "Training: Epoch 128, Batch 33, Loss: 0.058\n",
      "Training: Epoch 128, Batch 34, Loss: 0.066\n",
      "Training: Epoch 128, Batch 35, Loss: 0.09\n",
      "Training: Epoch 128, Batch 36, Loss: 0.097\n",
      "Training: Epoch 128, Batch 37, Loss: 0.085\n",
      "Training: Epoch 128, Batch 38, Loss: 0.058\n",
      "Training: Epoch 128, Batch 39, Loss: 0.066\n",
      "Training: Epoch 128, Batch 40, Loss: 0.062\n",
      "Training: Epoch 128, Batch 41, Loss: 0.08\n",
      "Training: Epoch 128, Batch 42, Loss: 0.069\n",
      "Training: Epoch 128, Batch 43, Loss: 0.072\n",
      "Training: Epoch 128, Batch 44, Loss: 0.068\n",
      "Training: Epoch 128, Batch 45, Loss: 0.062\n",
      "Training: Epoch 128, Batch 46, Loss: 0.058\n",
      "Training: Epoch 128, Batch 47, Loss: 0.082\n",
      "Training: Epoch 128, Batch 48, Loss: 0.083\n",
      "Training: Epoch 128, Batch 49, Loss: 0.077\n",
      "Training: Epoch 128, Batch 50, Loss: 0.064\n",
      "Training: Epoch 128, Batch 51, Loss: 0.072\n",
      "Training: Epoch 128, Batch 52, Loss: 0.086\n",
      "Training: Epoch 128, Batch 53, Loss: 0.076\n",
      "Training: Epoch 128, Batch 54, Loss: 0.081\n",
      "Training: Epoch 128, Batch 55, Loss: 0.069\n",
      "Training: Epoch 128, Batch 56, Loss: 0.06\n",
      "Training: Epoch 128, Batch 57, Loss: 0.082\n",
      "Training: Epoch 128, Batch 58, Loss: 0.076\n",
      "Training: Epoch 128, Batch 59, Loss: 0.076\n",
      "Val: Epoch 128, Loss: 0.276\n",
      "Training: Epoch 129, Batch 0, Loss: 0.069\n",
      "Training: Epoch 129, Batch 1, Loss: 0.06\n",
      "Training: Epoch 129, Batch 2, Loss: 0.077\n",
      "Training: Epoch 129, Batch 3, Loss: 0.068\n",
      "Training: Epoch 129, Batch 4, Loss: 0.068\n",
      "Training: Epoch 129, Batch 5, Loss: 0.076\n",
      "Training: Epoch 129, Batch 6, Loss: 0.064\n",
      "Training: Epoch 129, Batch 7, Loss: 0.077\n",
      "Training: Epoch 129, Batch 8, Loss: 0.094\n",
      "Training: Epoch 129, Batch 9, Loss: 0.06\n",
      "Training: Epoch 129, Batch 10, Loss: 0.083\n",
      "Training: Epoch 129, Batch 11, Loss: 0.067\n",
      "Training: Epoch 129, Batch 12, Loss: 0.068\n",
      "Training: Epoch 129, Batch 13, Loss: 0.087\n",
      "Training: Epoch 129, Batch 14, Loss: 0.067\n",
      "Training: Epoch 129, Batch 15, Loss: 0.075\n",
      "Training: Epoch 129, Batch 16, Loss: 0.075\n",
      "Training: Epoch 129, Batch 17, Loss: 0.07\n",
      "Training: Epoch 129, Batch 18, Loss: 0.074\n",
      "Training: Epoch 129, Batch 19, Loss: 0.074\n",
      "Training: Epoch 129, Batch 20, Loss: 0.076\n",
      "Training: Epoch 129, Batch 21, Loss: 0.078\n",
      "Training: Epoch 129, Batch 22, Loss: 0.063\n",
      "Training: Epoch 129, Batch 23, Loss: 0.062\n",
      "Training: Epoch 129, Batch 24, Loss: 0.053\n",
      "Training: Epoch 129, Batch 25, Loss: 0.063\n",
      "Training: Epoch 129, Batch 26, Loss: 0.077\n",
      "Training: Epoch 129, Batch 27, Loss: 0.053\n",
      "Training: Epoch 129, Batch 28, Loss: 0.072\n",
      "Training: Epoch 129, Batch 29, Loss: 0.08\n",
      "Training: Epoch 129, Batch 30, Loss: 0.067\n",
      "Training: Epoch 129, Batch 31, Loss: 0.074\n",
      "Training: Epoch 129, Batch 32, Loss: 0.056\n",
      "Training: Epoch 129, Batch 33, Loss: 0.068\n",
      "Training: Epoch 129, Batch 34, Loss: 0.087\n",
      "Training: Epoch 129, Batch 35, Loss: 0.078\n",
      "Training: Epoch 129, Batch 36, Loss: 0.072\n",
      "Training: Epoch 129, Batch 37, Loss: 0.069\n",
      "Training: Epoch 129, Batch 38, Loss: 0.066\n",
      "Training: Epoch 129, Batch 39, Loss: 0.062\n",
      "Training: Epoch 129, Batch 40, Loss: 0.067\n",
      "Training: Epoch 129, Batch 41, Loss: 0.088\n",
      "Training: Epoch 129, Batch 42, Loss: 0.081\n",
      "Training: Epoch 129, Batch 43, Loss: 0.065\n",
      "Training: Epoch 129, Batch 44, Loss: 0.073\n",
      "Training: Epoch 129, Batch 45, Loss: 0.069\n",
      "Training: Epoch 129, Batch 46, Loss: 0.081\n",
      "Training: Epoch 129, Batch 47, Loss: 0.075\n",
      "Training: Epoch 129, Batch 48, Loss: 0.081\n",
      "Training: Epoch 129, Batch 49, Loss: 0.085\n",
      "Training: Epoch 129, Batch 50, Loss: 0.058\n",
      "Training: Epoch 129, Batch 51, Loss: 0.072\n",
      "Training: Epoch 129, Batch 52, Loss: 0.08\n",
      "Training: Epoch 129, Batch 53, Loss: 0.072\n",
      "Training: Epoch 129, Batch 54, Loss: 0.086\n",
      "Training: Epoch 129, Batch 55, Loss: 0.065\n",
      "Training: Epoch 129, Batch 56, Loss: 0.069\n",
      "Training: Epoch 129, Batch 57, Loss: 0.056\n",
      "Training: Epoch 129, Batch 58, Loss: 0.074\n",
      "Training: Epoch 129, Batch 59, Loss: 0.075\n",
      "Val: Epoch 129, Loss: 0.273\n",
      "Training: Epoch 130, Batch 0, Loss: 0.072\n",
      "Training: Epoch 130, Batch 1, Loss: 0.089\n",
      "Training: Epoch 130, Batch 2, Loss: 0.075\n",
      "Training: Epoch 130, Batch 3, Loss: 0.064\n",
      "Training: Epoch 130, Batch 4, Loss: 0.071\n",
      "Training: Epoch 130, Batch 5, Loss: 0.075\n",
      "Training: Epoch 130, Batch 6, Loss: 0.055\n",
      "Training: Epoch 130, Batch 7, Loss: 0.092\n",
      "Training: Epoch 130, Batch 8, Loss: 0.078\n",
      "Training: Epoch 130, Batch 9, Loss: 0.06\n",
      "Training: Epoch 130, Batch 10, Loss: 0.059\n",
      "Training: Epoch 130, Batch 11, Loss: 0.095\n",
      "Training: Epoch 130, Batch 12, Loss: 0.072\n",
      "Training: Epoch 130, Batch 13, Loss: 0.067\n",
      "Training: Epoch 130, Batch 14, Loss: 0.068\n",
      "Training: Epoch 130, Batch 15, Loss: 0.074\n",
      "Training: Epoch 130, Batch 16, Loss: 0.058\n",
      "Training: Epoch 130, Batch 17, Loss: 0.071\n",
      "Training: Epoch 130, Batch 18, Loss: 0.076\n",
      "Training: Epoch 130, Batch 19, Loss: 0.065\n",
      "Training: Epoch 130, Batch 20, Loss: 0.084\n",
      "Training: Epoch 130, Batch 21, Loss: 0.067\n",
      "Training: Epoch 130, Batch 22, Loss: 0.068\n",
      "Training: Epoch 130, Batch 23, Loss: 0.075\n",
      "Training: Epoch 130, Batch 24, Loss: 0.084\n",
      "Training: Epoch 130, Batch 25, Loss: 0.059\n",
      "Training: Epoch 130, Batch 26, Loss: 0.071\n",
      "Training: Epoch 130, Batch 27, Loss: 0.074\n",
      "Training: Epoch 130, Batch 28, Loss: 0.064\n",
      "Training: Epoch 130, Batch 29, Loss: 0.071\n",
      "Training: Epoch 130, Batch 30, Loss: 0.068\n",
      "Training: Epoch 130, Batch 31, Loss: 0.066\n",
      "Training: Epoch 130, Batch 32, Loss: 0.07\n",
      "Training: Epoch 130, Batch 33, Loss: 0.062\n",
      "Training: Epoch 130, Batch 34, Loss: 0.073\n",
      "Training: Epoch 130, Batch 35, Loss: 0.054\n",
      "Training: Epoch 130, Batch 36, Loss: 0.077\n",
      "Training: Epoch 130, Batch 37, Loss: 0.064\n",
      "Training: Epoch 130, Batch 38, Loss: 0.075\n",
      "Training: Epoch 130, Batch 39, Loss: 0.061\n",
      "Training: Epoch 130, Batch 40, Loss: 0.07\n",
      "Training: Epoch 130, Batch 41, Loss: 0.08\n",
      "Training: Epoch 130, Batch 42, Loss: 0.063\n",
      "Training: Epoch 130, Batch 43, Loss: 0.068\n",
      "Training: Epoch 130, Batch 44, Loss: 0.054\n",
      "Training: Epoch 130, Batch 45, Loss: 0.065\n",
      "Training: Epoch 130, Batch 46, Loss: 0.077\n",
      "Training: Epoch 130, Batch 47, Loss: 0.088\n",
      "Training: Epoch 130, Batch 48, Loss: 0.053\n",
      "Training: Epoch 130, Batch 49, Loss: 0.064\n",
      "Training: Epoch 130, Batch 50, Loss: 0.078\n",
      "Training: Epoch 130, Batch 51, Loss: 0.097\n",
      "Training: Epoch 130, Batch 52, Loss: 0.059\n",
      "Training: Epoch 130, Batch 53, Loss: 0.072\n",
      "Training: Epoch 130, Batch 54, Loss: 0.07\n",
      "Training: Epoch 130, Batch 55, Loss: 0.07\n",
      "Training: Epoch 130, Batch 56, Loss: 0.07\n",
      "Training: Epoch 130, Batch 57, Loss: 0.071\n",
      "Training: Epoch 130, Batch 58, Loss: 0.063\n",
      "Training: Epoch 130, Batch 59, Loss: 0.074\n",
      "Val: Epoch 130, Loss: 0.275\n",
      "Training: Epoch 131, Batch 0, Loss: 0.077\n",
      "Training: Epoch 131, Batch 1, Loss: 0.082\n",
      "Training: Epoch 131, Batch 2, Loss: 0.059\n",
      "Training: Epoch 131, Batch 3, Loss: 0.065\n",
      "Training: Epoch 131, Batch 4, Loss: 0.078\n",
      "Training: Epoch 131, Batch 5, Loss: 0.054\n",
      "Training: Epoch 131, Batch 6, Loss: 0.067\n",
      "Training: Epoch 131, Batch 7, Loss: 0.084\n",
      "Training: Epoch 131, Batch 8, Loss: 0.079\n",
      "Training: Epoch 131, Batch 9, Loss: 0.056\n",
      "Training: Epoch 131, Batch 10, Loss: 0.068\n",
      "Training: Epoch 131, Batch 11, Loss: 0.073\n",
      "Training: Epoch 131, Batch 12, Loss: 0.051\n",
      "Training: Epoch 131, Batch 13, Loss: 0.081\n",
      "Training: Epoch 131, Batch 14, Loss: 0.078\n",
      "Training: Epoch 131, Batch 15, Loss: 0.06\n",
      "Training: Epoch 131, Batch 16, Loss: 0.064\n",
      "Training: Epoch 131, Batch 17, Loss: 0.069\n",
      "Training: Epoch 131, Batch 18, Loss: 0.084\n",
      "Training: Epoch 131, Batch 19, Loss: 0.056\n",
      "Training: Epoch 131, Batch 20, Loss: 0.064\n",
      "Training: Epoch 131, Batch 21, Loss: 0.068\n",
      "Training: Epoch 131, Batch 22, Loss: 0.088\n",
      "Training: Epoch 131, Batch 23, Loss: 0.072\n",
      "Training: Epoch 131, Batch 24, Loss: 0.069\n",
      "Training: Epoch 131, Batch 25, Loss: 0.068\n",
      "Training: Epoch 131, Batch 26, Loss: 0.079\n",
      "Training: Epoch 131, Batch 27, Loss: 0.071\n",
      "Training: Epoch 131, Batch 28, Loss: 0.057\n",
      "Training: Epoch 131, Batch 29, Loss: 0.069\n",
      "Training: Epoch 131, Batch 30, Loss: 0.07\n",
      "Training: Epoch 131, Batch 31, Loss: 0.059\n",
      "Training: Epoch 131, Batch 32, Loss: 0.073\n",
      "Training: Epoch 131, Batch 33, Loss: 0.069\n",
      "Training: Epoch 131, Batch 34, Loss: 0.082\n",
      "Training: Epoch 131, Batch 35, Loss: 0.075\n",
      "Training: Epoch 131, Batch 36, Loss: 0.068\n",
      "Training: Epoch 131, Batch 37, Loss: 0.072\n",
      "Training: Epoch 131, Batch 38, Loss: 0.057\n",
      "Training: Epoch 131, Batch 39, Loss: 0.07\n",
      "Training: Epoch 131, Batch 40, Loss: 0.073\n",
      "Training: Epoch 131, Batch 41, Loss: 0.09\n",
      "Training: Epoch 131, Batch 42, Loss: 0.093\n",
      "Training: Epoch 131, Batch 43, Loss: 0.063\n",
      "Training: Epoch 131, Batch 44, Loss: 0.072\n",
      "Training: Epoch 131, Batch 45, Loss: 0.066\n",
      "Training: Epoch 131, Batch 46, Loss: 0.078\n",
      "Training: Epoch 131, Batch 47, Loss: 0.072\n",
      "Training: Epoch 131, Batch 48, Loss: 0.074\n",
      "Training: Epoch 131, Batch 49, Loss: 0.072\n",
      "Training: Epoch 131, Batch 50, Loss: 0.062\n",
      "Training: Epoch 131, Batch 51, Loss: 0.077\n",
      "Training: Epoch 131, Batch 52, Loss: 0.081\n",
      "Training: Epoch 131, Batch 53, Loss: 0.078\n",
      "Training: Epoch 131, Batch 54, Loss: 0.064\n",
      "Training: Epoch 131, Batch 55, Loss: 0.057\n",
      "Training: Epoch 131, Batch 56, Loss: 0.072\n",
      "Training: Epoch 131, Batch 57, Loss: 0.063\n",
      "Training: Epoch 131, Batch 58, Loss: 0.062\n",
      "Training: Epoch 131, Batch 59, Loss: 0.072\n",
      "Val: Epoch 131, Loss: 0.284\n",
      "Training: Epoch 132, Batch 0, Loss: 0.07\n",
      "Training: Epoch 132, Batch 1, Loss: 0.075\n",
      "Training: Epoch 132, Batch 2, Loss: 0.076\n",
      "Training: Epoch 132, Batch 3, Loss: 0.08\n",
      "Training: Epoch 132, Batch 4, Loss: 0.071\n",
      "Training: Epoch 132, Batch 5, Loss: 0.065\n",
      "Training: Epoch 132, Batch 6, Loss: 0.075\n",
      "Training: Epoch 132, Batch 7, Loss: 0.07\n",
      "Training: Epoch 132, Batch 8, Loss: 0.076\n",
      "Training: Epoch 132, Batch 9, Loss: 0.057\n",
      "Training: Epoch 132, Batch 10, Loss: 0.063\n",
      "Training: Epoch 132, Batch 11, Loss: 0.092\n",
      "Training: Epoch 132, Batch 12, Loss: 0.058\n",
      "Training: Epoch 132, Batch 13, Loss: 0.06\n",
      "Training: Epoch 132, Batch 14, Loss: 0.059\n",
      "Training: Epoch 132, Batch 15, Loss: 0.07\n",
      "Training: Epoch 132, Batch 16, Loss: 0.075\n",
      "Training: Epoch 132, Batch 17, Loss: 0.059\n",
      "Training: Epoch 132, Batch 18, Loss: 0.063\n",
      "Training: Epoch 132, Batch 19, Loss: 0.068\n",
      "Training: Epoch 132, Batch 20, Loss: 0.07\n",
      "Training: Epoch 132, Batch 21, Loss: 0.079\n",
      "Training: Epoch 132, Batch 22, Loss: 0.082\n",
      "Training: Epoch 132, Batch 23, Loss: 0.069\n",
      "Training: Epoch 132, Batch 24, Loss: 0.068\n",
      "Training: Epoch 132, Batch 25, Loss: 0.07\n",
      "Training: Epoch 132, Batch 26, Loss: 0.07\n",
      "Training: Epoch 132, Batch 27, Loss: 0.071\n",
      "Training: Epoch 132, Batch 28, Loss: 0.075\n",
      "Training: Epoch 132, Batch 29, Loss: 0.072\n",
      "Training: Epoch 132, Batch 30, Loss: 0.065\n",
      "Training: Epoch 132, Batch 31, Loss: 0.058\n",
      "Training: Epoch 132, Batch 32, Loss: 0.079\n",
      "Training: Epoch 132, Batch 33, Loss: 0.063\n",
      "Training: Epoch 132, Batch 34, Loss: 0.062\n",
      "Training: Epoch 132, Batch 35, Loss: 0.061\n",
      "Training: Epoch 132, Batch 36, Loss: 0.058\n",
      "Training: Epoch 132, Batch 37, Loss: 0.071\n",
      "Training: Epoch 132, Batch 38, Loss: 0.073\n",
      "Training: Epoch 132, Batch 39, Loss: 0.072\n",
      "Training: Epoch 132, Batch 40, Loss: 0.066\n",
      "Training: Epoch 132, Batch 41, Loss: 0.082\n",
      "Training: Epoch 132, Batch 42, Loss: 0.073\n",
      "Training: Epoch 132, Batch 43, Loss: 0.073\n",
      "Training: Epoch 132, Batch 44, Loss: 0.06\n",
      "Training: Epoch 132, Batch 45, Loss: 0.072\n",
      "Training: Epoch 132, Batch 46, Loss: 0.092\n",
      "Training: Epoch 132, Batch 47, Loss: 0.058\n",
      "Training: Epoch 132, Batch 48, Loss: 0.065\n",
      "Training: Epoch 132, Batch 49, Loss: 0.071\n",
      "Training: Epoch 132, Batch 50, Loss: 0.064\n",
      "Training: Epoch 132, Batch 51, Loss: 0.068\n",
      "Training: Epoch 132, Batch 52, Loss: 0.074\n",
      "Training: Epoch 132, Batch 53, Loss: 0.081\n",
      "Training: Epoch 132, Batch 54, Loss: 0.064\n",
      "Training: Epoch 132, Batch 55, Loss: 0.069\n",
      "Training: Epoch 132, Batch 56, Loss: 0.065\n",
      "Training: Epoch 132, Batch 57, Loss: 0.065\n",
      "Training: Epoch 132, Batch 58, Loss: 0.087\n",
      "Training: Epoch 132, Batch 59, Loss: 0.054\n",
      "Val: Epoch 132, Loss: 0.302\n",
      "Training: Epoch 133, Batch 0, Loss: 0.079\n",
      "Training: Epoch 133, Batch 1, Loss: 0.058\n",
      "Training: Epoch 133, Batch 2, Loss: 0.068\n",
      "Training: Epoch 133, Batch 3, Loss: 0.062\n",
      "Training: Epoch 133, Batch 4, Loss: 0.076\n",
      "Training: Epoch 133, Batch 5, Loss: 0.069\n",
      "Training: Epoch 133, Batch 6, Loss: 0.078\n",
      "Training: Epoch 133, Batch 7, Loss: 0.057\n",
      "Training: Epoch 133, Batch 8, Loss: 0.089\n",
      "Training: Epoch 133, Batch 9, Loss: 0.08\n",
      "Training: Epoch 133, Batch 10, Loss: 0.068\n",
      "Training: Epoch 133, Batch 11, Loss: 0.07\n",
      "Training: Epoch 133, Batch 12, Loss: 0.068\n",
      "Training: Epoch 133, Batch 13, Loss: 0.057\n",
      "Training: Epoch 133, Batch 14, Loss: 0.074\n",
      "Training: Epoch 133, Batch 15, Loss: 0.064\n",
      "Training: Epoch 133, Batch 16, Loss: 0.101\n",
      "Training: Epoch 133, Batch 17, Loss: 0.06\n",
      "Training: Epoch 133, Batch 18, Loss: 0.063\n",
      "Training: Epoch 133, Batch 19, Loss: 0.092\n",
      "Training: Epoch 133, Batch 20, Loss: 0.06\n",
      "Training: Epoch 133, Batch 21, Loss: 0.054\n",
      "Training: Epoch 133, Batch 22, Loss: 0.06\n",
      "Training: Epoch 133, Batch 23, Loss: 0.081\n",
      "Training: Epoch 133, Batch 24, Loss: 0.084\n",
      "Training: Epoch 133, Batch 25, Loss: 0.071\n",
      "Training: Epoch 133, Batch 26, Loss: 0.073\n",
      "Training: Epoch 133, Batch 27, Loss: 0.063\n",
      "Training: Epoch 133, Batch 28, Loss: 0.051\n",
      "Training: Epoch 133, Batch 29, Loss: 0.054\n",
      "Training: Epoch 133, Batch 30, Loss: 0.076\n",
      "Training: Epoch 133, Batch 31, Loss: 0.085\n",
      "Training: Epoch 133, Batch 32, Loss: 0.052\n",
      "Training: Epoch 133, Batch 33, Loss: 0.067\n",
      "Training: Epoch 133, Batch 34, Loss: 0.064\n",
      "Training: Epoch 133, Batch 35, Loss: 0.069\n",
      "Training: Epoch 133, Batch 36, Loss: 0.068\n",
      "Training: Epoch 133, Batch 37, Loss: 0.061\n",
      "Training: Epoch 133, Batch 38, Loss: 0.06\n",
      "Training: Epoch 133, Batch 39, Loss: 0.067\n",
      "Training: Epoch 133, Batch 40, Loss: 0.065\n",
      "Training: Epoch 133, Batch 41, Loss: 0.074\n",
      "Training: Epoch 133, Batch 42, Loss: 0.062\n",
      "Training: Epoch 133, Batch 43, Loss: 0.086\n",
      "Training: Epoch 133, Batch 44, Loss: 0.066\n",
      "Training: Epoch 133, Batch 45, Loss: 0.073\n",
      "Training: Epoch 133, Batch 46, Loss: 0.066\n",
      "Training: Epoch 133, Batch 47, Loss: 0.064\n",
      "Training: Epoch 133, Batch 48, Loss: 0.09\n",
      "Training: Epoch 133, Batch 49, Loss: 0.068\n",
      "Training: Epoch 133, Batch 50, Loss: 0.085\n",
      "Training: Epoch 133, Batch 51, Loss: 0.068\n",
      "Training: Epoch 133, Batch 52, Loss: 0.057\n",
      "Training: Epoch 133, Batch 53, Loss: 0.064\n",
      "Training: Epoch 133, Batch 54, Loss: 0.076\n",
      "Training: Epoch 133, Batch 55, Loss: 0.075\n",
      "Training: Epoch 133, Batch 56, Loss: 0.071\n",
      "Training: Epoch 133, Batch 57, Loss: 0.074\n",
      "Training: Epoch 133, Batch 58, Loss: 0.073\n",
      "Training: Epoch 133, Batch 59, Loss: 0.067\n",
      "Val: Epoch 133, Loss: 0.286\n",
      "Training: Epoch 134, Batch 0, Loss: 0.08\n",
      "Training: Epoch 134, Batch 1, Loss: 0.064\n",
      "Training: Epoch 134, Batch 2, Loss: 0.055\n",
      "Training: Epoch 134, Batch 3, Loss: 0.056\n",
      "Training: Epoch 134, Batch 4, Loss: 0.071\n",
      "Training: Epoch 134, Batch 5, Loss: 0.076\n",
      "Training: Epoch 134, Batch 6, Loss: 0.067\n",
      "Training: Epoch 134, Batch 7, Loss: 0.069\n",
      "Training: Epoch 134, Batch 8, Loss: 0.06\n",
      "Training: Epoch 134, Batch 9, Loss: 0.069\n",
      "Training: Epoch 134, Batch 10, Loss: 0.081\n",
      "Training: Epoch 134, Batch 11, Loss: 0.085\n",
      "Training: Epoch 134, Batch 12, Loss: 0.068\n",
      "Training: Epoch 134, Batch 13, Loss: 0.073\n",
      "Training: Epoch 134, Batch 14, Loss: 0.054\n",
      "Training: Epoch 134, Batch 15, Loss: 0.062\n",
      "Training: Epoch 134, Batch 16, Loss: 0.077\n",
      "Training: Epoch 134, Batch 17, Loss: 0.089\n",
      "Training: Epoch 134, Batch 18, Loss: 0.066\n",
      "Training: Epoch 134, Batch 19, Loss: 0.085\n",
      "Training: Epoch 134, Batch 20, Loss: 0.073\n",
      "Training: Epoch 134, Batch 21, Loss: 0.09\n",
      "Training: Epoch 134, Batch 22, Loss: 0.056\n",
      "Training: Epoch 134, Batch 23, Loss: 0.07\n",
      "Training: Epoch 134, Batch 24, Loss: 0.052\n",
      "Training: Epoch 134, Batch 25, Loss: 0.075\n",
      "Training: Epoch 134, Batch 26, Loss: 0.074\n",
      "Training: Epoch 134, Batch 27, Loss: 0.053\n",
      "Training: Epoch 134, Batch 28, Loss: 0.071\n",
      "Training: Epoch 134, Batch 29, Loss: 0.057\n",
      "Training: Epoch 134, Batch 30, Loss: 0.072\n",
      "Training: Epoch 134, Batch 31, Loss: 0.079\n",
      "Training: Epoch 134, Batch 32, Loss: 0.066\n",
      "Training: Epoch 134, Batch 33, Loss: 0.06\n",
      "Training: Epoch 134, Batch 34, Loss: 0.059\n",
      "Training: Epoch 134, Batch 35, Loss: 0.055\n",
      "Training: Epoch 134, Batch 36, Loss: 0.068\n",
      "Training: Epoch 134, Batch 37, Loss: 0.081\n",
      "Training: Epoch 134, Batch 38, Loss: 0.071\n",
      "Training: Epoch 134, Batch 39, Loss: 0.065\n",
      "Training: Epoch 134, Batch 40, Loss: 0.077\n",
      "Training: Epoch 134, Batch 41, Loss: 0.071\n",
      "Training: Epoch 134, Batch 42, Loss: 0.071\n",
      "Training: Epoch 134, Batch 43, Loss: 0.075\n",
      "Training: Epoch 134, Batch 44, Loss: 0.073\n",
      "Training: Epoch 134, Batch 45, Loss: 0.077\n",
      "Training: Epoch 134, Batch 46, Loss: 0.066\n",
      "Training: Epoch 134, Batch 47, Loss: 0.054\n",
      "Training: Epoch 134, Batch 48, Loss: 0.067\n",
      "Training: Epoch 134, Batch 49, Loss: 0.052\n",
      "Training: Epoch 134, Batch 50, Loss: 0.06\n",
      "Training: Epoch 134, Batch 51, Loss: 0.092\n",
      "Training: Epoch 134, Batch 52, Loss: 0.075\n",
      "Training: Epoch 134, Batch 53, Loss: 0.075\n",
      "Training: Epoch 134, Batch 54, Loss: 0.078\n",
      "Training: Epoch 134, Batch 55, Loss: 0.062\n",
      "Training: Epoch 134, Batch 56, Loss: 0.067\n",
      "Training: Epoch 134, Batch 57, Loss: 0.062\n",
      "Training: Epoch 134, Batch 58, Loss: 0.077\n",
      "Training: Epoch 134, Batch 59, Loss: 0.094\n",
      "Val: Epoch 134, Loss: 0.298\n",
      "Training: Epoch 135, Batch 0, Loss: 0.07\n",
      "Training: Epoch 135, Batch 1, Loss: 0.073\n",
      "Training: Epoch 135, Batch 2, Loss: 0.062\n",
      "Training: Epoch 135, Batch 3, Loss: 0.065\n",
      "Training: Epoch 135, Batch 4, Loss: 0.078\n",
      "Training: Epoch 135, Batch 5, Loss: 0.085\n",
      "Training: Epoch 135, Batch 6, Loss: 0.068\n",
      "Training: Epoch 135, Batch 7, Loss: 0.064\n",
      "Training: Epoch 135, Batch 8, Loss: 0.063\n",
      "Training: Epoch 135, Batch 9, Loss: 0.077\n",
      "Training: Epoch 135, Batch 10, Loss: 0.067\n",
      "Training: Epoch 135, Batch 11, Loss: 0.077\n",
      "Training: Epoch 135, Batch 12, Loss: 0.058\n",
      "Training: Epoch 135, Batch 13, Loss: 0.075\n",
      "Training: Epoch 135, Batch 14, Loss: 0.067\n",
      "Training: Epoch 135, Batch 15, Loss: 0.064\n",
      "Training: Epoch 135, Batch 16, Loss: 0.067\n",
      "Training: Epoch 135, Batch 17, Loss: 0.075\n",
      "Training: Epoch 135, Batch 18, Loss: 0.047\n",
      "Training: Epoch 135, Batch 19, Loss: 0.07\n",
      "Training: Epoch 135, Batch 20, Loss: 0.064\n",
      "Training: Epoch 135, Batch 21, Loss: 0.045\n",
      "Training: Epoch 135, Batch 22, Loss: 0.064\n",
      "Training: Epoch 135, Batch 23, Loss: 0.084\n",
      "Training: Epoch 135, Batch 24, Loss: 0.086\n",
      "Training: Epoch 135, Batch 25, Loss: 0.057\n",
      "Training: Epoch 135, Batch 26, Loss: 0.069\n",
      "Training: Epoch 135, Batch 27, Loss: 0.088\n",
      "Training: Epoch 135, Batch 28, Loss: 0.075\n",
      "Training: Epoch 135, Batch 29, Loss: 0.063\n",
      "Training: Epoch 135, Batch 30, Loss: 0.082\n",
      "Training: Epoch 135, Batch 31, Loss: 0.069\n",
      "Training: Epoch 135, Batch 32, Loss: 0.067\n",
      "Training: Epoch 135, Batch 33, Loss: 0.065\n",
      "Training: Epoch 135, Batch 34, Loss: 0.06\n",
      "Training: Epoch 135, Batch 35, Loss: 0.06\n",
      "Training: Epoch 135, Batch 36, Loss: 0.063\n",
      "Training: Epoch 135, Batch 37, Loss: 0.069\n",
      "Training: Epoch 135, Batch 38, Loss: 0.075\n",
      "Training: Epoch 135, Batch 39, Loss: 0.082\n",
      "Training: Epoch 135, Batch 40, Loss: 0.066\n",
      "Training: Epoch 135, Batch 41, Loss: 0.102\n",
      "Training: Epoch 135, Batch 42, Loss: 0.084\n",
      "Training: Epoch 135, Batch 43, Loss: 0.066\n",
      "Training: Epoch 135, Batch 44, Loss: 0.059\n",
      "Training: Epoch 135, Batch 45, Loss: 0.059\n",
      "Training: Epoch 135, Batch 46, Loss: 0.073\n",
      "Training: Epoch 135, Batch 47, Loss: 0.084\n",
      "Training: Epoch 135, Batch 48, Loss: 0.067\n",
      "Training: Epoch 135, Batch 49, Loss: 0.07\n",
      "Training: Epoch 135, Batch 50, Loss: 0.059\n",
      "Training: Epoch 135, Batch 51, Loss: 0.071\n",
      "Training: Epoch 135, Batch 52, Loss: 0.066\n",
      "Training: Epoch 135, Batch 53, Loss: 0.088\n",
      "Training: Epoch 135, Batch 54, Loss: 0.058\n",
      "Training: Epoch 135, Batch 55, Loss: 0.068\n",
      "Training: Epoch 135, Batch 56, Loss: 0.074\n",
      "Training: Epoch 135, Batch 57, Loss: 0.059\n",
      "Training: Epoch 135, Batch 58, Loss: 0.063\n",
      "Training: Epoch 135, Batch 59, Loss: 0.064\n",
      "Val: Epoch 135, Loss: 0.296\n",
      "Training: Epoch 136, Batch 0, Loss: 0.076\n",
      "Training: Epoch 136, Batch 1, Loss: 0.066\n",
      "Training: Epoch 136, Batch 2, Loss: 0.085\n",
      "Training: Epoch 136, Batch 3, Loss: 0.075\n",
      "Training: Epoch 136, Batch 4, Loss: 0.074\n",
      "Training: Epoch 136, Batch 5, Loss: 0.081\n",
      "Training: Epoch 136, Batch 6, Loss: 0.068\n",
      "Training: Epoch 136, Batch 7, Loss: 0.074\n",
      "Training: Epoch 136, Batch 8, Loss: 0.079\n",
      "Training: Epoch 136, Batch 9, Loss: 0.08\n",
      "Training: Epoch 136, Batch 10, Loss: 0.074\n",
      "Training: Epoch 136, Batch 11, Loss: 0.064\n",
      "Training: Epoch 136, Batch 12, Loss: 0.061\n",
      "Training: Epoch 136, Batch 13, Loss: 0.074\n",
      "Training: Epoch 136, Batch 14, Loss: 0.063\n",
      "Training: Epoch 136, Batch 15, Loss: 0.08\n",
      "Training: Epoch 136, Batch 16, Loss: 0.059\n",
      "Training: Epoch 136, Batch 17, Loss: 0.062\n",
      "Training: Epoch 136, Batch 18, Loss: 0.054\n",
      "Training: Epoch 136, Batch 19, Loss: 0.059\n",
      "Training: Epoch 136, Batch 20, Loss: 0.058\n",
      "Training: Epoch 136, Batch 21, Loss: 0.082\n",
      "Training: Epoch 136, Batch 22, Loss: 0.059\n",
      "Training: Epoch 136, Batch 23, Loss: 0.09\n",
      "Training: Epoch 136, Batch 24, Loss: 0.062\n",
      "Training: Epoch 136, Batch 25, Loss: 0.059\n",
      "Training: Epoch 136, Batch 26, Loss: 0.066\n",
      "Training: Epoch 136, Batch 27, Loss: 0.069\n",
      "Training: Epoch 136, Batch 28, Loss: 0.059\n",
      "Training: Epoch 136, Batch 29, Loss: 0.056\n",
      "Training: Epoch 136, Batch 30, Loss: 0.085\n",
      "Training: Epoch 136, Batch 31, Loss: 0.056\n",
      "Training: Epoch 136, Batch 32, Loss: 0.077\n",
      "Training: Epoch 136, Batch 33, Loss: 0.061\n",
      "Training: Epoch 136, Batch 34, Loss: 0.071\n",
      "Training: Epoch 136, Batch 35, Loss: 0.068\n",
      "Training: Epoch 136, Batch 36, Loss: 0.087\n",
      "Training: Epoch 136, Batch 37, Loss: 0.079\n",
      "Training: Epoch 136, Batch 38, Loss: 0.06\n",
      "Training: Epoch 136, Batch 39, Loss: 0.064\n",
      "Training: Epoch 136, Batch 40, Loss: 0.069\n",
      "Training: Epoch 136, Batch 41, Loss: 0.077\n",
      "Training: Epoch 136, Batch 42, Loss: 0.071\n",
      "Training: Epoch 136, Batch 43, Loss: 0.077\n",
      "Training: Epoch 136, Batch 44, Loss: 0.078\n",
      "Training: Epoch 136, Batch 45, Loss: 0.074\n",
      "Training: Epoch 136, Batch 46, Loss: 0.075\n",
      "Training: Epoch 136, Batch 47, Loss: 0.074\n",
      "Training: Epoch 136, Batch 48, Loss: 0.069\n",
      "Training: Epoch 136, Batch 49, Loss: 0.063\n",
      "Training: Epoch 136, Batch 50, Loss: 0.059\n",
      "Training: Epoch 136, Batch 51, Loss: 0.061\n",
      "Training: Epoch 136, Batch 52, Loss: 0.08\n",
      "Training: Epoch 136, Batch 53, Loss: 0.066\n",
      "Training: Epoch 136, Batch 54, Loss: 0.06\n",
      "Training: Epoch 136, Batch 55, Loss: 0.074\n",
      "Training: Epoch 136, Batch 56, Loss: 0.067\n",
      "Training: Epoch 136, Batch 57, Loss: 0.067\n",
      "Training: Epoch 136, Batch 58, Loss: 0.058\n",
      "Training: Epoch 136, Batch 59, Loss: 0.072\n",
      "Val: Epoch 136, Loss: 0.289\n",
      "Training: Epoch 137, Batch 0, Loss: 0.066\n",
      "Training: Epoch 137, Batch 1, Loss: 0.078\n",
      "Training: Epoch 137, Batch 2, Loss: 0.07\n",
      "Training: Epoch 137, Batch 3, Loss: 0.065\n",
      "Training: Epoch 137, Batch 4, Loss: 0.067\n",
      "Training: Epoch 137, Batch 5, Loss: 0.077\n",
      "Training: Epoch 137, Batch 6, Loss: 0.065\n",
      "Training: Epoch 137, Batch 7, Loss: 0.061\n",
      "Training: Epoch 137, Batch 8, Loss: 0.057\n",
      "Training: Epoch 137, Batch 9, Loss: 0.077\n",
      "Training: Epoch 137, Batch 10, Loss: 0.089\n",
      "Training: Epoch 137, Batch 11, Loss: 0.073\n",
      "Training: Epoch 137, Batch 12, Loss: 0.065\n",
      "Training: Epoch 137, Batch 13, Loss: 0.07\n",
      "Training: Epoch 137, Batch 14, Loss: 0.077\n",
      "Training: Epoch 137, Batch 15, Loss: 0.07\n",
      "Training: Epoch 137, Batch 16, Loss: 0.06\n",
      "Training: Epoch 137, Batch 17, Loss: 0.084\n",
      "Training: Epoch 137, Batch 18, Loss: 0.066\n",
      "Training: Epoch 137, Batch 19, Loss: 0.069\n",
      "Training: Epoch 137, Batch 20, Loss: 0.113\n",
      "Training: Epoch 137, Batch 21, Loss: 0.068\n",
      "Training: Epoch 137, Batch 22, Loss: 0.065\n",
      "Training: Epoch 137, Batch 23, Loss: 0.074\n",
      "Training: Epoch 137, Batch 24, Loss: 0.071\n",
      "Training: Epoch 137, Batch 25, Loss: 0.058\n",
      "Training: Epoch 137, Batch 26, Loss: 0.072\n",
      "Training: Epoch 137, Batch 27, Loss: 0.06\n",
      "Training: Epoch 137, Batch 28, Loss: 0.063\n",
      "Training: Epoch 137, Batch 29, Loss: 0.073\n",
      "Training: Epoch 137, Batch 30, Loss: 0.068\n",
      "Training: Epoch 137, Batch 31, Loss: 0.068\n",
      "Training: Epoch 137, Batch 32, Loss: 0.067\n",
      "Training: Epoch 137, Batch 33, Loss: 0.088\n",
      "Training: Epoch 137, Batch 34, Loss: 0.083\n",
      "Training: Epoch 137, Batch 35, Loss: 0.061\n",
      "Training: Epoch 137, Batch 36, Loss: 0.065\n",
      "Training: Epoch 137, Batch 37, Loss: 0.078\n",
      "Training: Epoch 137, Batch 38, Loss: 0.079\n",
      "Training: Epoch 137, Batch 39, Loss: 0.053\n",
      "Training: Epoch 137, Batch 40, Loss: 0.066\n",
      "Training: Epoch 137, Batch 41, Loss: 0.073\n",
      "Training: Epoch 137, Batch 42, Loss: 0.064\n",
      "Training: Epoch 137, Batch 43, Loss: 0.054\n",
      "Training: Epoch 137, Batch 44, Loss: 0.068\n",
      "Training: Epoch 137, Batch 45, Loss: 0.075\n",
      "Training: Epoch 137, Batch 46, Loss: 0.071\n",
      "Training: Epoch 137, Batch 47, Loss: 0.075\n",
      "Training: Epoch 137, Batch 48, Loss: 0.067\n",
      "Training: Epoch 137, Batch 49, Loss: 0.079\n",
      "Training: Epoch 137, Batch 50, Loss: 0.067\n",
      "Training: Epoch 137, Batch 51, Loss: 0.063\n",
      "Training: Epoch 137, Batch 52, Loss: 0.073\n",
      "Training: Epoch 137, Batch 53, Loss: 0.073\n",
      "Training: Epoch 137, Batch 54, Loss: 0.056\n",
      "Training: Epoch 137, Batch 55, Loss: 0.059\n",
      "Training: Epoch 137, Batch 56, Loss: 0.059\n",
      "Training: Epoch 137, Batch 57, Loss: 0.066\n",
      "Training: Epoch 137, Batch 58, Loss: 0.065\n",
      "Training: Epoch 137, Batch 59, Loss: 0.063\n",
      "Val: Epoch 137, Loss: 0.293\n",
      "Training: Epoch 138, Batch 0, Loss: 0.077\n",
      "Training: Epoch 138, Batch 1, Loss: 0.066\n",
      "Training: Epoch 138, Batch 2, Loss: 0.082\n",
      "Training: Epoch 138, Batch 3, Loss: 0.066\n",
      "Training: Epoch 138, Batch 4, Loss: 0.068\n",
      "Training: Epoch 138, Batch 5, Loss: 0.077\n",
      "Training: Epoch 138, Batch 6, Loss: 0.061\n",
      "Training: Epoch 138, Batch 7, Loss: 0.096\n",
      "Training: Epoch 138, Batch 8, Loss: 0.069\n",
      "Training: Epoch 138, Batch 9, Loss: 0.047\n",
      "Training: Epoch 138, Batch 10, Loss: 0.081\n",
      "Training: Epoch 138, Batch 11, Loss: 0.095\n",
      "Training: Epoch 138, Batch 12, Loss: 0.064\n",
      "Training: Epoch 138, Batch 13, Loss: 0.07\n",
      "Training: Epoch 138, Batch 14, Loss: 0.093\n",
      "Training: Epoch 138, Batch 15, Loss: 0.084\n",
      "Training: Epoch 138, Batch 16, Loss: 0.086\n",
      "Training: Epoch 138, Batch 17, Loss: 0.095\n",
      "Training: Epoch 138, Batch 18, Loss: 0.083\n",
      "Training: Epoch 138, Batch 19, Loss: 0.071\n",
      "Training: Epoch 138, Batch 20, Loss: 0.061\n",
      "Training: Epoch 138, Batch 21, Loss: 0.086\n",
      "Training: Epoch 138, Batch 22, Loss: 0.065\n",
      "Training: Epoch 138, Batch 23, Loss: 0.069\n",
      "Training: Epoch 138, Batch 24, Loss: 0.068\n",
      "Training: Epoch 138, Batch 25, Loss: 0.073\n",
      "Training: Epoch 138, Batch 26, Loss: 0.077\n",
      "Training: Epoch 138, Batch 27, Loss: 0.083\n",
      "Training: Epoch 138, Batch 28, Loss: 0.07\n",
      "Training: Epoch 138, Batch 29, Loss: 0.059\n",
      "Training: Epoch 138, Batch 30, Loss: 0.073\n",
      "Training: Epoch 138, Batch 31, Loss: 0.077\n",
      "Training: Epoch 138, Batch 32, Loss: 0.071\n",
      "Training: Epoch 138, Batch 33, Loss: 0.065\n",
      "Training: Epoch 138, Batch 34, Loss: 0.07\n",
      "Training: Epoch 138, Batch 35, Loss: 0.06\n",
      "Training: Epoch 138, Batch 36, Loss: 0.075\n",
      "Training: Epoch 138, Batch 37, Loss: 0.062\n",
      "Training: Epoch 138, Batch 38, Loss: 0.062\n",
      "Training: Epoch 138, Batch 39, Loss: 0.076\n",
      "Training: Epoch 138, Batch 40, Loss: 0.083\n",
      "Training: Epoch 138, Batch 41, Loss: 0.06\n",
      "Training: Epoch 138, Batch 42, Loss: 0.076\n",
      "Training: Epoch 138, Batch 43, Loss: 0.067\n",
      "Training: Epoch 138, Batch 44, Loss: 0.065\n",
      "Training: Epoch 138, Batch 45, Loss: 0.076\n",
      "Training: Epoch 138, Batch 46, Loss: 0.063\n",
      "Training: Epoch 138, Batch 47, Loss: 0.066\n",
      "Training: Epoch 138, Batch 48, Loss: 0.053\n",
      "Training: Epoch 138, Batch 49, Loss: 0.068\n",
      "Training: Epoch 138, Batch 50, Loss: 0.061\n",
      "Training: Epoch 138, Batch 51, Loss: 0.056\n",
      "Training: Epoch 138, Batch 52, Loss: 0.075\n",
      "Training: Epoch 138, Batch 53, Loss: 0.072\n",
      "Training: Epoch 138, Batch 54, Loss: 0.058\n",
      "Training: Epoch 138, Batch 55, Loss: 0.067\n",
      "Training: Epoch 138, Batch 56, Loss: 0.068\n",
      "Training: Epoch 138, Batch 57, Loss: 0.071\n",
      "Training: Epoch 138, Batch 58, Loss: 0.068\n",
      "Training: Epoch 138, Batch 59, Loss: 0.072\n",
      "Val: Epoch 138, Loss: 0.283\n",
      "Training: Epoch 139, Batch 0, Loss: 0.082\n",
      "Training: Epoch 139, Batch 1, Loss: 0.058\n",
      "Training: Epoch 139, Batch 2, Loss: 0.057\n",
      "Training: Epoch 139, Batch 3, Loss: 0.064\n",
      "Training: Epoch 139, Batch 4, Loss: 0.071\n",
      "Training: Epoch 139, Batch 5, Loss: 0.071\n",
      "Training: Epoch 139, Batch 6, Loss: 0.081\n",
      "Training: Epoch 139, Batch 7, Loss: 0.069\n",
      "Training: Epoch 139, Batch 8, Loss: 0.057\n",
      "Training: Epoch 139, Batch 9, Loss: 0.067\n",
      "Training: Epoch 139, Batch 10, Loss: 0.064\n",
      "Training: Epoch 139, Batch 11, Loss: 0.083\n",
      "Training: Epoch 139, Batch 12, Loss: 0.061\n",
      "Training: Epoch 139, Batch 13, Loss: 0.082\n",
      "Training: Epoch 139, Batch 14, Loss: 0.074\n",
      "Training: Epoch 139, Batch 15, Loss: 0.066\n",
      "Training: Epoch 139, Batch 16, Loss: 0.071\n",
      "Training: Epoch 139, Batch 17, Loss: 0.063\n",
      "Training: Epoch 139, Batch 18, Loss: 0.086\n",
      "Training: Epoch 139, Batch 19, Loss: 0.069\n",
      "Training: Epoch 139, Batch 20, Loss: 0.078\n",
      "Training: Epoch 139, Batch 21, Loss: 0.074\n",
      "Training: Epoch 139, Batch 22, Loss: 0.062\n",
      "Training: Epoch 139, Batch 23, Loss: 0.076\n",
      "Training: Epoch 139, Batch 24, Loss: 0.106\n",
      "Training: Epoch 139, Batch 25, Loss: 0.057\n",
      "Training: Epoch 139, Batch 26, Loss: 0.07\n",
      "Training: Epoch 139, Batch 27, Loss: 0.085\n",
      "Training: Epoch 139, Batch 28, Loss: 0.065\n",
      "Training: Epoch 139, Batch 29, Loss: 0.079\n",
      "Training: Epoch 139, Batch 30, Loss: 0.066\n",
      "Training: Epoch 139, Batch 31, Loss: 0.067\n",
      "Training: Epoch 139, Batch 32, Loss: 0.056\n",
      "Training: Epoch 139, Batch 33, Loss: 0.069\n",
      "Training: Epoch 139, Batch 34, Loss: 0.081\n",
      "Training: Epoch 139, Batch 35, Loss: 0.063\n",
      "Training: Epoch 139, Batch 36, Loss: 0.106\n",
      "Training: Epoch 139, Batch 37, Loss: 0.066\n",
      "Training: Epoch 139, Batch 38, Loss: 0.063\n",
      "Training: Epoch 139, Batch 39, Loss: 0.059\n",
      "Training: Epoch 139, Batch 40, Loss: 0.066\n",
      "Training: Epoch 139, Batch 41, Loss: 0.069\n",
      "Training: Epoch 139, Batch 42, Loss: 0.07\n",
      "Training: Epoch 139, Batch 43, Loss: 0.062\n",
      "Training: Epoch 139, Batch 44, Loss: 0.068\n",
      "Training: Epoch 139, Batch 45, Loss: 0.076\n",
      "Training: Epoch 139, Batch 46, Loss: 0.059\n",
      "Training: Epoch 139, Batch 47, Loss: 0.061\n",
      "Training: Epoch 139, Batch 48, Loss: 0.062\n",
      "Training: Epoch 139, Batch 49, Loss: 0.052\n",
      "Training: Epoch 139, Batch 50, Loss: 0.052\n",
      "Training: Epoch 139, Batch 51, Loss: 0.072\n",
      "Training: Epoch 139, Batch 52, Loss: 0.065\n",
      "Training: Epoch 139, Batch 53, Loss: 0.062\n",
      "Training: Epoch 139, Batch 54, Loss: 0.063\n",
      "Training: Epoch 139, Batch 55, Loss: 0.066\n",
      "Training: Epoch 139, Batch 56, Loss: 0.07\n",
      "Training: Epoch 139, Batch 57, Loss: 0.069\n",
      "Training: Epoch 139, Batch 58, Loss: 0.084\n",
      "Training: Epoch 139, Batch 59, Loss: 0.068\n",
      "Val: Epoch 139, Loss: 0.294\n",
      "Training: Epoch 140, Batch 0, Loss: 0.053\n",
      "Training: Epoch 140, Batch 1, Loss: 0.055\n",
      "Training: Epoch 140, Batch 2, Loss: 0.072\n",
      "Training: Epoch 140, Batch 3, Loss: 0.057\n",
      "Training: Epoch 140, Batch 4, Loss: 0.089\n",
      "Training: Epoch 140, Batch 5, Loss: 0.056\n",
      "Training: Epoch 140, Batch 6, Loss: 0.071\n",
      "Training: Epoch 140, Batch 7, Loss: 0.08\n",
      "Training: Epoch 140, Batch 8, Loss: 0.056\n",
      "Training: Epoch 140, Batch 9, Loss: 0.058\n",
      "Training: Epoch 140, Batch 10, Loss: 0.083\n",
      "Training: Epoch 140, Batch 11, Loss: 0.05\n",
      "Training: Epoch 140, Batch 12, Loss: 0.069\n",
      "Training: Epoch 140, Batch 13, Loss: 0.076\n",
      "Training: Epoch 140, Batch 14, Loss: 0.056\n",
      "Training: Epoch 140, Batch 15, Loss: 0.076\n",
      "Training: Epoch 140, Batch 16, Loss: 0.069\n",
      "Training: Epoch 140, Batch 17, Loss: 0.062\n",
      "Training: Epoch 140, Batch 18, Loss: 0.071\n",
      "Training: Epoch 140, Batch 19, Loss: 0.061\n",
      "Training: Epoch 140, Batch 20, Loss: 0.066\n",
      "Training: Epoch 140, Batch 21, Loss: 0.052\n",
      "Training: Epoch 140, Batch 22, Loss: 0.056\n",
      "Training: Epoch 140, Batch 23, Loss: 0.069\n",
      "Training: Epoch 140, Batch 24, Loss: 0.074\n",
      "Training: Epoch 140, Batch 25, Loss: 0.063\n",
      "Training: Epoch 140, Batch 26, Loss: 0.063\n",
      "Training: Epoch 140, Batch 27, Loss: 0.059\n",
      "Training: Epoch 140, Batch 28, Loss: 0.08\n",
      "Training: Epoch 140, Batch 29, Loss: 0.069\n",
      "Training: Epoch 140, Batch 30, Loss: 0.083\n",
      "Training: Epoch 140, Batch 31, Loss: 0.077\n",
      "Training: Epoch 140, Batch 32, Loss: 0.077\n",
      "Training: Epoch 140, Batch 33, Loss: 0.066\n",
      "Training: Epoch 140, Batch 34, Loss: 0.069\n",
      "Training: Epoch 140, Batch 35, Loss: 0.071\n",
      "Training: Epoch 140, Batch 36, Loss: 0.072\n",
      "Training: Epoch 140, Batch 37, Loss: 0.067\n",
      "Training: Epoch 140, Batch 38, Loss: 0.055\n",
      "Training: Epoch 140, Batch 39, Loss: 0.074\n",
      "Training: Epoch 140, Batch 40, Loss: 0.072\n",
      "Training: Epoch 140, Batch 41, Loss: 0.078\n",
      "Training: Epoch 140, Batch 42, Loss: 0.061\n",
      "Training: Epoch 140, Batch 43, Loss: 0.069\n",
      "Training: Epoch 140, Batch 44, Loss: 0.071\n",
      "Training: Epoch 140, Batch 45, Loss: 0.061\n",
      "Training: Epoch 140, Batch 46, Loss: 0.059\n",
      "Training: Epoch 140, Batch 47, Loss: 0.064\n",
      "Training: Epoch 140, Batch 48, Loss: 0.068\n",
      "Training: Epoch 140, Batch 49, Loss: 0.067\n",
      "Training: Epoch 140, Batch 50, Loss: 0.063\n",
      "Training: Epoch 140, Batch 51, Loss: 0.064\n",
      "Training: Epoch 140, Batch 52, Loss: 0.08\n",
      "Training: Epoch 140, Batch 53, Loss: 0.063\n",
      "Training: Epoch 140, Batch 54, Loss: 0.081\n",
      "Training: Epoch 140, Batch 55, Loss: 0.053\n",
      "Training: Epoch 140, Batch 56, Loss: 0.072\n",
      "Training: Epoch 140, Batch 57, Loss: 0.092\n",
      "Training: Epoch 140, Batch 58, Loss: 0.076\n",
      "Training: Epoch 140, Batch 59, Loss: 0.084\n",
      "Val: Epoch 140, Loss: 0.305\n",
      "Training: Epoch 141, Batch 0, Loss: 0.068\n",
      "Training: Epoch 141, Batch 1, Loss: 0.061\n",
      "Training: Epoch 141, Batch 2, Loss: 0.085\n",
      "Training: Epoch 141, Batch 3, Loss: 0.066\n",
      "Training: Epoch 141, Batch 4, Loss: 0.067\n",
      "Training: Epoch 141, Batch 5, Loss: 0.073\n",
      "Training: Epoch 141, Batch 6, Loss: 0.06\n",
      "Training: Epoch 141, Batch 7, Loss: 0.078\n",
      "Training: Epoch 141, Batch 8, Loss: 0.067\n",
      "Training: Epoch 141, Batch 9, Loss: 0.069\n",
      "Training: Epoch 141, Batch 10, Loss: 0.068\n",
      "Training: Epoch 141, Batch 11, Loss: 0.073\n",
      "Training: Epoch 141, Batch 12, Loss: 0.058\n",
      "Training: Epoch 141, Batch 13, Loss: 0.075\n",
      "Training: Epoch 141, Batch 14, Loss: 0.079\n",
      "Training: Epoch 141, Batch 15, Loss: 0.069\n",
      "Training: Epoch 141, Batch 16, Loss: 0.06\n",
      "Training: Epoch 141, Batch 17, Loss: 0.058\n",
      "Training: Epoch 141, Batch 18, Loss: 0.061\n",
      "Training: Epoch 141, Batch 19, Loss: 0.055\n",
      "Training: Epoch 141, Batch 20, Loss: 0.067\n",
      "Training: Epoch 141, Batch 21, Loss: 0.072\n",
      "Training: Epoch 141, Batch 22, Loss: 0.067\n",
      "Training: Epoch 141, Batch 23, Loss: 0.069\n",
      "Training: Epoch 141, Batch 24, Loss: 0.066\n",
      "Training: Epoch 141, Batch 25, Loss: 0.073\n",
      "Training: Epoch 141, Batch 26, Loss: 0.07\n",
      "Training: Epoch 141, Batch 27, Loss: 0.07\n",
      "Training: Epoch 141, Batch 28, Loss: 0.055\n",
      "Training: Epoch 141, Batch 29, Loss: 0.064\n",
      "Training: Epoch 141, Batch 30, Loss: 0.074\n",
      "Training: Epoch 141, Batch 31, Loss: 0.069\n",
      "Training: Epoch 141, Batch 32, Loss: 0.063\n",
      "Training: Epoch 141, Batch 33, Loss: 0.079\n",
      "Training: Epoch 141, Batch 34, Loss: 0.078\n",
      "Training: Epoch 141, Batch 35, Loss: 0.053\n",
      "Training: Epoch 141, Batch 36, Loss: 0.079\n",
      "Training: Epoch 141, Batch 37, Loss: 0.06\n",
      "Training: Epoch 141, Batch 38, Loss: 0.071\n",
      "Training: Epoch 141, Batch 39, Loss: 0.072\n",
      "Training: Epoch 141, Batch 40, Loss: 0.076\n",
      "Training: Epoch 141, Batch 41, Loss: 0.069\n",
      "Training: Epoch 141, Batch 42, Loss: 0.054\n",
      "Training: Epoch 141, Batch 43, Loss: 0.071\n",
      "Training: Epoch 141, Batch 44, Loss: 0.066\n",
      "Training: Epoch 141, Batch 45, Loss: 0.061\n",
      "Training: Epoch 141, Batch 46, Loss: 0.059\n",
      "Training: Epoch 141, Batch 47, Loss: 0.075\n",
      "Training: Epoch 141, Batch 48, Loss: 0.068\n",
      "Training: Epoch 141, Batch 49, Loss: 0.061\n",
      "Training: Epoch 141, Batch 50, Loss: 0.062\n",
      "Training: Epoch 141, Batch 51, Loss: 0.065\n",
      "Training: Epoch 141, Batch 52, Loss: 0.074\n",
      "Training: Epoch 141, Batch 53, Loss: 0.07\n",
      "Training: Epoch 141, Batch 54, Loss: 0.082\n",
      "Training: Epoch 141, Batch 55, Loss: 0.061\n",
      "Training: Epoch 141, Batch 56, Loss: 0.062\n",
      "Training: Epoch 141, Batch 57, Loss: 0.074\n",
      "Training: Epoch 141, Batch 58, Loss: 0.054\n",
      "Training: Epoch 141, Batch 59, Loss: 0.072\n",
      "Val: Epoch 141, Loss: 0.29\n",
      "Training: Epoch 142, Batch 0, Loss: 0.055\n",
      "Training: Epoch 142, Batch 1, Loss: 0.058\n",
      "Training: Epoch 142, Batch 2, Loss: 0.06\n",
      "Training: Epoch 142, Batch 3, Loss: 0.063\n",
      "Training: Epoch 142, Batch 4, Loss: 0.083\n",
      "Training: Epoch 142, Batch 5, Loss: 0.074\n",
      "Training: Epoch 142, Batch 6, Loss: 0.069\n",
      "Training: Epoch 142, Batch 7, Loss: 0.063\n",
      "Training: Epoch 142, Batch 8, Loss: 0.069\n",
      "Training: Epoch 142, Batch 9, Loss: 0.068\n",
      "Training: Epoch 142, Batch 10, Loss: 0.065\n",
      "Training: Epoch 142, Batch 11, Loss: 0.073\n",
      "Training: Epoch 142, Batch 12, Loss: 0.066\n",
      "Training: Epoch 142, Batch 13, Loss: 0.068\n",
      "Training: Epoch 142, Batch 14, Loss: 0.059\n",
      "Training: Epoch 142, Batch 15, Loss: 0.067\n",
      "Training: Epoch 142, Batch 16, Loss: 0.073\n",
      "Training: Epoch 142, Batch 17, Loss: 0.082\n",
      "Training: Epoch 142, Batch 18, Loss: 0.068\n",
      "Training: Epoch 142, Batch 19, Loss: 0.064\n",
      "Training: Epoch 142, Batch 20, Loss: 0.076\n",
      "Training: Epoch 142, Batch 21, Loss: 0.073\n",
      "Training: Epoch 142, Batch 22, Loss: 0.061\n",
      "Training: Epoch 142, Batch 23, Loss: 0.07\n",
      "Training: Epoch 142, Batch 24, Loss: 0.078\n",
      "Training: Epoch 142, Batch 25, Loss: 0.075\n",
      "Training: Epoch 142, Batch 26, Loss: 0.069\n",
      "Training: Epoch 142, Batch 27, Loss: 0.071\n",
      "Training: Epoch 142, Batch 28, Loss: 0.063\n",
      "Training: Epoch 142, Batch 29, Loss: 0.073\n",
      "Training: Epoch 142, Batch 30, Loss: 0.059\n",
      "Training: Epoch 142, Batch 31, Loss: 0.068\n",
      "Training: Epoch 142, Batch 32, Loss: 0.08\n",
      "Training: Epoch 142, Batch 33, Loss: 0.061\n",
      "Training: Epoch 142, Batch 34, Loss: 0.072\n",
      "Training: Epoch 142, Batch 35, Loss: 0.069\n",
      "Training: Epoch 142, Batch 36, Loss: 0.063\n",
      "Training: Epoch 142, Batch 37, Loss: 0.052\n",
      "Training: Epoch 142, Batch 38, Loss: 0.062\n",
      "Training: Epoch 142, Batch 39, Loss: 0.085\n",
      "Training: Epoch 142, Batch 40, Loss: 0.063\n",
      "Training: Epoch 142, Batch 41, Loss: 0.064\n",
      "Training: Epoch 142, Batch 42, Loss: 0.067\n",
      "Training: Epoch 142, Batch 43, Loss: 0.074\n",
      "Training: Epoch 142, Batch 44, Loss: 0.077\n",
      "Training: Epoch 142, Batch 45, Loss: 0.053\n",
      "Training: Epoch 142, Batch 46, Loss: 0.061\n",
      "Training: Epoch 142, Batch 47, Loss: 0.074\n",
      "Training: Epoch 142, Batch 48, Loss: 0.073\n",
      "Training: Epoch 142, Batch 49, Loss: 0.078\n",
      "Training: Epoch 142, Batch 50, Loss: 0.067\n",
      "Training: Epoch 142, Batch 51, Loss: 0.074\n",
      "Training: Epoch 142, Batch 52, Loss: 0.071\n",
      "Training: Epoch 142, Batch 53, Loss: 0.065\n",
      "Training: Epoch 142, Batch 54, Loss: 0.061\n",
      "Training: Epoch 142, Batch 55, Loss: 0.055\n",
      "Training: Epoch 142, Batch 56, Loss: 0.065\n",
      "Training: Epoch 142, Batch 57, Loss: 0.067\n",
      "Training: Epoch 142, Batch 58, Loss: 0.067\n",
      "Training: Epoch 142, Batch 59, Loss: 0.069\n",
      "Val: Epoch 142, Loss: 0.293\n",
      "Training: Epoch 143, Batch 0, Loss: 0.071\n",
      "Training: Epoch 143, Batch 1, Loss: 0.069\n",
      "Training: Epoch 143, Batch 2, Loss: 0.07\n",
      "Training: Epoch 143, Batch 3, Loss: 0.059\n",
      "Training: Epoch 143, Batch 4, Loss: 0.069\n",
      "Training: Epoch 143, Batch 5, Loss: 0.058\n",
      "Training: Epoch 143, Batch 6, Loss: 0.053\n",
      "Training: Epoch 143, Batch 7, Loss: 0.046\n",
      "Training: Epoch 143, Batch 8, Loss: 0.077\n",
      "Training: Epoch 143, Batch 9, Loss: 0.072\n",
      "Training: Epoch 143, Batch 10, Loss: 0.081\n",
      "Training: Epoch 143, Batch 11, Loss: 0.068\n",
      "Training: Epoch 143, Batch 12, Loss: 0.078\n",
      "Training: Epoch 143, Batch 13, Loss: 0.07\n",
      "Training: Epoch 143, Batch 14, Loss: 0.071\n",
      "Training: Epoch 143, Batch 15, Loss: 0.077\n",
      "Training: Epoch 143, Batch 16, Loss: 0.064\n",
      "Training: Epoch 143, Batch 17, Loss: 0.057\n",
      "Training: Epoch 143, Batch 18, Loss: 0.064\n",
      "Training: Epoch 143, Batch 19, Loss: 0.074\n",
      "Training: Epoch 143, Batch 20, Loss: 0.055\n",
      "Training: Epoch 143, Batch 21, Loss: 0.066\n",
      "Training: Epoch 143, Batch 22, Loss: 0.06\n",
      "Training: Epoch 143, Batch 23, Loss: 0.054\n",
      "Training: Epoch 143, Batch 24, Loss: 0.059\n",
      "Training: Epoch 143, Batch 25, Loss: 0.064\n",
      "Training: Epoch 143, Batch 26, Loss: 0.057\n",
      "Training: Epoch 143, Batch 27, Loss: 0.065\n",
      "Training: Epoch 143, Batch 28, Loss: 0.069\n",
      "Training: Epoch 143, Batch 29, Loss: 0.074\n",
      "Training: Epoch 143, Batch 30, Loss: 0.07\n",
      "Training: Epoch 143, Batch 31, Loss: 0.065\n",
      "Training: Epoch 143, Batch 32, Loss: 0.07\n",
      "Training: Epoch 143, Batch 33, Loss: 0.064\n",
      "Training: Epoch 143, Batch 34, Loss: 0.079\n",
      "Training: Epoch 143, Batch 35, Loss: 0.068\n",
      "Training: Epoch 143, Batch 36, Loss: 0.073\n",
      "Training: Epoch 143, Batch 37, Loss: 0.072\n",
      "Training: Epoch 143, Batch 38, Loss: 0.066\n",
      "Training: Epoch 143, Batch 39, Loss: 0.085\n",
      "Training: Epoch 143, Batch 40, Loss: 0.083\n",
      "Training: Epoch 143, Batch 41, Loss: 0.058\n",
      "Training: Epoch 143, Batch 42, Loss: 0.074\n",
      "Training: Epoch 143, Batch 43, Loss: 0.052\n",
      "Training: Epoch 143, Batch 44, Loss: 0.071\n",
      "Training: Epoch 143, Batch 45, Loss: 0.073\n",
      "Training: Epoch 143, Batch 46, Loss: 0.073\n",
      "Training: Epoch 143, Batch 47, Loss: 0.079\n",
      "Training: Epoch 143, Batch 48, Loss: 0.078\n",
      "Training: Epoch 143, Batch 49, Loss: 0.048\n",
      "Training: Epoch 143, Batch 50, Loss: 0.055\n",
      "Training: Epoch 143, Batch 51, Loss: 0.069\n",
      "Training: Epoch 143, Batch 52, Loss: 0.083\n",
      "Training: Epoch 143, Batch 53, Loss: 0.059\n",
      "Training: Epoch 143, Batch 54, Loss: 0.061\n",
      "Training: Epoch 143, Batch 55, Loss: 0.062\n",
      "Training: Epoch 143, Batch 56, Loss: 0.062\n",
      "Training: Epoch 143, Batch 57, Loss: 0.076\n",
      "Training: Epoch 143, Batch 58, Loss: 0.066\n",
      "Training: Epoch 143, Batch 59, Loss: 0.063\n",
      "Val: Epoch 143, Loss: 0.286\n",
      "Training: Epoch 144, Batch 0, Loss: 0.063\n",
      "Training: Epoch 144, Batch 1, Loss: 0.075\n",
      "Training: Epoch 144, Batch 2, Loss: 0.072\n",
      "Training: Epoch 144, Batch 3, Loss: 0.07\n",
      "Training: Epoch 144, Batch 4, Loss: 0.064\n",
      "Training: Epoch 144, Batch 5, Loss: 0.054\n",
      "Training: Epoch 144, Batch 6, Loss: 0.079\n",
      "Training: Epoch 144, Batch 7, Loss: 0.062\n",
      "Training: Epoch 144, Batch 8, Loss: 0.061\n",
      "Training: Epoch 144, Batch 9, Loss: 0.057\n",
      "Training: Epoch 144, Batch 10, Loss: 0.077\n",
      "Training: Epoch 144, Batch 11, Loss: 0.061\n",
      "Training: Epoch 144, Batch 12, Loss: 0.066\n",
      "Training: Epoch 144, Batch 13, Loss: 0.08\n",
      "Training: Epoch 144, Batch 14, Loss: 0.063\n",
      "Training: Epoch 144, Batch 15, Loss: 0.057\n",
      "Training: Epoch 144, Batch 16, Loss: 0.063\n",
      "Training: Epoch 144, Batch 17, Loss: 0.076\n",
      "Training: Epoch 144, Batch 18, Loss: 0.069\n",
      "Training: Epoch 144, Batch 19, Loss: 0.069\n",
      "Training: Epoch 144, Batch 20, Loss: 0.071\n",
      "Training: Epoch 144, Batch 21, Loss: 0.068\n",
      "Training: Epoch 144, Batch 22, Loss: 0.061\n",
      "Training: Epoch 144, Batch 23, Loss: 0.075\n",
      "Training: Epoch 144, Batch 24, Loss: 0.065\n",
      "Training: Epoch 144, Batch 25, Loss: 0.065\n",
      "Training: Epoch 144, Batch 26, Loss: 0.077\n",
      "Training: Epoch 144, Batch 27, Loss: 0.074\n",
      "Training: Epoch 144, Batch 28, Loss: 0.068\n",
      "Training: Epoch 144, Batch 29, Loss: 0.064\n",
      "Training: Epoch 144, Batch 30, Loss: 0.082\n",
      "Training: Epoch 144, Batch 31, Loss: 0.073\n",
      "Training: Epoch 144, Batch 32, Loss: 0.045\n",
      "Training: Epoch 144, Batch 33, Loss: 0.064\n",
      "Training: Epoch 144, Batch 34, Loss: 0.087\n",
      "Training: Epoch 144, Batch 35, Loss: 0.061\n",
      "Training: Epoch 144, Batch 36, Loss: 0.073\n",
      "Training: Epoch 144, Batch 37, Loss: 0.079\n",
      "Training: Epoch 144, Batch 38, Loss: 0.071\n",
      "Training: Epoch 144, Batch 39, Loss: 0.066\n",
      "Training: Epoch 144, Batch 40, Loss: 0.059\n",
      "Training: Epoch 144, Batch 41, Loss: 0.074\n",
      "Training: Epoch 144, Batch 42, Loss: 0.054\n",
      "Training: Epoch 144, Batch 43, Loss: 0.08\n",
      "Training: Epoch 144, Batch 44, Loss: 0.078\n",
      "Training: Epoch 144, Batch 45, Loss: 0.055\n",
      "Training: Epoch 144, Batch 46, Loss: 0.05\n",
      "Training: Epoch 144, Batch 47, Loss: 0.058\n",
      "Training: Epoch 144, Batch 48, Loss: 0.066\n",
      "Training: Epoch 144, Batch 49, Loss: 0.076\n",
      "Training: Epoch 144, Batch 50, Loss: 0.084\n",
      "Training: Epoch 144, Batch 51, Loss: 0.073\n",
      "Training: Epoch 144, Batch 52, Loss: 0.052\n",
      "Training: Epoch 144, Batch 53, Loss: 0.069\n",
      "Training: Epoch 144, Batch 54, Loss: 0.055\n",
      "Training: Epoch 144, Batch 55, Loss: 0.055\n",
      "Training: Epoch 144, Batch 56, Loss: 0.061\n",
      "Training: Epoch 144, Batch 57, Loss: 0.073\n",
      "Training: Epoch 144, Batch 58, Loss: 0.076\n",
      "Training: Epoch 144, Batch 59, Loss: 0.071\n",
      "Val: Epoch 144, Loss: 0.287\n",
      "Training: Epoch 145, Batch 0, Loss: 0.075\n",
      "Training: Epoch 145, Batch 1, Loss: 0.065\n",
      "Training: Epoch 145, Batch 2, Loss: 0.07\n",
      "Training: Epoch 145, Batch 3, Loss: 0.067\n",
      "Training: Epoch 145, Batch 4, Loss: 0.064\n",
      "Training: Epoch 145, Batch 5, Loss: 0.063\n",
      "Training: Epoch 145, Batch 6, Loss: 0.059\n",
      "Training: Epoch 145, Batch 7, Loss: 0.078\n",
      "Training: Epoch 145, Batch 8, Loss: 0.067\n",
      "Training: Epoch 145, Batch 9, Loss: 0.062\n",
      "Training: Epoch 145, Batch 10, Loss: 0.075\n",
      "Training: Epoch 145, Batch 11, Loss: 0.069\n",
      "Training: Epoch 145, Batch 12, Loss: 0.085\n",
      "Training: Epoch 145, Batch 13, Loss: 0.057\n",
      "Training: Epoch 145, Batch 14, Loss: 0.077\n",
      "Training: Epoch 145, Batch 15, Loss: 0.071\n",
      "Training: Epoch 145, Batch 16, Loss: 0.068\n",
      "Training: Epoch 145, Batch 17, Loss: 0.064\n",
      "Training: Epoch 145, Batch 18, Loss: 0.07\n",
      "Training: Epoch 145, Batch 19, Loss: 0.075\n",
      "Training: Epoch 145, Batch 20, Loss: 0.06\n",
      "Training: Epoch 145, Batch 21, Loss: 0.061\n",
      "Training: Epoch 145, Batch 22, Loss: 0.075\n",
      "Training: Epoch 145, Batch 23, Loss: 0.075\n",
      "Training: Epoch 145, Batch 24, Loss: 0.055\n",
      "Training: Epoch 145, Batch 25, Loss: 0.076\n",
      "Training: Epoch 145, Batch 26, Loss: 0.06\n",
      "Training: Epoch 145, Batch 27, Loss: 0.065\n",
      "Training: Epoch 145, Batch 28, Loss: 0.095\n",
      "Training: Epoch 145, Batch 29, Loss: 0.069\n",
      "Training: Epoch 145, Batch 30, Loss: 0.085\n",
      "Training: Epoch 145, Batch 31, Loss: 0.055\n",
      "Training: Epoch 145, Batch 32, Loss: 0.058\n",
      "Training: Epoch 145, Batch 33, Loss: 0.076\n",
      "Training: Epoch 145, Batch 34, Loss: 0.074\n",
      "Training: Epoch 145, Batch 35, Loss: 0.076\n",
      "Training: Epoch 145, Batch 36, Loss: 0.06\n",
      "Training: Epoch 145, Batch 37, Loss: 0.063\n",
      "Training: Epoch 145, Batch 38, Loss: 0.061\n",
      "Training: Epoch 145, Batch 39, Loss: 0.061\n",
      "Training: Epoch 145, Batch 40, Loss: 0.083\n",
      "Training: Epoch 145, Batch 41, Loss: 0.066\n",
      "Training: Epoch 145, Batch 42, Loss: 0.067\n",
      "Training: Epoch 145, Batch 43, Loss: 0.074\n",
      "Training: Epoch 145, Batch 44, Loss: 0.062\n",
      "Training: Epoch 145, Batch 45, Loss: 0.057\n",
      "Training: Epoch 145, Batch 46, Loss: 0.067\n",
      "Training: Epoch 145, Batch 47, Loss: 0.058\n",
      "Training: Epoch 145, Batch 48, Loss: 0.084\n",
      "Training: Epoch 145, Batch 49, Loss: 0.07\n",
      "Training: Epoch 145, Batch 50, Loss: 0.066\n",
      "Training: Epoch 145, Batch 51, Loss: 0.081\n",
      "Training: Epoch 145, Batch 52, Loss: 0.064\n",
      "Training: Epoch 145, Batch 53, Loss: 0.065\n",
      "Training: Epoch 145, Batch 54, Loss: 0.064\n",
      "Training: Epoch 145, Batch 55, Loss: 0.055\n",
      "Training: Epoch 145, Batch 56, Loss: 0.085\n",
      "Training: Epoch 145, Batch 57, Loss: 0.054\n",
      "Training: Epoch 145, Batch 58, Loss: 0.042\n",
      "Training: Epoch 145, Batch 59, Loss: 0.07\n",
      "Val: Epoch 145, Loss: 0.279\n",
      "Training: Epoch 146, Batch 0, Loss: 0.073\n",
      "Training: Epoch 146, Batch 1, Loss: 0.063\n",
      "Training: Epoch 146, Batch 2, Loss: 0.072\n",
      "Training: Epoch 146, Batch 3, Loss: 0.071\n",
      "Training: Epoch 146, Batch 4, Loss: 0.068\n",
      "Training: Epoch 146, Batch 5, Loss: 0.061\n",
      "Training: Epoch 146, Batch 6, Loss: 0.075\n",
      "Training: Epoch 146, Batch 7, Loss: 0.078\n",
      "Training: Epoch 146, Batch 8, Loss: 0.066\n",
      "Training: Epoch 146, Batch 9, Loss: 0.059\n",
      "Training: Epoch 146, Batch 10, Loss: 0.069\n",
      "Training: Epoch 146, Batch 11, Loss: 0.078\n",
      "Training: Epoch 146, Batch 12, Loss: 0.06\n",
      "Training: Epoch 146, Batch 13, Loss: 0.08\n",
      "Training: Epoch 146, Batch 14, Loss: 0.061\n",
      "Training: Epoch 146, Batch 15, Loss: 0.058\n",
      "Training: Epoch 146, Batch 16, Loss: 0.076\n",
      "Training: Epoch 146, Batch 17, Loss: 0.063\n",
      "Training: Epoch 146, Batch 18, Loss: 0.07\n",
      "Training: Epoch 146, Batch 19, Loss: 0.053\n",
      "Training: Epoch 146, Batch 20, Loss: 0.064\n",
      "Training: Epoch 146, Batch 21, Loss: 0.067\n",
      "Training: Epoch 146, Batch 22, Loss: 0.063\n",
      "Training: Epoch 146, Batch 23, Loss: 0.066\n",
      "Training: Epoch 146, Batch 24, Loss: 0.065\n",
      "Training: Epoch 146, Batch 25, Loss: 0.061\n",
      "Training: Epoch 146, Batch 26, Loss: 0.07\n",
      "Training: Epoch 146, Batch 27, Loss: 0.069\n",
      "Training: Epoch 146, Batch 28, Loss: 0.078\n",
      "Training: Epoch 146, Batch 29, Loss: 0.069\n",
      "Training: Epoch 146, Batch 30, Loss: 0.07\n",
      "Training: Epoch 146, Batch 31, Loss: 0.062\n",
      "Training: Epoch 146, Batch 32, Loss: 0.064\n",
      "Training: Epoch 146, Batch 33, Loss: 0.051\n",
      "Training: Epoch 146, Batch 34, Loss: 0.079\n",
      "Training: Epoch 146, Batch 35, Loss: 0.062\n",
      "Training: Epoch 146, Batch 36, Loss: 0.059\n",
      "Training: Epoch 146, Batch 37, Loss: 0.071\n",
      "Training: Epoch 146, Batch 38, Loss: 0.071\n",
      "Training: Epoch 146, Batch 39, Loss: 0.062\n",
      "Training: Epoch 146, Batch 40, Loss: 0.048\n",
      "Training: Epoch 146, Batch 41, Loss: 0.075\n",
      "Training: Epoch 146, Batch 42, Loss: 0.074\n",
      "Training: Epoch 146, Batch 43, Loss: 0.065\n",
      "Training: Epoch 146, Batch 44, Loss: 0.063\n",
      "Training: Epoch 146, Batch 45, Loss: 0.074\n",
      "Training: Epoch 146, Batch 46, Loss: 0.068\n",
      "Training: Epoch 146, Batch 47, Loss: 0.052\n",
      "Training: Epoch 146, Batch 48, Loss: 0.07\n",
      "Training: Epoch 146, Batch 49, Loss: 0.065\n",
      "Training: Epoch 146, Batch 50, Loss: 0.058\n",
      "Training: Epoch 146, Batch 51, Loss: 0.064\n",
      "Training: Epoch 146, Batch 52, Loss: 0.067\n",
      "Training: Epoch 146, Batch 53, Loss: 0.065\n",
      "Training: Epoch 146, Batch 54, Loss: 0.061\n",
      "Training: Epoch 146, Batch 55, Loss: 0.069\n",
      "Training: Epoch 146, Batch 56, Loss: 0.078\n",
      "Training: Epoch 146, Batch 57, Loss: 0.086\n",
      "Training: Epoch 146, Batch 58, Loss: 0.072\n",
      "Training: Epoch 146, Batch 59, Loss: 0.072\n",
      "Val: Epoch 146, Loss: 0.295\n",
      "Training: Epoch 147, Batch 0, Loss: 0.054\n",
      "Training: Epoch 147, Batch 1, Loss: 0.079\n",
      "Training: Epoch 147, Batch 2, Loss: 0.063\n",
      "Training: Epoch 147, Batch 3, Loss: 0.066\n",
      "Training: Epoch 147, Batch 4, Loss: 0.083\n",
      "Training: Epoch 147, Batch 5, Loss: 0.074\n",
      "Training: Epoch 147, Batch 6, Loss: 0.072\n",
      "Training: Epoch 147, Batch 7, Loss: 0.058\n",
      "Training: Epoch 147, Batch 8, Loss: 0.07\n",
      "Training: Epoch 147, Batch 9, Loss: 0.082\n",
      "Training: Epoch 147, Batch 10, Loss: 0.069\n",
      "Training: Epoch 147, Batch 11, Loss: 0.078\n",
      "Training: Epoch 147, Batch 12, Loss: 0.072\n",
      "Training: Epoch 147, Batch 13, Loss: 0.067\n",
      "Training: Epoch 147, Batch 14, Loss: 0.067\n",
      "Training: Epoch 147, Batch 15, Loss: 0.067\n",
      "Training: Epoch 147, Batch 16, Loss: 0.07\n",
      "Training: Epoch 147, Batch 17, Loss: 0.07\n",
      "Training: Epoch 147, Batch 18, Loss: 0.055\n",
      "Training: Epoch 147, Batch 19, Loss: 0.07\n",
      "Training: Epoch 147, Batch 20, Loss: 0.062\n",
      "Training: Epoch 147, Batch 21, Loss: 0.072\n",
      "Training: Epoch 147, Batch 22, Loss: 0.071\n",
      "Training: Epoch 147, Batch 23, Loss: 0.057\n",
      "Training: Epoch 147, Batch 24, Loss: 0.067\n",
      "Training: Epoch 147, Batch 25, Loss: 0.066\n",
      "Training: Epoch 147, Batch 26, Loss: 0.076\n",
      "Training: Epoch 147, Batch 27, Loss: 0.051\n",
      "Training: Epoch 147, Batch 28, Loss: 0.063\n",
      "Training: Epoch 147, Batch 29, Loss: 0.066\n",
      "Training: Epoch 147, Batch 30, Loss: 0.075\n",
      "Training: Epoch 147, Batch 31, Loss: 0.077\n",
      "Training: Epoch 147, Batch 32, Loss: 0.066\n",
      "Training: Epoch 147, Batch 33, Loss: 0.053\n",
      "Training: Epoch 147, Batch 34, Loss: 0.062\n",
      "Training: Epoch 147, Batch 35, Loss: 0.071\n",
      "Training: Epoch 147, Batch 36, Loss: 0.056\n",
      "Training: Epoch 147, Batch 37, Loss: 0.076\n",
      "Training: Epoch 147, Batch 38, Loss: 0.075\n",
      "Training: Epoch 147, Batch 39, Loss: 0.051\n",
      "Training: Epoch 147, Batch 40, Loss: 0.067\n",
      "Training: Epoch 147, Batch 41, Loss: 0.054\n",
      "Training: Epoch 147, Batch 42, Loss: 0.061\n",
      "Training: Epoch 147, Batch 43, Loss: 0.072\n",
      "Training: Epoch 147, Batch 44, Loss: 0.053\n",
      "Training: Epoch 147, Batch 45, Loss: 0.06\n",
      "Training: Epoch 147, Batch 46, Loss: 0.054\n",
      "Training: Epoch 147, Batch 47, Loss: 0.052\n",
      "Training: Epoch 147, Batch 48, Loss: 0.072\n",
      "Training: Epoch 147, Batch 49, Loss: 0.072\n",
      "Training: Epoch 147, Batch 50, Loss: 0.051\n",
      "Training: Epoch 147, Batch 51, Loss: 0.066\n",
      "Training: Epoch 147, Batch 52, Loss: 0.071\n",
      "Training: Epoch 147, Batch 53, Loss: 0.052\n",
      "Training: Epoch 147, Batch 54, Loss: 0.058\n",
      "Training: Epoch 147, Batch 55, Loss: 0.069\n",
      "Training: Epoch 147, Batch 56, Loss: 0.073\n",
      "Training: Epoch 147, Batch 57, Loss: 0.055\n",
      "Training: Epoch 147, Batch 58, Loss: 0.071\n",
      "Training: Epoch 147, Batch 59, Loss: 0.076\n",
      "Val: Epoch 147, Loss: 0.315\n",
      "Training: Epoch 148, Batch 0, Loss: 0.063\n",
      "Training: Epoch 148, Batch 1, Loss: 0.066\n",
      "Training: Epoch 148, Batch 2, Loss: 0.082\n",
      "Training: Epoch 148, Batch 3, Loss: 0.061\n",
      "Training: Epoch 148, Batch 4, Loss: 0.064\n",
      "Training: Epoch 148, Batch 5, Loss: 0.058\n",
      "Training: Epoch 148, Batch 6, Loss: 0.06\n",
      "Training: Epoch 148, Batch 7, Loss: 0.056\n",
      "Training: Epoch 148, Batch 8, Loss: 0.058\n",
      "Training: Epoch 148, Batch 9, Loss: 0.056\n",
      "Training: Epoch 148, Batch 10, Loss: 0.073\n",
      "Training: Epoch 148, Batch 11, Loss: 0.062\n",
      "Training: Epoch 148, Batch 12, Loss: 0.065\n",
      "Training: Epoch 148, Batch 13, Loss: 0.069\n",
      "Training: Epoch 148, Batch 14, Loss: 0.063\n",
      "Training: Epoch 148, Batch 15, Loss: 0.07\n",
      "Training: Epoch 148, Batch 16, Loss: 0.08\n",
      "Training: Epoch 148, Batch 17, Loss: 0.058\n",
      "Training: Epoch 148, Batch 18, Loss: 0.066\n",
      "Training: Epoch 148, Batch 19, Loss: 0.068\n",
      "Training: Epoch 148, Batch 20, Loss: 0.076\n",
      "Training: Epoch 148, Batch 21, Loss: 0.07\n",
      "Training: Epoch 148, Batch 22, Loss: 0.05\n",
      "Training: Epoch 148, Batch 23, Loss: 0.058\n",
      "Training: Epoch 148, Batch 24, Loss: 0.07\n",
      "Training: Epoch 148, Batch 25, Loss: 0.056\n",
      "Training: Epoch 148, Batch 26, Loss: 0.074\n",
      "Training: Epoch 148, Batch 27, Loss: 0.061\n",
      "Training: Epoch 148, Batch 28, Loss: 0.065\n",
      "Training: Epoch 148, Batch 29, Loss: 0.067\n",
      "Training: Epoch 148, Batch 30, Loss: 0.054\n",
      "Training: Epoch 148, Batch 31, Loss: 0.076\n",
      "Training: Epoch 148, Batch 32, Loss: 0.062\n",
      "Training: Epoch 148, Batch 33, Loss: 0.052\n",
      "Training: Epoch 148, Batch 34, Loss: 0.059\n",
      "Training: Epoch 148, Batch 35, Loss: 0.071\n",
      "Training: Epoch 148, Batch 36, Loss: 0.064\n",
      "Training: Epoch 148, Batch 37, Loss: 0.08\n",
      "Training: Epoch 148, Batch 38, Loss: 0.066\n",
      "Training: Epoch 148, Batch 39, Loss: 0.063\n",
      "Training: Epoch 148, Batch 40, Loss: 0.067\n",
      "Training: Epoch 148, Batch 41, Loss: 0.06\n",
      "Training: Epoch 148, Batch 42, Loss: 0.067\n",
      "Training: Epoch 148, Batch 43, Loss: 0.051\n",
      "Training: Epoch 148, Batch 44, Loss: 0.067\n",
      "Training: Epoch 148, Batch 45, Loss: 0.055\n",
      "Training: Epoch 148, Batch 46, Loss: 0.063\n",
      "Training: Epoch 148, Batch 47, Loss: 0.072\n",
      "Training: Epoch 148, Batch 48, Loss: 0.069\n",
      "Training: Epoch 148, Batch 49, Loss: 0.066\n",
      "Training: Epoch 148, Batch 50, Loss: 0.065\n",
      "Training: Epoch 148, Batch 51, Loss: 0.065\n",
      "Training: Epoch 148, Batch 52, Loss: 0.065\n",
      "Training: Epoch 148, Batch 53, Loss: 0.053\n",
      "Training: Epoch 148, Batch 54, Loss: 0.063\n",
      "Training: Epoch 148, Batch 55, Loss: 0.076\n",
      "Training: Epoch 148, Batch 56, Loss: 0.066\n",
      "Training: Epoch 148, Batch 57, Loss: 0.077\n",
      "Training: Epoch 148, Batch 58, Loss: 0.065\n",
      "Training: Epoch 148, Batch 59, Loss: 0.069\n",
      "Val: Epoch 148, Loss: 0.302\n",
      "Training: Epoch 149, Batch 0, Loss: 0.073\n",
      "Training: Epoch 149, Batch 1, Loss: 0.061\n",
      "Training: Epoch 149, Batch 2, Loss: 0.058\n",
      "Training: Epoch 149, Batch 3, Loss: 0.05\n",
      "Training: Epoch 149, Batch 4, Loss: 0.08\n",
      "Training: Epoch 149, Batch 5, Loss: 0.075\n",
      "Training: Epoch 149, Batch 6, Loss: 0.069\n",
      "Training: Epoch 149, Batch 7, Loss: 0.053\n",
      "Training: Epoch 149, Batch 8, Loss: 0.066\n",
      "Training: Epoch 149, Batch 9, Loss: 0.066\n",
      "Training: Epoch 149, Batch 10, Loss: 0.072\n",
      "Training: Epoch 149, Batch 11, Loss: 0.081\n",
      "Training: Epoch 149, Batch 12, Loss: 0.07\n",
      "Training: Epoch 149, Batch 13, Loss: 0.078\n",
      "Training: Epoch 149, Batch 14, Loss: 0.069\n",
      "Training: Epoch 149, Batch 15, Loss: 0.06\n",
      "Training: Epoch 149, Batch 16, Loss: 0.058\n",
      "Training: Epoch 149, Batch 17, Loss: 0.056\n",
      "Training: Epoch 149, Batch 18, Loss: 0.065\n",
      "Training: Epoch 149, Batch 19, Loss: 0.049\n",
      "Training: Epoch 149, Batch 20, Loss: 0.068\n",
      "Training: Epoch 149, Batch 21, Loss: 0.056\n",
      "Training: Epoch 149, Batch 22, Loss: 0.071\n",
      "Training: Epoch 149, Batch 23, Loss: 0.064\n",
      "Training: Epoch 149, Batch 24, Loss: 0.083\n",
      "Training: Epoch 149, Batch 25, Loss: 0.065\n",
      "Training: Epoch 149, Batch 26, Loss: 0.064\n",
      "Training: Epoch 149, Batch 27, Loss: 0.061\n",
      "Training: Epoch 149, Batch 28, Loss: 0.072\n",
      "Training: Epoch 149, Batch 29, Loss: 0.054\n",
      "Training: Epoch 149, Batch 30, Loss: 0.065\n",
      "Training: Epoch 149, Batch 31, Loss: 0.053\n",
      "Training: Epoch 149, Batch 32, Loss: 0.069\n",
      "Training: Epoch 149, Batch 33, Loss: 0.065\n",
      "Training: Epoch 149, Batch 34, Loss: 0.069\n",
      "Training: Epoch 149, Batch 35, Loss: 0.065\n",
      "Training: Epoch 149, Batch 36, Loss: 0.068\n",
      "Training: Epoch 149, Batch 37, Loss: 0.082\n",
      "Training: Epoch 149, Batch 38, Loss: 0.063\n",
      "Training: Epoch 149, Batch 39, Loss: 0.072\n",
      "Training: Epoch 149, Batch 40, Loss: 0.059\n",
      "Training: Epoch 149, Batch 41, Loss: 0.056\n",
      "Training: Epoch 149, Batch 42, Loss: 0.073\n",
      "Training: Epoch 149, Batch 43, Loss: 0.057\n",
      "Training: Epoch 149, Batch 44, Loss: 0.109\n",
      "Training: Epoch 149, Batch 45, Loss: 0.071\n",
      "Training: Epoch 149, Batch 46, Loss: 0.082\n",
      "Training: Epoch 149, Batch 47, Loss: 0.069\n",
      "Training: Epoch 149, Batch 48, Loss: 0.062\n",
      "Training: Epoch 149, Batch 49, Loss: 0.067\n",
      "Training: Epoch 149, Batch 50, Loss: 0.066\n",
      "Training: Epoch 149, Batch 51, Loss: 0.065\n",
      "Training: Epoch 149, Batch 52, Loss: 0.063\n",
      "Training: Epoch 149, Batch 53, Loss: 0.072\n",
      "Training: Epoch 149, Batch 54, Loss: 0.07\n",
      "Training: Epoch 149, Batch 55, Loss: 0.062\n",
      "Training: Epoch 149, Batch 56, Loss: 0.072\n",
      "Training: Epoch 149, Batch 57, Loss: 0.068\n",
      "Training: Epoch 149, Batch 58, Loss: 0.071\n",
      "Training: Epoch 149, Batch 59, Loss: 0.076\n",
      "Val: Epoch 149, Loss: 0.325\n",
      "Training: Epoch 150, Batch 0, Loss: 0.079\n",
      "Training: Epoch 150, Batch 1, Loss: 0.058\n",
      "Training: Epoch 150, Batch 2, Loss: 0.08\n",
      "Training: Epoch 150, Batch 3, Loss: 0.056\n",
      "Training: Epoch 150, Batch 4, Loss: 0.049\n",
      "Training: Epoch 150, Batch 5, Loss: 0.066\n",
      "Training: Epoch 150, Batch 6, Loss: 0.081\n",
      "Training: Epoch 150, Batch 7, Loss: 0.05\n",
      "Training: Epoch 150, Batch 8, Loss: 0.061\n",
      "Training: Epoch 150, Batch 9, Loss: 0.051\n",
      "Training: Epoch 150, Batch 10, Loss: 0.071\n",
      "Training: Epoch 150, Batch 11, Loss: 0.06\n",
      "Training: Epoch 150, Batch 12, Loss: 0.065\n",
      "Training: Epoch 150, Batch 13, Loss: 0.055\n",
      "Training: Epoch 150, Batch 14, Loss: 0.061\n",
      "Training: Epoch 150, Batch 15, Loss: 0.073\n",
      "Training: Epoch 150, Batch 16, Loss: 0.07\n",
      "Training: Epoch 150, Batch 17, Loss: 0.071\n",
      "Training: Epoch 150, Batch 18, Loss: 0.075\n",
      "Training: Epoch 150, Batch 19, Loss: 0.053\n",
      "Training: Epoch 150, Batch 20, Loss: 0.065\n",
      "Training: Epoch 150, Batch 21, Loss: 0.069\n",
      "Training: Epoch 150, Batch 22, Loss: 0.059\n",
      "Training: Epoch 150, Batch 23, Loss: 0.058\n",
      "Training: Epoch 150, Batch 24, Loss: 0.063\n",
      "Training: Epoch 150, Batch 25, Loss: 0.07\n",
      "Training: Epoch 150, Batch 26, Loss: 0.069\n",
      "Training: Epoch 150, Batch 27, Loss: 0.06\n",
      "Training: Epoch 150, Batch 28, Loss: 0.056\n",
      "Training: Epoch 150, Batch 29, Loss: 0.07\n",
      "Training: Epoch 150, Batch 30, Loss: 0.064\n",
      "Training: Epoch 150, Batch 31, Loss: 0.067\n",
      "Training: Epoch 150, Batch 32, Loss: 0.062\n",
      "Training: Epoch 150, Batch 33, Loss: 0.065\n",
      "Training: Epoch 150, Batch 34, Loss: 0.063\n",
      "Training: Epoch 150, Batch 35, Loss: 0.078\n",
      "Training: Epoch 150, Batch 36, Loss: 0.07\n",
      "Training: Epoch 150, Batch 37, Loss: 0.061\n",
      "Training: Epoch 150, Batch 38, Loss: 0.061\n",
      "Training: Epoch 150, Batch 39, Loss: 0.062\n",
      "Training: Epoch 150, Batch 40, Loss: 0.055\n",
      "Training: Epoch 150, Batch 41, Loss: 0.076\n",
      "Training: Epoch 150, Batch 42, Loss: 0.069\n",
      "Training: Epoch 150, Batch 43, Loss: 0.059\n",
      "Training: Epoch 150, Batch 44, Loss: 0.05\n",
      "Training: Epoch 150, Batch 45, Loss: 0.072\n",
      "Training: Epoch 150, Batch 46, Loss: 0.07\n",
      "Training: Epoch 150, Batch 47, Loss: 0.076\n",
      "Training: Epoch 150, Batch 48, Loss: 0.05\n",
      "Training: Epoch 150, Batch 49, Loss: 0.083\n",
      "Training: Epoch 150, Batch 50, Loss: 0.081\n",
      "Training: Epoch 150, Batch 51, Loss: 0.081\n",
      "Training: Epoch 150, Batch 52, Loss: 0.074\n",
      "Training: Epoch 150, Batch 53, Loss: 0.075\n",
      "Training: Epoch 150, Batch 54, Loss: 0.074\n",
      "Training: Epoch 150, Batch 55, Loss: 0.073\n",
      "Training: Epoch 150, Batch 56, Loss: 0.062\n",
      "Training: Epoch 150, Batch 57, Loss: 0.078\n",
      "Training: Epoch 150, Batch 58, Loss: 0.068\n",
      "Training: Epoch 150, Batch 59, Loss: 0.053\n",
      "Val: Epoch 150, Loss: 0.29\n",
      "Training: Epoch 151, Batch 0, Loss: 0.065\n",
      "Training: Epoch 151, Batch 1, Loss: 0.054\n",
      "Training: Epoch 151, Batch 2, Loss: 0.074\n",
      "Training: Epoch 151, Batch 3, Loss: 0.063\n",
      "Training: Epoch 151, Batch 4, Loss: 0.057\n",
      "Training: Epoch 151, Batch 5, Loss: 0.059\n",
      "Training: Epoch 151, Batch 6, Loss: 0.063\n",
      "Training: Epoch 151, Batch 7, Loss: 0.056\n",
      "Training: Epoch 151, Batch 8, Loss: 0.074\n",
      "Training: Epoch 151, Batch 9, Loss: 0.061\n",
      "Training: Epoch 151, Batch 10, Loss: 0.072\n",
      "Training: Epoch 151, Batch 11, Loss: 0.057\n",
      "Training: Epoch 151, Batch 12, Loss: 0.057\n",
      "Training: Epoch 151, Batch 13, Loss: 0.087\n",
      "Training: Epoch 151, Batch 14, Loss: 0.07\n",
      "Training: Epoch 151, Batch 15, Loss: 0.059\n",
      "Training: Epoch 151, Batch 16, Loss: 0.066\n",
      "Training: Epoch 151, Batch 17, Loss: 0.063\n",
      "Training: Epoch 151, Batch 18, Loss: 0.063\n",
      "Training: Epoch 151, Batch 19, Loss: 0.078\n",
      "Training: Epoch 151, Batch 20, Loss: 0.065\n",
      "Training: Epoch 151, Batch 21, Loss: 0.064\n",
      "Training: Epoch 151, Batch 22, Loss: 0.05\n",
      "Training: Epoch 151, Batch 23, Loss: 0.059\n",
      "Training: Epoch 151, Batch 24, Loss: 0.056\n",
      "Training: Epoch 151, Batch 25, Loss: 0.062\n",
      "Training: Epoch 151, Batch 26, Loss: 0.057\n",
      "Training: Epoch 151, Batch 27, Loss: 0.074\n",
      "Training: Epoch 151, Batch 28, Loss: 0.077\n",
      "Training: Epoch 151, Batch 29, Loss: 0.068\n",
      "Training: Epoch 151, Batch 30, Loss: 0.049\n",
      "Training: Epoch 151, Batch 31, Loss: 0.053\n",
      "Training: Epoch 151, Batch 32, Loss: 0.068\n",
      "Training: Epoch 151, Batch 33, Loss: 0.065\n",
      "Training: Epoch 151, Batch 34, Loss: 0.058\n",
      "Training: Epoch 151, Batch 35, Loss: 0.064\n",
      "Training: Epoch 151, Batch 36, Loss: 0.07\n",
      "Training: Epoch 151, Batch 37, Loss: 0.074\n",
      "Training: Epoch 151, Batch 38, Loss: 0.061\n",
      "Training: Epoch 151, Batch 39, Loss: 0.076\n",
      "Training: Epoch 151, Batch 40, Loss: 0.063\n",
      "Training: Epoch 151, Batch 41, Loss: 0.065\n",
      "Training: Epoch 151, Batch 42, Loss: 0.074\n",
      "Training: Epoch 151, Batch 43, Loss: 0.068\n",
      "Training: Epoch 151, Batch 44, Loss: 0.059\n",
      "Training: Epoch 151, Batch 45, Loss: 0.067\n",
      "Training: Epoch 151, Batch 46, Loss: 0.073\n",
      "Training: Epoch 151, Batch 47, Loss: 0.071\n",
      "Training: Epoch 151, Batch 48, Loss: 0.072\n",
      "Training: Epoch 151, Batch 49, Loss: 0.08\n",
      "Training: Epoch 151, Batch 50, Loss: 0.065\n",
      "Training: Epoch 151, Batch 51, Loss: 0.067\n",
      "Training: Epoch 151, Batch 52, Loss: 0.064\n",
      "Training: Epoch 151, Batch 53, Loss: 0.066\n",
      "Training: Epoch 151, Batch 54, Loss: 0.064\n",
      "Training: Epoch 151, Batch 55, Loss: 0.05\n",
      "Training: Epoch 151, Batch 56, Loss: 0.064\n",
      "Training: Epoch 151, Batch 57, Loss: 0.064\n",
      "Training: Epoch 151, Batch 58, Loss: 0.062\n",
      "Training: Epoch 151, Batch 59, Loss: 0.063\n",
      "Val: Epoch 151, Loss: 0.317\n",
      "Training: Epoch 152, Batch 0, Loss: 0.074\n",
      "Training: Epoch 152, Batch 1, Loss: 0.052\n",
      "Training: Epoch 152, Batch 2, Loss: 0.068\n",
      "Training: Epoch 152, Batch 3, Loss: 0.067\n",
      "Training: Epoch 152, Batch 4, Loss: 0.077\n",
      "Training: Epoch 152, Batch 5, Loss: 0.056\n",
      "Training: Epoch 152, Batch 6, Loss: 0.066\n",
      "Training: Epoch 152, Batch 7, Loss: 0.072\n",
      "Training: Epoch 152, Batch 8, Loss: 0.061\n",
      "Training: Epoch 152, Batch 9, Loss: 0.058\n",
      "Training: Epoch 152, Batch 10, Loss: 0.057\n",
      "Training: Epoch 152, Batch 11, Loss: 0.069\n",
      "Training: Epoch 152, Batch 12, Loss: 0.063\n",
      "Training: Epoch 152, Batch 13, Loss: 0.067\n",
      "Training: Epoch 152, Batch 14, Loss: 0.068\n",
      "Training: Epoch 152, Batch 15, Loss: 0.083\n",
      "Training: Epoch 152, Batch 16, Loss: 0.079\n",
      "Training: Epoch 152, Batch 17, Loss: 0.068\n",
      "Training: Epoch 152, Batch 18, Loss: 0.055\n",
      "Training: Epoch 152, Batch 19, Loss: 0.057\n",
      "Training: Epoch 152, Batch 20, Loss: 0.057\n",
      "Training: Epoch 152, Batch 21, Loss: 0.072\n",
      "Training: Epoch 152, Batch 22, Loss: 0.076\n",
      "Training: Epoch 152, Batch 23, Loss: 0.059\n",
      "Training: Epoch 152, Batch 24, Loss: 0.049\n",
      "Training: Epoch 152, Batch 25, Loss: 0.066\n",
      "Training: Epoch 152, Batch 26, Loss: 0.07\n",
      "Training: Epoch 152, Batch 27, Loss: 0.069\n",
      "Training: Epoch 152, Batch 28, Loss: 0.058\n",
      "Training: Epoch 152, Batch 29, Loss: 0.071\n",
      "Training: Epoch 152, Batch 30, Loss: 0.075\n",
      "Training: Epoch 152, Batch 31, Loss: 0.069\n",
      "Training: Epoch 152, Batch 32, Loss: 0.067\n",
      "Training: Epoch 152, Batch 33, Loss: 0.057\n",
      "Training: Epoch 152, Batch 34, Loss: 0.072\n",
      "Training: Epoch 152, Batch 35, Loss: 0.06\n",
      "Training: Epoch 152, Batch 36, Loss: 0.072\n",
      "Training: Epoch 152, Batch 37, Loss: 0.084\n",
      "Training: Epoch 152, Batch 38, Loss: 0.067\n",
      "Training: Epoch 152, Batch 39, Loss: 0.065\n",
      "Training: Epoch 152, Batch 40, Loss: 0.072\n",
      "Training: Epoch 152, Batch 41, Loss: 0.081\n",
      "Training: Epoch 152, Batch 42, Loss: 0.049\n",
      "Training: Epoch 152, Batch 43, Loss: 0.056\n",
      "Training: Epoch 152, Batch 44, Loss: 0.075\n",
      "Training: Epoch 152, Batch 45, Loss: 0.061\n",
      "Training: Epoch 152, Batch 46, Loss: 0.065\n",
      "Training: Epoch 152, Batch 47, Loss: 0.049\n",
      "Training: Epoch 152, Batch 48, Loss: 0.065\n",
      "Training: Epoch 152, Batch 49, Loss: 0.062\n",
      "Training: Epoch 152, Batch 50, Loss: 0.072\n",
      "Training: Epoch 152, Batch 51, Loss: 0.073\n",
      "Training: Epoch 152, Batch 52, Loss: 0.061\n",
      "Training: Epoch 152, Batch 53, Loss: 0.065\n",
      "Training: Epoch 152, Batch 54, Loss: 0.07\n",
      "Training: Epoch 152, Batch 55, Loss: 0.074\n",
      "Training: Epoch 152, Batch 56, Loss: 0.06\n",
      "Training: Epoch 152, Batch 57, Loss: 0.067\n",
      "Training: Epoch 152, Batch 58, Loss: 0.066\n",
      "Training: Epoch 152, Batch 59, Loss: 0.056\n",
      "Val: Epoch 152, Loss: 0.312\n",
      "Training: Epoch 153, Batch 0, Loss: 0.077\n",
      "Training: Epoch 153, Batch 1, Loss: 0.064\n",
      "Training: Epoch 153, Batch 2, Loss: 0.072\n",
      "Training: Epoch 153, Batch 3, Loss: 0.056\n",
      "Training: Epoch 153, Batch 4, Loss: 0.055\n",
      "Training: Epoch 153, Batch 5, Loss: 0.063\n",
      "Training: Epoch 153, Batch 6, Loss: 0.065\n",
      "Training: Epoch 153, Batch 7, Loss: 0.053\n",
      "Training: Epoch 153, Batch 8, Loss: 0.088\n",
      "Training: Epoch 153, Batch 9, Loss: 0.051\n",
      "Training: Epoch 153, Batch 10, Loss: 0.065\n",
      "Training: Epoch 153, Batch 11, Loss: 0.065\n",
      "Training: Epoch 153, Batch 12, Loss: 0.064\n",
      "Training: Epoch 153, Batch 13, Loss: 0.071\n",
      "Training: Epoch 153, Batch 14, Loss: 0.058\n",
      "Training: Epoch 153, Batch 15, Loss: 0.062\n",
      "Training: Epoch 153, Batch 16, Loss: 0.075\n",
      "Training: Epoch 153, Batch 17, Loss: 0.066\n",
      "Training: Epoch 153, Batch 18, Loss: 0.07\n",
      "Training: Epoch 153, Batch 19, Loss: 0.057\n",
      "Training: Epoch 153, Batch 20, Loss: 0.066\n",
      "Training: Epoch 153, Batch 21, Loss: 0.059\n",
      "Training: Epoch 153, Batch 22, Loss: 0.074\n",
      "Training: Epoch 153, Batch 23, Loss: 0.073\n",
      "Training: Epoch 153, Batch 24, Loss: 0.064\n",
      "Training: Epoch 153, Batch 25, Loss: 0.063\n",
      "Training: Epoch 153, Batch 26, Loss: 0.062\n",
      "Training: Epoch 153, Batch 27, Loss: 0.073\n",
      "Training: Epoch 153, Batch 28, Loss: 0.055\n",
      "Training: Epoch 153, Batch 29, Loss: 0.061\n",
      "Training: Epoch 153, Batch 30, Loss: 0.058\n",
      "Training: Epoch 153, Batch 31, Loss: 0.057\n",
      "Training: Epoch 153, Batch 32, Loss: 0.061\n",
      "Training: Epoch 153, Batch 33, Loss: 0.063\n",
      "Training: Epoch 153, Batch 34, Loss: 0.07\n",
      "Training: Epoch 153, Batch 35, Loss: 0.075\n",
      "Training: Epoch 153, Batch 36, Loss: 0.067\n",
      "Training: Epoch 153, Batch 37, Loss: 0.044\n",
      "Training: Epoch 153, Batch 38, Loss: 0.056\n",
      "Training: Epoch 153, Batch 39, Loss: 0.059\n",
      "Training: Epoch 153, Batch 40, Loss: 0.074\n",
      "Training: Epoch 153, Batch 41, Loss: 0.068\n",
      "Training: Epoch 153, Batch 42, Loss: 0.074\n",
      "Training: Epoch 153, Batch 43, Loss: 0.057\n",
      "Training: Epoch 153, Batch 44, Loss: 0.064\n",
      "Training: Epoch 153, Batch 45, Loss: 0.064\n",
      "Training: Epoch 153, Batch 46, Loss: 0.071\n",
      "Training: Epoch 153, Batch 47, Loss: 0.082\n",
      "Training: Epoch 153, Batch 48, Loss: 0.069\n",
      "Training: Epoch 153, Batch 49, Loss: 0.06\n",
      "Training: Epoch 153, Batch 50, Loss: 0.073\n",
      "Training: Epoch 153, Batch 51, Loss: 0.064\n",
      "Training: Epoch 153, Batch 52, Loss: 0.054\n",
      "Training: Epoch 153, Batch 53, Loss: 0.06\n",
      "Training: Epoch 153, Batch 54, Loss: 0.067\n",
      "Training: Epoch 153, Batch 55, Loss: 0.058\n",
      "Training: Epoch 153, Batch 56, Loss: 0.074\n",
      "Training: Epoch 153, Batch 57, Loss: 0.058\n",
      "Training: Epoch 153, Batch 58, Loss: 0.055\n",
      "Training: Epoch 153, Batch 59, Loss: 0.066\n",
      "Val: Epoch 153, Loss: 0.307\n",
      "Training: Epoch 154, Batch 0, Loss: 0.067\n",
      "Training: Epoch 154, Batch 1, Loss: 0.064\n",
      "Training: Epoch 154, Batch 2, Loss: 0.055\n",
      "Training: Epoch 154, Batch 3, Loss: 0.065\n",
      "Training: Epoch 154, Batch 4, Loss: 0.057\n",
      "Training: Epoch 154, Batch 5, Loss: 0.064\n",
      "Training: Epoch 154, Batch 6, Loss: 0.059\n",
      "Training: Epoch 154, Batch 7, Loss: 0.079\n",
      "Training: Epoch 154, Batch 8, Loss: 0.053\n",
      "Training: Epoch 154, Batch 9, Loss: 0.071\n",
      "Training: Epoch 154, Batch 10, Loss: 0.084\n",
      "Training: Epoch 154, Batch 11, Loss: 0.065\n",
      "Training: Epoch 154, Batch 12, Loss: 0.061\n",
      "Training: Epoch 154, Batch 13, Loss: 0.052\n",
      "Training: Epoch 154, Batch 14, Loss: 0.066\n",
      "Training: Epoch 154, Batch 15, Loss: 0.063\n",
      "Training: Epoch 154, Batch 16, Loss: 0.057\n",
      "Training: Epoch 154, Batch 17, Loss: 0.077\n",
      "Training: Epoch 154, Batch 18, Loss: 0.065\n",
      "Training: Epoch 154, Batch 19, Loss: 0.053\n",
      "Training: Epoch 154, Batch 20, Loss: 0.055\n",
      "Training: Epoch 154, Batch 21, Loss: 0.067\n",
      "Training: Epoch 154, Batch 22, Loss: 0.066\n",
      "Training: Epoch 154, Batch 23, Loss: 0.06\n",
      "Training: Epoch 154, Batch 24, Loss: 0.069\n",
      "Training: Epoch 154, Batch 25, Loss: 0.065\n",
      "Training: Epoch 154, Batch 26, Loss: 0.067\n",
      "Training: Epoch 154, Batch 27, Loss: 0.069\n",
      "Training: Epoch 154, Batch 28, Loss: 0.067\n",
      "Training: Epoch 154, Batch 29, Loss: 0.065\n",
      "Training: Epoch 154, Batch 30, Loss: 0.068\n",
      "Training: Epoch 154, Batch 31, Loss: 0.077\n",
      "Training: Epoch 154, Batch 32, Loss: 0.058\n",
      "Training: Epoch 154, Batch 33, Loss: 0.06\n",
      "Training: Epoch 154, Batch 34, Loss: 0.07\n",
      "Training: Epoch 154, Batch 35, Loss: 0.084\n",
      "Training: Epoch 154, Batch 36, Loss: 0.071\n",
      "Training: Epoch 154, Batch 37, Loss: 0.053\n",
      "Training: Epoch 154, Batch 38, Loss: 0.069\n",
      "Training: Epoch 154, Batch 39, Loss: 0.056\n",
      "Training: Epoch 154, Batch 40, Loss: 0.051\n",
      "Training: Epoch 154, Batch 41, Loss: 0.057\n",
      "Training: Epoch 154, Batch 42, Loss: 0.06\n",
      "Training: Epoch 154, Batch 43, Loss: 0.066\n",
      "Training: Epoch 154, Batch 44, Loss: 0.061\n",
      "Training: Epoch 154, Batch 45, Loss: 0.077\n",
      "Training: Epoch 154, Batch 46, Loss: 0.06\n",
      "Training: Epoch 154, Batch 47, Loss: 0.067\n",
      "Training: Epoch 154, Batch 48, Loss: 0.061\n",
      "Training: Epoch 154, Batch 49, Loss: 0.065\n",
      "Training: Epoch 154, Batch 50, Loss: 0.07\n",
      "Training: Epoch 154, Batch 51, Loss: 0.078\n",
      "Training: Epoch 154, Batch 52, Loss: 0.053\n",
      "Training: Epoch 154, Batch 53, Loss: 0.078\n",
      "Training: Epoch 154, Batch 54, Loss: 0.072\n",
      "Training: Epoch 154, Batch 55, Loss: 0.063\n",
      "Training: Epoch 154, Batch 56, Loss: 0.051\n",
      "Training: Epoch 154, Batch 57, Loss: 0.074\n",
      "Training: Epoch 154, Batch 58, Loss: 0.057\n",
      "Training: Epoch 154, Batch 59, Loss: 0.082\n",
      "Val: Epoch 154, Loss: 0.296\n",
      "Training: Epoch 155, Batch 0, Loss: 0.081\n",
      "Training: Epoch 155, Batch 1, Loss: 0.06\n",
      "Training: Epoch 155, Batch 2, Loss: 0.08\n",
      "Training: Epoch 155, Batch 3, Loss: 0.059\n",
      "Training: Epoch 155, Batch 4, Loss: 0.062\n",
      "Training: Epoch 155, Batch 5, Loss: 0.063\n",
      "Training: Epoch 155, Batch 6, Loss: 0.063\n",
      "Training: Epoch 155, Batch 7, Loss: 0.081\n",
      "Training: Epoch 155, Batch 8, Loss: 0.068\n",
      "Training: Epoch 155, Batch 9, Loss: 0.067\n",
      "Training: Epoch 155, Batch 10, Loss: 0.049\n",
      "Training: Epoch 155, Batch 11, Loss: 0.072\n",
      "Training: Epoch 155, Batch 12, Loss: 0.06\n",
      "Training: Epoch 155, Batch 13, Loss: 0.058\n",
      "Training: Epoch 155, Batch 14, Loss: 0.078\n",
      "Training: Epoch 155, Batch 15, Loss: 0.057\n",
      "Training: Epoch 155, Batch 16, Loss: 0.058\n",
      "Training: Epoch 155, Batch 17, Loss: 0.061\n",
      "Training: Epoch 155, Batch 18, Loss: 0.076\n",
      "Training: Epoch 155, Batch 19, Loss: 0.076\n",
      "Training: Epoch 155, Batch 20, Loss: 0.071\n",
      "Training: Epoch 155, Batch 21, Loss: 0.062\n",
      "Training: Epoch 155, Batch 22, Loss: 0.051\n",
      "Training: Epoch 155, Batch 23, Loss: 0.066\n",
      "Training: Epoch 155, Batch 24, Loss: 0.063\n",
      "Training: Epoch 155, Batch 25, Loss: 0.069\n",
      "Training: Epoch 155, Batch 26, Loss: 0.077\n",
      "Training: Epoch 155, Batch 27, Loss: 0.057\n",
      "Training: Epoch 155, Batch 28, Loss: 0.072\n",
      "Training: Epoch 155, Batch 29, Loss: 0.078\n",
      "Training: Epoch 155, Batch 30, Loss: 0.062\n",
      "Training: Epoch 155, Batch 31, Loss: 0.076\n",
      "Training: Epoch 155, Batch 32, Loss: 0.072\n",
      "Training: Epoch 155, Batch 33, Loss: 0.073\n",
      "Training: Epoch 155, Batch 34, Loss: 0.073\n",
      "Training: Epoch 155, Batch 35, Loss: 0.065\n",
      "Training: Epoch 155, Batch 36, Loss: 0.063\n",
      "Training: Epoch 155, Batch 37, Loss: 0.07\n",
      "Training: Epoch 155, Batch 38, Loss: 0.07\n",
      "Training: Epoch 155, Batch 39, Loss: 0.077\n",
      "Training: Epoch 155, Batch 40, Loss: 0.058\n",
      "Training: Epoch 155, Batch 41, Loss: 0.065\n",
      "Training: Epoch 155, Batch 42, Loss: 0.068\n",
      "Training: Epoch 155, Batch 43, Loss: 0.065\n",
      "Training: Epoch 155, Batch 44, Loss: 0.058\n",
      "Training: Epoch 155, Batch 45, Loss: 0.06\n",
      "Training: Epoch 155, Batch 46, Loss: 0.049\n",
      "Training: Epoch 155, Batch 47, Loss: 0.063\n",
      "Training: Epoch 155, Batch 48, Loss: 0.067\n",
      "Training: Epoch 155, Batch 49, Loss: 0.067\n",
      "Training: Epoch 155, Batch 50, Loss: 0.066\n",
      "Training: Epoch 155, Batch 51, Loss: 0.057\n",
      "Training: Epoch 155, Batch 52, Loss: 0.076\n",
      "Training: Epoch 155, Batch 53, Loss: 0.072\n",
      "Training: Epoch 155, Batch 54, Loss: 0.047\n",
      "Training: Epoch 155, Batch 55, Loss: 0.062\n",
      "Training: Epoch 155, Batch 56, Loss: 0.062\n",
      "Training: Epoch 155, Batch 57, Loss: 0.063\n",
      "Training: Epoch 155, Batch 58, Loss: 0.077\n",
      "Training: Epoch 155, Batch 59, Loss: 0.06\n",
      "Val: Epoch 155, Loss: 0.315\n",
      "Training: Epoch 156, Batch 0, Loss: 0.058\n",
      "Training: Epoch 156, Batch 1, Loss: 0.067\n",
      "Training: Epoch 156, Batch 2, Loss: 0.075\n",
      "Training: Epoch 156, Batch 3, Loss: 0.057\n",
      "Training: Epoch 156, Batch 4, Loss: 0.072\n",
      "Training: Epoch 156, Batch 5, Loss: 0.068\n",
      "Training: Epoch 156, Batch 6, Loss: 0.068\n",
      "Training: Epoch 156, Batch 7, Loss: 0.067\n",
      "Training: Epoch 156, Batch 8, Loss: 0.068\n",
      "Training: Epoch 156, Batch 9, Loss: 0.059\n",
      "Training: Epoch 156, Batch 10, Loss: 0.08\n",
      "Training: Epoch 156, Batch 11, Loss: 0.069\n",
      "Training: Epoch 156, Batch 12, Loss: 0.068\n",
      "Training: Epoch 156, Batch 13, Loss: 0.066\n",
      "Training: Epoch 156, Batch 14, Loss: 0.055\n",
      "Training: Epoch 156, Batch 15, Loss: 0.062\n",
      "Training: Epoch 156, Batch 16, Loss: 0.058\n",
      "Training: Epoch 156, Batch 17, Loss: 0.054\n",
      "Training: Epoch 156, Batch 18, Loss: 0.064\n",
      "Training: Epoch 156, Batch 19, Loss: 0.073\n",
      "Training: Epoch 156, Batch 20, Loss: 0.046\n",
      "Training: Epoch 156, Batch 21, Loss: 0.065\n",
      "Training: Epoch 156, Batch 22, Loss: 0.052\n",
      "Training: Epoch 156, Batch 23, Loss: 0.076\n",
      "Training: Epoch 156, Batch 24, Loss: 0.063\n",
      "Training: Epoch 156, Batch 25, Loss: 0.058\n",
      "Training: Epoch 156, Batch 26, Loss: 0.067\n",
      "Training: Epoch 156, Batch 27, Loss: 0.068\n",
      "Training: Epoch 156, Batch 28, Loss: 0.067\n",
      "Training: Epoch 156, Batch 29, Loss: 0.059\n",
      "Training: Epoch 156, Batch 30, Loss: 0.073\n",
      "Training: Epoch 156, Batch 31, Loss: 0.044\n",
      "Training: Epoch 156, Batch 32, Loss: 0.057\n",
      "Training: Epoch 156, Batch 33, Loss: 0.052\n",
      "Training: Epoch 156, Batch 34, Loss: 0.076\n",
      "Training: Epoch 156, Batch 35, Loss: 0.068\n",
      "Training: Epoch 156, Batch 36, Loss: 0.076\n",
      "Training: Epoch 156, Batch 37, Loss: 0.068\n",
      "Training: Epoch 156, Batch 38, Loss: 0.051\n",
      "Training: Epoch 156, Batch 39, Loss: 0.069\n",
      "Training: Epoch 156, Batch 40, Loss: 0.064\n",
      "Training: Epoch 156, Batch 41, Loss: 0.074\n",
      "Training: Epoch 156, Batch 42, Loss: 0.066\n",
      "Training: Epoch 156, Batch 43, Loss: 0.054\n",
      "Training: Epoch 156, Batch 44, Loss: 0.054\n",
      "Training: Epoch 156, Batch 45, Loss: 0.066\n",
      "Training: Epoch 156, Batch 46, Loss: 0.072\n",
      "Training: Epoch 156, Batch 47, Loss: 0.061\n",
      "Training: Epoch 156, Batch 48, Loss: 0.052\n",
      "Training: Epoch 156, Batch 49, Loss: 0.071\n",
      "Training: Epoch 156, Batch 50, Loss: 0.068\n",
      "Training: Epoch 156, Batch 51, Loss: 0.072\n",
      "Training: Epoch 156, Batch 52, Loss: 0.061\n",
      "Training: Epoch 156, Batch 53, Loss: 0.08\n",
      "Training: Epoch 156, Batch 54, Loss: 0.079\n",
      "Training: Epoch 156, Batch 55, Loss: 0.062\n",
      "Training: Epoch 156, Batch 56, Loss: 0.055\n",
      "Training: Epoch 156, Batch 57, Loss: 0.082\n",
      "Training: Epoch 156, Batch 58, Loss: 0.057\n",
      "Training: Epoch 156, Batch 59, Loss: 0.062\n",
      "Val: Epoch 156, Loss: 0.33\n",
      "Training: Epoch 157, Batch 0, Loss: 0.066\n",
      "Training: Epoch 157, Batch 1, Loss: 0.067\n",
      "Training: Epoch 157, Batch 2, Loss: 0.066\n",
      "Training: Epoch 157, Batch 3, Loss: 0.068\n",
      "Training: Epoch 157, Batch 4, Loss: 0.077\n",
      "Training: Epoch 157, Batch 5, Loss: 0.053\n",
      "Training: Epoch 157, Batch 6, Loss: 0.066\n",
      "Training: Epoch 157, Batch 7, Loss: 0.078\n",
      "Training: Epoch 157, Batch 8, Loss: 0.058\n",
      "Training: Epoch 157, Batch 9, Loss: 0.047\n",
      "Training: Epoch 157, Batch 10, Loss: 0.065\n",
      "Training: Epoch 157, Batch 11, Loss: 0.081\n",
      "Training: Epoch 157, Batch 12, Loss: 0.057\n",
      "Training: Epoch 157, Batch 13, Loss: 0.068\n",
      "Training: Epoch 157, Batch 14, Loss: 0.069\n",
      "Training: Epoch 157, Batch 15, Loss: 0.066\n",
      "Training: Epoch 157, Batch 16, Loss: 0.061\n",
      "Training: Epoch 157, Batch 17, Loss: 0.07\n",
      "Training: Epoch 157, Batch 18, Loss: 0.071\n",
      "Training: Epoch 157, Batch 19, Loss: 0.06\n",
      "Training: Epoch 157, Batch 20, Loss: 0.066\n",
      "Training: Epoch 157, Batch 21, Loss: 0.071\n",
      "Training: Epoch 157, Batch 22, Loss: 0.065\n",
      "Training: Epoch 157, Batch 23, Loss: 0.062\n",
      "Training: Epoch 157, Batch 24, Loss: 0.062\n",
      "Training: Epoch 157, Batch 25, Loss: 0.072\n",
      "Training: Epoch 157, Batch 26, Loss: 0.057\n",
      "Training: Epoch 157, Batch 27, Loss: 0.058\n",
      "Training: Epoch 157, Batch 28, Loss: 0.058\n",
      "Training: Epoch 157, Batch 29, Loss: 0.074\n",
      "Training: Epoch 157, Batch 30, Loss: 0.057\n",
      "Training: Epoch 157, Batch 31, Loss: 0.057\n",
      "Training: Epoch 157, Batch 32, Loss: 0.061\n",
      "Training: Epoch 157, Batch 33, Loss: 0.051\n",
      "Training: Epoch 157, Batch 34, Loss: 0.058\n",
      "Training: Epoch 157, Batch 35, Loss: 0.056\n",
      "Training: Epoch 157, Batch 36, Loss: 0.069\n",
      "Training: Epoch 157, Batch 37, Loss: 0.069\n",
      "Training: Epoch 157, Batch 38, Loss: 0.063\n",
      "Training: Epoch 157, Batch 39, Loss: 0.058\n",
      "Training: Epoch 157, Batch 40, Loss: 0.067\n",
      "Training: Epoch 157, Batch 41, Loss: 0.08\n",
      "Training: Epoch 157, Batch 42, Loss: 0.059\n",
      "Training: Epoch 157, Batch 43, Loss: 0.067\n",
      "Training: Epoch 157, Batch 44, Loss: 0.072\n",
      "Training: Epoch 157, Batch 45, Loss: 0.054\n",
      "Training: Epoch 157, Batch 46, Loss: 0.062\n",
      "Training: Epoch 157, Batch 47, Loss: 0.065\n",
      "Training: Epoch 157, Batch 48, Loss: 0.07\n",
      "Training: Epoch 157, Batch 49, Loss: 0.059\n",
      "Training: Epoch 157, Batch 50, Loss: 0.062\n",
      "Training: Epoch 157, Batch 51, Loss: 0.056\n",
      "Training: Epoch 157, Batch 52, Loss: 0.068\n",
      "Training: Epoch 157, Batch 53, Loss: 0.073\n",
      "Training: Epoch 157, Batch 54, Loss: 0.059\n",
      "Training: Epoch 157, Batch 55, Loss: 0.063\n",
      "Training: Epoch 157, Batch 56, Loss: 0.073\n",
      "Training: Epoch 157, Batch 57, Loss: 0.07\n",
      "Training: Epoch 157, Batch 58, Loss: 0.081\n",
      "Training: Epoch 157, Batch 59, Loss: 0.051\n",
      "Val: Epoch 157, Loss: 0.305\n",
      "Training: Epoch 158, Batch 0, Loss: 0.079\n",
      "Training: Epoch 158, Batch 1, Loss: 0.077\n",
      "Training: Epoch 158, Batch 2, Loss: 0.072\n",
      "Training: Epoch 158, Batch 3, Loss: 0.07\n",
      "Training: Epoch 158, Batch 4, Loss: 0.058\n",
      "Training: Epoch 158, Batch 5, Loss: 0.052\n",
      "Training: Epoch 158, Batch 6, Loss: 0.067\n",
      "Training: Epoch 158, Batch 7, Loss: 0.066\n",
      "Training: Epoch 158, Batch 8, Loss: 0.064\n",
      "Training: Epoch 158, Batch 9, Loss: 0.057\n",
      "Training: Epoch 158, Batch 10, Loss: 0.056\n",
      "Training: Epoch 158, Batch 11, Loss: 0.067\n",
      "Training: Epoch 158, Batch 12, Loss: 0.057\n",
      "Training: Epoch 158, Batch 13, Loss: 0.054\n",
      "Training: Epoch 158, Batch 14, Loss: 0.08\n",
      "Training: Epoch 158, Batch 15, Loss: 0.065\n",
      "Training: Epoch 158, Batch 16, Loss: 0.058\n",
      "Training: Epoch 158, Batch 17, Loss: 0.05\n",
      "Training: Epoch 158, Batch 18, Loss: 0.056\n",
      "Training: Epoch 158, Batch 19, Loss: 0.069\n",
      "Training: Epoch 158, Batch 20, Loss: 0.052\n",
      "Training: Epoch 158, Batch 21, Loss: 0.056\n",
      "Training: Epoch 158, Batch 22, Loss: 0.059\n",
      "Training: Epoch 158, Batch 23, Loss: 0.067\n",
      "Training: Epoch 158, Batch 24, Loss: 0.051\n",
      "Training: Epoch 158, Batch 25, Loss: 0.068\n",
      "Training: Epoch 158, Batch 26, Loss: 0.069\n",
      "Training: Epoch 158, Batch 27, Loss: 0.059\n",
      "Training: Epoch 158, Batch 28, Loss: 0.078\n",
      "Training: Epoch 158, Batch 29, Loss: 0.061\n",
      "Training: Epoch 158, Batch 30, Loss: 0.061\n",
      "Training: Epoch 158, Batch 31, Loss: 0.062\n",
      "Training: Epoch 158, Batch 32, Loss: 0.084\n",
      "Training: Epoch 158, Batch 33, Loss: 0.065\n",
      "Training: Epoch 158, Batch 34, Loss: 0.053\n",
      "Training: Epoch 158, Batch 35, Loss: 0.063\n",
      "Training: Epoch 158, Batch 36, Loss: 0.058\n",
      "Training: Epoch 158, Batch 37, Loss: 0.06\n",
      "Training: Epoch 158, Batch 38, Loss: 0.078\n",
      "Training: Epoch 158, Batch 39, Loss: 0.06\n",
      "Training: Epoch 158, Batch 40, Loss: 0.047\n",
      "Training: Epoch 158, Batch 41, Loss: 0.064\n",
      "Training: Epoch 158, Batch 42, Loss: 0.067\n",
      "Training: Epoch 158, Batch 43, Loss: 0.06\n",
      "Training: Epoch 158, Batch 44, Loss: 0.064\n",
      "Training: Epoch 158, Batch 45, Loss: 0.06\n",
      "Training: Epoch 158, Batch 46, Loss: 0.062\n",
      "Training: Epoch 158, Batch 47, Loss: 0.059\n",
      "Training: Epoch 158, Batch 48, Loss: 0.077\n",
      "Training: Epoch 158, Batch 49, Loss: 0.078\n",
      "Training: Epoch 158, Batch 50, Loss: 0.065\n",
      "Training: Epoch 158, Batch 51, Loss: 0.064\n",
      "Training: Epoch 158, Batch 52, Loss: 0.058\n",
      "Training: Epoch 158, Batch 53, Loss: 0.064\n",
      "Training: Epoch 158, Batch 54, Loss: 0.061\n",
      "Training: Epoch 158, Batch 55, Loss: 0.066\n",
      "Training: Epoch 158, Batch 56, Loss: 0.059\n",
      "Training: Epoch 158, Batch 57, Loss: 0.054\n",
      "Training: Epoch 158, Batch 58, Loss: 0.065\n",
      "Training: Epoch 158, Batch 59, Loss: 0.067\n",
      "Val: Epoch 158, Loss: 0.317\n",
      "Training: Epoch 159, Batch 0, Loss: 0.05\n",
      "Training: Epoch 159, Batch 1, Loss: 0.058\n",
      "Training: Epoch 159, Batch 2, Loss: 0.065\n",
      "Training: Epoch 159, Batch 3, Loss: 0.076\n",
      "Training: Epoch 159, Batch 4, Loss: 0.07\n",
      "Training: Epoch 159, Batch 5, Loss: 0.061\n",
      "Training: Epoch 159, Batch 6, Loss: 0.047\n",
      "Training: Epoch 159, Batch 7, Loss: 0.063\n",
      "Training: Epoch 159, Batch 8, Loss: 0.066\n",
      "Training: Epoch 159, Batch 9, Loss: 0.078\n",
      "Training: Epoch 159, Batch 10, Loss: 0.057\n",
      "Training: Epoch 159, Batch 11, Loss: 0.062\n",
      "Training: Epoch 159, Batch 12, Loss: 0.08\n",
      "Training: Epoch 159, Batch 13, Loss: 0.052\n",
      "Training: Epoch 159, Batch 14, Loss: 0.062\n",
      "Training: Epoch 159, Batch 15, Loss: 0.064\n",
      "Training: Epoch 159, Batch 16, Loss: 0.063\n",
      "Training: Epoch 159, Batch 17, Loss: 0.081\n",
      "Training: Epoch 159, Batch 18, Loss: 0.059\n",
      "Training: Epoch 159, Batch 19, Loss: 0.064\n",
      "Training: Epoch 159, Batch 20, Loss: 0.075\n",
      "Training: Epoch 159, Batch 21, Loss: 0.06\n",
      "Training: Epoch 159, Batch 22, Loss: 0.071\n",
      "Training: Epoch 159, Batch 23, Loss: 0.057\n",
      "Training: Epoch 159, Batch 24, Loss: 0.07\n",
      "Training: Epoch 159, Batch 25, Loss: 0.064\n",
      "Training: Epoch 159, Batch 26, Loss: 0.054\n",
      "Training: Epoch 159, Batch 27, Loss: 0.06\n",
      "Training: Epoch 159, Batch 28, Loss: 0.058\n",
      "Training: Epoch 159, Batch 29, Loss: 0.071\n",
      "Training: Epoch 159, Batch 30, Loss: 0.068\n",
      "Training: Epoch 159, Batch 31, Loss: 0.072\n",
      "Training: Epoch 159, Batch 32, Loss: 0.058\n",
      "Training: Epoch 159, Batch 33, Loss: 0.067\n",
      "Training: Epoch 159, Batch 34, Loss: 0.059\n",
      "Training: Epoch 159, Batch 35, Loss: 0.062\n",
      "Training: Epoch 159, Batch 36, Loss: 0.059\n",
      "Training: Epoch 159, Batch 37, Loss: 0.064\n",
      "Training: Epoch 159, Batch 38, Loss: 0.063\n",
      "Training: Epoch 159, Batch 39, Loss: 0.058\n",
      "Training: Epoch 159, Batch 40, Loss: 0.049\n",
      "Training: Epoch 159, Batch 41, Loss: 0.058\n",
      "Training: Epoch 159, Batch 42, Loss: 0.068\n",
      "Training: Epoch 159, Batch 43, Loss: 0.067\n",
      "Training: Epoch 159, Batch 44, Loss: 0.054\n",
      "Training: Epoch 159, Batch 45, Loss: 0.063\n",
      "Training: Epoch 159, Batch 46, Loss: 0.055\n",
      "Training: Epoch 159, Batch 47, Loss: 0.068\n",
      "Training: Epoch 159, Batch 48, Loss: 0.066\n",
      "Training: Epoch 159, Batch 49, Loss: 0.069\n",
      "Training: Epoch 159, Batch 50, Loss: 0.057\n",
      "Training: Epoch 159, Batch 51, Loss: 0.062\n",
      "Training: Epoch 159, Batch 52, Loss: 0.066\n",
      "Training: Epoch 159, Batch 53, Loss: 0.056\n",
      "Training: Epoch 159, Batch 54, Loss: 0.054\n",
      "Training: Epoch 159, Batch 55, Loss: 0.054\n",
      "Training: Epoch 159, Batch 56, Loss: 0.077\n",
      "Training: Epoch 159, Batch 57, Loss: 0.062\n",
      "Training: Epoch 159, Batch 58, Loss: 0.069\n",
      "Training: Epoch 159, Batch 59, Loss: 0.06\n",
      "Val: Epoch 159, Loss: 0.322\n",
      "Training: Epoch 160, Batch 0, Loss: 0.063\n",
      "Training: Epoch 160, Batch 1, Loss: 0.076\n",
      "Training: Epoch 160, Batch 2, Loss: 0.052\n",
      "Training: Epoch 160, Batch 3, Loss: 0.072\n",
      "Training: Epoch 160, Batch 4, Loss: 0.054\n",
      "Training: Epoch 160, Batch 5, Loss: 0.056\n",
      "Training: Epoch 160, Batch 6, Loss: 0.05\n",
      "Training: Epoch 160, Batch 7, Loss: 0.055\n",
      "Training: Epoch 160, Batch 8, Loss: 0.08\n",
      "Training: Epoch 160, Batch 9, Loss: 0.075\n",
      "Training: Epoch 160, Batch 10, Loss: 0.054\n",
      "Training: Epoch 160, Batch 11, Loss: 0.058\n",
      "Training: Epoch 160, Batch 12, Loss: 0.09\n",
      "Training: Epoch 160, Batch 13, Loss: 0.069\n",
      "Training: Epoch 160, Batch 14, Loss: 0.066\n",
      "Training: Epoch 160, Batch 15, Loss: 0.081\n",
      "Training: Epoch 160, Batch 16, Loss: 0.068\n",
      "Training: Epoch 160, Batch 17, Loss: 0.07\n",
      "Training: Epoch 160, Batch 18, Loss: 0.072\n",
      "Training: Epoch 160, Batch 19, Loss: 0.063\n",
      "Training: Epoch 160, Batch 20, Loss: 0.076\n",
      "Training: Epoch 160, Batch 21, Loss: 0.068\n",
      "Training: Epoch 160, Batch 22, Loss: 0.057\n",
      "Training: Epoch 160, Batch 23, Loss: 0.054\n",
      "Training: Epoch 160, Batch 24, Loss: 0.059\n",
      "Training: Epoch 160, Batch 25, Loss: 0.069\n",
      "Training: Epoch 160, Batch 26, Loss: 0.057\n",
      "Training: Epoch 160, Batch 27, Loss: 0.063\n",
      "Training: Epoch 160, Batch 28, Loss: 0.062\n",
      "Training: Epoch 160, Batch 29, Loss: 0.055\n",
      "Training: Epoch 160, Batch 30, Loss: 0.053\n",
      "Training: Epoch 160, Batch 31, Loss: 0.065\n",
      "Training: Epoch 160, Batch 32, Loss: 0.063\n",
      "Training: Epoch 160, Batch 33, Loss: 0.074\n",
      "Training: Epoch 160, Batch 34, Loss: 0.063\n",
      "Training: Epoch 160, Batch 35, Loss: 0.061\n",
      "Training: Epoch 160, Batch 36, Loss: 0.069\n",
      "Training: Epoch 160, Batch 37, Loss: 0.073\n",
      "Training: Epoch 160, Batch 38, Loss: 0.061\n",
      "Training: Epoch 160, Batch 39, Loss: 0.054\n",
      "Training: Epoch 160, Batch 40, Loss: 0.068\n",
      "Training: Epoch 160, Batch 41, Loss: 0.066\n",
      "Training: Epoch 160, Batch 42, Loss: 0.052\n",
      "Training: Epoch 160, Batch 43, Loss: 0.067\n",
      "Training: Epoch 160, Batch 44, Loss: 0.058\n",
      "Training: Epoch 160, Batch 45, Loss: 0.065\n",
      "Training: Epoch 160, Batch 46, Loss: 0.059\n",
      "Training: Epoch 160, Batch 47, Loss: 0.062\n",
      "Training: Epoch 160, Batch 48, Loss: 0.056\n",
      "Training: Epoch 160, Batch 49, Loss: 0.061\n",
      "Training: Epoch 160, Batch 50, Loss: 0.063\n",
      "Training: Epoch 160, Batch 51, Loss: 0.051\n",
      "Training: Epoch 160, Batch 52, Loss: 0.062\n",
      "Training: Epoch 160, Batch 53, Loss: 0.05\n",
      "Training: Epoch 160, Batch 54, Loss: 0.062\n",
      "Training: Epoch 160, Batch 55, Loss: 0.063\n",
      "Training: Epoch 160, Batch 56, Loss: 0.073\n",
      "Training: Epoch 160, Batch 57, Loss: 0.06\n",
      "Training: Epoch 160, Batch 58, Loss: 0.071\n",
      "Training: Epoch 160, Batch 59, Loss: 0.055\n",
      "Val: Epoch 160, Loss: 0.324\n",
      "Training: Epoch 161, Batch 0, Loss: 0.067\n",
      "Training: Epoch 161, Batch 1, Loss: 0.058\n",
      "Training: Epoch 161, Batch 2, Loss: 0.085\n",
      "Training: Epoch 161, Batch 3, Loss: 0.064\n",
      "Training: Epoch 161, Batch 4, Loss: 0.061\n",
      "Training: Epoch 161, Batch 5, Loss: 0.076\n",
      "Training: Epoch 161, Batch 6, Loss: 0.059\n",
      "Training: Epoch 161, Batch 7, Loss: 0.055\n",
      "Training: Epoch 161, Batch 8, Loss: 0.062\n",
      "Training: Epoch 161, Batch 9, Loss: 0.065\n",
      "Training: Epoch 161, Batch 10, Loss: 0.047\n",
      "Training: Epoch 161, Batch 11, Loss: 0.06\n",
      "Training: Epoch 161, Batch 12, Loss: 0.053\n",
      "Training: Epoch 161, Batch 13, Loss: 0.065\n",
      "Training: Epoch 161, Batch 14, Loss: 0.066\n",
      "Training: Epoch 161, Batch 15, Loss: 0.059\n",
      "Training: Epoch 161, Batch 16, Loss: 0.053\n",
      "Training: Epoch 161, Batch 17, Loss: 0.074\n",
      "Training: Epoch 161, Batch 18, Loss: 0.079\n",
      "Training: Epoch 161, Batch 19, Loss: 0.058\n",
      "Training: Epoch 161, Batch 20, Loss: 0.066\n",
      "Training: Epoch 161, Batch 21, Loss: 0.063\n",
      "Training: Epoch 161, Batch 22, Loss: 0.076\n",
      "Training: Epoch 161, Batch 23, Loss: 0.067\n",
      "Training: Epoch 161, Batch 24, Loss: 0.073\n",
      "Training: Epoch 161, Batch 25, Loss: 0.058\n",
      "Training: Epoch 161, Batch 26, Loss: 0.05\n",
      "Training: Epoch 161, Batch 27, Loss: 0.05\n",
      "Training: Epoch 161, Batch 28, Loss: 0.066\n",
      "Training: Epoch 161, Batch 29, Loss: 0.052\n",
      "Training: Epoch 161, Batch 30, Loss: 0.066\n",
      "Training: Epoch 161, Batch 31, Loss: 0.066\n",
      "Training: Epoch 161, Batch 32, Loss: 0.048\n",
      "Training: Epoch 161, Batch 33, Loss: 0.06\n",
      "Training: Epoch 161, Batch 34, Loss: 0.055\n",
      "Training: Epoch 161, Batch 35, Loss: 0.057\n",
      "Training: Epoch 161, Batch 36, Loss: 0.067\n",
      "Training: Epoch 161, Batch 37, Loss: 0.068\n",
      "Training: Epoch 161, Batch 38, Loss: 0.057\n",
      "Training: Epoch 161, Batch 39, Loss: 0.062\n",
      "Training: Epoch 161, Batch 40, Loss: 0.065\n",
      "Training: Epoch 161, Batch 41, Loss: 0.064\n",
      "Training: Epoch 161, Batch 42, Loss: 0.076\n",
      "Training: Epoch 161, Batch 43, Loss: 0.067\n",
      "Training: Epoch 161, Batch 44, Loss: 0.073\n",
      "Training: Epoch 161, Batch 45, Loss: 0.063\n",
      "Training: Epoch 161, Batch 46, Loss: 0.068\n",
      "Training: Epoch 161, Batch 47, Loss: 0.059\n",
      "Training: Epoch 161, Batch 48, Loss: 0.062\n",
      "Training: Epoch 161, Batch 49, Loss: 0.055\n",
      "Training: Epoch 161, Batch 50, Loss: 0.056\n",
      "Training: Epoch 161, Batch 51, Loss: 0.068\n",
      "Training: Epoch 161, Batch 52, Loss: 0.055\n",
      "Training: Epoch 161, Batch 53, Loss: 0.062\n",
      "Training: Epoch 161, Batch 54, Loss: 0.065\n",
      "Training: Epoch 161, Batch 55, Loss: 0.068\n",
      "Training: Epoch 161, Batch 56, Loss: 0.058\n",
      "Training: Epoch 161, Batch 57, Loss: 0.056\n",
      "Training: Epoch 161, Batch 58, Loss: 0.063\n",
      "Training: Epoch 161, Batch 59, Loss: 0.065\n",
      "Val: Epoch 161, Loss: 0.326\n",
      "Training: Epoch 162, Batch 0, Loss: 0.066\n",
      "Training: Epoch 162, Batch 1, Loss: 0.05\n",
      "Training: Epoch 162, Batch 2, Loss: 0.071\n",
      "Training: Epoch 162, Batch 3, Loss: 0.067\n",
      "Training: Epoch 162, Batch 4, Loss: 0.057\n",
      "Training: Epoch 162, Batch 5, Loss: 0.073\n",
      "Training: Epoch 162, Batch 6, Loss: 0.065\n",
      "Training: Epoch 162, Batch 7, Loss: 0.055\n",
      "Training: Epoch 162, Batch 8, Loss: 0.054\n",
      "Training: Epoch 162, Batch 9, Loss: 0.082\n",
      "Training: Epoch 162, Batch 10, Loss: 0.069\n",
      "Training: Epoch 162, Batch 11, Loss: 0.061\n",
      "Training: Epoch 162, Batch 12, Loss: 0.066\n",
      "Training: Epoch 162, Batch 13, Loss: 0.06\n",
      "Training: Epoch 162, Batch 14, Loss: 0.06\n",
      "Training: Epoch 162, Batch 15, Loss: 0.052\n",
      "Training: Epoch 162, Batch 16, Loss: 0.069\n",
      "Training: Epoch 162, Batch 17, Loss: 0.057\n",
      "Training: Epoch 162, Batch 18, Loss: 0.06\n",
      "Training: Epoch 162, Batch 19, Loss: 0.064\n",
      "Training: Epoch 162, Batch 20, Loss: 0.065\n",
      "Training: Epoch 162, Batch 21, Loss: 0.052\n",
      "Training: Epoch 162, Batch 22, Loss: 0.059\n",
      "Training: Epoch 162, Batch 23, Loss: 0.069\n",
      "Training: Epoch 162, Batch 24, Loss: 0.058\n",
      "Training: Epoch 162, Batch 25, Loss: 0.052\n",
      "Training: Epoch 162, Batch 26, Loss: 0.047\n",
      "Training: Epoch 162, Batch 27, Loss: 0.07\n",
      "Training: Epoch 162, Batch 28, Loss: 0.059\n",
      "Training: Epoch 162, Batch 29, Loss: 0.064\n",
      "Training: Epoch 162, Batch 30, Loss: 0.066\n",
      "Training: Epoch 162, Batch 31, Loss: 0.053\n",
      "Training: Epoch 162, Batch 32, Loss: 0.056\n",
      "Training: Epoch 162, Batch 33, Loss: 0.067\n",
      "Training: Epoch 162, Batch 34, Loss: 0.057\n",
      "Training: Epoch 162, Batch 35, Loss: 0.048\n",
      "Training: Epoch 162, Batch 36, Loss: 0.054\n",
      "Training: Epoch 162, Batch 37, Loss: 0.058\n",
      "Training: Epoch 162, Batch 38, Loss: 0.056\n",
      "Training: Epoch 162, Batch 39, Loss: 0.078\n",
      "Training: Epoch 162, Batch 40, Loss: 0.061\n",
      "Training: Epoch 162, Batch 41, Loss: 0.065\n",
      "Training: Epoch 162, Batch 42, Loss: 0.07\n",
      "Training: Epoch 162, Batch 43, Loss: 0.069\n",
      "Training: Epoch 162, Batch 44, Loss: 0.068\n",
      "Training: Epoch 162, Batch 45, Loss: 0.068\n",
      "Training: Epoch 162, Batch 46, Loss: 0.075\n",
      "Training: Epoch 162, Batch 47, Loss: 0.066\n",
      "Training: Epoch 162, Batch 48, Loss: 0.056\n",
      "Training: Epoch 162, Batch 49, Loss: 0.064\n",
      "Training: Epoch 162, Batch 50, Loss: 0.081\n",
      "Training: Epoch 162, Batch 51, Loss: 0.059\n",
      "Training: Epoch 162, Batch 52, Loss: 0.06\n",
      "Training: Epoch 162, Batch 53, Loss: 0.071\n",
      "Training: Epoch 162, Batch 54, Loss: 0.069\n",
      "Training: Epoch 162, Batch 55, Loss: 0.063\n",
      "Training: Epoch 162, Batch 56, Loss: 0.068\n",
      "Training: Epoch 162, Batch 57, Loss: 0.064\n",
      "Training: Epoch 162, Batch 58, Loss: 0.045\n",
      "Training: Epoch 162, Batch 59, Loss: 0.072\n",
      "Val: Epoch 162, Loss: 0.305\n",
      "Training: Epoch 163, Batch 0, Loss: 0.055\n",
      "Training: Epoch 163, Batch 1, Loss: 0.068\n",
      "Training: Epoch 163, Batch 2, Loss: 0.079\n",
      "Training: Epoch 163, Batch 3, Loss: 0.064\n",
      "Training: Epoch 163, Batch 4, Loss: 0.054\n",
      "Training: Epoch 163, Batch 5, Loss: 0.061\n",
      "Training: Epoch 163, Batch 6, Loss: 0.059\n",
      "Training: Epoch 163, Batch 7, Loss: 0.058\n",
      "Training: Epoch 163, Batch 8, Loss: 0.082\n",
      "Training: Epoch 163, Batch 9, Loss: 0.061\n",
      "Training: Epoch 163, Batch 10, Loss: 0.057\n",
      "Training: Epoch 163, Batch 11, Loss: 0.077\n",
      "Training: Epoch 163, Batch 12, Loss: 0.055\n",
      "Training: Epoch 163, Batch 13, Loss: 0.063\n",
      "Training: Epoch 163, Batch 14, Loss: 0.063\n",
      "Training: Epoch 163, Batch 15, Loss: 0.056\n",
      "Training: Epoch 163, Batch 16, Loss: 0.065\n",
      "Training: Epoch 163, Batch 17, Loss: 0.069\n",
      "Training: Epoch 163, Batch 18, Loss: 0.074\n",
      "Training: Epoch 163, Batch 19, Loss: 0.076\n",
      "Training: Epoch 163, Batch 20, Loss: 0.066\n",
      "Training: Epoch 163, Batch 21, Loss: 0.058\n",
      "Training: Epoch 163, Batch 22, Loss: 0.062\n",
      "Training: Epoch 163, Batch 23, Loss: 0.063\n",
      "Training: Epoch 163, Batch 24, Loss: 0.064\n",
      "Training: Epoch 163, Batch 25, Loss: 0.065\n",
      "Training: Epoch 163, Batch 26, Loss: 0.054\n",
      "Training: Epoch 163, Batch 27, Loss: 0.064\n",
      "Training: Epoch 163, Batch 28, Loss: 0.056\n",
      "Training: Epoch 163, Batch 29, Loss: 0.079\n",
      "Training: Epoch 163, Batch 30, Loss: 0.06\n",
      "Training: Epoch 163, Batch 31, Loss: 0.058\n",
      "Training: Epoch 163, Batch 32, Loss: 0.06\n",
      "Training: Epoch 163, Batch 33, Loss: 0.075\n",
      "Training: Epoch 163, Batch 34, Loss: 0.071\n",
      "Training: Epoch 163, Batch 35, Loss: 0.073\n",
      "Training: Epoch 163, Batch 36, Loss: 0.059\n",
      "Training: Epoch 163, Batch 37, Loss: 0.057\n",
      "Training: Epoch 163, Batch 38, Loss: 0.063\n",
      "Training: Epoch 163, Batch 39, Loss: 0.059\n",
      "Training: Epoch 163, Batch 40, Loss: 0.066\n",
      "Training: Epoch 163, Batch 41, Loss: 0.07\n",
      "Training: Epoch 163, Batch 42, Loss: 0.069\n",
      "Training: Epoch 163, Batch 43, Loss: 0.057\n",
      "Training: Epoch 163, Batch 44, Loss: 0.061\n",
      "Training: Epoch 163, Batch 45, Loss: 0.065\n",
      "Training: Epoch 163, Batch 46, Loss: 0.065\n",
      "Training: Epoch 163, Batch 47, Loss: 0.074\n",
      "Training: Epoch 163, Batch 48, Loss: 0.056\n",
      "Training: Epoch 163, Batch 49, Loss: 0.052\n",
      "Training: Epoch 163, Batch 50, Loss: 0.077\n",
      "Training: Epoch 163, Batch 51, Loss: 0.052\n",
      "Training: Epoch 163, Batch 52, Loss: 0.059\n",
      "Training: Epoch 163, Batch 53, Loss: 0.063\n",
      "Training: Epoch 163, Batch 54, Loss: 0.056\n",
      "Training: Epoch 163, Batch 55, Loss: 0.056\n",
      "Training: Epoch 163, Batch 56, Loss: 0.06\n",
      "Training: Epoch 163, Batch 57, Loss: 0.073\n",
      "Training: Epoch 163, Batch 58, Loss: 0.066\n",
      "Training: Epoch 163, Batch 59, Loss: 0.055\n",
      "Val: Epoch 163, Loss: 0.322\n",
      "Training: Epoch 164, Batch 0, Loss: 0.058\n",
      "Training: Epoch 164, Batch 1, Loss: 0.057\n",
      "Training: Epoch 164, Batch 2, Loss: 0.063\n",
      "Training: Epoch 164, Batch 3, Loss: 0.066\n",
      "Training: Epoch 164, Batch 4, Loss: 0.055\n",
      "Training: Epoch 164, Batch 5, Loss: 0.067\n",
      "Training: Epoch 164, Batch 6, Loss: 0.065\n",
      "Training: Epoch 164, Batch 7, Loss: 0.072\n",
      "Training: Epoch 164, Batch 8, Loss: 0.077\n",
      "Training: Epoch 164, Batch 9, Loss: 0.064\n",
      "Training: Epoch 164, Batch 10, Loss: 0.071\n",
      "Training: Epoch 164, Batch 11, Loss: 0.064\n",
      "Training: Epoch 164, Batch 12, Loss: 0.067\n",
      "Training: Epoch 164, Batch 13, Loss: 0.062\n",
      "Training: Epoch 164, Batch 14, Loss: 0.07\n",
      "Training: Epoch 164, Batch 15, Loss: 0.061\n",
      "Training: Epoch 164, Batch 16, Loss: 0.05\n",
      "Training: Epoch 164, Batch 17, Loss: 0.064\n",
      "Training: Epoch 164, Batch 18, Loss: 0.055\n",
      "Training: Epoch 164, Batch 19, Loss: 0.055\n",
      "Training: Epoch 164, Batch 20, Loss: 0.077\n",
      "Training: Epoch 164, Batch 21, Loss: 0.056\n",
      "Training: Epoch 164, Batch 22, Loss: 0.081\n",
      "Training: Epoch 164, Batch 23, Loss: 0.062\n",
      "Training: Epoch 164, Batch 24, Loss: 0.049\n",
      "Training: Epoch 164, Batch 25, Loss: 0.061\n",
      "Training: Epoch 164, Batch 26, Loss: 0.081\n",
      "Training: Epoch 164, Batch 27, Loss: 0.066\n",
      "Training: Epoch 164, Batch 28, Loss: 0.069\n",
      "Training: Epoch 164, Batch 29, Loss: 0.057\n",
      "Training: Epoch 164, Batch 30, Loss: 0.051\n",
      "Training: Epoch 164, Batch 31, Loss: 0.072\n",
      "Training: Epoch 164, Batch 32, Loss: 0.07\n",
      "Training: Epoch 164, Batch 33, Loss: 0.058\n",
      "Training: Epoch 164, Batch 34, Loss: 0.053\n",
      "Training: Epoch 164, Batch 35, Loss: 0.075\n",
      "Training: Epoch 164, Batch 36, Loss: 0.051\n",
      "Training: Epoch 164, Batch 37, Loss: 0.072\n",
      "Training: Epoch 164, Batch 38, Loss: 0.064\n",
      "Training: Epoch 164, Batch 39, Loss: 0.051\n",
      "Training: Epoch 164, Batch 40, Loss: 0.06\n",
      "Training: Epoch 164, Batch 41, Loss: 0.06\n",
      "Training: Epoch 164, Batch 42, Loss: 0.064\n",
      "Training: Epoch 164, Batch 43, Loss: 0.056\n",
      "Training: Epoch 164, Batch 44, Loss: 0.067\n",
      "Training: Epoch 164, Batch 45, Loss: 0.052\n",
      "Training: Epoch 164, Batch 46, Loss: 0.06\n",
      "Training: Epoch 164, Batch 47, Loss: 0.066\n",
      "Training: Epoch 164, Batch 48, Loss: 0.064\n",
      "Training: Epoch 164, Batch 49, Loss: 0.06\n",
      "Training: Epoch 164, Batch 50, Loss: 0.05\n",
      "Training: Epoch 164, Batch 51, Loss: 0.062\n",
      "Training: Epoch 164, Batch 52, Loss: 0.067\n",
      "Training: Epoch 164, Batch 53, Loss: 0.067\n",
      "Training: Epoch 164, Batch 54, Loss: 0.057\n",
      "Training: Epoch 164, Batch 55, Loss: 0.088\n",
      "Training: Epoch 164, Batch 56, Loss: 0.058\n",
      "Training: Epoch 164, Batch 57, Loss: 0.066\n",
      "Training: Epoch 164, Batch 58, Loss: 0.045\n",
      "Training: Epoch 164, Batch 59, Loss: 0.072\n",
      "Val: Epoch 164, Loss: 0.324\n",
      "Training: Epoch 165, Batch 0, Loss: 0.066\n",
      "Training: Epoch 165, Batch 1, Loss: 0.065\n",
      "Training: Epoch 165, Batch 2, Loss: 0.057\n",
      "Training: Epoch 165, Batch 3, Loss: 0.062\n",
      "Training: Epoch 165, Batch 4, Loss: 0.067\n",
      "Training: Epoch 165, Batch 5, Loss: 0.05\n",
      "Training: Epoch 165, Batch 6, Loss: 0.066\n",
      "Training: Epoch 165, Batch 7, Loss: 0.06\n",
      "Training: Epoch 165, Batch 8, Loss: 0.055\n",
      "Training: Epoch 165, Batch 9, Loss: 0.075\n",
      "Training: Epoch 165, Batch 10, Loss: 0.061\n",
      "Training: Epoch 165, Batch 11, Loss: 0.079\n",
      "Training: Epoch 165, Batch 12, Loss: 0.073\n",
      "Training: Epoch 165, Batch 13, Loss: 0.071\n",
      "Training: Epoch 165, Batch 14, Loss: 0.07\n",
      "Training: Epoch 165, Batch 15, Loss: 0.045\n",
      "Training: Epoch 165, Batch 16, Loss: 0.061\n",
      "Training: Epoch 165, Batch 17, Loss: 0.06\n",
      "Training: Epoch 165, Batch 18, Loss: 0.066\n",
      "Training: Epoch 165, Batch 19, Loss: 0.057\n",
      "Training: Epoch 165, Batch 20, Loss: 0.07\n",
      "Training: Epoch 165, Batch 21, Loss: 0.066\n",
      "Training: Epoch 165, Batch 22, Loss: 0.051\n",
      "Training: Epoch 165, Batch 23, Loss: 0.068\n",
      "Training: Epoch 165, Batch 24, Loss: 0.085\n",
      "Training: Epoch 165, Batch 25, Loss: 0.071\n",
      "Training: Epoch 165, Batch 26, Loss: 0.052\n",
      "Training: Epoch 165, Batch 27, Loss: 0.048\n",
      "Training: Epoch 165, Batch 28, Loss: 0.064\n",
      "Training: Epoch 165, Batch 29, Loss: 0.072\n",
      "Training: Epoch 165, Batch 30, Loss: 0.076\n",
      "Training: Epoch 165, Batch 31, Loss: 0.071\n",
      "Training: Epoch 165, Batch 32, Loss: 0.05\n",
      "Training: Epoch 165, Batch 33, Loss: 0.058\n",
      "Training: Epoch 165, Batch 34, Loss: 0.061\n",
      "Training: Epoch 165, Batch 35, Loss: 0.073\n",
      "Training: Epoch 165, Batch 36, Loss: 0.075\n",
      "Training: Epoch 165, Batch 37, Loss: 0.059\n",
      "Training: Epoch 165, Batch 38, Loss: 0.069\n",
      "Training: Epoch 165, Batch 39, Loss: 0.063\n",
      "Training: Epoch 165, Batch 40, Loss: 0.068\n",
      "Training: Epoch 165, Batch 41, Loss: 0.068\n",
      "Training: Epoch 165, Batch 42, Loss: 0.04\n",
      "Training: Epoch 165, Batch 43, Loss: 0.061\n",
      "Training: Epoch 165, Batch 44, Loss: 0.084\n",
      "Training: Epoch 165, Batch 45, Loss: 0.044\n",
      "Training: Epoch 165, Batch 46, Loss: 0.081\n",
      "Training: Epoch 165, Batch 47, Loss: 0.057\n",
      "Training: Epoch 165, Batch 48, Loss: 0.055\n",
      "Training: Epoch 165, Batch 49, Loss: 0.068\n",
      "Training: Epoch 165, Batch 50, Loss: 0.075\n",
      "Training: Epoch 165, Batch 51, Loss: 0.055\n",
      "Training: Epoch 165, Batch 52, Loss: 0.054\n",
      "Training: Epoch 165, Batch 53, Loss: 0.047\n",
      "Training: Epoch 165, Batch 54, Loss: 0.062\n",
      "Training: Epoch 165, Batch 55, Loss: 0.064\n",
      "Training: Epoch 165, Batch 56, Loss: 0.078\n",
      "Training: Epoch 165, Batch 57, Loss: 0.066\n",
      "Training: Epoch 165, Batch 58, Loss: 0.061\n",
      "Training: Epoch 165, Batch 59, Loss: 0.058\n",
      "Val: Epoch 165, Loss: 0.295\n",
      "Training: Epoch 166, Batch 0, Loss: 0.065\n",
      "Training: Epoch 166, Batch 1, Loss: 0.061\n",
      "Training: Epoch 166, Batch 2, Loss: 0.055\n",
      "Training: Epoch 166, Batch 3, Loss: 0.066\n",
      "Training: Epoch 166, Batch 4, Loss: 0.074\n",
      "Training: Epoch 166, Batch 5, Loss: 0.055\n",
      "Training: Epoch 166, Batch 6, Loss: 0.053\n",
      "Training: Epoch 166, Batch 7, Loss: 0.062\n",
      "Training: Epoch 166, Batch 8, Loss: 0.072\n",
      "Training: Epoch 166, Batch 9, Loss: 0.066\n",
      "Training: Epoch 166, Batch 10, Loss: 0.059\n",
      "Training: Epoch 166, Batch 11, Loss: 0.055\n",
      "Training: Epoch 166, Batch 12, Loss: 0.066\n",
      "Training: Epoch 166, Batch 13, Loss: 0.069\n",
      "Training: Epoch 166, Batch 14, Loss: 0.071\n",
      "Training: Epoch 166, Batch 15, Loss: 0.057\n",
      "Training: Epoch 166, Batch 16, Loss: 0.06\n",
      "Training: Epoch 166, Batch 17, Loss: 0.055\n",
      "Training: Epoch 166, Batch 18, Loss: 0.055\n",
      "Training: Epoch 166, Batch 19, Loss: 0.067\n",
      "Training: Epoch 166, Batch 20, Loss: 0.056\n",
      "Training: Epoch 166, Batch 21, Loss: 0.076\n",
      "Training: Epoch 166, Batch 22, Loss: 0.066\n",
      "Training: Epoch 166, Batch 23, Loss: 0.064\n",
      "Training: Epoch 166, Batch 24, Loss: 0.056\n",
      "Training: Epoch 166, Batch 25, Loss: 0.062\n",
      "Training: Epoch 166, Batch 26, Loss: 0.058\n",
      "Training: Epoch 166, Batch 27, Loss: 0.059\n",
      "Training: Epoch 166, Batch 28, Loss: 0.107\n",
      "Training: Epoch 166, Batch 29, Loss: 0.073\n",
      "Training: Epoch 166, Batch 30, Loss: 0.06\n",
      "Training: Epoch 166, Batch 31, Loss: 0.066\n",
      "Training: Epoch 166, Batch 32, Loss: 0.062\n",
      "Training: Epoch 166, Batch 33, Loss: 0.064\n",
      "Training: Epoch 166, Batch 34, Loss: 0.05\n",
      "Training: Epoch 166, Batch 35, Loss: 0.063\n",
      "Training: Epoch 166, Batch 36, Loss: 0.075\n",
      "Training: Epoch 166, Batch 37, Loss: 0.058\n",
      "Training: Epoch 166, Batch 38, Loss: 0.053\n",
      "Training: Epoch 166, Batch 39, Loss: 0.071\n",
      "Training: Epoch 166, Batch 40, Loss: 0.063\n",
      "Training: Epoch 166, Batch 41, Loss: 0.051\n",
      "Training: Epoch 166, Batch 42, Loss: 0.061\n",
      "Training: Epoch 166, Batch 43, Loss: 0.051\n",
      "Training: Epoch 166, Batch 44, Loss: 0.056\n",
      "Training: Epoch 166, Batch 45, Loss: 0.053\n",
      "Training: Epoch 166, Batch 46, Loss: 0.062\n",
      "Training: Epoch 166, Batch 47, Loss: 0.068\n",
      "Training: Epoch 166, Batch 48, Loss: 0.057\n",
      "Training: Epoch 166, Batch 49, Loss: 0.085\n",
      "Training: Epoch 166, Batch 50, Loss: 0.051\n",
      "Training: Epoch 166, Batch 51, Loss: 0.074\n",
      "Training: Epoch 166, Batch 52, Loss: 0.054\n",
      "Training: Epoch 166, Batch 53, Loss: 0.053\n",
      "Training: Epoch 166, Batch 54, Loss: 0.059\n",
      "Training: Epoch 166, Batch 55, Loss: 0.06\n",
      "Training: Epoch 166, Batch 56, Loss: 0.06\n",
      "Training: Epoch 166, Batch 57, Loss: 0.059\n",
      "Training: Epoch 166, Batch 58, Loss: 0.049\n",
      "Training: Epoch 166, Batch 59, Loss: 0.06\n",
      "Val: Epoch 166, Loss: 0.312\n",
      "Training: Epoch 167, Batch 0, Loss: 0.054\n",
      "Training: Epoch 167, Batch 1, Loss: 0.052\n",
      "Training: Epoch 167, Batch 2, Loss: 0.059\n",
      "Training: Epoch 167, Batch 3, Loss: 0.059\n",
      "Training: Epoch 167, Batch 4, Loss: 0.067\n",
      "Training: Epoch 167, Batch 5, Loss: 0.059\n",
      "Training: Epoch 167, Batch 6, Loss: 0.079\n",
      "Training: Epoch 167, Batch 7, Loss: 0.059\n",
      "Training: Epoch 167, Batch 8, Loss: 0.062\n",
      "Training: Epoch 167, Batch 9, Loss: 0.069\n",
      "Training: Epoch 167, Batch 10, Loss: 0.07\n",
      "Training: Epoch 167, Batch 11, Loss: 0.052\n",
      "Training: Epoch 167, Batch 12, Loss: 0.054\n",
      "Training: Epoch 167, Batch 13, Loss: 0.062\n",
      "Training: Epoch 167, Batch 14, Loss: 0.054\n",
      "Training: Epoch 167, Batch 15, Loss: 0.073\n",
      "Training: Epoch 167, Batch 16, Loss: 0.067\n",
      "Training: Epoch 167, Batch 17, Loss: 0.066\n",
      "Training: Epoch 167, Batch 18, Loss: 0.061\n",
      "Training: Epoch 167, Batch 19, Loss: 0.062\n",
      "Training: Epoch 167, Batch 20, Loss: 0.058\n",
      "Training: Epoch 167, Batch 21, Loss: 0.05\n",
      "Training: Epoch 167, Batch 22, Loss: 0.049\n",
      "Training: Epoch 167, Batch 23, Loss: 0.081\n",
      "Training: Epoch 167, Batch 24, Loss: 0.066\n",
      "Training: Epoch 167, Batch 25, Loss: 0.079\n",
      "Training: Epoch 167, Batch 26, Loss: 0.065\n",
      "Training: Epoch 167, Batch 27, Loss: 0.056\n",
      "Training: Epoch 167, Batch 28, Loss: 0.048\n",
      "Training: Epoch 167, Batch 29, Loss: 0.071\n",
      "Training: Epoch 167, Batch 30, Loss: 0.059\n",
      "Training: Epoch 167, Batch 31, Loss: 0.059\n",
      "Training: Epoch 167, Batch 32, Loss: 0.056\n",
      "Training: Epoch 167, Batch 33, Loss: 0.069\n",
      "Training: Epoch 167, Batch 34, Loss: 0.064\n",
      "Training: Epoch 167, Batch 35, Loss: 0.078\n",
      "Training: Epoch 167, Batch 36, Loss: 0.063\n",
      "Training: Epoch 167, Batch 37, Loss: 0.068\n",
      "Training: Epoch 167, Batch 38, Loss: 0.059\n",
      "Training: Epoch 167, Batch 39, Loss: 0.064\n",
      "Training: Epoch 167, Batch 40, Loss: 0.062\n",
      "Training: Epoch 167, Batch 41, Loss: 0.057\n",
      "Training: Epoch 167, Batch 42, Loss: 0.08\n",
      "Training: Epoch 167, Batch 43, Loss: 0.06\n",
      "Training: Epoch 167, Batch 44, Loss: 0.068\n",
      "Training: Epoch 167, Batch 45, Loss: 0.044\n",
      "Training: Epoch 167, Batch 46, Loss: 0.067\n",
      "Training: Epoch 167, Batch 47, Loss: 0.068\n",
      "Training: Epoch 167, Batch 48, Loss: 0.058\n",
      "Training: Epoch 167, Batch 49, Loss: 0.073\n",
      "Training: Epoch 167, Batch 50, Loss: 0.059\n",
      "Training: Epoch 167, Batch 51, Loss: 0.053\n",
      "Training: Epoch 167, Batch 52, Loss: 0.072\n",
      "Training: Epoch 167, Batch 53, Loss: 0.06\n",
      "Training: Epoch 167, Batch 54, Loss: 0.059\n",
      "Training: Epoch 167, Batch 55, Loss: 0.042\n",
      "Training: Epoch 167, Batch 56, Loss: 0.065\n",
      "Training: Epoch 167, Batch 57, Loss: 0.069\n",
      "Training: Epoch 167, Batch 58, Loss: 0.058\n",
      "Training: Epoch 167, Batch 59, Loss: 0.059\n",
      "Val: Epoch 167, Loss: 0.318\n",
      "Training: Epoch 168, Batch 0, Loss: 0.063\n",
      "Training: Epoch 168, Batch 1, Loss: 0.061\n",
      "Training: Epoch 168, Batch 2, Loss: 0.065\n",
      "Training: Epoch 168, Batch 3, Loss: 0.05\n",
      "Training: Epoch 168, Batch 4, Loss: 0.075\n",
      "Training: Epoch 168, Batch 5, Loss: 0.052\n",
      "Training: Epoch 168, Batch 6, Loss: 0.062\n",
      "Training: Epoch 168, Batch 7, Loss: 0.053\n",
      "Training: Epoch 168, Batch 8, Loss: 0.071\n",
      "Training: Epoch 168, Batch 9, Loss: 0.046\n",
      "Training: Epoch 168, Batch 10, Loss: 0.063\n",
      "Training: Epoch 168, Batch 11, Loss: 0.061\n",
      "Training: Epoch 168, Batch 12, Loss: 0.054\n",
      "Training: Epoch 168, Batch 13, Loss: 0.06\n",
      "Training: Epoch 168, Batch 14, Loss: 0.061\n",
      "Training: Epoch 168, Batch 15, Loss: 0.049\n",
      "Training: Epoch 168, Batch 16, Loss: 0.059\n",
      "Training: Epoch 168, Batch 17, Loss: 0.06\n",
      "Training: Epoch 168, Batch 18, Loss: 0.062\n",
      "Training: Epoch 168, Batch 19, Loss: 0.046\n",
      "Training: Epoch 168, Batch 20, Loss: 0.053\n",
      "Training: Epoch 168, Batch 21, Loss: 0.059\n",
      "Training: Epoch 168, Batch 22, Loss: 0.063\n",
      "Training: Epoch 168, Batch 23, Loss: 0.064\n",
      "Training: Epoch 168, Batch 24, Loss: 0.056\n",
      "Training: Epoch 168, Batch 25, Loss: 0.054\n",
      "Training: Epoch 168, Batch 26, Loss: 0.063\n",
      "Training: Epoch 168, Batch 27, Loss: 0.059\n",
      "Training: Epoch 168, Batch 28, Loss: 0.073\n",
      "Training: Epoch 168, Batch 29, Loss: 0.071\n",
      "Training: Epoch 168, Batch 30, Loss: 0.068\n",
      "Training: Epoch 168, Batch 31, Loss: 0.055\n",
      "Training: Epoch 168, Batch 32, Loss: 0.065\n",
      "Training: Epoch 168, Batch 33, Loss: 0.07\n",
      "Training: Epoch 168, Batch 34, Loss: 0.063\n",
      "Training: Epoch 168, Batch 35, Loss: 0.065\n",
      "Training: Epoch 168, Batch 36, Loss: 0.055\n",
      "Training: Epoch 168, Batch 37, Loss: 0.068\n",
      "Training: Epoch 168, Batch 38, Loss: 0.048\n",
      "Training: Epoch 168, Batch 39, Loss: 0.057\n",
      "Training: Epoch 168, Batch 40, Loss: 0.079\n",
      "Training: Epoch 168, Batch 41, Loss: 0.064\n",
      "Training: Epoch 168, Batch 42, Loss: 0.059\n",
      "Training: Epoch 168, Batch 43, Loss: 0.064\n",
      "Training: Epoch 168, Batch 44, Loss: 0.071\n",
      "Training: Epoch 168, Batch 45, Loss: 0.072\n",
      "Training: Epoch 168, Batch 46, Loss: 0.063\n",
      "Training: Epoch 168, Batch 47, Loss: 0.066\n",
      "Training: Epoch 168, Batch 48, Loss: 0.051\n",
      "Training: Epoch 168, Batch 49, Loss: 0.062\n",
      "Training: Epoch 168, Batch 50, Loss: 0.052\n",
      "Training: Epoch 168, Batch 51, Loss: 0.075\n",
      "Training: Epoch 168, Batch 52, Loss: 0.05\n",
      "Training: Epoch 168, Batch 53, Loss: 0.053\n",
      "Training: Epoch 168, Batch 54, Loss: 0.069\n",
      "Training: Epoch 168, Batch 55, Loss: 0.055\n",
      "Training: Epoch 168, Batch 56, Loss: 0.058\n",
      "Training: Epoch 168, Batch 57, Loss: 0.076\n",
      "Training: Epoch 168, Batch 58, Loss: 0.091\n",
      "Training: Epoch 168, Batch 59, Loss: 0.06\n",
      "Val: Epoch 168, Loss: 0.312\n",
      "Training: Epoch 169, Batch 0, Loss: 0.058\n",
      "Training: Epoch 169, Batch 1, Loss: 0.059\n",
      "Training: Epoch 169, Batch 2, Loss: 0.056\n",
      "Training: Epoch 169, Batch 3, Loss: 0.068\n",
      "Training: Epoch 169, Batch 4, Loss: 0.055\n",
      "Training: Epoch 169, Batch 5, Loss: 0.061\n",
      "Training: Epoch 169, Batch 6, Loss: 0.067\n",
      "Training: Epoch 169, Batch 7, Loss: 0.08\n",
      "Training: Epoch 169, Batch 8, Loss: 0.058\n",
      "Training: Epoch 169, Batch 9, Loss: 0.053\n",
      "Training: Epoch 169, Batch 10, Loss: 0.062\n",
      "Training: Epoch 169, Batch 11, Loss: 0.056\n",
      "Training: Epoch 169, Batch 12, Loss: 0.061\n",
      "Training: Epoch 169, Batch 13, Loss: 0.072\n",
      "Training: Epoch 169, Batch 14, Loss: 0.062\n",
      "Training: Epoch 169, Batch 15, Loss: 0.06\n",
      "Training: Epoch 169, Batch 16, Loss: 0.057\n",
      "Training: Epoch 169, Batch 17, Loss: 0.081\n",
      "Training: Epoch 169, Batch 18, Loss: 0.061\n",
      "Training: Epoch 169, Batch 19, Loss: 0.053\n",
      "Training: Epoch 169, Batch 20, Loss: 0.055\n",
      "Training: Epoch 169, Batch 21, Loss: 0.078\n",
      "Training: Epoch 169, Batch 22, Loss: 0.054\n",
      "Training: Epoch 169, Batch 23, Loss: 0.061\n",
      "Training: Epoch 169, Batch 24, Loss: 0.054\n",
      "Training: Epoch 169, Batch 25, Loss: 0.075\n",
      "Training: Epoch 169, Batch 26, Loss: 0.062\n",
      "Training: Epoch 169, Batch 27, Loss: 0.062\n",
      "Training: Epoch 169, Batch 28, Loss: 0.051\n",
      "Training: Epoch 169, Batch 29, Loss: 0.064\n",
      "Training: Epoch 169, Batch 30, Loss: 0.071\n",
      "Training: Epoch 169, Batch 31, Loss: 0.058\n",
      "Training: Epoch 169, Batch 32, Loss: 0.061\n",
      "Training: Epoch 169, Batch 33, Loss: 0.056\n",
      "Training: Epoch 169, Batch 34, Loss: 0.069\n",
      "Training: Epoch 169, Batch 35, Loss: 0.073\n",
      "Training: Epoch 169, Batch 36, Loss: 0.063\n",
      "Training: Epoch 169, Batch 37, Loss: 0.052\n",
      "Training: Epoch 169, Batch 38, Loss: 0.074\n",
      "Training: Epoch 169, Batch 39, Loss: 0.071\n",
      "Training: Epoch 169, Batch 40, Loss: 0.067\n",
      "Training: Epoch 169, Batch 41, Loss: 0.067\n",
      "Training: Epoch 169, Batch 42, Loss: 0.057\n",
      "Training: Epoch 169, Batch 43, Loss: 0.061\n",
      "Training: Epoch 169, Batch 44, Loss: 0.063\n",
      "Training: Epoch 169, Batch 45, Loss: 0.099\n",
      "Training: Epoch 169, Batch 46, Loss: 0.061\n",
      "Training: Epoch 169, Batch 47, Loss: 0.063\n",
      "Training: Epoch 169, Batch 48, Loss: 0.061\n",
      "Training: Epoch 169, Batch 49, Loss: 0.058\n",
      "Training: Epoch 169, Batch 50, Loss: 0.054\n",
      "Training: Epoch 169, Batch 51, Loss: 0.066\n",
      "Training: Epoch 169, Batch 52, Loss: 0.056\n",
      "Training: Epoch 169, Batch 53, Loss: 0.066\n",
      "Training: Epoch 169, Batch 54, Loss: 0.049\n",
      "Training: Epoch 169, Batch 55, Loss: 0.077\n",
      "Training: Epoch 169, Batch 56, Loss: 0.058\n",
      "Training: Epoch 169, Batch 57, Loss: 0.065\n",
      "Training: Epoch 169, Batch 58, Loss: 0.054\n",
      "Training: Epoch 169, Batch 59, Loss: 0.061\n",
      "Val: Epoch 169, Loss: 0.314\n",
      "Training: Epoch 170, Batch 0, Loss: 0.06\n",
      "Training: Epoch 170, Batch 1, Loss: 0.057\n",
      "Training: Epoch 170, Batch 2, Loss: 0.059\n",
      "Training: Epoch 170, Batch 3, Loss: 0.05\n",
      "Training: Epoch 170, Batch 4, Loss: 0.06\n",
      "Training: Epoch 170, Batch 5, Loss: 0.058\n",
      "Training: Epoch 170, Batch 6, Loss: 0.076\n",
      "Training: Epoch 170, Batch 7, Loss: 0.065\n",
      "Training: Epoch 170, Batch 8, Loss: 0.054\n",
      "Training: Epoch 170, Batch 9, Loss: 0.078\n",
      "Training: Epoch 170, Batch 10, Loss: 0.054\n",
      "Training: Epoch 170, Batch 11, Loss: 0.06\n",
      "Training: Epoch 170, Batch 12, Loss: 0.052\n",
      "Training: Epoch 170, Batch 13, Loss: 0.058\n",
      "Training: Epoch 170, Batch 14, Loss: 0.07\n",
      "Training: Epoch 170, Batch 15, Loss: 0.055\n",
      "Training: Epoch 170, Batch 16, Loss: 0.069\n",
      "Training: Epoch 170, Batch 17, Loss: 0.06\n",
      "Training: Epoch 170, Batch 18, Loss: 0.054\n",
      "Training: Epoch 170, Batch 19, Loss: 0.055\n",
      "Training: Epoch 170, Batch 20, Loss: 0.068\n",
      "Training: Epoch 170, Batch 21, Loss: 0.063\n",
      "Training: Epoch 170, Batch 22, Loss: 0.056\n",
      "Training: Epoch 170, Batch 23, Loss: 0.07\n",
      "Training: Epoch 170, Batch 24, Loss: 0.067\n",
      "Training: Epoch 170, Batch 25, Loss: 0.066\n",
      "Training: Epoch 170, Batch 26, Loss: 0.053\n",
      "Training: Epoch 170, Batch 27, Loss: 0.053\n",
      "Training: Epoch 170, Batch 28, Loss: 0.067\n",
      "Training: Epoch 170, Batch 29, Loss: 0.045\n",
      "Training: Epoch 170, Batch 30, Loss: 0.069\n",
      "Training: Epoch 170, Batch 31, Loss: 0.065\n",
      "Training: Epoch 170, Batch 32, Loss: 0.058\n",
      "Training: Epoch 170, Batch 33, Loss: 0.066\n",
      "Training: Epoch 170, Batch 34, Loss: 0.073\n",
      "Training: Epoch 170, Batch 35, Loss: 0.062\n",
      "Training: Epoch 170, Batch 36, Loss: 0.061\n",
      "Training: Epoch 170, Batch 37, Loss: 0.069\n",
      "Training: Epoch 170, Batch 38, Loss: 0.073\n",
      "Training: Epoch 170, Batch 39, Loss: 0.051\n",
      "Training: Epoch 170, Batch 40, Loss: 0.063\n",
      "Training: Epoch 170, Batch 41, Loss: 0.066\n",
      "Training: Epoch 170, Batch 42, Loss: 0.05\n",
      "Training: Epoch 170, Batch 43, Loss: 0.066\n",
      "Training: Epoch 170, Batch 44, Loss: 0.056\n",
      "Training: Epoch 170, Batch 45, Loss: 0.056\n",
      "Training: Epoch 170, Batch 46, Loss: 0.066\n",
      "Training: Epoch 170, Batch 47, Loss: 0.073\n",
      "Training: Epoch 170, Batch 48, Loss: 0.087\n",
      "Training: Epoch 170, Batch 49, Loss: 0.046\n",
      "Training: Epoch 170, Batch 50, Loss: 0.068\n",
      "Training: Epoch 170, Batch 51, Loss: 0.057\n",
      "Training: Epoch 170, Batch 52, Loss: 0.057\n",
      "Training: Epoch 170, Batch 53, Loss: 0.056\n",
      "Training: Epoch 170, Batch 54, Loss: 0.059\n",
      "Training: Epoch 170, Batch 55, Loss: 0.068\n",
      "Training: Epoch 170, Batch 56, Loss: 0.066\n",
      "Training: Epoch 170, Batch 57, Loss: 0.068\n",
      "Training: Epoch 170, Batch 58, Loss: 0.052\n",
      "Training: Epoch 170, Batch 59, Loss: 0.062\n",
      "Val: Epoch 170, Loss: 0.333\n",
      "Training: Epoch 171, Batch 0, Loss: 0.061\n",
      "Training: Epoch 171, Batch 1, Loss: 0.065\n",
      "Training: Epoch 171, Batch 2, Loss: 0.06\n",
      "Training: Epoch 171, Batch 3, Loss: 0.052\n",
      "Training: Epoch 171, Batch 4, Loss: 0.072\n",
      "Training: Epoch 171, Batch 5, Loss: 0.07\n",
      "Training: Epoch 171, Batch 6, Loss: 0.07\n",
      "Training: Epoch 171, Batch 7, Loss: 0.069\n",
      "Training: Epoch 171, Batch 8, Loss: 0.067\n",
      "Training: Epoch 171, Batch 9, Loss: 0.067\n",
      "Training: Epoch 171, Batch 10, Loss: 0.052\n",
      "Training: Epoch 171, Batch 11, Loss: 0.077\n",
      "Training: Epoch 171, Batch 12, Loss: 0.082\n",
      "Training: Epoch 171, Batch 13, Loss: 0.074\n",
      "Training: Epoch 171, Batch 14, Loss: 0.06\n",
      "Training: Epoch 171, Batch 15, Loss: 0.064\n",
      "Training: Epoch 171, Batch 16, Loss: 0.053\n",
      "Training: Epoch 171, Batch 17, Loss: 0.052\n",
      "Training: Epoch 171, Batch 18, Loss: 0.063\n",
      "Training: Epoch 171, Batch 19, Loss: 0.075\n",
      "Training: Epoch 171, Batch 20, Loss: 0.059\n",
      "Training: Epoch 171, Batch 21, Loss: 0.06\n",
      "Training: Epoch 171, Batch 22, Loss: 0.065\n",
      "Training: Epoch 171, Batch 23, Loss: 0.067\n",
      "Training: Epoch 171, Batch 24, Loss: 0.068\n",
      "Training: Epoch 171, Batch 25, Loss: 0.06\n",
      "Training: Epoch 171, Batch 26, Loss: 0.052\n",
      "Training: Epoch 171, Batch 27, Loss: 0.057\n",
      "Training: Epoch 171, Batch 28, Loss: 0.048\n",
      "Training: Epoch 171, Batch 29, Loss: 0.058\n",
      "Training: Epoch 171, Batch 30, Loss: 0.065\n",
      "Training: Epoch 171, Batch 31, Loss: 0.056\n",
      "Training: Epoch 171, Batch 32, Loss: 0.071\n",
      "Training: Epoch 171, Batch 33, Loss: 0.058\n",
      "Training: Epoch 171, Batch 34, Loss: 0.051\n",
      "Training: Epoch 171, Batch 35, Loss: 0.074\n",
      "Training: Epoch 171, Batch 36, Loss: 0.059\n",
      "Training: Epoch 171, Batch 37, Loss: 0.048\n",
      "Training: Epoch 171, Batch 38, Loss: 0.045\n",
      "Training: Epoch 171, Batch 39, Loss: 0.063\n",
      "Training: Epoch 171, Batch 40, Loss: 0.045\n",
      "Training: Epoch 171, Batch 41, Loss: 0.062\n",
      "Training: Epoch 171, Batch 42, Loss: 0.071\n",
      "Training: Epoch 171, Batch 43, Loss: 0.067\n",
      "Training: Epoch 171, Batch 44, Loss: 0.06\n",
      "Training: Epoch 171, Batch 45, Loss: 0.065\n",
      "Training: Epoch 171, Batch 46, Loss: 0.064\n",
      "Training: Epoch 171, Batch 47, Loss: 0.062\n",
      "Training: Epoch 171, Batch 48, Loss: 0.061\n",
      "Training: Epoch 171, Batch 49, Loss: 0.066\n",
      "Training: Epoch 171, Batch 50, Loss: 0.071\n",
      "Training: Epoch 171, Batch 51, Loss: 0.058\n",
      "Training: Epoch 171, Batch 52, Loss: 0.069\n",
      "Training: Epoch 171, Batch 53, Loss: 0.054\n",
      "Training: Epoch 171, Batch 54, Loss: 0.053\n",
      "Training: Epoch 171, Batch 55, Loss: 0.053\n",
      "Training: Epoch 171, Batch 56, Loss: 0.057\n",
      "Training: Epoch 171, Batch 57, Loss: 0.076\n",
      "Training: Epoch 171, Batch 58, Loss: 0.053\n",
      "Training: Epoch 171, Batch 59, Loss: 0.062\n",
      "Val: Epoch 171, Loss: 0.323\n",
      "Training: Epoch 172, Batch 0, Loss: 0.04\n",
      "Training: Epoch 172, Batch 1, Loss: 0.059\n",
      "Training: Epoch 172, Batch 2, Loss: 0.07\n",
      "Training: Epoch 172, Batch 3, Loss: 0.052\n",
      "Training: Epoch 172, Batch 4, Loss: 0.059\n",
      "Training: Epoch 172, Batch 5, Loss: 0.061\n",
      "Training: Epoch 172, Batch 6, Loss: 0.057\n",
      "Training: Epoch 172, Batch 7, Loss: 0.064\n",
      "Training: Epoch 172, Batch 8, Loss: 0.052\n",
      "Training: Epoch 172, Batch 9, Loss: 0.05\n",
      "Training: Epoch 172, Batch 10, Loss: 0.052\n",
      "Training: Epoch 172, Batch 11, Loss: 0.051\n",
      "Training: Epoch 172, Batch 12, Loss: 0.06\n",
      "Training: Epoch 172, Batch 13, Loss: 0.063\n",
      "Training: Epoch 172, Batch 14, Loss: 0.054\n",
      "Training: Epoch 172, Batch 15, Loss: 0.057\n",
      "Training: Epoch 172, Batch 16, Loss: 0.068\n",
      "Training: Epoch 172, Batch 17, Loss: 0.063\n",
      "Training: Epoch 172, Batch 18, Loss: 0.064\n",
      "Training: Epoch 172, Batch 19, Loss: 0.045\n",
      "Training: Epoch 172, Batch 20, Loss: 0.057\n",
      "Training: Epoch 172, Batch 21, Loss: 0.067\n",
      "Training: Epoch 172, Batch 22, Loss: 0.059\n",
      "Training: Epoch 172, Batch 23, Loss: 0.064\n",
      "Training: Epoch 172, Batch 24, Loss: 0.064\n",
      "Training: Epoch 172, Batch 25, Loss: 0.061\n",
      "Training: Epoch 172, Batch 26, Loss: 0.054\n",
      "Training: Epoch 172, Batch 27, Loss: 0.058\n",
      "Training: Epoch 172, Batch 28, Loss: 0.058\n",
      "Training: Epoch 172, Batch 29, Loss: 0.056\n",
      "Training: Epoch 172, Batch 30, Loss: 0.053\n",
      "Training: Epoch 172, Batch 31, Loss: 0.065\n",
      "Training: Epoch 172, Batch 32, Loss: 0.053\n",
      "Training: Epoch 172, Batch 33, Loss: 0.049\n",
      "Training: Epoch 172, Batch 34, Loss: 0.052\n",
      "Training: Epoch 172, Batch 35, Loss: 0.076\n",
      "Training: Epoch 172, Batch 36, Loss: 0.067\n",
      "Training: Epoch 172, Batch 37, Loss: 0.066\n",
      "Training: Epoch 172, Batch 38, Loss: 0.061\n",
      "Training: Epoch 172, Batch 39, Loss: 0.064\n",
      "Training: Epoch 172, Batch 40, Loss: 0.07\n",
      "Training: Epoch 172, Batch 41, Loss: 0.059\n",
      "Training: Epoch 172, Batch 42, Loss: 0.066\n",
      "Training: Epoch 172, Batch 43, Loss: 0.064\n",
      "Training: Epoch 172, Batch 44, Loss: 0.051\n",
      "Training: Epoch 172, Batch 45, Loss: 0.06\n",
      "Training: Epoch 172, Batch 46, Loss: 0.075\n",
      "Training: Epoch 172, Batch 47, Loss: 0.052\n",
      "Training: Epoch 172, Batch 48, Loss: 0.069\n",
      "Training: Epoch 172, Batch 49, Loss: 0.072\n",
      "Training: Epoch 172, Batch 50, Loss: 0.063\n",
      "Training: Epoch 172, Batch 51, Loss: 0.07\n",
      "Training: Epoch 172, Batch 52, Loss: 0.07\n",
      "Training: Epoch 172, Batch 53, Loss: 0.062\n",
      "Training: Epoch 172, Batch 54, Loss: 0.07\n",
      "Training: Epoch 172, Batch 55, Loss: 0.045\n",
      "Training: Epoch 172, Batch 56, Loss: 0.067\n",
      "Training: Epoch 172, Batch 57, Loss: 0.078\n",
      "Training: Epoch 172, Batch 58, Loss: 0.051\n",
      "Training: Epoch 172, Batch 59, Loss: 0.057\n",
      "Val: Epoch 172, Loss: 0.319\n",
      "Training: Epoch 173, Batch 0, Loss: 0.047\n",
      "Training: Epoch 173, Batch 1, Loss: 0.069\n",
      "Training: Epoch 173, Batch 2, Loss: 0.05\n",
      "Training: Epoch 173, Batch 3, Loss: 0.061\n",
      "Training: Epoch 173, Batch 4, Loss: 0.06\n",
      "Training: Epoch 173, Batch 5, Loss: 0.063\n",
      "Training: Epoch 173, Batch 6, Loss: 0.056\n",
      "Training: Epoch 173, Batch 7, Loss: 0.055\n",
      "Training: Epoch 173, Batch 8, Loss: 0.057\n",
      "Training: Epoch 173, Batch 9, Loss: 0.062\n",
      "Training: Epoch 173, Batch 10, Loss: 0.069\n",
      "Training: Epoch 173, Batch 11, Loss: 0.063\n",
      "Training: Epoch 173, Batch 12, Loss: 0.054\n",
      "Training: Epoch 173, Batch 13, Loss: 0.075\n",
      "Training: Epoch 173, Batch 14, Loss: 0.061\n",
      "Training: Epoch 173, Batch 15, Loss: 0.06\n",
      "Training: Epoch 173, Batch 16, Loss: 0.06\n",
      "Training: Epoch 173, Batch 17, Loss: 0.074\n",
      "Training: Epoch 173, Batch 18, Loss: 0.078\n",
      "Training: Epoch 173, Batch 19, Loss: 0.059\n",
      "Training: Epoch 173, Batch 20, Loss: 0.086\n",
      "Training: Epoch 173, Batch 21, Loss: 0.056\n",
      "Training: Epoch 173, Batch 22, Loss: 0.067\n",
      "Training: Epoch 173, Batch 23, Loss: 0.054\n",
      "Training: Epoch 173, Batch 24, Loss: 0.067\n",
      "Training: Epoch 173, Batch 25, Loss: 0.053\n",
      "Training: Epoch 173, Batch 26, Loss: 0.058\n",
      "Training: Epoch 173, Batch 27, Loss: 0.05\n",
      "Training: Epoch 173, Batch 28, Loss: 0.062\n",
      "Training: Epoch 173, Batch 29, Loss: 0.059\n",
      "Training: Epoch 173, Batch 30, Loss: 0.044\n",
      "Training: Epoch 173, Batch 31, Loss: 0.059\n",
      "Training: Epoch 173, Batch 32, Loss: 0.067\n",
      "Training: Epoch 173, Batch 33, Loss: 0.063\n",
      "Training: Epoch 173, Batch 34, Loss: 0.076\n",
      "Training: Epoch 173, Batch 35, Loss: 0.074\n",
      "Training: Epoch 173, Batch 36, Loss: 0.054\n",
      "Training: Epoch 173, Batch 37, Loss: 0.053\n",
      "Training: Epoch 173, Batch 38, Loss: 0.077\n",
      "Training: Epoch 173, Batch 39, Loss: 0.045\n",
      "Training: Epoch 173, Batch 40, Loss: 0.062\n",
      "Training: Epoch 173, Batch 41, Loss: 0.049\n",
      "Training: Epoch 173, Batch 42, Loss: 0.047\n",
      "Training: Epoch 173, Batch 43, Loss: 0.053\n",
      "Training: Epoch 173, Batch 44, Loss: 0.072\n",
      "Training: Epoch 173, Batch 45, Loss: 0.057\n",
      "Training: Epoch 173, Batch 46, Loss: 0.057\n",
      "Training: Epoch 173, Batch 47, Loss: 0.063\n",
      "Training: Epoch 173, Batch 48, Loss: 0.076\n",
      "Training: Epoch 173, Batch 49, Loss: 0.077\n",
      "Training: Epoch 173, Batch 50, Loss: 0.058\n",
      "Training: Epoch 173, Batch 51, Loss: 0.068\n",
      "Training: Epoch 173, Batch 52, Loss: 0.067\n",
      "Training: Epoch 173, Batch 53, Loss: 0.057\n",
      "Training: Epoch 173, Batch 54, Loss: 0.056\n",
      "Training: Epoch 173, Batch 55, Loss: 0.052\n",
      "Training: Epoch 173, Batch 56, Loss: 0.058\n",
      "Training: Epoch 173, Batch 57, Loss: 0.064\n",
      "Training: Epoch 173, Batch 58, Loss: 0.064\n",
      "Training: Epoch 173, Batch 59, Loss: 0.055\n",
      "Val: Epoch 173, Loss: 0.34\n",
      "Training: Epoch 174, Batch 0, Loss: 0.05\n",
      "Training: Epoch 174, Batch 1, Loss: 0.061\n",
      "Training: Epoch 174, Batch 2, Loss: 0.072\n",
      "Training: Epoch 174, Batch 3, Loss: 0.066\n",
      "Training: Epoch 174, Batch 4, Loss: 0.062\n",
      "Training: Epoch 174, Batch 5, Loss: 0.071\n",
      "Training: Epoch 174, Batch 6, Loss: 0.045\n",
      "Training: Epoch 174, Batch 7, Loss: 0.067\n",
      "Training: Epoch 174, Batch 8, Loss: 0.062\n",
      "Training: Epoch 174, Batch 9, Loss: 0.055\n",
      "Training: Epoch 174, Batch 10, Loss: 0.049\n",
      "Training: Epoch 174, Batch 11, Loss: 0.054\n",
      "Training: Epoch 174, Batch 12, Loss: 0.06\n",
      "Training: Epoch 174, Batch 13, Loss: 0.049\n",
      "Training: Epoch 174, Batch 14, Loss: 0.063\n",
      "Training: Epoch 174, Batch 15, Loss: 0.051\n",
      "Training: Epoch 174, Batch 16, Loss: 0.064\n",
      "Training: Epoch 174, Batch 17, Loss: 0.06\n",
      "Training: Epoch 174, Batch 18, Loss: 0.05\n",
      "Training: Epoch 174, Batch 19, Loss: 0.057\n",
      "Training: Epoch 174, Batch 20, Loss: 0.065\n",
      "Training: Epoch 174, Batch 21, Loss: 0.072\n",
      "Training: Epoch 174, Batch 22, Loss: 0.058\n",
      "Training: Epoch 174, Batch 23, Loss: 0.062\n",
      "Training: Epoch 174, Batch 24, Loss: 0.059\n",
      "Training: Epoch 174, Batch 25, Loss: 0.071\n",
      "Training: Epoch 174, Batch 26, Loss: 0.063\n",
      "Training: Epoch 174, Batch 27, Loss: 0.059\n",
      "Training: Epoch 174, Batch 28, Loss: 0.059\n",
      "Training: Epoch 174, Batch 29, Loss: 0.065\n",
      "Training: Epoch 174, Batch 30, Loss: 0.062\n",
      "Training: Epoch 174, Batch 31, Loss: 0.063\n",
      "Training: Epoch 174, Batch 32, Loss: 0.073\n",
      "Training: Epoch 174, Batch 33, Loss: 0.061\n",
      "Training: Epoch 174, Batch 34, Loss: 0.05\n",
      "Training: Epoch 174, Batch 35, Loss: 0.057\n",
      "Training: Epoch 174, Batch 36, Loss: 0.079\n",
      "Training: Epoch 174, Batch 37, Loss: 0.049\n",
      "Training: Epoch 174, Batch 38, Loss: 0.059\n",
      "Training: Epoch 174, Batch 39, Loss: 0.065\n",
      "Training: Epoch 174, Batch 40, Loss: 0.054\n",
      "Training: Epoch 174, Batch 41, Loss: 0.064\n",
      "Training: Epoch 174, Batch 42, Loss: 0.072\n",
      "Training: Epoch 174, Batch 43, Loss: 0.058\n",
      "Training: Epoch 174, Batch 44, Loss: 0.068\n",
      "Training: Epoch 174, Batch 45, Loss: 0.062\n",
      "Training: Epoch 174, Batch 46, Loss: 0.053\n",
      "Training: Epoch 174, Batch 47, Loss: 0.058\n",
      "Training: Epoch 174, Batch 48, Loss: 0.045\n",
      "Training: Epoch 174, Batch 49, Loss: 0.059\n",
      "Training: Epoch 174, Batch 50, Loss: 0.05\n",
      "Training: Epoch 174, Batch 51, Loss: 0.053\n",
      "Training: Epoch 174, Batch 52, Loss: 0.051\n",
      "Training: Epoch 174, Batch 53, Loss: 0.064\n",
      "Training: Epoch 174, Batch 54, Loss: 0.064\n",
      "Training: Epoch 174, Batch 55, Loss: 0.072\n",
      "Training: Epoch 174, Batch 56, Loss: 0.07\n",
      "Training: Epoch 174, Batch 57, Loss: 0.047\n",
      "Training: Epoch 174, Batch 58, Loss: 0.075\n",
      "Training: Epoch 174, Batch 59, Loss: 0.068\n",
      "Val: Epoch 174, Loss: 0.316\n",
      "Training: Epoch 175, Batch 0, Loss: 0.054\n",
      "Training: Epoch 175, Batch 1, Loss: 0.052\n",
      "Training: Epoch 175, Batch 2, Loss: 0.067\n",
      "Training: Epoch 175, Batch 3, Loss: 0.048\n",
      "Training: Epoch 175, Batch 4, Loss: 0.062\n",
      "Training: Epoch 175, Batch 5, Loss: 0.055\n",
      "Training: Epoch 175, Batch 6, Loss: 0.053\n",
      "Training: Epoch 175, Batch 7, Loss: 0.064\n",
      "Training: Epoch 175, Batch 8, Loss: 0.056\n",
      "Training: Epoch 175, Batch 9, Loss: 0.049\n",
      "Training: Epoch 175, Batch 10, Loss: 0.065\n",
      "Training: Epoch 175, Batch 11, Loss: 0.062\n",
      "Training: Epoch 175, Batch 12, Loss: 0.044\n",
      "Training: Epoch 175, Batch 13, Loss: 0.063\n",
      "Training: Epoch 175, Batch 14, Loss: 0.05\n",
      "Training: Epoch 175, Batch 15, Loss: 0.05\n",
      "Training: Epoch 175, Batch 16, Loss: 0.046\n",
      "Training: Epoch 175, Batch 17, Loss: 0.055\n",
      "Training: Epoch 175, Batch 18, Loss: 0.064\n",
      "Training: Epoch 175, Batch 19, Loss: 0.06\n",
      "Training: Epoch 175, Batch 20, Loss: 0.054\n",
      "Training: Epoch 175, Batch 21, Loss: 0.069\n",
      "Training: Epoch 175, Batch 22, Loss: 0.051\n",
      "Training: Epoch 175, Batch 23, Loss: 0.081\n",
      "Training: Epoch 175, Batch 24, Loss: 0.059\n",
      "Training: Epoch 175, Batch 25, Loss: 0.06\n",
      "Training: Epoch 175, Batch 26, Loss: 0.061\n",
      "Training: Epoch 175, Batch 27, Loss: 0.066\n",
      "Training: Epoch 175, Batch 28, Loss: 0.074\n",
      "Training: Epoch 175, Batch 29, Loss: 0.061\n",
      "Training: Epoch 175, Batch 30, Loss: 0.058\n",
      "Training: Epoch 175, Batch 31, Loss: 0.043\n",
      "Training: Epoch 175, Batch 32, Loss: 0.059\n",
      "Training: Epoch 175, Batch 33, Loss: 0.056\n",
      "Training: Epoch 175, Batch 34, Loss: 0.073\n",
      "Training: Epoch 175, Batch 35, Loss: 0.069\n",
      "Training: Epoch 175, Batch 36, Loss: 0.063\n",
      "Training: Epoch 175, Batch 37, Loss: 0.048\n",
      "Training: Epoch 175, Batch 38, Loss: 0.07\n",
      "Training: Epoch 175, Batch 39, Loss: 0.056\n",
      "Training: Epoch 175, Batch 40, Loss: 0.065\n",
      "Training: Epoch 175, Batch 41, Loss: 0.046\n",
      "Training: Epoch 175, Batch 42, Loss: 0.064\n",
      "Training: Epoch 175, Batch 43, Loss: 0.064\n",
      "Training: Epoch 175, Batch 44, Loss: 0.065\n",
      "Training: Epoch 175, Batch 45, Loss: 0.06\n",
      "Training: Epoch 175, Batch 46, Loss: 0.056\n",
      "Training: Epoch 175, Batch 47, Loss: 0.058\n",
      "Training: Epoch 175, Batch 48, Loss: 0.058\n",
      "Training: Epoch 175, Batch 49, Loss: 0.061\n",
      "Training: Epoch 175, Batch 50, Loss: 0.057\n",
      "Training: Epoch 175, Batch 51, Loss: 0.052\n",
      "Training: Epoch 175, Batch 52, Loss: 0.076\n",
      "Training: Epoch 175, Batch 53, Loss: 0.067\n",
      "Training: Epoch 175, Batch 54, Loss: 0.059\n",
      "Training: Epoch 175, Batch 55, Loss: 0.058\n",
      "Training: Epoch 175, Batch 56, Loss: 0.061\n",
      "Training: Epoch 175, Batch 57, Loss: 0.07\n",
      "Training: Epoch 175, Batch 58, Loss: 0.052\n",
      "Training: Epoch 175, Batch 59, Loss: 0.08\n",
      "Val: Epoch 175, Loss: 0.32\n",
      "Training: Epoch 176, Batch 0, Loss: 0.064\n",
      "Training: Epoch 176, Batch 1, Loss: 0.048\n",
      "Training: Epoch 176, Batch 2, Loss: 0.065\n",
      "Training: Epoch 176, Batch 3, Loss: 0.051\n",
      "Training: Epoch 176, Batch 4, Loss: 0.052\n",
      "Training: Epoch 176, Batch 5, Loss: 0.058\n",
      "Training: Epoch 176, Batch 6, Loss: 0.064\n",
      "Training: Epoch 176, Batch 7, Loss: 0.072\n",
      "Training: Epoch 176, Batch 8, Loss: 0.058\n",
      "Training: Epoch 176, Batch 9, Loss: 0.064\n",
      "Training: Epoch 176, Batch 10, Loss: 0.058\n",
      "Training: Epoch 176, Batch 11, Loss: 0.056\n",
      "Training: Epoch 176, Batch 12, Loss: 0.053\n",
      "Training: Epoch 176, Batch 13, Loss: 0.096\n",
      "Training: Epoch 176, Batch 14, Loss: 0.064\n",
      "Training: Epoch 176, Batch 15, Loss: 0.049\n",
      "Training: Epoch 176, Batch 16, Loss: 0.049\n",
      "Training: Epoch 176, Batch 17, Loss: 0.077\n",
      "Training: Epoch 176, Batch 18, Loss: 0.058\n",
      "Training: Epoch 176, Batch 19, Loss: 0.07\n",
      "Training: Epoch 176, Batch 20, Loss: 0.065\n",
      "Training: Epoch 176, Batch 21, Loss: 0.061\n",
      "Training: Epoch 176, Batch 22, Loss: 0.076\n",
      "Training: Epoch 176, Batch 23, Loss: 0.061\n",
      "Training: Epoch 176, Batch 24, Loss: 0.067\n",
      "Training: Epoch 176, Batch 25, Loss: 0.059\n",
      "Training: Epoch 176, Batch 26, Loss: 0.067\n",
      "Training: Epoch 176, Batch 27, Loss: 0.065\n",
      "Training: Epoch 176, Batch 28, Loss: 0.062\n",
      "Training: Epoch 176, Batch 29, Loss: 0.053\n",
      "Training: Epoch 176, Batch 30, Loss: 0.062\n",
      "Training: Epoch 176, Batch 31, Loss: 0.059\n",
      "Training: Epoch 176, Batch 32, Loss: 0.066\n",
      "Training: Epoch 176, Batch 33, Loss: 0.066\n",
      "Training: Epoch 176, Batch 34, Loss: 0.064\n",
      "Training: Epoch 176, Batch 35, Loss: 0.056\n",
      "Training: Epoch 176, Batch 36, Loss: 0.082\n",
      "Training: Epoch 176, Batch 37, Loss: 0.063\n",
      "Training: Epoch 176, Batch 38, Loss: 0.056\n",
      "Training: Epoch 176, Batch 39, Loss: 0.067\n",
      "Training: Epoch 176, Batch 40, Loss: 0.057\n",
      "Training: Epoch 176, Batch 41, Loss: 0.051\n",
      "Training: Epoch 176, Batch 42, Loss: 0.055\n",
      "Training: Epoch 176, Batch 43, Loss: 0.07\n",
      "Training: Epoch 176, Batch 44, Loss: 0.082\n",
      "Training: Epoch 176, Batch 45, Loss: 0.052\n",
      "Training: Epoch 176, Batch 46, Loss: 0.056\n",
      "Training: Epoch 176, Batch 47, Loss: 0.047\n",
      "Training: Epoch 176, Batch 48, Loss: 0.081\n",
      "Training: Epoch 176, Batch 49, Loss: 0.051\n",
      "Training: Epoch 176, Batch 50, Loss: 0.077\n",
      "Training: Epoch 176, Batch 51, Loss: 0.059\n",
      "Training: Epoch 176, Batch 52, Loss: 0.06\n",
      "Training: Epoch 176, Batch 53, Loss: 0.053\n",
      "Training: Epoch 176, Batch 54, Loss: 0.053\n",
      "Training: Epoch 176, Batch 55, Loss: 0.071\n",
      "Training: Epoch 176, Batch 56, Loss: 0.064\n",
      "Training: Epoch 176, Batch 57, Loss: 0.068\n",
      "Training: Epoch 176, Batch 58, Loss: 0.053\n",
      "Training: Epoch 176, Batch 59, Loss: 0.058\n",
      "Val: Epoch 176, Loss: 0.319\n",
      "Training: Epoch 177, Batch 0, Loss: 0.064\n",
      "Training: Epoch 177, Batch 1, Loss: 0.066\n",
      "Training: Epoch 177, Batch 2, Loss: 0.053\n",
      "Training: Epoch 177, Batch 3, Loss: 0.051\n",
      "Training: Epoch 177, Batch 4, Loss: 0.054\n",
      "Training: Epoch 177, Batch 5, Loss: 0.063\n",
      "Training: Epoch 177, Batch 6, Loss: 0.062\n",
      "Training: Epoch 177, Batch 7, Loss: 0.057\n",
      "Training: Epoch 177, Batch 8, Loss: 0.064\n",
      "Training: Epoch 177, Batch 9, Loss: 0.063\n",
      "Training: Epoch 177, Batch 10, Loss: 0.066\n",
      "Training: Epoch 177, Batch 11, Loss: 0.069\n",
      "Training: Epoch 177, Batch 12, Loss: 0.057\n",
      "Training: Epoch 177, Batch 13, Loss: 0.06\n",
      "Training: Epoch 177, Batch 14, Loss: 0.063\n",
      "Training: Epoch 177, Batch 15, Loss: 0.055\n",
      "Training: Epoch 177, Batch 16, Loss: 0.051\n",
      "Training: Epoch 177, Batch 17, Loss: 0.07\n",
      "Training: Epoch 177, Batch 18, Loss: 0.051\n",
      "Training: Epoch 177, Batch 19, Loss: 0.057\n",
      "Training: Epoch 177, Batch 20, Loss: 0.059\n",
      "Training: Epoch 177, Batch 21, Loss: 0.068\n",
      "Training: Epoch 177, Batch 22, Loss: 0.071\n",
      "Training: Epoch 177, Batch 23, Loss: 0.059\n",
      "Training: Epoch 177, Batch 24, Loss: 0.047\n",
      "Training: Epoch 177, Batch 25, Loss: 0.062\n",
      "Training: Epoch 177, Batch 26, Loss: 0.061\n",
      "Training: Epoch 177, Batch 27, Loss: 0.048\n",
      "Training: Epoch 177, Batch 28, Loss: 0.065\n",
      "Training: Epoch 177, Batch 29, Loss: 0.051\n",
      "Training: Epoch 177, Batch 30, Loss: 0.054\n",
      "Training: Epoch 177, Batch 31, Loss: 0.061\n",
      "Training: Epoch 177, Batch 32, Loss: 0.069\n",
      "Training: Epoch 177, Batch 33, Loss: 0.055\n",
      "Training: Epoch 177, Batch 34, Loss: 0.058\n",
      "Training: Epoch 177, Batch 35, Loss: 0.067\n",
      "Training: Epoch 177, Batch 36, Loss: 0.063\n",
      "Training: Epoch 177, Batch 37, Loss: 0.057\n",
      "Training: Epoch 177, Batch 38, Loss: 0.051\n",
      "Training: Epoch 177, Batch 39, Loss: 0.059\n",
      "Training: Epoch 177, Batch 40, Loss: 0.066\n",
      "Training: Epoch 177, Batch 41, Loss: 0.063\n",
      "Training: Epoch 177, Batch 42, Loss: 0.061\n",
      "Training: Epoch 177, Batch 43, Loss: 0.068\n",
      "Training: Epoch 177, Batch 44, Loss: 0.061\n",
      "Training: Epoch 177, Batch 45, Loss: 0.061\n",
      "Training: Epoch 177, Batch 46, Loss: 0.068\n",
      "Training: Epoch 177, Batch 47, Loss: 0.055\n",
      "Training: Epoch 177, Batch 48, Loss: 0.069\n",
      "Training: Epoch 177, Batch 49, Loss: 0.075\n",
      "Training: Epoch 177, Batch 50, Loss: 0.073\n",
      "Training: Epoch 177, Batch 51, Loss: 0.051\n",
      "Training: Epoch 177, Batch 52, Loss: 0.062\n",
      "Training: Epoch 177, Batch 53, Loss: 0.058\n",
      "Training: Epoch 177, Batch 54, Loss: 0.077\n",
      "Training: Epoch 177, Batch 55, Loss: 0.06\n",
      "Training: Epoch 177, Batch 56, Loss: 0.045\n",
      "Training: Epoch 177, Batch 57, Loss: 0.062\n",
      "Training: Epoch 177, Batch 58, Loss: 0.069\n",
      "Training: Epoch 177, Batch 59, Loss: 0.068\n",
      "Val: Epoch 177, Loss: 0.312\n",
      "Training: Epoch 178, Batch 0, Loss: 0.065\n",
      "Training: Epoch 178, Batch 1, Loss: 0.064\n",
      "Training: Epoch 178, Batch 2, Loss: 0.046\n",
      "Training: Epoch 178, Batch 3, Loss: 0.05\n",
      "Training: Epoch 178, Batch 4, Loss: 0.064\n",
      "Training: Epoch 178, Batch 5, Loss: 0.061\n",
      "Training: Epoch 178, Batch 6, Loss: 0.068\n",
      "Training: Epoch 178, Batch 7, Loss: 0.057\n",
      "Training: Epoch 178, Batch 8, Loss: 0.053\n",
      "Training: Epoch 178, Batch 9, Loss: 0.075\n",
      "Training: Epoch 178, Batch 10, Loss: 0.052\n",
      "Training: Epoch 178, Batch 11, Loss: 0.056\n",
      "Training: Epoch 178, Batch 12, Loss: 0.066\n",
      "Training: Epoch 178, Batch 13, Loss: 0.059\n",
      "Training: Epoch 178, Batch 14, Loss: 0.047\n",
      "Training: Epoch 178, Batch 15, Loss: 0.053\n",
      "Training: Epoch 178, Batch 16, Loss: 0.063\n",
      "Training: Epoch 178, Batch 17, Loss: 0.051\n",
      "Training: Epoch 178, Batch 18, Loss: 0.061\n",
      "Training: Epoch 178, Batch 19, Loss: 0.055\n",
      "Training: Epoch 178, Batch 20, Loss: 0.059\n",
      "Training: Epoch 178, Batch 21, Loss: 0.055\n",
      "Training: Epoch 178, Batch 22, Loss: 0.068\n",
      "Training: Epoch 178, Batch 23, Loss: 0.077\n",
      "Training: Epoch 178, Batch 24, Loss: 0.073\n",
      "Training: Epoch 178, Batch 25, Loss: 0.051\n",
      "Training: Epoch 178, Batch 26, Loss: 0.059\n",
      "Training: Epoch 178, Batch 27, Loss: 0.063\n",
      "Training: Epoch 178, Batch 28, Loss: 0.051\n",
      "Training: Epoch 178, Batch 29, Loss: 0.064\n",
      "Training: Epoch 178, Batch 30, Loss: 0.066\n",
      "Training: Epoch 178, Batch 31, Loss: 0.062\n",
      "Training: Epoch 178, Batch 32, Loss: 0.052\n",
      "Training: Epoch 178, Batch 33, Loss: 0.058\n",
      "Training: Epoch 178, Batch 34, Loss: 0.062\n",
      "Training: Epoch 178, Batch 35, Loss: 0.059\n",
      "Training: Epoch 178, Batch 36, Loss: 0.065\n",
      "Training: Epoch 178, Batch 37, Loss: 0.062\n",
      "Training: Epoch 178, Batch 38, Loss: 0.063\n",
      "Training: Epoch 178, Batch 39, Loss: 0.062\n",
      "Training: Epoch 178, Batch 40, Loss: 0.053\n",
      "Training: Epoch 178, Batch 41, Loss: 0.059\n",
      "Training: Epoch 178, Batch 42, Loss: 0.062\n",
      "Training: Epoch 178, Batch 43, Loss: 0.065\n",
      "Training: Epoch 178, Batch 44, Loss: 0.062\n",
      "Training: Epoch 178, Batch 45, Loss: 0.048\n",
      "Training: Epoch 178, Batch 46, Loss: 0.064\n",
      "Training: Epoch 178, Batch 47, Loss: 0.06\n",
      "Training: Epoch 178, Batch 48, Loss: 0.058\n",
      "Training: Epoch 178, Batch 49, Loss: 0.052\n",
      "Training: Epoch 178, Batch 50, Loss: 0.049\n",
      "Training: Epoch 178, Batch 51, Loss: 0.056\n",
      "Training: Epoch 178, Batch 52, Loss: 0.047\n",
      "Training: Epoch 178, Batch 53, Loss: 0.067\n",
      "Training: Epoch 178, Batch 54, Loss: 0.057\n",
      "Training: Epoch 178, Batch 55, Loss: 0.06\n",
      "Training: Epoch 178, Batch 56, Loss: 0.064\n",
      "Training: Epoch 178, Batch 57, Loss: 0.058\n",
      "Training: Epoch 178, Batch 58, Loss: 0.054\n",
      "Training: Epoch 178, Batch 59, Loss: 0.066\n",
      "Val: Epoch 178, Loss: 0.316\n",
      "Training: Epoch 179, Batch 0, Loss: 0.048\n",
      "Training: Epoch 179, Batch 1, Loss: 0.052\n",
      "Training: Epoch 179, Batch 2, Loss: 0.061\n",
      "Training: Epoch 179, Batch 3, Loss: 0.058\n",
      "Training: Epoch 179, Batch 4, Loss: 0.057\n",
      "Training: Epoch 179, Batch 5, Loss: 0.055\n",
      "Training: Epoch 179, Batch 6, Loss: 0.067\n",
      "Training: Epoch 179, Batch 7, Loss: 0.06\n",
      "Training: Epoch 179, Batch 8, Loss: 0.058\n",
      "Training: Epoch 179, Batch 9, Loss: 0.074\n",
      "Training: Epoch 179, Batch 10, Loss: 0.07\n",
      "Training: Epoch 179, Batch 11, Loss: 0.065\n",
      "Training: Epoch 179, Batch 12, Loss: 0.064\n",
      "Training: Epoch 179, Batch 13, Loss: 0.058\n",
      "Training: Epoch 179, Batch 14, Loss: 0.063\n",
      "Training: Epoch 179, Batch 15, Loss: 0.064\n",
      "Training: Epoch 179, Batch 16, Loss: 0.068\n",
      "Training: Epoch 179, Batch 17, Loss: 0.051\n",
      "Training: Epoch 179, Batch 18, Loss: 0.058\n",
      "Training: Epoch 179, Batch 19, Loss: 0.052\n",
      "Training: Epoch 179, Batch 20, Loss: 0.058\n",
      "Training: Epoch 179, Batch 21, Loss: 0.064\n",
      "Training: Epoch 179, Batch 22, Loss: 0.052\n",
      "Training: Epoch 179, Batch 23, Loss: 0.062\n",
      "Training: Epoch 179, Batch 24, Loss: 0.056\n",
      "Training: Epoch 179, Batch 25, Loss: 0.043\n",
      "Training: Epoch 179, Batch 26, Loss: 0.055\n",
      "Training: Epoch 179, Batch 27, Loss: 0.051\n",
      "Training: Epoch 179, Batch 28, Loss: 0.069\n",
      "Training: Epoch 179, Batch 29, Loss: 0.064\n",
      "Training: Epoch 179, Batch 30, Loss: 0.069\n",
      "Training: Epoch 179, Batch 31, Loss: 0.055\n",
      "Training: Epoch 179, Batch 32, Loss: 0.057\n",
      "Training: Epoch 179, Batch 33, Loss: 0.059\n",
      "Training: Epoch 179, Batch 34, Loss: 0.071\n",
      "Training: Epoch 179, Batch 35, Loss: 0.072\n",
      "Training: Epoch 179, Batch 36, Loss: 0.055\n",
      "Training: Epoch 179, Batch 37, Loss: 0.062\n",
      "Training: Epoch 179, Batch 38, Loss: 0.06\n",
      "Training: Epoch 179, Batch 39, Loss: 0.055\n",
      "Training: Epoch 179, Batch 40, Loss: 0.058\n",
      "Training: Epoch 179, Batch 41, Loss: 0.051\n",
      "Training: Epoch 179, Batch 42, Loss: 0.048\n",
      "Training: Epoch 179, Batch 43, Loss: 0.067\n",
      "Training: Epoch 179, Batch 44, Loss: 0.056\n",
      "Training: Epoch 179, Batch 45, Loss: 0.053\n",
      "Training: Epoch 179, Batch 46, Loss: 0.056\n",
      "Training: Epoch 179, Batch 47, Loss: 0.057\n",
      "Training: Epoch 179, Batch 48, Loss: 0.064\n",
      "Training: Epoch 179, Batch 49, Loss: 0.05\n",
      "Training: Epoch 179, Batch 50, Loss: 0.064\n",
      "Training: Epoch 179, Batch 51, Loss: 0.054\n",
      "Training: Epoch 179, Batch 52, Loss: 0.073\n",
      "Training: Epoch 179, Batch 53, Loss: 0.058\n",
      "Training: Epoch 179, Batch 54, Loss: 0.061\n",
      "Training: Epoch 179, Batch 55, Loss: 0.057\n",
      "Training: Epoch 179, Batch 56, Loss: 0.075\n",
      "Training: Epoch 179, Batch 57, Loss: 0.061\n",
      "Training: Epoch 179, Batch 58, Loss: 0.064\n",
      "Training: Epoch 179, Batch 59, Loss: 0.052\n",
      "Val: Epoch 179, Loss: 0.308\n",
      "Training: Epoch 180, Batch 0, Loss: 0.049\n",
      "Training: Epoch 180, Batch 1, Loss: 0.066\n",
      "Training: Epoch 180, Batch 2, Loss: 0.059\n",
      "Training: Epoch 180, Batch 3, Loss: 0.061\n",
      "Training: Epoch 180, Batch 4, Loss: 0.061\n",
      "Training: Epoch 180, Batch 5, Loss: 0.058\n",
      "Training: Epoch 180, Batch 6, Loss: 0.054\n",
      "Training: Epoch 180, Batch 7, Loss: 0.058\n",
      "Training: Epoch 180, Batch 8, Loss: 0.051\n",
      "Training: Epoch 180, Batch 9, Loss: 0.082\n",
      "Training: Epoch 180, Batch 10, Loss: 0.057\n",
      "Training: Epoch 180, Batch 11, Loss: 0.066\n",
      "Training: Epoch 180, Batch 12, Loss: 0.061\n",
      "Training: Epoch 180, Batch 13, Loss: 0.057\n",
      "Training: Epoch 180, Batch 14, Loss: 0.058\n",
      "Training: Epoch 180, Batch 15, Loss: 0.058\n",
      "Training: Epoch 180, Batch 16, Loss: 0.062\n",
      "Training: Epoch 180, Batch 17, Loss: 0.052\n",
      "Training: Epoch 180, Batch 18, Loss: 0.069\n",
      "Training: Epoch 180, Batch 19, Loss: 0.057\n",
      "Training: Epoch 180, Batch 20, Loss: 0.067\n",
      "Training: Epoch 180, Batch 21, Loss: 0.065\n",
      "Training: Epoch 180, Batch 22, Loss: 0.058\n",
      "Training: Epoch 180, Batch 23, Loss: 0.067\n",
      "Training: Epoch 180, Batch 24, Loss: 0.06\n",
      "Training: Epoch 180, Batch 25, Loss: 0.042\n",
      "Training: Epoch 180, Batch 26, Loss: 0.052\n",
      "Training: Epoch 180, Batch 27, Loss: 0.048\n",
      "Training: Epoch 180, Batch 28, Loss: 0.057\n",
      "Training: Epoch 180, Batch 29, Loss: 0.071\n",
      "Training: Epoch 180, Batch 30, Loss: 0.06\n",
      "Training: Epoch 180, Batch 31, Loss: 0.054\n",
      "Training: Epoch 180, Batch 32, Loss: 0.061\n",
      "Training: Epoch 180, Batch 33, Loss: 0.06\n",
      "Training: Epoch 180, Batch 34, Loss: 0.063\n",
      "Training: Epoch 180, Batch 35, Loss: 0.046\n",
      "Training: Epoch 180, Batch 36, Loss: 0.071\n",
      "Training: Epoch 180, Batch 37, Loss: 0.059\n",
      "Training: Epoch 180, Batch 38, Loss: 0.068\n",
      "Training: Epoch 180, Batch 39, Loss: 0.067\n",
      "Training: Epoch 180, Batch 40, Loss: 0.058\n",
      "Training: Epoch 180, Batch 41, Loss: 0.053\n",
      "Training: Epoch 180, Batch 42, Loss: 0.075\n",
      "Training: Epoch 180, Batch 43, Loss: 0.063\n",
      "Training: Epoch 180, Batch 44, Loss: 0.052\n",
      "Training: Epoch 180, Batch 45, Loss: 0.055\n",
      "Training: Epoch 180, Batch 46, Loss: 0.064\n",
      "Training: Epoch 180, Batch 47, Loss: 0.047\n",
      "Training: Epoch 180, Batch 48, Loss: 0.059\n",
      "Training: Epoch 180, Batch 49, Loss: 0.064\n",
      "Training: Epoch 180, Batch 50, Loss: 0.057\n",
      "Training: Epoch 180, Batch 51, Loss: 0.052\n",
      "Training: Epoch 180, Batch 52, Loss: 0.068\n",
      "Training: Epoch 180, Batch 53, Loss: 0.071\n",
      "Training: Epoch 180, Batch 54, Loss: 0.064\n",
      "Training: Epoch 180, Batch 55, Loss: 0.059\n",
      "Training: Epoch 180, Batch 56, Loss: 0.048\n",
      "Training: Epoch 180, Batch 57, Loss: 0.055\n",
      "Training: Epoch 180, Batch 58, Loss: 0.054\n",
      "Training: Epoch 180, Batch 59, Loss: 0.054\n",
      "Val: Epoch 180, Loss: 0.334\n",
      "Training: Epoch 181, Batch 0, Loss: 0.059\n",
      "Training: Epoch 181, Batch 1, Loss: 0.076\n",
      "Training: Epoch 181, Batch 2, Loss: 0.054\n",
      "Training: Epoch 181, Batch 3, Loss: 0.056\n",
      "Training: Epoch 181, Batch 4, Loss: 0.076\n",
      "Training: Epoch 181, Batch 5, Loss: 0.068\n",
      "Training: Epoch 181, Batch 6, Loss: 0.063\n",
      "Training: Epoch 181, Batch 7, Loss: 0.062\n",
      "Training: Epoch 181, Batch 8, Loss: 0.07\n",
      "Training: Epoch 181, Batch 9, Loss: 0.061\n",
      "Training: Epoch 181, Batch 10, Loss: 0.058\n",
      "Training: Epoch 181, Batch 11, Loss: 0.068\n",
      "Training: Epoch 181, Batch 12, Loss: 0.053\n",
      "Training: Epoch 181, Batch 13, Loss: 0.075\n",
      "Training: Epoch 181, Batch 14, Loss: 0.058\n",
      "Training: Epoch 181, Batch 15, Loss: 0.074\n",
      "Training: Epoch 181, Batch 16, Loss: 0.078\n",
      "Training: Epoch 181, Batch 17, Loss: 0.04\n",
      "Training: Epoch 181, Batch 18, Loss: 0.053\n",
      "Training: Epoch 181, Batch 19, Loss: 0.055\n",
      "Training: Epoch 181, Batch 20, Loss: 0.068\n",
      "Training: Epoch 181, Batch 21, Loss: 0.055\n",
      "Training: Epoch 181, Batch 22, Loss: 0.068\n",
      "Training: Epoch 181, Batch 23, Loss: 0.062\n",
      "Training: Epoch 181, Batch 24, Loss: 0.053\n",
      "Training: Epoch 181, Batch 25, Loss: 0.046\n",
      "Training: Epoch 181, Batch 26, Loss: 0.074\n",
      "Training: Epoch 181, Batch 27, Loss: 0.049\n",
      "Training: Epoch 181, Batch 28, Loss: 0.073\n",
      "Training: Epoch 181, Batch 29, Loss: 0.06\n",
      "Training: Epoch 181, Batch 30, Loss: 0.047\n",
      "Training: Epoch 181, Batch 31, Loss: 0.063\n",
      "Training: Epoch 181, Batch 32, Loss: 0.065\n",
      "Training: Epoch 181, Batch 33, Loss: 0.057\n",
      "Training: Epoch 181, Batch 34, Loss: 0.057\n",
      "Training: Epoch 181, Batch 35, Loss: 0.048\n",
      "Training: Epoch 181, Batch 36, Loss: 0.072\n",
      "Training: Epoch 181, Batch 37, Loss: 0.061\n",
      "Training: Epoch 181, Batch 38, Loss: 0.056\n",
      "Training: Epoch 181, Batch 39, Loss: 0.053\n",
      "Training: Epoch 181, Batch 40, Loss: 0.053\n",
      "Training: Epoch 181, Batch 41, Loss: 0.058\n",
      "Training: Epoch 181, Batch 42, Loss: 0.053\n",
      "Training: Epoch 181, Batch 43, Loss: 0.05\n",
      "Training: Epoch 181, Batch 44, Loss: 0.061\n",
      "Training: Epoch 181, Batch 45, Loss: 0.055\n",
      "Training: Epoch 181, Batch 46, Loss: 0.047\n",
      "Training: Epoch 181, Batch 47, Loss: 0.054\n",
      "Training: Epoch 181, Batch 48, Loss: 0.052\n",
      "Training: Epoch 181, Batch 49, Loss: 0.052\n",
      "Training: Epoch 181, Batch 50, Loss: 0.064\n",
      "Training: Epoch 181, Batch 51, Loss: 0.06\n",
      "Training: Epoch 181, Batch 52, Loss: 0.071\n",
      "Training: Epoch 181, Batch 53, Loss: 0.047\n",
      "Training: Epoch 181, Batch 54, Loss: 0.066\n",
      "Training: Epoch 181, Batch 55, Loss: 0.079\n",
      "Training: Epoch 181, Batch 56, Loss: 0.055\n",
      "Training: Epoch 181, Batch 57, Loss: 0.074\n",
      "Training: Epoch 181, Batch 58, Loss: 0.057\n",
      "Training: Epoch 181, Batch 59, Loss: 0.059\n",
      "Val: Epoch 181, Loss: 0.326\n",
      "Training: Epoch 182, Batch 0, Loss: 0.057\n",
      "Training: Epoch 182, Batch 1, Loss: 0.061\n",
      "Training: Epoch 182, Batch 2, Loss: 0.068\n",
      "Training: Epoch 182, Batch 3, Loss: 0.058\n",
      "Training: Epoch 182, Batch 4, Loss: 0.05\n",
      "Training: Epoch 182, Batch 5, Loss: 0.064\n",
      "Training: Epoch 182, Batch 6, Loss: 0.064\n",
      "Training: Epoch 182, Batch 7, Loss: 0.057\n",
      "Training: Epoch 182, Batch 8, Loss: 0.057\n",
      "Training: Epoch 182, Batch 9, Loss: 0.058\n",
      "Training: Epoch 182, Batch 10, Loss: 0.057\n",
      "Training: Epoch 182, Batch 11, Loss: 0.046\n",
      "Training: Epoch 182, Batch 12, Loss: 0.053\n",
      "Training: Epoch 182, Batch 13, Loss: 0.052\n",
      "Training: Epoch 182, Batch 14, Loss: 0.059\n",
      "Training: Epoch 182, Batch 15, Loss: 0.068\n",
      "Training: Epoch 182, Batch 16, Loss: 0.053\n",
      "Training: Epoch 182, Batch 17, Loss: 0.046\n",
      "Training: Epoch 182, Batch 18, Loss: 0.073\n",
      "Training: Epoch 182, Batch 19, Loss: 0.054\n",
      "Training: Epoch 182, Batch 20, Loss: 0.049\n",
      "Training: Epoch 182, Batch 21, Loss: 0.05\n",
      "Training: Epoch 182, Batch 22, Loss: 0.063\n",
      "Training: Epoch 182, Batch 23, Loss: 0.064\n",
      "Training: Epoch 182, Batch 24, Loss: 0.065\n",
      "Training: Epoch 182, Batch 25, Loss: 0.059\n",
      "Training: Epoch 182, Batch 26, Loss: 0.063\n",
      "Training: Epoch 182, Batch 27, Loss: 0.059\n",
      "Training: Epoch 182, Batch 28, Loss: 0.064\n",
      "Training: Epoch 182, Batch 29, Loss: 0.067\n",
      "Training: Epoch 182, Batch 30, Loss: 0.063\n",
      "Training: Epoch 182, Batch 31, Loss: 0.065\n",
      "Training: Epoch 182, Batch 32, Loss: 0.064\n",
      "Training: Epoch 182, Batch 33, Loss: 0.071\n",
      "Training: Epoch 182, Batch 34, Loss: 0.057\n",
      "Training: Epoch 182, Batch 35, Loss: 0.055\n",
      "Training: Epoch 182, Batch 36, Loss: 0.058\n",
      "Training: Epoch 182, Batch 37, Loss: 0.074\n",
      "Training: Epoch 182, Batch 38, Loss: 0.058\n",
      "Training: Epoch 182, Batch 39, Loss: 0.056\n",
      "Training: Epoch 182, Batch 40, Loss: 0.051\n",
      "Training: Epoch 182, Batch 41, Loss: 0.051\n",
      "Training: Epoch 182, Batch 42, Loss: 0.054\n",
      "Training: Epoch 182, Batch 43, Loss: 0.056\n",
      "Training: Epoch 182, Batch 44, Loss: 0.053\n",
      "Training: Epoch 182, Batch 45, Loss: 0.062\n",
      "Training: Epoch 182, Batch 46, Loss: 0.074\n",
      "Training: Epoch 182, Batch 47, Loss: 0.065\n",
      "Training: Epoch 182, Batch 48, Loss: 0.052\n",
      "Training: Epoch 182, Batch 49, Loss: 0.07\n",
      "Training: Epoch 182, Batch 50, Loss: 0.063\n",
      "Training: Epoch 182, Batch 51, Loss: 0.054\n",
      "Training: Epoch 182, Batch 52, Loss: 0.06\n",
      "Training: Epoch 182, Batch 53, Loss: 0.054\n",
      "Training: Epoch 182, Batch 54, Loss: 0.07\n",
      "Training: Epoch 182, Batch 55, Loss: 0.067\n",
      "Training: Epoch 182, Batch 56, Loss: 0.068\n",
      "Training: Epoch 182, Batch 57, Loss: 0.048\n",
      "Training: Epoch 182, Batch 58, Loss: 0.072\n",
      "Training: Epoch 182, Batch 59, Loss: 0.057\n",
      "Val: Epoch 182, Loss: 0.331\n",
      "Training: Epoch 183, Batch 0, Loss: 0.057\n",
      "Training: Epoch 183, Batch 1, Loss: 0.077\n",
      "Training: Epoch 183, Batch 2, Loss: 0.068\n",
      "Training: Epoch 183, Batch 3, Loss: 0.065\n",
      "Training: Epoch 183, Batch 4, Loss: 0.063\n",
      "Training: Epoch 183, Batch 5, Loss: 0.053\n",
      "Training: Epoch 183, Batch 6, Loss: 0.065\n",
      "Training: Epoch 183, Batch 7, Loss: 0.066\n",
      "Training: Epoch 183, Batch 8, Loss: 0.064\n",
      "Training: Epoch 183, Batch 9, Loss: 0.052\n",
      "Training: Epoch 183, Batch 10, Loss: 0.06\n",
      "Training: Epoch 183, Batch 11, Loss: 0.066\n",
      "Training: Epoch 183, Batch 12, Loss: 0.054\n",
      "Training: Epoch 183, Batch 13, Loss: 0.064\n",
      "Training: Epoch 183, Batch 14, Loss: 0.054\n",
      "Training: Epoch 183, Batch 15, Loss: 0.069\n",
      "Training: Epoch 183, Batch 16, Loss: 0.065\n",
      "Training: Epoch 183, Batch 17, Loss: 0.054\n",
      "Training: Epoch 183, Batch 18, Loss: 0.07\n",
      "Training: Epoch 183, Batch 19, Loss: 0.048\n",
      "Training: Epoch 183, Batch 20, Loss: 0.063\n",
      "Training: Epoch 183, Batch 21, Loss: 0.057\n",
      "Training: Epoch 183, Batch 22, Loss: 0.057\n",
      "Training: Epoch 183, Batch 23, Loss: 0.057\n",
      "Training: Epoch 183, Batch 24, Loss: 0.078\n",
      "Training: Epoch 183, Batch 25, Loss: 0.071\n",
      "Training: Epoch 183, Batch 26, Loss: 0.053\n",
      "Training: Epoch 183, Batch 27, Loss: 0.07\n",
      "Training: Epoch 183, Batch 28, Loss: 0.058\n",
      "Training: Epoch 183, Batch 29, Loss: 0.069\n",
      "Training: Epoch 183, Batch 30, Loss: 0.056\n",
      "Training: Epoch 183, Batch 31, Loss: 0.059\n",
      "Training: Epoch 183, Batch 32, Loss: 0.061\n",
      "Training: Epoch 183, Batch 33, Loss: 0.05\n",
      "Training: Epoch 183, Batch 34, Loss: 0.059\n",
      "Training: Epoch 183, Batch 35, Loss: 0.074\n",
      "Training: Epoch 183, Batch 36, Loss: 0.052\n",
      "Training: Epoch 183, Batch 37, Loss: 0.054\n",
      "Training: Epoch 183, Batch 38, Loss: 0.06\n",
      "Training: Epoch 183, Batch 39, Loss: 0.053\n",
      "Training: Epoch 183, Batch 40, Loss: 0.067\n",
      "Training: Epoch 183, Batch 41, Loss: 0.052\n",
      "Training: Epoch 183, Batch 42, Loss: 0.067\n",
      "Training: Epoch 183, Batch 43, Loss: 0.053\n",
      "Training: Epoch 183, Batch 44, Loss: 0.058\n",
      "Training: Epoch 183, Batch 45, Loss: 0.048\n",
      "Training: Epoch 183, Batch 46, Loss: 0.064\n",
      "Training: Epoch 183, Batch 47, Loss: 0.061\n",
      "Training: Epoch 183, Batch 48, Loss: 0.055\n",
      "Training: Epoch 183, Batch 49, Loss: 0.064\n",
      "Training: Epoch 183, Batch 50, Loss: 0.058\n",
      "Training: Epoch 183, Batch 51, Loss: 0.062\n",
      "Training: Epoch 183, Batch 52, Loss: 0.055\n",
      "Training: Epoch 183, Batch 53, Loss: 0.067\n",
      "Training: Epoch 183, Batch 54, Loss: 0.063\n",
      "Training: Epoch 183, Batch 55, Loss: 0.058\n",
      "Training: Epoch 183, Batch 56, Loss: 0.064\n",
      "Training: Epoch 183, Batch 57, Loss: 0.052\n",
      "Training: Epoch 183, Batch 58, Loss: 0.05\n",
      "Training: Epoch 183, Batch 59, Loss: 0.057\n",
      "Val: Epoch 183, Loss: 0.326\n",
      "Training: Epoch 184, Batch 0, Loss: 0.059\n",
      "Training: Epoch 184, Batch 1, Loss: 0.053\n",
      "Training: Epoch 184, Batch 2, Loss: 0.055\n",
      "Training: Epoch 184, Batch 3, Loss: 0.051\n",
      "Training: Epoch 184, Batch 4, Loss: 0.063\n",
      "Training: Epoch 184, Batch 5, Loss: 0.054\n",
      "Training: Epoch 184, Batch 6, Loss: 0.066\n",
      "Training: Epoch 184, Batch 7, Loss: 0.068\n",
      "Training: Epoch 184, Batch 8, Loss: 0.066\n",
      "Training: Epoch 184, Batch 9, Loss: 0.057\n",
      "Training: Epoch 184, Batch 10, Loss: 0.067\n",
      "Training: Epoch 184, Batch 11, Loss: 0.049\n",
      "Training: Epoch 184, Batch 12, Loss: 0.053\n",
      "Training: Epoch 184, Batch 13, Loss: 0.054\n",
      "Training: Epoch 184, Batch 14, Loss: 0.045\n",
      "Training: Epoch 184, Batch 15, Loss: 0.071\n",
      "Training: Epoch 184, Batch 16, Loss: 0.056\n",
      "Training: Epoch 184, Batch 17, Loss: 0.071\n",
      "Training: Epoch 184, Batch 18, Loss: 0.058\n",
      "Training: Epoch 184, Batch 19, Loss: 0.06\n",
      "Training: Epoch 184, Batch 20, Loss: 0.057\n",
      "Training: Epoch 184, Batch 21, Loss: 0.054\n",
      "Training: Epoch 184, Batch 22, Loss: 0.064\n",
      "Training: Epoch 184, Batch 23, Loss: 0.072\n",
      "Training: Epoch 184, Batch 24, Loss: 0.052\n",
      "Training: Epoch 184, Batch 25, Loss: 0.053\n",
      "Training: Epoch 184, Batch 26, Loss: 0.061\n",
      "Training: Epoch 184, Batch 27, Loss: 0.05\n",
      "Training: Epoch 184, Batch 28, Loss: 0.064\n",
      "Training: Epoch 184, Batch 29, Loss: 0.062\n",
      "Training: Epoch 184, Batch 30, Loss: 0.044\n",
      "Training: Epoch 184, Batch 31, Loss: 0.065\n",
      "Training: Epoch 184, Batch 32, Loss: 0.062\n",
      "Training: Epoch 184, Batch 33, Loss: 0.066\n",
      "Training: Epoch 184, Batch 34, Loss: 0.052\n",
      "Training: Epoch 184, Batch 35, Loss: 0.068\n",
      "Training: Epoch 184, Batch 36, Loss: 0.068\n",
      "Training: Epoch 184, Batch 37, Loss: 0.07\n",
      "Training: Epoch 184, Batch 38, Loss: 0.048\n",
      "Training: Epoch 184, Batch 39, Loss: 0.059\n",
      "Training: Epoch 184, Batch 40, Loss: 0.061\n",
      "Training: Epoch 184, Batch 41, Loss: 0.058\n",
      "Training: Epoch 184, Batch 42, Loss: 0.052\n",
      "Training: Epoch 184, Batch 43, Loss: 0.064\n",
      "Training: Epoch 184, Batch 44, Loss: 0.061\n",
      "Training: Epoch 184, Batch 45, Loss: 0.061\n",
      "Training: Epoch 184, Batch 46, Loss: 0.053\n",
      "Training: Epoch 184, Batch 47, Loss: 0.056\n",
      "Training: Epoch 184, Batch 48, Loss: 0.053\n",
      "Training: Epoch 184, Batch 49, Loss: 0.058\n",
      "Training: Epoch 184, Batch 50, Loss: 0.046\n",
      "Training: Epoch 184, Batch 51, Loss: 0.051\n",
      "Training: Epoch 184, Batch 52, Loss: 0.056\n",
      "Training: Epoch 184, Batch 53, Loss: 0.064\n",
      "Training: Epoch 184, Batch 54, Loss: 0.071\n",
      "Training: Epoch 184, Batch 55, Loss: 0.059\n",
      "Training: Epoch 184, Batch 56, Loss: 0.054\n",
      "Training: Epoch 184, Batch 57, Loss: 0.054\n",
      "Training: Epoch 184, Batch 58, Loss: 0.065\n",
      "Training: Epoch 184, Batch 59, Loss: 0.052\n",
      "Val: Epoch 184, Loss: 0.33\n",
      "Training: Epoch 185, Batch 0, Loss: 0.056\n",
      "Training: Epoch 185, Batch 1, Loss: 0.053\n",
      "Training: Epoch 185, Batch 2, Loss: 0.062\n",
      "Training: Epoch 185, Batch 3, Loss: 0.056\n",
      "Training: Epoch 185, Batch 4, Loss: 0.06\n",
      "Training: Epoch 185, Batch 5, Loss: 0.056\n",
      "Training: Epoch 185, Batch 6, Loss: 0.069\n",
      "Training: Epoch 185, Batch 7, Loss: 0.072\n",
      "Training: Epoch 185, Batch 8, Loss: 0.057\n",
      "Training: Epoch 185, Batch 9, Loss: 0.051\n",
      "Training: Epoch 185, Batch 10, Loss: 0.049\n",
      "Training: Epoch 185, Batch 11, Loss: 0.047\n",
      "Training: Epoch 185, Batch 12, Loss: 0.058\n",
      "Training: Epoch 185, Batch 13, Loss: 0.054\n",
      "Training: Epoch 185, Batch 14, Loss: 0.059\n",
      "Training: Epoch 185, Batch 15, Loss: 0.055\n",
      "Training: Epoch 185, Batch 16, Loss: 0.055\n",
      "Training: Epoch 185, Batch 17, Loss: 0.055\n",
      "Training: Epoch 185, Batch 18, Loss: 0.063\n",
      "Training: Epoch 185, Batch 19, Loss: 0.055\n",
      "Training: Epoch 185, Batch 20, Loss: 0.058\n",
      "Training: Epoch 185, Batch 21, Loss: 0.048\n",
      "Training: Epoch 185, Batch 22, Loss: 0.054\n",
      "Training: Epoch 185, Batch 23, Loss: 0.069\n",
      "Training: Epoch 185, Batch 24, Loss: 0.06\n",
      "Training: Epoch 185, Batch 25, Loss: 0.042\n",
      "Training: Epoch 185, Batch 26, Loss: 0.052\n",
      "Training: Epoch 185, Batch 27, Loss: 0.05\n",
      "Training: Epoch 185, Batch 28, Loss: 0.047\n",
      "Training: Epoch 185, Batch 29, Loss: 0.066\n",
      "Training: Epoch 185, Batch 30, Loss: 0.058\n",
      "Training: Epoch 185, Batch 31, Loss: 0.072\n",
      "Training: Epoch 185, Batch 32, Loss: 0.055\n",
      "Training: Epoch 185, Batch 33, Loss: 0.053\n",
      "Training: Epoch 185, Batch 34, Loss: 0.065\n",
      "Training: Epoch 185, Batch 35, Loss: 0.056\n",
      "Training: Epoch 185, Batch 36, Loss: 0.061\n",
      "Training: Epoch 185, Batch 37, Loss: 0.054\n",
      "Training: Epoch 185, Batch 38, Loss: 0.057\n",
      "Training: Epoch 185, Batch 39, Loss: 0.045\n",
      "Training: Epoch 185, Batch 40, Loss: 0.061\n",
      "Training: Epoch 185, Batch 41, Loss: 0.078\n",
      "Training: Epoch 185, Batch 42, Loss: 0.063\n",
      "Training: Epoch 185, Batch 43, Loss: 0.059\n",
      "Training: Epoch 185, Batch 44, Loss: 0.051\n",
      "Training: Epoch 185, Batch 45, Loss: 0.057\n",
      "Training: Epoch 185, Batch 46, Loss: 0.053\n",
      "Training: Epoch 185, Batch 47, Loss: 0.054\n",
      "Training: Epoch 185, Batch 48, Loss: 0.058\n",
      "Training: Epoch 185, Batch 49, Loss: 0.057\n",
      "Training: Epoch 185, Batch 50, Loss: 0.055\n",
      "Training: Epoch 185, Batch 51, Loss: 0.062\n",
      "Training: Epoch 185, Batch 52, Loss: 0.053\n",
      "Training: Epoch 185, Batch 53, Loss: 0.054\n",
      "Training: Epoch 185, Batch 54, Loss: 0.061\n",
      "Training: Epoch 185, Batch 55, Loss: 0.046\n",
      "Training: Epoch 185, Batch 56, Loss: 0.051\n",
      "Training: Epoch 185, Batch 57, Loss: 0.066\n",
      "Training: Epoch 185, Batch 58, Loss: 0.071\n",
      "Training: Epoch 185, Batch 59, Loss: 0.068\n",
      "Val: Epoch 185, Loss: 0.336\n",
      "Training: Epoch 186, Batch 0, Loss: 0.051\n",
      "Training: Epoch 186, Batch 1, Loss: 0.054\n",
      "Training: Epoch 186, Batch 2, Loss: 0.067\n",
      "Training: Epoch 186, Batch 3, Loss: 0.06\n",
      "Training: Epoch 186, Batch 4, Loss: 0.058\n",
      "Training: Epoch 186, Batch 5, Loss: 0.049\n",
      "Training: Epoch 186, Batch 6, Loss: 0.053\n",
      "Training: Epoch 186, Batch 7, Loss: 0.057\n",
      "Training: Epoch 186, Batch 8, Loss: 0.049\n",
      "Training: Epoch 186, Batch 9, Loss: 0.062\n",
      "Training: Epoch 186, Batch 10, Loss: 0.066\n",
      "Training: Epoch 186, Batch 11, Loss: 0.063\n",
      "Training: Epoch 186, Batch 12, Loss: 0.06\n",
      "Training: Epoch 186, Batch 13, Loss: 0.059\n",
      "Training: Epoch 186, Batch 14, Loss: 0.05\n",
      "Training: Epoch 186, Batch 15, Loss: 0.053\n",
      "Training: Epoch 186, Batch 16, Loss: 0.072\n",
      "Training: Epoch 186, Batch 17, Loss: 0.063\n",
      "Training: Epoch 186, Batch 18, Loss: 0.062\n",
      "Training: Epoch 186, Batch 19, Loss: 0.059\n",
      "Training: Epoch 186, Batch 20, Loss: 0.069\n",
      "Training: Epoch 186, Batch 21, Loss: 0.05\n",
      "Training: Epoch 186, Batch 22, Loss: 0.061\n",
      "Training: Epoch 186, Batch 23, Loss: 0.058\n",
      "Training: Epoch 186, Batch 24, Loss: 0.054\n",
      "Training: Epoch 186, Batch 25, Loss: 0.056\n",
      "Training: Epoch 186, Batch 26, Loss: 0.061\n",
      "Training: Epoch 186, Batch 27, Loss: 0.06\n",
      "Training: Epoch 186, Batch 28, Loss: 0.057\n",
      "Training: Epoch 186, Batch 29, Loss: 0.058\n",
      "Training: Epoch 186, Batch 30, Loss: 0.07\n",
      "Training: Epoch 186, Batch 31, Loss: 0.06\n",
      "Training: Epoch 186, Batch 32, Loss: 0.066\n",
      "Training: Epoch 186, Batch 33, Loss: 0.061\n",
      "Training: Epoch 186, Batch 34, Loss: 0.052\n",
      "Training: Epoch 186, Batch 35, Loss: 0.062\n",
      "Training: Epoch 186, Batch 36, Loss: 0.042\n",
      "Training: Epoch 186, Batch 37, Loss: 0.045\n",
      "Training: Epoch 186, Batch 38, Loss: 0.059\n",
      "Training: Epoch 186, Batch 39, Loss: 0.054\n",
      "Training: Epoch 186, Batch 40, Loss: 0.064\n",
      "Training: Epoch 186, Batch 41, Loss: 0.061\n",
      "Training: Epoch 186, Batch 42, Loss: 0.05\n",
      "Training: Epoch 186, Batch 43, Loss: 0.059\n",
      "Training: Epoch 186, Batch 44, Loss: 0.057\n",
      "Training: Epoch 186, Batch 45, Loss: 0.059\n",
      "Training: Epoch 186, Batch 46, Loss: 0.057\n",
      "Training: Epoch 186, Batch 47, Loss: 0.054\n",
      "Training: Epoch 186, Batch 48, Loss: 0.061\n",
      "Training: Epoch 186, Batch 49, Loss: 0.044\n",
      "Training: Epoch 186, Batch 50, Loss: 0.064\n",
      "Training: Epoch 186, Batch 51, Loss: 0.052\n",
      "Training: Epoch 186, Batch 52, Loss: 0.067\n",
      "Training: Epoch 186, Batch 53, Loss: 0.055\n",
      "Training: Epoch 186, Batch 54, Loss: 0.054\n",
      "Training: Epoch 186, Batch 55, Loss: 0.058\n",
      "Training: Epoch 186, Batch 56, Loss: 0.048\n",
      "Training: Epoch 186, Batch 57, Loss: 0.053\n",
      "Training: Epoch 186, Batch 58, Loss: 0.061\n",
      "Training: Epoch 186, Batch 59, Loss: 0.061\n",
      "Val: Epoch 186, Loss: 0.314\n",
      "Training: Epoch 187, Batch 0, Loss: 0.053\n",
      "Training: Epoch 187, Batch 1, Loss: 0.051\n",
      "Training: Epoch 187, Batch 2, Loss: 0.062\n",
      "Training: Epoch 187, Batch 3, Loss: 0.052\n",
      "Training: Epoch 187, Batch 4, Loss: 0.042\n",
      "Training: Epoch 187, Batch 5, Loss: 0.064\n",
      "Training: Epoch 187, Batch 6, Loss: 0.048\n",
      "Training: Epoch 187, Batch 7, Loss: 0.049\n",
      "Training: Epoch 187, Batch 8, Loss: 0.057\n",
      "Training: Epoch 187, Batch 9, Loss: 0.06\n",
      "Training: Epoch 187, Batch 10, Loss: 0.058\n",
      "Training: Epoch 187, Batch 11, Loss: 0.058\n",
      "Training: Epoch 187, Batch 12, Loss: 0.057\n",
      "Training: Epoch 187, Batch 13, Loss: 0.062\n",
      "Training: Epoch 187, Batch 14, Loss: 0.053\n",
      "Training: Epoch 187, Batch 15, Loss: 0.062\n",
      "Training: Epoch 187, Batch 16, Loss: 0.065\n",
      "Training: Epoch 187, Batch 17, Loss: 0.067\n",
      "Training: Epoch 187, Batch 18, Loss: 0.057\n",
      "Training: Epoch 187, Batch 19, Loss: 0.059\n",
      "Training: Epoch 187, Batch 20, Loss: 0.048\n",
      "Training: Epoch 187, Batch 21, Loss: 0.071\n",
      "Training: Epoch 187, Batch 22, Loss: 0.05\n",
      "Training: Epoch 187, Batch 23, Loss: 0.083\n",
      "Training: Epoch 187, Batch 24, Loss: 0.063\n",
      "Training: Epoch 187, Batch 25, Loss: 0.047\n",
      "Training: Epoch 187, Batch 26, Loss: 0.057\n",
      "Training: Epoch 187, Batch 27, Loss: 0.078\n",
      "Training: Epoch 187, Batch 28, Loss: 0.057\n",
      "Training: Epoch 187, Batch 29, Loss: 0.07\n",
      "Training: Epoch 187, Batch 30, Loss: 0.06\n",
      "Training: Epoch 187, Batch 31, Loss: 0.058\n",
      "Training: Epoch 187, Batch 32, Loss: 0.05\n",
      "Training: Epoch 187, Batch 33, Loss: 0.066\n",
      "Training: Epoch 187, Batch 34, Loss: 0.057\n",
      "Training: Epoch 187, Batch 35, Loss: 0.058\n",
      "Training: Epoch 187, Batch 36, Loss: 0.055\n",
      "Training: Epoch 187, Batch 37, Loss: 0.061\n",
      "Training: Epoch 187, Batch 38, Loss: 0.067\n",
      "Training: Epoch 187, Batch 39, Loss: 0.067\n",
      "Training: Epoch 187, Batch 40, Loss: 0.058\n",
      "Training: Epoch 187, Batch 41, Loss: 0.051\n",
      "Training: Epoch 187, Batch 42, Loss: 0.055\n",
      "Training: Epoch 187, Batch 43, Loss: 0.04\n",
      "Training: Epoch 187, Batch 44, Loss: 0.056\n",
      "Training: Epoch 187, Batch 45, Loss: 0.054\n",
      "Training: Epoch 187, Batch 46, Loss: 0.067\n",
      "Training: Epoch 187, Batch 47, Loss: 0.065\n",
      "Training: Epoch 187, Batch 48, Loss: 0.046\n",
      "Training: Epoch 187, Batch 49, Loss: 0.062\n",
      "Training: Epoch 187, Batch 50, Loss: 0.05\n",
      "Training: Epoch 187, Batch 51, Loss: 0.052\n",
      "Training: Epoch 187, Batch 52, Loss: 0.057\n",
      "Training: Epoch 187, Batch 53, Loss: 0.061\n",
      "Training: Epoch 187, Batch 54, Loss: 0.046\n",
      "Training: Epoch 187, Batch 55, Loss: 0.048\n",
      "Training: Epoch 187, Batch 56, Loss: 0.061\n",
      "Training: Epoch 187, Batch 57, Loss: 0.046\n",
      "Training: Epoch 187, Batch 58, Loss: 0.064\n",
      "Training: Epoch 187, Batch 59, Loss: 0.057\n",
      "Val: Epoch 187, Loss: 0.323\n",
      "Training: Epoch 188, Batch 0, Loss: 0.063\n",
      "Training: Epoch 188, Batch 1, Loss: 0.057\n",
      "Training: Epoch 188, Batch 2, Loss: 0.062\n",
      "Training: Epoch 188, Batch 3, Loss: 0.05\n",
      "Training: Epoch 188, Batch 4, Loss: 0.043\n",
      "Training: Epoch 188, Batch 5, Loss: 0.064\n",
      "Training: Epoch 188, Batch 6, Loss: 0.059\n",
      "Training: Epoch 188, Batch 7, Loss: 0.066\n",
      "Training: Epoch 188, Batch 8, Loss: 0.064\n",
      "Training: Epoch 188, Batch 9, Loss: 0.061\n",
      "Training: Epoch 188, Batch 10, Loss: 0.055\n",
      "Training: Epoch 188, Batch 11, Loss: 0.045\n",
      "Training: Epoch 188, Batch 12, Loss: 0.061\n",
      "Training: Epoch 188, Batch 13, Loss: 0.056\n",
      "Training: Epoch 188, Batch 14, Loss: 0.05\n",
      "Training: Epoch 188, Batch 15, Loss: 0.058\n",
      "Training: Epoch 188, Batch 16, Loss: 0.052\n",
      "Training: Epoch 188, Batch 17, Loss: 0.057\n",
      "Training: Epoch 188, Batch 18, Loss: 0.057\n",
      "Training: Epoch 188, Batch 19, Loss: 0.078\n",
      "Training: Epoch 188, Batch 20, Loss: 0.053\n",
      "Training: Epoch 188, Batch 21, Loss: 0.055\n",
      "Training: Epoch 188, Batch 22, Loss: 0.068\n",
      "Training: Epoch 188, Batch 23, Loss: 0.048\n",
      "Training: Epoch 188, Batch 24, Loss: 0.06\n",
      "Training: Epoch 188, Batch 25, Loss: 0.049\n",
      "Training: Epoch 188, Batch 26, Loss: 0.068\n",
      "Training: Epoch 188, Batch 27, Loss: 0.043\n",
      "Training: Epoch 188, Batch 28, Loss: 0.055\n",
      "Training: Epoch 188, Batch 29, Loss: 0.061\n",
      "Training: Epoch 188, Batch 30, Loss: 0.058\n",
      "Training: Epoch 188, Batch 31, Loss: 0.05\n",
      "Training: Epoch 188, Batch 32, Loss: 0.054\n",
      "Training: Epoch 188, Batch 33, Loss: 0.06\n",
      "Training: Epoch 188, Batch 34, Loss: 0.057\n",
      "Training: Epoch 188, Batch 35, Loss: 0.059\n",
      "Training: Epoch 188, Batch 36, Loss: 0.06\n",
      "Training: Epoch 188, Batch 37, Loss: 0.058\n",
      "Training: Epoch 188, Batch 38, Loss: 0.054\n",
      "Training: Epoch 188, Batch 39, Loss: 0.049\n",
      "Training: Epoch 188, Batch 40, Loss: 0.05\n",
      "Training: Epoch 188, Batch 41, Loss: 0.051\n",
      "Training: Epoch 188, Batch 42, Loss: 0.061\n",
      "Training: Epoch 188, Batch 43, Loss: 0.056\n",
      "Training: Epoch 188, Batch 44, Loss: 0.052\n",
      "Training: Epoch 188, Batch 45, Loss: 0.052\n",
      "Training: Epoch 188, Batch 46, Loss: 0.064\n",
      "Training: Epoch 188, Batch 47, Loss: 0.078\n",
      "Training: Epoch 188, Batch 48, Loss: 0.067\n",
      "Training: Epoch 188, Batch 49, Loss: 0.058\n",
      "Training: Epoch 188, Batch 50, Loss: 0.059\n",
      "Training: Epoch 188, Batch 51, Loss: 0.065\n",
      "Training: Epoch 188, Batch 52, Loss: 0.062\n",
      "Training: Epoch 188, Batch 53, Loss: 0.073\n",
      "Training: Epoch 188, Batch 54, Loss: 0.048\n",
      "Training: Epoch 188, Batch 55, Loss: 0.065\n",
      "Training: Epoch 188, Batch 56, Loss: 0.054\n",
      "Training: Epoch 188, Batch 57, Loss: 0.046\n",
      "Training: Epoch 188, Batch 58, Loss: 0.057\n",
      "Training: Epoch 188, Batch 59, Loss: 0.069\n",
      "Val: Epoch 188, Loss: 0.331\n",
      "Training: Epoch 189, Batch 0, Loss: 0.055\n",
      "Training: Epoch 189, Batch 1, Loss: 0.059\n",
      "Training: Epoch 189, Batch 2, Loss: 0.058\n",
      "Training: Epoch 189, Batch 3, Loss: 0.072\n",
      "Training: Epoch 189, Batch 4, Loss: 0.049\n",
      "Training: Epoch 189, Batch 5, Loss: 0.046\n",
      "Training: Epoch 189, Batch 6, Loss: 0.052\n",
      "Training: Epoch 189, Batch 7, Loss: 0.06\n",
      "Training: Epoch 189, Batch 8, Loss: 0.052\n",
      "Training: Epoch 189, Batch 9, Loss: 0.052\n",
      "Training: Epoch 189, Batch 10, Loss: 0.064\n",
      "Training: Epoch 189, Batch 11, Loss: 0.044\n",
      "Training: Epoch 189, Batch 12, Loss: 0.054\n",
      "Training: Epoch 189, Batch 13, Loss: 0.066\n",
      "Training: Epoch 189, Batch 14, Loss: 0.057\n",
      "Training: Epoch 189, Batch 15, Loss: 0.063\n",
      "Training: Epoch 189, Batch 16, Loss: 0.06\n",
      "Training: Epoch 189, Batch 17, Loss: 0.062\n",
      "Training: Epoch 189, Batch 18, Loss: 0.053\n",
      "Training: Epoch 189, Batch 19, Loss: 0.054\n",
      "Training: Epoch 189, Batch 20, Loss: 0.062\n",
      "Training: Epoch 189, Batch 21, Loss: 0.076\n",
      "Training: Epoch 189, Batch 22, Loss: 0.064\n",
      "Training: Epoch 189, Batch 23, Loss: 0.055\n",
      "Training: Epoch 189, Batch 24, Loss: 0.064\n",
      "Training: Epoch 189, Batch 25, Loss: 0.055\n",
      "Training: Epoch 189, Batch 26, Loss: 0.068\n",
      "Training: Epoch 189, Batch 27, Loss: 0.062\n",
      "Training: Epoch 189, Batch 28, Loss: 0.059\n",
      "Training: Epoch 189, Batch 29, Loss: 0.081\n",
      "Training: Epoch 189, Batch 30, Loss: 0.056\n",
      "Training: Epoch 189, Batch 31, Loss: 0.071\n",
      "Training: Epoch 189, Batch 32, Loss: 0.056\n",
      "Training: Epoch 189, Batch 33, Loss: 0.063\n",
      "Training: Epoch 189, Batch 34, Loss: 0.051\n",
      "Training: Epoch 189, Batch 35, Loss: 0.063\n",
      "Training: Epoch 189, Batch 36, Loss: 0.063\n",
      "Training: Epoch 189, Batch 37, Loss: 0.059\n",
      "Training: Epoch 189, Batch 38, Loss: 0.067\n",
      "Training: Epoch 189, Batch 39, Loss: 0.048\n",
      "Training: Epoch 189, Batch 40, Loss: 0.059\n",
      "Training: Epoch 189, Batch 41, Loss: 0.061\n",
      "Training: Epoch 189, Batch 42, Loss: 0.064\n",
      "Training: Epoch 189, Batch 43, Loss: 0.064\n",
      "Training: Epoch 189, Batch 44, Loss: 0.058\n",
      "Training: Epoch 189, Batch 45, Loss: 0.069\n",
      "Training: Epoch 189, Batch 46, Loss: 0.062\n",
      "Training: Epoch 189, Batch 47, Loss: 0.066\n",
      "Training: Epoch 189, Batch 48, Loss: 0.05\n",
      "Training: Epoch 189, Batch 49, Loss: 0.053\n",
      "Training: Epoch 189, Batch 50, Loss: 0.061\n",
      "Training: Epoch 189, Batch 51, Loss: 0.068\n",
      "Training: Epoch 189, Batch 52, Loss: 0.052\n",
      "Training: Epoch 189, Batch 53, Loss: 0.083\n",
      "Training: Epoch 189, Batch 54, Loss: 0.048\n",
      "Training: Epoch 189, Batch 55, Loss: 0.061\n",
      "Training: Epoch 189, Batch 56, Loss: 0.058\n",
      "Training: Epoch 189, Batch 57, Loss: 0.051\n",
      "Training: Epoch 189, Batch 58, Loss: 0.067\n",
      "Training: Epoch 189, Batch 59, Loss: 0.056\n",
      "Val: Epoch 189, Loss: 0.34\n",
      "Training: Epoch 190, Batch 0, Loss: 0.048\n",
      "Training: Epoch 190, Batch 1, Loss: 0.054\n",
      "Training: Epoch 190, Batch 2, Loss: 0.063\n",
      "Training: Epoch 190, Batch 3, Loss: 0.069\n",
      "Training: Epoch 190, Batch 4, Loss: 0.051\n",
      "Training: Epoch 190, Batch 5, Loss: 0.064\n",
      "Training: Epoch 190, Batch 6, Loss: 0.057\n",
      "Training: Epoch 190, Batch 7, Loss: 0.054\n",
      "Training: Epoch 190, Batch 8, Loss: 0.057\n",
      "Training: Epoch 190, Batch 9, Loss: 0.049\n",
      "Training: Epoch 190, Batch 10, Loss: 0.053\n",
      "Training: Epoch 190, Batch 11, Loss: 0.056\n",
      "Training: Epoch 190, Batch 12, Loss: 0.059\n",
      "Training: Epoch 190, Batch 13, Loss: 0.065\n",
      "Training: Epoch 190, Batch 14, Loss: 0.053\n",
      "Training: Epoch 190, Batch 15, Loss: 0.054\n",
      "Training: Epoch 190, Batch 16, Loss: 0.063\n",
      "Training: Epoch 190, Batch 17, Loss: 0.05\n",
      "Training: Epoch 190, Batch 18, Loss: 0.054\n",
      "Training: Epoch 190, Batch 19, Loss: 0.065\n",
      "Training: Epoch 190, Batch 20, Loss: 0.064\n",
      "Training: Epoch 190, Batch 21, Loss: 0.056\n",
      "Training: Epoch 190, Batch 22, Loss: 0.044\n",
      "Training: Epoch 190, Batch 23, Loss: 0.066\n",
      "Training: Epoch 190, Batch 24, Loss: 0.059\n",
      "Training: Epoch 190, Batch 25, Loss: 0.049\n",
      "Training: Epoch 190, Batch 26, Loss: 0.061\n",
      "Training: Epoch 190, Batch 27, Loss: 0.05\n",
      "Training: Epoch 190, Batch 28, Loss: 0.055\n",
      "Training: Epoch 190, Batch 29, Loss: 0.071\n",
      "Training: Epoch 190, Batch 30, Loss: 0.064\n",
      "Training: Epoch 190, Batch 31, Loss: 0.05\n",
      "Training: Epoch 190, Batch 32, Loss: 0.072\n",
      "Training: Epoch 190, Batch 33, Loss: 0.065\n",
      "Training: Epoch 190, Batch 34, Loss: 0.066\n",
      "Training: Epoch 190, Batch 35, Loss: 0.06\n",
      "Training: Epoch 190, Batch 36, Loss: 0.054\n",
      "Training: Epoch 190, Batch 37, Loss: 0.057\n",
      "Training: Epoch 190, Batch 38, Loss: 0.057\n",
      "Training: Epoch 190, Batch 39, Loss: 0.053\n",
      "Training: Epoch 190, Batch 40, Loss: 0.055\n",
      "Training: Epoch 190, Batch 41, Loss: 0.08\n",
      "Training: Epoch 190, Batch 42, Loss: 0.049\n",
      "Training: Epoch 190, Batch 43, Loss: 0.053\n",
      "Training: Epoch 190, Batch 44, Loss: 0.061\n",
      "Training: Epoch 190, Batch 45, Loss: 0.052\n",
      "Training: Epoch 190, Batch 46, Loss: 0.054\n",
      "Training: Epoch 190, Batch 47, Loss: 0.05\n",
      "Training: Epoch 190, Batch 48, Loss: 0.063\n",
      "Training: Epoch 190, Batch 49, Loss: 0.051\n",
      "Training: Epoch 190, Batch 50, Loss: 0.064\n",
      "Training: Epoch 190, Batch 51, Loss: 0.066\n",
      "Training: Epoch 190, Batch 52, Loss: 0.053\n",
      "Training: Epoch 190, Batch 53, Loss: 0.058\n",
      "Training: Epoch 190, Batch 54, Loss: 0.046\n",
      "Training: Epoch 190, Batch 55, Loss: 0.063\n",
      "Training: Epoch 190, Batch 56, Loss: 0.057\n",
      "Training: Epoch 190, Batch 57, Loss: 0.062\n",
      "Training: Epoch 190, Batch 58, Loss: 0.053\n",
      "Training: Epoch 190, Batch 59, Loss: 0.059\n",
      "Val: Epoch 190, Loss: 0.326\n",
      "Training: Epoch 191, Batch 0, Loss: 0.057\n",
      "Training: Epoch 191, Batch 1, Loss: 0.061\n",
      "Training: Epoch 191, Batch 2, Loss: 0.06\n",
      "Training: Epoch 191, Batch 3, Loss: 0.055\n",
      "Training: Epoch 191, Batch 4, Loss: 0.053\n",
      "Training: Epoch 191, Batch 5, Loss: 0.062\n",
      "Training: Epoch 191, Batch 6, Loss: 0.053\n",
      "Training: Epoch 191, Batch 7, Loss: 0.061\n",
      "Training: Epoch 191, Batch 8, Loss: 0.053\n",
      "Training: Epoch 191, Batch 9, Loss: 0.048\n",
      "Training: Epoch 191, Batch 10, Loss: 0.048\n",
      "Training: Epoch 191, Batch 11, Loss: 0.064\n",
      "Training: Epoch 191, Batch 12, Loss: 0.052\n",
      "Training: Epoch 191, Batch 13, Loss: 0.055\n",
      "Training: Epoch 191, Batch 14, Loss: 0.057\n",
      "Training: Epoch 191, Batch 15, Loss: 0.06\n",
      "Training: Epoch 191, Batch 16, Loss: 0.065\n",
      "Training: Epoch 191, Batch 17, Loss: 0.058\n",
      "Training: Epoch 191, Batch 18, Loss: 0.048\n",
      "Training: Epoch 191, Batch 19, Loss: 0.057\n",
      "Training: Epoch 191, Batch 20, Loss: 0.058\n",
      "Training: Epoch 191, Batch 21, Loss: 0.053\n",
      "Training: Epoch 191, Batch 22, Loss: 0.063\n",
      "Training: Epoch 191, Batch 23, Loss: 0.051\n",
      "Training: Epoch 191, Batch 24, Loss: 0.054\n",
      "Training: Epoch 191, Batch 25, Loss: 0.053\n",
      "Training: Epoch 191, Batch 26, Loss: 0.047\n",
      "Training: Epoch 191, Batch 27, Loss: 0.069\n",
      "Training: Epoch 191, Batch 28, Loss: 0.056\n",
      "Training: Epoch 191, Batch 29, Loss: 0.061\n",
      "Training: Epoch 191, Batch 30, Loss: 0.048\n",
      "Training: Epoch 191, Batch 31, Loss: 0.062\n",
      "Training: Epoch 191, Batch 32, Loss: 0.059\n",
      "Training: Epoch 191, Batch 33, Loss: 0.074\n",
      "Training: Epoch 191, Batch 34, Loss: 0.052\n",
      "Training: Epoch 191, Batch 35, Loss: 0.064\n",
      "Training: Epoch 191, Batch 36, Loss: 0.067\n",
      "Training: Epoch 191, Batch 37, Loss: 0.062\n",
      "Training: Epoch 191, Batch 38, Loss: 0.055\n",
      "Training: Epoch 191, Batch 39, Loss: 0.052\n",
      "Training: Epoch 191, Batch 40, Loss: 0.061\n",
      "Training: Epoch 191, Batch 41, Loss: 0.046\n",
      "Training: Epoch 191, Batch 42, Loss: 0.06\n",
      "Training: Epoch 191, Batch 43, Loss: 0.061\n",
      "Training: Epoch 191, Batch 44, Loss: 0.051\n",
      "Training: Epoch 191, Batch 45, Loss: 0.074\n",
      "Training: Epoch 191, Batch 46, Loss: 0.08\n",
      "Training: Epoch 191, Batch 47, Loss: 0.061\n",
      "Training: Epoch 191, Batch 48, Loss: 0.064\n",
      "Training: Epoch 191, Batch 49, Loss: 0.045\n",
      "Training: Epoch 191, Batch 50, Loss: 0.052\n",
      "Training: Epoch 191, Batch 51, Loss: 0.058\n",
      "Training: Epoch 191, Batch 52, Loss: 0.055\n",
      "Training: Epoch 191, Batch 53, Loss: 0.048\n",
      "Training: Epoch 191, Batch 54, Loss: 0.059\n",
      "Training: Epoch 191, Batch 55, Loss: 0.069\n",
      "Training: Epoch 191, Batch 56, Loss: 0.051\n",
      "Training: Epoch 191, Batch 57, Loss: 0.054\n",
      "Training: Epoch 191, Batch 58, Loss: 0.058\n",
      "Training: Epoch 191, Batch 59, Loss: 0.053\n",
      "Val: Epoch 191, Loss: 0.326\n",
      "Training: Epoch 192, Batch 0, Loss: 0.043\n",
      "Training: Epoch 192, Batch 1, Loss: 0.056\n",
      "Training: Epoch 192, Batch 2, Loss: 0.082\n",
      "Training: Epoch 192, Batch 3, Loss: 0.058\n",
      "Training: Epoch 192, Batch 4, Loss: 0.069\n",
      "Training: Epoch 192, Batch 5, Loss: 0.068\n",
      "Training: Epoch 192, Batch 6, Loss: 0.063\n",
      "Training: Epoch 192, Batch 7, Loss: 0.064\n",
      "Training: Epoch 192, Batch 8, Loss: 0.047\n",
      "Training: Epoch 192, Batch 9, Loss: 0.06\n",
      "Training: Epoch 192, Batch 10, Loss: 0.062\n",
      "Training: Epoch 192, Batch 11, Loss: 0.05\n",
      "Training: Epoch 192, Batch 12, Loss: 0.057\n",
      "Training: Epoch 192, Batch 13, Loss: 0.057\n",
      "Training: Epoch 192, Batch 14, Loss: 0.049\n",
      "Training: Epoch 192, Batch 15, Loss: 0.071\n",
      "Training: Epoch 192, Batch 16, Loss: 0.042\n",
      "Training: Epoch 192, Batch 17, Loss: 0.052\n",
      "Training: Epoch 192, Batch 18, Loss: 0.059\n",
      "Training: Epoch 192, Batch 19, Loss: 0.061\n",
      "Training: Epoch 192, Batch 20, Loss: 0.061\n",
      "Training: Epoch 192, Batch 21, Loss: 0.057\n",
      "Training: Epoch 192, Batch 22, Loss: 0.052\n",
      "Training: Epoch 192, Batch 23, Loss: 0.045\n",
      "Training: Epoch 192, Batch 24, Loss: 0.059\n",
      "Training: Epoch 192, Batch 25, Loss: 0.052\n",
      "Training: Epoch 192, Batch 26, Loss: 0.048\n",
      "Training: Epoch 192, Batch 27, Loss: 0.061\n",
      "Training: Epoch 192, Batch 28, Loss: 0.048\n",
      "Training: Epoch 192, Batch 29, Loss: 0.064\n",
      "Training: Epoch 192, Batch 30, Loss: 0.048\n",
      "Training: Epoch 192, Batch 31, Loss: 0.056\n",
      "Training: Epoch 192, Batch 32, Loss: 0.049\n",
      "Training: Epoch 192, Batch 33, Loss: 0.062\n",
      "Training: Epoch 192, Batch 34, Loss: 0.064\n",
      "Training: Epoch 192, Batch 35, Loss: 0.059\n",
      "Training: Epoch 192, Batch 36, Loss: 0.058\n",
      "Training: Epoch 192, Batch 37, Loss: 0.073\n",
      "Training: Epoch 192, Batch 38, Loss: 0.059\n",
      "Training: Epoch 192, Batch 39, Loss: 0.056\n",
      "Training: Epoch 192, Batch 40, Loss: 0.06\n",
      "Training: Epoch 192, Batch 41, Loss: 0.047\n",
      "Training: Epoch 192, Batch 42, Loss: 0.063\n",
      "Training: Epoch 192, Batch 43, Loss: 0.056\n",
      "Training: Epoch 192, Batch 44, Loss: 0.054\n",
      "Training: Epoch 192, Batch 45, Loss: 0.056\n",
      "Training: Epoch 192, Batch 46, Loss: 0.067\n",
      "Training: Epoch 192, Batch 47, Loss: 0.052\n",
      "Training: Epoch 192, Batch 48, Loss: 0.061\n",
      "Training: Epoch 192, Batch 49, Loss: 0.051\n",
      "Training: Epoch 192, Batch 50, Loss: 0.049\n",
      "Training: Epoch 192, Batch 51, Loss: 0.069\n",
      "Training: Epoch 192, Batch 52, Loss: 0.061\n",
      "Training: Epoch 192, Batch 53, Loss: 0.058\n",
      "Training: Epoch 192, Batch 54, Loss: 0.052\n",
      "Training: Epoch 192, Batch 55, Loss: 0.052\n",
      "Training: Epoch 192, Batch 56, Loss: 0.064\n",
      "Training: Epoch 192, Batch 57, Loss: 0.056\n",
      "Training: Epoch 192, Batch 58, Loss: 0.055\n",
      "Training: Epoch 192, Batch 59, Loss: 0.06\n",
      "Val: Epoch 192, Loss: 0.335\n",
      "Training: Epoch 193, Batch 0, Loss: 0.054\n",
      "Training: Epoch 193, Batch 1, Loss: 0.062\n",
      "Training: Epoch 193, Batch 2, Loss: 0.057\n",
      "Training: Epoch 193, Batch 3, Loss: 0.057\n",
      "Training: Epoch 193, Batch 4, Loss: 0.057\n",
      "Training: Epoch 193, Batch 5, Loss: 0.058\n",
      "Training: Epoch 193, Batch 6, Loss: 0.054\n",
      "Training: Epoch 193, Batch 7, Loss: 0.061\n",
      "Training: Epoch 193, Batch 8, Loss: 0.064\n",
      "Training: Epoch 193, Batch 9, Loss: 0.058\n",
      "Training: Epoch 193, Batch 10, Loss: 0.046\n",
      "Training: Epoch 193, Batch 11, Loss: 0.047\n",
      "Training: Epoch 193, Batch 12, Loss: 0.057\n",
      "Training: Epoch 193, Batch 13, Loss: 0.071\n",
      "Training: Epoch 193, Batch 14, Loss: 0.078\n",
      "Training: Epoch 193, Batch 15, Loss: 0.059\n",
      "Training: Epoch 193, Batch 16, Loss: 0.053\n",
      "Training: Epoch 193, Batch 17, Loss: 0.052\n",
      "Training: Epoch 193, Batch 18, Loss: 0.051\n",
      "Training: Epoch 193, Batch 19, Loss: 0.049\n",
      "Training: Epoch 193, Batch 20, Loss: 0.075\n",
      "Training: Epoch 193, Batch 21, Loss: 0.049\n",
      "Training: Epoch 193, Batch 22, Loss: 0.049\n",
      "Training: Epoch 193, Batch 23, Loss: 0.07\n",
      "Training: Epoch 193, Batch 24, Loss: 0.062\n",
      "Training: Epoch 193, Batch 25, Loss: 0.057\n",
      "Training: Epoch 193, Batch 26, Loss: 0.059\n",
      "Training: Epoch 193, Batch 27, Loss: 0.06\n",
      "Training: Epoch 193, Batch 28, Loss: 0.05\n",
      "Training: Epoch 193, Batch 29, Loss: 0.054\n",
      "Training: Epoch 193, Batch 30, Loss: 0.07\n",
      "Training: Epoch 193, Batch 31, Loss: 0.055\n",
      "Training: Epoch 193, Batch 32, Loss: 0.057\n",
      "Training: Epoch 193, Batch 33, Loss: 0.051\n",
      "Training: Epoch 193, Batch 34, Loss: 0.044\n",
      "Training: Epoch 193, Batch 35, Loss: 0.049\n",
      "Training: Epoch 193, Batch 36, Loss: 0.071\n",
      "Training: Epoch 193, Batch 37, Loss: 0.057\n",
      "Training: Epoch 193, Batch 38, Loss: 0.054\n",
      "Training: Epoch 193, Batch 39, Loss: 0.049\n",
      "Training: Epoch 193, Batch 40, Loss: 0.076\n",
      "Training: Epoch 193, Batch 41, Loss: 0.048\n",
      "Training: Epoch 193, Batch 42, Loss: 0.056\n",
      "Training: Epoch 193, Batch 43, Loss: 0.074\n",
      "Training: Epoch 193, Batch 44, Loss: 0.06\n",
      "Training: Epoch 193, Batch 45, Loss: 0.062\n",
      "Training: Epoch 193, Batch 46, Loss: 0.066\n",
      "Training: Epoch 193, Batch 47, Loss: 0.054\n",
      "Training: Epoch 193, Batch 48, Loss: 0.047\n",
      "Training: Epoch 193, Batch 49, Loss: 0.047\n",
      "Training: Epoch 193, Batch 50, Loss: 0.049\n",
      "Training: Epoch 193, Batch 51, Loss: 0.062\n",
      "Training: Epoch 193, Batch 52, Loss: 0.063\n",
      "Training: Epoch 193, Batch 53, Loss: 0.049\n",
      "Training: Epoch 193, Batch 54, Loss: 0.054\n",
      "Training: Epoch 193, Batch 55, Loss: 0.056\n",
      "Training: Epoch 193, Batch 56, Loss: 0.071\n",
      "Training: Epoch 193, Batch 57, Loss: 0.07\n",
      "Training: Epoch 193, Batch 58, Loss: 0.062\n",
      "Training: Epoch 193, Batch 59, Loss: 0.044\n",
      "Val: Epoch 193, Loss: 0.35\n",
      "Training: Epoch 194, Batch 0, Loss: 0.062\n",
      "Training: Epoch 194, Batch 1, Loss: 0.063\n",
      "Training: Epoch 194, Batch 2, Loss: 0.057\n",
      "Training: Epoch 194, Batch 3, Loss: 0.057\n",
      "Training: Epoch 194, Batch 4, Loss: 0.048\n",
      "Training: Epoch 194, Batch 5, Loss: 0.053\n",
      "Training: Epoch 194, Batch 6, Loss: 0.059\n",
      "Training: Epoch 194, Batch 7, Loss: 0.047\n",
      "Training: Epoch 194, Batch 8, Loss: 0.057\n",
      "Training: Epoch 194, Batch 9, Loss: 0.058\n",
      "Training: Epoch 194, Batch 10, Loss: 0.055\n",
      "Training: Epoch 194, Batch 11, Loss: 0.065\n",
      "Training: Epoch 194, Batch 12, Loss: 0.063\n",
      "Training: Epoch 194, Batch 13, Loss: 0.052\n",
      "Training: Epoch 194, Batch 14, Loss: 0.055\n",
      "Training: Epoch 194, Batch 15, Loss: 0.055\n",
      "Training: Epoch 194, Batch 16, Loss: 0.049\n",
      "Training: Epoch 194, Batch 17, Loss: 0.052\n",
      "Training: Epoch 194, Batch 18, Loss: 0.062\n",
      "Training: Epoch 194, Batch 19, Loss: 0.041\n",
      "Training: Epoch 194, Batch 20, Loss: 0.057\n",
      "Training: Epoch 194, Batch 21, Loss: 0.05\n",
      "Training: Epoch 194, Batch 22, Loss: 0.055\n",
      "Training: Epoch 194, Batch 23, Loss: 0.065\n",
      "Training: Epoch 194, Batch 24, Loss: 0.055\n",
      "Training: Epoch 194, Batch 25, Loss: 0.054\n",
      "Training: Epoch 194, Batch 26, Loss: 0.058\n",
      "Training: Epoch 194, Batch 27, Loss: 0.063\n",
      "Training: Epoch 194, Batch 28, Loss: 0.062\n",
      "Training: Epoch 194, Batch 29, Loss: 0.057\n",
      "Training: Epoch 194, Batch 30, Loss: 0.058\n",
      "Training: Epoch 194, Batch 31, Loss: 0.056\n",
      "Training: Epoch 194, Batch 32, Loss: 0.066\n",
      "Training: Epoch 194, Batch 33, Loss: 0.047\n",
      "Training: Epoch 194, Batch 34, Loss: 0.054\n",
      "Training: Epoch 194, Batch 35, Loss: 0.047\n",
      "Training: Epoch 194, Batch 36, Loss: 0.068\n",
      "Training: Epoch 194, Batch 37, Loss: 0.063\n",
      "Training: Epoch 194, Batch 38, Loss: 0.058\n",
      "Training: Epoch 194, Batch 39, Loss: 0.075\n",
      "Training: Epoch 194, Batch 40, Loss: 0.056\n",
      "Training: Epoch 194, Batch 41, Loss: 0.062\n",
      "Training: Epoch 194, Batch 42, Loss: 0.064\n",
      "Training: Epoch 194, Batch 43, Loss: 0.056\n",
      "Training: Epoch 194, Batch 44, Loss: 0.037\n",
      "Training: Epoch 194, Batch 45, Loss: 0.048\n",
      "Training: Epoch 194, Batch 46, Loss: 0.047\n",
      "Training: Epoch 194, Batch 47, Loss: 0.057\n",
      "Training: Epoch 194, Batch 48, Loss: 0.056\n",
      "Training: Epoch 194, Batch 49, Loss: 0.056\n",
      "Training: Epoch 194, Batch 50, Loss: 0.061\n",
      "Training: Epoch 194, Batch 51, Loss: 0.066\n",
      "Training: Epoch 194, Batch 52, Loss: 0.048\n",
      "Training: Epoch 194, Batch 53, Loss: 0.053\n",
      "Training: Epoch 194, Batch 54, Loss: 0.06\n",
      "Training: Epoch 194, Batch 55, Loss: 0.049\n",
      "Training: Epoch 194, Batch 56, Loss: 0.045\n",
      "Training: Epoch 194, Batch 57, Loss: 0.056\n",
      "Training: Epoch 194, Batch 58, Loss: 0.057\n",
      "Training: Epoch 194, Batch 59, Loss: 0.055\n",
      "Val: Epoch 194, Loss: 0.337\n",
      "Training: Epoch 195, Batch 0, Loss: 0.061\n",
      "Training: Epoch 195, Batch 1, Loss: 0.053\n",
      "Training: Epoch 195, Batch 2, Loss: 0.057\n",
      "Training: Epoch 195, Batch 3, Loss: 0.063\n",
      "Training: Epoch 195, Batch 4, Loss: 0.052\n",
      "Training: Epoch 195, Batch 5, Loss: 0.053\n",
      "Training: Epoch 195, Batch 6, Loss: 0.052\n",
      "Training: Epoch 195, Batch 7, Loss: 0.054\n",
      "Training: Epoch 195, Batch 8, Loss: 0.066\n",
      "Training: Epoch 195, Batch 9, Loss: 0.055\n",
      "Training: Epoch 195, Batch 10, Loss: 0.05\n",
      "Training: Epoch 195, Batch 11, Loss: 0.06\n",
      "Training: Epoch 195, Batch 12, Loss: 0.058\n",
      "Training: Epoch 195, Batch 13, Loss: 0.057\n",
      "Training: Epoch 195, Batch 14, Loss: 0.069\n",
      "Training: Epoch 195, Batch 15, Loss: 0.058\n",
      "Training: Epoch 195, Batch 16, Loss: 0.046\n",
      "Training: Epoch 195, Batch 17, Loss: 0.058\n",
      "Training: Epoch 195, Batch 18, Loss: 0.048\n",
      "Training: Epoch 195, Batch 19, Loss: 0.049\n",
      "Training: Epoch 195, Batch 20, Loss: 0.057\n",
      "Training: Epoch 195, Batch 21, Loss: 0.058\n",
      "Training: Epoch 195, Batch 22, Loss: 0.06\n",
      "Training: Epoch 195, Batch 23, Loss: 0.067\n",
      "Training: Epoch 195, Batch 24, Loss: 0.058\n",
      "Training: Epoch 195, Batch 25, Loss: 0.041\n",
      "Training: Epoch 195, Batch 26, Loss: 0.046\n",
      "Training: Epoch 195, Batch 27, Loss: 0.055\n",
      "Training: Epoch 195, Batch 28, Loss: 0.053\n",
      "Training: Epoch 195, Batch 29, Loss: 0.063\n",
      "Training: Epoch 195, Batch 30, Loss: 0.067\n",
      "Training: Epoch 195, Batch 31, Loss: 0.059\n",
      "Training: Epoch 195, Batch 32, Loss: 0.063\n",
      "Training: Epoch 195, Batch 33, Loss: 0.053\n",
      "Training: Epoch 195, Batch 34, Loss: 0.062\n",
      "Training: Epoch 195, Batch 35, Loss: 0.058\n",
      "Training: Epoch 195, Batch 36, Loss: 0.057\n",
      "Training: Epoch 195, Batch 37, Loss: 0.049\n",
      "Training: Epoch 195, Batch 38, Loss: 0.059\n",
      "Training: Epoch 195, Batch 39, Loss: 0.064\n",
      "Training: Epoch 195, Batch 40, Loss: 0.061\n",
      "Training: Epoch 195, Batch 41, Loss: 0.054\n",
      "Training: Epoch 195, Batch 42, Loss: 0.055\n",
      "Training: Epoch 195, Batch 43, Loss: 0.054\n",
      "Training: Epoch 195, Batch 44, Loss: 0.052\n",
      "Training: Epoch 195, Batch 45, Loss: 0.057\n",
      "Training: Epoch 195, Batch 46, Loss: 0.056\n",
      "Training: Epoch 195, Batch 47, Loss: 0.049\n",
      "Training: Epoch 195, Batch 48, Loss: 0.049\n",
      "Training: Epoch 195, Batch 49, Loss: 0.06\n",
      "Training: Epoch 195, Batch 50, Loss: 0.052\n",
      "Training: Epoch 195, Batch 51, Loss: 0.062\n",
      "Training: Epoch 195, Batch 52, Loss: 0.048\n",
      "Training: Epoch 195, Batch 53, Loss: 0.052\n",
      "Training: Epoch 195, Batch 54, Loss: 0.049\n",
      "Training: Epoch 195, Batch 55, Loss: 0.067\n",
      "Training: Epoch 195, Batch 56, Loss: 0.063\n",
      "Training: Epoch 195, Batch 57, Loss: 0.06\n",
      "Training: Epoch 195, Batch 58, Loss: 0.07\n",
      "Training: Epoch 195, Batch 59, Loss: 0.055\n",
      "Val: Epoch 195, Loss: 0.323\n",
      "Training: Epoch 196, Batch 0, Loss: 0.043\n",
      "Training: Epoch 196, Batch 1, Loss: 0.066\n",
      "Training: Epoch 196, Batch 2, Loss: 0.056\n",
      "Training: Epoch 196, Batch 3, Loss: 0.057\n",
      "Training: Epoch 196, Batch 4, Loss: 0.055\n",
      "Training: Epoch 196, Batch 5, Loss: 0.063\n",
      "Training: Epoch 196, Batch 6, Loss: 0.049\n",
      "Training: Epoch 196, Batch 7, Loss: 0.059\n",
      "Training: Epoch 196, Batch 8, Loss: 0.05\n",
      "Training: Epoch 196, Batch 9, Loss: 0.068\n",
      "Training: Epoch 196, Batch 10, Loss: 0.062\n",
      "Training: Epoch 196, Batch 11, Loss: 0.06\n",
      "Training: Epoch 196, Batch 12, Loss: 0.055\n",
      "Training: Epoch 196, Batch 13, Loss: 0.053\n",
      "Training: Epoch 196, Batch 14, Loss: 0.056\n",
      "Training: Epoch 196, Batch 15, Loss: 0.07\n",
      "Training: Epoch 196, Batch 16, Loss: 0.058\n",
      "Training: Epoch 196, Batch 17, Loss: 0.058\n",
      "Training: Epoch 196, Batch 18, Loss: 0.066\n",
      "Training: Epoch 196, Batch 19, Loss: 0.06\n",
      "Training: Epoch 196, Batch 20, Loss: 0.058\n",
      "Training: Epoch 196, Batch 21, Loss: 0.054\n",
      "Training: Epoch 196, Batch 22, Loss: 0.059\n",
      "Training: Epoch 196, Batch 23, Loss: 0.05\n",
      "Training: Epoch 196, Batch 24, Loss: 0.059\n",
      "Training: Epoch 196, Batch 25, Loss: 0.057\n",
      "Training: Epoch 196, Batch 26, Loss: 0.054\n",
      "Training: Epoch 196, Batch 27, Loss: 0.043\n",
      "Training: Epoch 196, Batch 28, Loss: 0.056\n",
      "Training: Epoch 196, Batch 29, Loss: 0.054\n",
      "Training: Epoch 196, Batch 30, Loss: 0.063\n",
      "Training: Epoch 196, Batch 31, Loss: 0.055\n",
      "Training: Epoch 196, Batch 32, Loss: 0.059\n",
      "Training: Epoch 196, Batch 33, Loss: 0.055\n",
      "Training: Epoch 196, Batch 34, Loss: 0.054\n",
      "Training: Epoch 196, Batch 35, Loss: 0.053\n",
      "Training: Epoch 196, Batch 36, Loss: 0.068\n",
      "Training: Epoch 196, Batch 37, Loss: 0.057\n",
      "Training: Epoch 196, Batch 38, Loss: 0.052\n",
      "Training: Epoch 196, Batch 39, Loss: 0.051\n",
      "Training: Epoch 196, Batch 40, Loss: 0.055\n",
      "Training: Epoch 196, Batch 41, Loss: 0.056\n",
      "Training: Epoch 196, Batch 42, Loss: 0.06\n",
      "Training: Epoch 196, Batch 43, Loss: 0.062\n",
      "Training: Epoch 196, Batch 44, Loss: 0.075\n",
      "Training: Epoch 196, Batch 45, Loss: 0.056\n",
      "Training: Epoch 196, Batch 46, Loss: 0.056\n",
      "Training: Epoch 196, Batch 47, Loss: 0.062\n",
      "Training: Epoch 196, Batch 48, Loss: 0.043\n",
      "Training: Epoch 196, Batch 49, Loss: 0.053\n",
      "Training: Epoch 196, Batch 50, Loss: 0.051\n",
      "Training: Epoch 196, Batch 51, Loss: 0.066\n",
      "Training: Epoch 196, Batch 52, Loss: 0.059\n",
      "Training: Epoch 196, Batch 53, Loss: 0.055\n",
      "Training: Epoch 196, Batch 54, Loss: 0.052\n",
      "Training: Epoch 196, Batch 55, Loss: 0.051\n",
      "Training: Epoch 196, Batch 56, Loss: 0.068\n",
      "Training: Epoch 196, Batch 57, Loss: 0.056\n",
      "Training: Epoch 196, Batch 58, Loss: 0.045\n",
      "Training: Epoch 196, Batch 59, Loss: 0.061\n",
      "Val: Epoch 196, Loss: 0.342\n",
      "Training: Epoch 197, Batch 0, Loss: 0.039\n",
      "Training: Epoch 197, Batch 1, Loss: 0.053\n",
      "Training: Epoch 197, Batch 2, Loss: 0.056\n",
      "Training: Epoch 197, Batch 3, Loss: 0.047\n",
      "Training: Epoch 197, Batch 4, Loss: 0.063\n",
      "Training: Epoch 197, Batch 5, Loss: 0.051\n",
      "Training: Epoch 197, Batch 6, Loss: 0.044\n",
      "Training: Epoch 197, Batch 7, Loss: 0.044\n",
      "Training: Epoch 197, Batch 8, Loss: 0.062\n",
      "Training: Epoch 197, Batch 9, Loss: 0.043\n",
      "Training: Epoch 197, Batch 10, Loss: 0.082\n",
      "Training: Epoch 197, Batch 11, Loss: 0.063\n",
      "Training: Epoch 197, Batch 12, Loss: 0.052\n",
      "Training: Epoch 197, Batch 13, Loss: 0.066\n",
      "Training: Epoch 197, Batch 14, Loss: 0.058\n",
      "Training: Epoch 197, Batch 15, Loss: 0.055\n",
      "Training: Epoch 197, Batch 16, Loss: 0.052\n",
      "Training: Epoch 197, Batch 17, Loss: 0.052\n",
      "Training: Epoch 197, Batch 18, Loss: 0.075\n",
      "Training: Epoch 197, Batch 19, Loss: 0.063\n",
      "Training: Epoch 197, Batch 20, Loss: 0.056\n",
      "Training: Epoch 197, Batch 21, Loss: 0.045\n",
      "Training: Epoch 197, Batch 22, Loss: 0.054\n",
      "Training: Epoch 197, Batch 23, Loss: 0.064\n",
      "Training: Epoch 197, Batch 24, Loss: 0.063\n",
      "Training: Epoch 197, Batch 25, Loss: 0.055\n",
      "Training: Epoch 197, Batch 26, Loss: 0.048\n",
      "Training: Epoch 197, Batch 27, Loss: 0.061\n",
      "Training: Epoch 197, Batch 28, Loss: 0.061\n",
      "Training: Epoch 197, Batch 29, Loss: 0.048\n",
      "Training: Epoch 197, Batch 30, Loss: 0.062\n",
      "Training: Epoch 197, Batch 31, Loss: 0.055\n",
      "Training: Epoch 197, Batch 32, Loss: 0.061\n",
      "Training: Epoch 197, Batch 33, Loss: 0.049\n",
      "Training: Epoch 197, Batch 34, Loss: 0.063\n",
      "Training: Epoch 197, Batch 35, Loss: 0.061\n",
      "Training: Epoch 197, Batch 36, Loss: 0.047\n",
      "Training: Epoch 197, Batch 37, Loss: 0.055\n",
      "Training: Epoch 197, Batch 38, Loss: 0.059\n",
      "Training: Epoch 197, Batch 39, Loss: 0.05\n",
      "Training: Epoch 197, Batch 40, Loss: 0.073\n",
      "Training: Epoch 197, Batch 41, Loss: 0.049\n",
      "Training: Epoch 197, Batch 42, Loss: 0.05\n",
      "Training: Epoch 197, Batch 43, Loss: 0.064\n",
      "Training: Epoch 197, Batch 44, Loss: 0.05\n",
      "Training: Epoch 197, Batch 45, Loss: 0.05\n",
      "Training: Epoch 197, Batch 46, Loss: 0.077\n",
      "Training: Epoch 197, Batch 47, Loss: 0.052\n",
      "Training: Epoch 197, Batch 48, Loss: 0.062\n",
      "Training: Epoch 197, Batch 49, Loss: 0.056\n",
      "Training: Epoch 197, Batch 50, Loss: 0.068\n",
      "Training: Epoch 197, Batch 51, Loss: 0.06\n",
      "Training: Epoch 197, Batch 52, Loss: 0.054\n",
      "Training: Epoch 197, Batch 53, Loss: 0.052\n",
      "Training: Epoch 197, Batch 54, Loss: 0.07\n",
      "Training: Epoch 197, Batch 55, Loss: 0.065\n",
      "Training: Epoch 197, Batch 56, Loss: 0.064\n",
      "Training: Epoch 197, Batch 57, Loss: 0.064\n",
      "Training: Epoch 197, Batch 58, Loss: 0.063\n",
      "Training: Epoch 197, Batch 59, Loss: 0.055\n",
      "Val: Epoch 197, Loss: 0.317\n",
      "Training: Epoch 198, Batch 0, Loss: 0.066\n",
      "Training: Epoch 198, Batch 1, Loss: 0.064\n",
      "Training: Epoch 198, Batch 2, Loss: 0.043\n",
      "Training: Epoch 198, Batch 3, Loss: 0.063\n",
      "Training: Epoch 198, Batch 4, Loss: 0.05\n",
      "Training: Epoch 198, Batch 5, Loss: 0.072\n",
      "Training: Epoch 198, Batch 6, Loss: 0.054\n",
      "Training: Epoch 198, Batch 7, Loss: 0.06\n",
      "Training: Epoch 198, Batch 8, Loss: 0.06\n",
      "Training: Epoch 198, Batch 9, Loss: 0.059\n",
      "Training: Epoch 198, Batch 10, Loss: 0.06\n",
      "Training: Epoch 198, Batch 11, Loss: 0.056\n",
      "Training: Epoch 198, Batch 12, Loss: 0.052\n",
      "Training: Epoch 198, Batch 13, Loss: 0.055\n",
      "Training: Epoch 198, Batch 14, Loss: 0.057\n",
      "Training: Epoch 198, Batch 15, Loss: 0.058\n",
      "Training: Epoch 198, Batch 16, Loss: 0.071\n",
      "Training: Epoch 198, Batch 17, Loss: 0.058\n",
      "Training: Epoch 198, Batch 18, Loss: 0.067\n",
      "Training: Epoch 198, Batch 19, Loss: 0.038\n",
      "Training: Epoch 198, Batch 20, Loss: 0.063\n",
      "Training: Epoch 198, Batch 21, Loss: 0.046\n",
      "Training: Epoch 198, Batch 22, Loss: 0.058\n",
      "Training: Epoch 198, Batch 23, Loss: 0.063\n",
      "Training: Epoch 198, Batch 24, Loss: 0.044\n",
      "Training: Epoch 198, Batch 25, Loss: 0.053\n",
      "Training: Epoch 198, Batch 26, Loss: 0.04\n",
      "Training: Epoch 198, Batch 27, Loss: 0.063\n",
      "Training: Epoch 198, Batch 28, Loss: 0.045\n",
      "Training: Epoch 198, Batch 29, Loss: 0.045\n",
      "Training: Epoch 198, Batch 30, Loss: 0.059\n",
      "Training: Epoch 198, Batch 31, Loss: 0.067\n",
      "Training: Epoch 198, Batch 32, Loss: 0.064\n",
      "Training: Epoch 198, Batch 33, Loss: 0.06\n",
      "Training: Epoch 198, Batch 34, Loss: 0.042\n",
      "Training: Epoch 198, Batch 35, Loss: 0.059\n",
      "Training: Epoch 198, Batch 36, Loss: 0.07\n",
      "Training: Epoch 198, Batch 37, Loss: 0.059\n",
      "Training: Epoch 198, Batch 38, Loss: 0.054\n",
      "Training: Epoch 198, Batch 39, Loss: 0.058\n",
      "Training: Epoch 198, Batch 40, Loss: 0.056\n",
      "Training: Epoch 198, Batch 41, Loss: 0.053\n",
      "Training: Epoch 198, Batch 42, Loss: 0.051\n",
      "Training: Epoch 198, Batch 43, Loss: 0.047\n",
      "Training: Epoch 198, Batch 44, Loss: 0.047\n",
      "Training: Epoch 198, Batch 45, Loss: 0.056\n",
      "Training: Epoch 198, Batch 46, Loss: 0.052\n",
      "Training: Epoch 198, Batch 47, Loss: 0.055\n",
      "Training: Epoch 198, Batch 48, Loss: 0.064\n",
      "Training: Epoch 198, Batch 49, Loss: 0.05\n",
      "Training: Epoch 198, Batch 50, Loss: 0.06\n",
      "Training: Epoch 198, Batch 51, Loss: 0.05\n",
      "Training: Epoch 198, Batch 52, Loss: 0.051\n",
      "Training: Epoch 198, Batch 53, Loss: 0.054\n",
      "Training: Epoch 198, Batch 54, Loss: 0.056\n",
      "Training: Epoch 198, Batch 55, Loss: 0.056\n",
      "Training: Epoch 198, Batch 56, Loss: 0.05\n",
      "Training: Epoch 198, Batch 57, Loss: 0.066\n",
      "Training: Epoch 198, Batch 58, Loss: 0.061\n",
      "Training: Epoch 198, Batch 59, Loss: 0.051\n",
      "Val: Epoch 198, Loss: 0.335\n",
      "Training: Epoch 199, Batch 0, Loss: 0.052\n",
      "Training: Epoch 199, Batch 1, Loss: 0.046\n",
      "Training: Epoch 199, Batch 2, Loss: 0.057\n",
      "Training: Epoch 199, Batch 3, Loss: 0.054\n",
      "Training: Epoch 199, Batch 4, Loss: 0.059\n",
      "Training: Epoch 199, Batch 5, Loss: 0.065\n",
      "Training: Epoch 199, Batch 6, Loss: 0.06\n",
      "Training: Epoch 199, Batch 7, Loss: 0.047\n",
      "Training: Epoch 199, Batch 8, Loss: 0.047\n",
      "Training: Epoch 199, Batch 9, Loss: 0.049\n",
      "Training: Epoch 199, Batch 10, Loss: 0.056\n",
      "Training: Epoch 199, Batch 11, Loss: 0.058\n",
      "Training: Epoch 199, Batch 12, Loss: 0.062\n",
      "Training: Epoch 199, Batch 13, Loss: 0.061\n",
      "Training: Epoch 199, Batch 14, Loss: 0.055\n",
      "Training: Epoch 199, Batch 15, Loss: 0.055\n",
      "Training: Epoch 199, Batch 16, Loss: 0.054\n",
      "Training: Epoch 199, Batch 17, Loss: 0.056\n",
      "Training: Epoch 199, Batch 18, Loss: 0.056\n",
      "Training: Epoch 199, Batch 19, Loss: 0.047\n",
      "Training: Epoch 199, Batch 20, Loss: 0.059\n",
      "Training: Epoch 199, Batch 21, Loss: 0.06\n",
      "Training: Epoch 199, Batch 22, Loss: 0.06\n",
      "Training: Epoch 199, Batch 23, Loss: 0.042\n",
      "Training: Epoch 199, Batch 24, Loss: 0.067\n",
      "Training: Epoch 199, Batch 25, Loss: 0.047\n",
      "Training: Epoch 199, Batch 26, Loss: 0.055\n",
      "Training: Epoch 199, Batch 27, Loss: 0.048\n",
      "Training: Epoch 199, Batch 28, Loss: 0.066\n",
      "Training: Epoch 199, Batch 29, Loss: 0.045\n",
      "Training: Epoch 199, Batch 30, Loss: 0.049\n",
      "Training: Epoch 199, Batch 31, Loss: 0.066\n",
      "Training: Epoch 199, Batch 32, Loss: 0.059\n",
      "Training: Epoch 199, Batch 33, Loss: 0.052\n",
      "Training: Epoch 199, Batch 34, Loss: 0.049\n",
      "Training: Epoch 199, Batch 35, Loss: 0.049\n",
      "Training: Epoch 199, Batch 36, Loss: 0.051\n",
      "Training: Epoch 199, Batch 37, Loss: 0.058\n",
      "Training: Epoch 199, Batch 38, Loss: 0.058\n",
      "Training: Epoch 199, Batch 39, Loss: 0.056\n",
      "Training: Epoch 199, Batch 40, Loss: 0.048\n",
      "Training: Epoch 199, Batch 41, Loss: 0.049\n",
      "Training: Epoch 199, Batch 42, Loss: 0.048\n",
      "Training: Epoch 199, Batch 43, Loss: 0.054\n",
      "Training: Epoch 199, Batch 44, Loss: 0.064\n",
      "Training: Epoch 199, Batch 45, Loss: 0.046\n",
      "Training: Epoch 199, Batch 46, Loss: 0.047\n",
      "Training: Epoch 199, Batch 47, Loss: 0.053\n",
      "Training: Epoch 199, Batch 48, Loss: 0.057\n",
      "Training: Epoch 199, Batch 49, Loss: 0.058\n",
      "Training: Epoch 199, Batch 50, Loss: 0.065\n",
      "Training: Epoch 199, Batch 51, Loss: 0.053\n",
      "Training: Epoch 199, Batch 52, Loss: 0.054\n",
      "Training: Epoch 199, Batch 53, Loss: 0.06\n",
      "Training: Epoch 199, Batch 54, Loss: 0.07\n",
      "Training: Epoch 199, Batch 55, Loss: 0.064\n",
      "Training: Epoch 199, Batch 56, Loss: 0.053\n",
      "Training: Epoch 199, Batch 57, Loss: 0.061\n",
      "Training: Epoch 199, Batch 58, Loss: 0.054\n",
      "Training: Epoch 199, Batch 59, Loss: 0.066\n",
      "Val: Epoch 199, Loss: 0.339\n",
      "Training: Epoch 200, Batch 0, Loss: 0.045\n",
      "Training: Epoch 200, Batch 1, Loss: 0.064\n",
      "Training: Epoch 200, Batch 2, Loss: 0.057\n",
      "Training: Epoch 200, Batch 3, Loss: 0.048\n",
      "Training: Epoch 200, Batch 4, Loss: 0.059\n",
      "Training: Epoch 200, Batch 5, Loss: 0.056\n",
      "Training: Epoch 200, Batch 6, Loss: 0.057\n",
      "Training: Epoch 200, Batch 7, Loss: 0.066\n",
      "Training: Epoch 200, Batch 8, Loss: 0.053\n",
      "Training: Epoch 200, Batch 9, Loss: 0.05\n",
      "Training: Epoch 200, Batch 10, Loss: 0.047\n",
      "Training: Epoch 200, Batch 11, Loss: 0.056\n",
      "Training: Epoch 200, Batch 12, Loss: 0.056\n",
      "Training: Epoch 200, Batch 13, Loss: 0.062\n",
      "Training: Epoch 200, Batch 14, Loss: 0.052\n",
      "Training: Epoch 200, Batch 15, Loss: 0.058\n",
      "Training: Epoch 200, Batch 16, Loss: 0.061\n",
      "Training: Epoch 200, Batch 17, Loss: 0.058\n",
      "Training: Epoch 200, Batch 18, Loss: 0.052\n",
      "Training: Epoch 200, Batch 19, Loss: 0.056\n",
      "Training: Epoch 200, Batch 20, Loss: 0.063\n",
      "Training: Epoch 200, Batch 21, Loss: 0.074\n",
      "Training: Epoch 200, Batch 22, Loss: 0.064\n",
      "Training: Epoch 200, Batch 23, Loss: 0.057\n",
      "Training: Epoch 200, Batch 24, Loss: 0.055\n",
      "Training: Epoch 200, Batch 25, Loss: 0.058\n",
      "Training: Epoch 200, Batch 26, Loss: 0.047\n",
      "Training: Epoch 200, Batch 27, Loss: 0.043\n",
      "Training: Epoch 200, Batch 28, Loss: 0.063\n",
      "Training: Epoch 200, Batch 29, Loss: 0.052\n",
      "Training: Epoch 200, Batch 30, Loss: 0.056\n",
      "Training: Epoch 200, Batch 31, Loss: 0.054\n",
      "Training: Epoch 200, Batch 32, Loss: 0.045\n",
      "Training: Epoch 200, Batch 33, Loss: 0.052\n",
      "Training: Epoch 200, Batch 34, Loss: 0.075\n",
      "Training: Epoch 200, Batch 35, Loss: 0.06\n",
      "Training: Epoch 200, Batch 36, Loss: 0.06\n",
      "Training: Epoch 200, Batch 37, Loss: 0.069\n",
      "Training: Epoch 200, Batch 38, Loss: 0.052\n",
      "Training: Epoch 200, Batch 39, Loss: 0.064\n",
      "Training: Epoch 200, Batch 40, Loss: 0.061\n",
      "Training: Epoch 200, Batch 41, Loss: 0.06\n",
      "Training: Epoch 200, Batch 42, Loss: 0.062\n",
      "Training: Epoch 200, Batch 43, Loss: 0.06\n",
      "Training: Epoch 200, Batch 44, Loss: 0.048\n",
      "Training: Epoch 200, Batch 45, Loss: 0.058\n",
      "Training: Epoch 200, Batch 46, Loss: 0.041\n",
      "Training: Epoch 200, Batch 47, Loss: 0.057\n",
      "Training: Epoch 200, Batch 48, Loss: 0.061\n",
      "Training: Epoch 200, Batch 49, Loss: 0.054\n",
      "Training: Epoch 200, Batch 50, Loss: 0.053\n",
      "Training: Epoch 200, Batch 51, Loss: 0.061\n",
      "Training: Epoch 200, Batch 52, Loss: 0.061\n",
      "Training: Epoch 200, Batch 53, Loss: 0.056\n",
      "Training: Epoch 200, Batch 54, Loss: 0.064\n",
      "Training: Epoch 200, Batch 55, Loss: 0.066\n",
      "Training: Epoch 200, Batch 56, Loss: 0.062\n",
      "Training: Epoch 200, Batch 57, Loss: 0.06\n",
      "Training: Epoch 200, Batch 58, Loss: 0.056\n",
      "Training: Epoch 200, Batch 59, Loss: 0.063\n",
      "Val: Epoch 200, Loss: 0.331\n",
      "Best model found at epoch 61\n",
      "Total training time: 3588.2250792980194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[-1],map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_model.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97    937035\n",
      "           1       0.93      0.88      0.91   1187442\n",
      "           2       0.80      0.92      0.86    496963\n",
      "\n",
      "    accuracy                           0.92   2621440\n",
      "   macro avg       0.90      0.92      0.91   2621440\n",
      "weighted avg       0.92      0.92      0.92   2621440\n",
      "\n",
      "Training loss: 0.19000841081142425\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "from semseg_functions import train_model_transunet, make_predictions_transunet, train_model_transunet_sweep\n",
    "importlib.reload(sys.modules[\"semseg_functions\"])\n",
    "from semseg_functions import train_model_transunet, make_predictions_transunet, train_model_transunet_sweep\n",
    "from augment_train import augment_train\n",
    "importlib.reload(sys.modules[\"augment_train\"])\n",
    "from augment_train import augment_train\n",
    "from transunet import TransUNet\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#model = TransUNet()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "X_train_aug, Y_train_aug = augment_train(X_train, Y_train, augment_times=2)\n",
    "\n",
    "print(\"X_train_aug shape:\", X_train_aug.shape)\n",
    "print(\"Y_train_aug shape:\", Y_train_aug.shape)\n",
    "\n",
    "#X_train,Y_train,X_val,Y_val=load_imgs_labels()\n",
    "#model=train_model_transunet(X_train,Y_train,X_val,Y_val)\n",
    "start_time = time.time()\n",
    "model, best_model_loss=train_model_transunet(X_train_aug,Y_train_aug,X_val,Y_val, lr= 0.003, momentum= 0.9, weight_decay= 0.01)\n",
    "end_time = time.time()\n",
    "print(\"Total training time:\", end_time-start_time)\n",
    "y_val_pred=make_predictions_transunet(X_val,model=None)\n",
    "y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "#print loss\n",
    "print(\"Training loss:\", best_model_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abfb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9876867799988194\n"
     ]
    }
   ],
   "source": [
    "# Flatten prediction: shape (B, C, H, W) to (N, C)\n",
    "y_val_pred_flat = y_val_pred.transpose(0, 2, 3, 1).reshape(-1, y_val_pred.shape[1])\n",
    "\n",
    "# Flatten true labels: shape (B, H, W) to (N,)\n",
    "y_true = Y_val.numpy().flatten()\n",
    "\n",
    "# Binarize true labels for multiclass AUROC\n",
    "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(y_true_binarized, y_val_pred_flat, multi_class='ovr')\n",
    "\n",
    "print(\"AUROC:\", auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e59ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor lr in grid[\"lr\"]:\\n    for momentum in grid[\"momentum\"]:\\n        for weight_decay in grid[\"weight_decay\"]:\\n            print(f\"lr: {lr}, momentum: {momentum}, weight_decay: {weight_decay}\")\\n            model=train_model_transunet_sweep(X_train_aug,Y_train_aug,X_val,Y_val, lr=lr, momentum=momentum, weight_decay=weight_decay)\\n            #y_val_pred=make_predictions_transunet_sweep(X_val,model=None)\\n            #y_val_pred_lbls=y_val_pred.argmax(1)\\n            #print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\\nHyper parameter tuning'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid = {\n",
    "    \"lr\": [1e-3, 1e-2, 1e-1],\n",
    "    \"momentum\": [0.9, 0.99],\n",
    "    \"weight_decay\": [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\"\"\"\n",
    "for lr in grid[\"lr\"]:\n",
    "    for momentum in grid[\"momentum\"]:\n",
    "        for weight_decay in grid[\"weight_decay\"]:\n",
    "            print(f\"lr: {lr}, momentum: {momentum}, weight_decay: {weight_decay}\")\n",
    "            model=train_model_transunet_sweep(X_train_aug,Y_train_aug,X_val,Y_val, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "            #y_val_pred=make_predictions_transunet_sweep(X_val,model=None)\n",
    "            #y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "            #print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "Hyper parameter tuning\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c690010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001, momentum: 0.9, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.9_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96    937035\n",
      "           1       0.95      0.83      0.88   1187442\n",
      "           2       0.75      0.94      0.83    496963\n",
      "\n",
      "    accuracy                           0.90   2621440\n",
      "   macro avg       0.88      0.91      0.89   2621440\n",
      "weighted avg       0.91      0.90      0.90   2621440\n",
      "\n",
      "lr: 0.001, momentum: 0.9, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.9_wd0.001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96    937035\n",
      "           1       0.93      0.86      0.90   1187442\n",
      "           2       0.79      0.92      0.85    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.89      0.91      0.90   2621440\n",
      "weighted avg       0.91      0.91      0.91   2621440\n",
      "\n",
      "lr: 0.001, momentum: 0.9, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.9_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96    937035\n",
      "           1       0.93      0.86      0.89   1187442\n",
      "           2       0.77      0.92      0.84    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.89      0.91      0.90   2621440\n",
      "weighted avg       0.91      0.91      0.91   2621440\n",
      "\n",
      "lr: 0.001, momentum: 0.99, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.99_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96    937035\n",
      "           1       0.93      0.86      0.90   1187442\n",
      "           2       0.77      0.92      0.84    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.89      0.91      0.90   2621440\n",
      "weighted avg       0.91      0.91      0.91   2621440\n",
      "\n",
      "lr: 0.001, momentum: 0.99, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.99_wd0.001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96    937035\n",
      "           1       0.94      0.83      0.88   1187442\n",
      "           2       0.73      0.95      0.83    496963\n",
      "\n",
      "    accuracy                           0.90   2621440\n",
      "   macro avg       0.88      0.91      0.89   2621440\n",
      "weighted avg       0.91      0.90      0.90   2621440\n",
      "\n",
      "lr: 0.001, momentum: 0.99, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.001_mom0.99_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96    937035\n",
      "           1       0.94      0.85      0.89   1187442\n",
      "           2       0.76      0.95      0.84    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.89      0.92      0.90   2621440\n",
      "weighted avg       0.92      0.91      0.91   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.9, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.9_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97    937035\n",
      "           1       0.91      0.82      0.86   1187442\n",
      "           2       0.71      0.87      0.78    496963\n",
      "\n",
      "    accuracy                           0.88   2621440\n",
      "   macro avg       0.86      0.89      0.87   2621440\n",
      "weighted avg       0.89      0.88      0.89   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.9, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.9_wd0.001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96    937035\n",
      "           1       0.89      0.87      0.88   1187442\n",
      "           2       0.75      0.81      0.78    496963\n",
      "\n",
      "    accuracy                           0.89   2621440\n",
      "   macro avg       0.87      0.88      0.87   2621440\n",
      "weighted avg       0.89      0.89      0.89   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.9, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.9_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    937035\n",
      "           1       0.91      0.89      0.90   1187442\n",
      "           2       0.81      0.84      0.82    496963\n",
      "\n",
      "    accuracy                           0.91   2621440\n",
      "   macro avg       0.89      0.90      0.90   2621440\n",
      "weighted avg       0.91      0.91      0.91   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.99, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.99_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97    937035\n",
      "           1       0.90      0.83      0.86   1187442\n",
      "           2       0.71      0.84      0.77    496963\n",
      "\n",
      "    accuracy                           0.88   2621440\n",
      "   macro avg       0.86      0.88      0.87   2621440\n",
      "weighted avg       0.89      0.88      0.88   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.99, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.99_wd0.001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97    937035\n",
      "           1       0.89      0.87      0.88   1187442\n",
      "           2       0.77      0.84      0.80    496963\n",
      "\n",
      "    accuracy                           0.90   2621440\n",
      "   macro avg       0.88      0.89      0.88   2621440\n",
      "weighted avg       0.90      0.90      0.90   2621440\n",
      "\n",
      "lr: 0.01, momentum: 0.99, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.01_mom0.99_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96    937035\n",
      "           1       0.91      0.81      0.86   1187442\n",
      "           2       0.71      0.88      0.78    496963\n",
      "\n",
      "    accuracy                           0.88   2621440\n",
      "   macro avg       0.86      0.88      0.87   2621440\n",
      "weighted avg       0.89      0.88      0.88   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.9, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.9_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95    937035\n",
      "           1       0.91      0.61      0.73   1187442\n",
      "           2       0.54      0.97      0.69    496963\n",
      "\n",
      "    accuracy                           0.80   2621440\n",
      "   macro avg       0.80      0.84      0.79   2621440\n",
      "weighted avg       0.86      0.80      0.80   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.9, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.9_wd0.001.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    937035\n",
      "           1       0.45      1.00      0.62   1187442\n",
      "           2       0.00      0.00      0.00    496963\n",
      "\n",
      "    accuracy                           0.45   2621440\n",
      "   macro avg       0.15      0.33      0.21   2621440\n",
      "weighted avg       0.21      0.45      0.28   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.9, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.9_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95    937035\n",
      "           1       0.86      0.84      0.85   1187442\n",
      "           2       0.72      0.80      0.76    496963\n",
      "\n",
      "    accuracy                           0.87   2621440\n",
      "   macro avg       0.85      0.86      0.85   2621440\n",
      "weighted avg       0.87      0.87      0.87   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.99, weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.99_wd0.0001.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83    937035\n",
      "           1       0.91      0.49      0.64   1187442\n",
      "           2       0.66      0.90      0.76    496963\n",
      "\n",
      "    accuracy                           0.75   2621440\n",
      "   macro avg       0.76      0.79      0.74   2621440\n",
      "weighted avg       0.79      0.75      0.73   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.99, weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.99_wd0.001.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    937035\n",
      "           1       0.45      1.00      0.62   1187442\n",
      "           2       0.00      0.00      0.00    496963\n",
      "\n",
      "    accuracy                           0.45   2621440\n",
      "   macro avg       0.15      0.33      0.21   2621440\n",
      "weighted avg       0.21      0.45      0.28   2621440\n",
      "\n",
      "lr: 0.1, momentum: 0.99, weight_decay: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path,map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_lr0.1_mom0.99_wd0.01.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87    937035\n",
      "           1       0.78      0.79      0.78   1187442\n",
      "           2       0.64      0.91      0.75    496963\n",
      "\n",
      "    accuracy                           0.80   2621440\n",
      "   macro avg       0.81      0.82      0.80   2621440\n",
      "weighted avg       0.83      0.80      0.81   2621440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sys.modules[\"semseg_functions\"])\n",
    "from semseg_functions import make_predictions_transunet_sweep\n",
    "for lr in grid[\"lr\"]:\n",
    "    for momentum in grid[\"momentum\"]:\n",
    "        for weight_decay in grid[\"weight_decay\"]:\n",
    "            print(f\"lr: {lr}, momentum: {momentum}, weight_decay: {weight_decay}\")\n",
    "            #model=train_model_transunet_sweep(X_train_aug,Y_train_aug,X_val,Y_val, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "            y_val_pred=make_predictions_transunet_sweep(X_val, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "            y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "            print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ddac527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d04364c80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQ0AAATmCAYAAACLcIdsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAC4jAAAuIwF4pT92AAB38ElEQVR4nOzdCZTWddk38B/IpmCAuKOiMhVimqYGYm4hluZCFqJmr7icR7LnfXU01zIl7Zi5zFPPE+FulilqpqaWO2rauNsiaA2IBKLgmuwqvOd/n4dprptZ7nuYmfueuT+fc+bY7z//5TcsM/Q91/+6uq1atWpVAgAAAAD4X91X/w8AAAAAgIzQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAICgR1zSUWbOnJmefvrpNHfu3LRixYo0cODANGzYsDRq1KjUp0+fUm8PAAAAgAomNOxgd9xxR7rgggvS888/3+jn+/XrlyZMmJDOO++8tOGGG3b4/gAAAACg26pVq1aVehOVYPny5en4449PN954Y0Hnb7TRRum2225Le+21V7vvDQAAAAAaEhp2gJUrV6bDDjss3XnnneH4Ouusk7baaqvUv3//9Oqrr6b3338/fH699dZLDz74YNp99907eMcAAAAAVDKDUDrAJZdcskZgOHHixDRnzpw0a9as9MILL6R33nkn3X777bkQcbUlS5akww8/fI0wEQAAAADak0rDdvb222+nbbbZJn3wwQf1xy666KJ01llnNXr+vHnz0he+8IU0e/bs+mPf//7306RJkzpkvwAAAAAgNGxnZ555Zvrxj39cv856FE6bNi1169atyWseeuihtN9++9Wv119//dzry4MGDWr3/QIAAACA15PbuZfhddddF46df/75zQaGmdGjR6c999yzfp1VKd5yyy3ttk8AAAAAaEho2I6efPLJtHDhwvr1tttum/bZZ5+Crs0mLTd0xx13tPn+AAAAAKAxQsN2dM8994T1mDFjWqwybHhuQ9krzYsXL27T/QEAAABAY4SG7ejFF18M61GjRhV87eabb5623nrr+vWKFSvS9OnT23R/AAAAANCYHo0epU3MmDEjrIcPH17U9dn5DacoZ/fbbbfdUkd777330qOPPlq/3nLLLVPv3r07fB8AAAAAncXy5cvTP//5z/r13nvvnQYMGJA6C6FhO1m6dGmaM2dOOJaFbcXIP/+VV15JpZAFhmPHji3JswEAAAC6gjvuuCMdeuihqbMQGraTt956K61atap+3bNnz7TxxhsXdY/BgweH9YIFC9Z6X9k9Gg5nKUR++AkAAABA1yY0bCeLFi0K6/XWW6/gISir9e3bt9l7tsbkyZPTpEmT1vo+AAAAAHRdQsN2kh/w9enTp+h7rLvuus3es1R2TLun9VK/Um8DAABgDXPO/GyHPGeri//cIc8BOq8laVH6S/pTq9vWlZrQsJ0sW7YsrHv16lX0PfKHjWR9EstBFhj269a/1NsAAABYQ6/NNu2Q5/Tr9u+hlQCN+nfXupzONlRWaNhO8isLV6xY0aopO83dszVOOumkNG7cuKKuqaurMwgFAAAAoIIIDdtJv379mq08LER+ZWH+PVsjG8ZS7EAWAAAAACpL91JvoKvKD/iWLFkSpikXYvHixc3eEwAAAADag9CwnWy44YZhWvKHH36YFixYUNQ95s2bF9YqBAEAAADoCELDdpJNPt5qq63CsTlz5hR1j/zzhw0b1iZ7AwAAAIDmCA3bUX7IN3369KKunzFjRrP3AwAAAID2IDRsRzvttFNYP/nkkwVfO3/+/DR79uz6dc+ePdPw4cPbdH8AAAAA0BihYTs66KCDwvrBBx8seBjK/fffH9b77ruvQSgAAAAAdAihYTsaNWpUbiDKarNmzUrTpk0r6NprrrkmrA899NA23x8AAAAANKZHqTfQlXXv3j1NmDAhXXrppfXHJk2alPbZZ58wWTnfQw89lB5//PH69frrr58OP/zwdt8vAABAZ1NXM7Jsn1tVXdshewFoDyoN29mZZ54ZXit+9NFH08UXX9zk+fPmzUsnnHBCOHbyySeHikUAAAAAaE9Cw3aWhX3nnHNOOHb22Wenk046Kb3++uv1x1auXJnuuOOO3CvNDQegbL755um0007r0D0DAAAAUNmEhh1UbZg/FOXnP/952mqrrdLQoUPT5z73uTRo0KD01a9+Nc2ZM6f+nHXXXTfdcsstacCAASXYNQAAAACVSk/DDupteOutt6Zjjz023XzzzfXHP/7449xwlMZkIeJtt92W9thjjw7cKQAA0Jn66pWT1vTv6+q/bl3t69OjESqLSsMO0qdPn3TTTTflgsCddtqpyfP69u2be3V5+vTpuYEpAAAAANDRVBp2sK997Wu5j7q6uvTUU0/lBp+sWLEi9wrydtttl6sszAJGAAAAACgVoWGJVFVV5T4AAAAAoNx4PRkAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAwPRkAAAAoEV1NSPDuqq6tmR7AdqfSkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAAQ94hIAAACKV1czMqyrqmub/TwA5U2lIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEDQIy4BAABoqK5mZKm30Cn5dev62ur3uKq6tk3uA7QtlYYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAh6xCUAAEBlq6sZWeotAEDJqTQEAAAAAAKhIQAAAAAQCA0BAAAAgEBPQwAAoGLoVwgAhVFpCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACAxCAQAAAMpmQFFVdW3J9gL8m0pDAAAAACAQGgIAAAAAgdAQAAAAAAj0NAQAAADKtsdhKemvSCVTaQgAAAAABEJDAAAAACAQGgIAAAAAgZ6GAAAAZWDm+ClrfY+hUye2yV66Gr+2AMVTaQgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAgMQgEAACpGVXVtWNfVjCybQRvttY9KG+DRXr8X+fettF9XoPKoNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIesQlAABA11VXM7Loa2aOn5I6s/z9D506MXUlnf33B6BcqTQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEBqEAAABUkM40GMWQE8pteFJVdW3J9gIdTaUhAAAAABAIDQEAAACAQGgIAAAAAAR6GgIAAF2y9xidjx6GdMXvM/og0lmpNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DAAAASkIPQ4DypdIQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQGIQCAAB0CnU1I8O6qrq2ZHsBgK5OpSEAAAAAEAgNAQAAAIBAaAgAAAAABHoaAgAAXaLHIa0zc/yUFs8ZOnVih+wFgPKh0hAAAAAACISGAAAAAEAgNAQAAAAAAj0NAQAAKIveiVAJ/VerqmtLthcohkpDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAYBAKAABUSPP9clbOgwGGTp2YKn2gR/7XnP9rAnSO783l/L2W8qPSEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACDoEZcAAEBnVFczstRbgGDm+Cml3gLQws+Kquraku2F8qfSEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEBiEAgAAQFEMOYGuwWAUmqPSEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQ9IhLAACAjldXM7LUW2jSzPFTSr0FAOhwKg0BAAAAgEBoCAAAAAAEQkMAAAAAINDTEAAASqyc+/lVIj0MaczQqRNLvQWADqXSEAAAAAAIhIYAAAAAQCA0BAAAAAACPQ0BAICKoV8hABRGpSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAwCAUAAOgSDDmhLQ2dOrHUWwAoKZWGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAICgR6k3AAAAlaauZmSpt9AlzBw/pdRboIsYOnViqbcAUHZUGgIAAAAAgdAQAAAAAAiEhgAAAABAoKchAABlRb8/AOjcP4Orqmvb5D6UlkpDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEPeISAAAAAFqvrmZkWFdV15ZsL7SeSkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQNAjLgEAoHB1NSNLvQUAoAL+vVBVXdsme6FwKg0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAg6FHqDVSaZcuWpSeffDK9/PLL6d133029evVKW2yxRRoxYkTadtttS709AAAAAKjM0PD8889PkyZNavX1xxxzTLr++uuLumbhwoW5Z2bXLV68uNFzdtlll3TuueemQw89tNV7AwAAAIC15fXkDjBt2rQ0fPjw9LOf/azJwDDz3HPPpbFjx+ZCyRUrVnToHgEAAACgoisNO9If//jHdOCBB6alS5eG4wMGDEjbbLNN7hXlf/7zn+njjz+u/9wNN9yQFi1alG677bbUrVu3EuwaAAAAgEomNEwpXXrppemzn/1swedvvvnmBZ2XBYLjx48PgeGQIUPST37yk3TIIYfUB4Jz585NF154Ybriiivqz7v99ttTTU1NOvXUU4v6WgAAAABgbQkN/7eX4D777NPm973kkkvS66+/Xr/OKguzysP80DEbhDJlypS01VZbpe9+97v1x3/wgx+kY489Ng0cOLDN9wYAAJ3d0KkTw3rm+Ckl2wudW2N/dvL/fAFUGj0N20k2+OS///u/w7Grrrqq2SrFs88+O+2111716/fffz9XBQkAAAAAHUlo2E5uvvnmXF/C1bIwcPTo0c1ek72ufN5554Vj1157bVq1alW77RMAAAAA8gkN28mdd94Z1scff3xB1+27776515hXe+ONN1JtbW2b7w8AAAAAmiI0bAdZheFjjz0Wju2///4FXZtVG+63337h2N13392m+wMAAACA5ggN28FLL72UPvzww/p1Vjm46aabFnz9HnvsEdYvvvhim+4PAAAAAJpjevL/Wr58eZo1a1Z6++23U8+ePdOgQYNyQ0vWW2+9ou81Y8aMsB4+fHhR1+efn38/AAAAAGhPQsOU0re//e1cYLhs2bJwvEePHmmXXXZJBxxwQDrppJPSRhttVND9XnnllbDecssti9pP/vmvvfZabm99+vQp6j4AAAAA0BpeT04pTZ8+fY3AMPPRRx+lp556Kp1//vlpyJAh6fvf/376+OOPW7zfggULwnqLLbYoaj+bbLJJLrBcbeXKlbkKSAAAAADoCCoNC7R06dJ0wQUXpMcffzz97ne/S/369Wt2EEpDffv2LepZ2TCUddddN33wwQdN3rO1skBz4cKFRV1TV1fXJs8GAID2NHTqxBbPmTl+Sofshc4v/89KIX++ALqSig0Ns2Bu9913T1/5ylfS5z//+bTddtulDTbYIHXv3j1X1ff888/nphb/4he/CFWI06ZNS0cccUS688470zrrrNPovfMDvta8VtxeoeHkyZPTpEmT2uReAAAAAHRNFfl68v77759efvnl9MQTT6Rzzjkn7bfffmnw4MG5oK537965ASgHHXRQmjJlSvrHP/6xxjTje+65Jxe+NSX/VedevXoVvcdsH/mVjgAAAADQESoyNBw1alT61Kc+VdC5WT/CBx98MFeV2NCFF16YlixZ0ug1+ZWFK1asaNU05+buCQAAAADtpWJfTy5GFtjdcMMNuVeYs+Eoq3sD3n///Wns2LFrnJ/f77CxISstya8sbK6HYjGyKdDjxo0ruqdhY18nAAB0Nvl96fQ4pFB6HAKVRmhYoKqqqnTIIYek22+/vf5YoaHh4sWLi3rWqlWr2i003HjjjXMfAAAAANCUinw9ubVGjx4d1q+88kqj5+WHcnPnzi3qOW+++WZ9RWMmG86y4YYbFnUPAAAAAGgtoWERttxyy7BeuHBho+d9+tOfDus5c+YU9Zz884cMGaKnIQAAAAAdxuvJRejZs2dYf/jhh42eN2zYsLCePn16Uc+ZMWNGs/cDAADaRmN96fQ5BACVhkV54403wnqjjTZq9Lztt98+BIyzZ89O8+fPL/g5TzzxRFjvtNNORe8VAAAAAFpLaFiEP/7xj82+rrza+uuvn/baa69w7IEHHih4CMqDDz4Yjh188MFF7xUAAAAAWktoWKD33nsv/eY3v2l2MEpD2aTlhq655pqCnvPII4+kV199tX69ySabpBEjRhS9XwAAAABoLaFhgb7zne/kgsPVevXqlQ444IAmzz/iiCNS375969ePPfZYevjhh1usMpw0aVI4duyxx+amJwMAAABAR6m4NOpHP/pReu655wo+/6OPPkqnnXbaGpWCEydOTJtttlmT12288cbpP//zP8OxE044Ib3++utNXnPRRRflwsXV+vfvn04//fSC9woAAAAAbaHiQsM//OEPadddd0177LFH+slPfpL+9re/5YLBfO+//3666aab0m677ZYuv/zy8LmhQ4em73//+y0+64wzzkibbrpp/Tp77XjUqFHprrvuylUVrjZ37txcCPnd7343XJ+tN9hgg1Z+pQAAAADQOj1ShXryySdzH5nevXunLbbYIlfZt84666S33347N/F45cqVa1yXhYC///3v06BBg1p8Rhb4TZ06NX3pS19Ky5Ytyx177bXX0qGHHpoGDBiQttlmm9wrz3PmzEkff/xxuDY7J3slGgAAAAA6WsWGhg0tX748zZw5s8XzDjzwwHTdddflXj0uVDZF+Z577knjxo1L77zzTv3xLCx84YUXGr3mqKOOStdee23q1q1bwc8BAAAAgLZSca8nZ6/8Zq8Cb7/99rmqwpb069cvF/g9+uijufCvmMBwtS9+8Ytp+vTp6Vvf+lZab731mjxv5513zk1ovvHGG3PVjwAAAABQChVXaThmzJjcR2bJkiW5MC97FXn+/Plp0aJFuVeSs1eHBw4cmIYPH5522GGHgsLFlmyyySZp8uTJ6bLLLsu9Fj1jxoxctWE2hXnw4MFpxIgRqaqqqg2+QgAAAABYOxUXGjaUVf1lQ1Gyj46y7rrrptGjR+c+AAAAAKAcVdzryQAAAABA8yq60hAAgMo1c/yUVOmGTp1Y6i1Al/4e4u8Y0JmpNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAAQGoQAAUBEMPlmTQQ4AdBZ1NSPb5D5V1bVtcp9KoNIQAAAAAAiEhgAAAABAIDQEAAAAAAI9DQEA6JL0MGwb+h5C2/398XcF6ExUGgIAAAAAgdAQAAAAAAiEhgAAAABAoKchAADQ4f0j9XYDgPKm0hAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAYhAIAAJR8eEo5DUbJ30trBr0AUJ7qakaGdVV1bcn2Uu5UGgIAAAAAgdAQAAAAAAiEhgAAAABAoKchAABQcnocAkB5UWkIAAAAAARCQwAAAAAgEBoCAAAAAIGehkBFqasZWeot8L+qqmtLvQWgC9FjrjJ/T0vV97Cx5/ozCFA5/x+xqkL+v4xKQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABD3iEqDrqKsZWeotAADtaOb4KWE9dOrEku2lpWfn7xWArvP/Nauqa1NXpNIQAAAAAAiEhgAAAABAIDQEAAAAAAI9DQEA6HT0h6OzaU2/RX/OASgllYYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIDAIBQAAKBLKGRwSGsGkpRKY3s1HAWAjqLSEAAAAAAIhIYAAAAAQCA0BAAAAAACPQ0BKIm6mpFrHKuqri3JXgCoHPk9ATtTj8PG9qvHIQDtRaUhAAAAABAIDQEAAACAQGgIAAAAAAR6GgId0qsOKvHPjh6NdDZd7e8gVIJCejLqewhAa6g0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABAahAGtF03yAzsv3cChsSEghw0bKWf7+DUbpOJ39zw5Q2VQaAgAAAACB0BAAAAAACISGAAAAAECgpyEAAGVPDzYobZ89fwcBKo9KQwAAAAAgEBoCAAAAAIHQEAAAAAAI9DQEuiy9dypDa/oyAUBb/5uiq/88KuTrq7R/e3X133MAlYYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAh6xCUAdC4zx09Z63sMnToxtYe6mpFhXVVd2y7PAYBy0F4/T0vxb4Ny/voAOopKQwAAAAAgEBoCAAAAAIHQEAAAAAAI9DQE1qpHG3QFrel91Jq+RnocAkD7a+xndEf9rAfoSlQaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAoNQoIJ0tSEmrWloDR3556+lBupd7e9kZ2MQDdCePxcM0Sgvfj8AiqfSEAAAAAAIhIYAAAAAQCA0BAAAAAACPQ2BTkH/Qjoj/a0AKpefAQB0dioNAQAAAIBAaAgAAAAABEJDAAAAACDQ0xDocPoTUqn0tyovdTUjw7qqurZkewEAgHKj0hAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAYhAK0OYNOoO3+rhiWAlC5/z7yMwCAUlJpCAAAAAAEQkMAAAAAIBAaAgAAAACBnobQRdXVjOyQ5+hfCB37d0x/K9pSVXVtWfwsAQCg/Kg0BAAAAAACoSEAAAAAEAgNAQAAAIBAT0MoQ+XUQ0rPQoDK1VLPw0r4OQjl9u8wvW0Byk9dE/92WTH/jZQufiB1VioNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQ9IhLoBxUVdeGdV3NyJLtBSgvM8dPWePY0KkTS7KXrva9FgAA+DeVhgAAAABAIDQEAAAAAAKhIQAAAAAQ6GkIZahUPQwb65UGlL/8v7t6HAIAAGtLpSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAwCAUqiEEnAAAAQCFUGgIAAAAAgdAQAAAAAAiEhgAAAABAoKchdBH6FQIAAABtRaUhAAAAABAIDQEAAACAQGgIAAAAAAR6GsJaqKsZWeotALTY43To1Ikl20tX/x5eVV3bJnsBAIByo9IQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQGIQCnXCoAcDafg8xHAWg/PleDUApqTQEAAAAAAKhIQAAAAAQCA0BAAAAgEBPQyhDehgCHf19Rt8sAACgIZWGAAAAAEAgNAQAAAAAAqEhAAAAABDoaQhlQA9DAAAAoJyoNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQNAjLoH2NnP8lFJvAQAAAKBZKg0BAAAAgEBoCAAAAAAEQkMAAAAAINDTEIpQVzMyrPUnBLqK1nw/Gzp1Yrvsha71sxIAoKurqq5t9PiiVe+n11PnpdIQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQGIQCzTD4BACaZ/AJAEDXpNIQAAAAAAiEhgAAAABAIDQEAAAAAAI9DaGZnkx6GAI0rZDvkUOnTuyQvQB0Bb5nAlBOVBoCAAAAAIHQEAAAAAAIhIYAAAAAQKCnIRUrv4eh/oUAbS//e6t+XQAA0DmoNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAAQGoVAx7nv9xbwj+WsA2pvBKAAA0DmoNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DOlRdzcgSPl0PQ4By73HY2foctsXPtarq2jbZC1DeOtP3NgDIqDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBPw/+1bNmy9OSTT6aXX345vfvuu6lXr15piy22SCNGjEjbbrttmz5r5syZ6emnn05z585NK1asSAMHDkzDhg1Lo0aNSn369EldSal6GDbWIwsAADqKHoYAdHZlGxrOmzcvF6w99dRTuf8+++yz6YMPPqj//JAhQ9Ls2bPX+jkLFy5MkyZNStdff31avHhxo+fssssu6dxzz02HHnroWj3rjjvuSBdccEF6/vnnG/18v3790oQJE9J5552XNtxww7V6FgAAAAB0idDwiSeeSJdddlkuKHz99dfb/XnTpk1L48aNS2+99Vaz5z333HNp7Nix6f/8n/+TrrrqqlwVYjGWL1+ejj/++HTjjTc2e96iRYvS//zP/6SpU6em2267Le21115FPQcAAAAAulxPw2eeeSb99re/7ZDA8I9//GM68MAD1wgMBwwYkHbeeee09dZbp3XWWSd87oYbbkhHHnlkWrVqVcHPWblyZRo/fvwagWF272222SbttNNOqX///mtUPx5wwAHpT3/6U6u+NgAAAADoMqFhc7JXd9tK1rMwC/KWLl0aXnfOXh9+5513cq8Pv/rqq7nXn0888cRw7e23355qamoKftYll1yS7rzzznBs4sSJac6cOWnWrFnphRdeyD0zu+9WW21Vf86SJUvS4Ycfnt5///21+loBAAAAoEuEhuuvv37aZ5990umnn55uvfXWXHj3u9/9rs3unwV5DasZs4q/bAhK1rOwW7du9cezQShTpkxJP/zhD8P1P/jBD3LBY0vefvvtNa696KKL0s9//vO0+eab1x/r3r17+upXv5rbQ1bhuFo2KOXyyy9v9dcJAAAAAJ0+NDz44IPTSy+9lN577730yCOPpB//+Mfp61//eq4KsK1kr/7+93//dziW9SlsGOLlO/vss0N/waz679JLL23xWdn+Gw5vye5x5plnNnn+4MGD09VXXx2OZVWNWfgIAAAAABUZGg4dOjQNHz48V3nXXm6++ebcwJGGQd7o0aObvSarPswmGjd07bXXNtvbMOtleN1114Vj559/fqhkbEy2lz333LN+nYWOt9xyS7PXAAAAAECXDQ07Qn5/wWyqcSH23Xff3GvMq73xxhuptra2yfOzV42zqsbVtt1229wr14XI31PWaxEAAAAAOkqPVEGyCsPHHnssHNt///0LujarENxvv/1yrzKvdvfdd6fdd9+90fPvueeesB4zZkyLVYYNz21o2rRpafHixalv374FXV8JZo6fUuotAFCi7/FDp07ssL0AAEClqqhKw6xf4ocffli/zioHN91004Kv32OPPcL6xRdfbPLc/M+NGjWq4Odk/RUbDkRZsWJFmj59esHXAwAAAMDaqKjQcMaMGWGd9U8sRv75+fcr1bMAAAAAoC1VVGj4yiuvhPWWW25Z1PX557/22mtp2bJla5y3dOnSNGfOnDZ9Vv7eAQAAAKC9VFRPwwULFoT1FltsUdT1m2yySerRo0f66KOP6ickv/3222nw4MHhvLfeeitMVu7Zs2faeOONi3pW/j3z995a2X0aDmgpRF1dXSol/QsBAAAAOlbFDUJpqNjBItkgk3XXXTd98MEHTd6zsWPrrbdewUNQmtpbY89pjcmTJ6dJkya1yb0AAAAA6Joq6vXk/OCtT58+Rd8jCw2bu2dHPgcAAAAA2kNFhYb5/Qd79epV9D169+69Rv/CUj0HAAAAANpDRb2enF/xt2LFiqLvsXz58mbv2ZHPaY2TTjopjRs3ruiehmPHjm2T5wMAAABQ/ioqNOzXr19YNzb5uCX5FX/59+zI57RGNpCl2KEsAFBOChmQNXTqxNRZ1NWMXONYVXVtSfYCtF5n+r4DAIWoqNeT84O3xYsXF3V9NhG5NaHhkiVLwjTlQuTvra1CQwAAAABoSUWFhvkVdnPnzi3q+jfffDN99NFH9evu3bunDTfccI3zsmMNpyV/+OGHacGCBUU9a968eWGtOhAAAACAjlJRoeGnP/3psJ4zZ05R1+efP2TIkEZ7DWaTj7faaqs2fdawYcOKuh4AAAAAWquiehrmB2/Tp08v6voZM2Y0e7/8z7322mvhWbvttlu7PKujzTnzs6nXZpuWehsAUHDfw87Wa6yxPoctKVUfxPZ4bmu+fuhIne17CgC0RkVVGm6//fapZ8+e9evZs2en+fPnF3z9E088EdY77bRTk+fmf+7JJ58s+DnZnrK9rZbtefjw4QVfDwAAAABro6JCw/XXXz/ttdde4dgDDzxQ0LXZIJMHH3wwHDv44IObPP+ggw4K6+zaQoeh3H///WG97777GoQCAAAAQIepqNAwc8ghh4T1NddcU9B1jzzySHr11Vfr15tsskkaMWJEk+ePGjUqDEmZNWtWmjZtWkHPyt/ToYceWtB1AAAAANAWKi40POKII1Lfvn3r14899lh6+OGHm70mqxCcNGlSOHbsscfmpic3JfvchAkTwrHsHi1VGz700EPp8ccfD9WRhx9+eLPXAAAt9zjM/+hqsj6ADT8AAGBtVFxouPHGG6f//M//DMdOOOGE9Prrrzd5zUUXXZQLF1fr379/Ov3001t81plnnhleK3700UfTxRdf3OT58+bNy+2loZNPPjlULAIAAABAxU1PzoaNLF26dI3jf/7zn8N62bJla/QYXG3zzTdvdnDIGWeckX7xi1+kN954I7fOXjvOXif+6U9/mutT2K1bt9zxuXPnpgsvvDBdccUV4frvfve7aYMNNmjxa8nCvnPOOSf3sdrZZ5+d5syZk773ve/l9plZuXJluuuuu3IBYfa5hl/Haaed1uJzAAAAAKBLh4bf+MY30muvvdbieW+++WYaM2ZMo5875phj0vXXX9/ktVngN3Xq1PSlL30pFz5msmdmvQMHDBiQttlmm/Tee+/lAryPP/44XJud853vfKfgryerNswmJ9999931x37+85+nK6+8Mg0ZMiRXtZiFltnzGlp33XXTLbfcktsPAAAAAHSkins9ebVsivI999yzRsVgFt698MILuSAvPzA86qijcmHj6krEQmS9DW+99dZcL8WGsntnw1GyZ+UHhoMGDUr33ntv2mOPPVr1tQEAAABAl6o07Ehf/OIX0/Tp03MDSrLXlZcsWdLoeTvvvHPudeLDDjusVc/p06dPuummm9LXv/713OvOL774YqPnZQNasirJ8847L9d7sVJ1xeb0AAB0HkOnTiz1FgCg5MouNJw9e3aHPm+TTTZJkydPTpdddlnuNeIZM2bkKv969eqVBg8enEaMGJGqqqra5Flf+9rXch91dXXpqaeeyg0+WbFiRe4V5O222y5XWZgFjAAAAABQSmUXGpZK1kNw9OjRuY/2loWQbRVEAgAAAEBbq9iehgAAAABA41QaAgAAFUv/QgBonEpDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEPeISAKAyzBw/JayHTp1Ysr3Qsvzfn/zfPyiUv+sAUBiVhgAAAABAIDQEAAAAAAKhIQAAAAAQ6GlIyelJBABtr65mZIvnVFXXdsheoL3oTwjA2vLvoaapNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DAIAK1VLfw3Lu8ZPfy06P5M5Pf0IAOkI5//um3Kg0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABAahAAA0MkjDUIbOpbHfL8NRyoe/TwDQ+ag0BAAAAAACoSEAAAAAEAgNAQAAAIBAT0MAABpVVzNyjWNV1bXt/tzGntHYXorto6fHYdvQnxAAKoNKQwAAAAAgEBoCAAAAAIHQEAAAAAAI9DQEAGhEY/3v9HIrnfw+h63pcQgAQOFUGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKDUCjaVhf/OfXrNrugczUpBwA6YjBKIf8OyR9k09iwGwCg8/7sp22pNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DAAAK1hb9isulJ1F+j8OMPocAUB7K5d8LlUylIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAgh5xCQAAlWvo1InNfn7m+CkdthcAgFJSaQgAAAAABEJDAAAAACAQGgIAAAAAgZ6GAAAFyu9n11L/OwAA6KxUGgIAAAAAgdAQAAAAAAiEhgAAAABAoKchAAAUqLE+lvm9Lru6xr5e/T0BoOtRaQgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAgMQgEAoEuqqq4N67qake3ynPwhIJU2GKW1X7PhKQCVK/9nNOVJpSEAAAAAEAgNAQAAAIBAaAgAAAAABHoaAgDQodqjt2AhvZHaon9Se/VFBICuTA/DzkmlIQAAAAAQCA0BAAAAgEBoCAAAAAAEehoCAEAbGjp1YljPHD+lZHspZ/m/Lvm/bgBAaak0BAAAAAACoSEAAAAAEAgNAQAAAIBAT0MAAGhHjfXq0+dwTXocAkB5UWkIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIDEIBAADKTmPDYgxHAYCOo9IQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIOgRlwAAQHsbOnViWM8cP6VkewEAaIxKQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQGAQCgAAnV5dzcg2uU9VdW2b3AcAoLNTaQgAAAAABEJDAAAAACAQGgIAAAAAgZ6GAABQYkOnTmyX+84cPyV1Vu31awIAFEalIQAAAAAQCA0BAAAAgEBoCAAAAAAEehoCAECBqqpr1zhWVzMydaW+gKXqg6iHIQCUF5WGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAwCAUAABo4+EonWVQSmMMJAEAMioNAQAAAIBAaAgAAAAABEJDAAAAACDQ0xAAAACADuv3S+eg0hAAAAAACISGAAAAAEAgNAQAAAAAAj0NKbmhUyeG9czxU0q2FwCAjujrVFczsiR7AaDr0keQtqbSEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEBiEAgDQyuFd0BhDTgCArkClIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAg6BGXUHpDp04M65njp5RsLwAAAACVSKUhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQNAjLqH8DJ06cY1jM8dPKcleAICura5mZKm3AABQFlQaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAoNQAAAKHMQFAACVQqUhAAAAABAIDQEAAACAQGgIAAAAAAR6GtIl+0zNHD+lw/YCAAAA0NWoNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DAIAC+uUCAEAlUWkIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIDEKhYprZzxw/pSR7AQAAAOhsVBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABD3iEgAAaEtV1bUd8py6mpGp0n7dutrXDFSGjvq5AGtLpSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAwCAUAAACgnRh8Qmel0hAAAAAACISGAAAAAEAgNAQAAAAAAj0NqRhDp04M65njp5RsLwCU388F6Io9s+pqRpZkLwCVTA9DugqVhgAAAABAIDQEAAAAAAKhIQAAAAAQ6GlIxdLjEACga/UN08MRANqOSkMAAAAAIBAaAgAAAACB0BAAAAAACPQ0LIGZM2emp59+Os2dOzetWLEiDRw4MA0bNiyNGjUq9enTp9TbAwAAAKDClW1oOG/evFyw9tRTT+X+++yzz6YPPvig/vNDhgxJs2fPbtW9u3XrtlZ7e/XVV9PWW29d9HV33HFHuuCCC9Lzzz/f6Of79euXJkyYkM4777y04YYbrtUeAYCmh18BAACdKDR84okn0mWXXZYLCl9//fXUVSxfvjwdf/zx6cYbb2z2vEWLFqX/+Z//SVOnTk233XZb2muvvTpsjwAAAABQlj0Nn3nmmfTb3/62SwWGK1euTOPHj18jMFxnnXXSNttsk3baaafUv3//8LmFCxemAw44IP3pT3/q4N0CAAAAQJlVGjYne3U3q8RrazvuuGOuurEYm266acHnXnLJJenOO+8MxyZOnJjOPffctPnmm9cHi9k5p5xySpozZ07u2JIlS9Lhhx+e/va3v60RKgIAAABAxYWG66+/ftpll13Sbrvtlj7/+c/n/pv1Edx3333b/FnZEJL99tsvtYe33347/fCHPwzHLrroonTWWWeFY927d09f/epXc1/rF77whfpejdmglMsvvzxNmjQpdVZV1bVrfY+6mpFtshcAgEpTzv8Wa4u9tcU9/VsTKld7fB+CrqSsQsODDz447b///rlJwlmQ1lAWGnY2P/7xj8PwlqxH4Zlnntnk+YMHD05XX311CDFramrS//t//y8NGjSo3fcLAAAAAGXX03Do0KFp+PDhawSGnVH2yvF1110Xjp1//vktTm4ePXp02nPPPevXWeh4yy23tNs+AQAAACBf50/nytSTTz6ZG2iy2rbbbpv22Wefgq7NJi03dMcdd7T5/gAAAACgU7ye3JXcc889YT1mzJgWqwwbntvQtGnT0uLFi1Pfvn3bdI8A0FUNnTqx1FuALqOr9/xq7OvT5xDKX1f/3gTlQKVhO3nxxRfDetSoUQVfm01V3nrrrevXK1asSNOnT2/T/QEAAABAU4SG/2v+/PnpueeeS4899lj661//mluvjRkzZoR11quxGPnn598PAAAAANpLxb+enAWEWb/BxqYzb7rppmnvvfdOEyZMSF/+8pcLvufSpUvTnDlzwrEtt9yyqH3ln//KK68UdT0AAAAAtFbFVxq+8847jQaGmTfeeCNNnTo1HXDAAelzn/tcLmAsxFtvvZVWrVpVv+7Zs2faeOONi9rX4MGDw3rBggVFXQ8AAAAArVXxlYaFeuGFF9KIESPSL37xizRu3Lhmz120aFFYr7feegUPQVktf+hJ/j1bKwsfG051LkRdXV2q1Kb5M8dPKcleAGiaIScAAND+KjY03HDDDdNBBx2U9ttvv7TjjjumLbbYIq2//vq5cC57tfjxxx9PV111Vfrzn/8cXjs++uij0yabbJL22muvJu+dH/D16dOn6P2tu+66zd6ztSZPnpwmTZrUJvcCAAAAoGuqyNDwV7/6Va5asFevXmt8bsCAAbmPLEj89re/na644op08sknp+XLl9dPMj7qqKNy1XdNhYHLli0L68ae05LevXuHdRZYAgAAAEBHqMieht/4xjcKDvJOPPHE9Otf/zp17/7vX6p58+aln/3sZ01ekx8mZkFjsVaHlE3dEwAAAADaS0VWGhbrsMMOS9/85jdz/QxX++Uvf5lOO+20Rs/v169fs5WHhcivLMy/Z2uddNJJLfZkzJdVVY4dO7ZNng8AAABA+RMaFigLCBuGhn/5y1/Sm2++metvmC8/4FuyZElumnIxw1AWL17c7D1bK5viXOwkZwAAAAAqS0W+ntwaO+ywQwjbshDw73//e5NDVhoGhB9++GFuanExslegGxL0AQAAANBRhIZFyCYsN7Rw4cImJx9vtdVW4Vg2kbkY+ecPGzasqOsBAAAAoLW8nlyEnj17hnVWQdiULOR77bXX6tfTp09Pu+22W8HPmjFjxhr3AwAA2l9VdW1Y19WMLNleAKBUVBoW4Y033gjrjTbaqMlzd9ppp7B+8sknC37O/Pnz0+zZs0NYOXz48KL2CgAAAACtJTQs0Ny5c0PlYGbLLbds8vyDDjoorB988MFcH8RC3H///WG97777ttkgFAAAAABoidCwQNdcc80ageEnP/nJJs8fNWpUbiDKarNmzUrTpk1r1bMOPfTQovcLAAAAAK0lNCywv+Bll10Wjo0dO7bZa7p3754mTJgQjk2aNKnFasOHHnooPf744/Xr9ddfPx1++OGt2jcAAAAAtEZFDUJ58cUX0yOPPJJOPPHEtN566xV8TVbp98EHH4TpyGeddVaL15555plpypQpadGiRbn1o48+mi6++OImr503b1464YQTwrGTTz45VCzSsYZOnRjWM8dPKdleACpV/vdiAACgAkPDJ554Ii1dunSN43/+85/DetmyZbk+gY3ZfPPNGx0c8t5776VTTz01/fCHP0yHHXZY+upXv5qbaJwfymXVgH/729/SVVddla688sq0fPny8PmLLroo94yWZPc955xzch+rnX322WnOnDnpe9/7Xv09Vq5cme66665cQJh9ruHXcdppp7X4HAAAAADo0qHhN77xjTUGjjTmzTffTGPGjGn0c8ccc0y6/vrrm7z27bffzgWC2Udmk002yQV82avAWVVgVvH37rvvNnptFuJl4V6hsmrDbHLy3XffXX/s5z//eS6MHDJkSOrfv3969dVXc4FmQ1k14y233JIGDBhQ8LMAAAAAoEuGhqWQBZDZR3M+8YlPpMmTJ+dCzWJkvQ1vvfXWdOyxx6abb765/vjHH3+cG47SmEGDBqXbbrst7bHHHkU9CwAAAADaQkWFhjvssEOup2DW1/Dpp59O77zzTovXDBs2LB133HG5XoMDBw5s1XP79OmTbrrppvT1r389XXjhhbk+iY3p27dvrkryvPPOSxtvvHGrnkX70uMQoP3pYQiUm6rq2rCuqxlZsr1AJcr/OwhUaGg4e/bsdrt3VsF3xhln5D4y2WvQ//jHP3J9BLPXkbNeilnAl4WDm222WRoxYkTumrbyta99LfdRV1eXnnrqqdxr0CtWrMi9grzddtvlKguz5wMAAABAKZVdaNiRsp6C2UdHq6qqyn0AAAAAQDnqXuoNAAAAAADlpaIrDQEAAIqlv1rjKq3XY1v9OWiPXzd/RoG2oNIQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQGIQCAHSYoVMnlnoLANAqhosAlUalIQAAAAAQCA0BAAAAgEBoCAAAAAAEehoCAO1GD0OAyu35V1czsmR7qTT6LQLtQaUhAAAAABAIDQEAAACAQGgIAAAAAAR6GtIp+3OUS3+Uxnp1zRw/pSR7ASg1/QsBAKDrUGkIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAICgR1xC51BVXdvs5+tqRnbYXgAAAAC6GpWGAAAAAEAgNAQAAAAAAqEhAAAAABDoaUhF9jxsz76HQ6dObPbzM8dPaZfnAnS0lr7fAVDZCvk3OX6dgPKl0hAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAYhAJlMDjAcBSg3BhyAgAAlU2lIQAAAAAQCA0BAAAAgEBoCAAAAAAEehpSsaqqa8O6rmZkyfYCUGp6GAIAAA2pNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DKMNeYjPHTynZXoDKoIchAADQHJWGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAwCAUKEMGowBtydATAACgWCoNAQAAAIBAaAgAAAAABEJDAAAAACDQ0xD+V1V1bdHX1NWMTKXqR6bPIdAUPQwBAIC1pdIQAAAAAAiEhgAAAABAIDQEAAAAAAI9DaGN+yCWqs+hHodQufQwBAAA2ppKQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABD3iEuishk6dGNYzx08p2V4AAACAzk2lIQAAAAAQCA0BAAAAgEBoCAAAAAAEehpChfQ4zOhzCF3j7zIAAEB7U2kIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIDEKBCtKagQqGp0D7MeQEAAAoVyoNAQAAAIBAaAgAAAAABEJDAAAAACDQ0xDaWFV1bZvfs65mZCqXnmt6HELh9CwEAAA6K5WGAAAAAEAgNAQAAAAAAqEhAAAAABDoaQhdpE9iR/U9LKRHm76HVCL9CwEAgK5EpSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAwCAUoi4EQhqdQTgw1AQAAKp1KQwAAAAAgEBoCAAAAAIHQEAAAAAAI9DSELqKqujas62pGpkrrIacvIhn9CAEAANaeSkMAAAAAIBAaAgAAAACB0BAAAAAACPQ0hC6is/Uw7Ihednoclje9BwEAAMqXSkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAAQ94hLorKqqa8O6rmZkqnRDp04s9RYAAACgU1JpCAAAAAAEQkMAAAAAIBAaAgAAAACBnoZQIT0OC6EPIgAAAJBRaQgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAgMQgGaHZ5iOAoAAABUHpWGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAICgR1wCRFXVtaXeQsWoqxlZ6i0AAABAjkpDAAAAACAQGgIAAAAAgdAQAAAAAAj0NARoB/oTAgAA0JmpNAQAAAAAAqEhAAAAABAIDQEAAACAQE9DgBboTwgAAEClUWkIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAh6xCVAZaurGVnqLQAAAEDJqTQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEDQIy4Buo66mpGl3gIAAAB0SioNAQAAAIBAaAgAAAAABEJDAAAAACDQ0xDoMvQwBAAAgLah0hAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACHqkMrRq1ao0e/bs9Ne//jXNnTs3vffee6l3795p4MCB6ZOf/GTabbfdUp8+fdr0mR988EF64okn0t///vf0r3/9K6277rppyJAhadSoUWnzzTdv02e99NJL6bnnnkvz589PH3/8cRo0aFD6zGc+k0aMGJF69CjL3xIAAAAAKkjZJFTvvvtuuuOOO9If/vCH9PDDD6e33nqryXN79uyZvvKVr6RTTjkl7b333mv13FdffTV9//vfT7fccktasWLFGp/v1q1b7hmTJk1Ke+2111oFodddd126+OKLc8FkY7Lw8Fvf+lY666yzUt++fVv9LAAAAADo9K8nf/vb306bbrppOu6443LhXXOBYebDDz/MBYz77LNPOuaYY3KVga2RPSur8PvVr37VaGC4OuybNm1a7llZmJeti5VVSn7pS19Kxx9/fJOBYebtt99OF154Ydpxxx1z1YgAAAAAULGh4VNPPdVoaLfOOuukLbbYIu2yyy65IK1///5rnHPDDTekMWPGpEWLFhX1zFtvvTUdeeSRacmSJeH4RhttlD73uc/lnptVGa6WhYVZleCpp55a1HOWLl2aCwwfeOCBcLxXr17pU5/6VNphhx3WqCqcNWtW2nfffVNdXV1RzwIAAACALhMaNjRgwIB00kknpXvuuSf3yvI///nP9Oyzz6Y///nPuUq8Rx55JO25557hmqeffjpNmDCh4GfMnDkzHXvssWnlypX1xz772c/mXotesGBBrt9g9twZM2akww47LFz7X//1X+n2228v+FlZyJjtb7Xu3bunc889N73xxhvplVdeSX/5y1/SO++8k3t1OevZuNrChQvT4Ycfnut5CAAAAAAVGRpuvfXW6eqrr06vv/56+tnPfpYOPPDAtP76669ReZi9JpwFh//xH/8RPveb3/wmd7wQWWi3ePHi+nU2WOWxxx7LVfc19OlPfzrddtttazzrjDPOSB999FGLz3n55ZfTVVddFY5lr0L/4Ac/CAFhVnWYhZ6PP/54LjRd7YUXXshVUgIAAABAxYWG2ZCRrOou6/mXTS1uSRYeTp48Oe26667heBY6tiTrFTh16tQQ2P3iF79In/jEJxo9P3tF+Sc/+UluanPDSsWsMrAl5513XqgU/OY3v5l7Jbop22+/fbr00kvX+LXJejgCAAAAQEWFhtkk5Cy8K0YWHGYVfw3dd999LV537bXXhteSjzjiiLTddts1e02fPn1yQ1CKCSizV6sbvsachY/nn39+i/vLXpseMmRI/fq1115LDz74YIvXAQAAAECXCg1bK7+3YdbzMH+wSb677rorrLPqxkKMHz8+DCx55plncq9SNyXrydjwFebsteptt922xedkPQ+z4LChbFI0AAAAAHSUTh0aNuwLuNr777/f5PnZK9ANJxJnIeCoUaMKelb+udk05SwYbEr+5/bff/9UqGwadEN33313wdcCAAAAQEWHhvPmzVvj2KBBg5o8/8UXXwzrz3/+86lHjx4FP2+PPfZo9n7Nfa7QcDKzyy67pN69e9evs4rGbJoyAAAAAHSETh0aZtOGG8p6ATbXG3HGjBlhPXz48KKel39+/v1WywaXNKxoLPZZWWA4dOjQgp4FAAAAAG2tU4eG2VCThg488MBmz89eT25oyy23LOp5+efn32+1WbNmhX6G2UToDTfcsF2eBQAAAABtrfB3c8vMvffemx577LFwbMKECc1es2DBgrDeYostinrm4MGDw7qpV4bzn5N/XWuelX/P1sruU+yrzvlVkwAAAAB0bZ0yNHznnXfSiSeeGI6NHTs216OwOYsWLQrrhtOQC5F/fvYa8vLly0P/wbZ4TmPX5N+ztSZPnpwmTZrUJvcCAAAAoGvqdK8nr1y5Mh199NFp7ty59cf69++ffvrTn7Z4bX7w1qdPn6Kenb1m3NI92+I5jT2rrUJDAAAAAOhyoeHpp5+efv/734djV1xxRUH9CZctWxbWzQ1NaUx+RWFm6dKlbf6cxp7V2HMAAAAAIFX668lZNeHll18ejp1xxhlp/PjxBV2fX/G3YsWKop6fvYrc0j3b4jmNPas11YqNOemkk9K4ceOK7mmYvf4NAAAAQGXoNKHhr3/963TKKaesMfjkRz/6UcH36NevX7MVgS1prNov/55t8ZzGntXYc1pj4403zn0AALCmquraUm8BAKAsdIrXk+++++50zDHHpFWrVtUfO+yww9LVV1+dunXrVvB98oO3xYsXF7WP/PN79OjRaAXg2j6nsWvaKjQEAAAAgE4fGj7yyCO512k/+uij+mNjxoxJN910U1pnnXWKuld+hV3DYSqFmDdvXlhvtNFGBT0n/7rWPEt1IAAAAAAdpaxDw6eeeiodcsgh4fXeUaNGpd/+9retGi7y6U9/OqznzJlT1PX55w8bNqzR87bddttcFWLDV40XLlzYLs8CAAAAgIoJDf/yl7+kAw44IC1atKj+2M4775zuvffe1Ldv31bdMz94mz59elHXz5gxo9n7rdazZ880dOjQVj8rG4Iya9asgp4FAAAAABURGr7yyiu5V5Dffffd+mPbbbdduu+++1L//v1bfd+ddtoprJ955pnw2nNLnnjiiWbv19znnnzyyYKf89xzz4XpyZtttpnXkwEAAACo3NDwtddeS/vtt19asGBB/bFtttkmPfDAA032ECxUVq3XsAIwGzZSaJiXnfunP/2pfp0NYDnooIOaPD//c9n+C5V/7sEHH1zwtQAAAADQpULD+fPnp9GjR4cBJYMHD04PPfRQ7r9tIeuR2NA111xT0HVTp04Nr0rvuuuuafPNN2/y/AMPPDD0NZw2bdoarxw3JpsQff3114djhx56aEF7BAAAAIAuFRq+8847uVeSZ86cWX8sqyzMqu6ySsO2ctxxx+WqBFe7+eab1+hVmC8bxPKjH/0oHDv++OObvWaDDTZIY8eODWHg+eef3+L+rr322jR79uz69ZAhQ3KVlwAAAABQUaHhBx98kL785S+nl156qf7YgAED0v3335/rZdiWPvOZz6TDDz+8fr1ixYp0zDHHpH/961+Nnp+Ffaecckr6xz/+EaYjZ+FjSyZNmpS6d//3L/Evf/nLdNNNNzV5fjYs5Tvf+U44du6557ZqUjQAAAAAtNa/358toeyV4WwoSUOnnnpqeuutt9KDDz5Y1L122WWXNHDgwGbPufDCC9Pvfve7tGTJktw6e/Zee+2V/uu//ivts88+9ef9/e9/T2effXa6/fbbw/VZ1WE2Ibklw4cPTyeccEK68sor648dffTRucrG6urq+n1++OGH6cYbb8x9ze+99179uTvuuGMu0AQAAACAjtRtVVZKV2INXxdeW4888kgI/pqSvZZ81FFH5SoJG8peid5qq61yg1iy3or5n/+///f/pp/+9KcF7ycLJvfee+/07LPPhuNZ9WD22nXv3r1zvQ4b9kvMbLjhhrlpzZ/61KdSqWUVoFmF5moj05jUr1vrp1hDe6mrGVnqLQDQyVVV15Z6CwBAF7Fo1fupNv172O3f/va3tP3226fOoiwqDUvhiCOOyAWCWW/CpUuX1h9fuHBh7qMx2avDP/7xj4t6znrrrZfuu+++NG7cuPTwww+H16JfeeWVRq/Zeuut01133VUWgSEAAAAAlacsehqWypFHHplLebOKw+ZeN85eXc6mH19yySWtqorMhqJkA12y15SrqqqaPe+cc85Jf/3rX9MOO+xQ9HMAAAAAoMu8nlwOskEof/zjH3MDT7LBLH369Mm9przHHnukwYMHt+mzslDw+eefT/Pnz08ff/xxGjRoUO713xEjRhTUK7GjeT2ZzsLryQCsLa8nAwBtZZHXk7uGT3ziE+nAAw/skGdlVYQqCQEAAAAoVxX9ejIAAAAAsCahIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIDA9Gegyqqprw7quZmTJ9gIAAACdmUpDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAYBAKUDGDUQpheAoAAACoNAQAAAAA8ggNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEPSIS4DKVlVd2y73rasZ2S73BaB9v38DAFQqlYYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAg6BGXAABQ/qqqa0u9BQCALk2lIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIDAIBQCADmWICQBA+VNpCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIesQlAO2hqro2rOtqRpZsLwAAANASlYYAAAAAQCA0BAAAAAACoSEAAAAAEOhpCFAGPQ4bo+8hAAAApaLSEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABEJDAAAAACAQGgIAAAAAQY+4BKBcVFXXdshz6mpGdshzAAAA6DxUGgIAAAAAgdAQAAAAAAiEhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAg6BGXAFSaqurasK6rGVmyvQAAAFAeVBoCAAAAAIHQEAAAAAAIhIYAAAAAQKCnIQDN9jgshD6IAAAAXYtKQwAAAAAgEBoCAAAAAIHQEAAAAAAIhIYAAAAAQCA0BAAAAAACoSEAAAAAEAgNAQAAAIBAaAgAAAAABD3iEgCKV1Vd2+I5dTUjO2QvAAAArD2VhgAAAABAIDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAARCQwAAAAAgEBoCAAAAAIHQEAAAAAAIesQlALSPquraUm+h7NTVjCz1FujC/J0DAGBtqDQEAAAAAAKhIQAAAAAQCA0BAAAAgEBoCAAAAAAEQkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEAgNAQAAAAAAqEhAAAAABAIDQEAAACAQGgIAAAAAAQ94hIA6ChV1bUtnlNXM7JD9gIAANCQSkMAAAAAIBAaAgAAAACB0BAAAAAACISGAAAAAEBgEAoAlIghJ5T6z1chw3gAAKhMKg0BAAAAgEBoCAAAAACU/+vJq1atSrNnz05//etf09y5c9N7772XevfunQYOHJg++clPpt122y316dMndVYvvfRSeu6559L8+fPTxx9/nAYNGpQ+85nPpBEjRqQePcrytwQAAACAClI2CdW7776b7rjjjvSHP/whPfzww+mtt95q8tyePXumr3zlK+mUU05Je++9d1HPycLIbbbZZq1DzdZcc91116WLL744/f3vf2/0nCw8/Na3vpXOOuus1Ldv37XaIwDlr5z7yem3CAAAla0sXk/+9re/nTbddNN03HHHpVtuuaXZwDDz4Ycf5gLGffbZJx1zzDHpX//6VypnWaXkl770pXT88cc3GRhm3n777XThhRemHXfcMVeNCAAAAAAVGxo+9dRTacWKFWscX2edddIWW2yRdtlll1yQ1r9//zXOueGGG9KYMWPSokWLUjlaunRpLjB84IEHwvFevXqlT33qU2mHHXZYo6pw1qxZad999011dXUdvFsAAAAAKKPXk1cbMGBAOuqoo3KvH++5555p/fXXr/9c1v/v8ccfT9///vdz/13t6aefThMmTEi33XZb0c/bf//90+mnn57ay6mnnprb32rdu3dP3/3ud1N1dXWuR2MmC0x//etf587NXtPOLFy4MB1++OHpmWeeyYWnAAAAAFBxoeHWW2+dvve97+UCw3XXXbfRc7LwLHsl+ZFHHkknnXRSuvLKK+s/95vf/CZ3PKvQK8Zmm22W9ttvv9QeXn755XTVVVeFY7/61a/SkUceuUbVYRZ6ZgNevvCFL+ReZ8688MILuUrKY489tl32BwAAAABl+3rypEmT0iuvvJLr+ddUYJgfHk6ePDntuuuu4fjVV1+dysl5552Xq45c7Zvf/OYagWFD22+/fbr00kvX+LXJejgCAAAAQEWFhtmryFm1XTGy4PCMM84Ix+67775ULrLXjG+//fb6dbdu3dL555/f4nVZVeGQIUPq16+99lp68MEH222fAAAAAFCWoWFrZT0P86cPL1myJJWDe+65J3300Uf16+y16m233bbF67Keh/mvI2eTogEAAACgo3Tq0HD1IJGG3n///VQuoWH+wJVCZdOgG7r77rvbbF8AAAAA0KVDw3nz5q1xbNCgQakcvPjii2E9atSogq/dZZddUu/evevXr7/+em6aMgAAAABU1PTk1nj88cfDOusFWGxvxNX++c9/pjfeeCMtW7YsbbDBBmnjjTdOG220UavulQ0uqaurC8eGDx9e8PVZYDh06NA0ffr0+mMzZsxo9X4AAAAAoGJCw2uvvTasDzzwwKLvcf/996fNN988zZ8/f43Pbb311rlehP/xH/+Rdt9994LvOWvWrNDPMJsIveGGGxa1ry233DKEhtl06b322quoewAAAABARb2efO+996bHHnssHJswYULR98nCwsYCw8zs2bPT9ddfn3u1ePTo0WnOnDkF3XPBggVhPXjw4KL3lX9N/j0BAAAAoL10ykrDd955J5144onh2NixY9PnP//5dnvmww8/nHbeeef029/+tsWKv0WLFoV13759i35e/jX592ytLHwstj9i/qvWAHR9VdW1LZ5TVzOyQ/YCAAB0vE4XGq5cuTIdffTRae7cufXH+vfvn376058WdZ8tttgiHXzwwemLX/xi+sxnPpM222yzXFCXTV9+9dVX0yOPPJKmTJmSe9W4YVh56KGHpj/96U9p2LBhTd47P+Dr06dPKlb2SnNz92ytyZMnp0mTJrXJvQAAAADomjpdaHj66aen3//+9+HYFVdckesBWIgsYLzrrrvSV77yldS9e/dGpy9nH7vuums69dRT0wUXXJD7yMLKzHvvvZcLLZ955pnUrVu3Rp+RDVNpqDXDWRpOT84sXbq06HsAAAAAQJfvaZhVE15++eXh2BlnnJHGjx9f8D0GDhyYqzBsLDDMt84666Tzzz9/jWc+99xz6fbbb2/yuvzKwhUrVqRiLV++vNl7AgAAAECq9ErDX//61+mUU05ZY/DJj370o3Z/9sknn5zrZfjoo4/WH/vlL3+Zvva1rzV6fr9+/ZqtPCxEfmVh/j1b66STTkrjxo0ruqdh1jMSAOhafSkBAKBTh4Z33313OuaYY9KqVavqjx122GHp6quvbvIV4bZ22mmnhdAwG4zy0UcfpR491vwlzA/4Fi9eXPTz8q9pq9Bw4403zn0AAAAAQKd9PTkbSJJVxmUB3WpjxoxJN910U+714Y6SDUxpGFB+8MEHaf78+Y2emx/KzZs3r+jn5V8j6AMAAACgo5R1aPjUU0+lQw45JLzeO2rUqNyrwq0ZLrI2ssnKWT/EhhYuXNjoudtuu22oQMxeNW7q3KbMmTMnrJub1gwAAAAAFREa/uUvf0kHHHBAWrRoUf2xnXfeOd177725AK8UevbsGdYffvhhk+cNHTo0HJs+fXpRQ1BmzZoVjgkNAQAAAKjo0PCVV17JvYL87rvv1h/bbrvt0n333Zf69+9fkj1lr0e//fbb4dhGG23U5Pk77bRTWD/55JMFPyubztxwevJmm23m9WQAAAAAKjc0fO2119J+++2XFixYUH9sm222SQ888ECzIV17q62tDX0Vs9ePN9100ybPP+igg8I623+h8s89+OCDi9orAAAAAHSZ0DAbLDJ69Og0d+7c+mODBw9ODz30UO6/pXTNNdeE9e67757WW2+9Js8/8MADQ1/DadOmrfHKcWOyCdHXX399OHbooYe2as8AAAAA0KlDw3feeSf3SvLMmTPrj2WVhVnVXVZpWEpZ4PfLX/4yHBs7dmyz12ywwQbhnCwMPP/881t81rXXXptmz55dvx4yZEiu8hIAAAAAOsq/S+FK6IMPPkhf/vKX00svvVR/bMCAAen+++/P9TJsK1kAmVUxfvOb3wxVgM15+OGH09e//vX08ccfhx6DEydObPHaSZMmpdtvvz2tXLkyt86Cx2y4y5FHHtno+dmwlO985zvh2Lnnntvhk6IBoBBV1bUleW5dzciSPBcAACpJWYSGhxxySHrmmWfCsVNPPTW99dZb6cEHHyzqXrvssksaOHBgo5+bN29eOu6443JB3Lhx43LP/dznPrfGcJUsIHz22WfT5MmT069+9av60C/TvXv39LOf/azZV5NXGz58eDrhhBPSlVdeWX/s6KOP/v/t3QlwlOUdx/EnwXAlgWAIpxBu5QokHPGYJhxiBVGQqRxBiowzoFhUUFCQQg8YKtaLaR2xiNZyFLFAKdhBkKMGlCpeISA0QghgVK4AgRyQvJ3/28l2n80e7yabPb+fma2zm/fd903n/fFs/vs8/1cdPnxYzZw503aechfm1atXm79zUVGRbduUlBQ1efJkr35/AAAAAAAAoLaiDFk3G2BRUVE+e69du3apQYMGOf2Z9AqcMmVKtdelX6IsJ46NjVWXLl1SBQUFqri42Ol5vvrqq2rGjBmWz+fq1asqMzPTLELak9mDsuy6QYMGZq9Dx+M1b95c7d27V3Xr1k0FmswA7dWrl+35rWqYiosKzF2sAQBgpmFwzwQFAADA/xQbF9Un6v83uz148KDq2bOnChVBMdMw0GQGojzckSXJf/7zn82+i96QGYnbtm0zZzbKUucq5eXl6siRI0736dChg9q8eXNQFAwBAAAAAAAQeSKqaDhkyBCzz6DMRjxw4IDZS9EdWYrct29fNXXqVLMPopUlyc7ILEbppyh3YF66dKnKy8tzuZ30Spw7d66Ki4ur0bEAAAh3VmbQMRsRAAAACIPlyYEgv7bcqVkKeCdPnjR7CZaWlppLlKXXYLt27dTAgQNVkyZNfH7snJwc9fnnn6vCwkKzf2JiYqK5/Dc9PV3FxMSoYMPyZABAqKFoyPJkAACAQCtmeXJokv6EXbp0MR/+1rt3b/MBAAAAAAAABKPoQJ8AAAAAAAAAgOBC0RAAAAAAAACAhqIhAAAAAAAAAA1FQwAAAAAAAACaiL0RCqwrKyvTnl9VxUpF5D23AQChorzwexXp5G59AAAACJyrUj9xU18JdhQN4dHJkye151+rjwN2LgAAWPL8dhXpvgv0CQAAAKBafSUtLU2FCpYnAwAAAAAAANBQNAQAAAAAAACgiTIMg+50cKuoqEjt2bNHFRQUqMcff9z2+qZNm1SXLl0Cem5AuMjLy1OjR4+2PSdfgG+RMaBukTGg7pAvIHQzVlZWprV8y8zMVAkJCSpU0NMQHskFPWrUKJWbm6u9LiHq2bNnwM4LCGfkC6hbZAyoW2QMqDvkCwitjKWFUA9DRyxPBgAAAAAAAKChaAgAAAAAAABAQ9EQAAAAAAAAgIaiIQAAAAAAAAANRUMAAAAAAAAAGoqGAAAAAAAAADQUDQEAAAAAAABoKBoCAAAAAAAA0FA0BAAAAAAAAKChaAgAAAAAAABAQ9EQAAAAAAAAgOYG/SngWlJSklq4cKH2HIBvkC+gbpExoG6RMaDukC+gbpEx16IMwzDc/BwAAAAAAABAhGF5MgAAAAAAAAANRUMAAAAAAAAAGoqGAAAAAAAAADQUDQEAAAAAAABoKBoCAAAAAAAA0FA0BAAAAAAAAKChaAgAAAAAAABAQ9EQAAAAAAAAgIaiIQAAAAAAAAANRUMAAAAAAAAAGoqGAAAAAAAAADQUDQEAAAAAAABoKBoCAAAAAAAA0NygPwWc+/bbb9W///1vderUKVVeXq6aNWumbrnlFnX77berhg0bBvr0gIhSWlqq9u3bp7755ht14cIFVb9+fXXTTTep9PR01alTp0CfHhCxeWGsBOoO+UKgGYah8vPzVU5OjnkdFhUVqQYNGpjXYteuXdWAAQN8fi1evnxZ7d27Vx09elRdunRJNWrUSCUnJ5vXfZs2bXx6rNzcXHXgwAFVWFioKioqVGJiourVq5c5Xt5wA2UDhGfG/Ck3VDNmAG5s3LjRSEtLM+RScfaIi4szfvGLXxhnzpwJ9KkCfrVw4UKXubDymDx5stfH/PHHH43HHnvMiI2Ndfm+/fr1MzZt2lQnvzPgC6dOnTI2bNhgPPPMM8bgwYON+Ph47RpOTk72yXH8mRfGSkRCvmoz5snj+PHjNTou+UIgnT9/3li5cqUxduxYo3nz5m6v8ZiYGGP06NHG7t27a33cY8eOGQ8++KBRv359p8eKiooyBg0aZOzZs6dWx6msrDTefPNNo1u3bi5/r8TERGP+/PlGcXFxrX8vIFAZkzGotuNYpGaMoiGcKi0tNSZOnGg5QElJSbUetIBQ4u+i4a5duzwOpPaPn//850ZZWVmd/f6AN7Kzs43777/faNOmjcdr1xdFQ3/lhbESkZQvfxcNyRcCbfr06S6LdlbGlYsXL9bouOvWrTMaN25s6ThSPJQvCaQw4a0LFy4Yw4YNs/w7derUyTh48GCNficg0BkLRNHwQphkjJ6GqKayslKNGzdOrV69Wnu9Xr16qmPHjqpv376qadOm2s/OnDmjhg8frj7++GM/ny0Q/rKzs9WIESPU2bNntdcTEhJUamqq6tChg5lPe++8846aMGGCOc0fCLRPP/1Ubdy4UX333XdhkxfGSkRivvyFfCEY7N+/31wK70iuQ2lz0a9fP5WSklLtWqwaV4YNG6aKi4u9Oub69evN8ejq1ava60lJSSotLc08blRUlO11Gbeef/55NWvWLK+OU1JSon7605+q7du3a69LC49u3bqp3r17q9jYWO1nx44dU4MHD1Z5eXleHQsIpoz5S0kYZSyIF04jUF544QX197//XXvtkUceUb/85S9tvTPkw5xs8+STT6qCggLzNRncxo4dqw4ePOg02EA4+/3vf6/69OljeXurfWikB5v84SQDTxXpZfPqq6+q++67z/bBUfp+LFq0SC1fvty23YYNG9TLL7/s9QdJwJ/i4uJ89oHPn3lhrESk5cue/BH34osverVPq1atLG9LvhBs5IunrKwsdc8996if/OQnKj4+3vYz6U320UcfqQULFpj/rSI9OB966CH13nvvWe7bOWXKFPPariKfLWVskkJClSNHjqh58+aZ41aVV155xTyvMWPGWDqWjHVyflWio6PVc889p2bOnGn2jxNSzFmzZo25rYyvVcV5yZh8WeH4BRwQ7Bmzd9ddd6nZs2erujIrnDIW6KmOCC5nz56t1v9myZIlbnvndOjQQdt+wYIFfj1nIBiWJ8tyyLowd+5c7TgdO3Y0Tp8+7XL7xYsXa9s3bdrU7BUCBNLLL79sXo8yvkgPptmzZxvr16838vPzzez4avmkv/LCWIlIzJf9+2RmZhp1hXwhWEjfW7m2VqxYYVy9etXj9tevXzemTp1abcnhzp07LR1vwoQJ2n4DBgxwufxSliM7Hqtz587GtWvXPB7n8OHDRr169bR916xZ43J7WS6ZkJCgbS896IBQypjj8uSa9Je3KtwyRtEQmjlz5mgXa0ZGhsceGTt27ND2kQ968oEPCGf+KBrKjRykwbv9cSRv7kheJbf2+8ybN8/n5wZ4Iy8vz8jNzTUqKiqq/cxXRQ1/5oWxEpGWL38WDckXgsWWLVu87ncrRY3+/ftr12NWVpbH/aRoEB0dbdtH+rwdOnTI7T4lJSVG165dtWO98cYbHo8lN5yw32fSpEke95GijuO/JeXl5R73A4IlY/4sGo4Ns4zR0xA2MhX+rbfe0l771a9+pfXNcGbo0KHmFOIqly9fVu+++26dnScQKf76179qy8oyMjLMvLkjeV24cKH22sqVK+ltiIDq3Lmz6tGjh7k0I9TzwliJSMyXv5AvBBNZJin9x7whywnnzJmjvbZt2zaP+8nYY78sefz48ap79+5u92nYsKF69tlntddWrFjhdh9ZAmm/rFmyJRnzRJZNS7uPKidOnFA7duzwuB8QLBnzlwthmLHQ/3QBn9m3b5+5hr5Kp06d1KBBgyzt+/DDD2vPN23a5PPzAyKNYz8nx5y5In1vpFF8le+//1598sknPj8/IBLzwlgJ1B3yhXBgX8AW586dq3ZjE0ebN2+u0RgmfXztb6YgfdDc3RRp69at6vr167bnki/JmSfypYQUNeyRMYRSxvxlaxhmjKIhtAvcntyNyNM3u/bb2tu9e7e6cuWKT88PiCQyY+pf//pXtYa9Vkhu77zzTu21LVu2+PT8gEjNC2MlUHfIF8JB1U0O7F28eNHl9nJjE/u7pUoR8Pbbb7d0LMdtZaa8Y47sOf7M6ljpLGN8tkSoZMyftoZhxigawubLL7/UnlsdrITcya5Dhw6253InoEOHDvn0/IBIkpubq65du2Z7LjOhvLnz5B133OE230A48WdeGCuBukO+EA5Onz5d7bXExETL1/3AgQPVDTfcEHRjWL9+/VSDBg1sz2VGo/3MYCBYM+ZPX4Zhxigawubw4cPac+mP4w3H7R3fDwh3ZWVl5nWfnZ2t9u/fb35rXNOp8uQRCM68kE3g/woLC9WBAwfMmb45OTnm89ogXwgHH330kfZc+pS569vmr+tevlyzn9Ho7bGkmCE9VK0cCwimjLlz8uRJc1m/vKd8CV2bIt21MM2Y9a8wENZKSkpUQUGB9lq7du28eg/H7WWqPRApHnvsMXXs2DFVWlqqvS7fFMu3RsOHD1fTp09XSUlJlt7PMT+1zaM005Vzk6bZQLjxV14YK4H/kQKh9Gg6fvx4tZ/JLN/MzEz10EMPqbvvvtvye5IvhAu5qYm9ESNG+HUMc3Xdy+dU+15rjRo1Us2bN/f6WPYzeOVYcuMxIJgz5swHH3xgzlB39mWXzFqXXoRTp05Vt912m+X3DNeMMdMQprNnz2p3i4yJiVEtWrTw6j3atm2rPf/xxx99dn5AsJN/3B0LhkIGDpl1KHfNkm/BFixYoCoqKjy+n2N+brrpJq/Op2XLltrSFrkjnzQJBsKRv/LCWAn8z/nz550WDKtuJrRu3Trzy7K0tDSzwGgF+UI4eP/996v12JUCel2OYY7XvauZUo7HcdyvJsciYwiFjDkjxUJXs+Pz8/PV22+/bS4tHjp0aLUvtFwJ14xRNIStiby9xo0bW248XcX+zl3O3hOIdDKL4re//a150wVP+XD8uWO+PJH8yrdb7t4TCBf+ygtjJeCdL774QqWnp6v169d73JZ8IRyK6dOmTdNeGz16tNmjsC7HMMftZYmktMzx9XGc7UPGEAoZq42dO3eq1NTUaoVKZ8I1YxQN4fRirMkSRgoUiDTyx4x8A7V48WK1fft2derUKbOHocw4lAa9//jHP8yBzTFPckfH8ePHu51xSCYB6/yVF3KJSCfLrGRGx6pVq9TXX39t/gEnBYoLFy6or776Sv3hD39Qffr0qfaF2YMPPujxDy7yhVAmM9TlOpfPglWaNm2qli1b5nHf2l77jte9s/f0xXGcHYuMIRQy5jiT99FHHzW/zJJ+gUVFReY4JrPdpbfh0qVLzfYb9s6fP69GjRqlvvnmG7fvHa4Zo6chTI7LKmvSSNT+Tj9VHxKBcHXXXXeprKws1a1bN6c/lx4Z8hg5cqSaP3++WSTcu3ev7edbt25Vr732mpoxY4bT/ckkYJ2/8kIuEcmkUPjAAw84ve4TEhLMR0pKitnjd/ny5eqJJ56wzXaSOxnLmCkN4l39EUW+EMpmz56t/vnPf2qvSQ6s9Ces7bXveN0LxjCEm9pkrKrAuHnzZnXPPfeo6Ohop3dflkf//v3VrFmzzNVh8qisrDR/LsVFKVpKYdHVLPhwzRgzDWFy/AAnH+685TgNnhsuIJzJDENXBUNn32jt2LGjWiPdRYsWuby7MpkErPNXXsglItnEiRMt/wEks+zXrFmj/WEmM/D/+Mc/utyHfCFUyUynl156SXttzpw5aty4cZb2r+2172wpMmMYwkltMyaaNWum7r33XqcFQ0f16tUz+9E7HvPAgQNqw4YNLvcL14xRNIQpLi5Oe+7shg6eOFbBHd8TiGTyD/4777yj3WxBGtvKnbucIZOAdf7KC7kErBszZoyaNGmS9tpf/vIXl9uTL4QiKY4/+eST2muyhP93v/ud5feo7bXvbCYSYxjChS8yVlMyYz4zM1NF+jhG0RBOL0aZ/WR/Bzsrrly54vY9gUjXpUsXdd9992mvWS0aOubLE8lvMA46QF3wV14YKwHvPPXUU9pz6YP4ww8/ON2WfCHUbNmyRU2ePFm7TqVYvmLFCq9u4lPbMcxxe/mC2tnspNoex9k+ZAyhkDFfjmM7d+5U169fd7ptuGaMoiFsja3tgyfNQL29vbcsO7HXokULn50fEC6GDh2qPT9y5IjT7RzzY9/01wr5o8x+QJOp+JJzIBz5Ky+MlYB3evfurV3j8off0aNHnW5LvhBKdu3aZfb4tB87hg0bptauXWsubfTnGOZ43SclJVk6juN+NTkWGUMoZKw2hgwZoo1Nly9fVoWFhRGVMYqGsN2lp3379tprBQUFXr2H4/a33HKLT84NCCeOzXrPnDnjdLubb77Zp3lMTk4Oip4YQF3wV14YKwHvSV9fK+Me+UKo2L9/v7lyxH7pofS63rhxY41ufODrMczVdS93hLVvkyMz7F3lsbbHAoIpY7URGxtr9kO05yo34ZoxioZweUEeOnTIq/3lluXu3g+AUjExMdpzmUnhDHkErPNnXsgmUDfjniBfCHayxH748OGquLjY9lpqaqp6//33zeJCTfjrupcsdu7cucbHkhs0HDt2zNKxgGDKmL/GsZgwzRhFQ9j07dtXe75v3z7L+8oU3fz8fC0wPXr08On5AeHg+++/t7SEpGfPntoAJflyNRXemb1797rNNxBO/JkXxkqgbsY9Qb4QzKSljCyPvHDhgu217t27q23btqmmTZvW+H0dr/tPP/3UZc+0QI5hcudY+zu7tm7dOiiWTiJ81FXGauP69evq3LlzfhnHgjVjFA1hM3LkSO35jh07LDegdryZw+DBg4OiaScQbLKzs90uV64SHx+vMjIytNe2b99u6RiSW8mvvXvvvdfrcwVChT/zwlgJWCe92U6cOGFp3BPkC8FKruM777xT67PZsWNHc6xxV0CwQmYS2c9OkhshWC00yLYff/yx7bn0XnPMkT3Hn1kdK51ty2dLhErGauOTTz7Riviy/LhVq1YRlTGKhtD6BNg3fpepsbt377a075tvvqk9HzVqlM/PDwh1RUVF6m9/+5vbG6PYc7zTsmPO3DUOPn78uO15y5YtVXp6utfnC4QSf+WFsRKwzvGal4Jh165dXW5PvhCMZBarfF6zv0FJ27Zt1Ycffmj+N5Bj2Lp167RlnP3791dt2rRxuf2IESO0nmuSL8flkM5I8f7tt9/WXiNjCKWM1dSbDlm87bbbVOPGjSMrYwZg5+mnn5avc22PzMxMo7Ky0u0+O3bs0PaJj483zpw547dzBkLFww8/rGWlfv36xnfffedy+x9++MGIjY3V9vnwww/dHkPympGRoe3z7LPP1sFvA/jGrl27tOs1OTm5Ru/jz7wwViLS8lUThw4dMq9z++PPmDHD437kC8Hk3LlzRs+ePbXrKykpyby+fSknJ8eIiorSPiN6OkZJSYnRtWtX7dxef/11j8f62c9+pu0zadIkj/usWLGi2r8lZWVlXv2OQCAzVtMxtF69etq5vfjiixGXMYqG0MgHrLi4OO2CXbJkicvtT506ZXTo0EHbfv78+X49Z8DfJBOfffaZ5e2vXbtmzJo1S8uJPB5//HGP+z7zzDPaPh07djROnz7tcvvFixdr2zdt2tQcjIFIKGr4Ky+MlYikfH3xxRfGSy+9ZFy5csWrfdq3b68du1GjRm7zWIV8IVhcunTJGDBggHZtJSQkmNd3XRg3bpx2LDn2xYsXnW4rhfRp06Zp23fq1MkoLy/3eJzc3FwjOjpa23fNmjVut5ff2357KXAAoZKxDz74wFi5cqX5N5lV8sVzs2bNtHNr3bq1pbEw3DIWJf8T6NmOCC5LlixR8+bN01579NFH1fz5823T3SsrK9XmzZvVE088od0WXH6em5urEhIS/H7egL8MGjRI7dmzx1xGNXbsWHM6vfSjsZ+KLi5evGje6Wvp0qXqyy+/1H4mvWv279+vEhMT3R7r/Pnz5k0e7BvJJycnq2XLlpl9LqR3jZDp/IsWLVLLly/X9pdjz5492we/NVA70qi9pKSk2utfffWVevrpp7XlwatWrXL6HjLGuLuxgT/zwliJSMmXLK2S/oAyXo0ZM0bdf//9asCAAdoyYiF/Uhw8eFD96U9/Um+88YbWzF288sorZhasIF8IBnLdOy6P/81vfmMuT/RWv379VLNmzdxuk5eXp/r06aOuXr1qe02eS3bks2eVo0ePqrlz56oNGzZo+7/77rvqgQcesHQ+06ZNM3NaJTo6Wj333HNq5syZtvOUO8SuXr1azZo1S7sxRUpKinnDBsfPvUCwZkyW/U6ZMsVc6iwZkXYAaWlp1W6uUlFRoT777DP12muvmWOljDP2GXnvvffMMTDiMhboqiWCT0VFhTFy5Mhqs6Jkaq58g5WamlqtEl71DXJ2dnagTx+oc7JUyvH6b9CggdG5c2cjLS3N/MZMsuL4DVPVo1WrVsbRo0ctH2/Pnj1Gw4YNq72P5FDyKLOpHKfOy2PUqFEel3QB/iIznJzlwZvH5MmTgyYvjJWIlHw5zlaserRs2dJcUnbrrbcavXr1qjYjw/7x1FNPefX7kC8Eg9pmyv4hObJi7dq12jJl++Wa/fr1M9q1a+f051aW/tuT2VL9+/ev9j6yLPrmm282UlJSqs34lUfz5s2NI0eO1PD/USAwGXvrrbec7tO2bVujd+/e5jjWo0cPp9e8UsrM3LJlyyI2YxQN4bJHxvjx4y2HNDEx0fJgCIRj0dDqY8SIEWbvNW/JFPkbb7zR8nGysrKM0tLSOvn9gWAuGvozL4yViOSioZVHkyZNjFWrVtXodyJfCLTaZsr+4c21KcsYpQBu9b2lD2hNviSWdhxDhgyxfBxpA/D11197fRwgWIuGVh6tW7c2lzfXRLhkjLsnw6mGDRuqtWvXmlNw+/bt63K72NhYNX36dHXo0CFt2jwQzmRq+SOPPGIug6xXr57H7ePi4syp8LKkeevWrapFixZeH3PIkCFmzmR5lrs7dqWmppp3aJap7g0aNPD6OEA48FdeGCsRCXr37q2ef/55dffdd6sbb7zR0j7SskOW++fn56uJEyfW6LjkC5FqwoQJ5lL/rKwsFRMT43K7jIwMc2nnCy+8YGu/4Q3J8/bt280llF26dHG7nbQLyMnJMf89AELxc+Gvf/1rc4yIj4/3uL0sJZbly6+//rrZNmDYsGE1Om64ZIyehrBEwiL9106fPq3Ky8vNPjHdu3dXd9xxh/mhDohU0ndG/lCRP4wKCwtVcXGx2f9CMiL9KqQ/lPzjb6W4aJX0rdq3b586fPiwKioqUvXr1zd7dKSnp7sdkIBI5M+8MFYiEpw4cUL95z//MfsISg8myZhc3zLmtW7d2syWp369NUG+EIkuXbqksrOzzcxdvnzZvNbbt29vXvcylvmSFCw+//xz8/Os9HaTHPfq1cvMtLviJRBKpPz17bffmmPKyZMnzc+GpaWl5hdQMo61a9dODRw4UDVp0sTnx84J0YxRNAQAAAAAAACgYXkyAAAAAAAAAA1FQwAAAAAAAAAaioYAAAAAAAAANBQNAQAAAAAAAGgoGgIAAAAAAADQUDQEAAAAAAAAoKFoCAAAAAAAAEBD0RAAAAAAAACAhqIhAAAAAAAAAA1FQwAAAAAAAAAaioYAAAAAAAAANBQNAQAAAAAAAGgoGgIAAAAAAADQUDQEAAAAAAAAoKFoCAAAAAAAAEBD0RAAAAAAAACAhqIhAAAAAAAAAA1FQwAAAAAAAAAaioYAAAAAAAAANBQNAQAAAAAAAGgoGgIAAAAAAADQUDQEAAAAAAAAoKFoCAAAAAAAAEBD0RAAAAAAAACAhqIhAAAAAAAAAA1FQwAAAAAAAAAaioYAAAAAAAAANBQNAQAAAAAAAGgoGgIAAAAAAADQUDQEAAAAAAAAoKFoCAAAAAAAAEBD0RAAAAAAAACAhqIhAAAAAAAAAA1FQwAAAAAAAAAaioYAAAAAAAAANBQNAQAAAAAAAGgoGgIAAAAAAABQ9v4LlRhG2SN53gIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get fake images and append to orignal X_train and Y_train\n",
    "my_X_train, my_X_test, my_Y_train, my_Y_test = train_test_split(X_train, Y_train, test_size=0.5, random_state=42)\n",
    "#my_Y_test is the respective labels for the fake cells.\n",
    "plt.imshow(my_Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90185f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fake shape: torch.Size([80, 3, 256, 256])\n",
      "X_train_with_fake shape: torch.Size([240, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "image_paths = sorted(glob.glob(\"fake_cells_train/*_fake_B.png\"))\n",
    "\n",
    "image_tf = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "fake_images = [image_tf(Image.open(p)) for p in image_paths]\n",
    "\n",
    "X_fake = torch.stack(fake_images)\n",
    "Y_fake = my_Y_test\n",
    "\n",
    "print(\"X_fake shape:\", X_fake.shape) #should be (N, 3, 256, 256)\n",
    "\n",
    "#combine\n",
    "X_train_with_fake = torch.cat([X_train, X_fake], dim=0)\n",
    "Y_train_with_fake = torch.cat([Y_train, Y_fake], dim=0)\n",
    "\n",
    "print(\"X_train_with_fake shape:\", X_train_with_fake.shape) #should be (160+80, 3, 256, 256), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c83d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training: Epoch 1, Batch 0, Loss: 1.1\n",
      "Training: Epoch 1, Batch 1, Loss: 1.105\n",
      "Training: Epoch 1, Batch 2, Loss: 1.103\n",
      "Training: Epoch 1, Batch 3, Loss: 1.106\n",
      "Training: Epoch 1, Batch 4, Loss: 1.095\n",
      "Training: Epoch 1, Batch 5, Loss: 1.099\n",
      "Training: Epoch 1, Batch 6, Loss: 1.101\n",
      "Training: Epoch 1, Batch 7, Loss: 1.085\n",
      "Training: Epoch 1, Batch 8, Loss: 1.094\n",
      "Training: Epoch 1, Batch 9, Loss: 1.09\n",
      "Training: Epoch 1, Batch 10, Loss: 1.089\n",
      "Training: Epoch 1, Batch 11, Loss: 1.089\n",
      "Training: Epoch 1, Batch 12, Loss: 1.087\n",
      "Training: Epoch 1, Batch 13, Loss: 1.081\n",
      "Training: Epoch 1, Batch 14, Loss: 1.082\n",
      "Training: Epoch 1, Batch 15, Loss: 1.085\n",
      "Training: Epoch 1, Batch 16, Loss: 1.083\n",
      "Training: Epoch 1, Batch 17, Loss: 1.083\n",
      "Training: Epoch 1, Batch 18, Loss: 1.075\n",
      "Training: Epoch 1, Batch 19, Loss: 1.067\n",
      "Training: Epoch 1, Batch 20, Loss: 1.075\n",
      "Training: Epoch 1, Batch 21, Loss: 1.067\n",
      "Training: Epoch 1, Batch 22, Loss: 1.071\n",
      "Training: Epoch 1, Batch 23, Loss: 1.058\n",
      "Training: Epoch 1, Batch 24, Loss: 1.07\n",
      "Training: Epoch 1, Batch 25, Loss: 1.059\n",
      "Training: Epoch 1, Batch 26, Loss: 1.055\n",
      "Training: Epoch 1, Batch 27, Loss: 1.043\n",
      "Training: Epoch 1, Batch 28, Loss: 1.05\n",
      "Training: Epoch 1, Batch 29, Loss: 1.056\n",
      "Val: Epoch 1, Loss: 1.051\n",
      "Training: Epoch 2, Batch 0, Loss: 1.063\n",
      "Training: Epoch 2, Batch 1, Loss: 1.042\n",
      "Training: Epoch 2, Batch 2, Loss: 1.034\n",
      "Training: Epoch 2, Batch 3, Loss: 1.04\n",
      "Training: Epoch 2, Batch 4, Loss: 1.028\n",
      "Training: Epoch 2, Batch 5, Loss: 1.016\n",
      "Training: Epoch 2, Batch 6, Loss: 1.003\n",
      "Training: Epoch 2, Batch 7, Loss: 1.023\n",
      "Training: Epoch 2, Batch 8, Loss: 0.975\n",
      "Training: Epoch 2, Batch 9, Loss: 0.963\n",
      "Training: Epoch 2, Batch 10, Loss: 0.998\n",
      "Training: Epoch 2, Batch 11, Loss: 1.004\n",
      "Training: Epoch 2, Batch 12, Loss: 0.968\n",
      "Training: Epoch 2, Batch 13, Loss: 0.958\n",
      "Training: Epoch 2, Batch 14, Loss: 0.964\n",
      "Training: Epoch 2, Batch 15, Loss: 0.926\n",
      "Training: Epoch 2, Batch 16, Loss: 0.929\n",
      "Training: Epoch 2, Batch 17, Loss: 0.906\n",
      "Training: Epoch 2, Batch 18, Loss: 0.9\n",
      "Training: Epoch 2, Batch 19, Loss: 0.979\n",
      "Training: Epoch 2, Batch 20, Loss: 0.882\n",
      "Training: Epoch 2, Batch 21, Loss: 0.939\n",
      "Training: Epoch 2, Batch 22, Loss: 0.841\n",
      "Training: Epoch 2, Batch 23, Loss: 0.87\n",
      "Training: Epoch 2, Batch 24, Loss: 0.84\n",
      "Training: Epoch 2, Batch 25, Loss: 0.86\n",
      "Training: Epoch 2, Batch 26, Loss: 0.886\n",
      "Training: Epoch 2, Batch 27, Loss: 0.84\n",
      "Training: Epoch 2, Batch 28, Loss: 0.832\n",
      "Training: Epoch 2, Batch 29, Loss: 0.814\n",
      "Val: Epoch 2, Loss: 0.697\n",
      "Training: Epoch 3, Batch 0, Loss: 0.792\n",
      "Training: Epoch 3, Batch 1, Loss: 0.811\n",
      "Training: Epoch 3, Batch 2, Loss: 0.652\n",
      "Training: Epoch 3, Batch 3, Loss: 0.892\n",
      "Training: Epoch 3, Batch 4, Loss: 0.715\n",
      "Training: Epoch 3, Batch 5, Loss: 0.623\n",
      "Training: Epoch 3, Batch 6, Loss: 0.831\n",
      "Training: Epoch 3, Batch 7, Loss: 0.746\n",
      "Training: Epoch 3, Batch 8, Loss: 0.632\n",
      "Training: Epoch 3, Batch 9, Loss: 0.804\n",
      "Training: Epoch 3, Batch 10, Loss: 0.843\n",
      "Training: Epoch 3, Batch 11, Loss: 0.986\n",
      "Training: Epoch 3, Batch 12, Loss: 0.68\n",
      "Training: Epoch 3, Batch 13, Loss: 0.695\n",
      "Training: Epoch 3, Batch 14, Loss: 0.563\n",
      "Training: Epoch 3, Batch 15, Loss: 0.642\n",
      "Training: Epoch 3, Batch 16, Loss: 0.581\n",
      "Training: Epoch 3, Batch 17, Loss: 0.839\n",
      "Training: Epoch 3, Batch 18, Loss: 0.707\n",
      "Training: Epoch 3, Batch 19, Loss: 0.607\n",
      "Training: Epoch 3, Batch 20, Loss: 0.62\n",
      "Training: Epoch 3, Batch 21, Loss: 0.581\n",
      "Training: Epoch 3, Batch 22, Loss: 0.747\n",
      "Training: Epoch 3, Batch 23, Loss: 0.998\n",
      "Training: Epoch 3, Batch 24, Loss: 0.93\n",
      "Training: Epoch 3, Batch 25, Loss: 0.955\n",
      "Training: Epoch 3, Batch 26, Loss: 0.852\n",
      "Training: Epoch 3, Batch 27, Loss: 0.671\n",
      "Training: Epoch 3, Batch 28, Loss: 0.603\n",
      "Training: Epoch 3, Batch 29, Loss: 0.921\n",
      "Val: Epoch 3, Loss: 0.471\n",
      "Training: Epoch 4, Batch 0, Loss: 0.835\n",
      "Training: Epoch 4, Batch 1, Loss: 0.745\n",
      "Training: Epoch 4, Batch 2, Loss: 0.807\n",
      "Training: Epoch 4, Batch 3, Loss: 0.681\n",
      "Training: Epoch 4, Batch 4, Loss: 0.771\n",
      "Training: Epoch 4, Batch 5, Loss: 0.7\n",
      "Training: Epoch 4, Batch 6, Loss: 0.787\n",
      "Training: Epoch 4, Batch 7, Loss: 0.831\n",
      "Training: Epoch 4, Batch 8, Loss: 0.758\n",
      "Training: Epoch 4, Batch 9, Loss: 0.613\n",
      "Training: Epoch 4, Batch 10, Loss: 0.477\n",
      "Training: Epoch 4, Batch 11, Loss: 0.549\n",
      "Training: Epoch 4, Batch 12, Loss: 0.622\n",
      "Training: Epoch 4, Batch 13, Loss: 0.636\n",
      "Training: Epoch 4, Batch 14, Loss: 0.659\n",
      "Training: Epoch 4, Batch 15, Loss: 0.552\n",
      "Training: Epoch 4, Batch 16, Loss: 0.75\n",
      "Training: Epoch 4, Batch 17, Loss: 1.048\n",
      "Training: Epoch 4, Batch 18, Loss: 0.648\n",
      "Training: Epoch 4, Batch 19, Loss: 0.75\n",
      "Training: Epoch 4, Batch 20, Loss: 0.812\n",
      "Training: Epoch 4, Batch 21, Loss: 0.596\n",
      "Training: Epoch 4, Batch 22, Loss: 0.536\n",
      "Training: Epoch 4, Batch 23, Loss: 0.59\n",
      "Training: Epoch 4, Batch 24, Loss: 0.987\n",
      "Training: Epoch 4, Batch 25, Loss: 0.777\n",
      "Training: Epoch 4, Batch 26, Loss: 0.613\n",
      "Training: Epoch 4, Batch 27, Loss: 0.823\n",
      "Training: Epoch 4, Batch 28, Loss: 0.892\n",
      "Training: Epoch 4, Batch 29, Loss: 0.677\n",
      "Val: Epoch 4, Loss: 0.457\n",
      "Training: Epoch 5, Batch 0, Loss: 0.78\n",
      "Training: Epoch 5, Batch 1, Loss: 0.678\n",
      "Training: Epoch 5, Batch 2, Loss: 0.604\n",
      "Training: Epoch 5, Batch 3, Loss: 0.601\n",
      "Training: Epoch 5, Batch 4, Loss: 1.026\n",
      "Training: Epoch 5, Batch 5, Loss: 0.767\n",
      "Training: Epoch 5, Batch 6, Loss: 1.002\n",
      "Training: Epoch 5, Batch 7, Loss: 0.916\n",
      "Training: Epoch 5, Batch 8, Loss: 0.589\n",
      "Training: Epoch 5, Batch 9, Loss: 0.753\n",
      "Training: Epoch 5, Batch 10, Loss: 0.657\n",
      "Training: Epoch 5, Batch 11, Loss: 0.665\n",
      "Training: Epoch 5, Batch 12, Loss: 0.766\n",
      "Training: Epoch 5, Batch 13, Loss: 0.658\n",
      "Training: Epoch 5, Batch 14, Loss: 0.721\n",
      "Training: Epoch 5, Batch 15, Loss: 0.86\n",
      "Training: Epoch 5, Batch 16, Loss: 0.627\n",
      "Training: Epoch 5, Batch 17, Loss: 0.635\n",
      "Training: Epoch 5, Batch 18, Loss: 0.619\n",
      "Training: Epoch 5, Batch 19, Loss: 0.893\n",
      "Training: Epoch 5, Batch 20, Loss: 0.664\n",
      "Training: Epoch 5, Batch 21, Loss: 0.537\n",
      "Training: Epoch 5, Batch 22, Loss: 0.672\n",
      "Training: Epoch 5, Batch 23, Loss: 0.53\n",
      "Training: Epoch 5, Batch 24, Loss: 0.674\n",
      "Training: Epoch 5, Batch 25, Loss: 0.635\n",
      "Training: Epoch 5, Batch 26, Loss: 0.606\n",
      "Training: Epoch 5, Batch 27, Loss: 0.789\n",
      "Training: Epoch 5, Batch 28, Loss: 0.873\n",
      "Training: Epoch 5, Batch 29, Loss: 0.854\n",
      "Val: Epoch 5, Loss: 0.474\n",
      "Training: Epoch 6, Batch 0, Loss: 1.065\n",
      "Training: Epoch 6, Batch 1, Loss: 0.791\n",
      "Training: Epoch 6, Batch 2, Loss: 0.635\n",
      "Training: Epoch 6, Batch 3, Loss: 0.874\n",
      "Training: Epoch 6, Batch 4, Loss: 0.618\n",
      "Training: Epoch 6, Batch 5, Loss: 0.858\n",
      "Training: Epoch 6, Batch 6, Loss: 0.682\n",
      "Training: Epoch 6, Batch 7, Loss: 0.68\n",
      "Training: Epoch 6, Batch 8, Loss: 0.648\n",
      "Training: Epoch 6, Batch 9, Loss: 0.838\n",
      "Training: Epoch 6, Batch 10, Loss: 0.574\n",
      "Training: Epoch 6, Batch 11, Loss: 0.611\n",
      "Training: Epoch 6, Batch 12, Loss: 0.731\n",
      "Training: Epoch 6, Batch 13, Loss: 0.545\n",
      "Training: Epoch 6, Batch 14, Loss: 0.943\n",
      "Training: Epoch 6, Batch 15, Loss: 0.95\n",
      "Training: Epoch 6, Batch 16, Loss: 0.712\n",
      "Training: Epoch 6, Batch 17, Loss: 0.787\n",
      "Training: Epoch 6, Batch 18, Loss: 0.58\n",
      "Training: Epoch 6, Batch 19, Loss: 0.555\n",
      "Training: Epoch 6, Batch 20, Loss: 0.721\n",
      "Training: Epoch 6, Batch 21, Loss: 0.515\n",
      "Training: Epoch 6, Batch 22, Loss: 0.521\n",
      "Training: Epoch 6, Batch 23, Loss: 0.471\n",
      "Training: Epoch 6, Batch 24, Loss: 0.725\n",
      "Training: Epoch 6, Batch 25, Loss: 0.717\n",
      "Training: Epoch 6, Batch 26, Loss: 0.617\n",
      "Training: Epoch 6, Batch 27, Loss: 0.502\n",
      "Training: Epoch 6, Batch 28, Loss: 0.914\n",
      "Training: Epoch 6, Batch 29, Loss: 0.445\n",
      "Val: Epoch 6, Loss: 0.432\n",
      "Training: Epoch 7, Batch 0, Loss: 0.689\n",
      "Training: Epoch 7, Batch 1, Loss: 0.742\n",
      "Training: Epoch 7, Batch 2, Loss: 0.603\n",
      "Training: Epoch 7, Batch 3, Loss: 0.718\n",
      "Training: Epoch 7, Batch 4, Loss: 0.732\n",
      "Training: Epoch 7, Batch 5, Loss: 0.625\n",
      "Training: Epoch 7, Batch 6, Loss: 0.651\n",
      "Training: Epoch 7, Batch 7, Loss: 0.604\n",
      "Training: Epoch 7, Batch 8, Loss: 0.849\n",
      "Training: Epoch 7, Batch 9, Loss: 0.714\n",
      "Training: Epoch 7, Batch 10, Loss: 0.547\n",
      "Training: Epoch 7, Batch 11, Loss: 0.683\n",
      "Training: Epoch 7, Batch 12, Loss: 0.764\n",
      "Training: Epoch 7, Batch 13, Loss: 0.656\n",
      "Training: Epoch 7, Batch 14, Loss: 0.468\n",
      "Training: Epoch 7, Batch 15, Loss: 0.598\n",
      "Training: Epoch 7, Batch 16, Loss: 0.799\n",
      "Training: Epoch 7, Batch 17, Loss: 0.801\n",
      "Training: Epoch 7, Batch 18, Loss: 0.829\n",
      "Training: Epoch 7, Batch 19, Loss: 0.537\n",
      "Training: Epoch 7, Batch 20, Loss: 0.912\n",
      "Training: Epoch 7, Batch 21, Loss: 1.03\n",
      "Training: Epoch 7, Batch 22, Loss: 0.564\n",
      "Training: Epoch 7, Batch 23, Loss: 0.591\n",
      "Training: Epoch 7, Batch 24, Loss: 0.596\n",
      "Training: Epoch 7, Batch 25, Loss: 0.686\n",
      "Training: Epoch 7, Batch 26, Loss: 0.632\n",
      "Training: Epoch 7, Batch 27, Loss: 0.733\n",
      "Training: Epoch 7, Batch 28, Loss: 0.412\n",
      "Training: Epoch 7, Batch 29, Loss: 0.62\n",
      "Val: Epoch 7, Loss: 0.434\n",
      "Training: Epoch 8, Batch 0, Loss: 0.606\n",
      "Training: Epoch 8, Batch 1, Loss: 0.699\n",
      "Training: Epoch 8, Batch 2, Loss: 0.543\n",
      "Training: Epoch 8, Batch 3, Loss: 0.577\n",
      "Training: Epoch 8, Batch 4, Loss: 0.873\n",
      "Training: Epoch 8, Batch 5, Loss: 0.885\n",
      "Training: Epoch 8, Batch 6, Loss: 0.565\n",
      "Training: Epoch 8, Batch 7, Loss: 0.733\n",
      "Training: Epoch 8, Batch 8, Loss: 0.585\n",
      "Training: Epoch 8, Batch 9, Loss: 0.551\n",
      "Training: Epoch 8, Batch 10, Loss: 0.76\n",
      "Training: Epoch 8, Batch 11, Loss: 0.381\n",
      "Training: Epoch 8, Batch 12, Loss: 0.534\n",
      "Training: Epoch 8, Batch 13, Loss: 0.425\n",
      "Training: Epoch 8, Batch 14, Loss: 0.627\n",
      "Training: Epoch 8, Batch 15, Loss: 0.856\n",
      "Training: Epoch 8, Batch 16, Loss: 0.685\n",
      "Training: Epoch 8, Batch 17, Loss: 0.868\n",
      "Training: Epoch 8, Batch 18, Loss: 0.72\n",
      "Training: Epoch 8, Batch 19, Loss: 0.944\n",
      "Training: Epoch 8, Batch 20, Loss: 0.602\n",
      "Training: Epoch 8, Batch 21, Loss: 0.72\n",
      "Training: Epoch 8, Batch 22, Loss: 0.414\n",
      "Training: Epoch 8, Batch 23, Loss: 0.69\n",
      "Training: Epoch 8, Batch 24, Loss: 0.638\n",
      "Training: Epoch 8, Batch 25, Loss: 0.746\n",
      "Training: Epoch 8, Batch 26, Loss: 0.594\n",
      "Training: Epoch 8, Batch 27, Loss: 0.684\n",
      "Training: Epoch 8, Batch 28, Loss: 1.155\n",
      "Training: Epoch 8, Batch 29, Loss: 0.908\n",
      "Val: Epoch 8, Loss: 0.427\n",
      "Training: Epoch 9, Batch 0, Loss: 0.632\n",
      "Training: Epoch 9, Batch 1, Loss: 0.67\n",
      "Training: Epoch 9, Batch 2, Loss: 0.616\n",
      "Training: Epoch 9, Batch 3, Loss: 0.877\n",
      "Training: Epoch 9, Batch 4, Loss: 0.784\n",
      "Training: Epoch 9, Batch 5, Loss: 0.578\n",
      "Training: Epoch 9, Batch 6, Loss: 0.841\n",
      "Training: Epoch 9, Batch 7, Loss: 0.49\n",
      "Training: Epoch 9, Batch 8, Loss: 0.53\n",
      "Training: Epoch 9, Batch 9, Loss: 0.507\n",
      "Training: Epoch 9, Batch 10, Loss: 0.64\n",
      "Training: Epoch 9, Batch 11, Loss: 0.478\n",
      "Training: Epoch 9, Batch 12, Loss: 0.559\n",
      "Training: Epoch 9, Batch 13, Loss: 0.586\n",
      "Training: Epoch 9, Batch 14, Loss: 0.786\n",
      "Training: Epoch 9, Batch 15, Loss: 0.49\n",
      "Training: Epoch 9, Batch 16, Loss: 1.027\n",
      "Training: Epoch 9, Batch 17, Loss: 0.67\n",
      "Training: Epoch 9, Batch 18, Loss: 0.463\n",
      "Training: Epoch 9, Batch 19, Loss: 0.842\n",
      "Training: Epoch 9, Batch 20, Loss: 0.848\n",
      "Training: Epoch 9, Batch 21, Loss: 0.639\n",
      "Training: Epoch 9, Batch 22, Loss: 0.735\n",
      "Training: Epoch 9, Batch 23, Loss: 0.676\n",
      "Training: Epoch 9, Batch 24, Loss: 0.54\n",
      "Training: Epoch 9, Batch 25, Loss: 0.811\n",
      "Training: Epoch 9, Batch 26, Loss: 0.744\n",
      "Training: Epoch 9, Batch 27, Loss: 0.759\n",
      "Training: Epoch 9, Batch 28, Loss: 0.476\n",
      "Training: Epoch 9, Batch 29, Loss: 0.82\n",
      "Val: Epoch 9, Loss: 0.437\n",
      "Training: Epoch 10, Batch 0, Loss: 0.658\n",
      "Training: Epoch 10, Batch 1, Loss: 0.536\n",
      "Training: Epoch 10, Batch 2, Loss: 1.045\n",
      "Training: Epoch 10, Batch 3, Loss: 0.693\n",
      "Training: Epoch 10, Batch 4, Loss: 0.777\n",
      "Training: Epoch 10, Batch 5, Loss: 0.481\n",
      "Training: Epoch 10, Batch 6, Loss: 0.745\n",
      "Training: Epoch 10, Batch 7, Loss: 0.566\n",
      "Training: Epoch 10, Batch 8, Loss: 0.531\n",
      "Training: Epoch 10, Batch 9, Loss: 0.471\n",
      "Training: Epoch 10, Batch 10, Loss: 0.489\n",
      "Training: Epoch 10, Batch 11, Loss: 0.658\n",
      "Training: Epoch 10, Batch 12, Loss: 0.543\n",
      "Training: Epoch 10, Batch 13, Loss: 0.872\n",
      "Training: Epoch 10, Batch 14, Loss: 0.989\n",
      "Training: Epoch 10, Batch 15, Loss: 0.735\n",
      "Training: Epoch 10, Batch 16, Loss: 0.705\n",
      "Training: Epoch 10, Batch 17, Loss: 0.533\n",
      "Training: Epoch 10, Batch 18, Loss: 0.422\n",
      "Training: Epoch 10, Batch 19, Loss: 0.408\n",
      "Training: Epoch 10, Batch 20, Loss: 0.565\n",
      "Training: Epoch 10, Batch 21, Loss: 1.142\n",
      "Training: Epoch 10, Batch 22, Loss: 0.648\n",
      "Training: Epoch 10, Batch 23, Loss: 0.623\n",
      "Training: Epoch 10, Batch 24, Loss: 0.423\n",
      "Training: Epoch 10, Batch 25, Loss: 0.909\n",
      "Training: Epoch 10, Batch 26, Loss: 0.629\n",
      "Training: Epoch 10, Batch 27, Loss: 0.538\n",
      "Training: Epoch 10, Batch 28, Loss: 0.846\n",
      "Training: Epoch 10, Batch 29, Loss: 0.82\n",
      "Val: Epoch 10, Loss: 0.491\n",
      "Training: Epoch 11, Batch 0, Loss: 0.562\n",
      "Training: Epoch 11, Batch 1, Loss: 0.618\n",
      "Training: Epoch 11, Batch 2, Loss: 0.699\n",
      "Training: Epoch 11, Batch 3, Loss: 0.488\n",
      "Training: Epoch 11, Batch 4, Loss: 0.945\n",
      "Training: Epoch 11, Batch 5, Loss: 0.935\n",
      "Training: Epoch 11, Batch 6, Loss: 0.708\n",
      "Training: Epoch 11, Batch 7, Loss: 0.735\n",
      "Training: Epoch 11, Batch 8, Loss: 0.623\n",
      "Training: Epoch 11, Batch 9, Loss: 0.737\n",
      "Training: Epoch 11, Batch 10, Loss: 0.448\n",
      "Training: Epoch 11, Batch 11, Loss: 0.537\n",
      "Training: Epoch 11, Batch 12, Loss: 0.66\n",
      "Training: Epoch 11, Batch 13, Loss: 0.578\n",
      "Training: Epoch 11, Batch 14, Loss: 0.556\n",
      "Training: Epoch 11, Batch 15, Loss: 1.059\n",
      "Training: Epoch 11, Batch 16, Loss: 0.71\n",
      "Training: Epoch 11, Batch 17, Loss: 0.813\n",
      "Training: Epoch 11, Batch 18, Loss: 0.648\n",
      "Training: Epoch 11, Batch 19, Loss: 0.606\n",
      "Training: Epoch 11, Batch 20, Loss: 0.772\n",
      "Training: Epoch 11, Batch 21, Loss: 0.514\n",
      "Training: Epoch 11, Batch 22, Loss: 0.447\n",
      "Training: Epoch 11, Batch 23, Loss: 0.552\n",
      "Training: Epoch 11, Batch 24, Loss: 0.553\n",
      "Training: Epoch 11, Batch 25, Loss: 0.697\n",
      "Training: Epoch 11, Batch 26, Loss: 0.706\n",
      "Training: Epoch 11, Batch 27, Loss: 0.976\n",
      "Training: Epoch 11, Batch 28, Loss: 0.664\n",
      "Training: Epoch 11, Batch 29, Loss: 0.859\n",
      "Val: Epoch 11, Loss: 0.446\n",
      "Training: Epoch 12, Batch 0, Loss: 0.84\n",
      "Training: Epoch 12, Batch 1, Loss: 0.72\n",
      "Training: Epoch 12, Batch 2, Loss: 0.475\n",
      "Training: Epoch 12, Batch 3, Loss: 0.681\n",
      "Training: Epoch 12, Batch 4, Loss: 0.673\n",
      "Training: Epoch 12, Batch 5, Loss: 0.761\n",
      "Training: Epoch 12, Batch 6, Loss: 0.525\n",
      "Training: Epoch 12, Batch 7, Loss: 0.67\n",
      "Training: Epoch 12, Batch 8, Loss: 0.536\n",
      "Training: Epoch 12, Batch 9, Loss: 0.566\n",
      "Training: Epoch 12, Batch 10, Loss: 0.629\n",
      "Training: Epoch 12, Batch 11, Loss: 0.974\n",
      "Training: Epoch 12, Batch 12, Loss: 0.891\n",
      "Training: Epoch 12, Batch 13, Loss: 0.703\n",
      "Training: Epoch 12, Batch 14, Loss: 0.605\n",
      "Training: Epoch 12, Batch 15, Loss: 0.904\n",
      "Training: Epoch 12, Batch 16, Loss: 0.475\n",
      "Training: Epoch 12, Batch 17, Loss: 0.721\n",
      "Training: Epoch 12, Batch 18, Loss: 0.55\n",
      "Training: Epoch 12, Batch 19, Loss: 0.596\n",
      "Training: Epoch 12, Batch 20, Loss: 0.482\n",
      "Training: Epoch 12, Batch 21, Loss: 0.761\n",
      "Training: Epoch 12, Batch 22, Loss: 0.687\n",
      "Training: Epoch 12, Batch 23, Loss: 0.564\n",
      "Training: Epoch 12, Batch 24, Loss: 0.753\n",
      "Training: Epoch 12, Batch 25, Loss: 0.694\n",
      "Training: Epoch 12, Batch 26, Loss: 0.857\n",
      "Training: Epoch 12, Batch 27, Loss: 0.543\n",
      "Training: Epoch 12, Batch 28, Loss: 0.436\n",
      "Training: Epoch 12, Batch 29, Loss: 0.709\n",
      "Val: Epoch 12, Loss: 0.394\n",
      "Training: Epoch 13, Batch 0, Loss: 0.82\n",
      "Training: Epoch 13, Batch 1, Loss: 0.898\n",
      "Training: Epoch 13, Batch 2, Loss: 0.798\n",
      "Training: Epoch 13, Batch 3, Loss: 0.607\n",
      "Training: Epoch 13, Batch 4, Loss: 0.539\n",
      "Training: Epoch 13, Batch 5, Loss: 0.393\n",
      "Training: Epoch 13, Batch 6, Loss: 0.615\n",
      "Training: Epoch 13, Batch 7, Loss: 0.405\n",
      "Training: Epoch 13, Batch 8, Loss: 0.73\n",
      "Training: Epoch 13, Batch 9, Loss: 0.421\n",
      "Training: Epoch 13, Batch 10, Loss: 0.583\n",
      "Training: Epoch 13, Batch 11, Loss: 0.794\n",
      "Training: Epoch 13, Batch 12, Loss: 0.775\n",
      "Training: Epoch 13, Batch 13, Loss: 0.497\n",
      "Training: Epoch 13, Batch 14, Loss: 0.554\n",
      "Training: Epoch 13, Batch 15, Loss: 0.62\n",
      "Training: Epoch 13, Batch 16, Loss: 0.642\n",
      "Training: Epoch 13, Batch 17, Loss: 0.667\n",
      "Training: Epoch 13, Batch 18, Loss: 0.449\n",
      "Training: Epoch 13, Batch 19, Loss: 0.455\n",
      "Training: Epoch 13, Batch 20, Loss: 0.54\n",
      "Training: Epoch 13, Batch 21, Loss: 0.538\n",
      "Training: Epoch 13, Batch 22, Loss: 0.538\n",
      "Training: Epoch 13, Batch 23, Loss: 0.603\n",
      "Training: Epoch 13, Batch 24, Loss: 0.632\n",
      "Training: Epoch 13, Batch 25, Loss: 0.532\n",
      "Training: Epoch 13, Batch 26, Loss: 0.609\n",
      "Training: Epoch 13, Batch 27, Loss: 0.753\n",
      "Training: Epoch 13, Batch 28, Loss: 0.633\n",
      "Training: Epoch 13, Batch 29, Loss: 0.56\n",
      "Val: Epoch 13, Loss: 0.544\n",
      "Training: Epoch 14, Batch 0, Loss: 0.67\n",
      "Training: Epoch 14, Batch 1, Loss: 0.574\n",
      "Training: Epoch 14, Batch 2, Loss: 0.508\n",
      "Training: Epoch 14, Batch 3, Loss: 0.399\n",
      "Training: Epoch 14, Batch 4, Loss: 0.802\n",
      "Training: Epoch 14, Batch 5, Loss: 0.343\n",
      "Training: Epoch 14, Batch 6, Loss: 0.449\n",
      "Training: Epoch 14, Batch 7, Loss: 0.581\n",
      "Training: Epoch 14, Batch 8, Loss: 1.053\n",
      "Training: Epoch 14, Batch 9, Loss: 0.787\n",
      "Training: Epoch 14, Batch 10, Loss: 0.565\n",
      "Training: Epoch 14, Batch 11, Loss: 0.491\n",
      "Training: Epoch 14, Batch 12, Loss: 0.833\n",
      "Training: Epoch 14, Batch 13, Loss: 0.848\n",
      "Training: Epoch 14, Batch 14, Loss: 0.93\n",
      "Training: Epoch 14, Batch 15, Loss: 0.317\n",
      "Training: Epoch 14, Batch 16, Loss: 0.783\n",
      "Training: Epoch 14, Batch 17, Loss: 0.735\n",
      "Training: Epoch 14, Batch 18, Loss: 0.816\n",
      "Training: Epoch 14, Batch 19, Loss: 0.618\n",
      "Training: Epoch 14, Batch 20, Loss: 0.697\n",
      "Training: Epoch 14, Batch 21, Loss: 0.717\n",
      "Training: Epoch 14, Batch 22, Loss: 0.864\n",
      "Training: Epoch 14, Batch 23, Loss: 0.542\n",
      "Training: Epoch 14, Batch 24, Loss: 0.707\n",
      "Training: Epoch 14, Batch 25, Loss: 0.659\n",
      "Training: Epoch 14, Batch 26, Loss: 0.79\n",
      "Training: Epoch 14, Batch 27, Loss: 1.097\n",
      "Training: Epoch 14, Batch 28, Loss: 0.68\n",
      "Training: Epoch 14, Batch 29, Loss: 0.747\n",
      "Val: Epoch 14, Loss: 0.504\n",
      "Training: Epoch 15, Batch 0, Loss: 0.591\n",
      "Training: Epoch 15, Batch 1, Loss: 0.613\n",
      "Training: Epoch 15, Batch 2, Loss: 0.636\n",
      "Training: Epoch 15, Batch 3, Loss: 0.594\n",
      "Training: Epoch 15, Batch 4, Loss: 0.708\n",
      "Training: Epoch 15, Batch 5, Loss: 0.65\n",
      "Training: Epoch 15, Batch 6, Loss: 0.534\n",
      "Training: Epoch 15, Batch 7, Loss: 0.54\n",
      "Training: Epoch 15, Batch 8, Loss: 1.153\n",
      "Training: Epoch 15, Batch 9, Loss: 0.454\n",
      "Training: Epoch 15, Batch 10, Loss: 0.602\n",
      "Training: Epoch 15, Batch 11, Loss: 0.673\n",
      "Training: Epoch 15, Batch 12, Loss: 0.598\n",
      "Training: Epoch 15, Batch 13, Loss: 0.681\n",
      "Training: Epoch 15, Batch 14, Loss: 0.451\n",
      "Training: Epoch 15, Batch 15, Loss: 0.648\n",
      "Training: Epoch 15, Batch 16, Loss: 0.881\n",
      "Training: Epoch 15, Batch 17, Loss: 0.734\n",
      "Training: Epoch 15, Batch 18, Loss: 0.692\n",
      "Training: Epoch 15, Batch 19, Loss: 0.578\n",
      "Training: Epoch 15, Batch 20, Loss: 0.752\n",
      "Training: Epoch 15, Batch 21, Loss: 0.583\n",
      "Training: Epoch 15, Batch 22, Loss: 0.733\n",
      "Training: Epoch 15, Batch 23, Loss: 0.994\n",
      "Training: Epoch 15, Batch 24, Loss: 0.507\n",
      "Training: Epoch 15, Batch 25, Loss: 0.813\n",
      "Training: Epoch 15, Batch 26, Loss: 0.841\n",
      "Training: Epoch 15, Batch 27, Loss: 0.675\n",
      "Training: Epoch 15, Batch 28, Loss: 0.561\n",
      "Training: Epoch 15, Batch 29, Loss: 0.744\n",
      "Val: Epoch 15, Loss: 0.405\n",
      "Training: Epoch 16, Batch 0, Loss: 0.71\n",
      "Training: Epoch 16, Batch 1, Loss: 0.676\n",
      "Training: Epoch 16, Batch 2, Loss: 0.522\n",
      "Training: Epoch 16, Batch 3, Loss: 0.718\n",
      "Training: Epoch 16, Batch 4, Loss: 0.516\n",
      "Training: Epoch 16, Batch 5, Loss: 0.722\n",
      "Training: Epoch 16, Batch 6, Loss: 0.526\n",
      "Training: Epoch 16, Batch 7, Loss: 0.718\n",
      "Training: Epoch 16, Batch 8, Loss: 0.613\n",
      "Training: Epoch 16, Batch 9, Loss: 0.792\n",
      "Training: Epoch 16, Batch 10, Loss: 0.695\n",
      "Training: Epoch 16, Batch 11, Loss: 0.567\n",
      "Training: Epoch 16, Batch 12, Loss: 0.54\n",
      "Training: Epoch 16, Batch 13, Loss: 0.765\n",
      "Training: Epoch 16, Batch 14, Loss: 0.633\n",
      "Training: Epoch 16, Batch 15, Loss: 0.57\n",
      "Training: Epoch 16, Batch 16, Loss: 0.633\n",
      "Training: Epoch 16, Batch 17, Loss: 0.597\n",
      "Training: Epoch 16, Batch 18, Loss: 0.518\n",
      "Training: Epoch 16, Batch 19, Loss: 0.597\n",
      "Training: Epoch 16, Batch 20, Loss: 0.989\n",
      "Training: Epoch 16, Batch 21, Loss: 0.628\n",
      "Training: Epoch 16, Batch 22, Loss: 0.742\n",
      "Training: Epoch 16, Batch 23, Loss: 0.588\n",
      "Training: Epoch 16, Batch 24, Loss: 0.67\n",
      "Training: Epoch 16, Batch 25, Loss: 0.579\n",
      "Training: Epoch 16, Batch 26, Loss: 0.653\n",
      "Training: Epoch 16, Batch 27, Loss: 0.923\n",
      "Training: Epoch 16, Batch 28, Loss: 0.632\n",
      "Training: Epoch 16, Batch 29, Loss: 0.822\n",
      "Val: Epoch 16, Loss: 0.405\n",
      "Training: Epoch 17, Batch 0, Loss: 0.544\n",
      "Training: Epoch 17, Batch 1, Loss: 0.611\n",
      "Training: Epoch 17, Batch 2, Loss: 0.534\n",
      "Training: Epoch 17, Batch 3, Loss: 0.635\n",
      "Training: Epoch 17, Batch 4, Loss: 0.545\n",
      "Training: Epoch 17, Batch 5, Loss: 0.765\n",
      "Training: Epoch 17, Batch 6, Loss: 0.832\n",
      "Training: Epoch 17, Batch 7, Loss: 0.627\n",
      "Training: Epoch 17, Batch 8, Loss: 0.465\n",
      "Training: Epoch 17, Batch 9, Loss: 0.903\n",
      "Training: Epoch 17, Batch 10, Loss: 0.417\n",
      "Training: Epoch 17, Batch 11, Loss: 0.674\n",
      "Training: Epoch 17, Batch 12, Loss: 0.791\n",
      "Training: Epoch 17, Batch 13, Loss: 0.532\n",
      "Training: Epoch 17, Batch 14, Loss: 0.69\n",
      "Training: Epoch 17, Batch 15, Loss: 0.707\n",
      "Training: Epoch 17, Batch 16, Loss: 0.663\n",
      "Training: Epoch 17, Batch 17, Loss: 0.687\n",
      "Training: Epoch 17, Batch 18, Loss: 0.472\n",
      "Training: Epoch 17, Batch 19, Loss: 0.534\n",
      "Training: Epoch 17, Batch 20, Loss: 1.029\n",
      "Training: Epoch 17, Batch 21, Loss: 0.599\n",
      "Training: Epoch 17, Batch 22, Loss: 0.65\n",
      "Training: Epoch 17, Batch 23, Loss: 0.521\n",
      "Training: Epoch 17, Batch 24, Loss: 0.391\n",
      "Training: Epoch 17, Batch 25, Loss: 0.768\n",
      "Training: Epoch 17, Batch 26, Loss: 0.879\n",
      "Training: Epoch 17, Batch 27, Loss: 0.481\n",
      "Training: Epoch 17, Batch 28, Loss: 0.512\n",
      "Training: Epoch 17, Batch 29, Loss: 0.886\n",
      "Val: Epoch 17, Loss: 0.394\n",
      "Training: Epoch 18, Batch 0, Loss: 0.486\n",
      "Training: Epoch 18, Batch 1, Loss: 0.439\n",
      "Training: Epoch 18, Batch 2, Loss: 0.612\n",
      "Training: Epoch 18, Batch 3, Loss: 0.723\n",
      "Training: Epoch 18, Batch 4, Loss: 0.654\n",
      "Training: Epoch 18, Batch 5, Loss: 0.605\n",
      "Training: Epoch 18, Batch 6, Loss: 0.478\n",
      "Training: Epoch 18, Batch 7, Loss: 0.628\n",
      "Training: Epoch 18, Batch 8, Loss: 0.709\n",
      "Training: Epoch 18, Batch 9, Loss: 0.463\n",
      "Training: Epoch 18, Batch 10, Loss: 0.591\n",
      "Training: Epoch 18, Batch 11, Loss: 0.682\n",
      "Training: Epoch 18, Batch 12, Loss: 0.421\n",
      "Training: Epoch 18, Batch 13, Loss: 0.55\n",
      "Training: Epoch 18, Batch 14, Loss: 0.638\n",
      "Training: Epoch 18, Batch 15, Loss: 0.509\n",
      "Training: Epoch 18, Batch 16, Loss: 0.542\n",
      "Training: Epoch 18, Batch 17, Loss: 0.374\n",
      "Training: Epoch 18, Batch 18, Loss: 0.385\n",
      "Training: Epoch 18, Batch 19, Loss: 0.623\n",
      "Training: Epoch 18, Batch 20, Loss: 0.481\n",
      "Training: Epoch 18, Batch 21, Loss: 0.561\n",
      "Training: Epoch 18, Batch 22, Loss: 0.688\n",
      "Training: Epoch 18, Batch 23, Loss: 0.578\n",
      "Training: Epoch 18, Batch 24, Loss: 0.414\n",
      "Training: Epoch 18, Batch 25, Loss: 0.529\n",
      "Training: Epoch 18, Batch 26, Loss: 1.006\n",
      "Training: Epoch 18, Batch 27, Loss: 0.814\n",
      "Training: Epoch 18, Batch 28, Loss: 0.633\n",
      "Training: Epoch 18, Batch 29, Loss: 0.722\n",
      "Val: Epoch 18, Loss: 0.731\n",
      "Training: Epoch 19, Batch 0, Loss: 0.801\n",
      "Training: Epoch 19, Batch 1, Loss: 0.791\n",
      "Training: Epoch 19, Batch 2, Loss: 0.728\n",
      "Training: Epoch 19, Batch 3, Loss: 0.701\n",
      "Training: Epoch 19, Batch 4, Loss: 0.656\n",
      "Training: Epoch 19, Batch 5, Loss: 0.525\n",
      "Training: Epoch 19, Batch 6, Loss: 0.681\n",
      "Training: Epoch 19, Batch 7, Loss: 0.565\n",
      "Training: Epoch 19, Batch 8, Loss: 0.432\n",
      "Training: Epoch 19, Batch 9, Loss: 0.634\n",
      "Training: Epoch 19, Batch 10, Loss: 0.599\n",
      "Training: Epoch 19, Batch 11, Loss: 0.473\n",
      "Training: Epoch 19, Batch 12, Loss: 0.531\n",
      "Training: Epoch 19, Batch 13, Loss: 0.331\n",
      "Training: Epoch 19, Batch 14, Loss: 0.517\n",
      "Training: Epoch 19, Batch 15, Loss: 0.542\n",
      "Training: Epoch 19, Batch 16, Loss: 0.441\n",
      "Training: Epoch 19, Batch 17, Loss: 0.466\n",
      "Training: Epoch 19, Batch 18, Loss: 0.458\n",
      "Training: Epoch 19, Batch 19, Loss: 0.59\n",
      "Training: Epoch 19, Batch 20, Loss: 0.45\n",
      "Training: Epoch 19, Batch 21, Loss: 0.558\n",
      "Training: Epoch 19, Batch 22, Loss: 0.682\n",
      "Training: Epoch 19, Batch 23, Loss: 0.592\n",
      "Training: Epoch 19, Batch 24, Loss: 0.643\n",
      "Training: Epoch 19, Batch 25, Loss: 0.865\n",
      "Training: Epoch 19, Batch 26, Loss: 0.602\n",
      "Training: Epoch 19, Batch 27, Loss: 0.558\n",
      "Training: Epoch 19, Batch 28, Loss: 0.41\n",
      "Training: Epoch 19, Batch 29, Loss: 0.552\n",
      "Val: Epoch 19, Loss: 0.331\n",
      "Training: Epoch 20, Batch 0, Loss: 0.469\n",
      "Training: Epoch 20, Batch 1, Loss: 0.438\n",
      "Training: Epoch 20, Batch 2, Loss: 0.513\n",
      "Training: Epoch 20, Batch 3, Loss: 0.7\n",
      "Training: Epoch 20, Batch 4, Loss: 0.625\n",
      "Training: Epoch 20, Batch 5, Loss: 0.741\n",
      "Training: Epoch 20, Batch 6, Loss: 0.641\n",
      "Training: Epoch 20, Batch 7, Loss: 0.625\n",
      "Training: Epoch 20, Batch 8, Loss: 0.421\n",
      "Training: Epoch 20, Batch 9, Loss: 0.504\n",
      "Training: Epoch 20, Batch 10, Loss: 0.648\n",
      "Training: Epoch 20, Batch 11, Loss: 0.472\n",
      "Training: Epoch 20, Batch 12, Loss: 0.582\n",
      "Training: Epoch 20, Batch 13, Loss: 0.617\n",
      "Training: Epoch 20, Batch 14, Loss: 0.602\n",
      "Training: Epoch 20, Batch 15, Loss: 0.707\n",
      "Training: Epoch 20, Batch 16, Loss: 0.662\n",
      "Training: Epoch 20, Batch 17, Loss: 0.654\n",
      "Training: Epoch 20, Batch 18, Loss: 0.467\n",
      "Training: Epoch 20, Batch 19, Loss: 0.526\n",
      "Training: Epoch 20, Batch 20, Loss: 0.518\n",
      "Training: Epoch 20, Batch 21, Loss: 0.639\n",
      "Training: Epoch 20, Batch 22, Loss: 0.554\n",
      "Training: Epoch 20, Batch 23, Loss: 0.714\n",
      "Training: Epoch 20, Batch 24, Loss: 0.415\n",
      "Training: Epoch 20, Batch 25, Loss: 0.487\n",
      "Training: Epoch 20, Batch 26, Loss: 0.774\n",
      "Training: Epoch 20, Batch 27, Loss: 0.498\n",
      "Training: Epoch 20, Batch 28, Loss: 0.591\n",
      "Training: Epoch 20, Batch 29, Loss: 0.558\n",
      "Val: Epoch 20, Loss: 0.363\n",
      "Training: Epoch 21, Batch 0, Loss: 0.677\n",
      "Training: Epoch 21, Batch 1, Loss: 0.426\n",
      "Training: Epoch 21, Batch 2, Loss: 0.415\n",
      "Training: Epoch 21, Batch 3, Loss: 0.5\n",
      "Training: Epoch 21, Batch 4, Loss: 0.365\n",
      "Training: Epoch 21, Batch 5, Loss: 0.818\n",
      "Training: Epoch 21, Batch 6, Loss: 0.741\n",
      "Training: Epoch 21, Batch 7, Loss: 0.588\n",
      "Training: Epoch 21, Batch 8, Loss: 0.607\n",
      "Training: Epoch 21, Batch 9, Loss: 0.514\n",
      "Training: Epoch 21, Batch 10, Loss: 0.478\n",
      "Training: Epoch 21, Batch 11, Loss: 0.501\n",
      "Training: Epoch 21, Batch 12, Loss: 1.036\n",
      "Training: Epoch 21, Batch 13, Loss: 0.406\n",
      "Training: Epoch 21, Batch 14, Loss: 0.609\n",
      "Training: Epoch 21, Batch 15, Loss: 0.536\n",
      "Training: Epoch 21, Batch 16, Loss: 0.664\n",
      "Training: Epoch 21, Batch 17, Loss: 0.473\n",
      "Training: Epoch 21, Batch 18, Loss: 1.03\n",
      "Training: Epoch 21, Batch 19, Loss: 0.792\n",
      "Training: Epoch 21, Batch 20, Loss: 0.466\n",
      "Training: Epoch 21, Batch 21, Loss: 0.49\n",
      "Training: Epoch 21, Batch 22, Loss: 0.681\n",
      "Training: Epoch 21, Batch 23, Loss: 0.535\n",
      "Training: Epoch 21, Batch 24, Loss: 0.7\n",
      "Training: Epoch 21, Batch 25, Loss: 0.471\n",
      "Training: Epoch 21, Batch 26, Loss: 0.563\n",
      "Training: Epoch 21, Batch 27, Loss: 0.505\n",
      "Training: Epoch 21, Batch 28, Loss: 0.455\n",
      "Training: Epoch 21, Batch 29, Loss: 0.42\n",
      "Val: Epoch 21, Loss: 0.359\n",
      "Training: Epoch 22, Batch 0, Loss: 0.575\n",
      "Training: Epoch 22, Batch 1, Loss: 0.616\n",
      "Training: Epoch 22, Batch 2, Loss: 0.459\n",
      "Training: Epoch 22, Batch 3, Loss: 0.541\n",
      "Training: Epoch 22, Batch 4, Loss: 0.505\n",
      "Training: Epoch 22, Batch 5, Loss: 0.521\n",
      "Training: Epoch 22, Batch 6, Loss: 0.482\n",
      "Training: Epoch 22, Batch 7, Loss: 0.474\n",
      "Training: Epoch 22, Batch 8, Loss: 0.891\n",
      "Training: Epoch 22, Batch 9, Loss: 0.633\n",
      "Training: Epoch 22, Batch 10, Loss: 0.652\n",
      "Training: Epoch 22, Batch 11, Loss: 0.678\n",
      "Training: Epoch 22, Batch 12, Loss: 0.525\n",
      "Training: Epoch 22, Batch 13, Loss: 0.42\n",
      "Training: Epoch 22, Batch 14, Loss: 0.431\n",
      "Training: Epoch 22, Batch 15, Loss: 0.546\n",
      "Training: Epoch 22, Batch 16, Loss: 0.493\n",
      "Training: Epoch 22, Batch 17, Loss: 0.642\n",
      "Training: Epoch 22, Batch 18, Loss: 0.821\n",
      "Training: Epoch 22, Batch 19, Loss: 0.593\n",
      "Training: Epoch 22, Batch 20, Loss: 0.474\n",
      "Training: Epoch 22, Batch 21, Loss: 0.597\n",
      "Training: Epoch 22, Batch 22, Loss: 0.436\n",
      "Training: Epoch 22, Batch 23, Loss: 0.465\n",
      "Training: Epoch 22, Batch 24, Loss: 0.434\n",
      "Training: Epoch 22, Batch 25, Loss: 0.504\n",
      "Training: Epoch 22, Batch 26, Loss: 0.57\n",
      "Training: Epoch 22, Batch 27, Loss: 0.5\n",
      "Training: Epoch 22, Batch 28, Loss: 0.434\n",
      "Training: Epoch 22, Batch 29, Loss: 0.672\n",
      "Val: Epoch 22, Loss: 0.398\n",
      "Training: Epoch 23, Batch 0, Loss: 0.467\n",
      "Training: Epoch 23, Batch 1, Loss: 0.447\n",
      "Training: Epoch 23, Batch 2, Loss: 0.774\n",
      "Training: Epoch 23, Batch 3, Loss: 0.63\n",
      "Training: Epoch 23, Batch 4, Loss: 0.534\n",
      "Training: Epoch 23, Batch 5, Loss: 0.455\n",
      "Training: Epoch 23, Batch 6, Loss: 0.869\n",
      "Training: Epoch 23, Batch 7, Loss: 0.424\n",
      "Training: Epoch 23, Batch 8, Loss: 0.459\n",
      "Training: Epoch 23, Batch 9, Loss: 0.581\n",
      "Training: Epoch 23, Batch 10, Loss: 0.605\n",
      "Training: Epoch 23, Batch 11, Loss: 0.593\n",
      "Training: Epoch 23, Batch 12, Loss: 0.714\n",
      "Training: Epoch 23, Batch 13, Loss: 0.355\n",
      "Training: Epoch 23, Batch 14, Loss: 0.396\n",
      "Training: Epoch 23, Batch 15, Loss: 0.478\n",
      "Training: Epoch 23, Batch 16, Loss: 0.463\n",
      "Training: Epoch 23, Batch 17, Loss: 0.461\n",
      "Training: Epoch 23, Batch 18, Loss: 0.691\n",
      "Training: Epoch 23, Batch 19, Loss: 0.453\n",
      "Training: Epoch 23, Batch 20, Loss: 0.711\n",
      "Training: Epoch 23, Batch 21, Loss: 0.747\n",
      "Training: Epoch 23, Batch 22, Loss: 0.812\n",
      "Training: Epoch 23, Batch 23, Loss: 0.395\n",
      "Training: Epoch 23, Batch 24, Loss: 0.63\n",
      "Training: Epoch 23, Batch 25, Loss: 0.5\n",
      "Training: Epoch 23, Batch 26, Loss: 0.532\n",
      "Training: Epoch 23, Batch 27, Loss: 0.28\n",
      "Training: Epoch 23, Batch 28, Loss: 0.61\n",
      "Training: Epoch 23, Batch 29, Loss: 0.689\n",
      "Val: Epoch 23, Loss: 0.332\n",
      "Training: Epoch 24, Batch 0, Loss: 0.494\n",
      "Training: Epoch 24, Batch 1, Loss: 0.534\n",
      "Training: Epoch 24, Batch 2, Loss: 0.44\n",
      "Training: Epoch 24, Batch 3, Loss: 0.418\n",
      "Training: Epoch 24, Batch 4, Loss: 0.441\n",
      "Training: Epoch 24, Batch 5, Loss: 0.543\n",
      "Training: Epoch 24, Batch 6, Loss: 0.623\n",
      "Training: Epoch 24, Batch 7, Loss: 0.796\n",
      "Training: Epoch 24, Batch 8, Loss: 0.453\n",
      "Training: Epoch 24, Batch 9, Loss: 0.58\n",
      "Training: Epoch 24, Batch 10, Loss: 0.636\n",
      "Training: Epoch 24, Batch 11, Loss: 0.885\n",
      "Training: Epoch 24, Batch 12, Loss: 0.471\n",
      "Training: Epoch 24, Batch 13, Loss: 1.368\n",
      "Training: Epoch 24, Batch 14, Loss: 0.69\n",
      "Training: Epoch 24, Batch 15, Loss: 0.694\n",
      "Training: Epoch 24, Batch 16, Loss: 0.817\n",
      "Training: Epoch 24, Batch 17, Loss: 0.63\n",
      "Training: Epoch 24, Batch 18, Loss: 0.658\n",
      "Training: Epoch 24, Batch 19, Loss: 0.589\n",
      "Training: Epoch 24, Batch 20, Loss: 0.626\n",
      "Training: Epoch 24, Batch 21, Loss: 0.671\n",
      "Training: Epoch 24, Batch 22, Loss: 0.59\n",
      "Training: Epoch 24, Batch 23, Loss: 0.398\n",
      "Training: Epoch 24, Batch 24, Loss: 0.366\n",
      "Training: Epoch 24, Batch 25, Loss: 0.486\n",
      "Training: Epoch 24, Batch 26, Loss: 0.49\n",
      "Training: Epoch 24, Batch 27, Loss: 0.336\n",
      "Training: Epoch 24, Batch 28, Loss: 0.601\n",
      "Training: Epoch 24, Batch 29, Loss: 0.446\n",
      "Val: Epoch 24, Loss: 0.309\n",
      "Training: Epoch 25, Batch 0, Loss: 0.722\n",
      "Training: Epoch 25, Batch 1, Loss: 0.609\n",
      "Training: Epoch 25, Batch 2, Loss: 0.389\n",
      "Training: Epoch 25, Batch 3, Loss: 0.393\n",
      "Training: Epoch 25, Batch 4, Loss: 0.369\n",
      "Training: Epoch 25, Batch 5, Loss: 0.759\n",
      "Training: Epoch 25, Batch 6, Loss: 0.541\n",
      "Training: Epoch 25, Batch 7, Loss: 0.816\n",
      "Training: Epoch 25, Batch 8, Loss: 0.638\n",
      "Training: Epoch 25, Batch 9, Loss: 0.406\n",
      "Training: Epoch 25, Batch 10, Loss: 0.437\n",
      "Training: Epoch 25, Batch 11, Loss: 0.426\n",
      "Training: Epoch 25, Batch 12, Loss: 0.402\n",
      "Training: Epoch 25, Batch 13, Loss: 0.359\n",
      "Training: Epoch 25, Batch 14, Loss: 0.549\n",
      "Training: Epoch 25, Batch 15, Loss: 0.566\n",
      "Training: Epoch 25, Batch 16, Loss: 0.555\n",
      "Training: Epoch 25, Batch 17, Loss: 0.522\n",
      "Training: Epoch 25, Batch 18, Loss: 0.678\n",
      "Training: Epoch 25, Batch 19, Loss: 0.736\n",
      "Training: Epoch 25, Batch 20, Loss: 0.546\n",
      "Training: Epoch 25, Batch 21, Loss: 0.563\n",
      "Training: Epoch 25, Batch 22, Loss: 0.657\n",
      "Training: Epoch 25, Batch 23, Loss: 0.65\n",
      "Training: Epoch 25, Batch 24, Loss: 0.474\n",
      "Training: Epoch 25, Batch 25, Loss: 0.539\n",
      "Training: Epoch 25, Batch 26, Loss: 0.415\n",
      "Training: Epoch 25, Batch 27, Loss: 0.457\n",
      "Training: Epoch 25, Batch 28, Loss: 0.506\n",
      "Training: Epoch 25, Batch 29, Loss: 0.488\n",
      "Val: Epoch 25, Loss: 0.321\n",
      "Training: Epoch 26, Batch 0, Loss: 0.462\n",
      "Training: Epoch 26, Batch 1, Loss: 0.559\n",
      "Training: Epoch 26, Batch 2, Loss: 0.414\n",
      "Training: Epoch 26, Batch 3, Loss: 0.386\n",
      "Training: Epoch 26, Batch 4, Loss: 0.586\n",
      "Training: Epoch 26, Batch 5, Loss: 0.552\n",
      "Training: Epoch 26, Batch 6, Loss: 0.487\n",
      "Training: Epoch 26, Batch 7, Loss: 0.722\n",
      "Training: Epoch 26, Batch 8, Loss: 0.669\n",
      "Training: Epoch 26, Batch 9, Loss: 0.659\n",
      "Training: Epoch 26, Batch 10, Loss: 0.443\n",
      "Training: Epoch 26, Batch 11, Loss: 0.684\n",
      "Training: Epoch 26, Batch 12, Loss: 0.547\n",
      "Training: Epoch 26, Batch 13, Loss: 0.323\n",
      "Training: Epoch 26, Batch 14, Loss: 0.586\n",
      "Training: Epoch 26, Batch 15, Loss: 0.471\n",
      "Training: Epoch 26, Batch 16, Loss: 0.389\n",
      "Training: Epoch 26, Batch 17, Loss: 0.57\n",
      "Training: Epoch 26, Batch 18, Loss: 0.398\n",
      "Training: Epoch 26, Batch 19, Loss: 0.635\n",
      "Training: Epoch 26, Batch 20, Loss: 0.558\n",
      "Training: Epoch 26, Batch 21, Loss: 0.396\n",
      "Training: Epoch 26, Batch 22, Loss: 0.406\n",
      "Training: Epoch 26, Batch 23, Loss: 0.718\n",
      "Training: Epoch 26, Batch 24, Loss: 0.287\n",
      "Training: Epoch 26, Batch 25, Loss: 0.625\n",
      "Training: Epoch 26, Batch 26, Loss: 0.817\n",
      "Training: Epoch 26, Batch 27, Loss: 0.597\n",
      "Training: Epoch 26, Batch 28, Loss: 0.369\n",
      "Training: Epoch 26, Batch 29, Loss: 0.514\n",
      "Val: Epoch 26, Loss: 0.321\n",
      "Training: Epoch 27, Batch 0, Loss: 0.647\n",
      "Training: Epoch 27, Batch 1, Loss: 0.507\n",
      "Training: Epoch 27, Batch 2, Loss: 0.593\n",
      "Training: Epoch 27, Batch 3, Loss: 0.355\n",
      "Training: Epoch 27, Batch 4, Loss: 0.668\n",
      "Training: Epoch 27, Batch 5, Loss: 0.613\n",
      "Training: Epoch 27, Batch 6, Loss: 0.517\n",
      "Training: Epoch 27, Batch 7, Loss: 0.48\n",
      "Training: Epoch 27, Batch 8, Loss: 0.592\n",
      "Training: Epoch 27, Batch 9, Loss: 0.866\n",
      "Training: Epoch 27, Batch 10, Loss: 0.533\n",
      "Training: Epoch 27, Batch 11, Loss: 0.603\n",
      "Training: Epoch 27, Batch 12, Loss: 0.659\n",
      "Training: Epoch 27, Batch 13, Loss: 0.678\n",
      "Training: Epoch 27, Batch 14, Loss: 0.496\n",
      "Training: Epoch 27, Batch 15, Loss: 0.603\n",
      "Training: Epoch 27, Batch 16, Loss: 0.581\n",
      "Training: Epoch 27, Batch 17, Loss: 0.532\n",
      "Training: Epoch 27, Batch 18, Loss: 0.541\n",
      "Training: Epoch 27, Batch 19, Loss: 0.4\n",
      "Training: Epoch 27, Batch 20, Loss: 0.502\n",
      "Training: Epoch 27, Batch 21, Loss: 0.559\n",
      "Training: Epoch 27, Batch 22, Loss: 0.633\n",
      "Training: Epoch 27, Batch 23, Loss: 0.363\n",
      "Training: Epoch 27, Batch 24, Loss: 0.556\n",
      "Training: Epoch 27, Batch 25, Loss: 0.695\n",
      "Training: Epoch 27, Batch 26, Loss: 0.408\n",
      "Training: Epoch 27, Batch 27, Loss: 0.587\n",
      "Training: Epoch 27, Batch 28, Loss: 0.465\n",
      "Training: Epoch 27, Batch 29, Loss: 0.659\n",
      "Val: Epoch 27, Loss: 0.297\n",
      "Training: Epoch 28, Batch 0, Loss: 0.517\n",
      "Training: Epoch 28, Batch 1, Loss: 0.423\n",
      "Training: Epoch 28, Batch 2, Loss: 1.043\n",
      "Training: Epoch 28, Batch 3, Loss: 0.411\n",
      "Training: Epoch 28, Batch 4, Loss: 0.779\n",
      "Training: Epoch 28, Batch 5, Loss: 0.493\n",
      "Training: Epoch 28, Batch 6, Loss: 1.423\n",
      "Training: Epoch 28, Batch 7, Loss: 0.622\n",
      "Training: Epoch 28, Batch 8, Loss: 0.434\n",
      "Training: Epoch 28, Batch 9, Loss: 0.502\n",
      "Training: Epoch 28, Batch 10, Loss: 0.702\n",
      "Training: Epoch 28, Batch 11, Loss: 0.485\n",
      "Training: Epoch 28, Batch 12, Loss: 0.761\n",
      "Training: Epoch 28, Batch 13, Loss: 0.497\n",
      "Training: Epoch 28, Batch 14, Loss: 0.676\n",
      "Training: Epoch 28, Batch 15, Loss: 0.674\n",
      "Training: Epoch 28, Batch 16, Loss: 0.477\n",
      "Training: Epoch 28, Batch 17, Loss: 0.375\n",
      "Training: Epoch 28, Batch 18, Loss: 0.502\n",
      "Training: Epoch 28, Batch 19, Loss: 0.455\n",
      "Training: Epoch 28, Batch 20, Loss: 0.388\n",
      "Training: Epoch 28, Batch 21, Loss: 0.595\n",
      "Training: Epoch 28, Batch 22, Loss: 0.514\n",
      "Training: Epoch 28, Batch 23, Loss: 0.391\n",
      "Training: Epoch 28, Batch 24, Loss: 0.897\n",
      "Training: Epoch 28, Batch 25, Loss: 0.75\n",
      "Training: Epoch 28, Batch 26, Loss: 0.53\n",
      "Training: Epoch 28, Batch 27, Loss: 0.491\n",
      "Training: Epoch 28, Batch 28, Loss: 0.605\n",
      "Training: Epoch 28, Batch 29, Loss: 0.365\n",
      "Val: Epoch 28, Loss: 0.323\n",
      "Training: Epoch 29, Batch 0, Loss: 0.522\n",
      "Training: Epoch 29, Batch 1, Loss: 0.468\n",
      "Training: Epoch 29, Batch 2, Loss: 0.626\n",
      "Training: Epoch 29, Batch 3, Loss: 0.557\n",
      "Training: Epoch 29, Batch 4, Loss: 0.425\n",
      "Training: Epoch 29, Batch 5, Loss: 0.402\n",
      "Training: Epoch 29, Batch 6, Loss: 0.486\n",
      "Training: Epoch 29, Batch 7, Loss: 0.463\n",
      "Training: Epoch 29, Batch 8, Loss: 0.676\n",
      "Training: Epoch 29, Batch 9, Loss: 0.648\n",
      "Training: Epoch 29, Batch 10, Loss: 0.482\n",
      "Training: Epoch 29, Batch 11, Loss: 0.549\n",
      "Training: Epoch 29, Batch 12, Loss: 0.366\n",
      "Training: Epoch 29, Batch 13, Loss: 0.649\n",
      "Training: Epoch 29, Batch 14, Loss: 0.753\n",
      "Training: Epoch 29, Batch 15, Loss: 0.45\n",
      "Training: Epoch 29, Batch 16, Loss: 0.417\n",
      "Training: Epoch 29, Batch 17, Loss: 0.464\n",
      "Training: Epoch 29, Batch 18, Loss: 0.413\n",
      "Training: Epoch 29, Batch 19, Loss: 0.61\n",
      "Training: Epoch 29, Batch 20, Loss: 0.545\n",
      "Training: Epoch 29, Batch 21, Loss: 0.733\n",
      "Training: Epoch 29, Batch 22, Loss: 0.322\n",
      "Training: Epoch 29, Batch 23, Loss: 0.609\n",
      "Training: Epoch 29, Batch 24, Loss: 0.383\n",
      "Training: Epoch 29, Batch 25, Loss: 0.745\n",
      "Training: Epoch 29, Batch 26, Loss: 0.688\n",
      "Training: Epoch 29, Batch 27, Loss: 0.44\n",
      "Training: Epoch 29, Batch 28, Loss: 0.522\n",
      "Training: Epoch 29, Batch 29, Loss: 0.567\n",
      "Val: Epoch 29, Loss: 0.284\n",
      "Training: Epoch 30, Batch 0, Loss: 0.594\n",
      "Training: Epoch 30, Batch 1, Loss: 0.444\n",
      "Training: Epoch 30, Batch 2, Loss: 0.381\n",
      "Training: Epoch 30, Batch 3, Loss: 0.768\n",
      "Training: Epoch 30, Batch 4, Loss: 0.544\n",
      "Training: Epoch 30, Batch 5, Loss: 0.62\n",
      "Training: Epoch 30, Batch 6, Loss: 0.513\n",
      "Training: Epoch 30, Batch 7, Loss: 0.596\n",
      "Training: Epoch 30, Batch 8, Loss: 0.286\n",
      "Training: Epoch 30, Batch 9, Loss: 0.555\n",
      "Training: Epoch 30, Batch 10, Loss: 0.418\n",
      "Training: Epoch 30, Batch 11, Loss: 0.512\n",
      "Training: Epoch 30, Batch 12, Loss: 0.537\n",
      "Training: Epoch 30, Batch 13, Loss: 0.398\n",
      "Training: Epoch 30, Batch 14, Loss: 0.436\n",
      "Training: Epoch 30, Batch 15, Loss: 0.709\n",
      "Training: Epoch 30, Batch 16, Loss: 0.42\n",
      "Training: Epoch 30, Batch 17, Loss: 0.691\n",
      "Training: Epoch 30, Batch 18, Loss: 0.581\n",
      "Training: Epoch 30, Batch 19, Loss: 0.586\n",
      "Training: Epoch 30, Batch 20, Loss: 0.499\n",
      "Training: Epoch 30, Batch 21, Loss: 0.438\n",
      "Training: Epoch 30, Batch 22, Loss: 0.326\n",
      "Training: Epoch 30, Batch 23, Loss: 1.674\n",
      "Training: Epoch 30, Batch 24, Loss: 0.486\n",
      "Training: Epoch 30, Batch 25, Loss: 0.388\n",
      "Training: Epoch 30, Batch 26, Loss: 0.523\n",
      "Training: Epoch 30, Batch 27, Loss: 0.354\n",
      "Training: Epoch 30, Batch 28, Loss: 0.378\n",
      "Training: Epoch 30, Batch 29, Loss: 0.94\n",
      "Val: Epoch 30, Loss: 0.297\n",
      "Training: Epoch 31, Batch 0, Loss: 0.834\n",
      "Training: Epoch 31, Batch 1, Loss: 0.652\n",
      "Training: Epoch 31, Batch 2, Loss: 0.356\n",
      "Training: Epoch 31, Batch 3, Loss: 0.716\n",
      "Training: Epoch 31, Batch 4, Loss: 0.373\n",
      "Training: Epoch 31, Batch 5, Loss: 0.472\n",
      "Training: Epoch 31, Batch 6, Loss: 0.587\n",
      "Training: Epoch 31, Batch 7, Loss: 0.891\n",
      "Training: Epoch 31, Batch 8, Loss: 0.565\n",
      "Training: Epoch 31, Batch 9, Loss: 0.551\n",
      "Training: Epoch 31, Batch 10, Loss: 0.582\n",
      "Training: Epoch 31, Batch 11, Loss: 0.576\n",
      "Training: Epoch 31, Batch 12, Loss: 0.519\n",
      "Training: Epoch 31, Batch 13, Loss: 0.521\n",
      "Training: Epoch 31, Batch 14, Loss: 0.554\n",
      "Training: Epoch 31, Batch 15, Loss: 0.62\n",
      "Training: Epoch 31, Batch 16, Loss: 1.096\n",
      "Training: Epoch 31, Batch 17, Loss: 0.716\n",
      "Training: Epoch 31, Batch 18, Loss: 0.545\n",
      "Training: Epoch 31, Batch 19, Loss: 0.367\n",
      "Training: Epoch 31, Batch 20, Loss: 0.608\n",
      "Training: Epoch 31, Batch 21, Loss: 0.493\n",
      "Training: Epoch 31, Batch 22, Loss: 0.414\n",
      "Training: Epoch 31, Batch 23, Loss: 0.318\n",
      "Training: Epoch 31, Batch 24, Loss: 0.375\n",
      "Training: Epoch 31, Batch 25, Loss: 0.397\n",
      "Training: Epoch 31, Batch 26, Loss: 0.374\n",
      "Training: Epoch 31, Batch 27, Loss: 0.699\n",
      "Training: Epoch 31, Batch 28, Loss: 0.631\n",
      "Training: Epoch 31, Batch 29, Loss: 0.318\n",
      "Val: Epoch 31, Loss: 0.318\n",
      "Training: Epoch 32, Batch 0, Loss: 0.323\n",
      "Training: Epoch 32, Batch 1, Loss: 0.359\n",
      "Training: Epoch 32, Batch 2, Loss: 0.302\n",
      "Training: Epoch 32, Batch 3, Loss: 0.551\n",
      "Training: Epoch 32, Batch 4, Loss: 0.608\n",
      "Training: Epoch 32, Batch 5, Loss: 0.659\n",
      "Training: Epoch 32, Batch 6, Loss: 0.375\n",
      "Training: Epoch 32, Batch 7, Loss: 0.515\n",
      "Training: Epoch 32, Batch 8, Loss: 0.589\n",
      "Training: Epoch 32, Batch 9, Loss: 1.054\n",
      "Training: Epoch 32, Batch 10, Loss: 0.569\n",
      "Training: Epoch 32, Batch 11, Loss: 0.396\n",
      "Training: Epoch 32, Batch 12, Loss: 0.634\n",
      "Training: Epoch 32, Batch 13, Loss: 0.397\n",
      "Training: Epoch 32, Batch 14, Loss: 0.486\n",
      "Training: Epoch 32, Batch 15, Loss: 0.578\n",
      "Training: Epoch 32, Batch 16, Loss: 0.603\n",
      "Training: Epoch 32, Batch 17, Loss: 0.424\n",
      "Training: Epoch 32, Batch 18, Loss: 0.632\n",
      "Training: Epoch 32, Batch 19, Loss: 0.561\n",
      "Training: Epoch 32, Batch 20, Loss: 0.497\n",
      "Training: Epoch 32, Batch 21, Loss: 0.571\n",
      "Training: Epoch 32, Batch 22, Loss: 0.555\n",
      "Training: Epoch 32, Batch 23, Loss: 0.892\n",
      "Training: Epoch 32, Batch 24, Loss: 0.491\n",
      "Training: Epoch 32, Batch 25, Loss: 0.509\n",
      "Training: Epoch 32, Batch 26, Loss: 0.395\n",
      "Training: Epoch 32, Batch 27, Loss: 0.599\n",
      "Training: Epoch 32, Batch 28, Loss: 0.653\n",
      "Training: Epoch 32, Batch 29, Loss: 0.644\n",
      "Val: Epoch 32, Loss: 0.293\n",
      "Training: Epoch 33, Batch 0, Loss: 0.48\n",
      "Training: Epoch 33, Batch 1, Loss: 0.494\n",
      "Training: Epoch 33, Batch 2, Loss: 0.69\n",
      "Training: Epoch 33, Batch 3, Loss: 0.708\n",
      "Training: Epoch 33, Batch 4, Loss: 0.554\n",
      "Training: Epoch 33, Batch 5, Loss: 0.544\n",
      "Training: Epoch 33, Batch 6, Loss: 0.419\n",
      "Training: Epoch 33, Batch 7, Loss: 0.519\n",
      "Training: Epoch 33, Batch 8, Loss: 0.579\n",
      "Training: Epoch 33, Batch 9, Loss: 0.501\n",
      "Training: Epoch 33, Batch 10, Loss: 0.534\n",
      "Training: Epoch 33, Batch 11, Loss: 0.473\n",
      "Training: Epoch 33, Batch 12, Loss: 0.533\n",
      "Training: Epoch 33, Batch 13, Loss: 0.478\n",
      "Training: Epoch 33, Batch 14, Loss: 0.4\n",
      "Training: Epoch 33, Batch 15, Loss: 0.551\n",
      "Training: Epoch 33, Batch 16, Loss: 0.455\n",
      "Training: Epoch 33, Batch 17, Loss: 0.284\n",
      "Training: Epoch 33, Batch 18, Loss: 0.501\n",
      "Training: Epoch 33, Batch 19, Loss: 0.44\n",
      "Training: Epoch 33, Batch 20, Loss: 0.489\n",
      "Training: Epoch 33, Batch 21, Loss: 0.558\n",
      "Training: Epoch 33, Batch 22, Loss: 0.497\n",
      "Training: Epoch 33, Batch 23, Loss: 0.538\n",
      "Training: Epoch 33, Batch 24, Loss: 0.437\n",
      "Training: Epoch 33, Batch 25, Loss: 0.715\n",
      "Training: Epoch 33, Batch 26, Loss: 0.3\n",
      "Training: Epoch 33, Batch 27, Loss: 1.096\n",
      "Training: Epoch 33, Batch 28, Loss: 0.632\n",
      "Training: Epoch 33, Batch 29, Loss: 0.617\n",
      "Val: Epoch 33, Loss: 0.295\n",
      "Training: Epoch 34, Batch 0, Loss: 0.368\n",
      "Training: Epoch 34, Batch 1, Loss: 0.498\n",
      "Training: Epoch 34, Batch 2, Loss: 0.381\n",
      "Training: Epoch 34, Batch 3, Loss: 0.526\n",
      "Training: Epoch 34, Batch 4, Loss: 0.739\n",
      "Training: Epoch 34, Batch 5, Loss: 0.527\n",
      "Training: Epoch 34, Batch 6, Loss: 0.544\n",
      "Training: Epoch 34, Batch 7, Loss: 0.519\n",
      "Training: Epoch 34, Batch 8, Loss: 0.497\n",
      "Training: Epoch 34, Batch 9, Loss: 0.457\n",
      "Training: Epoch 34, Batch 10, Loss: 0.617\n",
      "Training: Epoch 34, Batch 11, Loss: 0.564\n",
      "Training: Epoch 34, Batch 12, Loss: 0.584\n",
      "Training: Epoch 34, Batch 13, Loss: 0.528\n",
      "Training: Epoch 34, Batch 14, Loss: 0.569\n",
      "Training: Epoch 34, Batch 15, Loss: 0.588\n",
      "Training: Epoch 34, Batch 16, Loss: 0.549\n",
      "Training: Epoch 34, Batch 17, Loss: 0.73\n",
      "Training: Epoch 34, Batch 18, Loss: 0.543\n",
      "Training: Epoch 34, Batch 19, Loss: 0.498\n",
      "Training: Epoch 34, Batch 20, Loss: 0.566\n",
      "Training: Epoch 34, Batch 21, Loss: 0.407\n",
      "Training: Epoch 34, Batch 22, Loss: 0.585\n",
      "Training: Epoch 34, Batch 23, Loss: 0.63\n",
      "Training: Epoch 34, Batch 24, Loss: 0.73\n",
      "Training: Epoch 34, Batch 25, Loss: 0.534\n",
      "Training: Epoch 34, Batch 26, Loss: 0.47\n",
      "Training: Epoch 34, Batch 27, Loss: 0.557\n",
      "Training: Epoch 34, Batch 28, Loss: 0.67\n",
      "Training: Epoch 34, Batch 29, Loss: 0.687\n",
      "Val: Epoch 34, Loss: 0.348\n",
      "Training: Epoch 35, Batch 0, Loss: 0.507\n",
      "Training: Epoch 35, Batch 1, Loss: 0.469\n",
      "Training: Epoch 35, Batch 2, Loss: 0.407\n",
      "Training: Epoch 35, Batch 3, Loss: 0.852\n",
      "Training: Epoch 35, Batch 4, Loss: 0.455\n",
      "Training: Epoch 35, Batch 5, Loss: 0.504\n",
      "Training: Epoch 35, Batch 6, Loss: 0.62\n",
      "Training: Epoch 35, Batch 7, Loss: 0.511\n",
      "Training: Epoch 35, Batch 8, Loss: 0.693\n",
      "Training: Epoch 35, Batch 9, Loss: 0.516\n",
      "Training: Epoch 35, Batch 10, Loss: 0.366\n",
      "Training: Epoch 35, Batch 11, Loss: 0.472\n",
      "Training: Epoch 35, Batch 12, Loss: 0.613\n",
      "Training: Epoch 35, Batch 13, Loss: 0.639\n",
      "Training: Epoch 35, Batch 14, Loss: 0.475\n",
      "Training: Epoch 35, Batch 15, Loss: 0.613\n",
      "Training: Epoch 35, Batch 16, Loss: 0.431\n",
      "Training: Epoch 35, Batch 17, Loss: 0.721\n",
      "Training: Epoch 35, Batch 18, Loss: 0.436\n",
      "Training: Epoch 35, Batch 19, Loss: 0.628\n",
      "Training: Epoch 35, Batch 20, Loss: 0.413\n",
      "Training: Epoch 35, Batch 21, Loss: 0.707\n",
      "Training: Epoch 35, Batch 22, Loss: 0.497\n",
      "Training: Epoch 35, Batch 23, Loss: 0.439\n",
      "Training: Epoch 35, Batch 24, Loss: 0.292\n",
      "Training: Epoch 35, Batch 25, Loss: 0.414\n",
      "Training: Epoch 35, Batch 26, Loss: 0.428\n",
      "Training: Epoch 35, Batch 27, Loss: 0.497\n",
      "Training: Epoch 35, Batch 28, Loss: 0.434\n",
      "Training: Epoch 35, Batch 29, Loss: 0.719\n",
      "Val: Epoch 35, Loss: 0.281\n",
      "Training: Epoch 36, Batch 0, Loss: 0.541\n",
      "Training: Epoch 36, Batch 1, Loss: 0.5\n",
      "Training: Epoch 36, Batch 2, Loss: 0.749\n",
      "Training: Epoch 36, Batch 3, Loss: 0.652\n",
      "Training: Epoch 36, Batch 4, Loss: 0.558\n",
      "Training: Epoch 36, Batch 5, Loss: 0.486\n",
      "Training: Epoch 36, Batch 6, Loss: 0.628\n",
      "Training: Epoch 36, Batch 7, Loss: 0.376\n",
      "Training: Epoch 36, Batch 8, Loss: 0.595\n",
      "Training: Epoch 36, Batch 9, Loss: 0.294\n",
      "Training: Epoch 36, Batch 10, Loss: 0.579\n",
      "Training: Epoch 36, Batch 11, Loss: 0.544\n",
      "Training: Epoch 36, Batch 12, Loss: 0.455\n",
      "Training: Epoch 36, Batch 13, Loss: 0.47\n",
      "Training: Epoch 36, Batch 14, Loss: 0.463\n",
      "Training: Epoch 36, Batch 15, Loss: 0.49\n",
      "Training: Epoch 36, Batch 16, Loss: 0.795\n",
      "Training: Epoch 36, Batch 17, Loss: 0.364\n",
      "Training: Epoch 36, Batch 18, Loss: 0.86\n",
      "Training: Epoch 36, Batch 19, Loss: 0.362\n",
      "Training: Epoch 36, Batch 20, Loss: 0.704\n",
      "Training: Epoch 36, Batch 21, Loss: 0.51\n",
      "Training: Epoch 36, Batch 22, Loss: 0.503\n",
      "Training: Epoch 36, Batch 23, Loss: 0.572\n",
      "Training: Epoch 36, Batch 24, Loss: 0.391\n",
      "Training: Epoch 36, Batch 25, Loss: 0.456\n",
      "Training: Epoch 36, Batch 26, Loss: 0.556\n",
      "Training: Epoch 36, Batch 27, Loss: 0.527\n",
      "Training: Epoch 36, Batch 28, Loss: 0.459\n",
      "Training: Epoch 36, Batch 29, Loss: 0.511\n",
      "Val: Epoch 36, Loss: 0.405\n",
      "Training: Epoch 37, Batch 0, Loss: 0.402\n",
      "Training: Epoch 37, Batch 1, Loss: 0.429\n",
      "Training: Epoch 37, Batch 2, Loss: 0.574\n",
      "Training: Epoch 37, Batch 3, Loss: 0.565\n",
      "Training: Epoch 37, Batch 4, Loss: 0.391\n",
      "Training: Epoch 37, Batch 5, Loss: 0.386\n",
      "Training: Epoch 37, Batch 6, Loss: 0.551\n",
      "Training: Epoch 37, Batch 7, Loss: 0.54\n",
      "Training: Epoch 37, Batch 8, Loss: 0.522\n",
      "Training: Epoch 37, Batch 9, Loss: 0.708\n",
      "Training: Epoch 37, Batch 10, Loss: 0.285\n",
      "Training: Epoch 37, Batch 11, Loss: 0.402\n",
      "Training: Epoch 37, Batch 12, Loss: 0.475\n",
      "Training: Epoch 37, Batch 13, Loss: 0.504\n",
      "Training: Epoch 37, Batch 14, Loss: 0.616\n",
      "Training: Epoch 37, Batch 15, Loss: 0.442\n",
      "Training: Epoch 37, Batch 16, Loss: 0.789\n",
      "Training: Epoch 37, Batch 17, Loss: 0.542\n",
      "Training: Epoch 37, Batch 18, Loss: 0.456\n",
      "Training: Epoch 37, Batch 19, Loss: 0.422\n",
      "Training: Epoch 37, Batch 20, Loss: 0.606\n",
      "Training: Epoch 37, Batch 21, Loss: 0.715\n",
      "Training: Epoch 37, Batch 22, Loss: 0.625\n",
      "Training: Epoch 37, Batch 23, Loss: 0.495\n",
      "Training: Epoch 37, Batch 24, Loss: 0.54\n",
      "Training: Epoch 37, Batch 25, Loss: 0.244\n",
      "Training: Epoch 37, Batch 26, Loss: 0.578\n",
      "Training: Epoch 37, Batch 27, Loss: 0.719\n",
      "Training: Epoch 37, Batch 28, Loss: 0.394\n",
      "Training: Epoch 37, Batch 29, Loss: 1.207\n",
      "Val: Epoch 37, Loss: 0.483\n",
      "Training: Epoch 38, Batch 0, Loss: 0.559\n",
      "Training: Epoch 38, Batch 1, Loss: 0.605\n",
      "Training: Epoch 38, Batch 2, Loss: 0.526\n",
      "Training: Epoch 38, Batch 3, Loss: 0.505\n",
      "Training: Epoch 38, Batch 4, Loss: 0.883\n",
      "Training: Epoch 38, Batch 5, Loss: 0.434\n",
      "Training: Epoch 38, Batch 6, Loss: 0.519\n",
      "Training: Epoch 38, Batch 7, Loss: 0.791\n",
      "Training: Epoch 38, Batch 8, Loss: 0.378\n",
      "Training: Epoch 38, Batch 9, Loss: 0.478\n",
      "Training: Epoch 38, Batch 10, Loss: 0.423\n",
      "Training: Epoch 38, Batch 11, Loss: 0.491\n",
      "Training: Epoch 38, Batch 12, Loss: 0.458\n",
      "Training: Epoch 38, Batch 13, Loss: 0.456\n",
      "Training: Epoch 38, Batch 14, Loss: 0.614\n",
      "Training: Epoch 38, Batch 15, Loss: 0.578\n",
      "Training: Epoch 38, Batch 16, Loss: 0.527\n",
      "Training: Epoch 38, Batch 17, Loss: 0.538\n",
      "Training: Epoch 38, Batch 18, Loss: 0.543\n",
      "Training: Epoch 38, Batch 19, Loss: 0.34\n",
      "Training: Epoch 38, Batch 20, Loss: 0.865\n",
      "Training: Epoch 38, Batch 21, Loss: 0.32\n",
      "Training: Epoch 38, Batch 22, Loss: 0.332\n",
      "Training: Epoch 38, Batch 23, Loss: 0.541\n",
      "Training: Epoch 38, Batch 24, Loss: 0.497\n",
      "Training: Epoch 38, Batch 25, Loss: 0.559\n",
      "Training: Epoch 38, Batch 26, Loss: 0.396\n",
      "Training: Epoch 38, Batch 27, Loss: 0.64\n",
      "Training: Epoch 38, Batch 28, Loss: 0.475\n",
      "Training: Epoch 38, Batch 29, Loss: 0.52\n",
      "Val: Epoch 38, Loss: 0.437\n",
      "Training: Epoch 39, Batch 0, Loss: 0.431\n",
      "Training: Epoch 39, Batch 1, Loss: 0.531\n",
      "Training: Epoch 39, Batch 2, Loss: 0.872\n",
      "Training: Epoch 39, Batch 3, Loss: 0.719\n",
      "Training: Epoch 39, Batch 4, Loss: 0.302\n",
      "Training: Epoch 39, Batch 5, Loss: 0.365\n",
      "Training: Epoch 39, Batch 6, Loss: 0.562\n",
      "Training: Epoch 39, Batch 7, Loss: 0.439\n",
      "Training: Epoch 39, Batch 8, Loss: 0.369\n",
      "Training: Epoch 39, Batch 9, Loss: 0.441\n",
      "Training: Epoch 39, Batch 10, Loss: 0.712\n",
      "Training: Epoch 39, Batch 11, Loss: 0.575\n",
      "Training: Epoch 39, Batch 12, Loss: 0.487\n",
      "Training: Epoch 39, Batch 13, Loss: 0.482\n",
      "Training: Epoch 39, Batch 14, Loss: 0.771\n",
      "Training: Epoch 39, Batch 15, Loss: 0.372\n",
      "Training: Epoch 39, Batch 16, Loss: 0.423\n",
      "Training: Epoch 39, Batch 17, Loss: 0.488\n",
      "Training: Epoch 39, Batch 18, Loss: 0.502\n",
      "Training: Epoch 39, Batch 19, Loss: 0.49\n",
      "Training: Epoch 39, Batch 20, Loss: 0.532\n",
      "Training: Epoch 39, Batch 21, Loss: 0.443\n",
      "Training: Epoch 39, Batch 22, Loss: 0.434\n",
      "Training: Epoch 39, Batch 23, Loss: 0.496\n",
      "Training: Epoch 39, Batch 24, Loss: 0.698\n",
      "Training: Epoch 39, Batch 25, Loss: 0.551\n",
      "Training: Epoch 39, Batch 26, Loss: 0.398\n",
      "Training: Epoch 39, Batch 27, Loss: 0.437\n",
      "Training: Epoch 39, Batch 28, Loss: 0.461\n",
      "Training: Epoch 39, Batch 29, Loss: 0.448\n",
      "Val: Epoch 39, Loss: 0.332\n",
      "Training: Epoch 40, Batch 0, Loss: 0.432\n",
      "Training: Epoch 40, Batch 1, Loss: 0.292\n",
      "Training: Epoch 40, Batch 2, Loss: 0.62\n",
      "Training: Epoch 40, Batch 3, Loss: 0.718\n",
      "Training: Epoch 40, Batch 4, Loss: 1.455\n",
      "Training: Epoch 40, Batch 5, Loss: 0.356\n",
      "Training: Epoch 40, Batch 6, Loss: 0.434\n",
      "Training: Epoch 40, Batch 7, Loss: 0.331\n",
      "Training: Epoch 40, Batch 8, Loss: 0.373\n",
      "Training: Epoch 40, Batch 9, Loss: 0.549\n",
      "Training: Epoch 40, Batch 10, Loss: 0.732\n",
      "Training: Epoch 40, Batch 11, Loss: 0.684\n",
      "Training: Epoch 40, Batch 12, Loss: 0.471\n",
      "Training: Epoch 40, Batch 13, Loss: 0.473\n",
      "Training: Epoch 40, Batch 14, Loss: 0.493\n",
      "Training: Epoch 40, Batch 15, Loss: 0.604\n",
      "Training: Epoch 40, Batch 16, Loss: 0.423\n",
      "Training: Epoch 40, Batch 17, Loss: 0.681\n",
      "Training: Epoch 40, Batch 18, Loss: 0.439\n",
      "Training: Epoch 40, Batch 19, Loss: 0.346\n",
      "Training: Epoch 40, Batch 20, Loss: 0.551\n",
      "Training: Epoch 40, Batch 21, Loss: 0.47\n",
      "Training: Epoch 40, Batch 22, Loss: 0.524\n",
      "Training: Epoch 40, Batch 23, Loss: 0.48\n",
      "Training: Epoch 40, Batch 24, Loss: 0.671\n",
      "Training: Epoch 40, Batch 25, Loss: 0.331\n",
      "Training: Epoch 40, Batch 26, Loss: 0.564\n",
      "Training: Epoch 40, Batch 27, Loss: 0.601\n",
      "Training: Epoch 40, Batch 28, Loss: 0.718\n",
      "Training: Epoch 40, Batch 29, Loss: 0.407\n",
      "Val: Epoch 40, Loss: 0.353\n",
      "Training: Epoch 41, Batch 0, Loss: 0.628\n",
      "Training: Epoch 41, Batch 1, Loss: 0.57\n",
      "Training: Epoch 41, Batch 2, Loss: 0.47\n",
      "Training: Epoch 41, Batch 3, Loss: 0.656\n",
      "Training: Epoch 41, Batch 4, Loss: 0.634\n",
      "Training: Epoch 41, Batch 5, Loss: 0.51\n",
      "Training: Epoch 41, Batch 6, Loss: 0.433\n",
      "Training: Epoch 41, Batch 7, Loss: 0.309\n",
      "Training: Epoch 41, Batch 8, Loss: 0.675\n",
      "Training: Epoch 41, Batch 9, Loss: 0.554\n",
      "Training: Epoch 41, Batch 10, Loss: 0.564\n",
      "Training: Epoch 41, Batch 11, Loss: 0.382\n",
      "Training: Epoch 41, Batch 12, Loss: 0.55\n",
      "Training: Epoch 41, Batch 13, Loss: 0.495\n",
      "Training: Epoch 41, Batch 14, Loss: 0.854\n",
      "Training: Epoch 41, Batch 15, Loss: 0.623\n",
      "Training: Epoch 41, Batch 16, Loss: 0.392\n",
      "Training: Epoch 41, Batch 17, Loss: 0.509\n",
      "Training: Epoch 41, Batch 18, Loss: 0.43\n",
      "Training: Epoch 41, Batch 19, Loss: 0.515\n",
      "Training: Epoch 41, Batch 20, Loss: 0.355\n",
      "Training: Epoch 41, Batch 21, Loss: 0.485\n",
      "Training: Epoch 41, Batch 22, Loss: 0.593\n",
      "Training: Epoch 41, Batch 23, Loss: 0.519\n",
      "Training: Epoch 41, Batch 24, Loss: 0.618\n",
      "Training: Epoch 41, Batch 25, Loss: 0.421\n",
      "Training: Epoch 41, Batch 26, Loss: 0.59\n",
      "Training: Epoch 41, Batch 27, Loss: 0.382\n",
      "Training: Epoch 41, Batch 28, Loss: 0.384\n",
      "Training: Epoch 41, Batch 29, Loss: 0.339\n",
      "Val: Epoch 41, Loss: 0.313\n",
      "Training: Epoch 42, Batch 0, Loss: 0.506\n",
      "Training: Epoch 42, Batch 1, Loss: 0.524\n",
      "Training: Epoch 42, Batch 2, Loss: 0.5\n",
      "Training: Epoch 42, Batch 3, Loss: 0.561\n",
      "Training: Epoch 42, Batch 4, Loss: 0.391\n",
      "Training: Epoch 42, Batch 5, Loss: 0.4\n",
      "Training: Epoch 42, Batch 6, Loss: 0.514\n",
      "Training: Epoch 42, Batch 7, Loss: 0.511\n",
      "Training: Epoch 42, Batch 8, Loss: 0.617\n",
      "Training: Epoch 42, Batch 9, Loss: 0.49\n",
      "Training: Epoch 42, Batch 10, Loss: 0.642\n",
      "Training: Epoch 42, Batch 11, Loss: 0.476\n",
      "Training: Epoch 42, Batch 12, Loss: 0.556\n",
      "Training: Epoch 42, Batch 13, Loss: 0.407\n",
      "Training: Epoch 42, Batch 14, Loss: 0.485\n",
      "Training: Epoch 42, Batch 15, Loss: 0.542\n",
      "Training: Epoch 42, Batch 16, Loss: 0.433\n",
      "Training: Epoch 42, Batch 17, Loss: 0.386\n",
      "Training: Epoch 42, Batch 18, Loss: 0.537\n",
      "Training: Epoch 42, Batch 19, Loss: 0.436\n",
      "Training: Epoch 42, Batch 20, Loss: 0.479\n",
      "Training: Epoch 42, Batch 21, Loss: 0.476\n",
      "Training: Epoch 42, Batch 22, Loss: 0.34\n",
      "Training: Epoch 42, Batch 23, Loss: 0.401\n",
      "Training: Epoch 42, Batch 24, Loss: 0.616\n",
      "Training: Epoch 42, Batch 25, Loss: 0.727\n",
      "Training: Epoch 42, Batch 26, Loss: 0.425\n",
      "Training: Epoch 42, Batch 27, Loss: 0.581\n",
      "Training: Epoch 42, Batch 28, Loss: 0.62\n",
      "Training: Epoch 42, Batch 29, Loss: 0.39\n",
      "Val: Epoch 42, Loss: 0.293\n",
      "Training: Epoch 43, Batch 0, Loss: 0.456\n",
      "Training: Epoch 43, Batch 1, Loss: 0.324\n",
      "Training: Epoch 43, Batch 2, Loss: 0.638\n",
      "Training: Epoch 43, Batch 3, Loss: 0.531\n",
      "Training: Epoch 43, Batch 4, Loss: 0.505\n",
      "Training: Epoch 43, Batch 5, Loss: 0.451\n",
      "Training: Epoch 43, Batch 6, Loss: 0.708\n",
      "Training: Epoch 43, Batch 7, Loss: 0.476\n",
      "Training: Epoch 43, Batch 8, Loss: 0.366\n",
      "Training: Epoch 43, Batch 9, Loss: 0.578\n",
      "Training: Epoch 43, Batch 10, Loss: 0.362\n",
      "Training: Epoch 43, Batch 11, Loss: 0.638\n",
      "Training: Epoch 43, Batch 12, Loss: 0.546\n",
      "Training: Epoch 43, Batch 13, Loss: 0.524\n",
      "Training: Epoch 43, Batch 14, Loss: 0.381\n",
      "Training: Epoch 43, Batch 15, Loss: 0.508\n",
      "Training: Epoch 43, Batch 16, Loss: 0.327\n",
      "Training: Epoch 43, Batch 17, Loss: 0.428\n",
      "Training: Epoch 43, Batch 18, Loss: 0.459\n",
      "Training: Epoch 43, Batch 19, Loss: 0.477\n",
      "Training: Epoch 43, Batch 20, Loss: 0.552\n",
      "Training: Epoch 43, Batch 21, Loss: 0.62\n",
      "Training: Epoch 43, Batch 22, Loss: 0.396\n",
      "Training: Epoch 43, Batch 23, Loss: 0.447\n",
      "Training: Epoch 43, Batch 24, Loss: 0.485\n",
      "Training: Epoch 43, Batch 25, Loss: 0.345\n",
      "Training: Epoch 43, Batch 26, Loss: 1.727\n",
      "Training: Epoch 43, Batch 27, Loss: 0.571\n",
      "Training: Epoch 43, Batch 28, Loss: 0.651\n",
      "Training: Epoch 43, Batch 29, Loss: 0.602\n",
      "Val: Epoch 43, Loss: 0.281\n",
      "Training: Epoch 44, Batch 0, Loss: 0.414\n",
      "Training: Epoch 44, Batch 1, Loss: 0.475\n",
      "Training: Epoch 44, Batch 2, Loss: 0.592\n",
      "Training: Epoch 44, Batch 3, Loss: 0.562\n",
      "Training: Epoch 44, Batch 4, Loss: 0.544\n",
      "Training: Epoch 44, Batch 5, Loss: 0.344\n",
      "Training: Epoch 44, Batch 6, Loss: 0.678\n",
      "Training: Epoch 44, Batch 7, Loss: 0.59\n",
      "Training: Epoch 44, Batch 8, Loss: 0.573\n",
      "Training: Epoch 44, Batch 9, Loss: 0.557\n",
      "Training: Epoch 44, Batch 10, Loss: 0.578\n",
      "Training: Epoch 44, Batch 11, Loss: 0.4\n",
      "Training: Epoch 44, Batch 12, Loss: 0.318\n",
      "Training: Epoch 44, Batch 13, Loss: 0.475\n",
      "Training: Epoch 44, Batch 14, Loss: 0.587\n",
      "Training: Epoch 44, Batch 15, Loss: 0.487\n",
      "Training: Epoch 44, Batch 16, Loss: 0.718\n",
      "Training: Epoch 44, Batch 17, Loss: 0.475\n",
      "Training: Epoch 44, Batch 18, Loss: 0.533\n",
      "Training: Epoch 44, Batch 19, Loss: 0.496\n",
      "Training: Epoch 44, Batch 20, Loss: 0.751\n",
      "Training: Epoch 44, Batch 21, Loss: 0.529\n",
      "Training: Epoch 44, Batch 22, Loss: 0.499\n",
      "Training: Epoch 44, Batch 23, Loss: 0.632\n",
      "Training: Epoch 44, Batch 24, Loss: 0.381\n",
      "Training: Epoch 44, Batch 25, Loss: 0.589\n",
      "Training: Epoch 44, Batch 26, Loss: 0.463\n",
      "Training: Epoch 44, Batch 27, Loss: 0.438\n",
      "Training: Epoch 44, Batch 28, Loss: 0.377\n",
      "Training: Epoch 44, Batch 29, Loss: 0.326\n",
      "Val: Epoch 44, Loss: 0.284\n",
      "Training: Epoch 45, Batch 0, Loss: 0.498\n",
      "Training: Epoch 45, Batch 1, Loss: 0.618\n",
      "Training: Epoch 45, Batch 2, Loss: 0.398\n",
      "Training: Epoch 45, Batch 3, Loss: 0.49\n",
      "Training: Epoch 45, Batch 4, Loss: 0.701\n",
      "Training: Epoch 45, Batch 5, Loss: 0.331\n",
      "Training: Epoch 45, Batch 6, Loss: 0.434\n",
      "Training: Epoch 45, Batch 7, Loss: 0.574\n",
      "Training: Epoch 45, Batch 8, Loss: 0.628\n",
      "Training: Epoch 45, Batch 9, Loss: 0.759\n",
      "Training: Epoch 45, Batch 10, Loss: 0.318\n",
      "Training: Epoch 45, Batch 11, Loss: 0.753\n",
      "Training: Epoch 45, Batch 12, Loss: 0.431\n",
      "Training: Epoch 45, Batch 13, Loss: 0.597\n",
      "Training: Epoch 45, Batch 14, Loss: 0.511\n",
      "Training: Epoch 45, Batch 15, Loss: 0.512\n",
      "Training: Epoch 45, Batch 16, Loss: 0.496\n",
      "Training: Epoch 45, Batch 17, Loss: 0.316\n",
      "Training: Epoch 45, Batch 18, Loss: 0.51\n",
      "Training: Epoch 45, Batch 19, Loss: 0.405\n",
      "Training: Epoch 45, Batch 20, Loss: 0.422\n",
      "Training: Epoch 45, Batch 21, Loss: 0.594\n",
      "Training: Epoch 45, Batch 22, Loss: 0.601\n",
      "Training: Epoch 45, Batch 23, Loss: 0.456\n",
      "Training: Epoch 45, Batch 24, Loss: 0.286\n",
      "Training: Epoch 45, Batch 25, Loss: 0.594\n",
      "Training: Epoch 45, Batch 26, Loss: 0.392\n",
      "Training: Epoch 45, Batch 27, Loss: 0.546\n",
      "Training: Epoch 45, Batch 28, Loss: 0.661\n",
      "Training: Epoch 45, Batch 29, Loss: 0.496\n",
      "Val: Epoch 45, Loss: 0.286\n",
      "Training: Epoch 46, Batch 0, Loss: 0.611\n",
      "Training: Epoch 46, Batch 1, Loss: 0.551\n",
      "Training: Epoch 46, Batch 2, Loss: 0.616\n",
      "Training: Epoch 46, Batch 3, Loss: 0.638\n",
      "Training: Epoch 46, Batch 4, Loss: 0.597\n",
      "Training: Epoch 46, Batch 5, Loss: 0.53\n",
      "Training: Epoch 46, Batch 6, Loss: 0.55\n",
      "Training: Epoch 46, Batch 7, Loss: 0.676\n",
      "Training: Epoch 46, Batch 8, Loss: 0.599\n",
      "Training: Epoch 46, Batch 9, Loss: 0.556\n",
      "Training: Epoch 46, Batch 10, Loss: 0.441\n",
      "Training: Epoch 46, Batch 11, Loss: 0.392\n",
      "Training: Epoch 46, Batch 12, Loss: 0.613\n",
      "Training: Epoch 46, Batch 13, Loss: 0.333\n",
      "Training: Epoch 46, Batch 14, Loss: 0.432\n",
      "Training: Epoch 46, Batch 15, Loss: 0.501\n",
      "Training: Epoch 46, Batch 16, Loss: 0.398\n",
      "Training: Epoch 46, Batch 17, Loss: 0.412\n",
      "Training: Epoch 46, Batch 18, Loss: 0.622\n",
      "Training: Epoch 46, Batch 19, Loss: 0.584\n",
      "Training: Epoch 46, Batch 20, Loss: 0.456\n",
      "Training: Epoch 46, Batch 21, Loss: 0.285\n",
      "Training: Epoch 46, Batch 22, Loss: 0.603\n",
      "Training: Epoch 46, Batch 23, Loss: 0.612\n",
      "Training: Epoch 46, Batch 24, Loss: 0.405\n",
      "Training: Epoch 46, Batch 25, Loss: 0.52\n",
      "Training: Epoch 46, Batch 26, Loss: 0.333\n",
      "Training: Epoch 46, Batch 27, Loss: 0.286\n",
      "Training: Epoch 46, Batch 28, Loss: 0.3\n",
      "Training: Epoch 46, Batch 29, Loss: 0.554\n",
      "Val: Epoch 46, Loss: 0.277\n",
      "Training: Epoch 47, Batch 0, Loss: 0.431\n",
      "Training: Epoch 47, Batch 1, Loss: 0.469\n",
      "Training: Epoch 47, Batch 2, Loss: 0.334\n",
      "Training: Epoch 47, Batch 3, Loss: 0.462\n",
      "Training: Epoch 47, Batch 4, Loss: 0.473\n",
      "Training: Epoch 47, Batch 5, Loss: 0.428\n",
      "Training: Epoch 47, Batch 6, Loss: 0.393\n",
      "Training: Epoch 47, Batch 7, Loss: 0.576\n",
      "Training: Epoch 47, Batch 8, Loss: 0.653\n",
      "Training: Epoch 47, Batch 9, Loss: 0.406\n",
      "Training: Epoch 47, Batch 10, Loss: 0.574\n",
      "Training: Epoch 47, Batch 11, Loss: 0.529\n",
      "Training: Epoch 47, Batch 12, Loss: 0.655\n",
      "Training: Epoch 47, Batch 13, Loss: 0.44\n",
      "Training: Epoch 47, Batch 14, Loss: 0.652\n",
      "Training: Epoch 47, Batch 15, Loss: 0.449\n",
      "Training: Epoch 47, Batch 16, Loss: 0.301\n",
      "Training: Epoch 47, Batch 17, Loss: 0.549\n",
      "Training: Epoch 47, Batch 18, Loss: 0.382\n",
      "Training: Epoch 47, Batch 19, Loss: 0.692\n",
      "Training: Epoch 47, Batch 20, Loss: 0.595\n",
      "Training: Epoch 47, Batch 21, Loss: 0.436\n",
      "Training: Epoch 47, Batch 22, Loss: 0.393\n",
      "Training: Epoch 47, Batch 23, Loss: 0.478\n",
      "Training: Epoch 47, Batch 24, Loss: 0.551\n",
      "Training: Epoch 47, Batch 25, Loss: 0.658\n",
      "Training: Epoch 47, Batch 26, Loss: 0.647\n",
      "Training: Epoch 47, Batch 27, Loss: 0.484\n",
      "Training: Epoch 47, Batch 28, Loss: 0.617\n",
      "Training: Epoch 47, Batch 29, Loss: 0.452\n",
      "Val: Epoch 47, Loss: 0.285\n",
      "Training: Epoch 48, Batch 0, Loss: 0.427\n",
      "Training: Epoch 48, Batch 1, Loss: 0.52\n",
      "Training: Epoch 48, Batch 2, Loss: 0.747\n",
      "Training: Epoch 48, Batch 3, Loss: 0.285\n",
      "Training: Epoch 48, Batch 4, Loss: 0.401\n",
      "Training: Epoch 48, Batch 5, Loss: 0.525\n",
      "Training: Epoch 48, Batch 6, Loss: 0.285\n",
      "Training: Epoch 48, Batch 7, Loss: 0.444\n",
      "Training: Epoch 48, Batch 8, Loss: 0.758\n",
      "Training: Epoch 48, Batch 9, Loss: 0.515\n",
      "Training: Epoch 48, Batch 10, Loss: 0.663\n",
      "Training: Epoch 48, Batch 11, Loss: 0.624\n",
      "Training: Epoch 48, Batch 12, Loss: 0.562\n",
      "Training: Epoch 48, Batch 13, Loss: 0.399\n",
      "Training: Epoch 48, Batch 14, Loss: 0.656\n",
      "Training: Epoch 48, Batch 15, Loss: 0.417\n",
      "Training: Epoch 48, Batch 16, Loss: 0.345\n",
      "Training: Epoch 48, Batch 17, Loss: 0.406\n",
      "Training: Epoch 48, Batch 18, Loss: 0.789\n",
      "Training: Epoch 48, Batch 19, Loss: 0.306\n",
      "Training: Epoch 48, Batch 20, Loss: 0.625\n",
      "Training: Epoch 48, Batch 21, Loss: 0.635\n",
      "Training: Epoch 48, Batch 22, Loss: 0.411\n",
      "Training: Epoch 48, Batch 23, Loss: 0.408\n",
      "Training: Epoch 48, Batch 24, Loss: 0.526\n",
      "Training: Epoch 48, Batch 25, Loss: 0.483\n",
      "Training: Epoch 48, Batch 26, Loss: 0.634\n",
      "Training: Epoch 48, Batch 27, Loss: 0.503\n",
      "Training: Epoch 48, Batch 28, Loss: 0.567\n",
      "Training: Epoch 48, Batch 29, Loss: 0.327\n",
      "Val: Epoch 48, Loss: 0.3\n",
      "Training: Epoch 49, Batch 0, Loss: 0.41\n",
      "Training: Epoch 49, Batch 1, Loss: 0.332\n",
      "Training: Epoch 49, Batch 2, Loss: 0.273\n",
      "Training: Epoch 49, Batch 3, Loss: 0.421\n",
      "Training: Epoch 49, Batch 4, Loss: 0.576\n",
      "Training: Epoch 49, Batch 5, Loss: 0.395\n",
      "Training: Epoch 49, Batch 6, Loss: 0.492\n",
      "Training: Epoch 49, Batch 7, Loss: 0.554\n",
      "Training: Epoch 49, Batch 8, Loss: 0.439\n",
      "Training: Epoch 49, Batch 9, Loss: 0.53\n",
      "Training: Epoch 49, Batch 10, Loss: 0.61\n",
      "Training: Epoch 49, Batch 11, Loss: 0.501\n",
      "Training: Epoch 49, Batch 12, Loss: 0.663\n",
      "Training: Epoch 49, Batch 13, Loss: 0.497\n",
      "Training: Epoch 49, Batch 14, Loss: 0.622\n",
      "Training: Epoch 49, Batch 15, Loss: 0.351\n",
      "Training: Epoch 49, Batch 16, Loss: 0.579\n",
      "Training: Epoch 49, Batch 17, Loss: 0.423\n",
      "Training: Epoch 49, Batch 18, Loss: 0.523\n",
      "Training: Epoch 49, Batch 19, Loss: 0.576\n",
      "Training: Epoch 49, Batch 20, Loss: 0.635\n",
      "Training: Epoch 49, Batch 21, Loss: 0.442\n",
      "Training: Epoch 49, Batch 22, Loss: 0.499\n",
      "Training: Epoch 49, Batch 23, Loss: 0.563\n",
      "Training: Epoch 49, Batch 24, Loss: 0.314\n",
      "Training: Epoch 49, Batch 25, Loss: 0.44\n",
      "Training: Epoch 49, Batch 26, Loss: 0.771\n",
      "Training: Epoch 49, Batch 27, Loss: 0.735\n",
      "Training: Epoch 49, Batch 28, Loss: 0.504\n",
      "Training: Epoch 49, Batch 29, Loss: 0.374\n",
      "Val: Epoch 49, Loss: 0.282\n",
      "Training: Epoch 50, Batch 0, Loss: 0.488\n",
      "Training: Epoch 50, Batch 1, Loss: 0.225\n",
      "Training: Epoch 50, Batch 2, Loss: 0.415\n",
      "Training: Epoch 50, Batch 3, Loss: 0.518\n",
      "Training: Epoch 50, Batch 4, Loss: 0.444\n",
      "Training: Epoch 50, Batch 5, Loss: 0.367\n",
      "Training: Epoch 50, Batch 6, Loss: 0.448\n",
      "Training: Epoch 50, Batch 7, Loss: 0.412\n",
      "Training: Epoch 50, Batch 8, Loss: 0.66\n",
      "Training: Epoch 50, Batch 9, Loss: 0.487\n",
      "Training: Epoch 50, Batch 10, Loss: 0.348\n",
      "Training: Epoch 50, Batch 11, Loss: 0.4\n",
      "Training: Epoch 50, Batch 12, Loss: 0.323\n",
      "Training: Epoch 50, Batch 13, Loss: 0.595\n",
      "Training: Epoch 50, Batch 14, Loss: 0.397\n",
      "Training: Epoch 50, Batch 15, Loss: 0.385\n",
      "Training: Epoch 50, Batch 16, Loss: 0.434\n",
      "Training: Epoch 50, Batch 17, Loss: 0.612\n",
      "Training: Epoch 50, Batch 18, Loss: 0.745\n",
      "Training: Epoch 50, Batch 19, Loss: 0.61\n",
      "Training: Epoch 50, Batch 20, Loss: 0.704\n",
      "Training: Epoch 50, Batch 21, Loss: 0.574\n",
      "Training: Epoch 50, Batch 22, Loss: 0.578\n",
      "Training: Epoch 50, Batch 23, Loss: 0.41\n",
      "Training: Epoch 50, Batch 24, Loss: 0.587\n",
      "Training: Epoch 50, Batch 25, Loss: 0.674\n",
      "Training: Epoch 50, Batch 26, Loss: 0.635\n",
      "Training: Epoch 50, Batch 27, Loss: 0.524\n",
      "Training: Epoch 50, Batch 28, Loss: 0.52\n",
      "Training: Epoch 50, Batch 29, Loss: 0.366\n",
      "Val: Epoch 50, Loss: 0.273\n",
      "Training: Epoch 51, Batch 0, Loss: 0.492\n",
      "Training: Epoch 51, Batch 1, Loss: 0.376\n",
      "Training: Epoch 51, Batch 2, Loss: 0.58\n",
      "Training: Epoch 51, Batch 3, Loss: 0.649\n",
      "Training: Epoch 51, Batch 4, Loss: 0.46\n",
      "Training: Epoch 51, Batch 5, Loss: 0.282\n",
      "Training: Epoch 51, Batch 6, Loss: 0.359\n",
      "Training: Epoch 51, Batch 7, Loss: 0.385\n",
      "Training: Epoch 51, Batch 8, Loss: 0.481\n",
      "Training: Epoch 51, Batch 9, Loss: 0.312\n",
      "Training: Epoch 51, Batch 10, Loss: 0.691\n",
      "Training: Epoch 51, Batch 11, Loss: 0.517\n",
      "Training: Epoch 51, Batch 12, Loss: 0.407\n",
      "Training: Epoch 51, Batch 13, Loss: 0.409\n",
      "Training: Epoch 51, Batch 14, Loss: 0.716\n",
      "Training: Epoch 51, Batch 15, Loss: 0.819\n",
      "Training: Epoch 51, Batch 16, Loss: 0.729\n",
      "Training: Epoch 51, Batch 17, Loss: 0.505\n",
      "Training: Epoch 51, Batch 18, Loss: 0.345\n",
      "Training: Epoch 51, Batch 19, Loss: 0.457\n",
      "Training: Epoch 51, Batch 20, Loss: 0.391\n",
      "Training: Epoch 51, Batch 21, Loss: 0.443\n",
      "Training: Epoch 51, Batch 22, Loss: 0.32\n",
      "Training: Epoch 51, Batch 23, Loss: 0.443\n",
      "Training: Epoch 51, Batch 24, Loss: 0.571\n",
      "Training: Epoch 51, Batch 25, Loss: 0.641\n",
      "Training: Epoch 51, Batch 26, Loss: 0.298\n",
      "Training: Epoch 51, Batch 27, Loss: 0.509\n",
      "Training: Epoch 51, Batch 28, Loss: 0.554\n",
      "Training: Epoch 51, Batch 29, Loss: 0.709\n",
      "Val: Epoch 51, Loss: 0.303\n",
      "Training: Epoch 52, Batch 0, Loss: 0.471\n",
      "Training: Epoch 52, Batch 1, Loss: 0.553\n",
      "Training: Epoch 52, Batch 2, Loss: 0.426\n",
      "Training: Epoch 52, Batch 3, Loss: 0.437\n",
      "Training: Epoch 52, Batch 4, Loss: 0.497\n",
      "Training: Epoch 52, Batch 5, Loss: 0.344\n",
      "Training: Epoch 52, Batch 6, Loss: 0.304\n",
      "Training: Epoch 52, Batch 7, Loss: 0.371\n",
      "Training: Epoch 52, Batch 8, Loss: 0.467\n",
      "Training: Epoch 52, Batch 9, Loss: 0.304\n",
      "Training: Epoch 52, Batch 10, Loss: 0.51\n",
      "Training: Epoch 52, Batch 11, Loss: 0.748\n",
      "Training: Epoch 52, Batch 12, Loss: 0.624\n",
      "Training: Epoch 52, Batch 13, Loss: 0.673\n",
      "Training: Epoch 52, Batch 14, Loss: 0.487\n",
      "Training: Epoch 52, Batch 15, Loss: 0.487\n",
      "Training: Epoch 52, Batch 16, Loss: 0.396\n",
      "Training: Epoch 52, Batch 17, Loss: 0.661\n",
      "Training: Epoch 52, Batch 18, Loss: 0.484\n",
      "Training: Epoch 52, Batch 19, Loss: 0.623\n",
      "Training: Epoch 52, Batch 20, Loss: 0.634\n",
      "Training: Epoch 52, Batch 21, Loss: 0.361\n",
      "Training: Epoch 52, Batch 22, Loss: 0.4\n",
      "Training: Epoch 52, Batch 23, Loss: 0.759\n",
      "Training: Epoch 52, Batch 24, Loss: 0.416\n",
      "Training: Epoch 52, Batch 25, Loss: 0.538\n",
      "Training: Epoch 52, Batch 26, Loss: 0.387\n",
      "Training: Epoch 52, Batch 27, Loss: 0.486\n",
      "Training: Epoch 52, Batch 28, Loss: 0.348\n",
      "Training: Epoch 52, Batch 29, Loss: 0.513\n",
      "Val: Epoch 52, Loss: 0.337\n",
      "Training: Epoch 53, Batch 0, Loss: 0.404\n",
      "Training: Epoch 53, Batch 1, Loss: 0.618\n",
      "Training: Epoch 53, Batch 2, Loss: 0.809\n",
      "Training: Epoch 53, Batch 3, Loss: 0.314\n",
      "Training: Epoch 53, Batch 4, Loss: 0.438\n",
      "Training: Epoch 53, Batch 5, Loss: 0.623\n",
      "Training: Epoch 53, Batch 6, Loss: 0.359\n",
      "Training: Epoch 53, Batch 7, Loss: 0.363\n",
      "Training: Epoch 53, Batch 8, Loss: 0.27\n",
      "Training: Epoch 53, Batch 9, Loss: 0.496\n",
      "Training: Epoch 53, Batch 10, Loss: 0.42\n",
      "Training: Epoch 53, Batch 11, Loss: 0.389\n",
      "Training: Epoch 53, Batch 12, Loss: 0.362\n",
      "Training: Epoch 53, Batch 13, Loss: 0.408\n",
      "Training: Epoch 53, Batch 14, Loss: 0.544\n",
      "Training: Epoch 53, Batch 15, Loss: 0.549\n",
      "Training: Epoch 53, Batch 16, Loss: 0.473\n",
      "Training: Epoch 53, Batch 17, Loss: 0.533\n",
      "Training: Epoch 53, Batch 18, Loss: 0.428\n",
      "Training: Epoch 53, Batch 19, Loss: 0.661\n",
      "Training: Epoch 53, Batch 20, Loss: 0.618\n",
      "Training: Epoch 53, Batch 21, Loss: 0.289\n",
      "Training: Epoch 53, Batch 22, Loss: 0.502\n",
      "Training: Epoch 53, Batch 23, Loss: 0.697\n",
      "Training: Epoch 53, Batch 24, Loss: 0.62\n",
      "Training: Epoch 53, Batch 25, Loss: 0.525\n",
      "Training: Epoch 53, Batch 26, Loss: 0.494\n",
      "Training: Epoch 53, Batch 27, Loss: 0.645\n",
      "Training: Epoch 53, Batch 28, Loss: 0.433\n",
      "Training: Epoch 53, Batch 29, Loss: 0.543\n",
      "Val: Epoch 53, Loss: 0.277\n",
      "Training: Epoch 54, Batch 0, Loss: 0.413\n",
      "Training: Epoch 54, Batch 1, Loss: 0.486\n",
      "Training: Epoch 54, Batch 2, Loss: 0.474\n",
      "Training: Epoch 54, Batch 3, Loss: 0.305\n",
      "Training: Epoch 54, Batch 4, Loss: 0.465\n",
      "Training: Epoch 54, Batch 5, Loss: 0.254\n",
      "Training: Epoch 54, Batch 6, Loss: 0.593\n",
      "Training: Epoch 54, Batch 7, Loss: 0.524\n",
      "Training: Epoch 54, Batch 8, Loss: 0.618\n",
      "Training: Epoch 54, Batch 9, Loss: 0.259\n",
      "Training: Epoch 54, Batch 10, Loss: 0.28\n",
      "Training: Epoch 54, Batch 11, Loss: 0.59\n",
      "Training: Epoch 54, Batch 12, Loss: 1.52\n",
      "Training: Epoch 54, Batch 13, Loss: 0.48\n",
      "Training: Epoch 54, Batch 14, Loss: 0.533\n",
      "Training: Epoch 54, Batch 15, Loss: 0.479\n",
      "Training: Epoch 54, Batch 16, Loss: 0.511\n",
      "Training: Epoch 54, Batch 17, Loss: 0.315\n",
      "Training: Epoch 54, Batch 18, Loss: 0.409\n",
      "Training: Epoch 54, Batch 19, Loss: 0.571\n",
      "Training: Epoch 54, Batch 20, Loss: 0.633\n",
      "Training: Epoch 54, Batch 21, Loss: 0.316\n",
      "Training: Epoch 54, Batch 22, Loss: 0.685\n",
      "Training: Epoch 54, Batch 23, Loss: 0.446\n",
      "Training: Epoch 54, Batch 24, Loss: 0.453\n",
      "Training: Epoch 54, Batch 25, Loss: 0.702\n",
      "Training: Epoch 54, Batch 26, Loss: 0.478\n",
      "Training: Epoch 54, Batch 27, Loss: 0.484\n",
      "Training: Epoch 54, Batch 28, Loss: 0.613\n",
      "Training: Epoch 54, Batch 29, Loss: 0.557\n",
      "Val: Epoch 54, Loss: 0.287\n",
      "Training: Epoch 55, Batch 0, Loss: 0.575\n",
      "Training: Epoch 55, Batch 1, Loss: 0.376\n",
      "Training: Epoch 55, Batch 2, Loss: 0.582\n",
      "Training: Epoch 55, Batch 3, Loss: 0.368\n",
      "Training: Epoch 55, Batch 4, Loss: 0.563\n",
      "Training: Epoch 55, Batch 5, Loss: 0.628\n",
      "Training: Epoch 55, Batch 6, Loss: 0.524\n",
      "Training: Epoch 55, Batch 7, Loss: 0.466\n",
      "Training: Epoch 55, Batch 8, Loss: 0.44\n",
      "Training: Epoch 55, Batch 9, Loss: 0.916\n",
      "Training: Epoch 55, Batch 10, Loss: 0.324\n",
      "Training: Epoch 55, Batch 11, Loss: 0.505\n",
      "Training: Epoch 55, Batch 12, Loss: 0.371\n",
      "Training: Epoch 55, Batch 13, Loss: 0.303\n",
      "Training: Epoch 55, Batch 14, Loss: 0.538\n",
      "Training: Epoch 55, Batch 15, Loss: 0.625\n",
      "Training: Epoch 55, Batch 16, Loss: 0.594\n",
      "Training: Epoch 55, Batch 17, Loss: 0.327\n",
      "Training: Epoch 55, Batch 18, Loss: 0.532\n",
      "Training: Epoch 55, Batch 19, Loss: 0.465\n",
      "Training: Epoch 55, Batch 20, Loss: 0.399\n",
      "Training: Epoch 55, Batch 21, Loss: 0.378\n",
      "Training: Epoch 55, Batch 22, Loss: 0.67\n",
      "Training: Epoch 55, Batch 23, Loss: 0.396\n",
      "Training: Epoch 55, Batch 24, Loss: 0.357\n",
      "Training: Epoch 55, Batch 25, Loss: 0.35\n",
      "Training: Epoch 55, Batch 26, Loss: 0.573\n",
      "Training: Epoch 55, Batch 27, Loss: 0.636\n",
      "Training: Epoch 55, Batch 28, Loss: 0.449\n",
      "Training: Epoch 55, Batch 29, Loss: 0.32\n",
      "Val: Epoch 55, Loss: 0.349\n",
      "Training: Epoch 56, Batch 0, Loss: 0.215\n",
      "Training: Epoch 56, Batch 1, Loss: 0.634\n",
      "Training: Epoch 56, Batch 2, Loss: 0.331\n",
      "Training: Epoch 56, Batch 3, Loss: 0.486\n",
      "Training: Epoch 56, Batch 4, Loss: 0.397\n",
      "Training: Epoch 56, Batch 5, Loss: 0.443\n",
      "Training: Epoch 56, Batch 6, Loss: 0.498\n",
      "Training: Epoch 56, Batch 7, Loss: 0.47\n",
      "Training: Epoch 56, Batch 8, Loss: 0.321\n",
      "Training: Epoch 56, Batch 9, Loss: 0.575\n",
      "Training: Epoch 56, Batch 10, Loss: 0.522\n",
      "Training: Epoch 56, Batch 11, Loss: 0.538\n",
      "Training: Epoch 56, Batch 12, Loss: 0.587\n",
      "Training: Epoch 56, Batch 13, Loss: 0.429\n",
      "Training: Epoch 56, Batch 14, Loss: 0.499\n",
      "Training: Epoch 56, Batch 15, Loss: 0.327\n",
      "Training: Epoch 56, Batch 16, Loss: 0.453\n",
      "Training: Epoch 56, Batch 17, Loss: 0.422\n",
      "Training: Epoch 56, Batch 18, Loss: 0.446\n",
      "Training: Epoch 56, Batch 19, Loss: 0.521\n",
      "Training: Epoch 56, Batch 20, Loss: 0.896\n",
      "Training: Epoch 56, Batch 21, Loss: 0.488\n",
      "Training: Epoch 56, Batch 22, Loss: 0.465\n",
      "Training: Epoch 56, Batch 23, Loss: 0.431\n",
      "Training: Epoch 56, Batch 24, Loss: 0.612\n",
      "Training: Epoch 56, Batch 25, Loss: 0.431\n",
      "Training: Epoch 56, Batch 26, Loss: 0.489\n",
      "Training: Epoch 56, Batch 27, Loss: 0.737\n",
      "Training: Epoch 56, Batch 28, Loss: 0.672\n",
      "Training: Epoch 56, Batch 29, Loss: 0.604\n",
      "Val: Epoch 56, Loss: 0.285\n",
      "Training: Epoch 57, Batch 0, Loss: 0.382\n",
      "Training: Epoch 57, Batch 1, Loss: 0.547\n",
      "Training: Epoch 57, Batch 2, Loss: 0.507\n",
      "Training: Epoch 57, Batch 3, Loss: 0.639\n",
      "Training: Epoch 57, Batch 4, Loss: 0.398\n",
      "Training: Epoch 57, Batch 5, Loss: 0.572\n",
      "Training: Epoch 57, Batch 6, Loss: 0.412\n",
      "Training: Epoch 57, Batch 7, Loss: 0.521\n",
      "Training: Epoch 57, Batch 8, Loss: 0.65\n",
      "Training: Epoch 57, Batch 9, Loss: 0.387\n",
      "Training: Epoch 57, Batch 10, Loss: 0.582\n",
      "Training: Epoch 57, Batch 11, Loss: 0.434\n",
      "Training: Epoch 57, Batch 12, Loss: 0.462\n",
      "Training: Epoch 57, Batch 13, Loss: 0.344\n",
      "Training: Epoch 57, Batch 14, Loss: 0.449\n",
      "Training: Epoch 57, Batch 15, Loss: 0.367\n",
      "Training: Epoch 57, Batch 16, Loss: 0.522\n",
      "Training: Epoch 57, Batch 17, Loss: 0.298\n",
      "Training: Epoch 57, Batch 18, Loss: 0.483\n",
      "Training: Epoch 57, Batch 19, Loss: 0.567\n",
      "Training: Epoch 57, Batch 20, Loss: 0.666\n",
      "Training: Epoch 57, Batch 21, Loss: 0.682\n",
      "Training: Epoch 57, Batch 22, Loss: 0.29\n",
      "Training: Epoch 57, Batch 23, Loss: 0.527\n",
      "Training: Epoch 57, Batch 24, Loss: 0.392\n",
      "Training: Epoch 57, Batch 25, Loss: 0.415\n",
      "Training: Epoch 57, Batch 26, Loss: 0.447\n",
      "Training: Epoch 57, Batch 27, Loss: 0.577\n",
      "Training: Epoch 57, Batch 28, Loss: 0.486\n",
      "Training: Epoch 57, Batch 29, Loss: 0.437\n",
      "Val: Epoch 57, Loss: 0.27\n",
      "Training: Epoch 58, Batch 0, Loss: 0.394\n",
      "Training: Epoch 58, Batch 1, Loss: 0.496\n",
      "Training: Epoch 58, Batch 2, Loss: 0.423\n",
      "Training: Epoch 58, Batch 3, Loss: 0.471\n",
      "Training: Epoch 58, Batch 4, Loss: 0.78\n",
      "Training: Epoch 58, Batch 5, Loss: 0.546\n",
      "Training: Epoch 58, Batch 6, Loss: 0.332\n",
      "Training: Epoch 58, Batch 7, Loss: 0.346\n",
      "Training: Epoch 58, Batch 8, Loss: 0.421\n",
      "Training: Epoch 58, Batch 9, Loss: 0.287\n",
      "Training: Epoch 58, Batch 10, Loss: 0.596\n",
      "Training: Epoch 58, Batch 11, Loss: 0.456\n",
      "Training: Epoch 58, Batch 12, Loss: 0.444\n",
      "Training: Epoch 58, Batch 13, Loss: 0.558\n",
      "Training: Epoch 58, Batch 14, Loss: 0.472\n",
      "Training: Epoch 58, Batch 15, Loss: 0.345\n",
      "Training: Epoch 58, Batch 16, Loss: 0.465\n",
      "Training: Epoch 58, Batch 17, Loss: 0.487\n",
      "Training: Epoch 58, Batch 18, Loss: 0.492\n",
      "Training: Epoch 58, Batch 19, Loss: 0.601\n",
      "Training: Epoch 58, Batch 20, Loss: 0.442\n",
      "Training: Epoch 58, Batch 21, Loss: 0.293\n",
      "Training: Epoch 58, Batch 22, Loss: 0.673\n",
      "Training: Epoch 58, Batch 23, Loss: 0.649\n",
      "Training: Epoch 58, Batch 24, Loss: 0.311\n",
      "Training: Epoch 58, Batch 25, Loss: 0.421\n",
      "Training: Epoch 58, Batch 26, Loss: 0.459\n",
      "Training: Epoch 58, Batch 27, Loss: 0.53\n",
      "Training: Epoch 58, Batch 28, Loss: 0.481\n",
      "Training: Epoch 58, Batch 29, Loss: 0.665\n",
      "Val: Epoch 58, Loss: 0.332\n",
      "Training: Epoch 59, Batch 0, Loss: 0.526\n",
      "Training: Epoch 59, Batch 1, Loss: 0.549\n",
      "Training: Epoch 59, Batch 2, Loss: 0.412\n",
      "Training: Epoch 59, Batch 3, Loss: 0.485\n",
      "Training: Epoch 59, Batch 4, Loss: 0.435\n",
      "Training: Epoch 59, Batch 5, Loss: 0.689\n",
      "Training: Epoch 59, Batch 6, Loss: 0.298\n",
      "Training: Epoch 59, Batch 7, Loss: 0.577\n",
      "Training: Epoch 59, Batch 8, Loss: 0.559\n",
      "Training: Epoch 59, Batch 9, Loss: 0.34\n",
      "Training: Epoch 59, Batch 10, Loss: 0.503\n",
      "Training: Epoch 59, Batch 11, Loss: 0.369\n",
      "Training: Epoch 59, Batch 12, Loss: 0.239\n",
      "Training: Epoch 59, Batch 13, Loss: 0.58\n",
      "Training: Epoch 59, Batch 14, Loss: 0.626\n",
      "Training: Epoch 59, Batch 15, Loss: 0.498\n",
      "Training: Epoch 59, Batch 16, Loss: 0.53\n",
      "Training: Epoch 59, Batch 17, Loss: 0.287\n",
      "Training: Epoch 59, Batch 18, Loss: 0.385\n",
      "Training: Epoch 59, Batch 19, Loss: 0.495\n",
      "Training: Epoch 59, Batch 20, Loss: 0.291\n",
      "Training: Epoch 59, Batch 21, Loss: 0.582\n",
      "Training: Epoch 59, Batch 22, Loss: 0.896\n",
      "Training: Epoch 59, Batch 23, Loss: 0.546\n",
      "Training: Epoch 59, Batch 24, Loss: 0.464\n",
      "Training: Epoch 59, Batch 25, Loss: 0.598\n",
      "Training: Epoch 59, Batch 26, Loss: 0.43\n",
      "Training: Epoch 59, Batch 27, Loss: 0.551\n",
      "Training: Epoch 59, Batch 28, Loss: 0.35\n",
      "Training: Epoch 59, Batch 29, Loss: 0.652\n",
      "Val: Epoch 59, Loss: 0.448\n",
      "Training: Epoch 60, Batch 0, Loss: 0.573\n",
      "Training: Epoch 60, Batch 1, Loss: 0.698\n",
      "Training: Epoch 60, Batch 2, Loss: 0.347\n",
      "Training: Epoch 60, Batch 3, Loss: 0.378\n",
      "Training: Epoch 60, Batch 4, Loss: 0.444\n",
      "Training: Epoch 60, Batch 5, Loss: 0.417\n",
      "Training: Epoch 60, Batch 6, Loss: 0.439\n",
      "Training: Epoch 60, Batch 7, Loss: 0.495\n",
      "Training: Epoch 60, Batch 8, Loss: 0.631\n",
      "Training: Epoch 60, Batch 9, Loss: 0.494\n",
      "Training: Epoch 60, Batch 10, Loss: 0.41\n",
      "Training: Epoch 60, Batch 11, Loss: 0.292\n",
      "Training: Epoch 60, Batch 12, Loss: 0.665\n",
      "Training: Epoch 60, Batch 13, Loss: 0.55\n",
      "Training: Epoch 60, Batch 14, Loss: 0.347\n",
      "Training: Epoch 60, Batch 15, Loss: 0.856\n",
      "Training: Epoch 60, Batch 16, Loss: 0.431\n",
      "Training: Epoch 60, Batch 17, Loss: 0.353\n",
      "Training: Epoch 60, Batch 18, Loss: 0.458\n",
      "Training: Epoch 60, Batch 19, Loss: 0.511\n",
      "Training: Epoch 60, Batch 20, Loss: 0.48\n",
      "Training: Epoch 60, Batch 21, Loss: 0.432\n",
      "Training: Epoch 60, Batch 22, Loss: 0.44\n",
      "Training: Epoch 60, Batch 23, Loss: 0.467\n",
      "Training: Epoch 60, Batch 24, Loss: 0.443\n",
      "Training: Epoch 60, Batch 25, Loss: 0.547\n",
      "Training: Epoch 60, Batch 26, Loss: 0.596\n",
      "Training: Epoch 60, Batch 27, Loss: 0.419\n",
      "Training: Epoch 60, Batch 28, Loss: 0.523\n",
      "Training: Epoch 60, Batch 29, Loss: 0.401\n",
      "Val: Epoch 60, Loss: 0.374\n",
      "Training: Epoch 61, Batch 0, Loss: 0.367\n",
      "Training: Epoch 61, Batch 1, Loss: 0.323\n",
      "Training: Epoch 61, Batch 2, Loss: 0.261\n",
      "Training: Epoch 61, Batch 3, Loss: 0.575\n",
      "Training: Epoch 61, Batch 4, Loss: 0.538\n",
      "Training: Epoch 61, Batch 5, Loss: 0.323\n",
      "Training: Epoch 61, Batch 6, Loss: 0.596\n",
      "Training: Epoch 61, Batch 7, Loss: 0.346\n",
      "Training: Epoch 61, Batch 8, Loss: 0.484\n",
      "Training: Epoch 61, Batch 9, Loss: 0.546\n",
      "Training: Epoch 61, Batch 10, Loss: 0.358\n",
      "Training: Epoch 61, Batch 11, Loss: 0.584\n",
      "Training: Epoch 61, Batch 12, Loss: 0.378\n",
      "Training: Epoch 61, Batch 13, Loss: 0.715\n",
      "Training: Epoch 61, Batch 14, Loss: 0.506\n",
      "Training: Epoch 61, Batch 15, Loss: 0.429\n",
      "Training: Epoch 61, Batch 16, Loss: 0.538\n",
      "Training: Epoch 61, Batch 17, Loss: 0.62\n",
      "Training: Epoch 61, Batch 18, Loss: 0.414\n",
      "Training: Epoch 61, Batch 19, Loss: 0.438\n",
      "Training: Epoch 61, Batch 20, Loss: 0.703\n",
      "Training: Epoch 61, Batch 21, Loss: 0.686\n",
      "Training: Epoch 61, Batch 22, Loss: 0.527\n",
      "Training: Epoch 61, Batch 23, Loss: 0.44\n",
      "Training: Epoch 61, Batch 24, Loss: 0.507\n",
      "Training: Epoch 61, Batch 25, Loss: 0.373\n",
      "Training: Epoch 61, Batch 26, Loss: 0.558\n",
      "Training: Epoch 61, Batch 27, Loss: 1.119\n",
      "Training: Epoch 61, Batch 28, Loss: 0.331\n",
      "Training: Epoch 61, Batch 29, Loss: 0.306\n",
      "Val: Epoch 61, Loss: 0.309\n",
      "Training: Epoch 62, Batch 0, Loss: 0.338\n",
      "Training: Epoch 62, Batch 1, Loss: 0.448\n",
      "Training: Epoch 62, Batch 2, Loss: 0.277\n",
      "Training: Epoch 62, Batch 3, Loss: 0.436\n",
      "Training: Epoch 62, Batch 4, Loss: 0.553\n",
      "Training: Epoch 62, Batch 5, Loss: 0.73\n",
      "Training: Epoch 62, Batch 6, Loss: 0.608\n",
      "Training: Epoch 62, Batch 7, Loss: 0.505\n",
      "Training: Epoch 62, Batch 8, Loss: 0.513\n",
      "Training: Epoch 62, Batch 9, Loss: 0.667\n",
      "Training: Epoch 62, Batch 10, Loss: 0.614\n",
      "Training: Epoch 62, Batch 11, Loss: 0.492\n",
      "Training: Epoch 62, Batch 12, Loss: 0.634\n",
      "Training: Epoch 62, Batch 13, Loss: 0.472\n",
      "Training: Epoch 62, Batch 14, Loss: 0.484\n",
      "Training: Epoch 62, Batch 15, Loss: 0.461\n",
      "Training: Epoch 62, Batch 16, Loss: 0.555\n",
      "Training: Epoch 62, Batch 17, Loss: 0.513\n",
      "Training: Epoch 62, Batch 18, Loss: 0.452\n",
      "Training: Epoch 62, Batch 19, Loss: 0.472\n",
      "Training: Epoch 62, Batch 20, Loss: 0.456\n",
      "Training: Epoch 62, Batch 21, Loss: 0.536\n",
      "Training: Epoch 62, Batch 22, Loss: 0.536\n",
      "Training: Epoch 62, Batch 23, Loss: 0.889\n",
      "Training: Epoch 62, Batch 24, Loss: 0.474\n",
      "Training: Epoch 62, Batch 25, Loss: 0.401\n",
      "Training: Epoch 62, Batch 26, Loss: 0.464\n",
      "Training: Epoch 62, Batch 27, Loss: 0.349\n",
      "Training: Epoch 62, Batch 28, Loss: 0.612\n",
      "Training: Epoch 62, Batch 29, Loss: 0.329\n",
      "Val: Epoch 62, Loss: 0.3\n",
      "Training: Epoch 63, Batch 0, Loss: 0.384\n",
      "Training: Epoch 63, Batch 1, Loss: 0.497\n",
      "Training: Epoch 63, Batch 2, Loss: 0.424\n",
      "Training: Epoch 63, Batch 3, Loss: 0.606\n",
      "Training: Epoch 63, Batch 4, Loss: 0.496\n",
      "Training: Epoch 63, Batch 5, Loss: 0.669\n",
      "Training: Epoch 63, Batch 6, Loss: 0.42\n",
      "Training: Epoch 63, Batch 7, Loss: 0.347\n",
      "Training: Epoch 63, Batch 8, Loss: 0.528\n",
      "Training: Epoch 63, Batch 9, Loss: 0.492\n",
      "Training: Epoch 63, Batch 10, Loss: 0.42\n",
      "Training: Epoch 63, Batch 11, Loss: 0.61\n",
      "Training: Epoch 63, Batch 12, Loss: 0.712\n",
      "Training: Epoch 63, Batch 13, Loss: 0.605\n",
      "Training: Epoch 63, Batch 14, Loss: 0.517\n",
      "Training: Epoch 63, Batch 15, Loss: 0.356\n",
      "Training: Epoch 63, Batch 16, Loss: 0.557\n",
      "Training: Epoch 63, Batch 17, Loss: 0.75\n",
      "Training: Epoch 63, Batch 18, Loss: 0.683\n",
      "Training: Epoch 63, Batch 19, Loss: 0.347\n",
      "Training: Epoch 63, Batch 20, Loss: 0.665\n",
      "Training: Epoch 63, Batch 21, Loss: 0.447\n",
      "Training: Epoch 63, Batch 22, Loss: 0.559\n",
      "Training: Epoch 63, Batch 23, Loss: 0.504\n",
      "Training: Epoch 63, Batch 24, Loss: 0.339\n",
      "Training: Epoch 63, Batch 25, Loss: 0.4\n",
      "Training: Epoch 63, Batch 26, Loss: 0.478\n",
      "Training: Epoch 63, Batch 27, Loss: 0.423\n",
      "Training: Epoch 63, Batch 28, Loss: 0.392\n",
      "Training: Epoch 63, Batch 29, Loss: 0.58\n",
      "Val: Epoch 63, Loss: 0.305\n",
      "Training: Epoch 64, Batch 0, Loss: 0.5\n",
      "Training: Epoch 64, Batch 1, Loss: 0.297\n",
      "Training: Epoch 64, Batch 2, Loss: 0.578\n",
      "Training: Epoch 64, Batch 3, Loss: 0.472\n",
      "Training: Epoch 64, Batch 4, Loss: 0.347\n",
      "Training: Epoch 64, Batch 5, Loss: 0.456\n",
      "Training: Epoch 64, Batch 6, Loss: 0.466\n",
      "Training: Epoch 64, Batch 7, Loss: 0.565\n",
      "Training: Epoch 64, Batch 8, Loss: 0.555\n",
      "Training: Epoch 64, Batch 9, Loss: 0.409\n",
      "Training: Epoch 64, Batch 10, Loss: 0.663\n",
      "Training: Epoch 64, Batch 11, Loss: 0.487\n",
      "Training: Epoch 64, Batch 12, Loss: 0.56\n",
      "Training: Epoch 64, Batch 13, Loss: 0.434\n",
      "Training: Epoch 64, Batch 14, Loss: 0.499\n",
      "Training: Epoch 64, Batch 15, Loss: 0.433\n",
      "Training: Epoch 64, Batch 16, Loss: 0.534\n",
      "Training: Epoch 64, Batch 17, Loss: 0.561\n",
      "Training: Epoch 64, Batch 18, Loss: 0.676\n",
      "Training: Epoch 64, Batch 19, Loss: 0.278\n",
      "Training: Epoch 64, Batch 20, Loss: 0.601\n",
      "Training: Epoch 64, Batch 21, Loss: 0.689\n",
      "Training: Epoch 64, Batch 22, Loss: 0.315\n",
      "Training: Epoch 64, Batch 23, Loss: 0.464\n",
      "Training: Epoch 64, Batch 24, Loss: 0.412\n",
      "Training: Epoch 64, Batch 25, Loss: 0.74\n",
      "Training: Epoch 64, Batch 26, Loss: 0.351\n",
      "Training: Epoch 64, Batch 27, Loss: 0.615\n",
      "Training: Epoch 64, Batch 28, Loss: 0.536\n",
      "Training: Epoch 64, Batch 29, Loss: 0.631\n",
      "Val: Epoch 64, Loss: 0.387\n",
      "Training: Epoch 65, Batch 0, Loss: 0.612\n",
      "Training: Epoch 65, Batch 1, Loss: 0.397\n",
      "Training: Epoch 65, Batch 2, Loss: 0.605\n",
      "Training: Epoch 65, Batch 3, Loss: 0.411\n",
      "Training: Epoch 65, Batch 4, Loss: 0.494\n",
      "Training: Epoch 65, Batch 5, Loss: 0.568\n",
      "Training: Epoch 65, Batch 6, Loss: 0.407\n",
      "Training: Epoch 65, Batch 7, Loss: 0.617\n",
      "Training: Epoch 65, Batch 8, Loss: 0.585\n",
      "Training: Epoch 65, Batch 9, Loss: 0.304\n",
      "Training: Epoch 65, Batch 10, Loss: 0.598\n",
      "Training: Epoch 65, Batch 11, Loss: 0.519\n",
      "Training: Epoch 65, Batch 12, Loss: 0.468\n",
      "Training: Epoch 65, Batch 13, Loss: 0.349\n",
      "Training: Epoch 65, Batch 14, Loss: 0.517\n",
      "Training: Epoch 65, Batch 15, Loss: 0.781\n",
      "Training: Epoch 65, Batch 16, Loss: 0.316\n",
      "Training: Epoch 65, Batch 17, Loss: 0.574\n",
      "Training: Epoch 65, Batch 18, Loss: 0.32\n",
      "Training: Epoch 65, Batch 19, Loss: 0.513\n",
      "Training: Epoch 65, Batch 20, Loss: 0.575\n",
      "Training: Epoch 65, Batch 21, Loss: 0.431\n",
      "Training: Epoch 65, Batch 22, Loss: 0.477\n",
      "Training: Epoch 65, Batch 23, Loss: 0.576\n",
      "Training: Epoch 65, Batch 24, Loss: 0.511\n",
      "Training: Epoch 65, Batch 25, Loss: 0.33\n",
      "Training: Epoch 65, Batch 26, Loss: 0.546\n",
      "Training: Epoch 65, Batch 27, Loss: 0.317\n",
      "Training: Epoch 65, Batch 28, Loss: 0.645\n",
      "Training: Epoch 65, Batch 29, Loss: 0.697\n",
      "Val: Epoch 65, Loss: 0.432\n",
      "Training: Epoch 66, Batch 0, Loss: 0.798\n",
      "Training: Epoch 66, Batch 1, Loss: 0.684\n",
      "Training: Epoch 66, Batch 2, Loss: 0.54\n",
      "Training: Epoch 66, Batch 3, Loss: 0.484\n",
      "Training: Epoch 66, Batch 4, Loss: 0.446\n",
      "Training: Epoch 66, Batch 5, Loss: 0.396\n",
      "Training: Epoch 66, Batch 6, Loss: 0.49\n",
      "Training: Epoch 66, Batch 7, Loss: 0.593\n",
      "Training: Epoch 66, Batch 8, Loss: 0.554\n",
      "Training: Epoch 66, Batch 9, Loss: 0.533\n",
      "Training: Epoch 66, Batch 10, Loss: 0.383\n",
      "Training: Epoch 66, Batch 11, Loss: 0.659\n",
      "Training: Epoch 66, Batch 12, Loss: 0.515\n",
      "Training: Epoch 66, Batch 13, Loss: 0.386\n",
      "Training: Epoch 66, Batch 14, Loss: 0.433\n",
      "Training: Epoch 66, Batch 15, Loss: 0.322\n",
      "Training: Epoch 66, Batch 16, Loss: 0.5\n",
      "Training: Epoch 66, Batch 17, Loss: 0.448\n",
      "Training: Epoch 66, Batch 18, Loss: 0.35\n",
      "Training: Epoch 66, Batch 19, Loss: 0.658\n",
      "Training: Epoch 66, Batch 20, Loss: 0.48\n",
      "Training: Epoch 66, Batch 21, Loss: 0.464\n",
      "Training: Epoch 66, Batch 22, Loss: 0.558\n",
      "Training: Epoch 66, Batch 23, Loss: 0.576\n",
      "Training: Epoch 66, Batch 24, Loss: 0.421\n",
      "Training: Epoch 66, Batch 25, Loss: 0.321\n",
      "Training: Epoch 66, Batch 26, Loss: 0.514\n",
      "Training: Epoch 66, Batch 27, Loss: 0.408\n",
      "Training: Epoch 66, Batch 28, Loss: 0.615\n",
      "Training: Epoch 66, Batch 29, Loss: 0.239\n",
      "Val: Epoch 66, Loss: 0.286\n",
      "Training: Epoch 67, Batch 0, Loss: 0.733\n",
      "Training: Epoch 67, Batch 1, Loss: 0.398\n",
      "Training: Epoch 67, Batch 2, Loss: 0.403\n",
      "Training: Epoch 67, Batch 3, Loss: 0.394\n",
      "Training: Epoch 67, Batch 4, Loss: 0.317\n",
      "Training: Epoch 67, Batch 5, Loss: 0.679\n",
      "Training: Epoch 67, Batch 6, Loss: 0.452\n",
      "Training: Epoch 67, Batch 7, Loss: 0.348\n",
      "Training: Epoch 67, Batch 8, Loss: 0.723\n",
      "Training: Epoch 67, Batch 9, Loss: 0.415\n",
      "Training: Epoch 67, Batch 10, Loss: 0.601\n",
      "Training: Epoch 67, Batch 11, Loss: 0.638\n",
      "Training: Epoch 67, Batch 12, Loss: 0.374\n",
      "Training: Epoch 67, Batch 13, Loss: 0.477\n",
      "Training: Epoch 67, Batch 14, Loss: 0.353\n",
      "Training: Epoch 67, Batch 15, Loss: 0.777\n",
      "Training: Epoch 67, Batch 16, Loss: 0.386\n",
      "Training: Epoch 67, Batch 17, Loss: 0.393\n",
      "Training: Epoch 67, Batch 18, Loss: 0.299\n",
      "Training: Epoch 67, Batch 19, Loss: 0.524\n",
      "Training: Epoch 67, Batch 20, Loss: 0.621\n",
      "Training: Epoch 67, Batch 21, Loss: 0.274\n",
      "Training: Epoch 67, Batch 22, Loss: 0.317\n",
      "Training: Epoch 67, Batch 23, Loss: 0.665\n",
      "Training: Epoch 67, Batch 24, Loss: 0.687\n",
      "Training: Epoch 67, Batch 25, Loss: 0.55\n",
      "Training: Epoch 67, Batch 26, Loss: 0.5\n",
      "Training: Epoch 67, Batch 27, Loss: 0.546\n",
      "Training: Epoch 67, Batch 28, Loss: 0.341\n",
      "Training: Epoch 67, Batch 29, Loss: 0.259\n",
      "Val: Epoch 67, Loss: 0.273\n",
      "Training: Epoch 68, Batch 0, Loss: 0.559\n",
      "Training: Epoch 68, Batch 1, Loss: 0.414\n",
      "Training: Epoch 68, Batch 2, Loss: 0.494\n",
      "Training: Epoch 68, Batch 3, Loss: 0.547\n",
      "Training: Epoch 68, Batch 4, Loss: 0.96\n",
      "Training: Epoch 68, Batch 5, Loss: 0.436\n",
      "Training: Epoch 68, Batch 6, Loss: 0.48\n",
      "Training: Epoch 68, Batch 7, Loss: 0.301\n",
      "Training: Epoch 68, Batch 8, Loss: 0.49\n",
      "Training: Epoch 68, Batch 9, Loss: 0.346\n",
      "Training: Epoch 68, Batch 10, Loss: 0.51\n",
      "Training: Epoch 68, Batch 11, Loss: 0.538\n",
      "Training: Epoch 68, Batch 12, Loss: 0.331\n",
      "Training: Epoch 68, Batch 13, Loss: 0.438\n",
      "Training: Epoch 68, Batch 14, Loss: 0.348\n",
      "Training: Epoch 68, Batch 15, Loss: 0.495\n",
      "Training: Epoch 68, Batch 16, Loss: 0.55\n",
      "Training: Epoch 68, Batch 17, Loss: 0.295\n",
      "Training: Epoch 68, Batch 18, Loss: 0.505\n",
      "Training: Epoch 68, Batch 19, Loss: 0.461\n",
      "Training: Epoch 68, Batch 20, Loss: 0.582\n",
      "Training: Epoch 68, Batch 21, Loss: 0.43\n",
      "Training: Epoch 68, Batch 22, Loss: 0.321\n",
      "Training: Epoch 68, Batch 23, Loss: 0.684\n",
      "Training: Epoch 68, Batch 24, Loss: 0.399\n",
      "Training: Epoch 68, Batch 25, Loss: 1.0\n",
      "Training: Epoch 68, Batch 26, Loss: 0.708\n",
      "Training: Epoch 68, Batch 27, Loss: 0.479\n",
      "Training: Epoch 68, Batch 28, Loss: 0.427\n",
      "Training: Epoch 68, Batch 29, Loss: 0.729\n",
      "Val: Epoch 68, Loss: 0.31\n",
      "Training: Epoch 69, Batch 0, Loss: 0.41\n",
      "Training: Epoch 69, Batch 1, Loss: 0.637\n",
      "Training: Epoch 69, Batch 2, Loss: 0.625\n",
      "Training: Epoch 69, Batch 3, Loss: 0.376\n",
      "Training: Epoch 69, Batch 4, Loss: 0.504\n",
      "Training: Epoch 69, Batch 5, Loss: 0.472\n",
      "Training: Epoch 69, Batch 6, Loss: 0.661\n",
      "Training: Epoch 69, Batch 7, Loss: 0.447\n",
      "Training: Epoch 69, Batch 8, Loss: 0.659\n",
      "Training: Epoch 69, Batch 9, Loss: 0.414\n",
      "Training: Epoch 69, Batch 10, Loss: 0.669\n",
      "Training: Epoch 69, Batch 11, Loss: 0.386\n",
      "Training: Epoch 69, Batch 12, Loss: 0.407\n",
      "Training: Epoch 69, Batch 13, Loss: 0.579\n",
      "Training: Epoch 69, Batch 14, Loss: 0.343\n",
      "Training: Epoch 69, Batch 15, Loss: 0.399\n",
      "Training: Epoch 69, Batch 16, Loss: 0.502\n",
      "Training: Epoch 69, Batch 17, Loss: 0.309\n",
      "Training: Epoch 69, Batch 18, Loss: 0.527\n",
      "Training: Epoch 69, Batch 19, Loss: 0.445\n",
      "Training: Epoch 69, Batch 20, Loss: 0.396\n",
      "Training: Epoch 69, Batch 21, Loss: 0.487\n",
      "Training: Epoch 69, Batch 22, Loss: 0.449\n",
      "Training: Epoch 69, Batch 23, Loss: 0.615\n",
      "Training: Epoch 69, Batch 24, Loss: 0.348\n",
      "Training: Epoch 69, Batch 25, Loss: 0.499\n",
      "Training: Epoch 69, Batch 26, Loss: 0.636\n",
      "Training: Epoch 69, Batch 27, Loss: 0.389\n",
      "Training: Epoch 69, Batch 28, Loss: 0.518\n",
      "Training: Epoch 69, Batch 29, Loss: 0.398\n",
      "Val: Epoch 69, Loss: 0.282\n",
      "Training: Epoch 70, Batch 0, Loss: 0.435\n",
      "Training: Epoch 70, Batch 1, Loss: 0.287\n",
      "Training: Epoch 70, Batch 2, Loss: 0.262\n",
      "Training: Epoch 70, Batch 3, Loss: 0.249\n",
      "Training: Epoch 70, Batch 4, Loss: 0.4\n",
      "Training: Epoch 70, Batch 5, Loss: 0.372\n",
      "Training: Epoch 70, Batch 6, Loss: 0.34\n",
      "Training: Epoch 70, Batch 7, Loss: 0.65\n",
      "Training: Epoch 70, Batch 8, Loss: 0.495\n",
      "Training: Epoch 70, Batch 9, Loss: 0.565\n",
      "Training: Epoch 70, Batch 10, Loss: 0.48\n",
      "Training: Epoch 70, Batch 11, Loss: 0.634\n",
      "Training: Epoch 70, Batch 12, Loss: 0.384\n",
      "Training: Epoch 70, Batch 13, Loss: 0.749\n",
      "Training: Epoch 70, Batch 14, Loss: 0.616\n",
      "Training: Epoch 70, Batch 15, Loss: 0.295\n",
      "Training: Epoch 70, Batch 16, Loss: 0.512\n",
      "Training: Epoch 70, Batch 17, Loss: 0.487\n",
      "Training: Epoch 70, Batch 18, Loss: 0.502\n",
      "Training: Epoch 70, Batch 19, Loss: 0.368\n",
      "Training: Epoch 70, Batch 20, Loss: 0.532\n",
      "Training: Epoch 70, Batch 21, Loss: 0.633\n",
      "Training: Epoch 70, Batch 22, Loss: 0.557\n",
      "Training: Epoch 70, Batch 23, Loss: 0.354\n",
      "Training: Epoch 70, Batch 24, Loss: 0.408\n",
      "Training: Epoch 70, Batch 25, Loss: 0.341\n",
      "Training: Epoch 70, Batch 26, Loss: 0.89\n",
      "Training: Epoch 70, Batch 27, Loss: 0.463\n",
      "Training: Epoch 70, Batch 28, Loss: 0.543\n",
      "Training: Epoch 70, Batch 29, Loss: 0.667\n",
      "Val: Epoch 70, Loss: 0.304\n",
      "Training: Epoch 71, Batch 0, Loss: 0.448\n",
      "Training: Epoch 71, Batch 1, Loss: 0.542\n",
      "Training: Epoch 71, Batch 2, Loss: 0.409\n",
      "Training: Epoch 71, Batch 3, Loss: 0.393\n",
      "Training: Epoch 71, Batch 4, Loss: 0.409\n",
      "Training: Epoch 71, Batch 5, Loss: 0.42\n",
      "Training: Epoch 71, Batch 6, Loss: 0.576\n",
      "Training: Epoch 71, Batch 7, Loss: 0.677\n",
      "Training: Epoch 71, Batch 8, Loss: 0.789\n",
      "Training: Epoch 71, Batch 9, Loss: 0.532\n",
      "Training: Epoch 71, Batch 10, Loss: 0.513\n",
      "Training: Epoch 71, Batch 11, Loss: 0.429\n",
      "Training: Epoch 71, Batch 12, Loss: 0.494\n",
      "Training: Epoch 71, Batch 13, Loss: 0.328\n",
      "Training: Epoch 71, Batch 14, Loss: 0.482\n",
      "Training: Epoch 71, Batch 15, Loss: 0.575\n",
      "Training: Epoch 71, Batch 16, Loss: 0.592\n",
      "Training: Epoch 71, Batch 17, Loss: 0.555\n",
      "Training: Epoch 71, Batch 18, Loss: 0.553\n",
      "Training: Epoch 71, Batch 19, Loss: 0.545\n",
      "Training: Epoch 71, Batch 20, Loss: 0.43\n",
      "Training: Epoch 71, Batch 21, Loss: 0.341\n",
      "Training: Epoch 71, Batch 22, Loss: 0.526\n",
      "Training: Epoch 71, Batch 23, Loss: 0.278\n",
      "Training: Epoch 71, Batch 24, Loss: 0.548\n",
      "Training: Epoch 71, Batch 25, Loss: 0.406\n",
      "Training: Epoch 71, Batch 26, Loss: 0.885\n",
      "Training: Epoch 71, Batch 27, Loss: 0.377\n",
      "Training: Epoch 71, Batch 28, Loss: 0.506\n",
      "Training: Epoch 71, Batch 29, Loss: 0.302\n",
      "Val: Epoch 71, Loss: 0.287\n",
      "Training: Epoch 72, Batch 0, Loss: 0.55\n",
      "Training: Epoch 72, Batch 1, Loss: 0.491\n",
      "Training: Epoch 72, Batch 2, Loss: 0.545\n",
      "Training: Epoch 72, Batch 3, Loss: 0.442\n",
      "Training: Epoch 72, Batch 4, Loss: 0.515\n",
      "Training: Epoch 72, Batch 5, Loss: 0.431\n",
      "Training: Epoch 72, Batch 6, Loss: 0.321\n",
      "Training: Epoch 72, Batch 7, Loss: 0.573\n",
      "Training: Epoch 72, Batch 8, Loss: 0.458\n",
      "Training: Epoch 72, Batch 9, Loss: 0.538\n",
      "Training: Epoch 72, Batch 10, Loss: 0.532\n",
      "Training: Epoch 72, Batch 11, Loss: 0.63\n",
      "Training: Epoch 72, Batch 12, Loss: 0.548\n",
      "Training: Epoch 72, Batch 13, Loss: 0.691\n",
      "Training: Epoch 72, Batch 14, Loss: 0.458\n",
      "Training: Epoch 72, Batch 15, Loss: 0.485\n",
      "Training: Epoch 72, Batch 16, Loss: 0.415\n",
      "Training: Epoch 72, Batch 17, Loss: 0.585\n",
      "Training: Epoch 72, Batch 18, Loss: 0.541\n",
      "Training: Epoch 72, Batch 19, Loss: 0.364\n",
      "Training: Epoch 72, Batch 20, Loss: 0.429\n",
      "Training: Epoch 72, Batch 21, Loss: 0.353\n",
      "Training: Epoch 72, Batch 22, Loss: 0.258\n",
      "Training: Epoch 72, Batch 23, Loss: 0.352\n",
      "Training: Epoch 72, Batch 24, Loss: 0.541\n",
      "Training: Epoch 72, Batch 25, Loss: 0.673\n",
      "Training: Epoch 72, Batch 26, Loss: 0.269\n",
      "Training: Epoch 72, Batch 27, Loss: 0.559\n",
      "Training: Epoch 72, Batch 28, Loss: 0.326\n",
      "Training: Epoch 72, Batch 29, Loss: 0.324\n",
      "Val: Epoch 72, Loss: 0.282\n",
      "Training: Epoch 73, Batch 0, Loss: 0.255\n",
      "Training: Epoch 73, Batch 1, Loss: 0.469\n",
      "Training: Epoch 73, Batch 2, Loss: 0.404\n",
      "Training: Epoch 73, Batch 3, Loss: 0.246\n",
      "Training: Epoch 73, Batch 4, Loss: 0.698\n",
      "Training: Epoch 73, Batch 5, Loss: 0.409\n",
      "Training: Epoch 73, Batch 6, Loss: 0.558\n",
      "Training: Epoch 73, Batch 7, Loss: 0.575\n",
      "Training: Epoch 73, Batch 8, Loss: 0.412\n",
      "Training: Epoch 73, Batch 9, Loss: 0.462\n",
      "Training: Epoch 73, Batch 10, Loss: 0.272\n",
      "Training: Epoch 73, Batch 11, Loss: 0.431\n",
      "Training: Epoch 73, Batch 12, Loss: 0.502\n",
      "Training: Epoch 73, Batch 13, Loss: 0.47\n",
      "Training: Epoch 73, Batch 14, Loss: 0.422\n",
      "Training: Epoch 73, Batch 15, Loss: 0.601\n",
      "Training: Epoch 73, Batch 16, Loss: 0.703\n",
      "Training: Epoch 73, Batch 17, Loss: 0.904\n",
      "Training: Epoch 73, Batch 18, Loss: 0.317\n",
      "Training: Epoch 73, Batch 19, Loss: 0.414\n",
      "Training: Epoch 73, Batch 20, Loss: 0.405\n",
      "Training: Epoch 73, Batch 21, Loss: 0.41\n",
      "Training: Epoch 73, Batch 22, Loss: 0.604\n",
      "Training: Epoch 73, Batch 23, Loss: 0.242\n",
      "Training: Epoch 73, Batch 24, Loss: 0.496\n",
      "Training: Epoch 73, Batch 25, Loss: 0.414\n",
      "Training: Epoch 73, Batch 26, Loss: 0.691\n",
      "Training: Epoch 73, Batch 27, Loss: 0.485\n",
      "Training: Epoch 73, Batch 28, Loss: 0.39\n",
      "Training: Epoch 73, Batch 29, Loss: 0.619\n",
      "Val: Epoch 73, Loss: 0.286\n",
      "Training: Epoch 74, Batch 0, Loss: 0.356\n",
      "Training: Epoch 74, Batch 1, Loss: 0.342\n",
      "Training: Epoch 74, Batch 2, Loss: 0.544\n",
      "Training: Epoch 74, Batch 3, Loss: 0.76\n",
      "Training: Epoch 74, Batch 4, Loss: 0.449\n",
      "Training: Epoch 74, Batch 5, Loss: 0.296\n",
      "Training: Epoch 74, Batch 6, Loss: 0.405\n",
      "Training: Epoch 74, Batch 7, Loss: 0.535\n",
      "Training: Epoch 74, Batch 8, Loss: 0.479\n",
      "Training: Epoch 74, Batch 9, Loss: 0.543\n",
      "Training: Epoch 74, Batch 10, Loss: 1.0\n",
      "Training: Epoch 74, Batch 11, Loss: 0.401\n",
      "Training: Epoch 74, Batch 12, Loss: 0.337\n",
      "Training: Epoch 74, Batch 13, Loss: 0.38\n",
      "Training: Epoch 74, Batch 14, Loss: 0.27\n",
      "Training: Epoch 74, Batch 15, Loss: 0.332\n",
      "Training: Epoch 74, Batch 16, Loss: 0.445\n",
      "Training: Epoch 74, Batch 17, Loss: 0.566\n",
      "Training: Epoch 74, Batch 18, Loss: 0.269\n",
      "Training: Epoch 74, Batch 19, Loss: 0.621\n",
      "Training: Epoch 74, Batch 20, Loss: 0.56\n",
      "Training: Epoch 74, Batch 21, Loss: 0.484\n",
      "Training: Epoch 74, Batch 22, Loss: 0.668\n",
      "Training: Epoch 74, Batch 23, Loss: 0.384\n",
      "Training: Epoch 74, Batch 24, Loss: 0.714\n",
      "Training: Epoch 74, Batch 25, Loss: 0.527\n",
      "Training: Epoch 74, Batch 26, Loss: 0.477\n",
      "Training: Epoch 74, Batch 27, Loss: 0.243\n",
      "Training: Epoch 74, Batch 28, Loss: 0.493\n",
      "Training: Epoch 74, Batch 29, Loss: 0.593\n",
      "Val: Epoch 74, Loss: 0.32\n",
      "Training: Epoch 75, Batch 0, Loss: 0.432\n",
      "Training: Epoch 75, Batch 1, Loss: 0.303\n",
      "Training: Epoch 75, Batch 2, Loss: 0.59\n",
      "Training: Epoch 75, Batch 3, Loss: 0.401\n",
      "Training: Epoch 75, Batch 4, Loss: 0.436\n",
      "Training: Epoch 75, Batch 5, Loss: 0.318\n",
      "Training: Epoch 75, Batch 6, Loss: 0.349\n",
      "Training: Epoch 75, Batch 7, Loss: 0.452\n",
      "Training: Epoch 75, Batch 8, Loss: 0.38\n",
      "Training: Epoch 75, Batch 9, Loss: 0.419\n",
      "Training: Epoch 75, Batch 10, Loss: 0.272\n",
      "Training: Epoch 75, Batch 11, Loss: 0.619\n",
      "Training: Epoch 75, Batch 12, Loss: 0.598\n",
      "Training: Epoch 75, Batch 13, Loss: 0.805\n",
      "Training: Epoch 75, Batch 14, Loss: 0.623\n",
      "Training: Epoch 75, Batch 15, Loss: 0.513\n",
      "Training: Epoch 75, Batch 16, Loss: 0.514\n",
      "Training: Epoch 75, Batch 17, Loss: 0.51\n",
      "Training: Epoch 75, Batch 18, Loss: 0.705\n",
      "Training: Epoch 75, Batch 19, Loss: 0.562\n",
      "Training: Epoch 75, Batch 20, Loss: 0.487\n",
      "Training: Epoch 75, Batch 21, Loss: 0.478\n",
      "Training: Epoch 75, Batch 22, Loss: 0.412\n",
      "Training: Epoch 75, Batch 23, Loss: 0.48\n",
      "Training: Epoch 75, Batch 24, Loss: 0.523\n",
      "Training: Epoch 75, Batch 25, Loss: 0.686\n",
      "Training: Epoch 75, Batch 26, Loss: 0.548\n",
      "Training: Epoch 75, Batch 27, Loss: 0.482\n",
      "Training: Epoch 75, Batch 28, Loss: 0.39\n",
      "Training: Epoch 75, Batch 29, Loss: 0.425\n",
      "Val: Epoch 75, Loss: 0.401\n",
      "Training: Epoch 76, Batch 0, Loss: 0.525\n",
      "Training: Epoch 76, Batch 1, Loss: 0.55\n",
      "Training: Epoch 76, Batch 2, Loss: 0.39\n",
      "Training: Epoch 76, Batch 3, Loss: 0.47\n",
      "Training: Epoch 76, Batch 4, Loss: 0.496\n",
      "Training: Epoch 76, Batch 5, Loss: 0.651\n",
      "Training: Epoch 76, Batch 6, Loss: 0.461\n",
      "Training: Epoch 76, Batch 7, Loss: 0.521\n",
      "Training: Epoch 76, Batch 8, Loss: 0.567\n",
      "Training: Epoch 76, Batch 9, Loss: 0.607\n",
      "Training: Epoch 76, Batch 10, Loss: 0.302\n",
      "Training: Epoch 76, Batch 11, Loss: 0.347\n",
      "Training: Epoch 76, Batch 12, Loss: 0.56\n",
      "Training: Epoch 76, Batch 13, Loss: 0.297\n",
      "Training: Epoch 76, Batch 14, Loss: 0.549\n",
      "Training: Epoch 76, Batch 15, Loss: 0.431\n",
      "Training: Epoch 76, Batch 16, Loss: 0.281\n",
      "Training: Epoch 76, Batch 17, Loss: 0.679\n",
      "Training: Epoch 76, Batch 18, Loss: 0.344\n",
      "Training: Epoch 76, Batch 19, Loss: 0.579\n",
      "Training: Epoch 76, Batch 20, Loss: 0.355\n",
      "Training: Epoch 76, Batch 21, Loss: 0.56\n",
      "Training: Epoch 76, Batch 22, Loss: 0.992\n",
      "Training: Epoch 76, Batch 23, Loss: 0.598\n",
      "Training: Epoch 76, Batch 24, Loss: 0.564\n",
      "Training: Epoch 76, Batch 25, Loss: 0.302\n",
      "Training: Epoch 76, Batch 26, Loss: 0.319\n",
      "Training: Epoch 76, Batch 27, Loss: 0.558\n",
      "Training: Epoch 76, Batch 28, Loss: 0.496\n",
      "Training: Epoch 76, Batch 29, Loss: 0.366\n",
      "Val: Epoch 76, Loss: 0.299\n",
      "Training: Epoch 77, Batch 0, Loss: 0.512\n",
      "Training: Epoch 77, Batch 1, Loss: 0.394\n",
      "Training: Epoch 77, Batch 2, Loss: 0.46\n",
      "Training: Epoch 77, Batch 3, Loss: 0.651\n",
      "Training: Epoch 77, Batch 4, Loss: 0.521\n",
      "Training: Epoch 77, Batch 5, Loss: 0.384\n",
      "Training: Epoch 77, Batch 6, Loss: 0.312\n",
      "Training: Epoch 77, Batch 7, Loss: 0.656\n",
      "Training: Epoch 77, Batch 8, Loss: 0.446\n",
      "Training: Epoch 77, Batch 9, Loss: 0.266\n",
      "Training: Epoch 77, Batch 10, Loss: 0.737\n",
      "Training: Epoch 77, Batch 11, Loss: 0.515\n",
      "Training: Epoch 77, Batch 12, Loss: 0.633\n",
      "Training: Epoch 77, Batch 13, Loss: 0.491\n",
      "Training: Epoch 77, Batch 14, Loss: 0.27\n",
      "Training: Epoch 77, Batch 15, Loss: 0.559\n",
      "Training: Epoch 77, Batch 16, Loss: 0.425\n",
      "Training: Epoch 77, Batch 17, Loss: 0.653\n",
      "Training: Epoch 77, Batch 18, Loss: 0.323\n",
      "Training: Epoch 77, Batch 19, Loss: 0.411\n",
      "Training: Epoch 77, Batch 20, Loss: 0.377\n",
      "Training: Epoch 77, Batch 21, Loss: 0.48\n",
      "Training: Epoch 77, Batch 22, Loss: 0.567\n",
      "Training: Epoch 77, Batch 23, Loss: 0.359\n",
      "Training: Epoch 77, Batch 24, Loss: 0.633\n",
      "Training: Epoch 77, Batch 25, Loss: 0.658\n",
      "Training: Epoch 77, Batch 26, Loss: 0.383\n",
      "Training: Epoch 77, Batch 27, Loss: 0.439\n",
      "Training: Epoch 77, Batch 28, Loss: 0.404\n",
      "Training: Epoch 77, Batch 29, Loss: 0.51\n",
      "Val: Epoch 77, Loss: 0.346\n",
      "Training: Epoch 78, Batch 0, Loss: 0.391\n",
      "Training: Epoch 78, Batch 1, Loss: 0.335\n",
      "Training: Epoch 78, Batch 2, Loss: 0.459\n",
      "Training: Epoch 78, Batch 3, Loss: 0.499\n",
      "Training: Epoch 78, Batch 4, Loss: 0.667\n",
      "Training: Epoch 78, Batch 5, Loss: 0.498\n",
      "Training: Epoch 78, Batch 6, Loss: 0.54\n",
      "Training: Epoch 78, Batch 7, Loss: 0.424\n",
      "Training: Epoch 78, Batch 8, Loss: 0.467\n",
      "Training: Epoch 78, Batch 9, Loss: 0.542\n",
      "Training: Epoch 78, Batch 10, Loss: 0.525\n",
      "Training: Epoch 78, Batch 11, Loss: 0.474\n",
      "Training: Epoch 78, Batch 12, Loss: 0.394\n",
      "Training: Epoch 78, Batch 13, Loss: 0.323\n",
      "Training: Epoch 78, Batch 14, Loss: 0.363\n",
      "Training: Epoch 78, Batch 15, Loss: 0.341\n",
      "Training: Epoch 78, Batch 16, Loss: 0.445\n",
      "Training: Epoch 78, Batch 17, Loss: 0.571\n",
      "Training: Epoch 78, Batch 18, Loss: 0.548\n",
      "Training: Epoch 78, Batch 19, Loss: 0.654\n",
      "Training: Epoch 78, Batch 20, Loss: 0.33\n",
      "Training: Epoch 78, Batch 21, Loss: 0.551\n",
      "Training: Epoch 78, Batch 22, Loss: 0.509\n",
      "Training: Epoch 78, Batch 23, Loss: 0.683\n",
      "Training: Epoch 78, Batch 24, Loss: 0.363\n",
      "Training: Epoch 78, Batch 25, Loss: 0.513\n",
      "Training: Epoch 78, Batch 26, Loss: 0.444\n",
      "Training: Epoch 78, Batch 27, Loss: 0.502\n",
      "Training: Epoch 78, Batch 28, Loss: 0.252\n",
      "Training: Epoch 78, Batch 29, Loss: 0.551\n",
      "Val: Epoch 78, Loss: 0.273\n",
      "Training: Epoch 79, Batch 0, Loss: 0.378\n",
      "Training: Epoch 79, Batch 1, Loss: 0.433\n",
      "Training: Epoch 79, Batch 2, Loss: 0.482\n",
      "Training: Epoch 79, Batch 3, Loss: 0.492\n",
      "Training: Epoch 79, Batch 4, Loss: 0.408\n",
      "Training: Epoch 79, Batch 5, Loss: 0.632\n",
      "Training: Epoch 79, Batch 6, Loss: 0.492\n",
      "Training: Epoch 79, Batch 7, Loss: 0.668\n",
      "Training: Epoch 79, Batch 8, Loss: 0.546\n",
      "Training: Epoch 79, Batch 9, Loss: 0.494\n",
      "Training: Epoch 79, Batch 10, Loss: 0.448\n",
      "Training: Epoch 79, Batch 11, Loss: 0.587\n",
      "Training: Epoch 79, Batch 12, Loss: 0.305\n",
      "Training: Epoch 79, Batch 13, Loss: 0.598\n",
      "Training: Epoch 79, Batch 14, Loss: 0.554\n",
      "Training: Epoch 79, Batch 15, Loss: 0.491\n",
      "Training: Epoch 79, Batch 16, Loss: 0.439\n",
      "Training: Epoch 79, Batch 17, Loss: 0.485\n",
      "Training: Epoch 79, Batch 18, Loss: 0.604\n",
      "Training: Epoch 79, Batch 19, Loss: 0.364\n",
      "Training: Epoch 79, Batch 20, Loss: 0.266\n",
      "Training: Epoch 79, Batch 21, Loss: 0.259\n",
      "Training: Epoch 79, Batch 22, Loss: 0.511\n",
      "Training: Epoch 79, Batch 23, Loss: 0.356\n",
      "Training: Epoch 79, Batch 24, Loss: 0.585\n",
      "Training: Epoch 79, Batch 25, Loss: 0.463\n",
      "Training: Epoch 79, Batch 26, Loss: 0.205\n",
      "Training: Epoch 79, Batch 27, Loss: 0.311\n",
      "Training: Epoch 79, Batch 28, Loss: 0.499\n",
      "Training: Epoch 79, Batch 29, Loss: 0.515\n",
      "Val: Epoch 79, Loss: 0.36\n",
      "Training: Epoch 80, Batch 0, Loss: 0.515\n",
      "Training: Epoch 80, Batch 1, Loss: 0.556\n",
      "Training: Epoch 80, Batch 2, Loss: 0.44\n",
      "Training: Epoch 80, Batch 3, Loss: 0.369\n",
      "Training: Epoch 80, Batch 4, Loss: 0.359\n",
      "Training: Epoch 80, Batch 5, Loss: 0.331\n",
      "Training: Epoch 80, Batch 6, Loss: 0.632\n",
      "Training: Epoch 80, Batch 7, Loss: 0.33\n",
      "Training: Epoch 80, Batch 8, Loss: 0.228\n",
      "Training: Epoch 80, Batch 9, Loss: 0.512\n",
      "Training: Epoch 80, Batch 10, Loss: 0.705\n",
      "Training: Epoch 80, Batch 11, Loss: 0.392\n",
      "Training: Epoch 80, Batch 12, Loss: 0.485\n",
      "Training: Epoch 80, Batch 13, Loss: 0.532\n",
      "Training: Epoch 80, Batch 14, Loss: 0.401\n",
      "Training: Epoch 80, Batch 15, Loss: 0.503\n",
      "Training: Epoch 80, Batch 16, Loss: 0.579\n",
      "Training: Epoch 80, Batch 17, Loss: 0.566\n",
      "Training: Epoch 80, Batch 18, Loss: 0.515\n",
      "Training: Epoch 80, Batch 19, Loss: 0.485\n",
      "Training: Epoch 80, Batch 20, Loss: 0.384\n",
      "Training: Epoch 80, Batch 21, Loss: 0.587\n",
      "Training: Epoch 80, Batch 22, Loss: 0.269\n",
      "Training: Epoch 80, Batch 23, Loss: 0.378\n",
      "Training: Epoch 80, Batch 24, Loss: 0.552\n",
      "Training: Epoch 80, Batch 25, Loss: 0.482\n",
      "Training: Epoch 80, Batch 26, Loss: 0.476\n",
      "Training: Epoch 80, Batch 27, Loss: 0.725\n",
      "Training: Epoch 80, Batch 28, Loss: 0.313\n",
      "Training: Epoch 80, Batch 29, Loss: 0.46\n",
      "Val: Epoch 80, Loss: 0.338\n",
      "Training: Epoch 81, Batch 0, Loss: 0.438\n",
      "Training: Epoch 81, Batch 1, Loss: 0.557\n",
      "Training: Epoch 81, Batch 2, Loss: 0.313\n",
      "Training: Epoch 81, Batch 3, Loss: 0.455\n",
      "Training: Epoch 81, Batch 4, Loss: 0.564\n",
      "Training: Epoch 81, Batch 5, Loss: 0.36\n",
      "Training: Epoch 81, Batch 6, Loss: 0.387\n",
      "Training: Epoch 81, Batch 7, Loss: 0.321\n",
      "Training: Epoch 81, Batch 8, Loss: 0.714\n",
      "Training: Epoch 81, Batch 9, Loss: 0.319\n",
      "Training: Epoch 81, Batch 10, Loss: 0.516\n",
      "Training: Epoch 81, Batch 11, Loss: 0.567\n",
      "Training: Epoch 81, Batch 12, Loss: 0.662\n",
      "Training: Epoch 81, Batch 13, Loss: 0.441\n",
      "Training: Epoch 81, Batch 14, Loss: 0.501\n",
      "Training: Epoch 81, Batch 15, Loss: 0.499\n",
      "Training: Epoch 81, Batch 16, Loss: 0.403\n",
      "Training: Epoch 81, Batch 17, Loss: 0.637\n",
      "Training: Epoch 81, Batch 18, Loss: 0.469\n",
      "Training: Epoch 81, Batch 19, Loss: 0.354\n",
      "Training: Epoch 81, Batch 20, Loss: 0.375\n",
      "Training: Epoch 81, Batch 21, Loss: 0.585\n",
      "Training: Epoch 81, Batch 22, Loss: 0.387\n",
      "Training: Epoch 81, Batch 23, Loss: 0.382\n",
      "Training: Epoch 81, Batch 24, Loss: 0.489\n",
      "Training: Epoch 81, Batch 25, Loss: 0.573\n",
      "Training: Epoch 81, Batch 26, Loss: 0.471\n",
      "Training: Epoch 81, Batch 27, Loss: 0.599\n",
      "Training: Epoch 81, Batch 28, Loss: 0.418\n",
      "Training: Epoch 81, Batch 29, Loss: 0.481\n",
      "Val: Epoch 81, Loss: 0.264\n",
      "Training: Epoch 82, Batch 0, Loss: 0.325\n",
      "Training: Epoch 82, Batch 1, Loss: 0.403\n",
      "Training: Epoch 82, Batch 2, Loss: 0.381\n",
      "Training: Epoch 82, Batch 3, Loss: 0.75\n",
      "Training: Epoch 82, Batch 4, Loss: 0.35\n",
      "Training: Epoch 82, Batch 5, Loss: 0.396\n",
      "Training: Epoch 82, Batch 6, Loss: 0.272\n",
      "Training: Epoch 82, Batch 7, Loss: 0.521\n",
      "Training: Epoch 82, Batch 8, Loss: 0.621\n",
      "Training: Epoch 82, Batch 9, Loss: 0.565\n",
      "Training: Epoch 82, Batch 10, Loss: 0.614\n",
      "Training: Epoch 82, Batch 11, Loss: 0.297\n",
      "Training: Epoch 82, Batch 12, Loss: 0.378\n",
      "Training: Epoch 82, Batch 13, Loss: 0.475\n",
      "Training: Epoch 82, Batch 14, Loss: 0.474\n",
      "Training: Epoch 82, Batch 15, Loss: 0.513\n",
      "Training: Epoch 82, Batch 16, Loss: 0.498\n",
      "Training: Epoch 82, Batch 17, Loss: 0.345\n",
      "Training: Epoch 82, Batch 18, Loss: 0.45\n",
      "Training: Epoch 82, Batch 19, Loss: 0.493\n",
      "Training: Epoch 82, Batch 20, Loss: 0.572\n",
      "Training: Epoch 82, Batch 21, Loss: 0.436\n",
      "Training: Epoch 82, Batch 22, Loss: 0.522\n",
      "Training: Epoch 82, Batch 23, Loss: 0.571\n",
      "Training: Epoch 82, Batch 24, Loss: 0.349\n",
      "Training: Epoch 82, Batch 25, Loss: 0.447\n",
      "Training: Epoch 82, Batch 26, Loss: 0.501\n",
      "Training: Epoch 82, Batch 27, Loss: 0.662\n",
      "Training: Epoch 82, Batch 28, Loss: 0.38\n",
      "Training: Epoch 82, Batch 29, Loss: 0.49\n",
      "Val: Epoch 82, Loss: 0.262\n",
      "Training: Epoch 83, Batch 0, Loss: 0.452\n",
      "Training: Epoch 83, Batch 1, Loss: 0.606\n",
      "Training: Epoch 83, Batch 2, Loss: 0.452\n",
      "Training: Epoch 83, Batch 3, Loss: 0.482\n",
      "Training: Epoch 83, Batch 4, Loss: 0.76\n",
      "Training: Epoch 83, Batch 5, Loss: 0.472\n",
      "Training: Epoch 83, Batch 6, Loss: 0.319\n",
      "Training: Epoch 83, Batch 7, Loss: 0.433\n",
      "Training: Epoch 83, Batch 8, Loss: 0.41\n",
      "Training: Epoch 83, Batch 9, Loss: 0.584\n",
      "Training: Epoch 83, Batch 10, Loss: 0.406\n",
      "Training: Epoch 83, Batch 11, Loss: 0.517\n",
      "Training: Epoch 83, Batch 12, Loss: 0.418\n",
      "Training: Epoch 83, Batch 13, Loss: 0.489\n",
      "Training: Epoch 83, Batch 14, Loss: 0.338\n",
      "Training: Epoch 83, Batch 15, Loss: 0.679\n",
      "Training: Epoch 83, Batch 16, Loss: 0.543\n",
      "Training: Epoch 83, Batch 17, Loss: 0.442\n",
      "Training: Epoch 83, Batch 18, Loss: 0.375\n",
      "Training: Epoch 83, Batch 19, Loss: 0.497\n",
      "Training: Epoch 83, Batch 20, Loss: 0.438\n",
      "Training: Epoch 83, Batch 21, Loss: 0.24\n",
      "Training: Epoch 83, Batch 22, Loss: 0.594\n",
      "Training: Epoch 83, Batch 23, Loss: 0.387\n",
      "Training: Epoch 83, Batch 24, Loss: 0.55\n",
      "Training: Epoch 83, Batch 25, Loss: 0.34\n",
      "Training: Epoch 83, Batch 26, Loss: 0.424\n",
      "Training: Epoch 83, Batch 27, Loss: 0.195\n",
      "Training: Epoch 83, Batch 28, Loss: 0.467\n",
      "Training: Epoch 83, Batch 29, Loss: 0.385\n",
      "Val: Epoch 83, Loss: 0.307\n",
      "Training: Epoch 84, Batch 0, Loss: 0.52\n",
      "Training: Epoch 84, Batch 1, Loss: 0.407\n",
      "Training: Epoch 84, Batch 2, Loss: 0.165\n",
      "Training: Epoch 84, Batch 3, Loss: 0.452\n",
      "Training: Epoch 84, Batch 4, Loss: 0.431\n",
      "Training: Epoch 84, Batch 5, Loss: 0.859\n",
      "Training: Epoch 84, Batch 6, Loss: 0.591\n",
      "Training: Epoch 84, Batch 7, Loss: 0.52\n",
      "Training: Epoch 84, Batch 8, Loss: 0.454\n",
      "Training: Epoch 84, Batch 9, Loss: 0.383\n",
      "Training: Epoch 84, Batch 10, Loss: 0.266\n",
      "Training: Epoch 84, Batch 11, Loss: 0.382\n",
      "Training: Epoch 84, Batch 12, Loss: 0.553\n",
      "Training: Epoch 84, Batch 13, Loss: 0.573\n",
      "Training: Epoch 84, Batch 14, Loss: 0.493\n",
      "Training: Epoch 84, Batch 15, Loss: 0.621\n",
      "Training: Epoch 84, Batch 16, Loss: 0.455\n",
      "Training: Epoch 84, Batch 17, Loss: 0.317\n",
      "Training: Epoch 84, Batch 18, Loss: 0.261\n",
      "Training: Epoch 84, Batch 19, Loss: 0.733\n",
      "Training: Epoch 84, Batch 20, Loss: 0.531\n",
      "Training: Epoch 84, Batch 21, Loss: 0.776\n",
      "Training: Epoch 84, Batch 22, Loss: 0.317\n",
      "Training: Epoch 84, Batch 23, Loss: 0.49\n",
      "Training: Epoch 84, Batch 24, Loss: 0.359\n",
      "Training: Epoch 84, Batch 25, Loss: 0.369\n",
      "Training: Epoch 84, Batch 26, Loss: 0.329\n",
      "Training: Epoch 84, Batch 27, Loss: 0.45\n",
      "Training: Epoch 84, Batch 28, Loss: 0.265\n",
      "Training: Epoch 84, Batch 29, Loss: 0.6\n",
      "Val: Epoch 84, Loss: 0.337\n",
      "Training: Epoch 85, Batch 0, Loss: 0.485\n",
      "Training: Epoch 85, Batch 1, Loss: 0.482\n",
      "Training: Epoch 85, Batch 2, Loss: 0.523\n",
      "Training: Epoch 85, Batch 3, Loss: 0.479\n",
      "Training: Epoch 85, Batch 4, Loss: 0.395\n",
      "Training: Epoch 85, Batch 5, Loss: 0.517\n",
      "Training: Epoch 85, Batch 6, Loss: 0.38\n",
      "Training: Epoch 85, Batch 7, Loss: 0.227\n",
      "Training: Epoch 85, Batch 8, Loss: 0.627\n",
      "Training: Epoch 85, Batch 9, Loss: 0.59\n",
      "Training: Epoch 85, Batch 10, Loss: 0.387\n",
      "Training: Epoch 85, Batch 11, Loss: 0.559\n",
      "Training: Epoch 85, Batch 12, Loss: 0.523\n",
      "Training: Epoch 85, Batch 13, Loss: 0.421\n",
      "Training: Epoch 85, Batch 14, Loss: 0.407\n",
      "Training: Epoch 85, Batch 15, Loss: 0.388\n",
      "Training: Epoch 85, Batch 16, Loss: 0.306\n",
      "Training: Epoch 85, Batch 17, Loss: 0.463\n",
      "Training: Epoch 85, Batch 18, Loss: 0.473\n",
      "Training: Epoch 85, Batch 19, Loss: 0.394\n",
      "Training: Epoch 85, Batch 20, Loss: 0.475\n",
      "Training: Epoch 85, Batch 21, Loss: 0.258\n",
      "Training: Epoch 85, Batch 22, Loss: 0.292\n",
      "Training: Epoch 85, Batch 23, Loss: 0.403\n",
      "Training: Epoch 85, Batch 24, Loss: 0.496\n",
      "Training: Epoch 85, Batch 25, Loss: 0.513\n",
      "Training: Epoch 85, Batch 26, Loss: 0.534\n",
      "Training: Epoch 85, Batch 27, Loss: 0.751\n",
      "Training: Epoch 85, Batch 28, Loss: 0.298\n",
      "Training: Epoch 85, Batch 29, Loss: 0.534\n",
      "Val: Epoch 85, Loss: 0.271\n",
      "Training: Epoch 86, Batch 0, Loss: 0.324\n",
      "Training: Epoch 86, Batch 1, Loss: 0.275\n",
      "Training: Epoch 86, Batch 2, Loss: 0.797\n",
      "Training: Epoch 86, Batch 3, Loss: 0.497\n",
      "Training: Epoch 86, Batch 4, Loss: 0.35\n",
      "Training: Epoch 86, Batch 5, Loss: 0.429\n",
      "Training: Epoch 86, Batch 6, Loss: 0.357\n",
      "Training: Epoch 86, Batch 7, Loss: 0.243\n",
      "Training: Epoch 86, Batch 8, Loss: 0.414\n",
      "Training: Epoch 86, Batch 9, Loss: 0.47\n",
      "Training: Epoch 86, Batch 10, Loss: 0.515\n",
      "Training: Epoch 86, Batch 11, Loss: 0.442\n",
      "Training: Epoch 86, Batch 12, Loss: 0.523\n",
      "Training: Epoch 86, Batch 13, Loss: 0.482\n",
      "Training: Epoch 86, Batch 14, Loss: 0.71\n",
      "Training: Epoch 86, Batch 15, Loss: 0.596\n",
      "Training: Epoch 86, Batch 16, Loss: 0.516\n",
      "Training: Epoch 86, Batch 17, Loss: 0.574\n",
      "Training: Epoch 86, Batch 18, Loss: 0.647\n",
      "Training: Epoch 86, Batch 19, Loss: 0.284\n",
      "Training: Epoch 86, Batch 20, Loss: 0.604\n",
      "Training: Epoch 86, Batch 21, Loss: 0.475\n",
      "Training: Epoch 86, Batch 22, Loss: 0.346\n",
      "Training: Epoch 86, Batch 23, Loss: 0.587\n",
      "Training: Epoch 86, Batch 24, Loss: 0.529\n",
      "Training: Epoch 86, Batch 25, Loss: 0.452\n",
      "Training: Epoch 86, Batch 26, Loss: 0.418\n",
      "Training: Epoch 86, Batch 27, Loss: 0.371\n",
      "Training: Epoch 86, Batch 28, Loss: 0.395\n",
      "Training: Epoch 86, Batch 29, Loss: 0.62\n",
      "Val: Epoch 86, Loss: 0.281\n",
      "Training: Epoch 87, Batch 0, Loss: 0.446\n",
      "Training: Epoch 87, Batch 1, Loss: 0.672\n",
      "Training: Epoch 87, Batch 2, Loss: 0.411\n",
      "Training: Epoch 87, Batch 3, Loss: 0.538\n",
      "Training: Epoch 87, Batch 4, Loss: 0.238\n",
      "Training: Epoch 87, Batch 5, Loss: 0.553\n",
      "Training: Epoch 87, Batch 6, Loss: 0.352\n",
      "Training: Epoch 87, Batch 7, Loss: 0.375\n",
      "Training: Epoch 87, Batch 8, Loss: 0.527\n",
      "Training: Epoch 87, Batch 9, Loss: 0.457\n",
      "Training: Epoch 87, Batch 10, Loss: 0.326\n",
      "Training: Epoch 87, Batch 11, Loss: 0.729\n",
      "Training: Epoch 87, Batch 12, Loss: 0.549\n",
      "Training: Epoch 87, Batch 13, Loss: 0.337\n",
      "Training: Epoch 87, Batch 14, Loss: 0.536\n",
      "Training: Epoch 87, Batch 15, Loss: 0.563\n",
      "Training: Epoch 87, Batch 16, Loss: 0.649\n",
      "Training: Epoch 87, Batch 17, Loss: 0.494\n",
      "Training: Epoch 87, Batch 18, Loss: 0.612\n",
      "Training: Epoch 87, Batch 19, Loss: 0.462\n",
      "Training: Epoch 87, Batch 20, Loss: 0.428\n",
      "Training: Epoch 87, Batch 21, Loss: 0.275\n",
      "Training: Epoch 87, Batch 22, Loss: 0.24\n",
      "Training: Epoch 87, Batch 23, Loss: 0.777\n",
      "Training: Epoch 87, Batch 24, Loss: 0.328\n",
      "Training: Epoch 87, Batch 25, Loss: 0.314\n",
      "Training: Epoch 87, Batch 26, Loss: 0.737\n",
      "Training: Epoch 87, Batch 27, Loss: 0.349\n",
      "Training: Epoch 87, Batch 28, Loss: 0.267\n",
      "Training: Epoch 87, Batch 29, Loss: 0.452\n",
      "Val: Epoch 87, Loss: 0.277\n",
      "Training: Epoch 88, Batch 0, Loss: 0.322\n",
      "Training: Epoch 88, Batch 1, Loss: 0.462\n",
      "Training: Epoch 88, Batch 2, Loss: 0.244\n",
      "Training: Epoch 88, Batch 3, Loss: 0.543\n",
      "Training: Epoch 88, Batch 4, Loss: 0.787\n",
      "Training: Epoch 88, Batch 5, Loss: 0.439\n",
      "Training: Epoch 88, Batch 6, Loss: 0.445\n",
      "Training: Epoch 88, Batch 7, Loss: 0.556\n",
      "Training: Epoch 88, Batch 8, Loss: 0.307\n",
      "Training: Epoch 88, Batch 9, Loss: 0.395\n",
      "Training: Epoch 88, Batch 10, Loss: 0.246\n",
      "Training: Epoch 88, Batch 11, Loss: 0.422\n",
      "Training: Epoch 88, Batch 12, Loss: 0.449\n",
      "Training: Epoch 88, Batch 13, Loss: 0.251\n",
      "Training: Epoch 88, Batch 14, Loss: 0.303\n",
      "Training: Epoch 88, Batch 15, Loss: 0.282\n",
      "Training: Epoch 88, Batch 16, Loss: 0.675\n",
      "Training: Epoch 88, Batch 17, Loss: 0.417\n",
      "Training: Epoch 88, Batch 18, Loss: 0.328\n",
      "Training: Epoch 88, Batch 19, Loss: 0.301\n",
      "Training: Epoch 88, Batch 20, Loss: 0.549\n",
      "Training: Epoch 88, Batch 21, Loss: 0.537\n",
      "Training: Epoch 88, Batch 22, Loss: 0.509\n",
      "Training: Epoch 88, Batch 23, Loss: 0.529\n",
      "Training: Epoch 88, Batch 24, Loss: 0.531\n",
      "Training: Epoch 88, Batch 25, Loss: 0.654\n",
      "Training: Epoch 88, Batch 26, Loss: 0.61\n",
      "Training: Epoch 88, Batch 27, Loss: 0.904\n",
      "Training: Epoch 88, Batch 28, Loss: 0.581\n",
      "Training: Epoch 88, Batch 29, Loss: 0.425\n",
      "Val: Epoch 88, Loss: 0.276\n",
      "Training: Epoch 89, Batch 0, Loss: 0.399\n",
      "Training: Epoch 89, Batch 1, Loss: 0.601\n",
      "Training: Epoch 89, Batch 2, Loss: 0.338\n",
      "Training: Epoch 89, Batch 3, Loss: 0.652\n",
      "Training: Epoch 89, Batch 4, Loss: 0.577\n",
      "Training: Epoch 89, Batch 5, Loss: 0.466\n",
      "Training: Epoch 89, Batch 6, Loss: 0.584\n",
      "Training: Epoch 89, Batch 7, Loss: 0.426\n",
      "Training: Epoch 89, Batch 8, Loss: 0.352\n",
      "Training: Epoch 89, Batch 9, Loss: 0.445\n",
      "Training: Epoch 89, Batch 10, Loss: 0.545\n",
      "Training: Epoch 89, Batch 11, Loss: 0.642\n",
      "Training: Epoch 89, Batch 12, Loss: 0.565\n",
      "Training: Epoch 89, Batch 13, Loss: 0.436\n",
      "Training: Epoch 89, Batch 14, Loss: 0.332\n",
      "Training: Epoch 89, Batch 15, Loss: 0.387\n",
      "Training: Epoch 89, Batch 16, Loss: 0.542\n",
      "Training: Epoch 89, Batch 17, Loss: 0.424\n",
      "Training: Epoch 89, Batch 18, Loss: 0.372\n",
      "Training: Epoch 89, Batch 19, Loss: 0.617\n",
      "Training: Epoch 89, Batch 20, Loss: 0.373\n",
      "Training: Epoch 89, Batch 21, Loss: 0.608\n",
      "Training: Epoch 89, Batch 22, Loss: 0.686\n",
      "Training: Epoch 89, Batch 23, Loss: 0.347\n",
      "Training: Epoch 89, Batch 24, Loss: 0.448\n",
      "Training: Epoch 89, Batch 25, Loss: 0.343\n",
      "Training: Epoch 89, Batch 26, Loss: 0.487\n",
      "Training: Epoch 89, Batch 27, Loss: 0.243\n",
      "Training: Epoch 89, Batch 28, Loss: 0.494\n",
      "Training: Epoch 89, Batch 29, Loss: 0.342\n",
      "Val: Epoch 89, Loss: 0.27\n",
      "Training: Epoch 90, Batch 0, Loss: 0.312\n",
      "Training: Epoch 90, Batch 1, Loss: 0.542\n",
      "Training: Epoch 90, Batch 2, Loss: 0.383\n",
      "Training: Epoch 90, Batch 3, Loss: 0.627\n",
      "Training: Epoch 90, Batch 4, Loss: 0.174\n",
      "Training: Epoch 90, Batch 5, Loss: 0.681\n",
      "Training: Epoch 90, Batch 6, Loss: 0.47\n",
      "Training: Epoch 90, Batch 7, Loss: 0.288\n",
      "Training: Epoch 90, Batch 8, Loss: 0.354\n",
      "Training: Epoch 90, Batch 9, Loss: 0.297\n",
      "Training: Epoch 90, Batch 10, Loss: 0.427\n",
      "Training: Epoch 90, Batch 11, Loss: 0.45\n",
      "Training: Epoch 90, Batch 12, Loss: 0.448\n",
      "Training: Epoch 90, Batch 13, Loss: 0.39\n",
      "Training: Epoch 90, Batch 14, Loss: 0.377\n",
      "Training: Epoch 90, Batch 15, Loss: 0.604\n",
      "Training: Epoch 90, Batch 16, Loss: 0.31\n",
      "Training: Epoch 90, Batch 17, Loss: 0.575\n",
      "Training: Epoch 90, Batch 18, Loss: 0.457\n",
      "Training: Epoch 90, Batch 19, Loss: 0.39\n",
      "Training: Epoch 90, Batch 20, Loss: 0.413\n",
      "Training: Epoch 90, Batch 21, Loss: 0.373\n",
      "Training: Epoch 90, Batch 22, Loss: 0.392\n",
      "Training: Epoch 90, Batch 23, Loss: 0.471\n",
      "Training: Epoch 90, Batch 24, Loss: 0.546\n",
      "Training: Epoch 90, Batch 25, Loss: 0.674\n",
      "Training: Epoch 90, Batch 26, Loss: 0.41\n",
      "Training: Epoch 90, Batch 27, Loss: 0.465\n",
      "Training: Epoch 90, Batch 28, Loss: 0.651\n",
      "Training: Epoch 90, Batch 29, Loss: 0.537\n",
      "Val: Epoch 90, Loss: 0.301\n",
      "Training: Epoch 91, Batch 0, Loss: 0.386\n",
      "Training: Epoch 91, Batch 1, Loss: 0.587\n",
      "Training: Epoch 91, Batch 2, Loss: 0.356\n",
      "Training: Epoch 91, Batch 3, Loss: 0.699\n",
      "Training: Epoch 91, Batch 4, Loss: 0.336\n",
      "Training: Epoch 91, Batch 5, Loss: 0.371\n",
      "Training: Epoch 91, Batch 6, Loss: 0.473\n",
      "Training: Epoch 91, Batch 7, Loss: 0.678\n",
      "Training: Epoch 91, Batch 8, Loss: 0.518\n",
      "Training: Epoch 91, Batch 9, Loss: 0.424\n",
      "Training: Epoch 91, Batch 10, Loss: 0.406\n",
      "Training: Epoch 91, Batch 11, Loss: 0.622\n",
      "Training: Epoch 91, Batch 12, Loss: 0.653\n",
      "Training: Epoch 91, Batch 13, Loss: 0.517\n",
      "Training: Epoch 91, Batch 14, Loss: 0.592\n",
      "Training: Epoch 91, Batch 15, Loss: 0.237\n",
      "Training: Epoch 91, Batch 16, Loss: 0.452\n",
      "Training: Epoch 91, Batch 17, Loss: 0.558\n",
      "Training: Epoch 91, Batch 18, Loss: 0.287\n",
      "Training: Epoch 91, Batch 19, Loss: 0.176\n",
      "Training: Epoch 91, Batch 20, Loss: 0.621\n",
      "Training: Epoch 91, Batch 21, Loss: 0.526\n",
      "Training: Epoch 91, Batch 22, Loss: 0.509\n",
      "Training: Epoch 91, Batch 23, Loss: 0.277\n",
      "Training: Epoch 91, Batch 24, Loss: 0.523\n",
      "Training: Epoch 91, Batch 25, Loss: 0.51\n",
      "Training: Epoch 91, Batch 26, Loss: 0.354\n",
      "Training: Epoch 91, Batch 27, Loss: 0.312\n",
      "Training: Epoch 91, Batch 28, Loss: 0.312\n",
      "Training: Epoch 91, Batch 29, Loss: 0.296\n",
      "Val: Epoch 91, Loss: 0.292\n",
      "Training: Epoch 92, Batch 0, Loss: 0.427\n",
      "Training: Epoch 92, Batch 1, Loss: 0.321\n",
      "Training: Epoch 92, Batch 2, Loss: 0.327\n",
      "Training: Epoch 92, Batch 3, Loss: 0.288\n",
      "Training: Epoch 92, Batch 4, Loss: 0.455\n",
      "Training: Epoch 92, Batch 5, Loss: 0.149\n",
      "Training: Epoch 92, Batch 6, Loss: 0.337\n",
      "Training: Epoch 92, Batch 7, Loss: 0.834\n",
      "Training: Epoch 92, Batch 8, Loss: 0.503\n",
      "Training: Epoch 92, Batch 9, Loss: 0.58\n",
      "Training: Epoch 92, Batch 10, Loss: 0.629\n",
      "Training: Epoch 92, Batch 11, Loss: 0.565\n",
      "Training: Epoch 92, Batch 12, Loss: 0.283\n",
      "Training: Epoch 92, Batch 13, Loss: 0.577\n",
      "Training: Epoch 92, Batch 14, Loss: 0.336\n",
      "Training: Epoch 92, Batch 15, Loss: 0.627\n",
      "Training: Epoch 92, Batch 16, Loss: 0.312\n",
      "Training: Epoch 92, Batch 17, Loss: 0.404\n",
      "Training: Epoch 92, Batch 18, Loss: 0.467\n",
      "Training: Epoch 92, Batch 19, Loss: 0.229\n",
      "Training: Epoch 92, Batch 20, Loss: 0.527\n",
      "Training: Epoch 92, Batch 21, Loss: 0.401\n",
      "Training: Epoch 92, Batch 22, Loss: 0.484\n",
      "Training: Epoch 92, Batch 23, Loss: 0.558\n",
      "Training: Epoch 92, Batch 24, Loss: 0.648\n",
      "Training: Epoch 92, Batch 25, Loss: 0.35\n",
      "Training: Epoch 92, Batch 26, Loss: 0.414\n",
      "Training: Epoch 92, Batch 27, Loss: 0.387\n",
      "Training: Epoch 92, Batch 28, Loss: 0.678\n",
      "Training: Epoch 92, Batch 29, Loss: 0.445\n",
      "Val: Epoch 92, Loss: 0.28\n",
      "Training: Epoch 93, Batch 0, Loss: 0.4\n",
      "Training: Epoch 93, Batch 1, Loss: 0.643\n",
      "Training: Epoch 93, Batch 2, Loss: 0.721\n",
      "Training: Epoch 93, Batch 3, Loss: 0.41\n",
      "Training: Epoch 93, Batch 4, Loss: 0.532\n",
      "Training: Epoch 93, Batch 5, Loss: 0.555\n",
      "Training: Epoch 93, Batch 6, Loss: 0.425\n",
      "Training: Epoch 93, Batch 7, Loss: 0.383\n",
      "Training: Epoch 93, Batch 8, Loss: 0.572\n",
      "Training: Epoch 93, Batch 9, Loss: 0.447\n",
      "Training: Epoch 93, Batch 10, Loss: 0.466\n",
      "Training: Epoch 93, Batch 11, Loss: 0.625\n",
      "Training: Epoch 93, Batch 12, Loss: 0.331\n",
      "Training: Epoch 93, Batch 13, Loss: 0.241\n",
      "Training: Epoch 93, Batch 14, Loss: 0.322\n",
      "Training: Epoch 93, Batch 15, Loss: 0.547\n",
      "Training: Epoch 93, Batch 16, Loss: 0.327\n",
      "Training: Epoch 93, Batch 17, Loss: 0.368\n",
      "Training: Epoch 93, Batch 18, Loss: 0.561\n",
      "Training: Epoch 93, Batch 19, Loss: 0.253\n",
      "Training: Epoch 93, Batch 20, Loss: 0.367\n",
      "Training: Epoch 93, Batch 21, Loss: 0.284\n",
      "Training: Epoch 93, Batch 22, Loss: 0.739\n",
      "Training: Epoch 93, Batch 23, Loss: 0.544\n",
      "Training: Epoch 93, Batch 24, Loss: 0.617\n",
      "Training: Epoch 93, Batch 25, Loss: 0.254\n",
      "Training: Epoch 93, Batch 26, Loss: 0.393\n",
      "Training: Epoch 93, Batch 27, Loss: 0.449\n",
      "Training: Epoch 93, Batch 28, Loss: 0.616\n",
      "Training: Epoch 93, Batch 29, Loss: 0.262\n",
      "Val: Epoch 93, Loss: 0.351\n",
      "Training: Epoch 94, Batch 0, Loss: 0.533\n",
      "Training: Epoch 94, Batch 1, Loss: 0.386\n",
      "Training: Epoch 94, Batch 2, Loss: 0.48\n",
      "Training: Epoch 94, Batch 3, Loss: 0.657\n",
      "Training: Epoch 94, Batch 4, Loss: 0.512\n",
      "Training: Epoch 94, Batch 5, Loss: 0.459\n",
      "Training: Epoch 94, Batch 6, Loss: 0.391\n",
      "Training: Epoch 94, Batch 7, Loss: 0.37\n",
      "Training: Epoch 94, Batch 8, Loss: 0.338\n",
      "Training: Epoch 94, Batch 9, Loss: 0.18\n",
      "Training: Epoch 94, Batch 10, Loss: 0.386\n",
      "Training: Epoch 94, Batch 11, Loss: 0.568\n",
      "Training: Epoch 94, Batch 12, Loss: 0.498\n",
      "Training: Epoch 94, Batch 13, Loss: 0.387\n",
      "Training: Epoch 94, Batch 14, Loss: 0.547\n",
      "Training: Epoch 94, Batch 15, Loss: 0.469\n",
      "Training: Epoch 94, Batch 16, Loss: 0.363\n",
      "Training: Epoch 94, Batch 17, Loss: 0.314\n",
      "Training: Epoch 94, Batch 18, Loss: 0.444\n",
      "Training: Epoch 94, Batch 19, Loss: 0.39\n",
      "Training: Epoch 94, Batch 20, Loss: 0.356\n",
      "Training: Epoch 94, Batch 21, Loss: 0.512\n",
      "Training: Epoch 94, Batch 22, Loss: 0.519\n",
      "Training: Epoch 94, Batch 23, Loss: 0.398\n",
      "Training: Epoch 94, Batch 24, Loss: 0.545\n",
      "Training: Epoch 94, Batch 25, Loss: 0.481\n",
      "Training: Epoch 94, Batch 26, Loss: 0.475\n",
      "Training: Epoch 94, Batch 27, Loss: 0.384\n",
      "Training: Epoch 94, Batch 28, Loss: 0.363\n",
      "Training: Epoch 94, Batch 29, Loss: 0.633\n",
      "Val: Epoch 94, Loss: 0.264\n",
      "Training: Epoch 95, Batch 0, Loss: 0.444\n",
      "Training: Epoch 95, Batch 1, Loss: 0.464\n",
      "Training: Epoch 95, Batch 2, Loss: 0.523\n",
      "Training: Epoch 95, Batch 3, Loss: 0.209\n",
      "Training: Epoch 95, Batch 4, Loss: 0.231\n",
      "Training: Epoch 95, Batch 5, Loss: 0.386\n",
      "Training: Epoch 95, Batch 6, Loss: 0.45\n",
      "Training: Epoch 95, Batch 7, Loss: 0.512\n",
      "Training: Epoch 95, Batch 8, Loss: 0.315\n",
      "Training: Epoch 95, Batch 9, Loss: 0.351\n",
      "Training: Epoch 95, Batch 10, Loss: 0.319\n",
      "Training: Epoch 95, Batch 11, Loss: 0.345\n",
      "Training: Epoch 95, Batch 12, Loss: 0.449\n",
      "Training: Epoch 95, Batch 13, Loss: 0.242\n",
      "Training: Epoch 95, Batch 14, Loss: 0.372\n",
      "Training: Epoch 95, Batch 15, Loss: 0.407\n",
      "Training: Epoch 95, Batch 16, Loss: 0.427\n",
      "Training: Epoch 95, Batch 17, Loss: 0.743\n",
      "Training: Epoch 95, Batch 18, Loss: 0.747\n",
      "Training: Epoch 95, Batch 19, Loss: 0.449\n",
      "Training: Epoch 95, Batch 20, Loss: 0.359\n",
      "Training: Epoch 95, Batch 21, Loss: 0.533\n",
      "Training: Epoch 95, Batch 22, Loss: 0.454\n",
      "Training: Epoch 95, Batch 23, Loss: 0.466\n",
      "Training: Epoch 95, Batch 24, Loss: 0.646\n",
      "Training: Epoch 95, Batch 25, Loss: 0.37\n",
      "Training: Epoch 95, Batch 26, Loss: 0.492\n",
      "Training: Epoch 95, Batch 27, Loss: 0.568\n",
      "Training: Epoch 95, Batch 28, Loss: 0.572\n",
      "Training: Epoch 95, Batch 29, Loss: 0.493\n",
      "Val: Epoch 95, Loss: 0.267\n",
      "Training: Epoch 96, Batch 0, Loss: 0.624\n",
      "Training: Epoch 96, Batch 1, Loss: 0.464\n",
      "Training: Epoch 96, Batch 2, Loss: 0.276\n",
      "Training: Epoch 96, Batch 3, Loss: 0.409\n",
      "Training: Epoch 96, Batch 4, Loss: 0.387\n",
      "Training: Epoch 96, Batch 5, Loss: 0.59\n",
      "Training: Epoch 96, Batch 6, Loss: 0.629\n",
      "Training: Epoch 96, Batch 7, Loss: 0.425\n",
      "Training: Epoch 96, Batch 8, Loss: 0.38\n",
      "Training: Epoch 96, Batch 9, Loss: 0.628\n",
      "Training: Epoch 96, Batch 10, Loss: 0.318\n",
      "Training: Epoch 96, Batch 11, Loss: 0.352\n",
      "Training: Epoch 96, Batch 12, Loss: 0.511\n",
      "Training: Epoch 96, Batch 13, Loss: 0.547\n",
      "Training: Epoch 96, Batch 14, Loss: 0.39\n",
      "Training: Epoch 96, Batch 15, Loss: 0.616\n",
      "Training: Epoch 96, Batch 16, Loss: 0.473\n",
      "Training: Epoch 96, Batch 17, Loss: 0.202\n",
      "Training: Epoch 96, Batch 18, Loss: 0.441\n",
      "Training: Epoch 96, Batch 19, Loss: 0.527\n",
      "Training: Epoch 96, Batch 20, Loss: 0.393\n",
      "Training: Epoch 96, Batch 21, Loss: 0.386\n",
      "Training: Epoch 96, Batch 22, Loss: 0.407\n",
      "Training: Epoch 96, Batch 23, Loss: 0.493\n",
      "Training: Epoch 96, Batch 24, Loss: 0.316\n",
      "Training: Epoch 96, Batch 25, Loss: 0.497\n",
      "Training: Epoch 96, Batch 26, Loss: 0.581\n",
      "Training: Epoch 96, Batch 27, Loss: 0.367\n",
      "Training: Epoch 96, Batch 28, Loss: 0.299\n",
      "Training: Epoch 96, Batch 29, Loss: 0.549\n",
      "Val: Epoch 96, Loss: 0.285\n",
      "Training: Epoch 97, Batch 0, Loss: 0.509\n",
      "Training: Epoch 97, Batch 1, Loss: 0.364\n",
      "Training: Epoch 97, Batch 2, Loss: 0.379\n",
      "Training: Epoch 97, Batch 3, Loss: 0.295\n",
      "Training: Epoch 97, Batch 4, Loss: 0.239\n",
      "Training: Epoch 97, Batch 5, Loss: 0.338\n",
      "Training: Epoch 97, Batch 6, Loss: 0.487\n",
      "Training: Epoch 97, Batch 7, Loss: 0.369\n",
      "Training: Epoch 97, Batch 8, Loss: 0.335\n",
      "Training: Epoch 97, Batch 9, Loss: 0.372\n",
      "Training: Epoch 97, Batch 10, Loss: 0.414\n",
      "Training: Epoch 97, Batch 11, Loss: 0.285\n",
      "Training: Epoch 97, Batch 12, Loss: 0.579\n",
      "Training: Epoch 97, Batch 13, Loss: 0.523\n",
      "Training: Epoch 97, Batch 14, Loss: 1.14\n",
      "Training: Epoch 97, Batch 15, Loss: 0.445\n",
      "Training: Epoch 97, Batch 16, Loss: 0.612\n",
      "Training: Epoch 97, Batch 17, Loss: 0.273\n",
      "Training: Epoch 97, Batch 18, Loss: 0.65\n",
      "Training: Epoch 97, Batch 19, Loss: 0.481\n",
      "Training: Epoch 97, Batch 20, Loss: 0.53\n",
      "Training: Epoch 97, Batch 21, Loss: 0.579\n",
      "Training: Epoch 97, Batch 22, Loss: 0.425\n",
      "Training: Epoch 97, Batch 23, Loss: 0.379\n",
      "Training: Epoch 97, Batch 24, Loss: 0.672\n",
      "Training: Epoch 97, Batch 25, Loss: 0.533\n",
      "Training: Epoch 97, Batch 26, Loss: 0.417\n",
      "Training: Epoch 97, Batch 27, Loss: 0.437\n",
      "Training: Epoch 97, Batch 28, Loss: 0.61\n",
      "Training: Epoch 97, Batch 29, Loss: 0.487\n",
      "Val: Epoch 97, Loss: 0.273\n",
      "Training: Epoch 98, Batch 0, Loss: 0.325\n",
      "Training: Epoch 98, Batch 1, Loss: 0.366\n",
      "Training: Epoch 98, Batch 2, Loss: 0.633\n",
      "Training: Epoch 98, Batch 3, Loss: 0.414\n",
      "Training: Epoch 98, Batch 4, Loss: 0.275\n",
      "Training: Epoch 98, Batch 5, Loss: 0.449\n",
      "Training: Epoch 98, Batch 6, Loss: 0.508\n",
      "Training: Epoch 98, Batch 7, Loss: 0.343\n",
      "Training: Epoch 98, Batch 8, Loss: 0.608\n",
      "Training: Epoch 98, Batch 9, Loss: 0.187\n",
      "Training: Epoch 98, Batch 10, Loss: 0.435\n",
      "Training: Epoch 98, Batch 11, Loss: 0.566\n",
      "Training: Epoch 98, Batch 12, Loss: 0.443\n",
      "Training: Epoch 98, Batch 13, Loss: 0.529\n",
      "Training: Epoch 98, Batch 14, Loss: 0.194\n",
      "Training: Epoch 98, Batch 15, Loss: 0.736\n",
      "Training: Epoch 98, Batch 16, Loss: 0.597\n",
      "Training: Epoch 98, Batch 17, Loss: 0.347\n",
      "Training: Epoch 98, Batch 18, Loss: 0.398\n",
      "Training: Epoch 98, Batch 19, Loss: 0.367\n",
      "Training: Epoch 98, Batch 20, Loss: 0.498\n",
      "Training: Epoch 98, Batch 21, Loss: 0.428\n",
      "Training: Epoch 98, Batch 22, Loss: 0.474\n",
      "Training: Epoch 98, Batch 23, Loss: 0.527\n",
      "Training: Epoch 98, Batch 24, Loss: 1.071\n",
      "Training: Epoch 98, Batch 25, Loss: 0.438\n",
      "Training: Epoch 98, Batch 26, Loss: 0.541\n",
      "Training: Epoch 98, Batch 27, Loss: 0.507\n",
      "Training: Epoch 98, Batch 28, Loss: 0.317\n",
      "Training: Epoch 98, Batch 29, Loss: 0.442\n",
      "Val: Epoch 98, Loss: 0.256\n",
      "Training: Epoch 99, Batch 0, Loss: 0.447\n",
      "Training: Epoch 99, Batch 1, Loss: 0.344\n",
      "Training: Epoch 99, Batch 2, Loss: 0.564\n",
      "Training: Epoch 99, Batch 3, Loss: 0.402\n",
      "Training: Epoch 99, Batch 4, Loss: 0.48\n",
      "Training: Epoch 99, Batch 5, Loss: 0.54\n",
      "Training: Epoch 99, Batch 6, Loss: 0.315\n",
      "Training: Epoch 99, Batch 7, Loss: 0.488\n",
      "Training: Epoch 99, Batch 8, Loss: 0.305\n",
      "Training: Epoch 99, Batch 9, Loss: 0.484\n",
      "Training: Epoch 99, Batch 10, Loss: 0.472\n",
      "Training: Epoch 99, Batch 11, Loss: 0.586\n",
      "Training: Epoch 99, Batch 12, Loss: 0.429\n",
      "Training: Epoch 99, Batch 13, Loss: 0.559\n",
      "Training: Epoch 99, Batch 14, Loss: 0.365\n",
      "Training: Epoch 99, Batch 15, Loss: 0.533\n",
      "Training: Epoch 99, Batch 16, Loss: 0.358\n",
      "Training: Epoch 99, Batch 17, Loss: 0.566\n",
      "Training: Epoch 99, Batch 18, Loss: 0.633\n",
      "Training: Epoch 99, Batch 19, Loss: 0.444\n",
      "Training: Epoch 99, Batch 20, Loss: 0.781\n",
      "Training: Epoch 99, Batch 21, Loss: 0.567\n",
      "Training: Epoch 99, Batch 22, Loss: 0.306\n",
      "Training: Epoch 99, Batch 23, Loss: 0.449\n",
      "Training: Epoch 99, Batch 24, Loss: 0.381\n",
      "Training: Epoch 99, Batch 25, Loss: 0.309\n",
      "Training: Epoch 99, Batch 26, Loss: 0.289\n",
      "Training: Epoch 99, Batch 27, Loss: 0.226\n",
      "Training: Epoch 99, Batch 28, Loss: 0.613\n",
      "Training: Epoch 99, Batch 29, Loss: 0.479\n",
      "Val: Epoch 99, Loss: 0.27\n",
      "Training: Epoch 100, Batch 0, Loss: 0.378\n",
      "Training: Epoch 100, Batch 1, Loss: 0.575\n",
      "Training: Epoch 100, Batch 2, Loss: 0.5\n",
      "Training: Epoch 100, Batch 3, Loss: 0.398\n",
      "Training: Epoch 100, Batch 4, Loss: 0.527\n",
      "Training: Epoch 100, Batch 5, Loss: 0.418\n",
      "Training: Epoch 100, Batch 6, Loss: 0.567\n",
      "Training: Epoch 100, Batch 7, Loss: 0.398\n",
      "Training: Epoch 100, Batch 8, Loss: 0.458\n",
      "Training: Epoch 100, Batch 9, Loss: 0.416\n",
      "Training: Epoch 100, Batch 10, Loss: 0.422\n",
      "Training: Epoch 100, Batch 11, Loss: 0.519\n",
      "Training: Epoch 100, Batch 12, Loss: 0.348\n",
      "Training: Epoch 100, Batch 13, Loss: 0.359\n",
      "Training: Epoch 100, Batch 14, Loss: 0.391\n",
      "Training: Epoch 100, Batch 15, Loss: 0.565\n",
      "Training: Epoch 100, Batch 16, Loss: 0.456\n",
      "Training: Epoch 100, Batch 17, Loss: 0.398\n",
      "Training: Epoch 100, Batch 18, Loss: 0.465\n",
      "Training: Epoch 100, Batch 19, Loss: 0.341\n",
      "Training: Epoch 100, Batch 20, Loss: 0.351\n",
      "Training: Epoch 100, Batch 21, Loss: 0.432\n",
      "Training: Epoch 100, Batch 22, Loss: 0.438\n",
      "Training: Epoch 100, Batch 23, Loss: 0.562\n",
      "Training: Epoch 100, Batch 24, Loss: 0.313\n",
      "Training: Epoch 100, Batch 25, Loss: 0.468\n",
      "Training: Epoch 100, Batch 26, Loss: 0.447\n",
      "Training: Epoch 100, Batch 27, Loss: 0.553\n",
      "Training: Epoch 100, Batch 28, Loss: 0.465\n",
      "Training: Epoch 100, Batch 29, Loss: 0.465\n",
      "Val: Epoch 100, Loss: 0.269\n",
      "Training: Epoch 101, Batch 0, Loss: 0.796\n",
      "Training: Epoch 101, Batch 1, Loss: 0.463\n",
      "Training: Epoch 101, Batch 2, Loss: 0.715\n",
      "Training: Epoch 101, Batch 3, Loss: 0.354\n",
      "Training: Epoch 101, Batch 4, Loss: 0.484\n",
      "Training: Epoch 101, Batch 5, Loss: 0.364\n",
      "Training: Epoch 101, Batch 6, Loss: 0.385\n",
      "Training: Epoch 101, Batch 7, Loss: 0.558\n",
      "Training: Epoch 101, Batch 8, Loss: 0.419\n",
      "Training: Epoch 101, Batch 9, Loss: 0.499\n",
      "Training: Epoch 101, Batch 10, Loss: 0.324\n",
      "Training: Epoch 101, Batch 11, Loss: 0.256\n",
      "Training: Epoch 101, Batch 12, Loss: 0.574\n",
      "Training: Epoch 101, Batch 13, Loss: 0.372\n",
      "Training: Epoch 101, Batch 14, Loss: 0.544\n",
      "Training: Epoch 101, Batch 15, Loss: 0.364\n",
      "Training: Epoch 101, Batch 16, Loss: 0.373\n",
      "Training: Epoch 101, Batch 17, Loss: 0.346\n",
      "Training: Epoch 101, Batch 18, Loss: 0.658\n",
      "Training: Epoch 101, Batch 19, Loss: 0.591\n",
      "Training: Epoch 101, Batch 20, Loss: 0.171\n",
      "Training: Epoch 101, Batch 21, Loss: 0.448\n",
      "Training: Epoch 101, Batch 22, Loss: 0.531\n",
      "Training: Epoch 101, Batch 23, Loss: 0.295\n",
      "Training: Epoch 101, Batch 24, Loss: 0.32\n",
      "Training: Epoch 101, Batch 25, Loss: 0.635\n",
      "Training: Epoch 101, Batch 26, Loss: 0.367\n",
      "Training: Epoch 101, Batch 27, Loss: 0.257\n",
      "Training: Epoch 101, Batch 28, Loss: 0.547\n",
      "Training: Epoch 101, Batch 29, Loss: 0.49\n",
      "Val: Epoch 101, Loss: 0.27\n",
      "Training: Epoch 102, Batch 0, Loss: 0.443\n",
      "Training: Epoch 102, Batch 1, Loss: 0.429\n",
      "Training: Epoch 102, Batch 2, Loss: 0.399\n",
      "Training: Epoch 102, Batch 3, Loss: 0.456\n",
      "Training: Epoch 102, Batch 4, Loss: 0.343\n",
      "Training: Epoch 102, Batch 5, Loss: 0.289\n",
      "Training: Epoch 102, Batch 6, Loss: 0.362\n",
      "Training: Epoch 102, Batch 7, Loss: 0.465\n",
      "Training: Epoch 102, Batch 8, Loss: 0.455\n",
      "Training: Epoch 102, Batch 9, Loss: 0.59\n",
      "Training: Epoch 102, Batch 10, Loss: 0.498\n",
      "Training: Epoch 102, Batch 11, Loss: 0.277\n",
      "Training: Epoch 102, Batch 12, Loss: 0.33\n",
      "Training: Epoch 102, Batch 13, Loss: 0.214\n",
      "Training: Epoch 102, Batch 14, Loss: 0.481\n",
      "Training: Epoch 102, Batch 15, Loss: 0.436\n",
      "Training: Epoch 102, Batch 16, Loss: 0.618\n",
      "Training: Epoch 102, Batch 17, Loss: 0.49\n",
      "Training: Epoch 102, Batch 18, Loss: 0.53\n",
      "Training: Epoch 102, Batch 19, Loss: 0.641\n",
      "Training: Epoch 102, Batch 20, Loss: 0.544\n",
      "Training: Epoch 102, Batch 21, Loss: 0.463\n",
      "Training: Epoch 102, Batch 22, Loss: 0.505\n",
      "Training: Epoch 102, Batch 23, Loss: 0.513\n",
      "Training: Epoch 102, Batch 24, Loss: 2.011\n",
      "Training: Epoch 102, Batch 25, Loss: 0.287\n",
      "Training: Epoch 102, Batch 26, Loss: 0.352\n",
      "Training: Epoch 102, Batch 27, Loss: 0.543\n",
      "Training: Epoch 102, Batch 28, Loss: 0.274\n",
      "Training: Epoch 102, Batch 29, Loss: 0.36\n",
      "Val: Epoch 102, Loss: 0.313\n",
      "Training: Epoch 103, Batch 0, Loss: 0.415\n",
      "Training: Epoch 103, Batch 1, Loss: 0.336\n",
      "Training: Epoch 103, Batch 2, Loss: 0.598\n",
      "Training: Epoch 103, Batch 3, Loss: 0.33\n",
      "Training: Epoch 103, Batch 4, Loss: 0.416\n",
      "Training: Epoch 103, Batch 5, Loss: 0.565\n",
      "Training: Epoch 103, Batch 6, Loss: 0.3\n",
      "Training: Epoch 103, Batch 7, Loss: 0.613\n",
      "Training: Epoch 103, Batch 8, Loss: 0.643\n",
      "Training: Epoch 103, Batch 9, Loss: 0.502\n",
      "Training: Epoch 103, Batch 10, Loss: 0.634\n",
      "Training: Epoch 103, Batch 11, Loss: 0.395\n",
      "Training: Epoch 103, Batch 12, Loss: 0.282\n",
      "Training: Epoch 103, Batch 13, Loss: 0.528\n",
      "Training: Epoch 103, Batch 14, Loss: 0.415\n",
      "Training: Epoch 103, Batch 15, Loss: 0.395\n",
      "Training: Epoch 103, Batch 16, Loss: 0.358\n",
      "Training: Epoch 103, Batch 17, Loss: 0.514\n",
      "Training: Epoch 103, Batch 18, Loss: 0.588\n",
      "Training: Epoch 103, Batch 19, Loss: 0.324\n",
      "Training: Epoch 103, Batch 20, Loss: 0.48\n",
      "Training: Epoch 103, Batch 21, Loss: 0.568\n",
      "Training: Epoch 103, Batch 22, Loss: 0.282\n",
      "Training: Epoch 103, Batch 23, Loss: 0.546\n",
      "Training: Epoch 103, Batch 24, Loss: 0.417\n",
      "Training: Epoch 103, Batch 25, Loss: 0.628\n",
      "Training: Epoch 103, Batch 26, Loss: 0.526\n",
      "Training: Epoch 103, Batch 27, Loss: 0.551\n",
      "Training: Epoch 103, Batch 28, Loss: 0.302\n",
      "Training: Epoch 103, Batch 29, Loss: 0.564\n",
      "Val: Epoch 103, Loss: 0.319\n",
      "Training: Epoch 104, Batch 0, Loss: 0.53\n",
      "Training: Epoch 104, Batch 1, Loss: 0.458\n",
      "Training: Epoch 104, Batch 2, Loss: 0.49\n",
      "Training: Epoch 104, Batch 3, Loss: 0.349\n",
      "Training: Epoch 104, Batch 4, Loss: 0.384\n",
      "Training: Epoch 104, Batch 5, Loss: 0.451\n",
      "Training: Epoch 104, Batch 6, Loss: 0.521\n",
      "Training: Epoch 104, Batch 7, Loss: 0.511\n",
      "Training: Epoch 104, Batch 8, Loss: 0.376\n",
      "Training: Epoch 104, Batch 9, Loss: 0.411\n",
      "Training: Epoch 104, Batch 10, Loss: 0.548\n",
      "Training: Epoch 104, Batch 11, Loss: 0.589\n",
      "Training: Epoch 104, Batch 12, Loss: 0.478\n",
      "Training: Epoch 104, Batch 13, Loss: 0.4\n",
      "Training: Epoch 104, Batch 14, Loss: 0.363\n",
      "Training: Epoch 104, Batch 15, Loss: 0.424\n",
      "Training: Epoch 104, Batch 16, Loss: 0.513\n",
      "Training: Epoch 104, Batch 17, Loss: 0.554\n",
      "Training: Epoch 104, Batch 18, Loss: 0.252\n",
      "Training: Epoch 104, Batch 19, Loss: 0.349\n",
      "Training: Epoch 104, Batch 20, Loss: 0.438\n",
      "Training: Epoch 104, Batch 21, Loss: 0.378\n",
      "Training: Epoch 104, Batch 22, Loss: 0.317\n",
      "Training: Epoch 104, Batch 23, Loss: 0.622\n",
      "Training: Epoch 104, Batch 24, Loss: 0.293\n",
      "Training: Epoch 104, Batch 25, Loss: 0.527\n",
      "Training: Epoch 104, Batch 26, Loss: 0.382\n",
      "Training: Epoch 104, Batch 27, Loss: 0.377\n",
      "Training: Epoch 104, Batch 28, Loss: 0.384\n",
      "Training: Epoch 104, Batch 29, Loss: 0.475\n",
      "Val: Epoch 104, Loss: 0.271\n",
      "Training: Epoch 105, Batch 0, Loss: 0.362\n",
      "Training: Epoch 105, Batch 1, Loss: 0.353\n",
      "Training: Epoch 105, Batch 2, Loss: 0.409\n",
      "Training: Epoch 105, Batch 3, Loss: 0.354\n",
      "Training: Epoch 105, Batch 4, Loss: 0.383\n",
      "Training: Epoch 105, Batch 5, Loss: 0.505\n",
      "Training: Epoch 105, Batch 6, Loss: 0.52\n",
      "Training: Epoch 105, Batch 7, Loss: 0.721\n",
      "Training: Epoch 105, Batch 8, Loss: 0.666\n",
      "Training: Epoch 105, Batch 9, Loss: 0.382\n",
      "Training: Epoch 105, Batch 10, Loss: 0.478\n",
      "Training: Epoch 105, Batch 11, Loss: 0.338\n",
      "Training: Epoch 105, Batch 12, Loss: 0.321\n",
      "Training: Epoch 105, Batch 13, Loss: 0.408\n",
      "Training: Epoch 105, Batch 14, Loss: 0.355\n",
      "Training: Epoch 105, Batch 15, Loss: 0.624\n",
      "Training: Epoch 105, Batch 16, Loss: 0.492\n",
      "Training: Epoch 105, Batch 17, Loss: 0.364\n",
      "Training: Epoch 105, Batch 18, Loss: 0.405\n",
      "Training: Epoch 105, Batch 19, Loss: 0.361\n",
      "Training: Epoch 105, Batch 20, Loss: 0.362\n",
      "Training: Epoch 105, Batch 21, Loss: 0.367\n",
      "Training: Epoch 105, Batch 22, Loss: 0.49\n",
      "Training: Epoch 105, Batch 23, Loss: 0.456\n",
      "Training: Epoch 105, Batch 24, Loss: 0.251\n",
      "Training: Epoch 105, Batch 25, Loss: 0.238\n",
      "Training: Epoch 105, Batch 26, Loss: 0.65\n",
      "Training: Epoch 105, Batch 27, Loss: 0.433\n",
      "Training: Epoch 105, Batch 28, Loss: 0.525\n",
      "Training: Epoch 105, Batch 29, Loss: 0.522\n",
      "Val: Epoch 105, Loss: 0.362\n",
      "Training: Epoch 106, Batch 0, Loss: 0.546\n",
      "Training: Epoch 106, Batch 1, Loss: 0.534\n",
      "Training: Epoch 106, Batch 2, Loss: 0.435\n",
      "Training: Epoch 106, Batch 3, Loss: 0.371\n",
      "Training: Epoch 106, Batch 4, Loss: 0.652\n",
      "Training: Epoch 106, Batch 5, Loss: 0.412\n",
      "Training: Epoch 106, Batch 6, Loss: 0.394\n",
      "Training: Epoch 106, Batch 7, Loss: 0.439\n",
      "Training: Epoch 106, Batch 8, Loss: 0.365\n",
      "Training: Epoch 106, Batch 9, Loss: 0.49\n",
      "Training: Epoch 106, Batch 10, Loss: 0.371\n",
      "Training: Epoch 106, Batch 11, Loss: 0.459\n",
      "Training: Epoch 106, Batch 12, Loss: 0.464\n",
      "Training: Epoch 106, Batch 13, Loss: 0.251\n",
      "Training: Epoch 106, Batch 14, Loss: 0.421\n",
      "Training: Epoch 106, Batch 15, Loss: 0.268\n",
      "Training: Epoch 106, Batch 16, Loss: 0.482\n",
      "Training: Epoch 106, Batch 17, Loss: 0.435\n",
      "Training: Epoch 106, Batch 18, Loss: 0.499\n",
      "Training: Epoch 106, Batch 19, Loss: 0.401\n",
      "Training: Epoch 106, Batch 20, Loss: 0.541\n",
      "Training: Epoch 106, Batch 21, Loss: 0.168\n",
      "Training: Epoch 106, Batch 22, Loss: 0.707\n",
      "Training: Epoch 106, Batch 23, Loss: 0.232\n",
      "Training: Epoch 106, Batch 24, Loss: 0.717\n",
      "Training: Epoch 106, Batch 25, Loss: 0.52\n",
      "Training: Epoch 106, Batch 26, Loss: 0.321\n",
      "Training: Epoch 106, Batch 27, Loss: 0.419\n",
      "Training: Epoch 106, Batch 28, Loss: 0.53\n",
      "Training: Epoch 106, Batch 29, Loss: 0.23\n",
      "Val: Epoch 106, Loss: 0.289\n",
      "Training: Epoch 107, Batch 0, Loss: 0.312\n",
      "Training: Epoch 107, Batch 1, Loss: 0.342\n",
      "Training: Epoch 107, Batch 2, Loss: 0.602\n",
      "Training: Epoch 107, Batch 3, Loss: 0.498\n",
      "Training: Epoch 107, Batch 4, Loss: 0.24\n",
      "Training: Epoch 107, Batch 5, Loss: 0.476\n",
      "Training: Epoch 107, Batch 6, Loss: 0.426\n",
      "Training: Epoch 107, Batch 7, Loss: 0.61\n",
      "Training: Epoch 107, Batch 8, Loss: 0.215\n",
      "Training: Epoch 107, Batch 9, Loss: 0.465\n",
      "Training: Epoch 107, Batch 10, Loss: 0.489\n",
      "Training: Epoch 107, Batch 11, Loss: 0.341\n",
      "Training: Epoch 107, Batch 12, Loss: 0.233\n",
      "Training: Epoch 107, Batch 13, Loss: 0.387\n",
      "Training: Epoch 107, Batch 14, Loss: 0.358\n",
      "Training: Epoch 107, Batch 15, Loss: 0.194\n",
      "Training: Epoch 107, Batch 16, Loss: 0.51\n",
      "Training: Epoch 107, Batch 17, Loss: 0.39\n",
      "Training: Epoch 107, Batch 18, Loss: 0.668\n",
      "Training: Epoch 107, Batch 19, Loss: 0.521\n",
      "Training: Epoch 107, Batch 20, Loss: 0.453\n",
      "Training: Epoch 107, Batch 21, Loss: 0.587\n",
      "Training: Epoch 107, Batch 22, Loss: 0.437\n",
      "Training: Epoch 107, Batch 23, Loss: 0.309\n",
      "Training: Epoch 107, Batch 24, Loss: 0.632\n",
      "Training: Epoch 107, Batch 25, Loss: 0.549\n",
      "Training: Epoch 107, Batch 26, Loss: 0.517\n",
      "Training: Epoch 107, Batch 27, Loss: 0.437\n",
      "Training: Epoch 107, Batch 28, Loss: 0.358\n",
      "Training: Epoch 107, Batch 29, Loss: 0.392\n",
      "Val: Epoch 107, Loss: 0.292\n",
      "Training: Epoch 108, Batch 0, Loss: 0.356\n",
      "Training: Epoch 108, Batch 1, Loss: 0.266\n",
      "Training: Epoch 108, Batch 2, Loss: 0.394\n",
      "Training: Epoch 108, Batch 3, Loss: 0.259\n",
      "Training: Epoch 108, Batch 4, Loss: 0.681\n",
      "Training: Epoch 108, Batch 5, Loss: 0.292\n",
      "Training: Epoch 108, Batch 6, Loss: 0.331\n",
      "Training: Epoch 108, Batch 7, Loss: 0.437\n",
      "Training: Epoch 108, Batch 8, Loss: 0.428\n",
      "Training: Epoch 108, Batch 9, Loss: 0.487\n",
      "Training: Epoch 108, Batch 10, Loss: 0.324\n",
      "Training: Epoch 108, Batch 11, Loss: 0.423\n",
      "Training: Epoch 108, Batch 12, Loss: 0.464\n",
      "Training: Epoch 108, Batch 13, Loss: 0.611\n",
      "Training: Epoch 108, Batch 14, Loss: 0.356\n",
      "Training: Epoch 108, Batch 15, Loss: 0.326\n",
      "Training: Epoch 108, Batch 16, Loss: 0.479\n",
      "Training: Epoch 108, Batch 17, Loss: 0.648\n",
      "Training: Epoch 108, Batch 18, Loss: 0.279\n",
      "Training: Epoch 108, Batch 19, Loss: 0.521\n",
      "Training: Epoch 108, Batch 20, Loss: 0.222\n",
      "Training: Epoch 108, Batch 21, Loss: 0.454\n",
      "Training: Epoch 108, Batch 22, Loss: 0.632\n",
      "Training: Epoch 108, Batch 23, Loss: 0.519\n",
      "Training: Epoch 108, Batch 24, Loss: 0.325\n",
      "Training: Epoch 108, Batch 25, Loss: 0.569\n",
      "Training: Epoch 108, Batch 26, Loss: 0.432\n",
      "Training: Epoch 108, Batch 27, Loss: 0.272\n",
      "Training: Epoch 108, Batch 28, Loss: 0.58\n",
      "Training: Epoch 108, Batch 29, Loss: 0.292\n",
      "Val: Epoch 108, Loss: 0.288\n",
      "Training: Epoch 109, Batch 0, Loss: 0.316\n",
      "Training: Epoch 109, Batch 1, Loss: 0.449\n",
      "Training: Epoch 109, Batch 2, Loss: 0.328\n",
      "Training: Epoch 109, Batch 3, Loss: 0.387\n",
      "Training: Epoch 109, Batch 4, Loss: 0.469\n",
      "Training: Epoch 109, Batch 5, Loss: 0.707\n",
      "Training: Epoch 109, Batch 6, Loss: 0.422\n",
      "Training: Epoch 109, Batch 7, Loss: 0.385\n",
      "Training: Epoch 109, Batch 8, Loss: 0.542\n",
      "Training: Epoch 109, Batch 9, Loss: 0.477\n",
      "Training: Epoch 109, Batch 10, Loss: 0.315\n",
      "Training: Epoch 109, Batch 11, Loss: 0.475\n",
      "Training: Epoch 109, Batch 12, Loss: 0.285\n",
      "Training: Epoch 109, Batch 13, Loss: 0.578\n",
      "Training: Epoch 109, Batch 14, Loss: 0.234\n",
      "Training: Epoch 109, Batch 15, Loss: 0.231\n",
      "Training: Epoch 109, Batch 16, Loss: 0.318\n",
      "Training: Epoch 109, Batch 17, Loss: 0.276\n",
      "Training: Epoch 109, Batch 18, Loss: 0.444\n",
      "Training: Epoch 109, Batch 19, Loss: 0.326\n",
      "Training: Epoch 109, Batch 20, Loss: 0.592\n",
      "Training: Epoch 109, Batch 21, Loss: 0.45\n",
      "Training: Epoch 109, Batch 22, Loss: 0.46\n",
      "Training: Epoch 109, Batch 23, Loss: 0.483\n",
      "Training: Epoch 109, Batch 24, Loss: 0.606\n",
      "Training: Epoch 109, Batch 25, Loss: 0.462\n",
      "Training: Epoch 109, Batch 26, Loss: 0.377\n",
      "Training: Epoch 109, Batch 27, Loss: 0.481\n",
      "Training: Epoch 109, Batch 28, Loss: 0.268\n",
      "Training: Epoch 109, Batch 29, Loss: 0.566\n",
      "Val: Epoch 109, Loss: 0.31\n",
      "Training: Epoch 110, Batch 0, Loss: 0.442\n",
      "Training: Epoch 110, Batch 1, Loss: 0.519\n",
      "Training: Epoch 110, Batch 2, Loss: 0.244\n",
      "Training: Epoch 110, Batch 3, Loss: 0.524\n",
      "Training: Epoch 110, Batch 4, Loss: 0.441\n",
      "Training: Epoch 110, Batch 5, Loss: 0.317\n",
      "Training: Epoch 110, Batch 6, Loss: 0.41\n",
      "Training: Epoch 110, Batch 7, Loss: 0.242\n",
      "Training: Epoch 110, Batch 8, Loss: 0.552\n",
      "Training: Epoch 110, Batch 9, Loss: 0.423\n",
      "Training: Epoch 110, Batch 10, Loss: 0.52\n",
      "Training: Epoch 110, Batch 11, Loss: 0.384\n",
      "Training: Epoch 110, Batch 12, Loss: 0.889\n",
      "Training: Epoch 110, Batch 13, Loss: 0.383\n",
      "Training: Epoch 110, Batch 14, Loss: 0.37\n",
      "Training: Epoch 110, Batch 15, Loss: 0.445\n",
      "Training: Epoch 110, Batch 16, Loss: 0.356\n",
      "Training: Epoch 110, Batch 17, Loss: 0.328\n",
      "Training: Epoch 110, Batch 18, Loss: 0.349\n",
      "Training: Epoch 110, Batch 19, Loss: 0.465\n",
      "Training: Epoch 110, Batch 20, Loss: 0.552\n",
      "Training: Epoch 110, Batch 21, Loss: 0.745\n",
      "Training: Epoch 110, Batch 22, Loss: 0.505\n",
      "Training: Epoch 110, Batch 23, Loss: 0.279\n",
      "Training: Epoch 110, Batch 24, Loss: 0.404\n",
      "Training: Epoch 110, Batch 25, Loss: 0.293\n",
      "Training: Epoch 110, Batch 26, Loss: 0.211\n",
      "Training: Epoch 110, Batch 27, Loss: 0.476\n",
      "Training: Epoch 110, Batch 28, Loss: 0.383\n",
      "Training: Epoch 110, Batch 29, Loss: 0.683\n",
      "Val: Epoch 110, Loss: 0.338\n",
      "Training: Epoch 111, Batch 0, Loss: 0.473\n",
      "Training: Epoch 111, Batch 1, Loss: 0.583\n",
      "Training: Epoch 111, Batch 2, Loss: 0.631\n",
      "Training: Epoch 111, Batch 3, Loss: 0.515\n",
      "Training: Epoch 111, Batch 4, Loss: 0.301\n",
      "Training: Epoch 111, Batch 5, Loss: 0.339\n",
      "Training: Epoch 111, Batch 6, Loss: 0.34\n",
      "Training: Epoch 111, Batch 7, Loss: 0.219\n",
      "Training: Epoch 111, Batch 8, Loss: 0.354\n",
      "Training: Epoch 111, Batch 9, Loss: 0.606\n",
      "Training: Epoch 111, Batch 10, Loss: 0.465\n",
      "Training: Epoch 111, Batch 11, Loss: 0.348\n",
      "Training: Epoch 111, Batch 12, Loss: 0.359\n",
      "Training: Epoch 111, Batch 13, Loss: 0.548\n",
      "Training: Epoch 111, Batch 14, Loss: 0.616\n",
      "Training: Epoch 111, Batch 15, Loss: 0.397\n",
      "Training: Epoch 111, Batch 16, Loss: 0.412\n",
      "Training: Epoch 111, Batch 17, Loss: 0.442\n",
      "Training: Epoch 111, Batch 18, Loss: 0.372\n",
      "Training: Epoch 111, Batch 19, Loss: 0.439\n",
      "Training: Epoch 111, Batch 20, Loss: 0.523\n",
      "Training: Epoch 111, Batch 21, Loss: 0.646\n",
      "Training: Epoch 111, Batch 22, Loss: 0.392\n",
      "Training: Epoch 111, Batch 23, Loss: 0.407\n",
      "Training: Epoch 111, Batch 24, Loss: 0.344\n",
      "Training: Epoch 111, Batch 25, Loss: 0.287\n",
      "Training: Epoch 111, Batch 26, Loss: 0.474\n",
      "Training: Epoch 111, Batch 27, Loss: 0.313\n",
      "Training: Epoch 111, Batch 28, Loss: 0.38\n",
      "Training: Epoch 111, Batch 29, Loss: 0.543\n",
      "Val: Epoch 111, Loss: 0.273\n",
      "Training: Epoch 112, Batch 0, Loss: 0.268\n",
      "Training: Epoch 112, Batch 1, Loss: 0.406\n",
      "Training: Epoch 112, Batch 2, Loss: 0.373\n",
      "Training: Epoch 112, Batch 3, Loss: 0.426\n",
      "Training: Epoch 112, Batch 4, Loss: 0.257\n",
      "Training: Epoch 112, Batch 5, Loss: 0.487\n",
      "Training: Epoch 112, Batch 6, Loss: 0.701\n",
      "Training: Epoch 112, Batch 7, Loss: 0.681\n",
      "Training: Epoch 112, Batch 8, Loss: 0.388\n",
      "Training: Epoch 112, Batch 9, Loss: 0.664\n",
      "Training: Epoch 112, Batch 10, Loss: 0.426\n",
      "Training: Epoch 112, Batch 11, Loss: 0.437\n",
      "Training: Epoch 112, Batch 12, Loss: 0.4\n",
      "Training: Epoch 112, Batch 13, Loss: 0.479\n",
      "Training: Epoch 112, Batch 14, Loss: 0.439\n",
      "Training: Epoch 112, Batch 15, Loss: 0.328\n",
      "Training: Epoch 112, Batch 16, Loss: 0.382\n",
      "Training: Epoch 112, Batch 17, Loss: 0.516\n",
      "Training: Epoch 112, Batch 18, Loss: 0.439\n",
      "Training: Epoch 112, Batch 19, Loss: 0.554\n",
      "Training: Epoch 112, Batch 20, Loss: 0.552\n",
      "Training: Epoch 112, Batch 21, Loss: 0.476\n",
      "Training: Epoch 112, Batch 22, Loss: 0.431\n",
      "Training: Epoch 112, Batch 23, Loss: 0.361\n",
      "Training: Epoch 112, Batch 24, Loss: 0.468\n",
      "Training: Epoch 112, Batch 25, Loss: 0.437\n",
      "Training: Epoch 112, Batch 26, Loss: 0.474\n",
      "Training: Epoch 112, Batch 27, Loss: 0.282\n",
      "Training: Epoch 112, Batch 28, Loss: 0.356\n",
      "Training: Epoch 112, Batch 29, Loss: 0.286\n",
      "Val: Epoch 112, Loss: 0.245\n",
      "Training: Epoch 113, Batch 0, Loss: 0.568\n",
      "Training: Epoch 113, Batch 1, Loss: 0.438\n",
      "Training: Epoch 113, Batch 2, Loss: 0.398\n",
      "Training: Epoch 113, Batch 3, Loss: 0.521\n",
      "Training: Epoch 113, Batch 4, Loss: 0.395\n",
      "Training: Epoch 113, Batch 5, Loss: 0.496\n",
      "Training: Epoch 113, Batch 6, Loss: 0.56\n",
      "Training: Epoch 113, Batch 7, Loss: 0.477\n",
      "Training: Epoch 113, Batch 8, Loss: 0.445\n",
      "Training: Epoch 113, Batch 9, Loss: 0.361\n",
      "Training: Epoch 113, Batch 10, Loss: 0.567\n",
      "Training: Epoch 113, Batch 11, Loss: 0.282\n",
      "Training: Epoch 113, Batch 12, Loss: 0.352\n",
      "Training: Epoch 113, Batch 13, Loss: 0.377\n",
      "Training: Epoch 113, Batch 14, Loss: 0.211\n",
      "Training: Epoch 113, Batch 15, Loss: 0.45\n",
      "Training: Epoch 113, Batch 16, Loss: 0.335\n",
      "Training: Epoch 113, Batch 17, Loss: 0.535\n",
      "Training: Epoch 113, Batch 18, Loss: 0.264\n",
      "Training: Epoch 113, Batch 19, Loss: 0.228\n",
      "Training: Epoch 113, Batch 20, Loss: 0.463\n",
      "Training: Epoch 113, Batch 21, Loss: 0.457\n",
      "Training: Epoch 113, Batch 22, Loss: 0.452\n",
      "Training: Epoch 113, Batch 23, Loss: 0.397\n",
      "Training: Epoch 113, Batch 24, Loss: 0.169\n",
      "Training: Epoch 113, Batch 25, Loss: 0.444\n",
      "Training: Epoch 113, Batch 26, Loss: 0.543\n",
      "Training: Epoch 113, Batch 27, Loss: 0.493\n",
      "Training: Epoch 113, Batch 28, Loss: 0.575\n",
      "Training: Epoch 113, Batch 29, Loss: 0.294\n",
      "Val: Epoch 113, Loss: 0.266\n",
      "Training: Epoch 114, Batch 0, Loss: 0.221\n",
      "Training: Epoch 114, Batch 1, Loss: 0.269\n",
      "Training: Epoch 114, Batch 2, Loss: 0.356\n",
      "Training: Epoch 114, Batch 3, Loss: 0.31\n",
      "Training: Epoch 114, Batch 4, Loss: 0.36\n",
      "Training: Epoch 114, Batch 5, Loss: 0.271\n",
      "Training: Epoch 114, Batch 6, Loss: 0.973\n",
      "Training: Epoch 114, Batch 7, Loss: 0.46\n",
      "Training: Epoch 114, Batch 8, Loss: 0.363\n",
      "Training: Epoch 114, Batch 9, Loss: 0.602\n",
      "Training: Epoch 114, Batch 10, Loss: 0.372\n",
      "Training: Epoch 114, Batch 11, Loss: 0.527\n",
      "Training: Epoch 114, Batch 12, Loss: 0.383\n",
      "Training: Epoch 114, Batch 13, Loss: 0.385\n",
      "Training: Epoch 114, Batch 14, Loss: 0.418\n",
      "Training: Epoch 114, Batch 15, Loss: 0.537\n",
      "Training: Epoch 114, Batch 16, Loss: 0.406\n",
      "Training: Epoch 114, Batch 17, Loss: 0.403\n",
      "Training: Epoch 114, Batch 18, Loss: 0.506\n",
      "Training: Epoch 114, Batch 19, Loss: 0.47\n",
      "Training: Epoch 114, Batch 20, Loss: 0.402\n",
      "Training: Epoch 114, Batch 21, Loss: 0.311\n",
      "Training: Epoch 114, Batch 22, Loss: 0.507\n",
      "Training: Epoch 114, Batch 23, Loss: 0.478\n",
      "Training: Epoch 114, Batch 24, Loss: 0.481\n",
      "Training: Epoch 114, Batch 25, Loss: 0.678\n",
      "Training: Epoch 114, Batch 26, Loss: 0.281\n",
      "Training: Epoch 114, Batch 27, Loss: 0.366\n",
      "Training: Epoch 114, Batch 28, Loss: 0.422\n",
      "Training: Epoch 114, Batch 29, Loss: 0.349\n",
      "Val: Epoch 114, Loss: 0.283\n",
      "Training: Epoch 115, Batch 0, Loss: 0.547\n",
      "Training: Epoch 115, Batch 1, Loss: 0.727\n",
      "Training: Epoch 115, Batch 2, Loss: 0.345\n",
      "Training: Epoch 115, Batch 3, Loss: 0.279\n",
      "Training: Epoch 115, Batch 4, Loss: 0.386\n",
      "Training: Epoch 115, Batch 5, Loss: 0.279\n",
      "Training: Epoch 115, Batch 6, Loss: 0.31\n",
      "Training: Epoch 115, Batch 7, Loss: 0.328\n",
      "Training: Epoch 115, Batch 8, Loss: 0.466\n",
      "Training: Epoch 115, Batch 9, Loss: 0.684\n",
      "Training: Epoch 115, Batch 10, Loss: 0.523\n",
      "Training: Epoch 115, Batch 11, Loss: 0.299\n",
      "Training: Epoch 115, Batch 12, Loss: 0.477\n",
      "Training: Epoch 115, Batch 13, Loss: 0.382\n",
      "Training: Epoch 115, Batch 14, Loss: 0.219\n",
      "Training: Epoch 115, Batch 15, Loss: 0.298\n",
      "Training: Epoch 115, Batch 16, Loss: 0.332\n",
      "Training: Epoch 115, Batch 17, Loss: 0.335\n",
      "Training: Epoch 115, Batch 18, Loss: 0.618\n",
      "Training: Epoch 115, Batch 19, Loss: 0.424\n",
      "Training: Epoch 115, Batch 20, Loss: 0.459\n",
      "Training: Epoch 115, Batch 21, Loss: 0.466\n",
      "Training: Epoch 115, Batch 22, Loss: 0.526\n",
      "Training: Epoch 115, Batch 23, Loss: 0.361\n",
      "Training: Epoch 115, Batch 24, Loss: 0.397\n",
      "Training: Epoch 115, Batch 25, Loss: 0.444\n",
      "Training: Epoch 115, Batch 26, Loss: 0.274\n",
      "Training: Epoch 115, Batch 27, Loss: 0.511\n",
      "Training: Epoch 115, Batch 28, Loss: 0.443\n",
      "Training: Epoch 115, Batch 29, Loss: 0.304\n",
      "Val: Epoch 115, Loss: 0.286\n",
      "Training: Epoch 116, Batch 0, Loss: 0.351\n",
      "Training: Epoch 116, Batch 1, Loss: 0.317\n",
      "Training: Epoch 116, Batch 2, Loss: 0.469\n",
      "Training: Epoch 116, Batch 3, Loss: 0.279\n",
      "Training: Epoch 116, Batch 4, Loss: 0.754\n",
      "Training: Epoch 116, Batch 5, Loss: 0.46\n",
      "Training: Epoch 116, Batch 6, Loss: 0.281\n",
      "Training: Epoch 116, Batch 7, Loss: 0.491\n",
      "Training: Epoch 116, Batch 8, Loss: 0.231\n",
      "Training: Epoch 116, Batch 9, Loss: 0.354\n",
      "Training: Epoch 116, Batch 10, Loss: 0.531\n",
      "Training: Epoch 116, Batch 11, Loss: 0.417\n",
      "Training: Epoch 116, Batch 12, Loss: 0.449\n",
      "Training: Epoch 116, Batch 13, Loss: 0.341\n",
      "Training: Epoch 116, Batch 14, Loss: 0.702\n",
      "Training: Epoch 116, Batch 15, Loss: 0.443\n",
      "Training: Epoch 116, Batch 16, Loss: 0.337\n",
      "Training: Epoch 116, Batch 17, Loss: 0.407\n",
      "Training: Epoch 116, Batch 18, Loss: 0.46\n",
      "Training: Epoch 116, Batch 19, Loss: 0.373\n",
      "Training: Epoch 116, Batch 20, Loss: 0.321\n",
      "Training: Epoch 116, Batch 21, Loss: 0.399\n",
      "Training: Epoch 116, Batch 22, Loss: 0.49\n",
      "Training: Epoch 116, Batch 23, Loss: 0.5\n",
      "Training: Epoch 116, Batch 24, Loss: 0.414\n",
      "Training: Epoch 116, Batch 25, Loss: 0.379\n",
      "Training: Epoch 116, Batch 26, Loss: 0.345\n",
      "Training: Epoch 116, Batch 27, Loss: 0.526\n",
      "Training: Epoch 116, Batch 28, Loss: 0.481\n",
      "Training: Epoch 116, Batch 29, Loss: 0.251\n",
      "Val: Epoch 116, Loss: 0.283\n",
      "Training: Epoch 117, Batch 0, Loss: 0.472\n",
      "Training: Epoch 117, Batch 1, Loss: 0.258\n",
      "Training: Epoch 117, Batch 2, Loss: 0.366\n",
      "Training: Epoch 117, Batch 3, Loss: 0.576\n",
      "Training: Epoch 117, Batch 4, Loss: 0.398\n",
      "Training: Epoch 117, Batch 5, Loss: 0.313\n",
      "Training: Epoch 117, Batch 6, Loss: 0.163\n",
      "Training: Epoch 117, Batch 7, Loss: 0.439\n",
      "Training: Epoch 117, Batch 8, Loss: 0.534\n",
      "Training: Epoch 117, Batch 9, Loss: 0.428\n",
      "Training: Epoch 117, Batch 10, Loss: 0.552\n",
      "Training: Epoch 117, Batch 11, Loss: 0.503\n",
      "Training: Epoch 117, Batch 12, Loss: 0.494\n",
      "Training: Epoch 117, Batch 13, Loss: 0.575\n",
      "Training: Epoch 117, Batch 14, Loss: 0.539\n",
      "Training: Epoch 117, Batch 15, Loss: 0.222\n",
      "Training: Epoch 117, Batch 16, Loss: 0.373\n",
      "Training: Epoch 117, Batch 17, Loss: 0.405\n",
      "Training: Epoch 117, Batch 18, Loss: 0.4\n",
      "Training: Epoch 117, Batch 19, Loss: 0.305\n",
      "Training: Epoch 117, Batch 20, Loss: 0.429\n",
      "Training: Epoch 117, Batch 21, Loss: 0.378\n",
      "Training: Epoch 117, Batch 22, Loss: 0.635\n",
      "Training: Epoch 117, Batch 23, Loss: 0.336\n",
      "Training: Epoch 117, Batch 24, Loss: 0.365\n",
      "Training: Epoch 117, Batch 25, Loss: 0.742\n",
      "Training: Epoch 117, Batch 26, Loss: 0.483\n",
      "Training: Epoch 117, Batch 27, Loss: 0.263\n",
      "Training: Epoch 117, Batch 28, Loss: 0.352\n",
      "Training: Epoch 117, Batch 29, Loss: 0.311\n",
      "Val: Epoch 117, Loss: 0.273\n",
      "Training: Epoch 118, Batch 0, Loss: 0.287\n",
      "Training: Epoch 118, Batch 1, Loss: 0.554\n",
      "Training: Epoch 118, Batch 2, Loss: 0.529\n",
      "Training: Epoch 118, Batch 3, Loss: 0.406\n",
      "Training: Epoch 118, Batch 4, Loss: 0.575\n",
      "Training: Epoch 118, Batch 5, Loss: 0.352\n",
      "Training: Epoch 118, Batch 6, Loss: 0.452\n",
      "Training: Epoch 118, Batch 7, Loss: 0.319\n",
      "Training: Epoch 118, Batch 8, Loss: 0.328\n",
      "Training: Epoch 118, Batch 9, Loss: 0.472\n",
      "Training: Epoch 118, Batch 10, Loss: 0.376\n",
      "Training: Epoch 118, Batch 11, Loss: 0.518\n",
      "Training: Epoch 118, Batch 12, Loss: 0.25\n",
      "Training: Epoch 118, Batch 13, Loss: 0.412\n",
      "Training: Epoch 118, Batch 14, Loss: 0.591\n",
      "Training: Epoch 118, Batch 15, Loss: 0.411\n",
      "Training: Epoch 118, Batch 16, Loss: 0.386\n",
      "Training: Epoch 118, Batch 17, Loss: 0.597\n",
      "Training: Epoch 118, Batch 18, Loss: 0.319\n",
      "Training: Epoch 118, Batch 19, Loss: 0.531\n",
      "Training: Epoch 118, Batch 20, Loss: 0.443\n",
      "Training: Epoch 118, Batch 21, Loss: 0.289\n",
      "Training: Epoch 118, Batch 22, Loss: 0.568\n",
      "Training: Epoch 118, Batch 23, Loss: 0.395\n",
      "Training: Epoch 118, Batch 24, Loss: 0.266\n",
      "Training: Epoch 118, Batch 25, Loss: 0.468\n",
      "Training: Epoch 118, Batch 26, Loss: 0.676\n",
      "Training: Epoch 118, Batch 27, Loss: 0.314\n",
      "Training: Epoch 118, Batch 28, Loss: 0.346\n",
      "Training: Epoch 118, Batch 29, Loss: 0.488\n",
      "Val: Epoch 118, Loss: 0.307\n",
      "Training: Epoch 119, Batch 0, Loss: 0.442\n",
      "Training: Epoch 119, Batch 1, Loss: 0.451\n",
      "Training: Epoch 119, Batch 2, Loss: 0.638\n",
      "Training: Epoch 119, Batch 3, Loss: 0.489\n",
      "Training: Epoch 119, Batch 4, Loss: 0.249\n",
      "Training: Epoch 119, Batch 5, Loss: 0.282\n",
      "Training: Epoch 119, Batch 6, Loss: 0.641\n",
      "Training: Epoch 119, Batch 7, Loss: 0.469\n",
      "Training: Epoch 119, Batch 8, Loss: 0.325\n",
      "Training: Epoch 119, Batch 9, Loss: 0.441\n",
      "Training: Epoch 119, Batch 10, Loss: 0.362\n",
      "Training: Epoch 119, Batch 11, Loss: 0.375\n",
      "Training: Epoch 119, Batch 12, Loss: 0.227\n",
      "Training: Epoch 119, Batch 13, Loss: 0.445\n",
      "Training: Epoch 119, Batch 14, Loss: 0.527\n",
      "Training: Epoch 119, Batch 15, Loss: 0.562\n",
      "Training: Epoch 119, Batch 16, Loss: 0.313\n",
      "Training: Epoch 119, Batch 17, Loss: 0.544\n",
      "Training: Epoch 119, Batch 18, Loss: 0.289\n",
      "Training: Epoch 119, Batch 19, Loss: 0.361\n",
      "Training: Epoch 119, Batch 20, Loss: 0.252\n",
      "Training: Epoch 119, Batch 21, Loss: 0.323\n",
      "Training: Epoch 119, Batch 22, Loss: 0.407\n",
      "Training: Epoch 119, Batch 23, Loss: 0.473\n",
      "Training: Epoch 119, Batch 24, Loss: 0.397\n",
      "Training: Epoch 119, Batch 25, Loss: 0.208\n",
      "Training: Epoch 119, Batch 26, Loss: 0.602\n",
      "Training: Epoch 119, Batch 27, Loss: 0.539\n",
      "Training: Epoch 119, Batch 28, Loss: 0.47\n",
      "Training: Epoch 119, Batch 29, Loss: 0.319\n",
      "Val: Epoch 119, Loss: 0.272\n",
      "Training: Epoch 120, Batch 0, Loss: 0.353\n",
      "Training: Epoch 120, Batch 1, Loss: 0.34\n",
      "Training: Epoch 120, Batch 2, Loss: 0.433\n",
      "Training: Epoch 120, Batch 3, Loss: 0.222\n",
      "Training: Epoch 120, Batch 4, Loss: 0.531\n",
      "Training: Epoch 120, Batch 5, Loss: 0.29\n",
      "Training: Epoch 120, Batch 6, Loss: 0.506\n",
      "Training: Epoch 120, Batch 7, Loss: 0.393\n",
      "Training: Epoch 120, Batch 8, Loss: 0.361\n",
      "Training: Epoch 120, Batch 9, Loss: 0.458\n",
      "Training: Epoch 120, Batch 10, Loss: 0.526\n",
      "Training: Epoch 120, Batch 11, Loss: 0.436\n",
      "Training: Epoch 120, Batch 12, Loss: 0.501\n",
      "Training: Epoch 120, Batch 13, Loss: 0.181\n",
      "Training: Epoch 120, Batch 14, Loss: 0.336\n",
      "Training: Epoch 120, Batch 15, Loss: 0.644\n",
      "Training: Epoch 120, Batch 16, Loss: 0.407\n",
      "Training: Epoch 120, Batch 17, Loss: 0.406\n",
      "Training: Epoch 120, Batch 18, Loss: 0.433\n",
      "Training: Epoch 120, Batch 19, Loss: 0.24\n",
      "Training: Epoch 120, Batch 20, Loss: 0.241\n",
      "Training: Epoch 120, Batch 21, Loss: 0.478\n",
      "Training: Epoch 120, Batch 22, Loss: 0.45\n",
      "Training: Epoch 120, Batch 23, Loss: 0.454\n",
      "Training: Epoch 120, Batch 24, Loss: 0.453\n",
      "Training: Epoch 120, Batch 25, Loss: 0.403\n",
      "Training: Epoch 120, Batch 26, Loss: 0.334\n",
      "Training: Epoch 120, Batch 27, Loss: 0.484\n",
      "Training: Epoch 120, Batch 28, Loss: 0.561\n",
      "Training: Epoch 120, Batch 29, Loss: 0.267\n",
      "Val: Epoch 120, Loss: 0.263\n",
      "Training: Epoch 121, Batch 0, Loss: 0.584\n",
      "Training: Epoch 121, Batch 1, Loss: 0.234\n",
      "Training: Epoch 121, Batch 2, Loss: 0.349\n",
      "Training: Epoch 121, Batch 3, Loss: 0.583\n",
      "Training: Epoch 121, Batch 4, Loss: 0.418\n",
      "Training: Epoch 121, Batch 5, Loss: 0.177\n",
      "Training: Epoch 121, Batch 6, Loss: 0.449\n",
      "Training: Epoch 121, Batch 7, Loss: 0.364\n",
      "Training: Epoch 121, Batch 8, Loss: 0.542\n",
      "Training: Epoch 121, Batch 9, Loss: 0.511\n",
      "Training: Epoch 121, Batch 10, Loss: 0.294\n",
      "Training: Epoch 121, Batch 11, Loss: 0.326\n",
      "Training: Epoch 121, Batch 12, Loss: 0.638\n",
      "Training: Epoch 121, Batch 13, Loss: 0.648\n",
      "Training: Epoch 121, Batch 14, Loss: 0.268\n",
      "Training: Epoch 121, Batch 15, Loss: 0.269\n",
      "Training: Epoch 121, Batch 16, Loss: 0.68\n",
      "Training: Epoch 121, Batch 17, Loss: 0.229\n",
      "Training: Epoch 121, Batch 18, Loss: 0.306\n",
      "Training: Epoch 121, Batch 19, Loss: 0.45\n",
      "Training: Epoch 121, Batch 20, Loss: 0.546\n",
      "Training: Epoch 121, Batch 21, Loss: 0.316\n",
      "Training: Epoch 121, Batch 22, Loss: 0.27\n",
      "Training: Epoch 121, Batch 23, Loss: 0.673\n",
      "Training: Epoch 121, Batch 24, Loss: 0.446\n",
      "Training: Epoch 121, Batch 25, Loss: 0.335\n",
      "Training: Epoch 121, Batch 26, Loss: 0.405\n",
      "Training: Epoch 121, Batch 27, Loss: 0.448\n",
      "Training: Epoch 121, Batch 28, Loss: 0.257\n",
      "Training: Epoch 121, Batch 29, Loss: 0.287\n",
      "Val: Epoch 121, Loss: 0.277\n",
      "Training: Epoch 122, Batch 0, Loss: 0.488\n",
      "Training: Epoch 122, Batch 1, Loss: 0.588\n",
      "Training: Epoch 122, Batch 2, Loss: 0.326\n",
      "Training: Epoch 122, Batch 3, Loss: 0.131\n",
      "Training: Epoch 122, Batch 4, Loss: 0.495\n",
      "Training: Epoch 122, Batch 5, Loss: 0.337\n",
      "Training: Epoch 122, Batch 6, Loss: 0.196\n",
      "Training: Epoch 122, Batch 7, Loss: 0.457\n",
      "Training: Epoch 122, Batch 8, Loss: 0.423\n",
      "Training: Epoch 122, Batch 9, Loss: 0.308\n",
      "Training: Epoch 122, Batch 10, Loss: 0.428\n",
      "Training: Epoch 122, Batch 11, Loss: 0.466\n",
      "Training: Epoch 122, Batch 12, Loss: 0.508\n",
      "Training: Epoch 122, Batch 13, Loss: 0.376\n",
      "Training: Epoch 122, Batch 14, Loss: 0.49\n",
      "Training: Epoch 122, Batch 15, Loss: 0.633\n",
      "Training: Epoch 122, Batch 16, Loss: 0.225\n",
      "Training: Epoch 122, Batch 17, Loss: 0.437\n",
      "Training: Epoch 122, Batch 18, Loss: 0.573\n",
      "Training: Epoch 122, Batch 19, Loss: 0.508\n",
      "Training: Epoch 122, Batch 20, Loss: 0.406\n",
      "Training: Epoch 122, Batch 21, Loss: 0.124\n",
      "Training: Epoch 122, Batch 22, Loss: 0.447\n",
      "Training: Epoch 122, Batch 23, Loss: 0.433\n",
      "Training: Epoch 122, Batch 24, Loss: 0.26\n",
      "Training: Epoch 122, Batch 25, Loss: 0.29\n",
      "Training: Epoch 122, Batch 26, Loss: 0.351\n",
      "Training: Epoch 122, Batch 27, Loss: 0.376\n",
      "Training: Epoch 122, Batch 28, Loss: 0.385\n",
      "Training: Epoch 122, Batch 29, Loss: 0.551\n",
      "Val: Epoch 122, Loss: 0.288\n",
      "Training: Epoch 123, Batch 0, Loss: 0.265\n",
      "Training: Epoch 123, Batch 1, Loss: 0.348\n",
      "Training: Epoch 123, Batch 2, Loss: 0.276\n",
      "Training: Epoch 123, Batch 3, Loss: 0.484\n",
      "Training: Epoch 123, Batch 4, Loss: 0.386\n",
      "Training: Epoch 123, Batch 5, Loss: 0.171\n",
      "Training: Epoch 123, Batch 6, Loss: 0.162\n",
      "Training: Epoch 123, Batch 7, Loss: 0.566\n",
      "Training: Epoch 123, Batch 8, Loss: 0.273\n",
      "Training: Epoch 123, Batch 9, Loss: 0.201\n",
      "Training: Epoch 123, Batch 10, Loss: 0.382\n",
      "Training: Epoch 123, Batch 11, Loss: 0.271\n",
      "Training: Epoch 123, Batch 12, Loss: 0.458\n",
      "Training: Epoch 123, Batch 13, Loss: 0.303\n",
      "Training: Epoch 123, Batch 14, Loss: 0.387\n",
      "Training: Epoch 123, Batch 15, Loss: 0.495\n",
      "Training: Epoch 123, Batch 16, Loss: 0.806\n",
      "Training: Epoch 123, Batch 17, Loss: 0.399\n",
      "Training: Epoch 123, Batch 18, Loss: 0.461\n",
      "Training: Epoch 123, Batch 19, Loss: 0.555\n",
      "Training: Epoch 123, Batch 20, Loss: 0.517\n",
      "Training: Epoch 123, Batch 21, Loss: 0.601\n",
      "Training: Epoch 123, Batch 22, Loss: 0.516\n",
      "Training: Epoch 123, Batch 23, Loss: 0.464\n",
      "Training: Epoch 123, Batch 24, Loss: 0.421\n",
      "Training: Epoch 123, Batch 25, Loss: 0.477\n",
      "Training: Epoch 123, Batch 26, Loss: 0.258\n",
      "Training: Epoch 123, Batch 27, Loss: 0.327\n",
      "Training: Epoch 123, Batch 28, Loss: 0.749\n",
      "Training: Epoch 123, Batch 29, Loss: 0.485\n",
      "Val: Epoch 123, Loss: 0.288\n",
      "Training: Epoch 124, Batch 0, Loss: 0.48\n",
      "Training: Epoch 124, Batch 1, Loss: 0.342\n",
      "Training: Epoch 124, Batch 2, Loss: 0.307\n",
      "Training: Epoch 124, Batch 3, Loss: 0.466\n",
      "Training: Epoch 124, Batch 4, Loss: 0.367\n",
      "Training: Epoch 124, Batch 5, Loss: 0.467\n",
      "Training: Epoch 124, Batch 6, Loss: 0.471\n",
      "Training: Epoch 124, Batch 7, Loss: 0.296\n",
      "Training: Epoch 124, Batch 8, Loss: 0.314\n",
      "Training: Epoch 124, Batch 9, Loss: 0.506\n",
      "Training: Epoch 124, Batch 10, Loss: 0.549\n",
      "Training: Epoch 124, Batch 11, Loss: 0.594\n",
      "Training: Epoch 124, Batch 12, Loss: 0.42\n",
      "Training: Epoch 124, Batch 13, Loss: 0.356\n",
      "Training: Epoch 124, Batch 14, Loss: 0.572\n",
      "Training: Epoch 124, Batch 15, Loss: 0.423\n",
      "Training: Epoch 124, Batch 16, Loss: 0.295\n",
      "Training: Epoch 124, Batch 17, Loss: 0.309\n",
      "Training: Epoch 124, Batch 18, Loss: 0.305\n",
      "Training: Epoch 124, Batch 19, Loss: 0.439\n",
      "Training: Epoch 124, Batch 20, Loss: 0.376\n",
      "Training: Epoch 124, Batch 21, Loss: 0.267\n",
      "Training: Epoch 124, Batch 22, Loss: 0.395\n",
      "Training: Epoch 124, Batch 23, Loss: 0.318\n",
      "Training: Epoch 124, Batch 24, Loss: 0.636\n",
      "Training: Epoch 124, Batch 25, Loss: 0.278\n",
      "Training: Epoch 124, Batch 26, Loss: 0.309\n",
      "Training: Epoch 124, Batch 27, Loss: 0.729\n",
      "Training: Epoch 124, Batch 28, Loss: 0.348\n",
      "Training: Epoch 124, Batch 29, Loss: 0.608\n",
      "Val: Epoch 124, Loss: 0.298\n",
      "Training: Epoch 125, Batch 0, Loss: 0.287\n",
      "Training: Epoch 125, Batch 1, Loss: 0.441\n",
      "Training: Epoch 125, Batch 2, Loss: 0.33\n",
      "Training: Epoch 125, Batch 3, Loss: 0.378\n",
      "Training: Epoch 125, Batch 4, Loss: 0.476\n",
      "Training: Epoch 125, Batch 5, Loss: 0.477\n",
      "Training: Epoch 125, Batch 6, Loss: 0.46\n",
      "Training: Epoch 125, Batch 7, Loss: 0.585\n",
      "Training: Epoch 125, Batch 8, Loss: 0.33\n",
      "Training: Epoch 125, Batch 9, Loss: 0.492\n",
      "Training: Epoch 125, Batch 10, Loss: 0.586\n",
      "Training: Epoch 125, Batch 11, Loss: 0.392\n",
      "Training: Epoch 125, Batch 12, Loss: 0.507\n",
      "Training: Epoch 125, Batch 13, Loss: 0.344\n",
      "Training: Epoch 125, Batch 14, Loss: 0.348\n",
      "Training: Epoch 125, Batch 15, Loss: 0.378\n",
      "Training: Epoch 125, Batch 16, Loss: 0.425\n",
      "Training: Epoch 125, Batch 17, Loss: 0.376\n",
      "Training: Epoch 125, Batch 18, Loss: 0.364\n",
      "Training: Epoch 125, Batch 19, Loss: 0.442\n",
      "Training: Epoch 125, Batch 20, Loss: 0.572\n",
      "Training: Epoch 125, Batch 21, Loss: 0.431\n",
      "Training: Epoch 125, Batch 22, Loss: 0.343\n",
      "Training: Epoch 125, Batch 23, Loss: 0.438\n",
      "Training: Epoch 125, Batch 24, Loss: 0.432\n",
      "Training: Epoch 125, Batch 25, Loss: 0.168\n",
      "Training: Epoch 125, Batch 26, Loss: 0.407\n",
      "Training: Epoch 125, Batch 27, Loss: 0.288\n",
      "Training: Epoch 125, Batch 28, Loss: 0.455\n",
      "Training: Epoch 125, Batch 29, Loss: 0.218\n",
      "Val: Epoch 125, Loss: 0.353\n",
      "Training: Epoch 126, Batch 0, Loss: 0.298\n",
      "Training: Epoch 126, Batch 1, Loss: 0.456\n",
      "Training: Epoch 126, Batch 2, Loss: 0.327\n",
      "Training: Epoch 126, Batch 3, Loss: 0.404\n",
      "Training: Epoch 126, Batch 4, Loss: 0.511\n",
      "Training: Epoch 126, Batch 5, Loss: 0.436\n",
      "Training: Epoch 126, Batch 6, Loss: 0.597\n",
      "Training: Epoch 126, Batch 7, Loss: 0.449\n",
      "Training: Epoch 126, Batch 8, Loss: 0.341\n",
      "Training: Epoch 126, Batch 9, Loss: 0.267\n",
      "Training: Epoch 126, Batch 10, Loss: 0.363\n",
      "Training: Epoch 126, Batch 11, Loss: 0.343\n",
      "Training: Epoch 126, Batch 12, Loss: 0.585\n",
      "Training: Epoch 126, Batch 13, Loss: 0.249\n",
      "Training: Epoch 126, Batch 14, Loss: 0.403\n",
      "Training: Epoch 126, Batch 15, Loss: 0.488\n",
      "Training: Epoch 126, Batch 16, Loss: 0.399\n",
      "Training: Epoch 126, Batch 17, Loss: 0.49\n",
      "Training: Epoch 126, Batch 18, Loss: 0.326\n",
      "Training: Epoch 126, Batch 19, Loss: 0.241\n",
      "Training: Epoch 126, Batch 20, Loss: 0.574\n",
      "Training: Epoch 126, Batch 21, Loss: 0.196\n",
      "Training: Epoch 126, Batch 22, Loss: 0.393\n",
      "Training: Epoch 126, Batch 23, Loss: 0.519\n",
      "Training: Epoch 126, Batch 24, Loss: 0.339\n",
      "Training: Epoch 126, Batch 25, Loss: 0.417\n",
      "Training: Epoch 126, Batch 26, Loss: 0.41\n",
      "Training: Epoch 126, Batch 27, Loss: 0.356\n",
      "Training: Epoch 126, Batch 28, Loss: 0.511\n",
      "Training: Epoch 126, Batch 29, Loss: 0.361\n",
      "Val: Epoch 126, Loss: 0.292\n",
      "Training: Epoch 127, Batch 0, Loss: 0.527\n",
      "Training: Epoch 127, Batch 1, Loss: 0.395\n",
      "Training: Epoch 127, Batch 2, Loss: 0.379\n",
      "Training: Epoch 127, Batch 3, Loss: 0.282\n",
      "Training: Epoch 127, Batch 4, Loss: 0.314\n",
      "Training: Epoch 127, Batch 5, Loss: 0.337\n",
      "Training: Epoch 127, Batch 6, Loss: 0.443\n",
      "Training: Epoch 127, Batch 7, Loss: 0.366\n",
      "Training: Epoch 127, Batch 8, Loss: 0.251\n",
      "Training: Epoch 127, Batch 9, Loss: 0.638\n",
      "Training: Epoch 127, Batch 10, Loss: 0.408\n",
      "Training: Epoch 127, Batch 11, Loss: 0.304\n",
      "Training: Epoch 127, Batch 12, Loss: 0.6\n",
      "Training: Epoch 127, Batch 13, Loss: 0.158\n",
      "Training: Epoch 127, Batch 14, Loss: 0.379\n",
      "Training: Epoch 127, Batch 15, Loss: 0.403\n",
      "Training: Epoch 127, Batch 16, Loss: 0.488\n",
      "Training: Epoch 127, Batch 17, Loss: 0.316\n",
      "Training: Epoch 127, Batch 18, Loss: 0.367\n",
      "Training: Epoch 127, Batch 19, Loss: 0.222\n",
      "Training: Epoch 127, Batch 20, Loss: 0.362\n",
      "Training: Epoch 127, Batch 21, Loss: 0.356\n",
      "Training: Epoch 127, Batch 22, Loss: 0.382\n",
      "Training: Epoch 127, Batch 23, Loss: 0.431\n",
      "Training: Epoch 127, Batch 24, Loss: 0.419\n",
      "Training: Epoch 127, Batch 25, Loss: 0.395\n",
      "Training: Epoch 127, Batch 26, Loss: 0.48\n",
      "Training: Epoch 127, Batch 27, Loss: 0.384\n",
      "Training: Epoch 127, Batch 28, Loss: 0.555\n",
      "Training: Epoch 127, Batch 29, Loss: 0.633\n",
      "Val: Epoch 127, Loss: 0.306\n",
      "Training: Epoch 128, Batch 0, Loss: 0.373\n",
      "Training: Epoch 128, Batch 1, Loss: 0.232\n",
      "Training: Epoch 128, Batch 2, Loss: 0.512\n",
      "Training: Epoch 128, Batch 3, Loss: 0.367\n",
      "Training: Epoch 128, Batch 4, Loss: 0.291\n",
      "Training: Epoch 128, Batch 5, Loss: 0.231\n",
      "Training: Epoch 128, Batch 6, Loss: 0.461\n",
      "Training: Epoch 128, Batch 7, Loss: 0.317\n",
      "Training: Epoch 128, Batch 8, Loss: 0.438\n",
      "Training: Epoch 128, Batch 9, Loss: 0.539\n",
      "Training: Epoch 128, Batch 10, Loss: 0.305\n",
      "Training: Epoch 128, Batch 11, Loss: 0.418\n",
      "Training: Epoch 128, Batch 12, Loss: 0.186\n",
      "Training: Epoch 128, Batch 13, Loss: 0.318\n",
      "Training: Epoch 128, Batch 14, Loss: 0.621\n",
      "Training: Epoch 128, Batch 15, Loss: 0.465\n",
      "Training: Epoch 128, Batch 16, Loss: 0.466\n",
      "Training: Epoch 128, Batch 17, Loss: 0.377\n",
      "Training: Epoch 128, Batch 18, Loss: 0.406\n",
      "Training: Epoch 128, Batch 19, Loss: 0.69\n",
      "Training: Epoch 128, Batch 20, Loss: 0.342\n",
      "Training: Epoch 128, Batch 21, Loss: 0.393\n",
      "Training: Epoch 128, Batch 22, Loss: 0.617\n",
      "Training: Epoch 128, Batch 23, Loss: 0.284\n",
      "Training: Epoch 128, Batch 24, Loss: 0.374\n",
      "Training: Epoch 128, Batch 25, Loss: 0.412\n",
      "Training: Epoch 128, Batch 26, Loss: 0.458\n",
      "Training: Epoch 128, Batch 27, Loss: 0.425\n",
      "Training: Epoch 128, Batch 28, Loss: 0.358\n",
      "Training: Epoch 128, Batch 29, Loss: 0.471\n",
      "Val: Epoch 128, Loss: 0.273\n",
      "Training: Epoch 129, Batch 0, Loss: 0.329\n",
      "Training: Epoch 129, Batch 1, Loss: 0.4\n",
      "Training: Epoch 129, Batch 2, Loss: 0.292\n",
      "Training: Epoch 129, Batch 3, Loss: 0.418\n",
      "Training: Epoch 129, Batch 4, Loss: 0.368\n",
      "Training: Epoch 129, Batch 5, Loss: 0.326\n",
      "Training: Epoch 129, Batch 6, Loss: 0.515\n",
      "Training: Epoch 129, Batch 7, Loss: 0.304\n",
      "Training: Epoch 129, Batch 8, Loss: 0.461\n",
      "Training: Epoch 129, Batch 9, Loss: 0.557\n",
      "Training: Epoch 129, Batch 10, Loss: 0.508\n",
      "Training: Epoch 129, Batch 11, Loss: 0.218\n",
      "Training: Epoch 129, Batch 12, Loss: 0.406\n",
      "Training: Epoch 129, Batch 13, Loss: 0.47\n",
      "Training: Epoch 129, Batch 14, Loss: 0.5\n",
      "Training: Epoch 129, Batch 15, Loss: 0.206\n",
      "Training: Epoch 129, Batch 16, Loss: 0.467\n",
      "Training: Epoch 129, Batch 17, Loss: 0.51\n",
      "Training: Epoch 129, Batch 18, Loss: 0.574\n",
      "Training: Epoch 129, Batch 19, Loss: 0.233\n",
      "Training: Epoch 129, Batch 20, Loss: 0.279\n",
      "Training: Epoch 129, Batch 21, Loss: 0.379\n",
      "Training: Epoch 129, Batch 22, Loss: 0.508\n",
      "Training: Epoch 129, Batch 23, Loss: 0.379\n",
      "Training: Epoch 129, Batch 24, Loss: 0.51\n",
      "Training: Epoch 129, Batch 25, Loss: 0.224\n",
      "Training: Epoch 129, Batch 26, Loss: 0.361\n",
      "Training: Epoch 129, Batch 27, Loss: 0.25\n",
      "Training: Epoch 129, Batch 28, Loss: 0.56\n",
      "Training: Epoch 129, Batch 29, Loss: 0.471\n",
      "Val: Epoch 129, Loss: 0.253\n",
      "Training: Epoch 130, Batch 0, Loss: 0.342\n",
      "Training: Epoch 130, Batch 1, Loss: 0.386\n",
      "Training: Epoch 130, Batch 2, Loss: 0.402\n",
      "Training: Epoch 130, Batch 3, Loss: 0.433\n",
      "Training: Epoch 130, Batch 4, Loss: 0.268\n",
      "Training: Epoch 130, Batch 5, Loss: 0.345\n",
      "Training: Epoch 130, Batch 6, Loss: 0.283\n",
      "Training: Epoch 130, Batch 7, Loss: 0.496\n",
      "Training: Epoch 130, Batch 8, Loss: 0.351\n",
      "Training: Epoch 130, Batch 9, Loss: 0.345\n",
      "Training: Epoch 130, Batch 10, Loss: 0.136\n",
      "Training: Epoch 130, Batch 11, Loss: 0.307\n",
      "Training: Epoch 130, Batch 12, Loss: 0.468\n",
      "Training: Epoch 130, Batch 13, Loss: 0.206\n",
      "Training: Epoch 130, Batch 14, Loss: 0.49\n",
      "Training: Epoch 130, Batch 15, Loss: 0.52\n",
      "Training: Epoch 130, Batch 16, Loss: 0.513\n",
      "Training: Epoch 130, Batch 17, Loss: 0.426\n",
      "Training: Epoch 130, Batch 18, Loss: 0.312\n",
      "Training: Epoch 130, Batch 19, Loss: 0.507\n",
      "Training: Epoch 130, Batch 20, Loss: 0.384\n",
      "Training: Epoch 130, Batch 21, Loss: 0.283\n",
      "Training: Epoch 130, Batch 22, Loss: 0.597\n",
      "Training: Epoch 130, Batch 23, Loss: 0.436\n",
      "Training: Epoch 130, Batch 24, Loss: 0.326\n",
      "Training: Epoch 130, Batch 25, Loss: 0.353\n",
      "Training: Epoch 130, Batch 26, Loss: 0.369\n",
      "Training: Epoch 130, Batch 27, Loss: 0.504\n",
      "Training: Epoch 130, Batch 28, Loss: 0.463\n",
      "Training: Epoch 130, Batch 29, Loss: 0.565\n",
      "Val: Epoch 130, Loss: 0.257\n",
      "Training: Epoch 131, Batch 0, Loss: 0.457\n",
      "Training: Epoch 131, Batch 1, Loss: 0.428\n",
      "Training: Epoch 131, Batch 2, Loss: 0.533\n",
      "Training: Epoch 131, Batch 3, Loss: 0.449\n",
      "Training: Epoch 131, Batch 4, Loss: 0.617\n",
      "Training: Epoch 131, Batch 5, Loss: 0.372\n",
      "Training: Epoch 131, Batch 6, Loss: 0.252\n",
      "Training: Epoch 131, Batch 7, Loss: 0.234\n",
      "Training: Epoch 131, Batch 8, Loss: 0.367\n",
      "Training: Epoch 131, Batch 9, Loss: 0.436\n",
      "Training: Epoch 131, Batch 10, Loss: 0.433\n",
      "Training: Epoch 131, Batch 11, Loss: 0.312\n",
      "Training: Epoch 131, Batch 12, Loss: 0.329\n",
      "Training: Epoch 131, Batch 13, Loss: 0.215\n",
      "Training: Epoch 131, Batch 14, Loss: 0.249\n",
      "Training: Epoch 131, Batch 15, Loss: 0.271\n",
      "Training: Epoch 131, Batch 16, Loss: 0.51\n",
      "Training: Epoch 131, Batch 17, Loss: 0.371\n",
      "Training: Epoch 131, Batch 18, Loss: 0.363\n",
      "Training: Epoch 131, Batch 19, Loss: 0.175\n",
      "Training: Epoch 131, Batch 20, Loss: 0.347\n",
      "Training: Epoch 131, Batch 21, Loss: 0.481\n",
      "Training: Epoch 131, Batch 22, Loss: 0.399\n",
      "Training: Epoch 131, Batch 23, Loss: 0.412\n",
      "Training: Epoch 131, Batch 24, Loss: 0.601\n",
      "Training: Epoch 131, Batch 25, Loss: 0.3\n",
      "Training: Epoch 131, Batch 26, Loss: 0.497\n",
      "Training: Epoch 131, Batch 27, Loss: 0.544\n",
      "Training: Epoch 131, Batch 28, Loss: 0.213\n",
      "Training: Epoch 131, Batch 29, Loss: 0.529\n",
      "Val: Epoch 131, Loss: 0.288\n",
      "Training: Epoch 132, Batch 0, Loss: 0.542\n",
      "Training: Epoch 132, Batch 1, Loss: 0.612\n",
      "Training: Epoch 132, Batch 2, Loss: 0.467\n",
      "Training: Epoch 132, Batch 3, Loss: 0.428\n",
      "Training: Epoch 132, Batch 4, Loss: 0.545\n",
      "Training: Epoch 132, Batch 5, Loss: 0.298\n",
      "Training: Epoch 132, Batch 6, Loss: 0.175\n",
      "Training: Epoch 132, Batch 7, Loss: 0.487\n",
      "Training: Epoch 132, Batch 8, Loss: 0.265\n",
      "Training: Epoch 132, Batch 9, Loss: 0.244\n",
      "Training: Epoch 132, Batch 10, Loss: 0.467\n",
      "Training: Epoch 132, Batch 11, Loss: 0.302\n",
      "Training: Epoch 132, Batch 12, Loss: 0.516\n",
      "Training: Epoch 132, Batch 13, Loss: 0.304\n",
      "Training: Epoch 132, Batch 14, Loss: 0.29\n",
      "Training: Epoch 132, Batch 15, Loss: 0.427\n",
      "Training: Epoch 132, Batch 16, Loss: 0.316\n",
      "Training: Epoch 132, Batch 17, Loss: 0.317\n",
      "Training: Epoch 132, Batch 18, Loss: 0.484\n",
      "Training: Epoch 132, Batch 19, Loss: 0.237\n",
      "Training: Epoch 132, Batch 20, Loss: 0.661\n",
      "Training: Epoch 132, Batch 21, Loss: 0.409\n",
      "Training: Epoch 132, Batch 22, Loss: 0.336\n",
      "Training: Epoch 132, Batch 23, Loss: 0.225\n",
      "Training: Epoch 132, Batch 24, Loss: 0.296\n",
      "Training: Epoch 132, Batch 25, Loss: 0.471\n",
      "Training: Epoch 132, Batch 26, Loss: 0.266\n",
      "Training: Epoch 132, Batch 27, Loss: 0.456\n",
      "Training: Epoch 132, Batch 28, Loss: 0.341\n",
      "Training: Epoch 132, Batch 29, Loss: 0.41\n",
      "Val: Epoch 132, Loss: 0.312\n",
      "Training: Epoch 133, Batch 0, Loss: 0.372\n",
      "Training: Epoch 133, Batch 1, Loss: 0.35\n",
      "Training: Epoch 133, Batch 2, Loss: 0.411\n",
      "Training: Epoch 133, Batch 3, Loss: 0.465\n",
      "Training: Epoch 133, Batch 4, Loss: 0.43\n",
      "Training: Epoch 133, Batch 5, Loss: 0.308\n",
      "Training: Epoch 133, Batch 6, Loss: 0.365\n",
      "Training: Epoch 133, Batch 7, Loss: 0.311\n",
      "Training: Epoch 133, Batch 8, Loss: 0.287\n",
      "Training: Epoch 133, Batch 9, Loss: 0.414\n",
      "Training: Epoch 133, Batch 10, Loss: 0.653\n",
      "Training: Epoch 133, Batch 11, Loss: 0.694\n",
      "Training: Epoch 133, Batch 12, Loss: 0.218\n",
      "Training: Epoch 133, Batch 13, Loss: 0.309\n",
      "Training: Epoch 133, Batch 14, Loss: 0.191\n",
      "Training: Epoch 133, Batch 15, Loss: 0.44\n",
      "Training: Epoch 133, Batch 16, Loss: 0.401\n",
      "Training: Epoch 133, Batch 17, Loss: 0.4\n",
      "Training: Epoch 133, Batch 18, Loss: 0.418\n",
      "Training: Epoch 133, Batch 19, Loss: 0.234\n",
      "Training: Epoch 133, Batch 20, Loss: 0.217\n",
      "Training: Epoch 133, Batch 21, Loss: 0.45\n",
      "Training: Epoch 133, Batch 22, Loss: 0.48\n",
      "Training: Epoch 133, Batch 23, Loss: 0.417\n",
      "Training: Epoch 133, Batch 24, Loss: 0.399\n",
      "Training: Epoch 133, Batch 25, Loss: 0.357\n",
      "Training: Epoch 133, Batch 26, Loss: 0.289\n",
      "Training: Epoch 133, Batch 27, Loss: 0.624\n",
      "Training: Epoch 133, Batch 28, Loss: 0.435\n",
      "Training: Epoch 133, Batch 29, Loss: 0.345\n",
      "Val: Epoch 133, Loss: 0.271\n",
      "Training: Epoch 134, Batch 0, Loss: 0.416\n",
      "Training: Epoch 134, Batch 1, Loss: 0.439\n",
      "Training: Epoch 134, Batch 2, Loss: 0.348\n",
      "Training: Epoch 134, Batch 3, Loss: 0.275\n",
      "Training: Epoch 134, Batch 4, Loss: 0.137\n",
      "Training: Epoch 134, Batch 5, Loss: 0.452\n",
      "Training: Epoch 134, Batch 6, Loss: 0.551\n",
      "Training: Epoch 134, Batch 7, Loss: 0.568\n",
      "Training: Epoch 134, Batch 8, Loss: 0.275\n",
      "Training: Epoch 134, Batch 9, Loss: 0.284\n",
      "Training: Epoch 134, Batch 10, Loss: 0.423\n",
      "Training: Epoch 134, Batch 11, Loss: 0.24\n",
      "Training: Epoch 134, Batch 12, Loss: 0.304\n",
      "Training: Epoch 134, Batch 13, Loss: 0.389\n",
      "Training: Epoch 134, Batch 14, Loss: 0.284\n",
      "Training: Epoch 134, Batch 15, Loss: 0.385\n",
      "Training: Epoch 134, Batch 16, Loss: 0.406\n",
      "Training: Epoch 134, Batch 17, Loss: 0.341\n",
      "Training: Epoch 134, Batch 18, Loss: 0.665\n",
      "Training: Epoch 134, Batch 19, Loss: 0.369\n",
      "Training: Epoch 134, Batch 20, Loss: 0.528\n",
      "Training: Epoch 134, Batch 21, Loss: 0.331\n",
      "Training: Epoch 134, Batch 22, Loss: 0.395\n",
      "Training: Epoch 134, Batch 23, Loss: 0.277\n",
      "Training: Epoch 134, Batch 24, Loss: 0.509\n",
      "Training: Epoch 134, Batch 25, Loss: 0.431\n",
      "Training: Epoch 134, Batch 26, Loss: 0.673\n",
      "Training: Epoch 134, Batch 27, Loss: 0.363\n",
      "Training: Epoch 134, Batch 28, Loss: 0.447\n",
      "Training: Epoch 134, Batch 29, Loss: 0.125\n",
      "Val: Epoch 134, Loss: 0.299\n",
      "Training: Epoch 135, Batch 0, Loss: 0.306\n",
      "Training: Epoch 135, Batch 1, Loss: 0.492\n",
      "Training: Epoch 135, Batch 2, Loss: 0.243\n",
      "Training: Epoch 135, Batch 3, Loss: 0.287\n",
      "Training: Epoch 135, Batch 4, Loss: 0.447\n",
      "Training: Epoch 135, Batch 5, Loss: 0.399\n",
      "Training: Epoch 135, Batch 6, Loss: 0.306\n",
      "Training: Epoch 135, Batch 7, Loss: 0.365\n",
      "Training: Epoch 135, Batch 8, Loss: 0.446\n",
      "Training: Epoch 135, Batch 9, Loss: 0.438\n",
      "Training: Epoch 135, Batch 10, Loss: 0.377\n",
      "Training: Epoch 135, Batch 11, Loss: 0.413\n",
      "Training: Epoch 135, Batch 12, Loss: 0.458\n",
      "Training: Epoch 135, Batch 13, Loss: 0.203\n",
      "Training: Epoch 135, Batch 14, Loss: 0.205\n",
      "Training: Epoch 135, Batch 15, Loss: 0.466\n",
      "Training: Epoch 135, Batch 16, Loss: 0.609\n",
      "Training: Epoch 135, Batch 17, Loss: 0.317\n",
      "Training: Epoch 135, Batch 18, Loss: 0.204\n",
      "Training: Epoch 135, Batch 19, Loss: 0.41\n",
      "Training: Epoch 135, Batch 20, Loss: 0.537\n",
      "Training: Epoch 135, Batch 21, Loss: 0.458\n",
      "Training: Epoch 135, Batch 22, Loss: 0.336\n",
      "Training: Epoch 135, Batch 23, Loss: 0.246\n",
      "Training: Epoch 135, Batch 24, Loss: 0.56\n",
      "Training: Epoch 135, Batch 25, Loss: 0.25\n",
      "Training: Epoch 135, Batch 26, Loss: 0.15\n",
      "Training: Epoch 135, Batch 27, Loss: 0.452\n",
      "Training: Epoch 135, Batch 28, Loss: 0.615\n",
      "Training: Epoch 135, Batch 29, Loss: 0.437\n",
      "Val: Epoch 135, Loss: 0.273\n",
      "Training: Epoch 136, Batch 0, Loss: 0.547\n",
      "Training: Epoch 136, Batch 1, Loss: 0.194\n",
      "Training: Epoch 136, Batch 2, Loss: 0.246\n",
      "Training: Epoch 136, Batch 3, Loss: 0.376\n",
      "Training: Epoch 136, Batch 4, Loss: 0.314\n",
      "Training: Epoch 136, Batch 5, Loss: 0.675\n",
      "Training: Epoch 136, Batch 6, Loss: 0.235\n",
      "Training: Epoch 136, Batch 7, Loss: 0.604\n",
      "Training: Epoch 136, Batch 8, Loss: 0.348\n",
      "Training: Epoch 136, Batch 9, Loss: 0.522\n",
      "Training: Epoch 136, Batch 10, Loss: 0.445\n",
      "Training: Epoch 136, Batch 11, Loss: 0.293\n",
      "Training: Epoch 136, Batch 12, Loss: 0.336\n",
      "Training: Epoch 136, Batch 13, Loss: 0.265\n",
      "Training: Epoch 136, Batch 14, Loss: 0.395\n",
      "Training: Epoch 136, Batch 15, Loss: 0.245\n",
      "Training: Epoch 136, Batch 16, Loss: 0.617\n",
      "Training: Epoch 136, Batch 17, Loss: 0.429\n",
      "Training: Epoch 136, Batch 18, Loss: 0.294\n",
      "Training: Epoch 136, Batch 19, Loss: 0.41\n",
      "Training: Epoch 136, Batch 20, Loss: 0.327\n",
      "Training: Epoch 136, Batch 21, Loss: 0.221\n",
      "Training: Epoch 136, Batch 22, Loss: 0.259\n",
      "Training: Epoch 136, Batch 23, Loss: 0.484\n",
      "Training: Epoch 136, Batch 24, Loss: 0.294\n",
      "Training: Epoch 136, Batch 25, Loss: 0.546\n",
      "Training: Epoch 136, Batch 26, Loss: 0.521\n",
      "Training: Epoch 136, Batch 27, Loss: 0.297\n",
      "Training: Epoch 136, Batch 28, Loss: 0.343\n",
      "Training: Epoch 136, Batch 29, Loss: 0.404\n",
      "Val: Epoch 136, Loss: 0.282\n",
      "Training: Epoch 137, Batch 0, Loss: 0.626\n",
      "Training: Epoch 137, Batch 1, Loss: 0.322\n",
      "Training: Epoch 137, Batch 2, Loss: 0.395\n",
      "Training: Epoch 137, Batch 3, Loss: 0.459\n",
      "Training: Epoch 137, Batch 4, Loss: 0.429\n",
      "Training: Epoch 137, Batch 5, Loss: 0.385\n",
      "Training: Epoch 137, Batch 6, Loss: 0.483\n",
      "Training: Epoch 137, Batch 7, Loss: 0.286\n",
      "Training: Epoch 137, Batch 8, Loss: 0.249\n",
      "Training: Epoch 137, Batch 9, Loss: 0.275\n",
      "Training: Epoch 137, Batch 10, Loss: 0.208\n",
      "Training: Epoch 137, Batch 11, Loss: 0.424\n",
      "Training: Epoch 137, Batch 12, Loss: 0.447\n",
      "Training: Epoch 137, Batch 13, Loss: 0.414\n",
      "Training: Epoch 137, Batch 14, Loss: 0.227\n",
      "Training: Epoch 137, Batch 15, Loss: 0.452\n",
      "Training: Epoch 137, Batch 16, Loss: 0.641\n",
      "Training: Epoch 137, Batch 17, Loss: 0.292\n",
      "Training: Epoch 137, Batch 18, Loss: 0.592\n",
      "Training: Epoch 137, Batch 19, Loss: 0.364\n",
      "Training: Epoch 137, Batch 20, Loss: 0.233\n",
      "Training: Epoch 137, Batch 21, Loss: 0.188\n",
      "Training: Epoch 137, Batch 22, Loss: 0.425\n",
      "Training: Epoch 137, Batch 23, Loss: 0.423\n",
      "Training: Epoch 137, Batch 24, Loss: 0.317\n",
      "Training: Epoch 137, Batch 25, Loss: 0.273\n",
      "Training: Epoch 137, Batch 26, Loss: 0.432\n",
      "Training: Epoch 137, Batch 27, Loss: 0.311\n",
      "Training: Epoch 137, Batch 28, Loss: 0.424\n",
      "Training: Epoch 137, Batch 29, Loss: 0.379\n",
      "Val: Epoch 137, Loss: 0.34\n",
      "Training: Epoch 138, Batch 0, Loss: 0.365\n",
      "Training: Epoch 138, Batch 1, Loss: 0.197\n",
      "Training: Epoch 138, Batch 2, Loss: 0.27\n",
      "Training: Epoch 138, Batch 3, Loss: 0.367\n",
      "Training: Epoch 138, Batch 4, Loss: 0.46\n",
      "Training: Epoch 138, Batch 5, Loss: 0.49\n",
      "Training: Epoch 138, Batch 6, Loss: 0.446\n",
      "Training: Epoch 138, Batch 7, Loss: 0.455\n",
      "Training: Epoch 138, Batch 8, Loss: 0.473\n",
      "Training: Epoch 138, Batch 9, Loss: 0.249\n",
      "Training: Epoch 138, Batch 10, Loss: 0.601\n",
      "Training: Epoch 138, Batch 11, Loss: 0.208\n",
      "Training: Epoch 138, Batch 12, Loss: 0.271\n",
      "Training: Epoch 138, Batch 13, Loss: 0.435\n",
      "Training: Epoch 138, Batch 14, Loss: 0.51\n",
      "Training: Epoch 138, Batch 15, Loss: 0.196\n",
      "Training: Epoch 138, Batch 16, Loss: 0.415\n",
      "Training: Epoch 138, Batch 17, Loss: 0.448\n",
      "Training: Epoch 138, Batch 18, Loss: 0.463\n",
      "Training: Epoch 138, Batch 19, Loss: 0.452\n",
      "Training: Epoch 138, Batch 20, Loss: 0.247\n",
      "Training: Epoch 138, Batch 21, Loss: 0.393\n",
      "Training: Epoch 138, Batch 22, Loss: 0.38\n",
      "Training: Epoch 138, Batch 23, Loss: 0.279\n",
      "Training: Epoch 138, Batch 24, Loss: 0.428\n",
      "Training: Epoch 138, Batch 25, Loss: 0.39\n",
      "Training: Epoch 138, Batch 26, Loss: 0.418\n",
      "Training: Epoch 138, Batch 27, Loss: 0.505\n",
      "Training: Epoch 138, Batch 28, Loss: 0.478\n",
      "Training: Epoch 138, Batch 29, Loss: 0.317\n",
      "Val: Epoch 138, Loss: 0.303\n",
      "Training: Epoch 139, Batch 0, Loss: 0.351\n",
      "Training: Epoch 139, Batch 1, Loss: 0.375\n",
      "Training: Epoch 139, Batch 2, Loss: 0.494\n",
      "Training: Epoch 139, Batch 3, Loss: 0.222\n",
      "Training: Epoch 139, Batch 4, Loss: 0.44\n",
      "Training: Epoch 139, Batch 5, Loss: 0.389\n",
      "Training: Epoch 139, Batch 6, Loss: 0.283\n",
      "Training: Epoch 139, Batch 7, Loss: 0.343\n",
      "Training: Epoch 139, Batch 8, Loss: 0.536\n",
      "Training: Epoch 139, Batch 9, Loss: 0.346\n",
      "Training: Epoch 139, Batch 10, Loss: 0.335\n",
      "Training: Epoch 139, Batch 11, Loss: 0.248\n",
      "Training: Epoch 139, Batch 12, Loss: 0.563\n",
      "Training: Epoch 139, Batch 13, Loss: 0.412\n",
      "Training: Epoch 139, Batch 14, Loss: 0.395\n",
      "Training: Epoch 139, Batch 15, Loss: 0.552\n",
      "Training: Epoch 139, Batch 16, Loss: 0.327\n",
      "Training: Epoch 139, Batch 17, Loss: 0.261\n",
      "Training: Epoch 139, Batch 18, Loss: 0.324\n",
      "Training: Epoch 139, Batch 19, Loss: 0.332\n",
      "Training: Epoch 139, Batch 20, Loss: 0.367\n",
      "Training: Epoch 139, Batch 21, Loss: 0.445\n",
      "Training: Epoch 139, Batch 22, Loss: 0.408\n",
      "Training: Epoch 139, Batch 23, Loss: 0.314\n",
      "Training: Epoch 139, Batch 24, Loss: 0.346\n",
      "Training: Epoch 139, Batch 25, Loss: 0.359\n",
      "Training: Epoch 139, Batch 26, Loss: 0.599\n",
      "Training: Epoch 139, Batch 27, Loss: 0.214\n",
      "Training: Epoch 139, Batch 28, Loss: 0.382\n",
      "Training: Epoch 139, Batch 29, Loss: 0.368\n",
      "Val: Epoch 139, Loss: 0.279\n",
      "Training: Epoch 140, Batch 0, Loss: 0.422\n",
      "Training: Epoch 140, Batch 1, Loss: 0.251\n",
      "Training: Epoch 140, Batch 2, Loss: 0.659\n",
      "Training: Epoch 140, Batch 3, Loss: 0.24\n",
      "Training: Epoch 140, Batch 4, Loss: 0.379\n",
      "Training: Epoch 140, Batch 5, Loss: 0.215\n",
      "Training: Epoch 140, Batch 6, Loss: 0.485\n",
      "Training: Epoch 140, Batch 7, Loss: 0.547\n",
      "Training: Epoch 140, Batch 8, Loss: 0.247\n",
      "Training: Epoch 140, Batch 9, Loss: 0.385\n",
      "Training: Epoch 140, Batch 10, Loss: 0.319\n",
      "Training: Epoch 140, Batch 11, Loss: 0.323\n",
      "Training: Epoch 140, Batch 12, Loss: 0.247\n",
      "Training: Epoch 140, Batch 13, Loss: 0.218\n",
      "Training: Epoch 140, Batch 14, Loss: 0.665\n",
      "Training: Epoch 140, Batch 15, Loss: 0.427\n",
      "Training: Epoch 140, Batch 16, Loss: 0.302\n",
      "Training: Epoch 140, Batch 17, Loss: 0.417\n",
      "Training: Epoch 140, Batch 18, Loss: 0.397\n",
      "Training: Epoch 140, Batch 19, Loss: 0.294\n",
      "Training: Epoch 140, Batch 20, Loss: 0.366\n",
      "Training: Epoch 140, Batch 21, Loss: 0.536\n",
      "Training: Epoch 140, Batch 22, Loss: 0.387\n",
      "Training: Epoch 140, Batch 23, Loss: 0.213\n",
      "Training: Epoch 140, Batch 24, Loss: 0.443\n",
      "Training: Epoch 140, Batch 25, Loss: 0.317\n",
      "Training: Epoch 140, Batch 26, Loss: 0.2\n",
      "Training: Epoch 140, Batch 27, Loss: 0.602\n",
      "Training: Epoch 140, Batch 28, Loss: 0.593\n",
      "Training: Epoch 140, Batch 29, Loss: 0.348\n",
      "Val: Epoch 140, Loss: 0.281\n",
      "Training: Epoch 141, Batch 0, Loss: 0.345\n",
      "Training: Epoch 141, Batch 1, Loss: 0.369\n",
      "Training: Epoch 141, Batch 2, Loss: 0.328\n",
      "Training: Epoch 141, Batch 3, Loss: 0.48\n",
      "Training: Epoch 141, Batch 4, Loss: 0.363\n",
      "Training: Epoch 141, Batch 5, Loss: 0.242\n",
      "Training: Epoch 141, Batch 6, Loss: 0.269\n",
      "Training: Epoch 141, Batch 7, Loss: 0.431\n",
      "Training: Epoch 141, Batch 8, Loss: 0.68\n",
      "Training: Epoch 141, Batch 9, Loss: 0.379\n",
      "Training: Epoch 141, Batch 10, Loss: 0.431\n",
      "Training: Epoch 141, Batch 11, Loss: 0.433\n",
      "Training: Epoch 141, Batch 12, Loss: 0.442\n",
      "Training: Epoch 141, Batch 13, Loss: 0.278\n",
      "Training: Epoch 141, Batch 14, Loss: 0.562\n",
      "Training: Epoch 141, Batch 15, Loss: 0.54\n",
      "Training: Epoch 141, Batch 16, Loss: 0.437\n",
      "Training: Epoch 141, Batch 17, Loss: 0.127\n",
      "Training: Epoch 141, Batch 18, Loss: 0.391\n",
      "Training: Epoch 141, Batch 19, Loss: 0.332\n",
      "Training: Epoch 141, Batch 20, Loss: 0.329\n",
      "Training: Epoch 141, Batch 21, Loss: 0.31\n",
      "Training: Epoch 141, Batch 22, Loss: 0.437\n",
      "Training: Epoch 141, Batch 23, Loss: 0.414\n",
      "Training: Epoch 141, Batch 24, Loss: 0.324\n",
      "Training: Epoch 141, Batch 25, Loss: 0.457\n",
      "Training: Epoch 141, Batch 26, Loss: 0.396\n",
      "Training: Epoch 141, Batch 27, Loss: 0.286\n",
      "Training: Epoch 141, Batch 28, Loss: 0.204\n",
      "Training: Epoch 141, Batch 29, Loss: 0.319\n",
      "Val: Epoch 141, Loss: 0.29\n",
      "Training: Epoch 142, Batch 0, Loss: 0.397\n",
      "Training: Epoch 142, Batch 1, Loss: 0.443\n",
      "Training: Epoch 142, Batch 2, Loss: 0.313\n",
      "Training: Epoch 142, Batch 3, Loss: 0.573\n",
      "Training: Epoch 142, Batch 4, Loss: 0.528\n",
      "Training: Epoch 142, Batch 5, Loss: 0.351\n",
      "Training: Epoch 142, Batch 6, Loss: 0.436\n",
      "Training: Epoch 142, Batch 7, Loss: 0.253\n",
      "Training: Epoch 142, Batch 8, Loss: 0.406\n",
      "Training: Epoch 142, Batch 9, Loss: 0.237\n",
      "Training: Epoch 142, Batch 10, Loss: 0.471\n",
      "Training: Epoch 142, Batch 11, Loss: 0.384\n",
      "Training: Epoch 142, Batch 12, Loss: 0.179\n",
      "Training: Epoch 142, Batch 13, Loss: 0.529\n",
      "Training: Epoch 142, Batch 14, Loss: 0.319\n",
      "Training: Epoch 142, Batch 15, Loss: 0.601\n",
      "Training: Epoch 142, Batch 16, Loss: 0.251\n",
      "Training: Epoch 142, Batch 17, Loss: 0.401\n",
      "Training: Epoch 142, Batch 18, Loss: 0.382\n",
      "Training: Epoch 142, Batch 19, Loss: 0.455\n",
      "Training: Epoch 142, Batch 20, Loss: 0.444\n",
      "Training: Epoch 142, Batch 21, Loss: 0.582\n",
      "Training: Epoch 142, Batch 22, Loss: 0.33\n",
      "Training: Epoch 142, Batch 23, Loss: 0.513\n",
      "Training: Epoch 142, Batch 24, Loss: 0.365\n",
      "Training: Epoch 142, Batch 25, Loss: 0.266\n",
      "Training: Epoch 142, Batch 26, Loss: 0.277\n",
      "Training: Epoch 142, Batch 27, Loss: 0.275\n",
      "Training: Epoch 142, Batch 28, Loss: 0.326\n",
      "Training: Epoch 142, Batch 29, Loss: 0.223\n",
      "Val: Epoch 142, Loss: 0.347\n",
      "Training: Epoch 143, Batch 0, Loss: 0.405\n",
      "Training: Epoch 143, Batch 1, Loss: 0.262\n",
      "Training: Epoch 143, Batch 2, Loss: 0.422\n",
      "Training: Epoch 143, Batch 3, Loss: 0.386\n",
      "Training: Epoch 143, Batch 4, Loss: 0.215\n",
      "Training: Epoch 143, Batch 5, Loss: 0.527\n",
      "Training: Epoch 143, Batch 6, Loss: 0.5\n",
      "Training: Epoch 143, Batch 7, Loss: 0.375\n",
      "Training: Epoch 143, Batch 8, Loss: 0.492\n",
      "Training: Epoch 143, Batch 9, Loss: 0.316\n",
      "Training: Epoch 143, Batch 10, Loss: 0.377\n",
      "Training: Epoch 143, Batch 11, Loss: 0.395\n",
      "Training: Epoch 143, Batch 12, Loss: 0.482\n",
      "Training: Epoch 143, Batch 13, Loss: 0.309\n",
      "Training: Epoch 143, Batch 14, Loss: 0.343\n",
      "Training: Epoch 143, Batch 15, Loss: 0.385\n",
      "Training: Epoch 143, Batch 16, Loss: 0.358\n",
      "Training: Epoch 143, Batch 17, Loss: 0.461\n",
      "Training: Epoch 143, Batch 18, Loss: 0.168\n",
      "Training: Epoch 143, Batch 19, Loss: 0.281\n",
      "Training: Epoch 143, Batch 20, Loss: 0.555\n",
      "Training: Epoch 143, Batch 21, Loss: 0.315\n",
      "Training: Epoch 143, Batch 22, Loss: 0.481\n",
      "Training: Epoch 143, Batch 23, Loss: 0.493\n",
      "Training: Epoch 143, Batch 24, Loss: 0.332\n",
      "Training: Epoch 143, Batch 25, Loss: 0.469\n",
      "Training: Epoch 143, Batch 26, Loss: 0.325\n",
      "Training: Epoch 143, Batch 27, Loss: 0.337\n",
      "Training: Epoch 143, Batch 28, Loss: 0.387\n",
      "Training: Epoch 143, Batch 29, Loss: 0.414\n",
      "Val: Epoch 143, Loss: 0.292\n",
      "Training: Epoch 144, Batch 0, Loss: 0.359\n",
      "Training: Epoch 144, Batch 1, Loss: 0.558\n",
      "Training: Epoch 144, Batch 2, Loss: 0.458\n",
      "Training: Epoch 144, Batch 3, Loss: 0.234\n",
      "Training: Epoch 144, Batch 4, Loss: 0.329\n",
      "Training: Epoch 144, Batch 5, Loss: 0.407\n",
      "Training: Epoch 144, Batch 6, Loss: 0.24\n",
      "Training: Epoch 144, Batch 7, Loss: 0.316\n",
      "Training: Epoch 144, Batch 8, Loss: 0.284\n",
      "Training: Epoch 144, Batch 9, Loss: 0.439\n",
      "Training: Epoch 144, Batch 10, Loss: 0.476\n",
      "Training: Epoch 144, Batch 11, Loss: 0.392\n",
      "Training: Epoch 144, Batch 12, Loss: 0.465\n",
      "Training: Epoch 144, Batch 13, Loss: 0.459\n",
      "Training: Epoch 144, Batch 14, Loss: 0.412\n",
      "Training: Epoch 144, Batch 15, Loss: 0.422\n",
      "Training: Epoch 144, Batch 16, Loss: 0.269\n",
      "Training: Epoch 144, Batch 17, Loss: 0.33\n",
      "Training: Epoch 144, Batch 18, Loss: 0.428\n",
      "Training: Epoch 144, Batch 19, Loss: 0.583\n",
      "Training: Epoch 144, Batch 20, Loss: 0.317\n",
      "Training: Epoch 144, Batch 21, Loss: 0.302\n",
      "Training: Epoch 144, Batch 22, Loss: 0.391\n",
      "Training: Epoch 144, Batch 23, Loss: 0.363\n",
      "Training: Epoch 144, Batch 24, Loss: 0.415\n",
      "Training: Epoch 144, Batch 25, Loss: 0.572\n",
      "Training: Epoch 144, Batch 26, Loss: 0.228\n",
      "Training: Epoch 144, Batch 27, Loss: 0.128\n",
      "Training: Epoch 144, Batch 28, Loss: 0.4\n",
      "Training: Epoch 144, Batch 29, Loss: 0.479\n",
      "Val: Epoch 144, Loss: 0.304\n",
      "Training: Epoch 145, Batch 0, Loss: 0.253\n",
      "Training: Epoch 145, Batch 1, Loss: 0.482\n",
      "Training: Epoch 145, Batch 2, Loss: 0.422\n",
      "Training: Epoch 145, Batch 3, Loss: 0.554\n",
      "Training: Epoch 145, Batch 4, Loss: 0.426\n",
      "Training: Epoch 145, Batch 5, Loss: 0.488\n",
      "Training: Epoch 145, Batch 6, Loss: 0.423\n",
      "Training: Epoch 145, Batch 7, Loss: 0.649\n",
      "Training: Epoch 145, Batch 8, Loss: 0.361\n",
      "Training: Epoch 145, Batch 9, Loss: 0.24\n",
      "Training: Epoch 145, Batch 10, Loss: 0.231\n",
      "Training: Epoch 145, Batch 11, Loss: 0.213\n",
      "Training: Epoch 145, Batch 12, Loss: 0.211\n",
      "Training: Epoch 145, Batch 13, Loss: 0.563\n",
      "Training: Epoch 145, Batch 14, Loss: 0.4\n",
      "Training: Epoch 145, Batch 15, Loss: 0.532\n",
      "Training: Epoch 145, Batch 16, Loss: 0.272\n",
      "Training: Epoch 145, Batch 17, Loss: 0.333\n",
      "Training: Epoch 145, Batch 18, Loss: 0.417\n",
      "Training: Epoch 145, Batch 19, Loss: 0.345\n",
      "Training: Epoch 145, Batch 20, Loss: 0.461\n",
      "Training: Epoch 145, Batch 21, Loss: 0.16\n",
      "Training: Epoch 145, Batch 22, Loss: 0.299\n",
      "Training: Epoch 145, Batch 23, Loss: 0.237\n",
      "Training: Epoch 145, Batch 24, Loss: 0.381\n",
      "Training: Epoch 145, Batch 25, Loss: 0.359\n",
      "Training: Epoch 145, Batch 26, Loss: 0.409\n",
      "Training: Epoch 145, Batch 27, Loss: 0.573\n",
      "Training: Epoch 145, Batch 28, Loss: 0.509\n",
      "Training: Epoch 145, Batch 29, Loss: 0.186\n",
      "Val: Epoch 145, Loss: 0.305\n",
      "Training: Epoch 146, Batch 0, Loss: 0.566\n",
      "Training: Epoch 146, Batch 1, Loss: 0.404\n",
      "Training: Epoch 146, Batch 2, Loss: 0.358\n",
      "Training: Epoch 146, Batch 3, Loss: 0.318\n",
      "Training: Epoch 146, Batch 4, Loss: 0.368\n",
      "Training: Epoch 146, Batch 5, Loss: 0.461\n",
      "Training: Epoch 146, Batch 6, Loss: 0.38\n",
      "Training: Epoch 146, Batch 7, Loss: 0.459\n",
      "Training: Epoch 146, Batch 8, Loss: 0.364\n",
      "Training: Epoch 146, Batch 9, Loss: 0.29\n",
      "Training: Epoch 146, Batch 10, Loss: 0.299\n",
      "Training: Epoch 146, Batch 11, Loss: 0.337\n",
      "Training: Epoch 146, Batch 12, Loss: 0.49\n",
      "Training: Epoch 146, Batch 13, Loss: 0.446\n",
      "Training: Epoch 146, Batch 14, Loss: 0.367\n",
      "Training: Epoch 146, Batch 15, Loss: 0.371\n",
      "Training: Epoch 146, Batch 16, Loss: 0.414\n",
      "Training: Epoch 146, Batch 17, Loss: 0.407\n",
      "Training: Epoch 146, Batch 18, Loss: 0.308\n",
      "Training: Epoch 146, Batch 19, Loss: 0.329\n",
      "Training: Epoch 146, Batch 20, Loss: 0.477\n",
      "Training: Epoch 146, Batch 21, Loss: 0.618\n",
      "Training: Epoch 146, Batch 22, Loss: 0.439\n",
      "Training: Epoch 146, Batch 23, Loss: 0.43\n",
      "Training: Epoch 146, Batch 24, Loss: 0.201\n",
      "Training: Epoch 146, Batch 25, Loss: 0.274\n",
      "Training: Epoch 146, Batch 26, Loss: 0.31\n",
      "Training: Epoch 146, Batch 27, Loss: 0.313\n",
      "Training: Epoch 146, Batch 28, Loss: 0.355\n",
      "Training: Epoch 146, Batch 29, Loss: 0.223\n",
      "Val: Epoch 146, Loss: 0.272\n",
      "Training: Epoch 147, Batch 0, Loss: 0.445\n",
      "Training: Epoch 147, Batch 1, Loss: 0.468\n",
      "Training: Epoch 147, Batch 2, Loss: 0.32\n",
      "Training: Epoch 147, Batch 3, Loss: 0.419\n",
      "Training: Epoch 147, Batch 4, Loss: 0.406\n",
      "Training: Epoch 147, Batch 5, Loss: 0.524\n",
      "Training: Epoch 147, Batch 6, Loss: 0.373\n",
      "Training: Epoch 147, Batch 7, Loss: 0.244\n",
      "Training: Epoch 147, Batch 8, Loss: 0.285\n",
      "Training: Epoch 147, Batch 9, Loss: 0.41\n",
      "Training: Epoch 147, Batch 10, Loss: 0.417\n",
      "Training: Epoch 147, Batch 11, Loss: 0.31\n",
      "Training: Epoch 147, Batch 12, Loss: 0.331\n",
      "Training: Epoch 147, Batch 13, Loss: 0.315\n",
      "Training: Epoch 147, Batch 14, Loss: 0.385\n",
      "Training: Epoch 147, Batch 15, Loss: 0.317\n",
      "Training: Epoch 147, Batch 16, Loss: 0.309\n",
      "Training: Epoch 147, Batch 17, Loss: 0.397\n",
      "Training: Epoch 147, Batch 18, Loss: 0.324\n",
      "Training: Epoch 147, Batch 19, Loss: 0.216\n",
      "Training: Epoch 147, Batch 20, Loss: 0.387\n",
      "Training: Epoch 147, Batch 21, Loss: 0.276\n",
      "Training: Epoch 147, Batch 22, Loss: 0.551\n",
      "Training: Epoch 147, Batch 23, Loss: 0.514\n",
      "Training: Epoch 147, Batch 24, Loss: 0.249\n",
      "Training: Epoch 147, Batch 25, Loss: 0.541\n",
      "Training: Epoch 147, Batch 26, Loss: 0.463\n",
      "Training: Epoch 147, Batch 27, Loss: 0.404\n",
      "Training: Epoch 147, Batch 28, Loss: 0.155\n",
      "Training: Epoch 147, Batch 29, Loss: 0.35\n",
      "Val: Epoch 147, Loss: 0.283\n",
      "Training: Epoch 148, Batch 0, Loss: 0.395\n",
      "Training: Epoch 148, Batch 1, Loss: 0.406\n",
      "Training: Epoch 148, Batch 2, Loss: 0.359\n",
      "Training: Epoch 148, Batch 3, Loss: 0.647\n",
      "Training: Epoch 148, Batch 4, Loss: 0.443\n",
      "Training: Epoch 148, Batch 5, Loss: 0.393\n",
      "Training: Epoch 148, Batch 6, Loss: 0.399\n",
      "Training: Epoch 148, Batch 7, Loss: 0.293\n",
      "Training: Epoch 148, Batch 8, Loss: 0.364\n",
      "Training: Epoch 148, Batch 9, Loss: 0.547\n",
      "Training: Epoch 148, Batch 10, Loss: 0.471\n",
      "Training: Epoch 148, Batch 11, Loss: 0.319\n",
      "Training: Epoch 148, Batch 12, Loss: 0.466\n",
      "Training: Epoch 148, Batch 13, Loss: 0.534\n",
      "Training: Epoch 148, Batch 14, Loss: 0.49\n",
      "Training: Epoch 148, Batch 15, Loss: 0.364\n",
      "Training: Epoch 148, Batch 16, Loss: 0.461\n",
      "Training: Epoch 148, Batch 17, Loss: 0.402\n",
      "Training: Epoch 148, Batch 18, Loss: 0.459\n",
      "Training: Epoch 148, Batch 19, Loss: 0.263\n",
      "Training: Epoch 148, Batch 20, Loss: 0.303\n",
      "Training: Epoch 148, Batch 21, Loss: 0.306\n",
      "Training: Epoch 148, Batch 22, Loss: 0.312\n",
      "Training: Epoch 148, Batch 23, Loss: 0.296\n",
      "Training: Epoch 148, Batch 24, Loss: 0.455\n",
      "Training: Epoch 148, Batch 25, Loss: 0.411\n",
      "Training: Epoch 148, Batch 26, Loss: 0.155\n",
      "Training: Epoch 148, Batch 27, Loss: 0.38\n",
      "Training: Epoch 148, Batch 28, Loss: 0.273\n",
      "Training: Epoch 148, Batch 29, Loss: 0.135\n",
      "Val: Epoch 148, Loss: 0.269\n",
      "Training: Epoch 149, Batch 0, Loss: 0.339\n",
      "Training: Epoch 149, Batch 1, Loss: 0.173\n",
      "Training: Epoch 149, Batch 2, Loss: 0.364\n",
      "Training: Epoch 149, Batch 3, Loss: 0.502\n",
      "Training: Epoch 149, Batch 4, Loss: 0.346\n",
      "Training: Epoch 149, Batch 5, Loss: 0.256\n",
      "Training: Epoch 149, Batch 6, Loss: 0.471\n",
      "Training: Epoch 149, Batch 7, Loss: 0.205\n",
      "Training: Epoch 149, Batch 8, Loss: 0.724\n",
      "Training: Epoch 149, Batch 9, Loss: 0.407\n",
      "Training: Epoch 149, Batch 10, Loss: 0.287\n",
      "Training: Epoch 149, Batch 11, Loss: 0.415\n",
      "Training: Epoch 149, Batch 12, Loss: 0.419\n",
      "Training: Epoch 149, Batch 13, Loss: 0.57\n",
      "Training: Epoch 149, Batch 14, Loss: 0.702\n",
      "Training: Epoch 149, Batch 15, Loss: 0.244\n",
      "Training: Epoch 149, Batch 16, Loss: 0.248\n",
      "Training: Epoch 149, Batch 17, Loss: 0.273\n",
      "Training: Epoch 149, Batch 18, Loss: 0.11\n",
      "Training: Epoch 149, Batch 19, Loss: 0.341\n",
      "Training: Epoch 149, Batch 20, Loss: 0.604\n",
      "Training: Epoch 149, Batch 21, Loss: 0.192\n",
      "Training: Epoch 149, Batch 22, Loss: 0.316\n",
      "Training: Epoch 149, Batch 23, Loss: 0.276\n",
      "Training: Epoch 149, Batch 24, Loss: 0.369\n",
      "Training: Epoch 149, Batch 25, Loss: 0.612\n",
      "Training: Epoch 149, Batch 26, Loss: 0.401\n",
      "Training: Epoch 149, Batch 27, Loss: 0.387\n",
      "Training: Epoch 149, Batch 28, Loss: 0.278\n",
      "Training: Epoch 149, Batch 29, Loss: 0.41\n",
      "Val: Epoch 149, Loss: 0.317\n",
      "Training: Epoch 150, Batch 0, Loss: 0.347\n",
      "Training: Epoch 150, Batch 1, Loss: 0.218\n",
      "Training: Epoch 150, Batch 2, Loss: 0.335\n",
      "Training: Epoch 150, Batch 3, Loss: 0.276\n",
      "Training: Epoch 150, Batch 4, Loss: 0.426\n",
      "Training: Epoch 150, Batch 5, Loss: 0.364\n",
      "Training: Epoch 150, Batch 6, Loss: 0.541\n",
      "Training: Epoch 150, Batch 7, Loss: 0.287\n",
      "Training: Epoch 150, Batch 8, Loss: 0.389\n",
      "Training: Epoch 150, Batch 9, Loss: 0.122\n",
      "Training: Epoch 150, Batch 10, Loss: 0.607\n",
      "Training: Epoch 150, Batch 11, Loss: 0.285\n",
      "Training: Epoch 150, Batch 12, Loss: 0.511\n",
      "Training: Epoch 150, Batch 13, Loss: 0.286\n",
      "Training: Epoch 150, Batch 14, Loss: 0.357\n",
      "Training: Epoch 150, Batch 15, Loss: 0.361\n",
      "Training: Epoch 150, Batch 16, Loss: 0.366\n",
      "Training: Epoch 150, Batch 17, Loss: 0.411\n",
      "Training: Epoch 150, Batch 18, Loss: 0.424\n",
      "Training: Epoch 150, Batch 19, Loss: 0.309\n",
      "Training: Epoch 150, Batch 20, Loss: 0.321\n",
      "Training: Epoch 150, Batch 21, Loss: 0.494\n",
      "Training: Epoch 150, Batch 22, Loss: 0.175\n",
      "Training: Epoch 150, Batch 23, Loss: 0.515\n",
      "Training: Epoch 150, Batch 24, Loss: 0.528\n",
      "Training: Epoch 150, Batch 25, Loss: 0.281\n",
      "Training: Epoch 150, Batch 26, Loss: 0.207\n",
      "Training: Epoch 150, Batch 27, Loss: 0.326\n",
      "Training: Epoch 150, Batch 28, Loss: 0.558\n",
      "Training: Epoch 150, Batch 29, Loss: 0.34\n",
      "Val: Epoch 150, Loss: 0.315\n",
      "Training: Epoch 151, Batch 0, Loss: 0.637\n",
      "Training: Epoch 151, Batch 1, Loss: 0.402\n",
      "Training: Epoch 151, Batch 2, Loss: 0.399\n",
      "Training: Epoch 151, Batch 3, Loss: 0.338\n",
      "Training: Epoch 151, Batch 4, Loss: 0.274\n",
      "Training: Epoch 151, Batch 5, Loss: 0.499\n",
      "Training: Epoch 151, Batch 6, Loss: 0.339\n",
      "Training: Epoch 151, Batch 7, Loss: 0.329\n",
      "Training: Epoch 151, Batch 8, Loss: 0.326\n",
      "Training: Epoch 151, Batch 9, Loss: 0.165\n",
      "Training: Epoch 151, Batch 10, Loss: 0.334\n",
      "Training: Epoch 151, Batch 11, Loss: 0.136\n",
      "Training: Epoch 151, Batch 12, Loss: 0.409\n",
      "Training: Epoch 151, Batch 13, Loss: 0.305\n",
      "Training: Epoch 151, Batch 14, Loss: 0.444\n",
      "Training: Epoch 151, Batch 15, Loss: 0.499\n",
      "Training: Epoch 151, Batch 16, Loss: 0.548\n",
      "Training: Epoch 151, Batch 17, Loss: 0.185\n",
      "Training: Epoch 151, Batch 18, Loss: 0.708\n",
      "Training: Epoch 151, Batch 19, Loss: 0.235\n",
      "Training: Epoch 151, Batch 20, Loss: 0.378\n",
      "Training: Epoch 151, Batch 21, Loss: 0.587\n",
      "Training: Epoch 151, Batch 22, Loss: 0.264\n",
      "Training: Epoch 151, Batch 23, Loss: 0.244\n",
      "Training: Epoch 151, Batch 24, Loss: 0.592\n",
      "Training: Epoch 151, Batch 25, Loss: 0.561\n",
      "Training: Epoch 151, Batch 26, Loss: 0.308\n",
      "Training: Epoch 151, Batch 27, Loss: 0.357\n",
      "Training: Epoch 151, Batch 28, Loss: 0.343\n",
      "Training: Epoch 151, Batch 29, Loss: 0.225\n",
      "Val: Epoch 151, Loss: 0.277\n",
      "Training: Epoch 152, Batch 0, Loss: 0.648\n",
      "Training: Epoch 152, Batch 1, Loss: 0.457\n",
      "Training: Epoch 152, Batch 2, Loss: 0.295\n",
      "Training: Epoch 152, Batch 3, Loss: 0.2\n",
      "Training: Epoch 152, Batch 4, Loss: 0.302\n",
      "Training: Epoch 152, Batch 5, Loss: 0.421\n",
      "Training: Epoch 152, Batch 6, Loss: 0.239\n",
      "Training: Epoch 152, Batch 7, Loss: 0.312\n",
      "Training: Epoch 152, Batch 8, Loss: 0.5\n",
      "Training: Epoch 152, Batch 9, Loss: 0.266\n",
      "Training: Epoch 152, Batch 10, Loss: 0.253\n",
      "Training: Epoch 152, Batch 11, Loss: 0.363\n",
      "Training: Epoch 152, Batch 12, Loss: 0.431\n",
      "Training: Epoch 152, Batch 13, Loss: 0.339\n",
      "Training: Epoch 152, Batch 14, Loss: 0.295\n",
      "Training: Epoch 152, Batch 15, Loss: 0.304\n",
      "Training: Epoch 152, Batch 16, Loss: 0.499\n",
      "Training: Epoch 152, Batch 17, Loss: 0.328\n",
      "Training: Epoch 152, Batch 18, Loss: 0.131\n",
      "Training: Epoch 152, Batch 19, Loss: 0.35\n",
      "Training: Epoch 152, Batch 20, Loss: 0.526\n",
      "Training: Epoch 152, Batch 21, Loss: 0.296\n",
      "Training: Epoch 152, Batch 22, Loss: 0.364\n",
      "Training: Epoch 152, Batch 23, Loss: 0.368\n",
      "Training: Epoch 152, Batch 24, Loss: 0.406\n",
      "Training: Epoch 152, Batch 25, Loss: 0.699\n",
      "Training: Epoch 152, Batch 26, Loss: 0.353\n",
      "Training: Epoch 152, Batch 27, Loss: 0.408\n",
      "Training: Epoch 152, Batch 28, Loss: 0.315\n",
      "Training: Epoch 152, Batch 29, Loss: 0.406\n",
      "Val: Epoch 152, Loss: 0.312\n",
      "Training: Epoch 153, Batch 0, Loss: 0.431\n",
      "Training: Epoch 153, Batch 1, Loss: 0.422\n",
      "Training: Epoch 153, Batch 2, Loss: 0.19\n",
      "Training: Epoch 153, Batch 3, Loss: 0.319\n",
      "Training: Epoch 153, Batch 4, Loss: 0.407\n",
      "Training: Epoch 153, Batch 5, Loss: 0.484\n",
      "Training: Epoch 153, Batch 6, Loss: 0.238\n",
      "Training: Epoch 153, Batch 7, Loss: 0.376\n",
      "Training: Epoch 153, Batch 8, Loss: 0.308\n",
      "Training: Epoch 153, Batch 9, Loss: 0.444\n",
      "Training: Epoch 153, Batch 10, Loss: 0.337\n",
      "Training: Epoch 153, Batch 11, Loss: 0.253\n",
      "Training: Epoch 153, Batch 12, Loss: 0.338\n",
      "Training: Epoch 153, Batch 13, Loss: 0.398\n",
      "Training: Epoch 153, Batch 14, Loss: 0.403\n",
      "Training: Epoch 153, Batch 15, Loss: 0.139\n",
      "Training: Epoch 153, Batch 16, Loss: 0.342\n",
      "Training: Epoch 153, Batch 17, Loss: 0.36\n",
      "Training: Epoch 153, Batch 18, Loss: 0.322\n",
      "Training: Epoch 153, Batch 19, Loss: 0.408\n",
      "Training: Epoch 153, Batch 20, Loss: 0.252\n",
      "Training: Epoch 153, Batch 21, Loss: 0.533\n",
      "Training: Epoch 153, Batch 22, Loss: 0.32\n",
      "Training: Epoch 153, Batch 23, Loss: 0.432\n",
      "Training: Epoch 153, Batch 24, Loss: 0.272\n",
      "Training: Epoch 153, Batch 25, Loss: 0.658\n",
      "Training: Epoch 153, Batch 26, Loss: 0.309\n",
      "Training: Epoch 153, Batch 27, Loss: 0.635\n",
      "Training: Epoch 153, Batch 28, Loss: 0.341\n",
      "Training: Epoch 153, Batch 29, Loss: 0.421\n",
      "Val: Epoch 153, Loss: 0.346\n",
      "Training: Epoch 154, Batch 0, Loss: 0.628\n",
      "Training: Epoch 154, Batch 1, Loss: 0.479\n",
      "Training: Epoch 154, Batch 2, Loss: 0.313\n",
      "Training: Epoch 154, Batch 3, Loss: 0.395\n",
      "Training: Epoch 154, Batch 4, Loss: 0.432\n",
      "Training: Epoch 154, Batch 5, Loss: 0.27\n",
      "Training: Epoch 154, Batch 6, Loss: 0.325\n",
      "Training: Epoch 154, Batch 7, Loss: 0.218\n",
      "Training: Epoch 154, Batch 8, Loss: 0.344\n",
      "Training: Epoch 154, Batch 9, Loss: 0.338\n",
      "Training: Epoch 154, Batch 10, Loss: 0.195\n",
      "Training: Epoch 154, Batch 11, Loss: 0.381\n",
      "Training: Epoch 154, Batch 12, Loss: 0.76\n",
      "Training: Epoch 154, Batch 13, Loss: 0.44\n",
      "Training: Epoch 154, Batch 14, Loss: 0.322\n",
      "Training: Epoch 154, Batch 15, Loss: 0.183\n",
      "Training: Epoch 154, Batch 16, Loss: 0.651\n",
      "Training: Epoch 154, Batch 17, Loss: 0.511\n",
      "Training: Epoch 154, Batch 18, Loss: 0.423\n",
      "Training: Epoch 154, Batch 19, Loss: 0.337\n",
      "Training: Epoch 154, Batch 20, Loss: 0.245\n",
      "Training: Epoch 154, Batch 21, Loss: 0.296\n",
      "Training: Epoch 154, Batch 22, Loss: 0.226\n",
      "Training: Epoch 154, Batch 23, Loss: 0.481\n",
      "Training: Epoch 154, Batch 24, Loss: 0.45\n",
      "Training: Epoch 154, Batch 25, Loss: 0.416\n",
      "Training: Epoch 154, Batch 26, Loss: 0.347\n",
      "Training: Epoch 154, Batch 27, Loss: 0.298\n",
      "Training: Epoch 154, Batch 28, Loss: 0.24\n",
      "Training: Epoch 154, Batch 29, Loss: 0.122\n",
      "Val: Epoch 154, Loss: 0.289\n",
      "Training: Epoch 155, Batch 0, Loss: 0.366\n",
      "Training: Epoch 155, Batch 1, Loss: 0.265\n",
      "Training: Epoch 155, Batch 2, Loss: 0.307\n",
      "Training: Epoch 155, Batch 3, Loss: 0.265\n",
      "Training: Epoch 155, Batch 4, Loss: 0.361\n",
      "Training: Epoch 155, Batch 5, Loss: 0.469\n",
      "Training: Epoch 155, Batch 6, Loss: 0.503\n",
      "Training: Epoch 155, Batch 7, Loss: 0.289\n",
      "Training: Epoch 155, Batch 8, Loss: 0.451\n",
      "Training: Epoch 155, Batch 9, Loss: 0.659\n",
      "Training: Epoch 155, Batch 10, Loss: 0.638\n",
      "Training: Epoch 155, Batch 11, Loss: 0.216\n",
      "Training: Epoch 155, Batch 12, Loss: 0.216\n",
      "Training: Epoch 155, Batch 13, Loss: 0.473\n",
      "Training: Epoch 155, Batch 14, Loss: 0.155\n",
      "Training: Epoch 155, Batch 15, Loss: 0.409\n",
      "Training: Epoch 155, Batch 16, Loss: 0.268\n",
      "Training: Epoch 155, Batch 17, Loss: 0.275\n",
      "Training: Epoch 155, Batch 18, Loss: 0.22\n",
      "Training: Epoch 155, Batch 19, Loss: 0.45\n",
      "Training: Epoch 155, Batch 20, Loss: 0.63\n",
      "Training: Epoch 155, Batch 21, Loss: 0.462\n",
      "Training: Epoch 155, Batch 22, Loss: 0.212\n",
      "Training: Epoch 155, Batch 23, Loss: 0.34\n",
      "Training: Epoch 155, Batch 24, Loss: 0.448\n",
      "Training: Epoch 155, Batch 25, Loss: 0.426\n",
      "Training: Epoch 155, Batch 26, Loss: 0.319\n",
      "Training: Epoch 155, Batch 27, Loss: 0.637\n",
      "Training: Epoch 155, Batch 28, Loss: 0.315\n",
      "Training: Epoch 155, Batch 29, Loss: 0.386\n",
      "Val: Epoch 155, Loss: 0.309\n",
      "Training: Epoch 156, Batch 0, Loss: 0.429\n",
      "Training: Epoch 156, Batch 1, Loss: 0.32\n",
      "Training: Epoch 156, Batch 2, Loss: 0.41\n",
      "Training: Epoch 156, Batch 3, Loss: 0.534\n",
      "Training: Epoch 156, Batch 4, Loss: 0.607\n",
      "Training: Epoch 156, Batch 5, Loss: 0.366\n",
      "Training: Epoch 156, Batch 6, Loss: 0.366\n",
      "Training: Epoch 156, Batch 7, Loss: 0.485\n",
      "Training: Epoch 156, Batch 8, Loss: 0.311\n",
      "Training: Epoch 156, Batch 9, Loss: 0.411\n",
      "Training: Epoch 156, Batch 10, Loss: 0.608\n",
      "Training: Epoch 156, Batch 11, Loss: 0.549\n",
      "Training: Epoch 156, Batch 12, Loss: 0.634\n",
      "Training: Epoch 156, Batch 13, Loss: 0.468\n",
      "Training: Epoch 156, Batch 14, Loss: 0.369\n",
      "Training: Epoch 156, Batch 15, Loss: 0.468\n",
      "Training: Epoch 156, Batch 16, Loss: 0.447\n",
      "Training: Epoch 156, Batch 17, Loss: 0.3\n",
      "Training: Epoch 156, Batch 18, Loss: 0.144\n",
      "Training: Epoch 156, Batch 19, Loss: 0.356\n",
      "Training: Epoch 156, Batch 20, Loss: 0.373\n",
      "Training: Epoch 156, Batch 21, Loss: 0.232\n",
      "Training: Epoch 156, Batch 22, Loss: 0.215\n",
      "Training: Epoch 156, Batch 23, Loss: 0.368\n",
      "Training: Epoch 156, Batch 24, Loss: 0.537\n",
      "Training: Epoch 156, Batch 25, Loss: 0.205\n",
      "Training: Epoch 156, Batch 26, Loss: 0.284\n",
      "Training: Epoch 156, Batch 27, Loss: 0.278\n",
      "Training: Epoch 156, Batch 28, Loss: 0.328\n",
      "Training: Epoch 156, Batch 29, Loss: 0.216\n",
      "Val: Epoch 156, Loss: 0.27\n",
      "Training: Epoch 157, Batch 0, Loss: 0.234\n",
      "Training: Epoch 157, Batch 1, Loss: 0.248\n",
      "Training: Epoch 157, Batch 2, Loss: 0.282\n",
      "Training: Epoch 157, Batch 3, Loss: 0.47\n",
      "Training: Epoch 157, Batch 4, Loss: 0.318\n",
      "Training: Epoch 157, Batch 5, Loss: 0.394\n",
      "Training: Epoch 157, Batch 6, Loss: 0.421\n",
      "Training: Epoch 157, Batch 7, Loss: 0.292\n",
      "Training: Epoch 157, Batch 8, Loss: 0.323\n",
      "Training: Epoch 157, Batch 9, Loss: 0.273\n",
      "Training: Epoch 157, Batch 10, Loss: 0.246\n",
      "Training: Epoch 157, Batch 11, Loss: 0.298\n",
      "Training: Epoch 157, Batch 12, Loss: 0.379\n",
      "Training: Epoch 157, Batch 13, Loss: 0.679\n",
      "Training: Epoch 157, Batch 14, Loss: 0.242\n",
      "Training: Epoch 157, Batch 15, Loss: 0.352\n",
      "Training: Epoch 157, Batch 16, Loss: 0.647\n",
      "Training: Epoch 157, Batch 17, Loss: 0.367\n",
      "Training: Epoch 157, Batch 18, Loss: 0.36\n",
      "Training: Epoch 157, Batch 19, Loss: 0.516\n",
      "Training: Epoch 157, Batch 20, Loss: 0.392\n",
      "Training: Epoch 157, Batch 21, Loss: 0.563\n",
      "Training: Epoch 157, Batch 22, Loss: 0.386\n",
      "Training: Epoch 157, Batch 23, Loss: 0.399\n",
      "Training: Epoch 157, Batch 24, Loss: 0.329\n",
      "Training: Epoch 157, Batch 25, Loss: 0.267\n",
      "Training: Epoch 157, Batch 26, Loss: 0.404\n",
      "Training: Epoch 157, Batch 27, Loss: 0.241\n",
      "Training: Epoch 157, Batch 28, Loss: 0.397\n",
      "Training: Epoch 157, Batch 29, Loss: 0.442\n",
      "Val: Epoch 157, Loss: 0.326\n",
      "Training: Epoch 158, Batch 0, Loss: 0.407\n",
      "Training: Epoch 158, Batch 1, Loss: 0.448\n",
      "Training: Epoch 158, Batch 2, Loss: 0.329\n",
      "Training: Epoch 158, Batch 3, Loss: 0.362\n",
      "Training: Epoch 158, Batch 4, Loss: 0.336\n",
      "Training: Epoch 158, Batch 5, Loss: 0.435\n",
      "Training: Epoch 158, Batch 6, Loss: 0.181\n",
      "Training: Epoch 158, Batch 7, Loss: 0.205\n",
      "Training: Epoch 158, Batch 8, Loss: 0.207\n",
      "Training: Epoch 158, Batch 9, Loss: 0.396\n",
      "Training: Epoch 158, Batch 10, Loss: 0.294\n",
      "Training: Epoch 158, Batch 11, Loss: 0.526\n",
      "Training: Epoch 158, Batch 12, Loss: 0.562\n",
      "Training: Epoch 158, Batch 13, Loss: 0.125\n",
      "Training: Epoch 158, Batch 14, Loss: 0.619\n",
      "Training: Epoch 158, Batch 15, Loss: 0.279\n",
      "Training: Epoch 158, Batch 16, Loss: 0.329\n",
      "Training: Epoch 158, Batch 17, Loss: 0.502\n",
      "Training: Epoch 158, Batch 18, Loss: 0.387\n",
      "Training: Epoch 158, Batch 19, Loss: 0.312\n",
      "Training: Epoch 158, Batch 20, Loss: 0.242\n",
      "Training: Epoch 158, Batch 21, Loss: 0.402\n",
      "Training: Epoch 158, Batch 22, Loss: 0.434\n",
      "Training: Epoch 158, Batch 23, Loss: 0.417\n",
      "Training: Epoch 158, Batch 24, Loss: 0.233\n",
      "Training: Epoch 158, Batch 25, Loss: 0.293\n",
      "Training: Epoch 158, Batch 26, Loss: 0.513\n",
      "Training: Epoch 158, Batch 27, Loss: 0.41\n",
      "Training: Epoch 158, Batch 28, Loss: 0.232\n",
      "Training: Epoch 158, Batch 29, Loss: 0.494\n",
      "Val: Epoch 158, Loss: 0.315\n",
      "Training: Epoch 159, Batch 0, Loss: 0.645\n",
      "Training: Epoch 159, Batch 1, Loss: 0.404\n",
      "Training: Epoch 159, Batch 2, Loss: 0.288\n",
      "Training: Epoch 159, Batch 3, Loss: 0.443\n",
      "Training: Epoch 159, Batch 4, Loss: 0.386\n",
      "Training: Epoch 159, Batch 5, Loss: 0.631\n",
      "Training: Epoch 159, Batch 6, Loss: 0.39\n",
      "Training: Epoch 159, Batch 7, Loss: 0.658\n",
      "Training: Epoch 159, Batch 8, Loss: 0.338\n",
      "Training: Epoch 159, Batch 9, Loss: 0.217\n",
      "Training: Epoch 159, Batch 10, Loss: 0.216\n",
      "Training: Epoch 159, Batch 11, Loss: 0.218\n",
      "Training: Epoch 159, Batch 12, Loss: 0.394\n",
      "Training: Epoch 159, Batch 13, Loss: 0.368\n",
      "Training: Epoch 159, Batch 14, Loss: 0.235\n",
      "Training: Epoch 159, Batch 15, Loss: 0.474\n",
      "Training: Epoch 159, Batch 16, Loss: 0.227\n",
      "Training: Epoch 159, Batch 17, Loss: 0.352\n",
      "Training: Epoch 159, Batch 18, Loss: 0.332\n",
      "Training: Epoch 159, Batch 19, Loss: 0.33\n",
      "Training: Epoch 159, Batch 20, Loss: 0.388\n",
      "Training: Epoch 159, Batch 21, Loss: 0.315\n",
      "Training: Epoch 159, Batch 22, Loss: 0.491\n",
      "Training: Epoch 159, Batch 23, Loss: 0.443\n",
      "Training: Epoch 159, Batch 24, Loss: 0.316\n",
      "Training: Epoch 159, Batch 25, Loss: 0.324\n",
      "Training: Epoch 159, Batch 26, Loss: 0.354\n",
      "Training: Epoch 159, Batch 27, Loss: 0.285\n",
      "Training: Epoch 159, Batch 28, Loss: 0.206\n",
      "Training: Epoch 159, Batch 29, Loss: 0.202\n",
      "Val: Epoch 159, Loss: 0.313\n",
      "Training: Epoch 160, Batch 0, Loss: 0.395\n",
      "Training: Epoch 160, Batch 1, Loss: 0.155\n",
      "Training: Epoch 160, Batch 2, Loss: 0.311\n",
      "Training: Epoch 160, Batch 3, Loss: 0.497\n",
      "Training: Epoch 160, Batch 4, Loss: 0.474\n",
      "Training: Epoch 160, Batch 5, Loss: 0.147\n",
      "Training: Epoch 160, Batch 6, Loss: 0.539\n",
      "Training: Epoch 160, Batch 7, Loss: 0.228\n",
      "Training: Epoch 160, Batch 8, Loss: 0.443\n",
      "Training: Epoch 160, Batch 9, Loss: 0.301\n",
      "Training: Epoch 160, Batch 10, Loss: 0.429\n",
      "Training: Epoch 160, Batch 11, Loss: 0.632\n",
      "Training: Epoch 160, Batch 12, Loss: 0.485\n",
      "Training: Epoch 160, Batch 13, Loss: 0.395\n",
      "Training: Epoch 160, Batch 14, Loss: 0.327\n",
      "Training: Epoch 160, Batch 15, Loss: 0.203\n",
      "Training: Epoch 160, Batch 16, Loss: 0.416\n",
      "Training: Epoch 160, Batch 17, Loss: 0.27\n",
      "Training: Epoch 160, Batch 18, Loss: 0.412\n",
      "Training: Epoch 160, Batch 19, Loss: 0.298\n",
      "Training: Epoch 160, Batch 20, Loss: 0.322\n",
      "Training: Epoch 160, Batch 21, Loss: 0.412\n",
      "Training: Epoch 160, Batch 22, Loss: 0.28\n",
      "Training: Epoch 160, Batch 23, Loss: 0.474\n",
      "Training: Epoch 160, Batch 24, Loss: 0.263\n",
      "Training: Epoch 160, Batch 25, Loss: 0.353\n",
      "Training: Epoch 160, Batch 26, Loss: 0.394\n",
      "Training: Epoch 160, Batch 27, Loss: 0.414\n",
      "Training: Epoch 160, Batch 28, Loss: 0.225\n",
      "Training: Epoch 160, Batch 29, Loss: 0.337\n",
      "Val: Epoch 160, Loss: 0.307\n",
      "Training: Epoch 161, Batch 0, Loss: 0.376\n",
      "Training: Epoch 161, Batch 1, Loss: 0.24\n",
      "Training: Epoch 161, Batch 2, Loss: 0.563\n",
      "Training: Epoch 161, Batch 3, Loss: 0.306\n",
      "Training: Epoch 161, Batch 4, Loss: 0.413\n",
      "Training: Epoch 161, Batch 5, Loss: 0.449\n",
      "Training: Epoch 161, Batch 6, Loss: 0.457\n",
      "Training: Epoch 161, Batch 7, Loss: 0.204\n",
      "Training: Epoch 161, Batch 8, Loss: 0.186\n",
      "Training: Epoch 161, Batch 9, Loss: 0.207\n",
      "Training: Epoch 161, Batch 10, Loss: 0.199\n",
      "Training: Epoch 161, Batch 11, Loss: 0.294\n",
      "Training: Epoch 161, Batch 12, Loss: 0.929\n",
      "Training: Epoch 161, Batch 13, Loss: 0.387\n",
      "Training: Epoch 161, Batch 14, Loss: 0.228\n",
      "Training: Epoch 161, Batch 15, Loss: 0.695\n",
      "Training: Epoch 161, Batch 16, Loss: 0.268\n",
      "Training: Epoch 161, Batch 17, Loss: 0.153\n",
      "Training: Epoch 161, Batch 18, Loss: 0.511\n",
      "Training: Epoch 161, Batch 19, Loss: 0.345\n",
      "Training: Epoch 161, Batch 20, Loss: 0.55\n",
      "Training: Epoch 161, Batch 21, Loss: 0.273\n",
      "Training: Epoch 161, Batch 22, Loss: 0.294\n",
      "Training: Epoch 161, Batch 23, Loss: 0.336\n",
      "Training: Epoch 161, Batch 24, Loss: 0.271\n",
      "Training: Epoch 161, Batch 25, Loss: 0.551\n",
      "Training: Epoch 161, Batch 26, Loss: 0.411\n",
      "Training: Epoch 161, Batch 27, Loss: 0.526\n",
      "Training: Epoch 161, Batch 28, Loss: 0.474\n",
      "Training: Epoch 161, Batch 29, Loss: 0.287\n",
      "Val: Epoch 161, Loss: 0.315\n",
      "Training: Epoch 162, Batch 0, Loss: 0.424\n",
      "Training: Epoch 162, Batch 1, Loss: 0.673\n",
      "Training: Epoch 162, Batch 2, Loss: 0.413\n",
      "Training: Epoch 162, Batch 3, Loss: 0.296\n",
      "Training: Epoch 162, Batch 4, Loss: 0.307\n",
      "Training: Epoch 162, Batch 5, Loss: 0.439\n",
      "Training: Epoch 162, Batch 6, Loss: 0.192\n",
      "Training: Epoch 162, Batch 7, Loss: 0.391\n",
      "Training: Epoch 162, Batch 8, Loss: 0.327\n",
      "Training: Epoch 162, Batch 9, Loss: 0.192\n",
      "Training: Epoch 162, Batch 10, Loss: 0.383\n",
      "Training: Epoch 162, Batch 11, Loss: 0.301\n",
      "Training: Epoch 162, Batch 12, Loss: 0.32\n",
      "Training: Epoch 162, Batch 13, Loss: 0.447\n",
      "Training: Epoch 162, Batch 14, Loss: 0.204\n",
      "Training: Epoch 162, Batch 15, Loss: 0.508\n",
      "Training: Epoch 162, Batch 16, Loss: 0.391\n",
      "Training: Epoch 162, Batch 17, Loss: 0.395\n",
      "Training: Epoch 162, Batch 18, Loss: 0.21\n",
      "Training: Epoch 162, Batch 19, Loss: 0.333\n",
      "Training: Epoch 162, Batch 20, Loss: 0.449\n",
      "Training: Epoch 162, Batch 21, Loss: 0.308\n",
      "Training: Epoch 162, Batch 22, Loss: 0.393\n",
      "Training: Epoch 162, Batch 23, Loss: 0.592\n",
      "Training: Epoch 162, Batch 24, Loss: 0.399\n",
      "Training: Epoch 162, Batch 25, Loss: 0.464\n",
      "Training: Epoch 162, Batch 26, Loss: 0.642\n",
      "Training: Epoch 162, Batch 27, Loss: 0.352\n",
      "Training: Epoch 162, Batch 28, Loss: 0.366\n",
      "Training: Epoch 162, Batch 29, Loss: 0.289\n",
      "Val: Epoch 162, Loss: 0.282\n",
      "Training: Epoch 163, Batch 0, Loss: 0.387\n",
      "Training: Epoch 163, Batch 1, Loss: 0.333\n",
      "Training: Epoch 163, Batch 2, Loss: 0.367\n",
      "Training: Epoch 163, Batch 3, Loss: 0.399\n",
      "Training: Epoch 163, Batch 4, Loss: 0.152\n",
      "Training: Epoch 163, Batch 5, Loss: 0.242\n",
      "Training: Epoch 163, Batch 6, Loss: 0.428\n",
      "Training: Epoch 163, Batch 7, Loss: 0.321\n",
      "Training: Epoch 163, Batch 8, Loss: 0.38\n",
      "Training: Epoch 163, Batch 9, Loss: 0.487\n",
      "Training: Epoch 163, Batch 10, Loss: 0.396\n",
      "Training: Epoch 163, Batch 11, Loss: 0.318\n",
      "Training: Epoch 163, Batch 12, Loss: 0.27\n",
      "Training: Epoch 163, Batch 13, Loss: 0.302\n",
      "Training: Epoch 163, Batch 14, Loss: 0.416\n",
      "Training: Epoch 163, Batch 15, Loss: 0.248\n",
      "Training: Epoch 163, Batch 16, Loss: 0.334\n",
      "Training: Epoch 163, Batch 17, Loss: 0.572\n",
      "Training: Epoch 163, Batch 18, Loss: 0.312\n",
      "Training: Epoch 163, Batch 19, Loss: 0.489\n",
      "Training: Epoch 163, Batch 20, Loss: 0.326\n",
      "Training: Epoch 163, Batch 21, Loss: 0.473\n",
      "Training: Epoch 163, Batch 22, Loss: 0.269\n",
      "Training: Epoch 163, Batch 23, Loss: 0.209\n",
      "Training: Epoch 163, Batch 24, Loss: 0.357\n",
      "Training: Epoch 163, Batch 25, Loss: 0.569\n",
      "Training: Epoch 163, Batch 26, Loss: 0.219\n",
      "Training: Epoch 163, Batch 27, Loss: 0.327\n",
      "Training: Epoch 163, Batch 28, Loss: 0.455\n",
      "Training: Epoch 163, Batch 29, Loss: 0.386\n",
      "Val: Epoch 163, Loss: 0.312\n",
      "Training: Epoch 164, Batch 0, Loss: 0.501\n",
      "Training: Epoch 164, Batch 1, Loss: 0.355\n",
      "Training: Epoch 164, Batch 2, Loss: 0.302\n",
      "Training: Epoch 164, Batch 3, Loss: 0.3\n",
      "Training: Epoch 164, Batch 4, Loss: 0.4\n",
      "Training: Epoch 164, Batch 5, Loss: 0.286\n",
      "Training: Epoch 164, Batch 6, Loss: 0.283\n",
      "Training: Epoch 164, Batch 7, Loss: 0.223\n",
      "Training: Epoch 164, Batch 8, Loss: 0.441\n",
      "Training: Epoch 164, Batch 9, Loss: 0.511\n",
      "Training: Epoch 164, Batch 10, Loss: 0.442\n",
      "Training: Epoch 164, Batch 11, Loss: 0.188\n",
      "Training: Epoch 164, Batch 12, Loss: 0.457\n",
      "Training: Epoch 164, Batch 13, Loss: 0.349\n",
      "Training: Epoch 164, Batch 14, Loss: 0.455\n",
      "Training: Epoch 164, Batch 15, Loss: 0.352\n",
      "Training: Epoch 164, Batch 16, Loss: 0.445\n",
      "Training: Epoch 164, Batch 17, Loss: 0.308\n",
      "Training: Epoch 164, Batch 18, Loss: 0.382\n",
      "Training: Epoch 164, Batch 19, Loss: 0.375\n",
      "Training: Epoch 164, Batch 20, Loss: 0.419\n",
      "Training: Epoch 164, Batch 21, Loss: 0.206\n",
      "Training: Epoch 164, Batch 22, Loss: 0.114\n",
      "Training: Epoch 164, Batch 23, Loss: 0.146\n",
      "Training: Epoch 164, Batch 24, Loss: 0.614\n",
      "Training: Epoch 164, Batch 25, Loss: 0.539\n",
      "Training: Epoch 164, Batch 26, Loss: 0.453\n",
      "Training: Epoch 164, Batch 27, Loss: 0.34\n",
      "Training: Epoch 164, Batch 28, Loss: 0.207\n",
      "Training: Epoch 164, Batch 29, Loss: 0.412\n",
      "Val: Epoch 164, Loss: 0.27\n",
      "Training: Epoch 165, Batch 0, Loss: 0.4\n",
      "Training: Epoch 165, Batch 1, Loss: 0.274\n",
      "Training: Epoch 165, Batch 2, Loss: 0.321\n",
      "Training: Epoch 165, Batch 3, Loss: 0.477\n",
      "Training: Epoch 165, Batch 4, Loss: 0.351\n",
      "Training: Epoch 165, Batch 5, Loss: 0.42\n",
      "Training: Epoch 165, Batch 6, Loss: 0.273\n",
      "Training: Epoch 165, Batch 7, Loss: 0.519\n",
      "Training: Epoch 165, Batch 8, Loss: 0.325\n",
      "Training: Epoch 165, Batch 9, Loss: 0.416\n",
      "Training: Epoch 165, Batch 10, Loss: 0.308\n",
      "Training: Epoch 165, Batch 11, Loss: 0.365\n",
      "Training: Epoch 165, Batch 12, Loss: 0.216\n",
      "Training: Epoch 165, Batch 13, Loss: 0.35\n",
      "Training: Epoch 165, Batch 14, Loss: 0.188\n",
      "Training: Epoch 165, Batch 15, Loss: 0.231\n",
      "Training: Epoch 165, Batch 16, Loss: 0.354\n",
      "Training: Epoch 165, Batch 17, Loss: 0.482\n",
      "Training: Epoch 165, Batch 18, Loss: 0.275\n",
      "Training: Epoch 165, Batch 19, Loss: 0.368\n",
      "Training: Epoch 165, Batch 20, Loss: 0.257\n",
      "Training: Epoch 165, Batch 21, Loss: 0.399\n",
      "Training: Epoch 165, Batch 22, Loss: 0.409\n",
      "Training: Epoch 165, Batch 23, Loss: 0.305\n",
      "Training: Epoch 165, Batch 24, Loss: 0.604\n",
      "Training: Epoch 165, Batch 25, Loss: 0.296\n",
      "Training: Epoch 165, Batch 26, Loss: 0.4\n",
      "Training: Epoch 165, Batch 27, Loss: 0.67\n",
      "Training: Epoch 165, Batch 28, Loss: 0.322\n",
      "Training: Epoch 165, Batch 29, Loss: 0.478\n",
      "Val: Epoch 165, Loss: 0.394\n",
      "Training: Epoch 166, Batch 0, Loss: 0.42\n",
      "Training: Epoch 166, Batch 1, Loss: 0.156\n",
      "Training: Epoch 166, Batch 2, Loss: 0.403\n",
      "Training: Epoch 166, Batch 3, Loss: 0.389\n",
      "Training: Epoch 166, Batch 4, Loss: 0.454\n",
      "Training: Epoch 166, Batch 5, Loss: 0.473\n",
      "Training: Epoch 166, Batch 6, Loss: 0.277\n",
      "Training: Epoch 166, Batch 7, Loss: 0.54\n",
      "Training: Epoch 166, Batch 8, Loss: 0.356\n",
      "Training: Epoch 166, Batch 9, Loss: 0.387\n",
      "Training: Epoch 166, Batch 10, Loss: 0.41\n",
      "Training: Epoch 166, Batch 11, Loss: 0.336\n",
      "Training: Epoch 166, Batch 12, Loss: 0.471\n",
      "Training: Epoch 166, Batch 13, Loss: 0.364\n",
      "Training: Epoch 166, Batch 14, Loss: 0.65\n",
      "Training: Epoch 166, Batch 15, Loss: 0.358\n",
      "Training: Epoch 166, Batch 16, Loss: 0.537\n",
      "Training: Epoch 166, Batch 17, Loss: 0.208\n",
      "Training: Epoch 166, Batch 18, Loss: 0.372\n",
      "Training: Epoch 166, Batch 19, Loss: 0.484\n",
      "Training: Epoch 166, Batch 20, Loss: 0.257\n",
      "Training: Epoch 166, Batch 21, Loss: 0.487\n",
      "Training: Epoch 166, Batch 22, Loss: 0.29\n",
      "Training: Epoch 166, Batch 23, Loss: 0.323\n",
      "Training: Epoch 166, Batch 24, Loss: 0.293\n",
      "Training: Epoch 166, Batch 25, Loss: 0.24\n",
      "Training: Epoch 166, Batch 26, Loss: 0.416\n",
      "Training: Epoch 166, Batch 27, Loss: 0.299\n",
      "Training: Epoch 166, Batch 28, Loss: 0.272\n",
      "Training: Epoch 166, Batch 29, Loss: 0.301\n",
      "Val: Epoch 166, Loss: 0.281\n",
      "Training: Epoch 167, Batch 0, Loss: 0.403\n",
      "Training: Epoch 167, Batch 1, Loss: 0.449\n",
      "Training: Epoch 167, Batch 2, Loss: 0.357\n",
      "Training: Epoch 167, Batch 3, Loss: 0.358\n",
      "Training: Epoch 167, Batch 4, Loss: 0.318\n",
      "Training: Epoch 167, Batch 5, Loss: 0.352\n",
      "Training: Epoch 167, Batch 6, Loss: 0.377\n",
      "Training: Epoch 167, Batch 7, Loss: 0.319\n",
      "Training: Epoch 167, Batch 8, Loss: 0.188\n",
      "Training: Epoch 167, Batch 9, Loss: 0.39\n",
      "Training: Epoch 167, Batch 10, Loss: 0.671\n",
      "Training: Epoch 167, Batch 11, Loss: 0.462\n",
      "Training: Epoch 167, Batch 12, Loss: 0.293\n",
      "Training: Epoch 167, Batch 13, Loss: 0.379\n",
      "Training: Epoch 167, Batch 14, Loss: 0.303\n",
      "Training: Epoch 167, Batch 15, Loss: 0.512\n",
      "Training: Epoch 167, Batch 16, Loss: 0.499\n",
      "Training: Epoch 167, Batch 17, Loss: 0.249\n",
      "Training: Epoch 167, Batch 18, Loss: 0.215\n",
      "Training: Epoch 167, Batch 19, Loss: 0.203\n",
      "Training: Epoch 167, Batch 20, Loss: 0.413\n",
      "Training: Epoch 167, Batch 21, Loss: 0.229\n",
      "Training: Epoch 167, Batch 22, Loss: 0.417\n",
      "Training: Epoch 167, Batch 23, Loss: 0.604\n",
      "Training: Epoch 167, Batch 24, Loss: 0.43\n",
      "Training: Epoch 167, Batch 25, Loss: 0.197\n",
      "Training: Epoch 167, Batch 26, Loss: 0.341\n",
      "Training: Epoch 167, Batch 27, Loss: 0.234\n",
      "Training: Epoch 167, Batch 28, Loss: 0.342\n",
      "Training: Epoch 167, Batch 29, Loss: 0.299\n",
      "Val: Epoch 167, Loss: 0.293\n",
      "Training: Epoch 168, Batch 0, Loss: 0.356\n",
      "Training: Epoch 168, Batch 1, Loss: 0.549\n",
      "Training: Epoch 168, Batch 2, Loss: 0.188\n",
      "Training: Epoch 168, Batch 3, Loss: 0.416\n",
      "Training: Epoch 168, Batch 4, Loss: 0.136\n",
      "Training: Epoch 168, Batch 5, Loss: 0.251\n",
      "Training: Epoch 168, Batch 6, Loss: 0.342\n",
      "Training: Epoch 168, Batch 7, Loss: 0.296\n",
      "Training: Epoch 168, Batch 8, Loss: 0.572\n",
      "Training: Epoch 168, Batch 9, Loss: 0.546\n",
      "Training: Epoch 168, Batch 10, Loss: 0.72\n",
      "Training: Epoch 168, Batch 11, Loss: 0.366\n",
      "Training: Epoch 168, Batch 12, Loss: 0.377\n",
      "Training: Epoch 168, Batch 13, Loss: 0.433\n",
      "Training: Epoch 168, Batch 14, Loss: 0.536\n",
      "Training: Epoch 168, Batch 15, Loss: 0.318\n",
      "Training: Epoch 168, Batch 16, Loss: 0.46\n",
      "Training: Epoch 168, Batch 17, Loss: 0.389\n",
      "Training: Epoch 168, Batch 18, Loss: 0.295\n",
      "Training: Epoch 168, Batch 19, Loss: 0.544\n",
      "Training: Epoch 168, Batch 20, Loss: 0.334\n",
      "Training: Epoch 168, Batch 21, Loss: 0.306\n",
      "Training: Epoch 168, Batch 22, Loss: 0.389\n",
      "Training: Epoch 168, Batch 23, Loss: 0.318\n",
      "Training: Epoch 168, Batch 24, Loss: 0.327\n",
      "Training: Epoch 168, Batch 25, Loss: 0.246\n",
      "Training: Epoch 168, Batch 26, Loss: 0.165\n",
      "Training: Epoch 168, Batch 27, Loss: 0.47\n",
      "Training: Epoch 168, Batch 28, Loss: 0.263\n",
      "Training: Epoch 168, Batch 29, Loss: 0.619\n",
      "Val: Epoch 168, Loss: 0.332\n",
      "Training: Epoch 169, Batch 0, Loss: 0.321\n",
      "Training: Epoch 169, Batch 1, Loss: 0.31\n",
      "Training: Epoch 169, Batch 2, Loss: 0.174\n",
      "Training: Epoch 169, Batch 3, Loss: 0.49\n",
      "Training: Epoch 169, Batch 4, Loss: 0.412\n",
      "Training: Epoch 169, Batch 5, Loss: 0.404\n",
      "Training: Epoch 169, Batch 6, Loss: 0.372\n",
      "Training: Epoch 169, Batch 7, Loss: 0.355\n",
      "Training: Epoch 169, Batch 8, Loss: 0.648\n",
      "Training: Epoch 169, Batch 9, Loss: 0.396\n",
      "Training: Epoch 169, Batch 10, Loss: 0.184\n",
      "Training: Epoch 169, Batch 11, Loss: 0.294\n",
      "Training: Epoch 169, Batch 12, Loss: 0.292\n",
      "Training: Epoch 169, Batch 13, Loss: 0.298\n",
      "Training: Epoch 169, Batch 14, Loss: 0.533\n",
      "Training: Epoch 169, Batch 15, Loss: 0.31\n",
      "Training: Epoch 169, Batch 16, Loss: 0.236\n",
      "Training: Epoch 169, Batch 17, Loss: 0.275\n",
      "Training: Epoch 169, Batch 18, Loss: 0.577\n",
      "Training: Epoch 169, Batch 19, Loss: 0.363\n",
      "Training: Epoch 169, Batch 20, Loss: 0.436\n",
      "Training: Epoch 169, Batch 21, Loss: 0.422\n",
      "Training: Epoch 169, Batch 22, Loss: 0.332\n",
      "Training: Epoch 169, Batch 23, Loss: 0.358\n",
      "Training: Epoch 169, Batch 24, Loss: 0.367\n",
      "Training: Epoch 169, Batch 25, Loss: 0.376\n",
      "Training: Epoch 169, Batch 26, Loss: 0.386\n",
      "Training: Epoch 169, Batch 27, Loss: 0.496\n",
      "Training: Epoch 169, Batch 28, Loss: 0.254\n",
      "Training: Epoch 169, Batch 29, Loss: 0.359\n",
      "Val: Epoch 169, Loss: 0.314\n",
      "Training: Epoch 170, Batch 0, Loss: 0.182\n",
      "Training: Epoch 170, Batch 1, Loss: 0.436\n",
      "Training: Epoch 170, Batch 2, Loss: 0.386\n",
      "Training: Epoch 170, Batch 3, Loss: 0.267\n",
      "Training: Epoch 170, Batch 4, Loss: 0.401\n",
      "Training: Epoch 170, Batch 5, Loss: 0.511\n",
      "Training: Epoch 170, Batch 6, Loss: 0.265\n",
      "Training: Epoch 170, Batch 7, Loss: 0.468\n",
      "Training: Epoch 170, Batch 8, Loss: 0.268\n",
      "Training: Epoch 170, Batch 9, Loss: 0.402\n",
      "Training: Epoch 170, Batch 10, Loss: 0.578\n",
      "Training: Epoch 170, Batch 11, Loss: 0.364\n",
      "Training: Epoch 170, Batch 12, Loss: 0.523\n",
      "Training: Epoch 170, Batch 13, Loss: 0.371\n",
      "Training: Epoch 170, Batch 14, Loss: 0.319\n",
      "Training: Epoch 170, Batch 15, Loss: 0.269\n",
      "Training: Epoch 170, Batch 16, Loss: 0.394\n",
      "Training: Epoch 170, Batch 17, Loss: 0.377\n",
      "Training: Epoch 170, Batch 18, Loss: 0.389\n",
      "Training: Epoch 170, Batch 19, Loss: 0.236\n",
      "Training: Epoch 170, Batch 20, Loss: 0.206\n",
      "Training: Epoch 170, Batch 21, Loss: 0.428\n",
      "Training: Epoch 170, Batch 22, Loss: 0.289\n",
      "Training: Epoch 170, Batch 23, Loss: 0.464\n",
      "Training: Epoch 170, Batch 24, Loss: 0.46\n",
      "Training: Epoch 170, Batch 25, Loss: 0.389\n",
      "Training: Epoch 170, Batch 26, Loss: 0.308\n",
      "Training: Epoch 170, Batch 27, Loss: 0.372\n",
      "Training: Epoch 170, Batch 28, Loss: 0.333\n",
      "Training: Epoch 170, Batch 29, Loss: 0.194\n",
      "Val: Epoch 170, Loss: 0.295\n",
      "Training: Epoch 171, Batch 0, Loss: 0.441\n",
      "Training: Epoch 171, Batch 1, Loss: 0.285\n",
      "Training: Epoch 171, Batch 2, Loss: 0.43\n",
      "Training: Epoch 171, Batch 3, Loss: 0.303\n",
      "Training: Epoch 171, Batch 4, Loss: 0.292\n",
      "Training: Epoch 171, Batch 5, Loss: 0.205\n",
      "Training: Epoch 171, Batch 6, Loss: 0.37\n",
      "Training: Epoch 171, Batch 7, Loss: 0.751\n",
      "Training: Epoch 171, Batch 8, Loss: 0.414\n",
      "Training: Epoch 171, Batch 9, Loss: 0.384\n",
      "Training: Epoch 171, Batch 10, Loss: 0.25\n",
      "Training: Epoch 171, Batch 11, Loss: 0.348\n",
      "Training: Epoch 171, Batch 12, Loss: 0.567\n",
      "Training: Epoch 171, Batch 13, Loss: 0.448\n",
      "Training: Epoch 171, Batch 14, Loss: 0.377\n",
      "Training: Epoch 171, Batch 15, Loss: 0.392\n",
      "Training: Epoch 171, Batch 16, Loss: 0.236\n",
      "Training: Epoch 171, Batch 17, Loss: 0.48\n",
      "Training: Epoch 171, Batch 18, Loss: 0.454\n",
      "Training: Epoch 171, Batch 19, Loss: 0.346\n",
      "Training: Epoch 171, Batch 20, Loss: 0.33\n",
      "Training: Epoch 171, Batch 21, Loss: 0.363\n",
      "Training: Epoch 171, Batch 22, Loss: 0.325\n",
      "Training: Epoch 171, Batch 23, Loss: 0.337\n",
      "Training: Epoch 171, Batch 24, Loss: 0.345\n",
      "Training: Epoch 171, Batch 25, Loss: 0.198\n",
      "Training: Epoch 171, Batch 26, Loss: 0.296\n",
      "Training: Epoch 171, Batch 27, Loss: 0.478\n",
      "Training: Epoch 171, Batch 28, Loss: 0.292\n",
      "Training: Epoch 171, Batch 29, Loss: 0.217\n",
      "Val: Epoch 171, Loss: 0.29\n",
      "Training: Epoch 172, Batch 0, Loss: 0.554\n",
      "Training: Epoch 172, Batch 1, Loss: 0.386\n",
      "Training: Epoch 172, Batch 2, Loss: 0.413\n",
      "Training: Epoch 172, Batch 3, Loss: 0.284\n",
      "Training: Epoch 172, Batch 4, Loss: 0.242\n",
      "Training: Epoch 172, Batch 5, Loss: 0.255\n",
      "Training: Epoch 172, Batch 6, Loss: 0.119\n",
      "Training: Epoch 172, Batch 7, Loss: 0.401\n",
      "Training: Epoch 172, Batch 8, Loss: 0.257\n",
      "Training: Epoch 172, Batch 9, Loss: 0.305\n",
      "Training: Epoch 172, Batch 10, Loss: 0.42\n",
      "Training: Epoch 172, Batch 11, Loss: 0.178\n",
      "Training: Epoch 172, Batch 12, Loss: 0.23\n",
      "Training: Epoch 172, Batch 13, Loss: 0.576\n",
      "Training: Epoch 172, Batch 14, Loss: 0.432\n",
      "Training: Epoch 172, Batch 15, Loss: 0.49\n",
      "Training: Epoch 172, Batch 16, Loss: 0.282\n",
      "Training: Epoch 172, Batch 17, Loss: 0.368\n",
      "Training: Epoch 172, Batch 18, Loss: 0.501\n",
      "Training: Epoch 172, Batch 19, Loss: 0.389\n",
      "Training: Epoch 172, Batch 20, Loss: 0.446\n",
      "Training: Epoch 172, Batch 21, Loss: 0.34\n",
      "Training: Epoch 172, Batch 22, Loss: 0.356\n",
      "Training: Epoch 172, Batch 23, Loss: 0.305\n",
      "Training: Epoch 172, Batch 24, Loss: 0.394\n",
      "Training: Epoch 172, Batch 25, Loss: 0.215\n",
      "Training: Epoch 172, Batch 26, Loss: 0.267\n",
      "Training: Epoch 172, Batch 27, Loss: 0.23\n",
      "Training: Epoch 172, Batch 28, Loss: 0.744\n",
      "Training: Epoch 172, Batch 29, Loss: 0.576\n",
      "Val: Epoch 172, Loss: 0.299\n",
      "Training: Epoch 173, Batch 0, Loss: 0.282\n",
      "Training: Epoch 173, Batch 1, Loss: 0.139\n",
      "Training: Epoch 173, Batch 2, Loss: 0.546\n",
      "Training: Epoch 173, Batch 3, Loss: 0.397\n",
      "Training: Epoch 173, Batch 4, Loss: 0.322\n",
      "Training: Epoch 173, Batch 5, Loss: 0.389\n",
      "Training: Epoch 173, Batch 6, Loss: 0.414\n",
      "Training: Epoch 173, Batch 7, Loss: 0.329\n",
      "Training: Epoch 173, Batch 8, Loss: 0.437\n",
      "Training: Epoch 173, Batch 9, Loss: 0.39\n",
      "Training: Epoch 173, Batch 10, Loss: 0.422\n",
      "Training: Epoch 173, Batch 11, Loss: 0.382\n",
      "Training: Epoch 173, Batch 12, Loss: 0.227\n",
      "Training: Epoch 173, Batch 13, Loss: 0.437\n",
      "Training: Epoch 173, Batch 14, Loss: 0.484\n",
      "Training: Epoch 173, Batch 15, Loss: 0.361\n",
      "Training: Epoch 173, Batch 16, Loss: 0.38\n",
      "Training: Epoch 173, Batch 17, Loss: 0.129\n",
      "Training: Epoch 173, Batch 18, Loss: 0.492\n",
      "Training: Epoch 173, Batch 19, Loss: 0.445\n",
      "Training: Epoch 173, Batch 20, Loss: 0.444\n",
      "Training: Epoch 173, Batch 21, Loss: 0.511\n",
      "Training: Epoch 173, Batch 22, Loss: 0.331\n",
      "Training: Epoch 173, Batch 23, Loss: 0.324\n",
      "Training: Epoch 173, Batch 24, Loss: 0.153\n",
      "Training: Epoch 173, Batch 25, Loss: 0.271\n",
      "Training: Epoch 173, Batch 26, Loss: 0.34\n",
      "Training: Epoch 173, Batch 27, Loss: 0.293\n",
      "Training: Epoch 173, Batch 28, Loss: 0.25\n",
      "Training: Epoch 173, Batch 29, Loss: 0.311\n",
      "Val: Epoch 173, Loss: 0.287\n",
      "Training: Epoch 174, Batch 0, Loss: 0.273\n",
      "Training: Epoch 174, Batch 1, Loss: 0.262\n",
      "Training: Epoch 174, Batch 2, Loss: 0.381\n",
      "Training: Epoch 174, Batch 3, Loss: 0.475\n",
      "Training: Epoch 174, Batch 4, Loss: 0.37\n",
      "Training: Epoch 174, Batch 5, Loss: 0.427\n",
      "Training: Epoch 174, Batch 6, Loss: 0.412\n",
      "Training: Epoch 174, Batch 7, Loss: 0.497\n",
      "Training: Epoch 174, Batch 8, Loss: 0.418\n",
      "Training: Epoch 174, Batch 9, Loss: 0.299\n",
      "Training: Epoch 174, Batch 10, Loss: 0.341\n",
      "Training: Epoch 174, Batch 11, Loss: 0.391\n",
      "Training: Epoch 174, Batch 12, Loss: 0.189\n",
      "Training: Epoch 174, Batch 13, Loss: 0.555\n",
      "Training: Epoch 174, Batch 14, Loss: 0.582\n",
      "Training: Epoch 174, Batch 15, Loss: 0.302\n",
      "Training: Epoch 174, Batch 16, Loss: 0.348\n",
      "Training: Epoch 174, Batch 17, Loss: 0.474\n",
      "Training: Epoch 174, Batch 18, Loss: 0.195\n",
      "Training: Epoch 174, Batch 19, Loss: 0.238\n",
      "Training: Epoch 174, Batch 20, Loss: 0.437\n",
      "Training: Epoch 174, Batch 21, Loss: 0.468\n",
      "Training: Epoch 174, Batch 22, Loss: 0.34\n",
      "Training: Epoch 174, Batch 23, Loss: 0.332\n",
      "Training: Epoch 174, Batch 24, Loss: 0.169\n",
      "Training: Epoch 174, Batch 25, Loss: 0.295\n",
      "Training: Epoch 174, Batch 26, Loss: 0.227\n",
      "Training: Epoch 174, Batch 27, Loss: 0.352\n",
      "Training: Epoch 174, Batch 28, Loss: 0.204\n",
      "Training: Epoch 174, Batch 29, Loss: 0.303\n",
      "Val: Epoch 174, Loss: 0.316\n",
      "Training: Epoch 175, Batch 0, Loss: 0.342\n",
      "Training: Epoch 175, Batch 1, Loss: 0.392\n",
      "Training: Epoch 175, Batch 2, Loss: 0.381\n",
      "Training: Epoch 175, Batch 3, Loss: 0.318\n",
      "Training: Epoch 175, Batch 4, Loss: 0.211\n",
      "Training: Epoch 175, Batch 5, Loss: 0.297\n",
      "Training: Epoch 175, Batch 6, Loss: 0.403\n",
      "Training: Epoch 175, Batch 7, Loss: 0.452\n",
      "Training: Epoch 175, Batch 8, Loss: 0.473\n",
      "Training: Epoch 175, Batch 9, Loss: 0.272\n",
      "Training: Epoch 175, Batch 10, Loss: 0.123\n",
      "Training: Epoch 175, Batch 11, Loss: 0.475\n",
      "Training: Epoch 175, Batch 12, Loss: 0.187\n",
      "Training: Epoch 175, Batch 13, Loss: 0.21\n",
      "Training: Epoch 175, Batch 14, Loss: 0.219\n",
      "Training: Epoch 175, Batch 15, Loss: 0.205\n",
      "Training: Epoch 175, Batch 16, Loss: 0.45\n",
      "Training: Epoch 175, Batch 17, Loss: 0.316\n",
      "Training: Epoch 175, Batch 18, Loss: 0.484\n",
      "Training: Epoch 175, Batch 19, Loss: 0.241\n",
      "Training: Epoch 175, Batch 20, Loss: 0.596\n",
      "Training: Epoch 175, Batch 21, Loss: 0.333\n",
      "Training: Epoch 175, Batch 22, Loss: 0.407\n",
      "Training: Epoch 175, Batch 23, Loss: 0.2\n",
      "Training: Epoch 175, Batch 24, Loss: 0.484\n",
      "Training: Epoch 175, Batch 25, Loss: 0.366\n",
      "Training: Epoch 175, Batch 26, Loss: 0.475\n",
      "Training: Epoch 175, Batch 27, Loss: 0.372\n",
      "Training: Epoch 175, Batch 28, Loss: 0.358\n",
      "Training: Epoch 175, Batch 29, Loss: 0.389\n",
      "Val: Epoch 175, Loss: 0.294\n",
      "Training: Epoch 176, Batch 0, Loss: 0.375\n",
      "Training: Epoch 176, Batch 1, Loss: 0.32\n",
      "Training: Epoch 176, Batch 2, Loss: 0.489\n",
      "Training: Epoch 176, Batch 3, Loss: 0.533\n",
      "Training: Epoch 176, Batch 4, Loss: 0.481\n",
      "Training: Epoch 176, Batch 5, Loss: 0.479\n",
      "Training: Epoch 176, Batch 6, Loss: 0.389\n",
      "Training: Epoch 176, Batch 7, Loss: 0.362\n",
      "Training: Epoch 176, Batch 8, Loss: 0.133\n",
      "Training: Epoch 176, Batch 9, Loss: 0.343\n",
      "Training: Epoch 176, Batch 10, Loss: 0.396\n",
      "Training: Epoch 176, Batch 11, Loss: 0.252\n",
      "Training: Epoch 176, Batch 12, Loss: 0.395\n",
      "Training: Epoch 176, Batch 13, Loss: 0.24\n",
      "Training: Epoch 176, Batch 14, Loss: 0.364\n",
      "Training: Epoch 176, Batch 15, Loss: 0.359\n",
      "Training: Epoch 176, Batch 16, Loss: 0.174\n",
      "Training: Epoch 176, Batch 17, Loss: 0.236\n",
      "Training: Epoch 176, Batch 18, Loss: 0.241\n",
      "Training: Epoch 176, Batch 19, Loss: 0.281\n",
      "Training: Epoch 176, Batch 20, Loss: 0.505\n",
      "Training: Epoch 176, Batch 21, Loss: 0.44\n",
      "Training: Epoch 176, Batch 22, Loss: 0.318\n",
      "Training: Epoch 176, Batch 23, Loss: 0.302\n",
      "Training: Epoch 176, Batch 24, Loss: 0.38\n",
      "Training: Epoch 176, Batch 25, Loss: 0.358\n",
      "Training: Epoch 176, Batch 26, Loss: 0.329\n",
      "Training: Epoch 176, Batch 27, Loss: 0.384\n",
      "Training: Epoch 176, Batch 28, Loss: 0.242\n",
      "Training: Epoch 176, Batch 29, Loss: 0.273\n",
      "Val: Epoch 176, Loss: 0.257\n",
      "Training: Epoch 177, Batch 0, Loss: 0.418\n",
      "Training: Epoch 177, Batch 1, Loss: 0.36\n",
      "Training: Epoch 177, Batch 2, Loss: 0.232\n",
      "Training: Epoch 177, Batch 3, Loss: 0.381\n",
      "Training: Epoch 177, Batch 4, Loss: 0.421\n",
      "Training: Epoch 177, Batch 5, Loss: 0.471\n",
      "Training: Epoch 177, Batch 6, Loss: 0.417\n",
      "Training: Epoch 177, Batch 7, Loss: 0.414\n",
      "Training: Epoch 177, Batch 8, Loss: 0.327\n",
      "Training: Epoch 177, Batch 9, Loss: 0.241\n",
      "Training: Epoch 177, Batch 10, Loss: 0.272\n",
      "Training: Epoch 177, Batch 11, Loss: 0.316\n",
      "Training: Epoch 177, Batch 12, Loss: 0.364\n",
      "Training: Epoch 177, Batch 13, Loss: 0.16\n",
      "Training: Epoch 177, Batch 14, Loss: 0.238\n",
      "Training: Epoch 177, Batch 15, Loss: 0.348\n",
      "Training: Epoch 177, Batch 16, Loss: 0.215\n",
      "Training: Epoch 177, Batch 17, Loss: 0.337\n",
      "Training: Epoch 177, Batch 18, Loss: 0.466\n",
      "Training: Epoch 177, Batch 19, Loss: 0.123\n",
      "Training: Epoch 177, Batch 20, Loss: 0.439\n",
      "Training: Epoch 177, Batch 21, Loss: 0.424\n",
      "Training: Epoch 177, Batch 22, Loss: 0.322\n",
      "Training: Epoch 177, Batch 23, Loss: 0.291\n",
      "Training: Epoch 177, Batch 24, Loss: 0.344\n",
      "Training: Epoch 177, Batch 25, Loss: 0.206\n",
      "Training: Epoch 177, Batch 26, Loss: 0.427\n",
      "Training: Epoch 177, Batch 27, Loss: 0.52\n",
      "Training: Epoch 177, Batch 28, Loss: 0.468\n",
      "Training: Epoch 177, Batch 29, Loss: 0.152\n",
      "Val: Epoch 177, Loss: 0.359\n",
      "Training: Epoch 178, Batch 0, Loss: 0.365\n",
      "Training: Epoch 178, Batch 1, Loss: 0.371\n",
      "Training: Epoch 178, Batch 2, Loss: 0.431\n",
      "Training: Epoch 178, Batch 3, Loss: 0.488\n",
      "Training: Epoch 178, Batch 4, Loss: 0.408\n",
      "Training: Epoch 178, Batch 5, Loss: 0.381\n",
      "Training: Epoch 178, Batch 6, Loss: 0.27\n",
      "Training: Epoch 178, Batch 7, Loss: 0.405\n",
      "Training: Epoch 178, Batch 8, Loss: 0.372\n",
      "Training: Epoch 178, Batch 9, Loss: 0.406\n",
      "Training: Epoch 178, Batch 10, Loss: 0.363\n",
      "Training: Epoch 178, Batch 11, Loss: 0.378\n",
      "Training: Epoch 178, Batch 12, Loss: 0.301\n",
      "Training: Epoch 178, Batch 13, Loss: 0.27\n",
      "Training: Epoch 178, Batch 14, Loss: 0.338\n",
      "Training: Epoch 178, Batch 15, Loss: 0.621\n",
      "Training: Epoch 178, Batch 16, Loss: 0.284\n",
      "Training: Epoch 178, Batch 17, Loss: 0.214\n",
      "Training: Epoch 178, Batch 18, Loss: 0.336\n",
      "Training: Epoch 178, Batch 19, Loss: 0.298\n",
      "Training: Epoch 178, Batch 20, Loss: 0.439\n",
      "Training: Epoch 178, Batch 21, Loss: 0.314\n",
      "Training: Epoch 178, Batch 22, Loss: 0.43\n",
      "Training: Epoch 178, Batch 23, Loss: 0.204\n",
      "Training: Epoch 178, Batch 24, Loss: 0.14\n",
      "Training: Epoch 178, Batch 25, Loss: 0.314\n",
      "Training: Epoch 178, Batch 26, Loss: 0.211\n",
      "Training: Epoch 178, Batch 27, Loss: 0.421\n",
      "Training: Epoch 178, Batch 28, Loss: 0.449\n",
      "Training: Epoch 178, Batch 29, Loss: 0.281\n",
      "Val: Epoch 178, Loss: 0.309\n",
      "Training: Epoch 179, Batch 0, Loss: 0.456\n",
      "Training: Epoch 179, Batch 1, Loss: 0.328\n",
      "Training: Epoch 179, Batch 2, Loss: 0.345\n",
      "Training: Epoch 179, Batch 3, Loss: 0.238\n",
      "Training: Epoch 179, Batch 4, Loss: 0.793\n",
      "Training: Epoch 179, Batch 5, Loss: 0.181\n",
      "Training: Epoch 179, Batch 6, Loss: 0.413\n",
      "Training: Epoch 179, Batch 7, Loss: 0.22\n",
      "Training: Epoch 179, Batch 8, Loss: 0.283\n",
      "Training: Epoch 179, Batch 9, Loss: 0.415\n",
      "Training: Epoch 179, Batch 10, Loss: 0.489\n",
      "Training: Epoch 179, Batch 11, Loss: 0.16\n",
      "Training: Epoch 179, Batch 12, Loss: 0.344\n",
      "Training: Epoch 179, Batch 13, Loss: 0.446\n",
      "Training: Epoch 179, Batch 14, Loss: 0.429\n",
      "Training: Epoch 179, Batch 15, Loss: 0.315\n",
      "Training: Epoch 179, Batch 16, Loss: 0.467\n",
      "Training: Epoch 179, Batch 17, Loss: 0.345\n",
      "Training: Epoch 179, Batch 18, Loss: 0.4\n",
      "Training: Epoch 179, Batch 19, Loss: 0.279\n",
      "Training: Epoch 179, Batch 20, Loss: 0.316\n",
      "Training: Epoch 179, Batch 21, Loss: 0.502\n",
      "Training: Epoch 179, Batch 22, Loss: 0.431\n",
      "Training: Epoch 179, Batch 23, Loss: 0.366\n",
      "Training: Epoch 179, Batch 24, Loss: 0.366\n",
      "Training: Epoch 179, Batch 25, Loss: 0.409\n",
      "Training: Epoch 179, Batch 26, Loss: 0.416\n",
      "Training: Epoch 179, Batch 27, Loss: 0.277\n",
      "Training: Epoch 179, Batch 28, Loss: 0.514\n",
      "Training: Epoch 179, Batch 29, Loss: 0.206\n",
      "Val: Epoch 179, Loss: 0.275\n",
      "Training: Epoch 180, Batch 0, Loss: 0.406\n",
      "Training: Epoch 180, Batch 1, Loss: 0.112\n",
      "Training: Epoch 180, Batch 2, Loss: 0.276\n",
      "Training: Epoch 180, Batch 3, Loss: 0.306\n",
      "Training: Epoch 180, Batch 4, Loss: 0.251\n",
      "Training: Epoch 180, Batch 5, Loss: 0.362\n",
      "Training: Epoch 180, Batch 6, Loss: 0.284\n",
      "Training: Epoch 180, Batch 7, Loss: 0.328\n",
      "Training: Epoch 180, Batch 8, Loss: 0.484\n",
      "Training: Epoch 180, Batch 9, Loss: 0.411\n",
      "Training: Epoch 180, Batch 10, Loss: 0.356\n",
      "Training: Epoch 180, Batch 11, Loss: 0.394\n",
      "Training: Epoch 180, Batch 12, Loss: 0.424\n",
      "Training: Epoch 180, Batch 13, Loss: 0.27\n",
      "Training: Epoch 180, Batch 14, Loss: 0.273\n",
      "Training: Epoch 180, Batch 15, Loss: 0.433\n",
      "Training: Epoch 180, Batch 16, Loss: 0.456\n",
      "Training: Epoch 180, Batch 17, Loss: 0.202\n",
      "Training: Epoch 180, Batch 18, Loss: 0.436\n",
      "Training: Epoch 180, Batch 19, Loss: 0.327\n",
      "Training: Epoch 180, Batch 20, Loss: 0.193\n",
      "Training: Epoch 180, Batch 21, Loss: 0.345\n",
      "Training: Epoch 180, Batch 22, Loss: 0.341\n",
      "Training: Epoch 180, Batch 23, Loss: 0.371\n",
      "Training: Epoch 180, Batch 24, Loss: 0.392\n",
      "Training: Epoch 180, Batch 25, Loss: 0.435\n",
      "Training: Epoch 180, Batch 26, Loss: 0.414\n",
      "Training: Epoch 180, Batch 27, Loss: 0.216\n",
      "Training: Epoch 180, Batch 28, Loss: 0.498\n",
      "Training: Epoch 180, Batch 29, Loss: 0.366\n",
      "Val: Epoch 180, Loss: 0.356\n",
      "Training: Epoch 181, Batch 0, Loss: 0.261\n",
      "Training: Epoch 181, Batch 1, Loss: 0.237\n",
      "Training: Epoch 181, Batch 2, Loss: 0.286\n",
      "Training: Epoch 181, Batch 3, Loss: 0.287\n",
      "Training: Epoch 181, Batch 4, Loss: 0.339\n",
      "Training: Epoch 181, Batch 5, Loss: 0.215\n",
      "Training: Epoch 181, Batch 6, Loss: 0.333\n",
      "Training: Epoch 181, Batch 7, Loss: 0.324\n",
      "Training: Epoch 181, Batch 8, Loss: 0.482\n",
      "Training: Epoch 181, Batch 9, Loss: 0.319\n",
      "Training: Epoch 181, Batch 10, Loss: 0.293\n",
      "Training: Epoch 181, Batch 11, Loss: 0.364\n",
      "Training: Epoch 181, Batch 12, Loss: 0.266\n",
      "Training: Epoch 181, Batch 13, Loss: 0.28\n",
      "Training: Epoch 181, Batch 14, Loss: 0.56\n",
      "Training: Epoch 181, Batch 15, Loss: 0.248\n",
      "Training: Epoch 181, Batch 16, Loss: 0.357\n",
      "Training: Epoch 181, Batch 17, Loss: 0.44\n",
      "Training: Epoch 181, Batch 18, Loss: 0.338\n",
      "Training: Epoch 181, Batch 19, Loss: 0.257\n",
      "Training: Epoch 181, Batch 20, Loss: 0.538\n",
      "Training: Epoch 181, Batch 21, Loss: 0.249\n",
      "Training: Epoch 181, Batch 22, Loss: 0.227\n",
      "Training: Epoch 181, Batch 23, Loss: 0.371\n",
      "Training: Epoch 181, Batch 24, Loss: 0.351\n",
      "Training: Epoch 181, Batch 25, Loss: 0.364\n",
      "Training: Epoch 181, Batch 26, Loss: 0.284\n",
      "Training: Epoch 181, Batch 27, Loss: 0.46\n",
      "Training: Epoch 181, Batch 28, Loss: 0.325\n",
      "Training: Epoch 181, Batch 29, Loss: 0.381\n",
      "Val: Epoch 181, Loss: 0.284\n",
      "Training: Epoch 182, Batch 0, Loss: 0.359\n",
      "Training: Epoch 182, Batch 1, Loss: 0.129\n",
      "Training: Epoch 182, Batch 2, Loss: 0.253\n",
      "Training: Epoch 182, Batch 3, Loss: 0.198\n",
      "Training: Epoch 182, Batch 4, Loss: 0.539\n",
      "Training: Epoch 182, Batch 5, Loss: 0.588\n",
      "Training: Epoch 182, Batch 6, Loss: 0.321\n",
      "Training: Epoch 182, Batch 7, Loss: 0.354\n",
      "Training: Epoch 182, Batch 8, Loss: 0.412\n",
      "Training: Epoch 182, Batch 9, Loss: 0.483\n",
      "Training: Epoch 182, Batch 10, Loss: 0.396\n",
      "Training: Epoch 182, Batch 11, Loss: 0.283\n",
      "Training: Epoch 182, Batch 12, Loss: 0.335\n",
      "Training: Epoch 182, Batch 13, Loss: 0.318\n",
      "Training: Epoch 182, Batch 14, Loss: 0.245\n",
      "Training: Epoch 182, Batch 15, Loss: 0.216\n",
      "Training: Epoch 182, Batch 16, Loss: 0.189\n",
      "Training: Epoch 182, Batch 17, Loss: 0.425\n",
      "Training: Epoch 182, Batch 18, Loss: 0.357\n",
      "Training: Epoch 182, Batch 19, Loss: 0.338\n",
      "Training: Epoch 182, Batch 20, Loss: 0.348\n",
      "Training: Epoch 182, Batch 21, Loss: 0.414\n",
      "Training: Epoch 182, Batch 22, Loss: 0.261\n",
      "Training: Epoch 182, Batch 23, Loss: 0.332\n",
      "Training: Epoch 182, Batch 24, Loss: 0.132\n",
      "Training: Epoch 182, Batch 25, Loss: 0.128\n",
      "Training: Epoch 182, Batch 26, Loss: 0.476\n",
      "Training: Epoch 182, Batch 27, Loss: 0.462\n",
      "Training: Epoch 182, Batch 28, Loss: 0.161\n",
      "Training: Epoch 182, Batch 29, Loss: 0.404\n",
      "Val: Epoch 182, Loss: 0.295\n",
      "Training: Epoch 183, Batch 0, Loss: 0.227\n",
      "Training: Epoch 183, Batch 1, Loss: 0.412\n",
      "Training: Epoch 183, Batch 2, Loss: 0.304\n",
      "Training: Epoch 183, Batch 3, Loss: 0.314\n",
      "Training: Epoch 183, Batch 4, Loss: 0.326\n",
      "Training: Epoch 183, Batch 5, Loss: 0.331\n",
      "Training: Epoch 183, Batch 6, Loss: 0.478\n",
      "Training: Epoch 183, Batch 7, Loss: 0.223\n",
      "Training: Epoch 183, Batch 8, Loss: 0.315\n",
      "Training: Epoch 183, Batch 9, Loss: 0.433\n",
      "Training: Epoch 183, Batch 10, Loss: 0.33\n",
      "Training: Epoch 183, Batch 11, Loss: 0.598\n",
      "Training: Epoch 183, Batch 12, Loss: 0.451\n",
      "Training: Epoch 183, Batch 13, Loss: 0.185\n",
      "Training: Epoch 183, Batch 14, Loss: 0.423\n",
      "Training: Epoch 183, Batch 15, Loss: 0.255\n",
      "Training: Epoch 183, Batch 16, Loss: 0.217\n",
      "Training: Epoch 183, Batch 17, Loss: 0.287\n",
      "Training: Epoch 183, Batch 18, Loss: 0.415\n",
      "Training: Epoch 183, Batch 19, Loss: 0.223\n",
      "Training: Epoch 183, Batch 20, Loss: 0.223\n",
      "Training: Epoch 183, Batch 21, Loss: 0.505\n",
      "Training: Epoch 183, Batch 22, Loss: 0.244\n",
      "Training: Epoch 183, Batch 23, Loss: 0.255\n",
      "Training: Epoch 183, Batch 24, Loss: 0.331\n",
      "Training: Epoch 183, Batch 25, Loss: 0.477\n",
      "Training: Epoch 183, Batch 26, Loss: 0.329\n",
      "Training: Epoch 183, Batch 27, Loss: 0.247\n",
      "Training: Epoch 183, Batch 28, Loss: 0.359\n",
      "Training: Epoch 183, Batch 29, Loss: 0.45\n",
      "Val: Epoch 183, Loss: 0.307\n",
      "Training: Epoch 184, Batch 0, Loss: 0.193\n",
      "Training: Epoch 184, Batch 1, Loss: 0.362\n",
      "Training: Epoch 184, Batch 2, Loss: 0.316\n",
      "Training: Epoch 184, Batch 3, Loss: 0.491\n",
      "Training: Epoch 184, Batch 4, Loss: 0.429\n",
      "Training: Epoch 184, Batch 5, Loss: 0.39\n",
      "Training: Epoch 184, Batch 6, Loss: 0.133\n",
      "Training: Epoch 184, Batch 7, Loss: 0.332\n",
      "Training: Epoch 184, Batch 8, Loss: 0.426\n",
      "Training: Epoch 184, Batch 9, Loss: 0.28\n",
      "Training: Epoch 184, Batch 10, Loss: 0.196\n",
      "Training: Epoch 184, Batch 11, Loss: 0.332\n",
      "Training: Epoch 184, Batch 12, Loss: 0.438\n",
      "Training: Epoch 184, Batch 13, Loss: 0.283\n",
      "Training: Epoch 184, Batch 14, Loss: 0.262\n",
      "Training: Epoch 184, Batch 15, Loss: 0.443\n",
      "Training: Epoch 184, Batch 16, Loss: 0.292\n",
      "Training: Epoch 184, Batch 17, Loss: 0.305\n",
      "Training: Epoch 184, Batch 18, Loss: 0.367\n",
      "Training: Epoch 184, Batch 19, Loss: 0.369\n",
      "Training: Epoch 184, Batch 20, Loss: 0.674\n",
      "Training: Epoch 184, Batch 21, Loss: 0.302\n",
      "Training: Epoch 184, Batch 22, Loss: 0.367\n",
      "Training: Epoch 184, Batch 23, Loss: 0.348\n",
      "Training: Epoch 184, Batch 24, Loss: 0.356\n",
      "Training: Epoch 184, Batch 25, Loss: 0.411\n",
      "Training: Epoch 184, Batch 26, Loss: 0.39\n",
      "Training: Epoch 184, Batch 27, Loss: 0.293\n",
      "Training: Epoch 184, Batch 28, Loss: 0.274\n",
      "Training: Epoch 184, Batch 29, Loss: 0.285\n",
      "Val: Epoch 184, Loss: 0.276\n",
      "Training: Epoch 185, Batch 0, Loss: 0.273\n",
      "Training: Epoch 185, Batch 1, Loss: 0.421\n",
      "Training: Epoch 185, Batch 2, Loss: 0.393\n",
      "Training: Epoch 185, Batch 3, Loss: 0.496\n",
      "Training: Epoch 185, Batch 4, Loss: 0.507\n",
      "Training: Epoch 185, Batch 5, Loss: 0.344\n",
      "Training: Epoch 185, Batch 6, Loss: 0.329\n",
      "Training: Epoch 185, Batch 7, Loss: 0.349\n",
      "Training: Epoch 185, Batch 8, Loss: 0.446\n",
      "Training: Epoch 185, Batch 9, Loss: 0.209\n",
      "Training: Epoch 185, Batch 10, Loss: 0.202\n",
      "Training: Epoch 185, Batch 11, Loss: 0.479\n",
      "Training: Epoch 185, Batch 12, Loss: 0.203\n",
      "Training: Epoch 185, Batch 13, Loss: 0.205\n",
      "Training: Epoch 185, Batch 14, Loss: 0.353\n",
      "Training: Epoch 185, Batch 15, Loss: 0.418\n",
      "Training: Epoch 185, Batch 16, Loss: 0.574\n",
      "Training: Epoch 185, Batch 17, Loss: 0.229\n",
      "Training: Epoch 185, Batch 18, Loss: 0.354\n",
      "Training: Epoch 185, Batch 19, Loss: 0.315\n",
      "Training: Epoch 185, Batch 20, Loss: 0.337\n",
      "Training: Epoch 185, Batch 21, Loss: 0.462\n",
      "Training: Epoch 185, Batch 22, Loss: 0.263\n",
      "Training: Epoch 185, Batch 23, Loss: 0.298\n",
      "Training: Epoch 185, Batch 24, Loss: 0.265\n",
      "Training: Epoch 185, Batch 25, Loss: 0.361\n",
      "Training: Epoch 185, Batch 26, Loss: 0.314\n",
      "Training: Epoch 185, Batch 27, Loss: 0.204\n",
      "Training: Epoch 185, Batch 28, Loss: 0.434\n",
      "Training: Epoch 185, Batch 29, Loss: 0.435\n",
      "Val: Epoch 185, Loss: 0.285\n",
      "Training: Epoch 186, Batch 0, Loss: 0.231\n",
      "Training: Epoch 186, Batch 1, Loss: 0.216\n",
      "Training: Epoch 186, Batch 2, Loss: 0.331\n",
      "Training: Epoch 186, Batch 3, Loss: 0.407\n",
      "Training: Epoch 186, Batch 4, Loss: 0.294\n",
      "Training: Epoch 186, Batch 5, Loss: 0.28\n",
      "Training: Epoch 186, Batch 6, Loss: 0.394\n",
      "Training: Epoch 186, Batch 7, Loss: 0.581\n",
      "Training: Epoch 186, Batch 8, Loss: 0.488\n",
      "Training: Epoch 186, Batch 9, Loss: 0.507\n",
      "Training: Epoch 186, Batch 10, Loss: 0.108\n",
      "Training: Epoch 186, Batch 11, Loss: 0.542\n",
      "Training: Epoch 186, Batch 12, Loss: 0.308\n",
      "Training: Epoch 186, Batch 13, Loss: 0.318\n",
      "Training: Epoch 186, Batch 14, Loss: 0.45\n",
      "Training: Epoch 186, Batch 15, Loss: 0.315\n",
      "Training: Epoch 186, Batch 16, Loss: 0.29\n",
      "Training: Epoch 186, Batch 17, Loss: 0.275\n",
      "Training: Epoch 186, Batch 18, Loss: 0.44\n",
      "Training: Epoch 186, Batch 19, Loss: 0.311\n",
      "Training: Epoch 186, Batch 20, Loss: 0.26\n",
      "Training: Epoch 186, Batch 21, Loss: 0.312\n",
      "Training: Epoch 186, Batch 22, Loss: 0.241\n",
      "Training: Epoch 186, Batch 23, Loss: 0.29\n",
      "Training: Epoch 186, Batch 24, Loss: 0.379\n",
      "Training: Epoch 186, Batch 25, Loss: 0.369\n",
      "Training: Epoch 186, Batch 26, Loss: 0.453\n",
      "Training: Epoch 186, Batch 27, Loss: 0.259\n",
      "Training: Epoch 186, Batch 28, Loss: 0.33\n",
      "Training: Epoch 186, Batch 29, Loss: 0.229\n",
      "Val: Epoch 186, Loss: 0.254\n",
      "Training: Epoch 187, Batch 0, Loss: 0.459\n",
      "Training: Epoch 187, Batch 1, Loss: 0.265\n",
      "Training: Epoch 187, Batch 2, Loss: 0.272\n",
      "Training: Epoch 187, Batch 3, Loss: 0.278\n",
      "Training: Epoch 187, Batch 4, Loss: 0.168\n",
      "Training: Epoch 187, Batch 5, Loss: 0.383\n",
      "Training: Epoch 187, Batch 6, Loss: 0.401\n",
      "Training: Epoch 187, Batch 7, Loss: 0.203\n",
      "Training: Epoch 187, Batch 8, Loss: 0.328\n",
      "Training: Epoch 187, Batch 9, Loss: 0.434\n",
      "Training: Epoch 187, Batch 10, Loss: 0.21\n",
      "Training: Epoch 187, Batch 11, Loss: 0.342\n",
      "Training: Epoch 187, Batch 12, Loss: 0.327\n",
      "Training: Epoch 187, Batch 13, Loss: 0.256\n",
      "Training: Epoch 187, Batch 14, Loss: 0.314\n",
      "Training: Epoch 187, Batch 15, Loss: 0.536\n",
      "Training: Epoch 187, Batch 16, Loss: 0.353\n",
      "Training: Epoch 187, Batch 17, Loss: 0.326\n",
      "Training: Epoch 187, Batch 18, Loss: 0.36\n",
      "Training: Epoch 187, Batch 19, Loss: 0.336\n",
      "Training: Epoch 187, Batch 20, Loss: 0.233\n",
      "Training: Epoch 187, Batch 21, Loss: 0.283\n",
      "Training: Epoch 187, Batch 22, Loss: 0.339\n",
      "Training: Epoch 187, Batch 23, Loss: 0.396\n",
      "Training: Epoch 187, Batch 24, Loss: 0.167\n",
      "Training: Epoch 187, Batch 25, Loss: 0.21\n",
      "Training: Epoch 187, Batch 26, Loss: 0.282\n",
      "Training: Epoch 187, Batch 27, Loss: 0.336\n",
      "Training: Epoch 187, Batch 28, Loss: 0.534\n",
      "Training: Epoch 187, Batch 29, Loss: 0.395\n",
      "Val: Epoch 187, Loss: 0.255\n",
      "Training: Epoch 188, Batch 0, Loss: 0.193\n",
      "Training: Epoch 188, Batch 1, Loss: 0.276\n",
      "Training: Epoch 188, Batch 2, Loss: 0.347\n",
      "Training: Epoch 188, Batch 3, Loss: 0.258\n",
      "Training: Epoch 188, Batch 4, Loss: 0.311\n",
      "Training: Epoch 188, Batch 5, Loss: 0.543\n",
      "Training: Epoch 188, Batch 6, Loss: 0.548\n",
      "Training: Epoch 188, Batch 7, Loss: 0.376\n",
      "Training: Epoch 188, Batch 8, Loss: 0.334\n",
      "Training: Epoch 188, Batch 9, Loss: 0.299\n",
      "Training: Epoch 188, Batch 10, Loss: 0.198\n",
      "Training: Epoch 188, Batch 11, Loss: 0.229\n",
      "Training: Epoch 188, Batch 12, Loss: 0.28\n",
      "Training: Epoch 188, Batch 13, Loss: 0.364\n",
      "Training: Epoch 188, Batch 14, Loss: 0.498\n",
      "Training: Epoch 188, Batch 15, Loss: 0.265\n",
      "Training: Epoch 188, Batch 16, Loss: 0.367\n",
      "Training: Epoch 188, Batch 17, Loss: 0.376\n",
      "Training: Epoch 188, Batch 18, Loss: 0.306\n",
      "Training: Epoch 188, Batch 19, Loss: 0.417\n",
      "Training: Epoch 188, Batch 20, Loss: 0.34\n",
      "Training: Epoch 188, Batch 21, Loss: 0.354\n",
      "Training: Epoch 188, Batch 22, Loss: 0.114\n",
      "Training: Epoch 188, Batch 23, Loss: 0.486\n",
      "Training: Epoch 188, Batch 24, Loss: 0.308\n",
      "Training: Epoch 188, Batch 25, Loss: 0.237\n",
      "Training: Epoch 188, Batch 26, Loss: 0.366\n",
      "Training: Epoch 188, Batch 27, Loss: 0.631\n",
      "Training: Epoch 188, Batch 28, Loss: 0.567\n",
      "Training: Epoch 188, Batch 29, Loss: 0.352\n",
      "Val: Epoch 188, Loss: 0.655\n",
      "Training: Epoch 189, Batch 0, Loss: 0.395\n",
      "Training: Epoch 189, Batch 1, Loss: 0.26\n",
      "Training: Epoch 189, Batch 2, Loss: 0.308\n",
      "Training: Epoch 189, Batch 3, Loss: 0.254\n",
      "Training: Epoch 189, Batch 4, Loss: 0.285\n",
      "Training: Epoch 189, Batch 5, Loss: 0.528\n",
      "Training: Epoch 189, Batch 6, Loss: 0.274\n",
      "Training: Epoch 189, Batch 7, Loss: 0.57\n",
      "Training: Epoch 189, Batch 8, Loss: 0.382\n",
      "Training: Epoch 189, Batch 9, Loss: 0.274\n",
      "Training: Epoch 189, Batch 10, Loss: 0.244\n",
      "Training: Epoch 189, Batch 11, Loss: 0.294\n",
      "Training: Epoch 189, Batch 12, Loss: 0.319\n",
      "Training: Epoch 189, Batch 13, Loss: 0.313\n",
      "Training: Epoch 189, Batch 14, Loss: 0.221\n",
      "Training: Epoch 189, Batch 15, Loss: 0.381\n",
      "Training: Epoch 189, Batch 16, Loss: 0.313\n",
      "Training: Epoch 189, Batch 17, Loss: 0.778\n",
      "Training: Epoch 189, Batch 18, Loss: 0.606\n",
      "Training: Epoch 189, Batch 19, Loss: 0.381\n",
      "Training: Epoch 189, Batch 20, Loss: 0.341\n",
      "Training: Epoch 189, Batch 21, Loss: 0.432\n",
      "Training: Epoch 189, Batch 22, Loss: 0.449\n",
      "Training: Epoch 189, Batch 23, Loss: 0.237\n",
      "Training: Epoch 189, Batch 24, Loss: 0.321\n",
      "Training: Epoch 189, Batch 25, Loss: 0.429\n",
      "Training: Epoch 189, Batch 26, Loss: 0.485\n",
      "Training: Epoch 189, Batch 27, Loss: 0.364\n",
      "Training: Epoch 189, Batch 28, Loss: 0.347\n",
      "Training: Epoch 189, Batch 29, Loss: 0.347\n",
      "Val: Epoch 189, Loss: 0.292\n",
      "Training: Epoch 190, Batch 0, Loss: 0.427\n",
      "Training: Epoch 190, Batch 1, Loss: 0.302\n",
      "Training: Epoch 190, Batch 2, Loss: 0.536\n",
      "Training: Epoch 190, Batch 3, Loss: 0.372\n",
      "Training: Epoch 190, Batch 4, Loss: 0.103\n",
      "Training: Epoch 190, Batch 5, Loss: 0.517\n",
      "Training: Epoch 190, Batch 6, Loss: 0.465\n",
      "Training: Epoch 190, Batch 7, Loss: 0.29\n",
      "Training: Epoch 190, Batch 8, Loss: 0.28\n",
      "Training: Epoch 190, Batch 9, Loss: 0.353\n",
      "Training: Epoch 190, Batch 10, Loss: 0.546\n",
      "Training: Epoch 190, Batch 11, Loss: 0.341\n",
      "Training: Epoch 190, Batch 12, Loss: 0.19\n",
      "Training: Epoch 190, Batch 13, Loss: 0.412\n",
      "Training: Epoch 190, Batch 14, Loss: 0.417\n",
      "Training: Epoch 190, Batch 15, Loss: 0.308\n",
      "Training: Epoch 190, Batch 16, Loss: 0.448\n",
      "Training: Epoch 190, Batch 17, Loss: 0.501\n",
      "Training: Epoch 190, Batch 18, Loss: 0.103\n",
      "Training: Epoch 190, Batch 19, Loss: 0.47\n",
      "Training: Epoch 190, Batch 20, Loss: 0.307\n",
      "Training: Epoch 190, Batch 21, Loss: 0.327\n",
      "Training: Epoch 190, Batch 22, Loss: 0.266\n",
      "Training: Epoch 190, Batch 23, Loss: 0.278\n",
      "Training: Epoch 190, Batch 24, Loss: 0.369\n",
      "Training: Epoch 190, Batch 25, Loss: 0.379\n",
      "Training: Epoch 190, Batch 26, Loss: 0.432\n",
      "Training: Epoch 190, Batch 27, Loss: 0.189\n",
      "Training: Epoch 190, Batch 28, Loss: 0.441\n",
      "Training: Epoch 190, Batch 29, Loss: 0.413\n",
      "Val: Epoch 190, Loss: 0.28\n",
      "Training: Epoch 191, Batch 0, Loss: 0.297\n",
      "Training: Epoch 191, Batch 1, Loss: 0.224\n",
      "Training: Epoch 191, Batch 2, Loss: 0.146\n",
      "Training: Epoch 191, Batch 3, Loss: 0.528\n",
      "Training: Epoch 191, Batch 4, Loss: 0.381\n",
      "Training: Epoch 191, Batch 5, Loss: 0.599\n",
      "Training: Epoch 191, Batch 6, Loss: 0.349\n",
      "Training: Epoch 191, Batch 7, Loss: 0.291\n",
      "Training: Epoch 191, Batch 8, Loss: 0.507\n",
      "Training: Epoch 191, Batch 9, Loss: 0.208\n",
      "Training: Epoch 191, Batch 10, Loss: 0.231\n",
      "Training: Epoch 191, Batch 11, Loss: 0.262\n",
      "Training: Epoch 191, Batch 12, Loss: 0.214\n",
      "Training: Epoch 191, Batch 13, Loss: 0.192\n",
      "Training: Epoch 191, Batch 14, Loss: 0.349\n",
      "Training: Epoch 191, Batch 15, Loss: 0.288\n",
      "Training: Epoch 191, Batch 16, Loss: 0.306\n",
      "Training: Epoch 191, Batch 17, Loss: 0.296\n",
      "Training: Epoch 191, Batch 18, Loss: 0.482\n",
      "Training: Epoch 191, Batch 19, Loss: 0.198\n",
      "Training: Epoch 191, Batch 20, Loss: 0.244\n",
      "Training: Epoch 191, Batch 21, Loss: 0.333\n",
      "Training: Epoch 191, Batch 22, Loss: 0.35\n",
      "Training: Epoch 191, Batch 23, Loss: 0.288\n",
      "Training: Epoch 191, Batch 24, Loss: 0.237\n",
      "Training: Epoch 191, Batch 25, Loss: 0.294\n",
      "Training: Epoch 191, Batch 26, Loss: 0.364\n",
      "Training: Epoch 191, Batch 27, Loss: 0.459\n",
      "Training: Epoch 191, Batch 28, Loss: 0.51\n",
      "Training: Epoch 191, Batch 29, Loss: 0.322\n",
      "Val: Epoch 191, Loss: 0.283\n",
      "Training: Epoch 192, Batch 0, Loss: 0.354\n",
      "Training: Epoch 192, Batch 1, Loss: 0.274\n",
      "Training: Epoch 192, Batch 2, Loss: 0.397\n",
      "Training: Epoch 192, Batch 3, Loss: 0.317\n",
      "Training: Epoch 192, Batch 4, Loss: 0.25\n",
      "Training: Epoch 192, Batch 5, Loss: 0.373\n",
      "Training: Epoch 192, Batch 6, Loss: 0.301\n",
      "Training: Epoch 192, Batch 7, Loss: 0.321\n",
      "Training: Epoch 192, Batch 8, Loss: 0.226\n",
      "Training: Epoch 192, Batch 9, Loss: 0.309\n",
      "Training: Epoch 192, Batch 10, Loss: 0.201\n",
      "Training: Epoch 192, Batch 11, Loss: 0.298\n",
      "Training: Epoch 192, Batch 12, Loss: 0.325\n",
      "Training: Epoch 192, Batch 13, Loss: 0.374\n",
      "Training: Epoch 192, Batch 14, Loss: 0.211\n",
      "Training: Epoch 192, Batch 15, Loss: 0.331\n",
      "Training: Epoch 192, Batch 16, Loss: 0.339\n",
      "Training: Epoch 192, Batch 17, Loss: 0.294\n",
      "Training: Epoch 192, Batch 18, Loss: 0.186\n",
      "Training: Epoch 192, Batch 19, Loss: 0.387\n",
      "Training: Epoch 192, Batch 20, Loss: 0.336\n",
      "Training: Epoch 192, Batch 21, Loss: 0.197\n",
      "Training: Epoch 192, Batch 22, Loss: 0.319\n",
      "Training: Epoch 192, Batch 23, Loss: 0.156\n",
      "Training: Epoch 192, Batch 24, Loss: 0.298\n",
      "Training: Epoch 192, Batch 25, Loss: 0.486\n",
      "Training: Epoch 192, Batch 26, Loss: 0.317\n",
      "Training: Epoch 192, Batch 27, Loss: 0.367\n",
      "Training: Epoch 192, Batch 28, Loss: 0.355\n",
      "Training: Epoch 192, Batch 29, Loss: 0.364\n",
      "Val: Epoch 192, Loss: 0.303\n",
      "Training: Epoch 193, Batch 0, Loss: 0.399\n",
      "Training: Epoch 193, Batch 1, Loss: 0.392\n",
      "Training: Epoch 193, Batch 2, Loss: 0.344\n",
      "Training: Epoch 193, Batch 3, Loss: 0.405\n",
      "Training: Epoch 193, Batch 4, Loss: 0.367\n",
      "Training: Epoch 193, Batch 5, Loss: 0.355\n",
      "Training: Epoch 193, Batch 6, Loss: 0.326\n",
      "Training: Epoch 193, Batch 7, Loss: 0.286\n",
      "Training: Epoch 193, Batch 8, Loss: 0.283\n",
      "Training: Epoch 193, Batch 9, Loss: 0.32\n",
      "Training: Epoch 193, Batch 10, Loss: 0.26\n",
      "Training: Epoch 193, Batch 11, Loss: 0.242\n",
      "Training: Epoch 193, Batch 12, Loss: 0.181\n",
      "Training: Epoch 193, Batch 13, Loss: 0.214\n",
      "Training: Epoch 193, Batch 14, Loss: 0.131\n",
      "Training: Epoch 193, Batch 15, Loss: 0.254\n",
      "Training: Epoch 193, Batch 16, Loss: 0.246\n",
      "Training: Epoch 193, Batch 17, Loss: 0.263\n",
      "Training: Epoch 193, Batch 18, Loss: 0.253\n",
      "Training: Epoch 193, Batch 19, Loss: 0.199\n",
      "Training: Epoch 193, Batch 20, Loss: 0.275\n",
      "Training: Epoch 193, Batch 21, Loss: 0.21\n",
      "Training: Epoch 193, Batch 22, Loss: 0.264\n",
      "Training: Epoch 193, Batch 23, Loss: 0.325\n",
      "Training: Epoch 193, Batch 24, Loss: 0.19\n",
      "Training: Epoch 193, Batch 25, Loss: 0.687\n",
      "Training: Epoch 193, Batch 26, Loss: 0.254\n",
      "Training: Epoch 193, Batch 27, Loss: 0.356\n",
      "Training: Epoch 193, Batch 28, Loss: 0.281\n",
      "Training: Epoch 193, Batch 29, Loss: 0.261\n",
      "Val: Epoch 193, Loss: 0.269\n",
      "Training: Epoch 194, Batch 0, Loss: 0.301\n",
      "Training: Epoch 194, Batch 1, Loss: 0.242\n",
      "Training: Epoch 194, Batch 2, Loss: 0.237\n",
      "Training: Epoch 194, Batch 3, Loss: 0.31\n",
      "Training: Epoch 194, Batch 4, Loss: 0.268\n",
      "Training: Epoch 194, Batch 5, Loss: 0.361\n",
      "Training: Epoch 194, Batch 6, Loss: 0.229\n",
      "Training: Epoch 194, Batch 7, Loss: 0.406\n",
      "Training: Epoch 194, Batch 8, Loss: 0.208\n",
      "Training: Epoch 194, Batch 9, Loss: 0.421\n",
      "Training: Epoch 194, Batch 10, Loss: 0.332\n",
      "Training: Epoch 194, Batch 11, Loss: 0.342\n",
      "Training: Epoch 194, Batch 12, Loss: 0.283\n",
      "Training: Epoch 194, Batch 13, Loss: 0.302\n",
      "Training: Epoch 194, Batch 14, Loss: 0.241\n",
      "Training: Epoch 194, Batch 15, Loss: 0.258\n",
      "Training: Epoch 194, Batch 16, Loss: 0.105\n",
      "Training: Epoch 194, Batch 17, Loss: 0.331\n",
      "Training: Epoch 194, Batch 18, Loss: 0.213\n",
      "Training: Epoch 194, Batch 19, Loss: 0.327\n",
      "Training: Epoch 194, Batch 20, Loss: 0.4\n",
      "Training: Epoch 194, Batch 21, Loss: 0.37\n",
      "Training: Epoch 194, Batch 22, Loss: 0.224\n",
      "Training: Epoch 194, Batch 23, Loss: 0.203\n",
      "Training: Epoch 194, Batch 24, Loss: 0.366\n",
      "Training: Epoch 194, Batch 25, Loss: 0.424\n",
      "Training: Epoch 194, Batch 26, Loss: 0.201\n",
      "Training: Epoch 194, Batch 27, Loss: 0.286\n",
      "Training: Epoch 194, Batch 28, Loss: 0.276\n",
      "Training: Epoch 194, Batch 29, Loss: 0.277\n",
      "Val: Epoch 194, Loss: 0.355\n",
      "Training: Epoch 195, Batch 0, Loss: 0.431\n",
      "Training: Epoch 195, Batch 1, Loss: 0.209\n",
      "Training: Epoch 195, Batch 2, Loss: 0.336\n",
      "Training: Epoch 195, Batch 3, Loss: 0.23\n",
      "Training: Epoch 195, Batch 4, Loss: 0.242\n",
      "Training: Epoch 195, Batch 5, Loss: 0.15\n",
      "Training: Epoch 195, Batch 6, Loss: 0.154\n",
      "Training: Epoch 195, Batch 7, Loss: 0.305\n",
      "Training: Epoch 195, Batch 8, Loss: 0.186\n",
      "Training: Epoch 195, Batch 9, Loss: 0.295\n",
      "Training: Epoch 195, Batch 10, Loss: 0.434\n",
      "Training: Epoch 195, Batch 11, Loss: 0.359\n",
      "Training: Epoch 195, Batch 12, Loss: 0.392\n",
      "Training: Epoch 195, Batch 13, Loss: 0.41\n",
      "Training: Epoch 195, Batch 14, Loss: 0.3\n",
      "Training: Epoch 195, Batch 15, Loss: 0.366\n",
      "Training: Epoch 195, Batch 16, Loss: 0.154\n",
      "Training: Epoch 195, Batch 17, Loss: 0.307\n",
      "Training: Epoch 195, Batch 18, Loss: 0.274\n",
      "Training: Epoch 195, Batch 19, Loss: 0.39\n",
      "Training: Epoch 195, Batch 20, Loss: 0.31\n",
      "Training: Epoch 195, Batch 21, Loss: 0.289\n",
      "Training: Epoch 195, Batch 22, Loss: 0.19\n",
      "Training: Epoch 195, Batch 23, Loss: 0.323\n",
      "Training: Epoch 195, Batch 24, Loss: 0.224\n",
      "Training: Epoch 195, Batch 25, Loss: 0.265\n",
      "Training: Epoch 195, Batch 26, Loss: 0.216\n",
      "Training: Epoch 195, Batch 27, Loss: 0.239\n",
      "Training: Epoch 195, Batch 28, Loss: 0.292\n",
      "Training: Epoch 195, Batch 29, Loss: 0.342\n",
      "Val: Epoch 195, Loss: 0.268\n",
      "Training: Epoch 196, Batch 0, Loss: 0.269\n",
      "Training: Epoch 196, Batch 1, Loss: 0.333\n",
      "Training: Epoch 196, Batch 2, Loss: 0.277\n",
      "Training: Epoch 196, Batch 3, Loss: 0.332\n",
      "Training: Epoch 196, Batch 4, Loss: 0.207\n",
      "Training: Epoch 196, Batch 5, Loss: 0.359\n",
      "Training: Epoch 196, Batch 6, Loss: 0.244\n",
      "Training: Epoch 196, Batch 7, Loss: 0.302\n",
      "Training: Epoch 196, Batch 8, Loss: 0.326\n",
      "Training: Epoch 196, Batch 9, Loss: 0.291\n",
      "Training: Epoch 196, Batch 10, Loss: 0.212\n",
      "Training: Epoch 196, Batch 11, Loss: 0.345\n",
      "Training: Epoch 196, Batch 12, Loss: 0.135\n",
      "Training: Epoch 196, Batch 13, Loss: 0.253\n",
      "Training: Epoch 196, Batch 14, Loss: 0.397\n",
      "Training: Epoch 196, Batch 15, Loss: 0.345\n",
      "Training: Epoch 196, Batch 16, Loss: 0.167\n",
      "Training: Epoch 196, Batch 17, Loss: 0.224\n",
      "Training: Epoch 196, Batch 18, Loss: 0.261\n",
      "Training: Epoch 196, Batch 19, Loss: 0.105\n",
      "Training: Epoch 196, Batch 20, Loss: 0.345\n",
      "Training: Epoch 196, Batch 21, Loss: 0.291\n",
      "Training: Epoch 196, Batch 22, Loss: 0.371\n",
      "Training: Epoch 196, Batch 23, Loss: 0.314\n",
      "Training: Epoch 196, Batch 24, Loss: 0.384\n",
      "Training: Epoch 196, Batch 25, Loss: 0.347\n",
      "Training: Epoch 196, Batch 26, Loss: 0.231\n",
      "Training: Epoch 196, Batch 27, Loss: 0.291\n",
      "Training: Epoch 196, Batch 28, Loss: 0.246\n",
      "Training: Epoch 196, Batch 29, Loss: 0.217\n",
      "Val: Epoch 196, Loss: 0.299\n",
      "Training: Epoch 197, Batch 0, Loss: 0.358\n",
      "Training: Epoch 197, Batch 1, Loss: 0.24\n",
      "Training: Epoch 197, Batch 2, Loss: 0.164\n",
      "Training: Epoch 197, Batch 3, Loss: 0.236\n",
      "Training: Epoch 197, Batch 4, Loss: 0.329\n",
      "Training: Epoch 197, Batch 5, Loss: 0.171\n",
      "Training: Epoch 197, Batch 6, Loss: 0.485\n",
      "Training: Epoch 197, Batch 7, Loss: 0.266\n",
      "Training: Epoch 197, Batch 8, Loss: 0.261\n",
      "Training: Epoch 197, Batch 9, Loss: 0.174\n",
      "Training: Epoch 197, Batch 10, Loss: 0.327\n",
      "Training: Epoch 197, Batch 11, Loss: 0.354\n",
      "Training: Epoch 197, Batch 12, Loss: 0.153\n",
      "Training: Epoch 197, Batch 13, Loss: 0.39\n",
      "Training: Epoch 197, Batch 14, Loss: 0.248\n",
      "Training: Epoch 197, Batch 15, Loss: 0.241\n",
      "Training: Epoch 197, Batch 16, Loss: 0.214\n",
      "Training: Epoch 197, Batch 17, Loss: 0.37\n",
      "Training: Epoch 197, Batch 18, Loss: 0.378\n",
      "Training: Epoch 197, Batch 19, Loss: 0.216\n",
      "Training: Epoch 197, Batch 20, Loss: 0.204\n",
      "Training: Epoch 197, Batch 21, Loss: 0.239\n",
      "Training: Epoch 197, Batch 22, Loss: 0.374\n",
      "Training: Epoch 197, Batch 23, Loss: 0.193\n",
      "Training: Epoch 197, Batch 24, Loss: 0.369\n",
      "Training: Epoch 197, Batch 25, Loss: 0.386\n",
      "Training: Epoch 197, Batch 26, Loss: 0.332\n",
      "Training: Epoch 197, Batch 27, Loss: 0.552\n",
      "Training: Epoch 197, Batch 28, Loss: 0.421\n",
      "Training: Epoch 197, Batch 29, Loss: 0.307\n",
      "Val: Epoch 197, Loss: 0.258\n",
      "Training: Epoch 198, Batch 0, Loss: 0.367\n",
      "Training: Epoch 198, Batch 1, Loss: 0.442\n",
      "Training: Epoch 198, Batch 2, Loss: 0.31\n",
      "Training: Epoch 198, Batch 3, Loss: 0.277\n",
      "Training: Epoch 198, Batch 4, Loss: 0.287\n",
      "Training: Epoch 198, Batch 5, Loss: 0.31\n",
      "Training: Epoch 198, Batch 6, Loss: 0.311\n",
      "Training: Epoch 198, Batch 7, Loss: 0.304\n",
      "Training: Epoch 198, Batch 8, Loss: 0.27\n",
      "Training: Epoch 198, Batch 9, Loss: 0.27\n",
      "Training: Epoch 198, Batch 10, Loss: 0.182\n",
      "Training: Epoch 198, Batch 11, Loss: 0.286\n",
      "Training: Epoch 198, Batch 12, Loss: 0.211\n",
      "Training: Epoch 198, Batch 13, Loss: 0.207\n",
      "Training: Epoch 198, Batch 14, Loss: 0.238\n",
      "Training: Epoch 198, Batch 15, Loss: 0.268\n",
      "Training: Epoch 198, Batch 16, Loss: 0.232\n",
      "Training: Epoch 198, Batch 17, Loss: 0.252\n",
      "Training: Epoch 198, Batch 18, Loss: 0.279\n",
      "Training: Epoch 198, Batch 19, Loss: 0.175\n",
      "Training: Epoch 198, Batch 20, Loss: 0.355\n",
      "Training: Epoch 198, Batch 21, Loss: 0.419\n",
      "Training: Epoch 198, Batch 22, Loss: 0.348\n",
      "Training: Epoch 198, Batch 23, Loss: 0.394\n",
      "Training: Epoch 198, Batch 24, Loss: 0.218\n",
      "Training: Epoch 198, Batch 25, Loss: 0.227\n",
      "Training: Epoch 198, Batch 26, Loss: 0.292\n",
      "Training: Epoch 198, Batch 27, Loss: 0.329\n",
      "Training: Epoch 198, Batch 28, Loss: 0.399\n",
      "Training: Epoch 198, Batch 29, Loss: 0.358\n",
      "Val: Epoch 198, Loss: 0.287\n",
      "Training: Epoch 199, Batch 0, Loss: 0.145\n",
      "Training: Epoch 199, Batch 1, Loss: 0.258\n",
      "Training: Epoch 199, Batch 2, Loss: 0.482\n",
      "Training: Epoch 199, Batch 3, Loss: 0.237\n",
      "Training: Epoch 199, Batch 4, Loss: 0.281\n",
      "Training: Epoch 199, Batch 5, Loss: 0.353\n",
      "Training: Epoch 199, Batch 6, Loss: 0.247\n",
      "Training: Epoch 199, Batch 7, Loss: 0.268\n",
      "Training: Epoch 199, Batch 8, Loss: 0.264\n",
      "Training: Epoch 199, Batch 9, Loss: 0.584\n",
      "Training: Epoch 199, Batch 10, Loss: 0.169\n",
      "Training: Epoch 199, Batch 11, Loss: 0.163\n",
      "Training: Epoch 199, Batch 12, Loss: 0.23\n",
      "Training: Epoch 199, Batch 13, Loss: 0.374\n",
      "Training: Epoch 199, Batch 14, Loss: 0.316\n",
      "Training: Epoch 199, Batch 15, Loss: 0.278\n",
      "Training: Epoch 199, Batch 16, Loss: 0.316\n",
      "Training: Epoch 199, Batch 17, Loss: 0.29\n",
      "Training: Epoch 199, Batch 18, Loss: 0.343\n",
      "Training: Epoch 199, Batch 19, Loss: 0.229\n",
      "Training: Epoch 199, Batch 20, Loss: 0.187\n",
      "Training: Epoch 199, Batch 21, Loss: 0.176\n",
      "Training: Epoch 199, Batch 22, Loss: 0.249\n",
      "Training: Epoch 199, Batch 23, Loss: 0.288\n",
      "Training: Epoch 199, Batch 24, Loss: 0.261\n",
      "Training: Epoch 199, Batch 25, Loss: 0.219\n",
      "Training: Epoch 199, Batch 26, Loss: 0.376\n",
      "Training: Epoch 199, Batch 27, Loss: 0.195\n",
      "Training: Epoch 199, Batch 28, Loss: 0.282\n",
      "Training: Epoch 199, Batch 29, Loss: 0.194\n",
      "Val: Epoch 199, Loss: 0.289\n",
      "Training: Epoch 200, Batch 0, Loss: 0.247\n",
      "Training: Epoch 200, Batch 1, Loss: 0.246\n",
      "Training: Epoch 200, Batch 2, Loss: 0.134\n",
      "Training: Epoch 200, Batch 3, Loss: 0.234\n",
      "Training: Epoch 200, Batch 4, Loss: 0.226\n",
      "Training: Epoch 200, Batch 5, Loss: 0.265\n",
      "Training: Epoch 200, Batch 6, Loss: 0.253\n",
      "Training: Epoch 200, Batch 7, Loss: 0.277\n",
      "Training: Epoch 200, Batch 8, Loss: 0.34\n",
      "Training: Epoch 200, Batch 9, Loss: 0.218\n",
      "Training: Epoch 200, Batch 10, Loss: 0.212\n",
      "Training: Epoch 200, Batch 11, Loss: 0.339\n",
      "Training: Epoch 200, Batch 12, Loss: 0.311\n",
      "Training: Epoch 200, Batch 13, Loss: 0.209\n",
      "Training: Epoch 200, Batch 14, Loss: 0.221\n",
      "Training: Epoch 200, Batch 15, Loss: 0.242\n",
      "Training: Epoch 200, Batch 16, Loss: 0.289\n",
      "Training: Epoch 200, Batch 17, Loss: 0.293\n",
      "Training: Epoch 200, Batch 18, Loss: 0.263\n",
      "Training: Epoch 200, Batch 19, Loss: 0.359\n",
      "Training: Epoch 200, Batch 20, Loss: 0.387\n",
      "Training: Epoch 200, Batch 21, Loss: 0.281\n",
      "Training: Epoch 200, Batch 22, Loss: 0.257\n",
      "Training: Epoch 200, Batch 23, Loss: 0.195\n",
      "Training: Epoch 200, Batch 24, Loss: 0.181\n",
      "Training: Epoch 200, Batch 25, Loss: 0.382\n",
      "Training: Epoch 200, Batch 26, Loss: 0.24\n",
      "Training: Epoch 200, Batch 27, Loss: 0.188\n",
      "Training: Epoch 200, Batch 28, Loss: 0.268\n",
      "Training: Epoch 200, Batch 29, Loss: 0.201\n",
      "Val: Epoch 200, Loss: 0.259\n",
      "Best model found at epoch 112\n",
      "Total training time: 1408.949695110321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[-1],map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_model.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97    937035\n",
      "           1       0.92      0.84      0.88   1187442\n",
      "           2       0.73      0.88      0.80    496963\n",
      "\n",
      "    accuracy                           0.89   2621440\n",
      "   macro avg       0.87      0.89      0.88   2621440\n",
      "weighted avg       0.90      0.89      0.89   2621440\n",
      "\n",
      "Training loss: 0.245191290974617\n",
      "AUROC: 0.9791740003419669\n"
     ]
    }
   ],
   "source": [
    "#train TransuNet with train+fake dataset\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "model, best_model_loss=train_model_transunet(X_train_with_fake,Y_train_with_fake,X_val,Y_val, lr= 0.003, momentum= 0.9, weight_decay= 0.01)\n",
    "end_time = time.time()\n",
    "print(\"Total training time:\", end_time-start_time)\n",
    "\n",
    "y_val_pred=make_predictions_transunet(X_val,model=None)\n",
    "y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "#print loss\n",
    "print(\"Training loss:\", best_model_loss)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Flatten prediction: shape (B, C, H, W) → (N, C)\n",
    "y_val_pred_flat = y_val_pred.transpose(0, 2, 3, 1).reshape(-1, y_val_pred.shape[1])\n",
    "\n",
    "# Flatten true labels: shape (B, H, W) → (N,)\n",
    "y_true = Y_val.numpy().flatten()\n",
    "\n",
    "# Binarize true labels for multiclass AUROC\n",
    "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(y_true_binarized, y_val_pred_flat, multi_class='ovr')\n",
    "\n",
    "print(\"AUROC:\", auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:4969: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:4902: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented X shape: torch.Size([720, 3, 256, 256]), Augmented Y shape: torch.Size([720, 256, 256])\n",
      "X_train_aug shape: torch.Size([720, 3, 256, 256])\n",
      "Y_train_aug shape: torch.Size([720, 256, 256])\n",
      "Using device: cuda\n",
      "Training: Epoch 1, Batch 0, Loss: 1.101\n",
      "Training: Epoch 1, Batch 1, Loss: 1.119\n",
      "Training: Epoch 1, Batch 2, Loss: 1.097\n",
      "Training: Epoch 1, Batch 3, Loss: 1.109\n",
      "Training: Epoch 1, Batch 4, Loss: 1.093\n",
      "Training: Epoch 1, Batch 5, Loss: 1.095\n",
      "Training: Epoch 1, Batch 6, Loss: 1.103\n",
      "Training: Epoch 1, Batch 7, Loss: 1.107\n",
      "Training: Epoch 1, Batch 8, Loss: 1.096\n",
      "Training: Epoch 1, Batch 9, Loss: 1.097\n",
      "Training: Epoch 1, Batch 10, Loss: 1.097\n",
      "Training: Epoch 1, Batch 11, Loss: 1.094\n",
      "Training: Epoch 1, Batch 12, Loss: 1.091\n",
      "Training: Epoch 1, Batch 13, Loss: 1.097\n",
      "Training: Epoch 1, Batch 14, Loss: 1.094\n",
      "Training: Epoch 1, Batch 15, Loss: 1.093\n",
      "Training: Epoch 1, Batch 16, Loss: 1.084\n",
      "Training: Epoch 1, Batch 17, Loss: 1.084\n",
      "Training: Epoch 1, Batch 18, Loss: 1.076\n",
      "Training: Epoch 1, Batch 19, Loss: 1.097\n",
      "Training: Epoch 1, Batch 20, Loss: 1.097\n",
      "Training: Epoch 1, Batch 21, Loss: 1.087\n",
      "Training: Epoch 1, Batch 22, Loss: 1.073\n",
      "Training: Epoch 1, Batch 23, Loss: 1.086\n",
      "Training: Epoch 1, Batch 24, Loss: 1.074\n",
      "Training: Epoch 1, Batch 25, Loss: 1.065\n",
      "Training: Epoch 1, Batch 26, Loss: 1.072\n",
      "Training: Epoch 1, Batch 27, Loss: 1.065\n",
      "Training: Epoch 1, Batch 28, Loss: 1.071\n",
      "Training: Epoch 1, Batch 29, Loss: 1.055\n",
      "Training: Epoch 1, Batch 30, Loss: 1.075\n",
      "Training: Epoch 1, Batch 31, Loss: 1.073\n",
      "Training: Epoch 1, Batch 32, Loss: 1.055\n",
      "Training: Epoch 1, Batch 33, Loss: 1.06\n",
      "Training: Epoch 1, Batch 34, Loss: 1.06\n",
      "Training: Epoch 1, Batch 35, Loss: 1.054\n",
      "Training: Epoch 1, Batch 36, Loss: 1.045\n",
      "Training: Epoch 1, Batch 37, Loss: 1.062\n",
      "Training: Epoch 1, Batch 38, Loss: 1.033\n",
      "Training: Epoch 1, Batch 39, Loss: 1.033\n",
      "Training: Epoch 1, Batch 40, Loss: 1.023\n",
      "Training: Epoch 1, Batch 41, Loss: 1.026\n",
      "Training: Epoch 1, Batch 42, Loss: 1.04\n",
      "Training: Epoch 1, Batch 43, Loss: 1.031\n",
      "Training: Epoch 1, Batch 44, Loss: 1.016\n",
      "Training: Epoch 1, Batch 45, Loss: 1.026\n",
      "Training: Epoch 1, Batch 46, Loss: 0.977\n",
      "Training: Epoch 1, Batch 47, Loss: 1.015\n",
      "Training: Epoch 1, Batch 48, Loss: 1.015\n",
      "Training: Epoch 1, Batch 49, Loss: 1.044\n",
      "Training: Epoch 1, Batch 50, Loss: 0.981\n",
      "Training: Epoch 1, Batch 51, Loss: 0.986\n",
      "Training: Epoch 1, Batch 52, Loss: 0.947\n",
      "Training: Epoch 1, Batch 53, Loss: 1.035\n",
      "Training: Epoch 1, Batch 54, Loss: 0.999\n",
      "Training: Epoch 1, Batch 55, Loss: 0.962\n",
      "Training: Epoch 1, Batch 56, Loss: 0.918\n",
      "Training: Epoch 1, Batch 57, Loss: 0.996\n",
      "Training: Epoch 1, Batch 58, Loss: 1.017\n",
      "Training: Epoch 1, Batch 59, Loss: 0.935\n",
      "Training: Epoch 1, Batch 60, Loss: 0.929\n",
      "Training: Epoch 1, Batch 61, Loss: 0.963\n",
      "Training: Epoch 1, Batch 62, Loss: 0.918\n",
      "Training: Epoch 1, Batch 63, Loss: 0.986\n",
      "Training: Epoch 1, Batch 64, Loss: 0.954\n",
      "Training: Epoch 1, Batch 65, Loss: 0.846\n",
      "Training: Epoch 1, Batch 66, Loss: 0.968\n",
      "Training: Epoch 1, Batch 67, Loss: 0.887\n",
      "Training: Epoch 1, Batch 68, Loss: 0.872\n",
      "Training: Epoch 1, Batch 69, Loss: 0.886\n",
      "Training: Epoch 1, Batch 70, Loss: 0.921\n",
      "Training: Epoch 1, Batch 71, Loss: 0.931\n",
      "Training: Epoch 1, Batch 72, Loss: 1.01\n",
      "Training: Epoch 1, Batch 73, Loss: 0.892\n",
      "Training: Epoch 1, Batch 74, Loss: 0.839\n",
      "Training: Epoch 1, Batch 75, Loss: 0.898\n",
      "Training: Epoch 1, Batch 76, Loss: 0.776\n",
      "Training: Epoch 1, Batch 77, Loss: 0.754\n",
      "Training: Epoch 1, Batch 78, Loss: 0.818\n",
      "Training: Epoch 1, Batch 79, Loss: 0.909\n",
      "Training: Epoch 1, Batch 80, Loss: 0.86\n",
      "Training: Epoch 1, Batch 81, Loss: 0.901\n",
      "Training: Epoch 1, Batch 82, Loss: 0.813\n",
      "Training: Epoch 1, Batch 83, Loss: 0.898\n",
      "Training: Epoch 1, Batch 84, Loss: 0.77\n",
      "Training: Epoch 1, Batch 85, Loss: 0.951\n",
      "Training: Epoch 1, Batch 86, Loss: 0.933\n",
      "Training: Epoch 1, Batch 87, Loss: 0.777\n",
      "Training: Epoch 1, Batch 88, Loss: 1.086\n",
      "Training: Epoch 1, Batch 89, Loss: 0.907\n",
      "Val: Epoch 1, Loss: 0.655\n",
      "Training: Epoch 2, Batch 0, Loss: 1.074\n",
      "Training: Epoch 2, Batch 1, Loss: 0.869\n",
      "Training: Epoch 2, Batch 2, Loss: 0.673\n",
      "Training: Epoch 2, Batch 3, Loss: 0.887\n",
      "Training: Epoch 2, Batch 4, Loss: 0.701\n",
      "Training: Epoch 2, Batch 5, Loss: 0.827\n",
      "Training: Epoch 2, Batch 6, Loss: 0.874\n",
      "Training: Epoch 2, Batch 7, Loss: 0.739\n",
      "Training: Epoch 2, Batch 8, Loss: 0.949\n",
      "Training: Epoch 2, Batch 9, Loss: 0.735\n",
      "Training: Epoch 2, Batch 10, Loss: 0.749\n",
      "Training: Epoch 2, Batch 11, Loss: 0.695\n",
      "Training: Epoch 2, Batch 12, Loss: 0.709\n",
      "Training: Epoch 2, Batch 13, Loss: 1.096\n",
      "Training: Epoch 2, Batch 14, Loss: 0.886\n",
      "Training: Epoch 2, Batch 15, Loss: 0.814\n",
      "Training: Epoch 2, Batch 16, Loss: 0.706\n",
      "Training: Epoch 2, Batch 17, Loss: 0.837\n",
      "Training: Epoch 2, Batch 18, Loss: 0.7\n",
      "Training: Epoch 2, Batch 19, Loss: 0.648\n",
      "Training: Epoch 2, Batch 20, Loss: 0.73\n",
      "Training: Epoch 2, Batch 21, Loss: 0.811\n",
      "Training: Epoch 2, Batch 22, Loss: 0.902\n",
      "Training: Epoch 2, Batch 23, Loss: 0.669\n",
      "Training: Epoch 2, Batch 24, Loss: 0.788\n",
      "Training: Epoch 2, Batch 25, Loss: 0.982\n",
      "Training: Epoch 2, Batch 26, Loss: 0.965\n",
      "Training: Epoch 2, Batch 27, Loss: 0.772\n",
      "Training: Epoch 2, Batch 28, Loss: 0.784\n",
      "Training: Epoch 2, Batch 29, Loss: 0.769\n",
      "Training: Epoch 2, Batch 30, Loss: 0.63\n",
      "Training: Epoch 2, Batch 31, Loss: 0.852\n",
      "Training: Epoch 2, Batch 32, Loss: 0.924\n",
      "Training: Epoch 2, Batch 33, Loss: 0.836\n",
      "Training: Epoch 2, Batch 34, Loss: 0.653\n",
      "Training: Epoch 2, Batch 35, Loss: 0.905\n",
      "Training: Epoch 2, Batch 36, Loss: 0.951\n",
      "Training: Epoch 2, Batch 37, Loss: 0.738\n",
      "Training: Epoch 2, Batch 38, Loss: 0.897\n",
      "Training: Epoch 2, Batch 39, Loss: 0.96\n",
      "Training: Epoch 2, Batch 40, Loss: 0.853\n",
      "Training: Epoch 2, Batch 41, Loss: 0.555\n",
      "Training: Epoch 2, Batch 42, Loss: 0.712\n",
      "Training: Epoch 2, Batch 43, Loss: 0.776\n",
      "Training: Epoch 2, Batch 44, Loss: 0.743\n",
      "Training: Epoch 2, Batch 45, Loss: 0.778\n",
      "Training: Epoch 2, Batch 46, Loss: 0.714\n",
      "Training: Epoch 2, Batch 47, Loss: 0.845\n",
      "Training: Epoch 2, Batch 48, Loss: 0.799\n",
      "Training: Epoch 2, Batch 49, Loss: 0.718\n",
      "Training: Epoch 2, Batch 50, Loss: 0.732\n",
      "Training: Epoch 2, Batch 51, Loss: 0.762\n",
      "Training: Epoch 2, Batch 52, Loss: 0.641\n",
      "Training: Epoch 2, Batch 53, Loss: 0.723\n",
      "Training: Epoch 2, Batch 54, Loss: 0.666\n",
      "Training: Epoch 2, Batch 55, Loss: 0.646\n",
      "Training: Epoch 2, Batch 56, Loss: 0.879\n",
      "Training: Epoch 2, Batch 57, Loss: 0.643\n",
      "Training: Epoch 2, Batch 58, Loss: 0.896\n",
      "Training: Epoch 2, Batch 59, Loss: 0.759\n",
      "Training: Epoch 2, Batch 60, Loss: 0.805\n",
      "Training: Epoch 2, Batch 61, Loss: 0.652\n",
      "Training: Epoch 2, Batch 62, Loss: 1.152\n",
      "Training: Epoch 2, Batch 63, Loss: 0.712\n",
      "Training: Epoch 2, Batch 64, Loss: 1.054\n",
      "Training: Epoch 2, Batch 65, Loss: 0.725\n",
      "Training: Epoch 2, Batch 66, Loss: 0.905\n",
      "Training: Epoch 2, Batch 67, Loss: 0.789\n",
      "Training: Epoch 2, Batch 68, Loss: 0.725\n",
      "Training: Epoch 2, Batch 69, Loss: 0.662\n",
      "Training: Epoch 2, Batch 70, Loss: 0.807\n",
      "Training: Epoch 2, Batch 71, Loss: 0.614\n",
      "Training: Epoch 2, Batch 72, Loss: 0.754\n",
      "Training: Epoch 2, Batch 73, Loss: 0.821\n",
      "Training: Epoch 2, Batch 74, Loss: 0.571\n",
      "Training: Epoch 2, Batch 75, Loss: 0.726\n",
      "Training: Epoch 2, Batch 76, Loss: 0.609\n",
      "Training: Epoch 2, Batch 77, Loss: 0.918\n",
      "Training: Epoch 2, Batch 78, Loss: 0.707\n",
      "Training: Epoch 2, Batch 79, Loss: 0.669\n",
      "Training: Epoch 2, Batch 80, Loss: 0.619\n",
      "Training: Epoch 2, Batch 81, Loss: 0.848\n",
      "Training: Epoch 2, Batch 82, Loss: 0.569\n",
      "Training: Epoch 2, Batch 83, Loss: 0.868\n",
      "Training: Epoch 2, Batch 84, Loss: 0.739\n",
      "Training: Epoch 2, Batch 85, Loss: 0.684\n",
      "Training: Epoch 2, Batch 86, Loss: 0.735\n",
      "Training: Epoch 2, Batch 87, Loss: 0.685\n",
      "Training: Epoch 2, Batch 88, Loss: 0.789\n",
      "Training: Epoch 2, Batch 89, Loss: 0.644\n",
      "Val: Epoch 2, Loss: 0.485\n",
      "Training: Epoch 3, Batch 0, Loss: 0.753\n",
      "Training: Epoch 3, Batch 1, Loss: 0.662\n",
      "Training: Epoch 3, Batch 2, Loss: 0.702\n",
      "Training: Epoch 3, Batch 3, Loss: 0.651\n",
      "Training: Epoch 3, Batch 4, Loss: 0.782\n",
      "Training: Epoch 3, Batch 5, Loss: 0.767\n",
      "Training: Epoch 3, Batch 6, Loss: 0.692\n",
      "Training: Epoch 3, Batch 7, Loss: 0.612\n",
      "Training: Epoch 3, Batch 8, Loss: 0.84\n",
      "Training: Epoch 3, Batch 9, Loss: 0.923\n",
      "Training: Epoch 3, Batch 10, Loss: 0.783\n",
      "Training: Epoch 3, Batch 11, Loss: 0.577\n",
      "Training: Epoch 3, Batch 12, Loss: 0.742\n",
      "Training: Epoch 3, Batch 13, Loss: 0.745\n",
      "Training: Epoch 3, Batch 14, Loss: 0.726\n",
      "Training: Epoch 3, Batch 15, Loss: 0.754\n",
      "Training: Epoch 3, Batch 16, Loss: 0.772\n",
      "Training: Epoch 3, Batch 17, Loss: 0.686\n",
      "Training: Epoch 3, Batch 18, Loss: 0.965\n",
      "Training: Epoch 3, Batch 19, Loss: 0.536\n",
      "Training: Epoch 3, Batch 20, Loss: 0.504\n",
      "Training: Epoch 3, Batch 21, Loss: 0.613\n",
      "Training: Epoch 3, Batch 22, Loss: 0.9\n",
      "Training: Epoch 3, Batch 23, Loss: 1.16\n",
      "Training: Epoch 3, Batch 24, Loss: 0.903\n",
      "Training: Epoch 3, Batch 25, Loss: 0.675\n",
      "Training: Epoch 3, Batch 26, Loss: 0.577\n",
      "Training: Epoch 3, Batch 27, Loss: 0.773\n",
      "Training: Epoch 3, Batch 28, Loss: 0.881\n",
      "Training: Epoch 3, Batch 29, Loss: 0.894\n",
      "Training: Epoch 3, Batch 30, Loss: 0.869\n",
      "Training: Epoch 3, Batch 31, Loss: 1.027\n",
      "Training: Epoch 3, Batch 32, Loss: 0.913\n",
      "Training: Epoch 3, Batch 33, Loss: 0.616\n",
      "Training: Epoch 3, Batch 34, Loss: 0.725\n",
      "Training: Epoch 3, Batch 35, Loss: 0.854\n",
      "Training: Epoch 3, Batch 36, Loss: 0.716\n",
      "Training: Epoch 3, Batch 37, Loss: 0.59\n",
      "Training: Epoch 3, Batch 38, Loss: 0.826\n",
      "Training: Epoch 3, Batch 39, Loss: 0.928\n",
      "Training: Epoch 3, Batch 40, Loss: 0.891\n",
      "Training: Epoch 3, Batch 41, Loss: 0.829\n",
      "Training: Epoch 3, Batch 42, Loss: 0.595\n",
      "Training: Epoch 3, Batch 43, Loss: 0.821\n",
      "Training: Epoch 3, Batch 44, Loss: 0.621\n",
      "Training: Epoch 3, Batch 45, Loss: 0.817\n",
      "Training: Epoch 3, Batch 46, Loss: 0.539\n",
      "Training: Epoch 3, Batch 47, Loss: 0.624\n",
      "Training: Epoch 3, Batch 48, Loss: 0.744\n",
      "Training: Epoch 3, Batch 49, Loss: 0.712\n",
      "Training: Epoch 3, Batch 50, Loss: 0.7\n",
      "Training: Epoch 3, Batch 51, Loss: 0.692\n",
      "Training: Epoch 3, Batch 52, Loss: 0.584\n",
      "Training: Epoch 3, Batch 53, Loss: 0.908\n",
      "Training: Epoch 3, Batch 54, Loss: 0.709\n",
      "Training: Epoch 3, Batch 55, Loss: 1.037\n",
      "Training: Epoch 3, Batch 56, Loss: 0.714\n",
      "Training: Epoch 3, Batch 57, Loss: 0.761\n",
      "Training: Epoch 3, Batch 58, Loss: 0.545\n",
      "Training: Epoch 3, Batch 59, Loss: 0.573\n",
      "Training: Epoch 3, Batch 60, Loss: 0.715\n",
      "Training: Epoch 3, Batch 61, Loss: 0.689\n",
      "Training: Epoch 3, Batch 62, Loss: 0.628\n",
      "Training: Epoch 3, Batch 63, Loss: 0.684\n",
      "Training: Epoch 3, Batch 64, Loss: 0.759\n",
      "Training: Epoch 3, Batch 65, Loss: 0.85\n",
      "Training: Epoch 3, Batch 66, Loss: 0.597\n",
      "Training: Epoch 3, Batch 67, Loss: 0.425\n",
      "Training: Epoch 3, Batch 68, Loss: 0.745\n",
      "Training: Epoch 3, Batch 69, Loss: 0.597\n",
      "Training: Epoch 3, Batch 70, Loss: 0.698\n",
      "Training: Epoch 3, Batch 71, Loss: 0.751\n",
      "Training: Epoch 3, Batch 72, Loss: 0.829\n",
      "Training: Epoch 3, Batch 73, Loss: 0.595\n",
      "Training: Epoch 3, Batch 74, Loss: 0.598\n",
      "Training: Epoch 3, Batch 75, Loss: 0.687\n",
      "Training: Epoch 3, Batch 76, Loss: 0.533\n",
      "Training: Epoch 3, Batch 77, Loss: 0.727\n",
      "Training: Epoch 3, Batch 78, Loss: 0.656\n",
      "Training: Epoch 3, Batch 79, Loss: 0.64\n",
      "Training: Epoch 3, Batch 80, Loss: 0.76\n",
      "Training: Epoch 3, Batch 81, Loss: 0.781\n",
      "Training: Epoch 3, Batch 82, Loss: 0.759\n",
      "Training: Epoch 3, Batch 83, Loss: 0.57\n",
      "Training: Epoch 3, Batch 84, Loss: 0.625\n",
      "Training: Epoch 3, Batch 85, Loss: 0.605\n",
      "Training: Epoch 3, Batch 86, Loss: 0.733\n",
      "Training: Epoch 3, Batch 87, Loss: 0.628\n",
      "Training: Epoch 3, Batch 88, Loss: 0.867\n",
      "Training: Epoch 3, Batch 89, Loss: 0.753\n",
      "Val: Epoch 3, Loss: 0.426\n",
      "Training: Epoch 4, Batch 0, Loss: 0.558\n",
      "Training: Epoch 4, Batch 1, Loss: 0.761\n",
      "Training: Epoch 4, Batch 2, Loss: 0.733\n",
      "Training: Epoch 4, Batch 3, Loss: 0.661\n",
      "Training: Epoch 4, Batch 4, Loss: 0.711\n",
      "Training: Epoch 4, Batch 5, Loss: 0.883\n",
      "Training: Epoch 4, Batch 6, Loss: 0.704\n",
      "Training: Epoch 4, Batch 7, Loss: 0.799\n",
      "Training: Epoch 4, Batch 8, Loss: 0.88\n",
      "Training: Epoch 4, Batch 9, Loss: 0.608\n",
      "Training: Epoch 4, Batch 10, Loss: 0.645\n",
      "Training: Epoch 4, Batch 11, Loss: 0.653\n",
      "Training: Epoch 4, Batch 12, Loss: 0.644\n",
      "Training: Epoch 4, Batch 13, Loss: 0.737\n",
      "Training: Epoch 4, Batch 14, Loss: 1.036\n",
      "Training: Epoch 4, Batch 15, Loss: 0.717\n",
      "Training: Epoch 4, Batch 16, Loss: 0.69\n",
      "Training: Epoch 4, Batch 17, Loss: 0.803\n",
      "Training: Epoch 4, Batch 18, Loss: 0.704\n",
      "Training: Epoch 4, Batch 19, Loss: 0.543\n",
      "Training: Epoch 4, Batch 20, Loss: 0.782\n",
      "Training: Epoch 4, Batch 21, Loss: 0.841\n",
      "Training: Epoch 4, Batch 22, Loss: 0.766\n",
      "Training: Epoch 4, Batch 23, Loss: 0.519\n",
      "Training: Epoch 4, Batch 24, Loss: 0.609\n",
      "Training: Epoch 4, Batch 25, Loss: 0.664\n",
      "Training: Epoch 4, Batch 26, Loss: 0.55\n",
      "Training: Epoch 4, Batch 27, Loss: 0.574\n",
      "Training: Epoch 4, Batch 28, Loss: 0.763\n",
      "Training: Epoch 4, Batch 29, Loss: 0.756\n",
      "Training: Epoch 4, Batch 30, Loss: 0.647\n",
      "Training: Epoch 4, Batch 31, Loss: 0.835\n",
      "Training: Epoch 4, Batch 32, Loss: 0.877\n",
      "Training: Epoch 4, Batch 33, Loss: 0.516\n",
      "Training: Epoch 4, Batch 34, Loss: 0.432\n",
      "Training: Epoch 4, Batch 35, Loss: 0.681\n",
      "Training: Epoch 4, Batch 36, Loss: 0.427\n",
      "Training: Epoch 4, Batch 37, Loss: 0.76\n",
      "Training: Epoch 4, Batch 38, Loss: 0.486\n",
      "Training: Epoch 4, Batch 39, Loss: 0.702\n",
      "Training: Epoch 4, Batch 40, Loss: 0.624\n",
      "Training: Epoch 4, Batch 41, Loss: 0.663\n",
      "Training: Epoch 4, Batch 42, Loss: 0.695\n",
      "Training: Epoch 4, Batch 43, Loss: 0.587\n",
      "Training: Epoch 4, Batch 44, Loss: 0.506\n",
      "Training: Epoch 4, Batch 45, Loss: 0.932\n",
      "Training: Epoch 4, Batch 46, Loss: 0.771\n",
      "Training: Epoch 4, Batch 47, Loss: 0.749\n",
      "Training: Epoch 4, Batch 48, Loss: 1.005\n",
      "Training: Epoch 4, Batch 49, Loss: 0.531\n",
      "Training: Epoch 4, Batch 50, Loss: 0.929\n",
      "Training: Epoch 4, Batch 51, Loss: 0.503\n",
      "Training: Epoch 4, Batch 52, Loss: 0.674\n",
      "Training: Epoch 4, Batch 53, Loss: 0.421\n",
      "Training: Epoch 4, Batch 54, Loss: 0.717\n",
      "Training: Epoch 4, Batch 55, Loss: 0.471\n",
      "Training: Epoch 4, Batch 56, Loss: 0.685\n",
      "Training: Epoch 4, Batch 57, Loss: 0.995\n",
      "Training: Epoch 4, Batch 58, Loss: 0.858\n",
      "Training: Epoch 4, Batch 59, Loss: 0.826\n",
      "Training: Epoch 4, Batch 60, Loss: 0.737\n",
      "Training: Epoch 4, Batch 61, Loss: 0.528\n",
      "Training: Epoch 4, Batch 62, Loss: 0.562\n",
      "Training: Epoch 4, Batch 63, Loss: 0.636\n",
      "Training: Epoch 4, Batch 64, Loss: 0.726\n",
      "Training: Epoch 4, Batch 65, Loss: 0.689\n",
      "Training: Epoch 4, Batch 66, Loss: 0.7\n",
      "Training: Epoch 4, Batch 67, Loss: 0.631\n",
      "Training: Epoch 4, Batch 68, Loss: 0.514\n",
      "Training: Epoch 4, Batch 69, Loss: 0.564\n",
      "Training: Epoch 4, Batch 70, Loss: 0.715\n",
      "Training: Epoch 4, Batch 71, Loss: 0.834\n",
      "Training: Epoch 4, Batch 72, Loss: 0.627\n",
      "Training: Epoch 4, Batch 73, Loss: 0.71\n",
      "Training: Epoch 4, Batch 74, Loss: 0.641\n",
      "Training: Epoch 4, Batch 75, Loss: 0.674\n",
      "Training: Epoch 4, Batch 76, Loss: 0.882\n",
      "Training: Epoch 4, Batch 77, Loss: 0.497\n",
      "Training: Epoch 4, Batch 78, Loss: 0.799\n",
      "Training: Epoch 4, Batch 79, Loss: 0.657\n",
      "Training: Epoch 4, Batch 80, Loss: 0.719\n",
      "Training: Epoch 4, Batch 81, Loss: 0.818\n",
      "Training: Epoch 4, Batch 82, Loss: 0.644\n",
      "Training: Epoch 4, Batch 83, Loss: 0.656\n",
      "Training: Epoch 4, Batch 84, Loss: 0.384\n",
      "Training: Epoch 4, Batch 85, Loss: 0.621\n",
      "Training: Epoch 4, Batch 86, Loss: 0.575\n",
      "Training: Epoch 4, Batch 87, Loss: 0.73\n",
      "Training: Epoch 4, Batch 88, Loss: 0.517\n",
      "Training: Epoch 4, Batch 89, Loss: 0.766\n",
      "Val: Epoch 4, Loss: 0.436\n",
      "Training: Epoch 5, Batch 0, Loss: 0.95\n",
      "Training: Epoch 5, Batch 1, Loss: 0.791\n",
      "Training: Epoch 5, Batch 2, Loss: 0.623\n",
      "Training: Epoch 5, Batch 3, Loss: 0.428\n",
      "Training: Epoch 5, Batch 4, Loss: 1.004\n",
      "Training: Epoch 5, Batch 5, Loss: 0.72\n",
      "Training: Epoch 5, Batch 6, Loss: 0.599\n",
      "Training: Epoch 5, Batch 7, Loss: 0.756\n",
      "Training: Epoch 5, Batch 8, Loss: 0.514\n",
      "Training: Epoch 5, Batch 9, Loss: 0.651\n",
      "Training: Epoch 5, Batch 10, Loss: 0.532\n",
      "Training: Epoch 5, Batch 11, Loss: 0.785\n",
      "Training: Epoch 5, Batch 12, Loss: 0.657\n",
      "Training: Epoch 5, Batch 13, Loss: 0.886\n",
      "Training: Epoch 5, Batch 14, Loss: 0.764\n",
      "Training: Epoch 5, Batch 15, Loss: 0.513\n",
      "Training: Epoch 5, Batch 16, Loss: 0.664\n",
      "Training: Epoch 5, Batch 17, Loss: 0.801\n",
      "Training: Epoch 5, Batch 18, Loss: 0.556\n",
      "Training: Epoch 5, Batch 19, Loss: 0.628\n",
      "Training: Epoch 5, Batch 20, Loss: 0.753\n",
      "Training: Epoch 5, Batch 21, Loss: 0.873\n",
      "Training: Epoch 5, Batch 22, Loss: 0.502\n",
      "Training: Epoch 5, Batch 23, Loss: 0.624\n",
      "Training: Epoch 5, Batch 24, Loss: 0.927\n",
      "Training: Epoch 5, Batch 25, Loss: 0.719\n",
      "Training: Epoch 5, Batch 26, Loss: 0.572\n",
      "Training: Epoch 5, Batch 27, Loss: 0.596\n",
      "Training: Epoch 5, Batch 28, Loss: 0.734\n",
      "Training: Epoch 5, Batch 29, Loss: 0.511\n",
      "Training: Epoch 5, Batch 30, Loss: 0.426\n",
      "Training: Epoch 5, Batch 31, Loss: 0.62\n",
      "Training: Epoch 5, Batch 32, Loss: 0.644\n",
      "Training: Epoch 5, Batch 33, Loss: 0.489\n",
      "Training: Epoch 5, Batch 34, Loss: 0.627\n",
      "Training: Epoch 5, Batch 35, Loss: 0.654\n",
      "Training: Epoch 5, Batch 36, Loss: 0.724\n",
      "Training: Epoch 5, Batch 37, Loss: 0.768\n",
      "Training: Epoch 5, Batch 38, Loss: 0.736\n",
      "Training: Epoch 5, Batch 39, Loss: 0.433\n",
      "Training: Epoch 5, Batch 40, Loss: 0.593\n",
      "Training: Epoch 5, Batch 41, Loss: 0.745\n",
      "Training: Epoch 5, Batch 42, Loss: 0.897\n",
      "Training: Epoch 5, Batch 43, Loss: 0.773\n",
      "Training: Epoch 5, Batch 44, Loss: 0.581\n",
      "Training: Epoch 5, Batch 45, Loss: 0.961\n",
      "Training: Epoch 5, Batch 46, Loss: 0.667\n",
      "Training: Epoch 5, Batch 47, Loss: 0.672\n",
      "Training: Epoch 5, Batch 48, Loss: 0.778\n",
      "Training: Epoch 5, Batch 49, Loss: 0.724\n",
      "Training: Epoch 5, Batch 50, Loss: 0.911\n",
      "Training: Epoch 5, Batch 51, Loss: 0.752\n",
      "Training: Epoch 5, Batch 52, Loss: 0.774\n",
      "Training: Epoch 5, Batch 53, Loss: 0.489\n",
      "Training: Epoch 5, Batch 54, Loss: 0.513\n",
      "Training: Epoch 5, Batch 55, Loss: 0.806\n",
      "Training: Epoch 5, Batch 56, Loss: 0.795\n",
      "Training: Epoch 5, Batch 57, Loss: 0.735\n",
      "Training: Epoch 5, Batch 58, Loss: 0.603\n",
      "Training: Epoch 5, Batch 59, Loss: 0.426\n",
      "Training: Epoch 5, Batch 60, Loss: 0.539\n",
      "Training: Epoch 5, Batch 61, Loss: 0.938\n",
      "Training: Epoch 5, Batch 62, Loss: 0.741\n",
      "Training: Epoch 5, Batch 63, Loss: 0.893\n",
      "Training: Epoch 5, Batch 64, Loss: 0.791\n",
      "Training: Epoch 5, Batch 65, Loss: 0.633\n",
      "Training: Epoch 5, Batch 66, Loss: 0.659\n",
      "Training: Epoch 5, Batch 67, Loss: 0.478\n",
      "Training: Epoch 5, Batch 68, Loss: 0.626\n",
      "Training: Epoch 5, Batch 69, Loss: 0.606\n",
      "Training: Epoch 5, Batch 70, Loss: 0.945\n",
      "Training: Epoch 5, Batch 71, Loss: 0.937\n",
      "Training: Epoch 5, Batch 72, Loss: 0.829\n",
      "Training: Epoch 5, Batch 73, Loss: 0.622\n",
      "Training: Epoch 5, Batch 74, Loss: 0.742\n",
      "Training: Epoch 5, Batch 75, Loss: 0.586\n",
      "Training: Epoch 5, Batch 76, Loss: 0.66\n",
      "Training: Epoch 5, Batch 77, Loss: 0.568\n",
      "Training: Epoch 5, Batch 78, Loss: 0.583\n",
      "Training: Epoch 5, Batch 79, Loss: 0.578\n",
      "Training: Epoch 5, Batch 80, Loss: 0.926\n",
      "Training: Epoch 5, Batch 81, Loss: 0.539\n",
      "Training: Epoch 5, Batch 82, Loss: 0.742\n",
      "Training: Epoch 5, Batch 83, Loss: 0.619\n",
      "Training: Epoch 5, Batch 84, Loss: 0.507\n",
      "Training: Epoch 5, Batch 85, Loss: 0.815\n",
      "Training: Epoch 5, Batch 86, Loss: 0.673\n",
      "Training: Epoch 5, Batch 87, Loss: 0.521\n",
      "Training: Epoch 5, Batch 88, Loss: 0.858\n",
      "Training: Epoch 5, Batch 89, Loss: 0.69\n",
      "Val: Epoch 5, Loss: 0.434\n",
      "Training: Epoch 6, Batch 0, Loss: 0.682\n",
      "Training: Epoch 6, Batch 1, Loss: 0.58\n",
      "Training: Epoch 6, Batch 2, Loss: 0.634\n",
      "Training: Epoch 6, Batch 3, Loss: 0.453\n",
      "Training: Epoch 6, Batch 4, Loss: 0.729\n",
      "Training: Epoch 6, Batch 5, Loss: 0.747\n",
      "Training: Epoch 6, Batch 6, Loss: 0.598\n",
      "Training: Epoch 6, Batch 7, Loss: 0.826\n",
      "Training: Epoch 6, Batch 8, Loss: 0.589\n",
      "Training: Epoch 6, Batch 9, Loss: 0.548\n",
      "Training: Epoch 6, Batch 10, Loss: 0.486\n",
      "Training: Epoch 6, Batch 11, Loss: 0.638\n",
      "Training: Epoch 6, Batch 12, Loss: 0.639\n",
      "Training: Epoch 6, Batch 13, Loss: 0.705\n",
      "Training: Epoch 6, Batch 14, Loss: 1.053\n",
      "Training: Epoch 6, Batch 15, Loss: 0.65\n",
      "Training: Epoch 6, Batch 16, Loss: 0.492\n",
      "Training: Epoch 6, Batch 17, Loss: 0.733\n",
      "Training: Epoch 6, Batch 18, Loss: 0.708\n",
      "Training: Epoch 6, Batch 19, Loss: 0.708\n",
      "Training: Epoch 6, Batch 20, Loss: 0.626\n",
      "Training: Epoch 6, Batch 21, Loss: 0.542\n",
      "Training: Epoch 6, Batch 22, Loss: 0.79\n",
      "Training: Epoch 6, Batch 23, Loss: 0.436\n",
      "Training: Epoch 6, Batch 24, Loss: 0.433\n",
      "Training: Epoch 6, Batch 25, Loss: 0.482\n",
      "Training: Epoch 6, Batch 26, Loss: 0.597\n",
      "Training: Epoch 6, Batch 27, Loss: 0.831\n",
      "Training: Epoch 6, Batch 28, Loss: 0.858\n",
      "Training: Epoch 6, Batch 29, Loss: 0.595\n",
      "Training: Epoch 6, Batch 30, Loss: 0.577\n",
      "Training: Epoch 6, Batch 31, Loss: 0.572\n",
      "Training: Epoch 6, Batch 32, Loss: 0.782\n",
      "Training: Epoch 6, Batch 33, Loss: 0.495\n",
      "Training: Epoch 6, Batch 34, Loss: 0.805\n",
      "Training: Epoch 6, Batch 35, Loss: 0.867\n",
      "Training: Epoch 6, Batch 36, Loss: 0.564\n",
      "Training: Epoch 6, Batch 37, Loss: 0.735\n",
      "Training: Epoch 6, Batch 38, Loss: 0.636\n",
      "Training: Epoch 6, Batch 39, Loss: 0.518\n",
      "Training: Epoch 6, Batch 40, Loss: 0.449\n",
      "Training: Epoch 6, Batch 41, Loss: 0.47\n",
      "Training: Epoch 6, Batch 42, Loss: 0.674\n",
      "Training: Epoch 6, Batch 43, Loss: 0.808\n",
      "Training: Epoch 6, Batch 44, Loss: 0.832\n",
      "Training: Epoch 6, Batch 45, Loss: 0.785\n",
      "Training: Epoch 6, Batch 46, Loss: 0.875\n",
      "Training: Epoch 6, Batch 47, Loss: 0.492\n",
      "Training: Epoch 6, Batch 48, Loss: 0.867\n",
      "Training: Epoch 6, Batch 49, Loss: 0.365\n",
      "Training: Epoch 6, Batch 50, Loss: 0.657\n",
      "Training: Epoch 6, Batch 51, Loss: 0.464\n",
      "Training: Epoch 6, Batch 52, Loss: 0.63\n",
      "Training: Epoch 6, Batch 53, Loss: 0.694\n",
      "Training: Epoch 6, Batch 54, Loss: 0.696\n",
      "Training: Epoch 6, Batch 55, Loss: 0.671\n",
      "Training: Epoch 6, Batch 56, Loss: 0.588\n",
      "Training: Epoch 6, Batch 57, Loss: 1.062\n",
      "Training: Epoch 6, Batch 58, Loss: 0.508\n",
      "Training: Epoch 6, Batch 59, Loss: 0.613\n",
      "Training: Epoch 6, Batch 60, Loss: 0.558\n",
      "Training: Epoch 6, Batch 61, Loss: 0.841\n",
      "Training: Epoch 6, Batch 62, Loss: 0.567\n",
      "Training: Epoch 6, Batch 63, Loss: 0.514\n",
      "Training: Epoch 6, Batch 64, Loss: 0.523\n",
      "Training: Epoch 6, Batch 65, Loss: 0.564\n",
      "Training: Epoch 6, Batch 66, Loss: 0.85\n",
      "Training: Epoch 6, Batch 67, Loss: 0.548\n",
      "Training: Epoch 6, Batch 68, Loss: 0.642\n",
      "Training: Epoch 6, Batch 69, Loss: 0.611\n",
      "Training: Epoch 6, Batch 70, Loss: 0.539\n",
      "Training: Epoch 6, Batch 71, Loss: 0.777\n",
      "Training: Epoch 6, Batch 72, Loss: 0.496\n",
      "Training: Epoch 6, Batch 73, Loss: 0.546\n",
      "Training: Epoch 6, Batch 74, Loss: 0.655\n",
      "Training: Epoch 6, Batch 75, Loss: 0.58\n",
      "Training: Epoch 6, Batch 76, Loss: 0.725\n",
      "Training: Epoch 6, Batch 77, Loss: 0.552\n",
      "Training: Epoch 6, Batch 78, Loss: 0.61\n",
      "Training: Epoch 6, Batch 79, Loss: 0.631\n",
      "Training: Epoch 6, Batch 80, Loss: 0.639\n",
      "Training: Epoch 6, Batch 81, Loss: 0.469\n",
      "Training: Epoch 6, Batch 82, Loss: 0.564\n",
      "Training: Epoch 6, Batch 83, Loss: 0.64\n",
      "Training: Epoch 6, Batch 84, Loss: 0.767\n",
      "Training: Epoch 6, Batch 85, Loss: 0.425\n",
      "Training: Epoch 6, Batch 86, Loss: 0.49\n",
      "Training: Epoch 6, Batch 87, Loss: 0.56\n",
      "Training: Epoch 6, Batch 88, Loss: 0.629\n",
      "Training: Epoch 6, Batch 89, Loss: 0.715\n",
      "Val: Epoch 6, Loss: 0.34\n",
      "Training: Epoch 7, Batch 0, Loss: 0.619\n",
      "Training: Epoch 7, Batch 1, Loss: 0.489\n",
      "Training: Epoch 7, Batch 2, Loss: 0.725\n",
      "Training: Epoch 7, Batch 3, Loss: 0.507\n",
      "Training: Epoch 7, Batch 4, Loss: 0.565\n",
      "Training: Epoch 7, Batch 5, Loss: 0.57\n",
      "Training: Epoch 7, Batch 6, Loss: 0.542\n",
      "Training: Epoch 7, Batch 7, Loss: 0.55\n",
      "Training: Epoch 7, Batch 8, Loss: 0.6\n",
      "Training: Epoch 7, Batch 9, Loss: 0.989\n",
      "Training: Epoch 7, Batch 10, Loss: 0.444\n",
      "Training: Epoch 7, Batch 11, Loss: 0.836\n",
      "Training: Epoch 7, Batch 12, Loss: 0.739\n",
      "Training: Epoch 7, Batch 13, Loss: 0.757\n",
      "Training: Epoch 7, Batch 14, Loss: 0.879\n",
      "Training: Epoch 7, Batch 15, Loss: 0.631\n",
      "Training: Epoch 7, Batch 16, Loss: 0.605\n",
      "Training: Epoch 7, Batch 17, Loss: 0.557\n",
      "Training: Epoch 7, Batch 18, Loss: 0.525\n",
      "Training: Epoch 7, Batch 19, Loss: 0.639\n",
      "Training: Epoch 7, Batch 20, Loss: 0.496\n",
      "Training: Epoch 7, Batch 21, Loss: 0.743\n",
      "Training: Epoch 7, Batch 22, Loss: 0.439\n",
      "Training: Epoch 7, Batch 23, Loss: 0.498\n",
      "Training: Epoch 7, Batch 24, Loss: 0.743\n",
      "Training: Epoch 7, Batch 25, Loss: 0.41\n",
      "Training: Epoch 7, Batch 26, Loss: 0.793\n",
      "Training: Epoch 7, Batch 27, Loss: 0.582\n",
      "Training: Epoch 7, Batch 28, Loss: 0.398\n",
      "Training: Epoch 7, Batch 29, Loss: 0.799\n",
      "Training: Epoch 7, Batch 30, Loss: 0.579\n",
      "Training: Epoch 7, Batch 31, Loss: 0.585\n",
      "Training: Epoch 7, Batch 32, Loss: 0.404\n",
      "Training: Epoch 7, Batch 33, Loss: 0.523\n",
      "Training: Epoch 7, Batch 34, Loss: 0.406\n",
      "Training: Epoch 7, Batch 35, Loss: 0.404\n",
      "Training: Epoch 7, Batch 36, Loss: 0.521\n",
      "Training: Epoch 7, Batch 37, Loss: 0.977\n",
      "Training: Epoch 7, Batch 38, Loss: 0.457\n",
      "Training: Epoch 7, Batch 39, Loss: 0.715\n",
      "Training: Epoch 7, Batch 40, Loss: 0.597\n",
      "Training: Epoch 7, Batch 41, Loss: 0.67\n",
      "Training: Epoch 7, Batch 42, Loss: 0.62\n",
      "Training: Epoch 7, Batch 43, Loss: 0.505\n",
      "Training: Epoch 7, Batch 44, Loss: 0.569\n",
      "Training: Epoch 7, Batch 45, Loss: 0.535\n",
      "Training: Epoch 7, Batch 46, Loss: 0.651\n",
      "Training: Epoch 7, Batch 47, Loss: 0.47\n",
      "Training: Epoch 7, Batch 48, Loss: 0.726\n",
      "Training: Epoch 7, Batch 49, Loss: 0.413\n",
      "Training: Epoch 7, Batch 50, Loss: 0.625\n",
      "Training: Epoch 7, Batch 51, Loss: 0.343\n",
      "Training: Epoch 7, Batch 52, Loss: 0.574\n",
      "Training: Epoch 7, Batch 53, Loss: 0.472\n",
      "Training: Epoch 7, Batch 54, Loss: 0.468\n",
      "Training: Epoch 7, Batch 55, Loss: 0.818\n",
      "Training: Epoch 7, Batch 56, Loss: 0.427\n",
      "Training: Epoch 7, Batch 57, Loss: 0.768\n",
      "Training: Epoch 7, Batch 58, Loss: 0.598\n",
      "Training: Epoch 7, Batch 59, Loss: 0.38\n",
      "Training: Epoch 7, Batch 60, Loss: 0.575\n",
      "Training: Epoch 7, Batch 61, Loss: 0.494\n",
      "Training: Epoch 7, Batch 62, Loss: 0.619\n",
      "Training: Epoch 7, Batch 63, Loss: 0.81\n",
      "Training: Epoch 7, Batch 64, Loss: 0.638\n",
      "Training: Epoch 7, Batch 65, Loss: 0.643\n",
      "Training: Epoch 7, Batch 66, Loss: 0.618\n",
      "Training: Epoch 7, Batch 67, Loss: 0.723\n",
      "Training: Epoch 7, Batch 68, Loss: 0.609\n",
      "Training: Epoch 7, Batch 69, Loss: 0.66\n",
      "Training: Epoch 7, Batch 70, Loss: 0.694\n",
      "Training: Epoch 7, Batch 71, Loss: 0.49\n",
      "Training: Epoch 7, Batch 72, Loss: 0.747\n",
      "Training: Epoch 7, Batch 73, Loss: 0.551\n",
      "Training: Epoch 7, Batch 74, Loss: 0.508\n",
      "Training: Epoch 7, Batch 75, Loss: 0.433\n",
      "Training: Epoch 7, Batch 76, Loss: 0.44\n",
      "Training: Epoch 7, Batch 77, Loss: 0.602\n",
      "Training: Epoch 7, Batch 78, Loss: 0.524\n",
      "Training: Epoch 7, Batch 79, Loss: 0.649\n",
      "Training: Epoch 7, Batch 80, Loss: 1.216\n",
      "Training: Epoch 7, Batch 81, Loss: 0.457\n",
      "Training: Epoch 7, Batch 82, Loss: 0.552\n",
      "Training: Epoch 7, Batch 83, Loss: 0.964\n",
      "Training: Epoch 7, Batch 84, Loss: 1.111\n",
      "Training: Epoch 7, Batch 85, Loss: 0.507\n",
      "Training: Epoch 7, Batch 86, Loss: 0.458\n",
      "Training: Epoch 7, Batch 87, Loss: 0.605\n",
      "Training: Epoch 7, Batch 88, Loss: 0.61\n",
      "Training: Epoch 7, Batch 89, Loss: 0.685\n",
      "Val: Epoch 7, Loss: 0.401\n",
      "Training: Epoch 8, Batch 0, Loss: 0.524\n",
      "Training: Epoch 8, Batch 1, Loss: 0.571\n",
      "Training: Epoch 8, Batch 2, Loss: 0.49\n",
      "Training: Epoch 8, Batch 3, Loss: 0.634\n",
      "Training: Epoch 8, Batch 4, Loss: 0.846\n",
      "Training: Epoch 8, Batch 5, Loss: 0.535\n",
      "Training: Epoch 8, Batch 6, Loss: 0.818\n",
      "Training: Epoch 8, Batch 7, Loss: 0.486\n",
      "Training: Epoch 8, Batch 8, Loss: 0.626\n",
      "Training: Epoch 8, Batch 9, Loss: 0.735\n",
      "Training: Epoch 8, Batch 10, Loss: 0.669\n",
      "Training: Epoch 8, Batch 11, Loss: 0.496\n",
      "Training: Epoch 8, Batch 12, Loss: 0.58\n",
      "Training: Epoch 8, Batch 13, Loss: 0.535\n",
      "Training: Epoch 8, Batch 14, Loss: 0.735\n",
      "Training: Epoch 8, Batch 15, Loss: 0.515\n",
      "Training: Epoch 8, Batch 16, Loss: 0.474\n",
      "Training: Epoch 8, Batch 17, Loss: 0.512\n",
      "Training: Epoch 8, Batch 18, Loss: 0.629\n",
      "Training: Epoch 8, Batch 19, Loss: 0.463\n",
      "Training: Epoch 8, Batch 20, Loss: 0.504\n",
      "Training: Epoch 8, Batch 21, Loss: 0.431\n",
      "Training: Epoch 8, Batch 22, Loss: 0.902\n",
      "Training: Epoch 8, Batch 23, Loss: 0.579\n",
      "Training: Epoch 8, Batch 24, Loss: 0.78\n",
      "Training: Epoch 8, Batch 25, Loss: 0.629\n",
      "Training: Epoch 8, Batch 26, Loss: 0.731\n",
      "Training: Epoch 8, Batch 27, Loss: 0.53\n",
      "Training: Epoch 8, Batch 28, Loss: 0.571\n",
      "Training: Epoch 8, Batch 29, Loss: 0.435\n",
      "Training: Epoch 8, Batch 30, Loss: 0.797\n",
      "Training: Epoch 8, Batch 31, Loss: 0.441\n",
      "Training: Epoch 8, Batch 32, Loss: 0.543\n",
      "Training: Epoch 8, Batch 33, Loss: 0.515\n",
      "Training: Epoch 8, Batch 34, Loss: 0.546\n",
      "Training: Epoch 8, Batch 35, Loss: 0.499\n",
      "Training: Epoch 8, Batch 36, Loss: 0.654\n",
      "Training: Epoch 8, Batch 37, Loss: 0.673\n",
      "Training: Epoch 8, Batch 38, Loss: 0.625\n",
      "Training: Epoch 8, Batch 39, Loss: 0.52\n",
      "Training: Epoch 8, Batch 40, Loss: 0.52\n",
      "Training: Epoch 8, Batch 41, Loss: 0.845\n",
      "Training: Epoch 8, Batch 42, Loss: 0.697\n",
      "Training: Epoch 8, Batch 43, Loss: 0.546\n",
      "Training: Epoch 8, Batch 44, Loss: 0.638\n",
      "Training: Epoch 8, Batch 45, Loss: 0.584\n",
      "Training: Epoch 8, Batch 46, Loss: 0.784\n",
      "Training: Epoch 8, Batch 47, Loss: 0.624\n",
      "Training: Epoch 8, Batch 48, Loss: 0.478\n",
      "Training: Epoch 8, Batch 49, Loss: 0.484\n",
      "Training: Epoch 8, Batch 50, Loss: 0.515\n",
      "Training: Epoch 8, Batch 51, Loss: 0.636\n",
      "Training: Epoch 8, Batch 52, Loss: 0.571\n",
      "Training: Epoch 8, Batch 53, Loss: 0.57\n",
      "Training: Epoch 8, Batch 54, Loss: 0.535\n",
      "Training: Epoch 8, Batch 55, Loss: 0.612\n",
      "Training: Epoch 8, Batch 56, Loss: 0.458\n",
      "Training: Epoch 8, Batch 57, Loss: 0.378\n",
      "Training: Epoch 8, Batch 58, Loss: 0.802\n",
      "Training: Epoch 8, Batch 59, Loss: 0.508\n",
      "Training: Epoch 8, Batch 60, Loss: 0.432\n",
      "Training: Epoch 8, Batch 61, Loss: 0.744\n",
      "Training: Epoch 8, Batch 62, Loss: 0.56\n",
      "Training: Epoch 8, Batch 63, Loss: 0.743\n",
      "Training: Epoch 8, Batch 64, Loss: 0.486\n",
      "Training: Epoch 8, Batch 65, Loss: 0.651\n",
      "Training: Epoch 8, Batch 66, Loss: 0.482\n",
      "Training: Epoch 8, Batch 67, Loss: 0.451\n",
      "Training: Epoch 8, Batch 68, Loss: 0.505\n",
      "Training: Epoch 8, Batch 69, Loss: 0.595\n",
      "Training: Epoch 8, Batch 70, Loss: 0.488\n",
      "Training: Epoch 8, Batch 71, Loss: 0.477\n",
      "Training: Epoch 8, Batch 72, Loss: 0.464\n",
      "Training: Epoch 8, Batch 73, Loss: 0.485\n",
      "Training: Epoch 8, Batch 74, Loss: 0.507\n",
      "Training: Epoch 8, Batch 75, Loss: 0.393\n",
      "Training: Epoch 8, Batch 76, Loss: 0.699\n",
      "Training: Epoch 8, Batch 77, Loss: 0.545\n",
      "Training: Epoch 8, Batch 78, Loss: 0.641\n",
      "Training: Epoch 8, Batch 79, Loss: 0.598\n",
      "Training: Epoch 8, Batch 80, Loss: 0.748\n",
      "Training: Epoch 8, Batch 81, Loss: 0.51\n",
      "Training: Epoch 8, Batch 82, Loss: 1.223\n",
      "Training: Epoch 8, Batch 83, Loss: 1.054\n",
      "Training: Epoch 8, Batch 84, Loss: 0.471\n",
      "Training: Epoch 8, Batch 85, Loss: 0.517\n",
      "Training: Epoch 8, Batch 86, Loss: 0.537\n",
      "Training: Epoch 8, Batch 87, Loss: 0.635\n",
      "Training: Epoch 8, Batch 88, Loss: 0.619\n",
      "Training: Epoch 8, Batch 89, Loss: 0.649\n",
      "Val: Epoch 8, Loss: 0.524\n",
      "Training: Epoch 9, Batch 0, Loss: 0.552\n",
      "Training: Epoch 9, Batch 1, Loss: 0.651\n",
      "Training: Epoch 9, Batch 2, Loss: 0.77\n",
      "Training: Epoch 9, Batch 3, Loss: 0.642\n",
      "Training: Epoch 9, Batch 4, Loss: 0.503\n",
      "Training: Epoch 9, Batch 5, Loss: 0.745\n",
      "Training: Epoch 9, Batch 6, Loss: 0.604\n",
      "Training: Epoch 9, Batch 7, Loss: 0.979\n",
      "Training: Epoch 9, Batch 8, Loss: 0.58\n",
      "Training: Epoch 9, Batch 9, Loss: 0.844\n",
      "Training: Epoch 9, Batch 10, Loss: 0.675\n",
      "Training: Epoch 9, Batch 11, Loss: 0.61\n",
      "Training: Epoch 9, Batch 12, Loss: 0.594\n",
      "Training: Epoch 9, Batch 13, Loss: 0.686\n",
      "Training: Epoch 9, Batch 14, Loss: 0.495\n",
      "Training: Epoch 9, Batch 15, Loss: 0.574\n",
      "Training: Epoch 9, Batch 16, Loss: 0.634\n",
      "Training: Epoch 9, Batch 17, Loss: 0.614\n",
      "Training: Epoch 9, Batch 18, Loss: 0.742\n",
      "Training: Epoch 9, Batch 19, Loss: 0.567\n",
      "Training: Epoch 9, Batch 20, Loss: 0.576\n",
      "Training: Epoch 9, Batch 21, Loss: 0.595\n",
      "Training: Epoch 9, Batch 22, Loss: 0.456\n",
      "Training: Epoch 9, Batch 23, Loss: 0.497\n",
      "Training: Epoch 9, Batch 24, Loss: 0.682\n",
      "Training: Epoch 9, Batch 25, Loss: 0.457\n",
      "Training: Epoch 9, Batch 26, Loss: 0.565\n",
      "Training: Epoch 9, Batch 27, Loss: 0.466\n",
      "Training: Epoch 9, Batch 28, Loss: 0.542\n",
      "Training: Epoch 9, Batch 29, Loss: 0.61\n",
      "Training: Epoch 9, Batch 30, Loss: 0.579\n",
      "Training: Epoch 9, Batch 31, Loss: 0.814\n",
      "Training: Epoch 9, Batch 32, Loss: 0.516\n",
      "Training: Epoch 9, Batch 33, Loss: 0.614\n",
      "Training: Epoch 9, Batch 34, Loss: 0.72\n",
      "Training: Epoch 9, Batch 35, Loss: 0.529\n",
      "Training: Epoch 9, Batch 36, Loss: 0.463\n",
      "Training: Epoch 9, Batch 37, Loss: 0.58\n",
      "Training: Epoch 9, Batch 38, Loss: 0.399\n",
      "Training: Epoch 9, Batch 39, Loss: 0.843\n",
      "Training: Epoch 9, Batch 40, Loss: 0.573\n",
      "Training: Epoch 9, Batch 41, Loss: 0.913\n",
      "Training: Epoch 9, Batch 42, Loss: 0.493\n",
      "Training: Epoch 9, Batch 43, Loss: 0.602\n",
      "Training: Epoch 9, Batch 44, Loss: 0.441\n",
      "Training: Epoch 9, Batch 45, Loss: 0.682\n",
      "Training: Epoch 9, Batch 46, Loss: 0.424\n",
      "Training: Epoch 9, Batch 47, Loss: 0.798\n",
      "Training: Epoch 9, Batch 48, Loss: 0.399\n",
      "Training: Epoch 9, Batch 49, Loss: 0.582\n",
      "Training: Epoch 9, Batch 50, Loss: 0.687\n",
      "Training: Epoch 9, Batch 51, Loss: 0.567\n",
      "Training: Epoch 9, Batch 52, Loss: 0.59\n",
      "Training: Epoch 9, Batch 53, Loss: 0.669\n",
      "Training: Epoch 9, Batch 54, Loss: 0.596\n",
      "Training: Epoch 9, Batch 55, Loss: 0.46\n",
      "Training: Epoch 9, Batch 56, Loss: 0.509\n",
      "Training: Epoch 9, Batch 57, Loss: 0.789\n",
      "Training: Epoch 9, Batch 58, Loss: 0.52\n",
      "Training: Epoch 9, Batch 59, Loss: 0.78\n",
      "Training: Epoch 9, Batch 60, Loss: 0.6\n",
      "Training: Epoch 9, Batch 61, Loss: 0.575\n",
      "Training: Epoch 9, Batch 62, Loss: 0.419\n",
      "Training: Epoch 9, Batch 63, Loss: 0.825\n",
      "Training: Epoch 9, Batch 64, Loss: 0.568\n",
      "Training: Epoch 9, Batch 65, Loss: 0.382\n",
      "Training: Epoch 9, Batch 66, Loss: 0.51\n",
      "Training: Epoch 9, Batch 67, Loss: 0.346\n",
      "Training: Epoch 9, Batch 68, Loss: 0.71\n",
      "Training: Epoch 9, Batch 69, Loss: 0.387\n",
      "Training: Epoch 9, Batch 70, Loss: 1.027\n",
      "Training: Epoch 9, Batch 71, Loss: 0.517\n",
      "Training: Epoch 9, Batch 72, Loss: 0.619\n",
      "Training: Epoch 9, Batch 73, Loss: 0.497\n",
      "Training: Epoch 9, Batch 74, Loss: 0.514\n",
      "Training: Epoch 9, Batch 75, Loss: 0.467\n",
      "Training: Epoch 9, Batch 76, Loss: 0.891\n",
      "Training: Epoch 9, Batch 77, Loss: 0.331\n",
      "Training: Epoch 9, Batch 78, Loss: 0.472\n",
      "Training: Epoch 9, Batch 79, Loss: 0.719\n",
      "Training: Epoch 9, Batch 80, Loss: 0.634\n",
      "Training: Epoch 9, Batch 81, Loss: 0.578\n",
      "Training: Epoch 9, Batch 82, Loss: 0.64\n",
      "Training: Epoch 9, Batch 83, Loss: 0.532\n",
      "Training: Epoch 9, Batch 84, Loss: 0.721\n",
      "Training: Epoch 9, Batch 85, Loss: 0.473\n",
      "Training: Epoch 9, Batch 86, Loss: 0.516\n",
      "Training: Epoch 9, Batch 87, Loss: 0.566\n",
      "Training: Epoch 9, Batch 88, Loss: 0.396\n",
      "Training: Epoch 9, Batch 89, Loss: 0.723\n",
      "Val: Epoch 9, Loss: 0.38\n",
      "Training: Epoch 10, Batch 0, Loss: 0.475\n",
      "Training: Epoch 10, Batch 1, Loss: 0.497\n",
      "Training: Epoch 10, Batch 2, Loss: 0.488\n",
      "Training: Epoch 10, Batch 3, Loss: 0.536\n",
      "Training: Epoch 10, Batch 4, Loss: 0.457\n",
      "Training: Epoch 10, Batch 5, Loss: 0.658\n",
      "Training: Epoch 10, Batch 6, Loss: 0.792\n",
      "Training: Epoch 10, Batch 7, Loss: 0.544\n",
      "Training: Epoch 10, Batch 8, Loss: 0.576\n",
      "Training: Epoch 10, Batch 9, Loss: 0.532\n",
      "Training: Epoch 10, Batch 10, Loss: 0.573\n",
      "Training: Epoch 10, Batch 11, Loss: 0.585\n",
      "Training: Epoch 10, Batch 12, Loss: 0.575\n",
      "Training: Epoch 10, Batch 13, Loss: 0.51\n",
      "Training: Epoch 10, Batch 14, Loss: 0.479\n",
      "Training: Epoch 10, Batch 15, Loss: 0.429\n",
      "Training: Epoch 10, Batch 16, Loss: 0.534\n",
      "Training: Epoch 10, Batch 17, Loss: 0.573\n",
      "Training: Epoch 10, Batch 18, Loss: 0.726\n",
      "Training: Epoch 10, Batch 19, Loss: 0.698\n",
      "Training: Epoch 10, Batch 20, Loss: 0.589\n",
      "Training: Epoch 10, Batch 21, Loss: 0.464\n",
      "Training: Epoch 10, Batch 22, Loss: 0.375\n",
      "Training: Epoch 10, Batch 23, Loss: 0.46\n",
      "Training: Epoch 10, Batch 24, Loss: 0.782\n",
      "Training: Epoch 10, Batch 25, Loss: 0.49\n",
      "Training: Epoch 10, Batch 26, Loss: 0.442\n",
      "Training: Epoch 10, Batch 27, Loss: 0.659\n",
      "Training: Epoch 10, Batch 28, Loss: 0.848\n",
      "Training: Epoch 10, Batch 29, Loss: 0.53\n",
      "Training: Epoch 10, Batch 30, Loss: 0.652\n",
      "Training: Epoch 10, Batch 31, Loss: 0.553\n",
      "Training: Epoch 10, Batch 32, Loss: 0.74\n",
      "Training: Epoch 10, Batch 33, Loss: 0.582\n",
      "Training: Epoch 10, Batch 34, Loss: 0.411\n",
      "Training: Epoch 10, Batch 35, Loss: 0.758\n",
      "Training: Epoch 10, Batch 36, Loss: 0.488\n",
      "Training: Epoch 10, Batch 37, Loss: 0.543\n",
      "Training: Epoch 10, Batch 38, Loss: 0.815\n",
      "Training: Epoch 10, Batch 39, Loss: 0.437\n",
      "Training: Epoch 10, Batch 40, Loss: 0.573\n",
      "Training: Epoch 10, Batch 41, Loss: 0.494\n",
      "Training: Epoch 10, Batch 42, Loss: 0.478\n",
      "Training: Epoch 10, Batch 43, Loss: 0.59\n",
      "Training: Epoch 10, Batch 44, Loss: 0.407\n",
      "Training: Epoch 10, Batch 45, Loss: 0.401\n",
      "Training: Epoch 10, Batch 46, Loss: 0.417\n",
      "Training: Epoch 10, Batch 47, Loss: 0.472\n",
      "Training: Epoch 10, Batch 48, Loss: 1.453\n",
      "Training: Epoch 10, Batch 49, Loss: 1.102\n",
      "Training: Epoch 10, Batch 50, Loss: 0.402\n",
      "Training: Epoch 10, Batch 51, Loss: 0.522\n",
      "Training: Epoch 10, Batch 52, Loss: 0.479\n",
      "Training: Epoch 10, Batch 53, Loss: 0.784\n",
      "Training: Epoch 10, Batch 54, Loss: 0.88\n",
      "Training: Epoch 10, Batch 55, Loss: 0.523\n",
      "Training: Epoch 10, Batch 56, Loss: 0.543\n",
      "Training: Epoch 10, Batch 57, Loss: 0.638\n",
      "Training: Epoch 10, Batch 58, Loss: 0.924\n",
      "Training: Epoch 10, Batch 59, Loss: 0.793\n",
      "Training: Epoch 10, Batch 60, Loss: 0.415\n",
      "Training: Epoch 10, Batch 61, Loss: 0.452\n",
      "Training: Epoch 10, Batch 62, Loss: 0.454\n",
      "Training: Epoch 10, Batch 63, Loss: 0.495\n",
      "Training: Epoch 10, Batch 64, Loss: 0.652\n",
      "Training: Epoch 10, Batch 65, Loss: 0.62\n",
      "Training: Epoch 10, Batch 66, Loss: 0.46\n",
      "Training: Epoch 10, Batch 67, Loss: 0.591\n",
      "Training: Epoch 10, Batch 68, Loss: 0.63\n",
      "Training: Epoch 10, Batch 69, Loss: 0.658\n",
      "Training: Epoch 10, Batch 70, Loss: 0.821\n",
      "Training: Epoch 10, Batch 71, Loss: 0.67\n",
      "Training: Epoch 10, Batch 72, Loss: 0.498\n",
      "Training: Epoch 10, Batch 73, Loss: 0.602\n",
      "Training: Epoch 10, Batch 74, Loss: 0.56\n",
      "Training: Epoch 10, Batch 75, Loss: 0.684\n",
      "Training: Epoch 10, Batch 76, Loss: 0.532\n",
      "Training: Epoch 10, Batch 77, Loss: 0.697\n",
      "Training: Epoch 10, Batch 78, Loss: 0.541\n",
      "Training: Epoch 10, Batch 79, Loss: 0.386\n",
      "Training: Epoch 10, Batch 80, Loss: 0.78\n",
      "Training: Epoch 10, Batch 81, Loss: 0.67\n",
      "Training: Epoch 10, Batch 82, Loss: 0.4\n",
      "Training: Epoch 10, Batch 83, Loss: 0.434\n",
      "Training: Epoch 10, Batch 84, Loss: 0.535\n",
      "Training: Epoch 10, Batch 85, Loss: 0.69\n",
      "Training: Epoch 10, Batch 86, Loss: 0.664\n",
      "Training: Epoch 10, Batch 87, Loss: 0.483\n",
      "Training: Epoch 10, Batch 88, Loss: 0.47\n",
      "Training: Epoch 10, Batch 89, Loss: 0.479\n",
      "Val: Epoch 10, Loss: 0.355\n",
      "Training: Epoch 11, Batch 0, Loss: 0.504\n",
      "Training: Epoch 11, Batch 1, Loss: 0.35\n",
      "Training: Epoch 11, Batch 2, Loss: 0.447\n",
      "Training: Epoch 11, Batch 3, Loss: 0.6\n",
      "Training: Epoch 11, Batch 4, Loss: 0.841\n",
      "Training: Epoch 11, Batch 5, Loss: 0.518\n",
      "Training: Epoch 11, Batch 6, Loss: 0.512\n",
      "Training: Epoch 11, Batch 7, Loss: 0.698\n",
      "Training: Epoch 11, Batch 8, Loss: 0.458\n",
      "Training: Epoch 11, Batch 9, Loss: 0.442\n",
      "Training: Epoch 11, Batch 10, Loss: 0.584\n",
      "Training: Epoch 11, Batch 11, Loss: 0.736\n",
      "Training: Epoch 11, Batch 12, Loss: 0.656\n",
      "Training: Epoch 11, Batch 13, Loss: 0.473\n",
      "Training: Epoch 11, Batch 14, Loss: 0.496\n",
      "Training: Epoch 11, Batch 15, Loss: 0.37\n",
      "Training: Epoch 11, Batch 16, Loss: 1.012\n",
      "Training: Epoch 11, Batch 17, Loss: 0.43\n",
      "Training: Epoch 11, Batch 18, Loss: 0.531\n",
      "Training: Epoch 11, Batch 19, Loss: 0.626\n",
      "Training: Epoch 11, Batch 20, Loss: 0.547\n",
      "Training: Epoch 11, Batch 21, Loss: 0.739\n",
      "Training: Epoch 11, Batch 22, Loss: 0.795\n",
      "Training: Epoch 11, Batch 23, Loss: 0.458\n",
      "Training: Epoch 11, Batch 24, Loss: 0.468\n",
      "Training: Epoch 11, Batch 25, Loss: 0.535\n",
      "Training: Epoch 11, Batch 26, Loss: 0.523\n",
      "Training: Epoch 11, Batch 27, Loss: 0.533\n",
      "Training: Epoch 11, Batch 28, Loss: 0.585\n",
      "Training: Epoch 11, Batch 29, Loss: 0.695\n",
      "Training: Epoch 11, Batch 30, Loss: 0.548\n",
      "Training: Epoch 11, Batch 31, Loss: 0.685\n",
      "Training: Epoch 11, Batch 32, Loss: 0.708\n",
      "Training: Epoch 11, Batch 33, Loss: 0.508\n",
      "Training: Epoch 11, Batch 34, Loss: 0.459\n",
      "Training: Epoch 11, Batch 35, Loss: 0.57\n",
      "Training: Epoch 11, Batch 36, Loss: 0.608\n",
      "Training: Epoch 11, Batch 37, Loss: 0.447\n",
      "Training: Epoch 11, Batch 38, Loss: 0.447\n",
      "Training: Epoch 11, Batch 39, Loss: 0.662\n",
      "Training: Epoch 11, Batch 40, Loss: 0.542\n",
      "Training: Epoch 11, Batch 41, Loss: 0.687\n",
      "Training: Epoch 11, Batch 42, Loss: 0.559\n",
      "Training: Epoch 11, Batch 43, Loss: 0.405\n",
      "Training: Epoch 11, Batch 44, Loss: 0.625\n",
      "Training: Epoch 11, Batch 45, Loss: 0.493\n",
      "Training: Epoch 11, Batch 46, Loss: 0.652\n",
      "Training: Epoch 11, Batch 47, Loss: 0.627\n",
      "Training: Epoch 11, Batch 48, Loss: 0.454\n",
      "Training: Epoch 11, Batch 49, Loss: 0.517\n",
      "Training: Epoch 11, Batch 50, Loss: 0.635\n",
      "Training: Epoch 11, Batch 51, Loss: 0.477\n",
      "Training: Epoch 11, Batch 52, Loss: 0.551\n",
      "Training: Epoch 11, Batch 53, Loss: 0.373\n",
      "Training: Epoch 11, Batch 54, Loss: 0.61\n",
      "Training: Epoch 11, Batch 55, Loss: 0.383\n",
      "Training: Epoch 11, Batch 56, Loss: 0.603\n",
      "Training: Epoch 11, Batch 57, Loss: 0.689\n",
      "Training: Epoch 11, Batch 58, Loss: 0.341\n",
      "Training: Epoch 11, Batch 59, Loss: 0.508\n",
      "Training: Epoch 11, Batch 60, Loss: 0.657\n",
      "Training: Epoch 11, Batch 61, Loss: 0.462\n",
      "Training: Epoch 11, Batch 62, Loss: 0.341\n",
      "Training: Epoch 11, Batch 63, Loss: 0.605\n",
      "Training: Epoch 11, Batch 64, Loss: 0.524\n",
      "Training: Epoch 11, Batch 65, Loss: 0.627\n",
      "Training: Epoch 11, Batch 66, Loss: 0.55\n",
      "Training: Epoch 11, Batch 67, Loss: 0.551\n",
      "Training: Epoch 11, Batch 68, Loss: 0.43\n",
      "Training: Epoch 11, Batch 69, Loss: 0.541\n",
      "Training: Epoch 11, Batch 70, Loss: 0.439\n",
      "Training: Epoch 11, Batch 71, Loss: 0.501\n",
      "Training: Epoch 11, Batch 72, Loss: 0.502\n",
      "Training: Epoch 11, Batch 73, Loss: 0.625\n",
      "Training: Epoch 11, Batch 74, Loss: 0.593\n",
      "Training: Epoch 11, Batch 75, Loss: 0.51\n",
      "Training: Epoch 11, Batch 76, Loss: 0.512\n",
      "Training: Epoch 11, Batch 77, Loss: 0.318\n",
      "Training: Epoch 11, Batch 78, Loss: 0.77\n",
      "Training: Epoch 11, Batch 79, Loss: 0.365\n",
      "Training: Epoch 11, Batch 80, Loss: 0.803\n",
      "Training: Epoch 11, Batch 81, Loss: 0.54\n",
      "Training: Epoch 11, Batch 82, Loss: 0.414\n",
      "Training: Epoch 11, Batch 83, Loss: 0.638\n",
      "Training: Epoch 11, Batch 84, Loss: 0.675\n",
      "Training: Epoch 11, Batch 85, Loss: 0.476\n",
      "Training: Epoch 11, Batch 86, Loss: 0.497\n",
      "Training: Epoch 11, Batch 87, Loss: 0.484\n",
      "Training: Epoch 11, Batch 88, Loss: 0.643\n",
      "Training: Epoch 11, Batch 89, Loss: 0.542\n",
      "Val: Epoch 11, Loss: 0.334\n",
      "Training: Epoch 12, Batch 0, Loss: 0.84\n",
      "Training: Epoch 12, Batch 1, Loss: 0.514\n",
      "Training: Epoch 12, Batch 2, Loss: 0.551\n",
      "Training: Epoch 12, Batch 3, Loss: 0.553\n",
      "Training: Epoch 12, Batch 4, Loss: 0.44\n",
      "Training: Epoch 12, Batch 5, Loss: 0.539\n",
      "Training: Epoch 12, Batch 6, Loss: 0.486\n",
      "Training: Epoch 12, Batch 7, Loss: 0.507\n",
      "Training: Epoch 12, Batch 8, Loss: 0.53\n",
      "Training: Epoch 12, Batch 9, Loss: 0.496\n",
      "Training: Epoch 12, Batch 10, Loss: 0.482\n",
      "Training: Epoch 12, Batch 11, Loss: 0.64\n",
      "Training: Epoch 12, Batch 12, Loss: 0.596\n",
      "Training: Epoch 12, Batch 13, Loss: 0.38\n",
      "Training: Epoch 12, Batch 14, Loss: 0.456\n",
      "Training: Epoch 12, Batch 15, Loss: 0.83\n",
      "Training: Epoch 12, Batch 16, Loss: 0.642\n",
      "Training: Epoch 12, Batch 17, Loss: 0.65\n",
      "Training: Epoch 12, Batch 18, Loss: 0.494\n",
      "Training: Epoch 12, Batch 19, Loss: 0.467\n",
      "Training: Epoch 12, Batch 20, Loss: 0.523\n",
      "Training: Epoch 12, Batch 21, Loss: 0.388\n",
      "Training: Epoch 12, Batch 22, Loss: 0.533\n",
      "Training: Epoch 12, Batch 23, Loss: 0.445\n",
      "Training: Epoch 12, Batch 24, Loss: 0.507\n",
      "Training: Epoch 12, Batch 25, Loss: 0.727\n",
      "Training: Epoch 12, Batch 26, Loss: 0.427\n",
      "Training: Epoch 12, Batch 27, Loss: 0.53\n",
      "Training: Epoch 12, Batch 28, Loss: 0.582\n",
      "Training: Epoch 12, Batch 29, Loss: 0.482\n",
      "Training: Epoch 12, Batch 30, Loss: 0.518\n",
      "Training: Epoch 12, Batch 31, Loss: 0.542\n",
      "Training: Epoch 12, Batch 32, Loss: 0.54\n",
      "Training: Epoch 12, Batch 33, Loss: 0.453\n",
      "Training: Epoch 12, Batch 34, Loss: 0.781\n",
      "Training: Epoch 12, Batch 35, Loss: 0.515\n",
      "Training: Epoch 12, Batch 36, Loss: 0.422\n",
      "Training: Epoch 12, Batch 37, Loss: 0.596\n",
      "Training: Epoch 12, Batch 38, Loss: 0.542\n",
      "Training: Epoch 12, Batch 39, Loss: 0.492\n",
      "Training: Epoch 12, Batch 40, Loss: 0.428\n",
      "Training: Epoch 12, Batch 41, Loss: 0.489\n",
      "Training: Epoch 12, Batch 42, Loss: 0.493\n",
      "Training: Epoch 12, Batch 43, Loss: 0.456\n",
      "Training: Epoch 12, Batch 44, Loss: 0.647\n",
      "Training: Epoch 12, Batch 45, Loss: 0.492\n",
      "Training: Epoch 12, Batch 46, Loss: 0.494\n",
      "Training: Epoch 12, Batch 47, Loss: 0.552\n",
      "Training: Epoch 12, Batch 48, Loss: 0.392\n",
      "Training: Epoch 12, Batch 49, Loss: 0.495\n",
      "Training: Epoch 12, Batch 50, Loss: 0.414\n",
      "Training: Epoch 12, Batch 51, Loss: 0.598\n",
      "Training: Epoch 12, Batch 52, Loss: 0.805\n",
      "Training: Epoch 12, Batch 53, Loss: 0.499\n",
      "Training: Epoch 12, Batch 54, Loss: 0.653\n",
      "Training: Epoch 12, Batch 55, Loss: 0.477\n",
      "Training: Epoch 12, Batch 56, Loss: 0.644\n",
      "Training: Epoch 12, Batch 57, Loss: 0.548\n",
      "Training: Epoch 12, Batch 58, Loss: 0.675\n",
      "Training: Epoch 12, Batch 59, Loss: 0.477\n",
      "Training: Epoch 12, Batch 60, Loss: 0.588\n",
      "Training: Epoch 12, Batch 61, Loss: 0.603\n",
      "Training: Epoch 12, Batch 62, Loss: 0.593\n",
      "Training: Epoch 12, Batch 63, Loss: 0.595\n",
      "Training: Epoch 12, Batch 64, Loss: 0.475\n",
      "Training: Epoch 12, Batch 65, Loss: 0.549\n",
      "Training: Epoch 12, Batch 66, Loss: 0.615\n",
      "Training: Epoch 12, Batch 67, Loss: 0.555\n",
      "Training: Epoch 12, Batch 68, Loss: 0.433\n",
      "Training: Epoch 12, Batch 69, Loss: 0.562\n",
      "Training: Epoch 12, Batch 70, Loss: 0.54\n",
      "Training: Epoch 12, Batch 71, Loss: 0.443\n",
      "Training: Epoch 12, Batch 72, Loss: 0.772\n",
      "Training: Epoch 12, Batch 73, Loss: 0.497\n",
      "Training: Epoch 12, Batch 74, Loss: 0.471\n",
      "Training: Epoch 12, Batch 75, Loss: 0.428\n",
      "Training: Epoch 12, Batch 76, Loss: 0.633\n",
      "Training: Epoch 12, Batch 77, Loss: 0.538\n",
      "Training: Epoch 12, Batch 78, Loss: 0.331\n",
      "Training: Epoch 12, Batch 79, Loss: 0.417\n",
      "Training: Epoch 12, Batch 80, Loss: 0.549\n",
      "Training: Epoch 12, Batch 81, Loss: 0.355\n",
      "Training: Epoch 12, Batch 82, Loss: 0.572\n",
      "Training: Epoch 12, Batch 83, Loss: 0.548\n",
      "Training: Epoch 12, Batch 84, Loss: 0.451\n",
      "Training: Epoch 12, Batch 85, Loss: 0.281\n",
      "Training: Epoch 12, Batch 86, Loss: 0.519\n",
      "Training: Epoch 12, Batch 87, Loss: 0.933\n",
      "Training: Epoch 12, Batch 88, Loss: 1.164\n",
      "Training: Epoch 12, Batch 89, Loss: 0.593\n",
      "Val: Epoch 12, Loss: 0.311\n",
      "Training: Epoch 13, Batch 0, Loss: 0.532\n",
      "Training: Epoch 13, Batch 1, Loss: 0.462\n",
      "Training: Epoch 13, Batch 2, Loss: 0.527\n",
      "Training: Epoch 13, Batch 3, Loss: 0.592\n",
      "Training: Epoch 13, Batch 4, Loss: 0.71\n",
      "Training: Epoch 13, Batch 5, Loss: 0.736\n",
      "Training: Epoch 13, Batch 6, Loss: 0.427\n",
      "Training: Epoch 13, Batch 7, Loss: 0.663\n",
      "Training: Epoch 13, Batch 8, Loss: 0.638\n",
      "Training: Epoch 13, Batch 9, Loss: 0.422\n",
      "Training: Epoch 13, Batch 10, Loss: 0.595\n",
      "Training: Epoch 13, Batch 11, Loss: 0.44\n",
      "Training: Epoch 13, Batch 12, Loss: 0.4\n",
      "Training: Epoch 13, Batch 13, Loss: 0.502\n",
      "Training: Epoch 13, Batch 14, Loss: 0.449\n",
      "Training: Epoch 13, Batch 15, Loss: 0.379\n",
      "Training: Epoch 13, Batch 16, Loss: 0.819\n",
      "Training: Epoch 13, Batch 17, Loss: 0.554\n",
      "Training: Epoch 13, Batch 18, Loss: 0.48\n",
      "Training: Epoch 13, Batch 19, Loss: 0.54\n",
      "Training: Epoch 13, Batch 20, Loss: 0.561\n",
      "Training: Epoch 13, Batch 21, Loss: 0.431\n",
      "Training: Epoch 13, Batch 22, Loss: 0.54\n",
      "Training: Epoch 13, Batch 23, Loss: 0.411\n",
      "Training: Epoch 13, Batch 24, Loss: 0.615\n",
      "Training: Epoch 13, Batch 25, Loss: 0.617\n",
      "Training: Epoch 13, Batch 26, Loss: 0.576\n",
      "Training: Epoch 13, Batch 27, Loss: 0.51\n",
      "Training: Epoch 13, Batch 28, Loss: 0.564\n",
      "Training: Epoch 13, Batch 29, Loss: 0.519\n",
      "Training: Epoch 13, Batch 30, Loss: 0.719\n",
      "Training: Epoch 13, Batch 31, Loss: 0.493\n",
      "Training: Epoch 13, Batch 32, Loss: 0.589\n",
      "Training: Epoch 13, Batch 33, Loss: 0.731\n",
      "Training: Epoch 13, Batch 34, Loss: 0.297\n",
      "Training: Epoch 13, Batch 35, Loss: 0.565\n",
      "Training: Epoch 13, Batch 36, Loss: 0.414\n",
      "Training: Epoch 13, Batch 37, Loss: 0.627\n",
      "Training: Epoch 13, Batch 38, Loss: 0.602\n",
      "Training: Epoch 13, Batch 39, Loss: 0.713\n",
      "Training: Epoch 13, Batch 40, Loss: 0.631\n",
      "Training: Epoch 13, Batch 41, Loss: 0.684\n",
      "Training: Epoch 13, Batch 42, Loss: 0.396\n",
      "Training: Epoch 13, Batch 43, Loss: 0.595\n",
      "Training: Epoch 13, Batch 44, Loss: 0.434\n",
      "Training: Epoch 13, Batch 45, Loss: 0.486\n",
      "Training: Epoch 13, Batch 46, Loss: 0.481\n",
      "Training: Epoch 13, Batch 47, Loss: 1.031\n",
      "Training: Epoch 13, Batch 48, Loss: 0.446\n",
      "Training: Epoch 13, Batch 49, Loss: 0.524\n",
      "Training: Epoch 13, Batch 50, Loss: 0.397\n",
      "Training: Epoch 13, Batch 51, Loss: 0.793\n",
      "Training: Epoch 13, Batch 52, Loss: 0.45\n",
      "Training: Epoch 13, Batch 53, Loss: 0.719\n",
      "Training: Epoch 13, Batch 54, Loss: 0.638\n",
      "Training: Epoch 13, Batch 55, Loss: 0.444\n",
      "Training: Epoch 13, Batch 56, Loss: 0.628\n",
      "Training: Epoch 13, Batch 57, Loss: 0.58\n",
      "Training: Epoch 13, Batch 58, Loss: 0.504\n",
      "Training: Epoch 13, Batch 59, Loss: 0.689\n",
      "Training: Epoch 13, Batch 60, Loss: 0.572\n",
      "Training: Epoch 13, Batch 61, Loss: 0.453\n",
      "Training: Epoch 13, Batch 62, Loss: 0.404\n",
      "Training: Epoch 13, Batch 63, Loss: 0.412\n",
      "Training: Epoch 13, Batch 64, Loss: 0.506\n",
      "Training: Epoch 13, Batch 65, Loss: 0.468\n",
      "Training: Epoch 13, Batch 66, Loss: 0.374\n",
      "Training: Epoch 13, Batch 67, Loss: 0.691\n",
      "Training: Epoch 13, Batch 68, Loss: 0.488\n",
      "Training: Epoch 13, Batch 69, Loss: 0.521\n",
      "Training: Epoch 13, Batch 70, Loss: 0.535\n",
      "Training: Epoch 13, Batch 71, Loss: 0.468\n",
      "Training: Epoch 13, Batch 72, Loss: 0.461\n",
      "Training: Epoch 13, Batch 73, Loss: 0.431\n",
      "Training: Epoch 13, Batch 74, Loss: 0.458\n",
      "Training: Epoch 13, Batch 75, Loss: 0.495\n",
      "Training: Epoch 13, Batch 76, Loss: 0.58\n",
      "Training: Epoch 13, Batch 77, Loss: 0.566\n",
      "Training: Epoch 13, Batch 78, Loss: 0.548\n",
      "Training: Epoch 13, Batch 79, Loss: 0.503\n",
      "Training: Epoch 13, Batch 80, Loss: 0.441\n",
      "Training: Epoch 13, Batch 81, Loss: 0.57\n",
      "Training: Epoch 13, Batch 82, Loss: 0.68\n",
      "Training: Epoch 13, Batch 83, Loss: 0.685\n",
      "Training: Epoch 13, Batch 84, Loss: 0.568\n",
      "Training: Epoch 13, Batch 85, Loss: 0.357\n",
      "Training: Epoch 13, Batch 86, Loss: 0.287\n",
      "Training: Epoch 13, Batch 87, Loss: 0.523\n",
      "Training: Epoch 13, Batch 88, Loss: 0.331\n",
      "Training: Epoch 13, Batch 89, Loss: 0.629\n",
      "Val: Epoch 13, Loss: 0.345\n",
      "Training: Epoch 14, Batch 0, Loss: 0.712\n",
      "Training: Epoch 14, Batch 1, Loss: 0.465\n",
      "Training: Epoch 14, Batch 2, Loss: 0.466\n",
      "Training: Epoch 14, Batch 3, Loss: 0.477\n",
      "Training: Epoch 14, Batch 4, Loss: 0.39\n",
      "Training: Epoch 14, Batch 5, Loss: 0.434\n",
      "Training: Epoch 14, Batch 6, Loss: 0.694\n",
      "Training: Epoch 14, Batch 7, Loss: 0.326\n",
      "Training: Epoch 14, Batch 8, Loss: 0.432\n",
      "Training: Epoch 14, Batch 9, Loss: 0.744\n",
      "Training: Epoch 14, Batch 10, Loss: 0.453\n",
      "Training: Epoch 14, Batch 11, Loss: 0.459\n",
      "Training: Epoch 14, Batch 12, Loss: 0.803\n",
      "Training: Epoch 14, Batch 13, Loss: 0.451\n",
      "Training: Epoch 14, Batch 14, Loss: 0.812\n",
      "Training: Epoch 14, Batch 15, Loss: 0.554\n",
      "Training: Epoch 14, Batch 16, Loss: 0.827\n",
      "Training: Epoch 14, Batch 17, Loss: 0.528\n",
      "Training: Epoch 14, Batch 18, Loss: 0.685\n",
      "Training: Epoch 14, Batch 19, Loss: 0.54\n",
      "Training: Epoch 14, Batch 20, Loss: 0.58\n",
      "Training: Epoch 14, Batch 21, Loss: 0.567\n",
      "Training: Epoch 14, Batch 22, Loss: 0.525\n",
      "Training: Epoch 14, Batch 23, Loss: 0.47\n",
      "Training: Epoch 14, Batch 24, Loss: 0.584\n",
      "Training: Epoch 14, Batch 25, Loss: 0.572\n",
      "Training: Epoch 14, Batch 26, Loss: 0.585\n",
      "Training: Epoch 14, Batch 27, Loss: 0.571\n",
      "Training: Epoch 14, Batch 28, Loss: 0.463\n",
      "Training: Epoch 14, Batch 29, Loss: 0.408\n",
      "Training: Epoch 14, Batch 30, Loss: 0.511\n",
      "Training: Epoch 14, Batch 31, Loss: 0.325\n",
      "Training: Epoch 14, Batch 32, Loss: 0.506\n",
      "Training: Epoch 14, Batch 33, Loss: 0.62\n",
      "Training: Epoch 14, Batch 34, Loss: 0.673\n",
      "Training: Epoch 14, Batch 35, Loss: 0.6\n",
      "Training: Epoch 14, Batch 36, Loss: 0.294\n",
      "Training: Epoch 14, Batch 37, Loss: 0.535\n",
      "Training: Epoch 14, Batch 38, Loss: 0.416\n",
      "Training: Epoch 14, Batch 39, Loss: 0.932\n",
      "Training: Epoch 14, Batch 40, Loss: 0.655\n",
      "Training: Epoch 14, Batch 41, Loss: 0.452\n",
      "Training: Epoch 14, Batch 42, Loss: 0.42\n",
      "Training: Epoch 14, Batch 43, Loss: 0.372\n",
      "Training: Epoch 14, Batch 44, Loss: 0.388\n",
      "Training: Epoch 14, Batch 45, Loss: 0.524\n",
      "Training: Epoch 14, Batch 46, Loss: 0.454\n",
      "Training: Epoch 14, Batch 47, Loss: 0.407\n",
      "Training: Epoch 14, Batch 48, Loss: 0.548\n",
      "Training: Epoch 14, Batch 49, Loss: 0.427\n",
      "Training: Epoch 14, Batch 50, Loss: 0.49\n",
      "Training: Epoch 14, Batch 51, Loss: 0.675\n",
      "Training: Epoch 14, Batch 52, Loss: 0.617\n",
      "Training: Epoch 14, Batch 53, Loss: 0.567\n",
      "Training: Epoch 14, Batch 54, Loss: 0.519\n",
      "Training: Epoch 14, Batch 55, Loss: 0.608\n",
      "Training: Epoch 14, Batch 56, Loss: 0.682\n",
      "Training: Epoch 14, Batch 57, Loss: 0.448\n",
      "Training: Epoch 14, Batch 58, Loss: 0.631\n",
      "Training: Epoch 14, Batch 59, Loss: 0.383\n",
      "Training: Epoch 14, Batch 60, Loss: 0.514\n",
      "Training: Epoch 14, Batch 61, Loss: 0.543\n",
      "Training: Epoch 14, Batch 62, Loss: 0.662\n",
      "Training: Epoch 14, Batch 63, Loss: 0.565\n",
      "Training: Epoch 14, Batch 64, Loss: 0.562\n",
      "Training: Epoch 14, Batch 65, Loss: 0.686\n",
      "Training: Epoch 14, Batch 66, Loss: 0.522\n",
      "Training: Epoch 14, Batch 67, Loss: 0.639\n",
      "Training: Epoch 14, Batch 68, Loss: 0.411\n",
      "Training: Epoch 14, Batch 69, Loss: 0.495\n",
      "Training: Epoch 14, Batch 70, Loss: 0.374\n",
      "Training: Epoch 14, Batch 71, Loss: 0.697\n",
      "Training: Epoch 14, Batch 72, Loss: 0.552\n",
      "Training: Epoch 14, Batch 73, Loss: 0.576\n",
      "Training: Epoch 14, Batch 74, Loss: 0.412\n",
      "Training: Epoch 14, Batch 75, Loss: 0.34\n",
      "Training: Epoch 14, Batch 76, Loss: 0.52\n",
      "Training: Epoch 14, Batch 77, Loss: 0.512\n",
      "Training: Epoch 14, Batch 78, Loss: 0.294\n",
      "Training: Epoch 14, Batch 79, Loss: 0.596\n",
      "Training: Epoch 14, Batch 80, Loss: 0.429\n",
      "Training: Epoch 14, Batch 81, Loss: 0.557\n",
      "Training: Epoch 14, Batch 82, Loss: 0.76\n",
      "Training: Epoch 14, Batch 83, Loss: 0.464\n",
      "Training: Epoch 14, Batch 84, Loss: 0.472\n",
      "Training: Epoch 14, Batch 85, Loss: 0.371\n",
      "Training: Epoch 14, Batch 86, Loss: 0.458\n",
      "Training: Epoch 14, Batch 87, Loss: 0.551\n",
      "Training: Epoch 14, Batch 88, Loss: 0.332\n",
      "Training: Epoch 14, Batch 89, Loss: 0.388\n",
      "Val: Epoch 14, Loss: 0.322\n",
      "Training: Epoch 15, Batch 0, Loss: 0.582\n",
      "Training: Epoch 15, Batch 1, Loss: 0.557\n",
      "Training: Epoch 15, Batch 2, Loss: 0.335\n",
      "Training: Epoch 15, Batch 3, Loss: 0.424\n",
      "Training: Epoch 15, Batch 4, Loss: 0.537\n",
      "Training: Epoch 15, Batch 5, Loss: 0.275\n",
      "Training: Epoch 15, Batch 6, Loss: 0.68\n",
      "Training: Epoch 15, Batch 7, Loss: 0.606\n",
      "Training: Epoch 15, Batch 8, Loss: 0.597\n",
      "Training: Epoch 15, Batch 9, Loss: 0.744\n",
      "Training: Epoch 15, Batch 10, Loss: 0.945\n",
      "Training: Epoch 15, Batch 11, Loss: 0.551\n",
      "Training: Epoch 15, Batch 12, Loss: 0.525\n",
      "Training: Epoch 15, Batch 13, Loss: 0.562\n",
      "Training: Epoch 15, Batch 14, Loss: 0.519\n",
      "Training: Epoch 15, Batch 15, Loss: 0.486\n",
      "Training: Epoch 15, Batch 16, Loss: 0.625\n",
      "Training: Epoch 15, Batch 17, Loss: 0.476\n",
      "Training: Epoch 15, Batch 18, Loss: 0.618\n",
      "Training: Epoch 15, Batch 19, Loss: 0.69\n",
      "Training: Epoch 15, Batch 20, Loss: 0.458\n",
      "Training: Epoch 15, Batch 21, Loss: 0.667\n",
      "Training: Epoch 15, Batch 22, Loss: 0.658\n",
      "Training: Epoch 15, Batch 23, Loss: 0.666\n",
      "Training: Epoch 15, Batch 24, Loss: 0.781\n",
      "Training: Epoch 15, Batch 25, Loss: 0.537\n",
      "Training: Epoch 15, Batch 26, Loss: 0.542\n",
      "Training: Epoch 15, Batch 27, Loss: 0.481\n",
      "Training: Epoch 15, Batch 28, Loss: 0.5\n",
      "Training: Epoch 15, Batch 29, Loss: 0.481\n",
      "Training: Epoch 15, Batch 30, Loss: 0.717\n",
      "Training: Epoch 15, Batch 31, Loss: 0.451\n",
      "Training: Epoch 15, Batch 32, Loss: 0.658\n",
      "Training: Epoch 15, Batch 33, Loss: 0.895\n",
      "Training: Epoch 15, Batch 34, Loss: 0.386\n",
      "Training: Epoch 15, Batch 35, Loss: 0.671\n",
      "Training: Epoch 15, Batch 36, Loss: 0.514\n",
      "Training: Epoch 15, Batch 37, Loss: 0.491\n",
      "Training: Epoch 15, Batch 38, Loss: 0.579\n",
      "Training: Epoch 15, Batch 39, Loss: 0.5\n",
      "Training: Epoch 15, Batch 40, Loss: 0.468\n",
      "Training: Epoch 15, Batch 41, Loss: 0.566\n",
      "Training: Epoch 15, Batch 42, Loss: 0.32\n",
      "Training: Epoch 15, Batch 43, Loss: 0.396\n",
      "Training: Epoch 15, Batch 44, Loss: 0.61\n",
      "Training: Epoch 15, Batch 45, Loss: 0.491\n",
      "Training: Epoch 15, Batch 46, Loss: 0.597\n",
      "Training: Epoch 15, Batch 47, Loss: 0.433\n",
      "Training: Epoch 15, Batch 48, Loss: 0.503\n",
      "Training: Epoch 15, Batch 49, Loss: 0.434\n",
      "Training: Epoch 15, Batch 50, Loss: 0.57\n",
      "Training: Epoch 15, Batch 51, Loss: 0.895\n",
      "Training: Epoch 15, Batch 52, Loss: 0.421\n",
      "Training: Epoch 15, Batch 53, Loss: 0.635\n",
      "Training: Epoch 15, Batch 54, Loss: 0.568\n",
      "Training: Epoch 15, Batch 55, Loss: 0.628\n",
      "Training: Epoch 15, Batch 56, Loss: 0.507\n",
      "Training: Epoch 15, Batch 57, Loss: 0.558\n",
      "Training: Epoch 15, Batch 58, Loss: 0.576\n",
      "Training: Epoch 15, Batch 59, Loss: 0.498\n",
      "Training: Epoch 15, Batch 60, Loss: 0.459\n",
      "Training: Epoch 15, Batch 61, Loss: 0.614\n",
      "Training: Epoch 15, Batch 62, Loss: 0.469\n",
      "Training: Epoch 15, Batch 63, Loss: 0.768\n",
      "Training: Epoch 15, Batch 64, Loss: 0.622\n",
      "Training: Epoch 15, Batch 65, Loss: 0.598\n",
      "Training: Epoch 15, Batch 66, Loss: 0.55\n",
      "Training: Epoch 15, Batch 67, Loss: 0.553\n",
      "Training: Epoch 15, Batch 68, Loss: 0.456\n",
      "Training: Epoch 15, Batch 69, Loss: 0.557\n",
      "Training: Epoch 15, Batch 70, Loss: 0.359\n",
      "Training: Epoch 15, Batch 71, Loss: 0.497\n",
      "Training: Epoch 15, Batch 72, Loss: 0.861\n",
      "Training: Epoch 15, Batch 73, Loss: 0.458\n",
      "Training: Epoch 15, Batch 74, Loss: 0.498\n",
      "Training: Epoch 15, Batch 75, Loss: 0.624\n",
      "Training: Epoch 15, Batch 76, Loss: 0.619\n",
      "Training: Epoch 15, Batch 77, Loss: 0.582\n",
      "Training: Epoch 15, Batch 78, Loss: 0.278\n",
      "Training: Epoch 15, Batch 79, Loss: 0.465\n",
      "Training: Epoch 15, Batch 80, Loss: 0.445\n",
      "Training: Epoch 15, Batch 81, Loss: 0.678\n",
      "Training: Epoch 15, Batch 82, Loss: 0.596\n",
      "Training: Epoch 15, Batch 83, Loss: 0.717\n",
      "Training: Epoch 15, Batch 84, Loss: 0.445\n",
      "Training: Epoch 15, Batch 85, Loss: 0.667\n",
      "Training: Epoch 15, Batch 86, Loss: 0.468\n",
      "Training: Epoch 15, Batch 87, Loss: 0.433\n",
      "Training: Epoch 15, Batch 88, Loss: 0.519\n",
      "Training: Epoch 15, Batch 89, Loss: 0.577\n",
      "Val: Epoch 15, Loss: 0.329\n",
      "Training: Epoch 16, Batch 0, Loss: 0.772\n",
      "Training: Epoch 16, Batch 1, Loss: 0.708\n",
      "Training: Epoch 16, Batch 2, Loss: 0.625\n",
      "Training: Epoch 16, Batch 3, Loss: 0.525\n",
      "Training: Epoch 16, Batch 4, Loss: 0.585\n",
      "Training: Epoch 16, Batch 5, Loss: 0.503\n",
      "Training: Epoch 16, Batch 6, Loss: 0.487\n",
      "Training: Epoch 16, Batch 7, Loss: 0.468\n",
      "Training: Epoch 16, Batch 8, Loss: 0.599\n",
      "Training: Epoch 16, Batch 9, Loss: 0.571\n",
      "Training: Epoch 16, Batch 10, Loss: 0.44\n",
      "Training: Epoch 16, Batch 11, Loss: 0.468\n",
      "Training: Epoch 16, Batch 12, Loss: 0.56\n",
      "Training: Epoch 16, Batch 13, Loss: 0.654\n",
      "Training: Epoch 16, Batch 14, Loss: 0.906\n",
      "Training: Epoch 16, Batch 15, Loss: 0.461\n",
      "Training: Epoch 16, Batch 16, Loss: 0.648\n",
      "Training: Epoch 16, Batch 17, Loss: 0.425\n",
      "Training: Epoch 16, Batch 18, Loss: 0.397\n",
      "Training: Epoch 16, Batch 19, Loss: 0.579\n",
      "Training: Epoch 16, Batch 20, Loss: 0.477\n",
      "Training: Epoch 16, Batch 21, Loss: 0.695\n",
      "Training: Epoch 16, Batch 22, Loss: 0.563\n",
      "Training: Epoch 16, Batch 23, Loss: 0.584\n",
      "Training: Epoch 16, Batch 24, Loss: 0.528\n",
      "Training: Epoch 16, Batch 25, Loss: 0.602\n",
      "Training: Epoch 16, Batch 26, Loss: 0.826\n",
      "Training: Epoch 16, Batch 27, Loss: 0.348\n",
      "Training: Epoch 16, Batch 28, Loss: 0.441\n",
      "Training: Epoch 16, Batch 29, Loss: 0.34\n",
      "Training: Epoch 16, Batch 30, Loss: 0.535\n",
      "Training: Epoch 16, Batch 31, Loss: 0.528\n",
      "Training: Epoch 16, Batch 32, Loss: 0.503\n",
      "Training: Epoch 16, Batch 33, Loss: 0.441\n",
      "Training: Epoch 16, Batch 34, Loss: 0.381\n",
      "Training: Epoch 16, Batch 35, Loss: 0.521\n",
      "Training: Epoch 16, Batch 36, Loss: 0.572\n",
      "Training: Epoch 16, Batch 37, Loss: 0.513\n",
      "Training: Epoch 16, Batch 38, Loss: 0.542\n",
      "Training: Epoch 16, Batch 39, Loss: 0.402\n",
      "Training: Epoch 16, Batch 40, Loss: 0.982\n",
      "Training: Epoch 16, Batch 41, Loss: 0.567\n",
      "Training: Epoch 16, Batch 42, Loss: 0.459\n",
      "Training: Epoch 16, Batch 43, Loss: 0.593\n",
      "Training: Epoch 16, Batch 44, Loss: 0.537\n",
      "Training: Epoch 16, Batch 45, Loss: 0.363\n",
      "Training: Epoch 16, Batch 46, Loss: 0.558\n",
      "Training: Epoch 16, Batch 47, Loss: 0.362\n",
      "Training: Epoch 16, Batch 48, Loss: 0.415\n",
      "Training: Epoch 16, Batch 49, Loss: 0.565\n",
      "Training: Epoch 16, Batch 50, Loss: 0.473\n",
      "Training: Epoch 16, Batch 51, Loss: 0.731\n",
      "Training: Epoch 16, Batch 52, Loss: 0.454\n",
      "Training: Epoch 16, Batch 53, Loss: 0.404\n",
      "Training: Epoch 16, Batch 54, Loss: 0.472\n",
      "Training: Epoch 16, Batch 55, Loss: 0.549\n",
      "Training: Epoch 16, Batch 56, Loss: 0.419\n",
      "Training: Epoch 16, Batch 57, Loss: 0.508\n",
      "Training: Epoch 16, Batch 58, Loss: 0.402\n",
      "Training: Epoch 16, Batch 59, Loss: 0.444\n",
      "Training: Epoch 16, Batch 60, Loss: 0.691\n",
      "Training: Epoch 16, Batch 61, Loss: 0.605\n",
      "Training: Epoch 16, Batch 62, Loss: 0.483\n",
      "Training: Epoch 16, Batch 63, Loss: 0.328\n",
      "Training: Epoch 16, Batch 64, Loss: 0.438\n",
      "Training: Epoch 16, Batch 65, Loss: 0.34\n",
      "Training: Epoch 16, Batch 66, Loss: 0.732\n",
      "Training: Epoch 16, Batch 67, Loss: 0.501\n",
      "Training: Epoch 16, Batch 68, Loss: 0.519\n",
      "Training: Epoch 16, Batch 69, Loss: 0.592\n",
      "Training: Epoch 16, Batch 70, Loss: 0.557\n",
      "Training: Epoch 16, Batch 71, Loss: 0.324\n",
      "Training: Epoch 16, Batch 72, Loss: 0.473\n",
      "Training: Epoch 16, Batch 73, Loss: 0.522\n",
      "Training: Epoch 16, Batch 74, Loss: 0.462\n",
      "Training: Epoch 16, Batch 75, Loss: 0.576\n",
      "Training: Epoch 16, Batch 76, Loss: 0.496\n",
      "Training: Epoch 16, Batch 77, Loss: 0.601\n",
      "Training: Epoch 16, Batch 78, Loss: 0.396\n",
      "Training: Epoch 16, Batch 79, Loss: 0.482\n",
      "Training: Epoch 16, Batch 80, Loss: 0.547\n",
      "Training: Epoch 16, Batch 81, Loss: 0.546\n",
      "Training: Epoch 16, Batch 82, Loss: 0.53\n",
      "Training: Epoch 16, Batch 83, Loss: 0.51\n",
      "Training: Epoch 16, Batch 84, Loss: 0.367\n",
      "Training: Epoch 16, Batch 85, Loss: 0.33\n",
      "Training: Epoch 16, Batch 86, Loss: 0.736\n",
      "Training: Epoch 16, Batch 87, Loss: 0.459\n",
      "Training: Epoch 16, Batch 88, Loss: 0.447\n",
      "Training: Epoch 16, Batch 89, Loss: 0.34\n",
      "Val: Epoch 16, Loss: 0.32\n",
      "Training: Epoch 17, Batch 0, Loss: 0.513\n",
      "Training: Epoch 17, Batch 1, Loss: 0.498\n",
      "Training: Epoch 17, Batch 2, Loss: 0.62\n",
      "Training: Epoch 17, Batch 3, Loss: 0.523\n",
      "Training: Epoch 17, Batch 4, Loss: 0.398\n",
      "Training: Epoch 17, Batch 5, Loss: 0.635\n",
      "Training: Epoch 17, Batch 6, Loss: 0.367\n",
      "Training: Epoch 17, Batch 7, Loss: 0.469\n",
      "Training: Epoch 17, Batch 8, Loss: 0.397\n",
      "Training: Epoch 17, Batch 9, Loss: 0.763\n",
      "Training: Epoch 17, Batch 10, Loss: 0.47\n",
      "Training: Epoch 17, Batch 11, Loss: 0.41\n",
      "Training: Epoch 17, Batch 12, Loss: 0.569\n",
      "Training: Epoch 17, Batch 13, Loss: 0.478\n",
      "Training: Epoch 17, Batch 14, Loss: 0.543\n",
      "Training: Epoch 17, Batch 15, Loss: 0.286\n",
      "Training: Epoch 17, Batch 16, Loss: 0.378\n",
      "Training: Epoch 17, Batch 17, Loss: 0.493\n",
      "Training: Epoch 17, Batch 18, Loss: 0.498\n",
      "Training: Epoch 17, Batch 19, Loss: 0.377\n",
      "Training: Epoch 17, Batch 20, Loss: 0.68\n",
      "Training: Epoch 17, Batch 21, Loss: 0.384\n",
      "Training: Epoch 17, Batch 22, Loss: 0.437\n",
      "Training: Epoch 17, Batch 23, Loss: 0.477\n",
      "Training: Epoch 17, Batch 24, Loss: 0.516\n",
      "Training: Epoch 17, Batch 25, Loss: 0.429\n",
      "Training: Epoch 17, Batch 26, Loss: 0.471\n",
      "Training: Epoch 17, Batch 27, Loss: 0.453\n",
      "Training: Epoch 17, Batch 28, Loss: 0.526\n",
      "Training: Epoch 17, Batch 29, Loss: 0.468\n",
      "Training: Epoch 17, Batch 30, Loss: 0.504\n",
      "Training: Epoch 17, Batch 31, Loss: 0.645\n",
      "Training: Epoch 17, Batch 32, Loss: 0.424\n",
      "Training: Epoch 17, Batch 33, Loss: 0.522\n",
      "Training: Epoch 17, Batch 34, Loss: 0.344\n",
      "Training: Epoch 17, Batch 35, Loss: 0.403\n",
      "Training: Epoch 17, Batch 36, Loss: 0.622\n",
      "Training: Epoch 17, Batch 37, Loss: 0.617\n",
      "Training: Epoch 17, Batch 38, Loss: 0.424\n",
      "Training: Epoch 17, Batch 39, Loss: 0.294\n",
      "Training: Epoch 17, Batch 40, Loss: 0.725\n",
      "Training: Epoch 17, Batch 41, Loss: 0.388\n",
      "Training: Epoch 17, Batch 42, Loss: 0.362\n",
      "Training: Epoch 17, Batch 43, Loss: 0.51\n",
      "Training: Epoch 17, Batch 44, Loss: 0.585\n",
      "Training: Epoch 17, Batch 45, Loss: 0.469\n",
      "Training: Epoch 17, Batch 46, Loss: 0.611\n",
      "Training: Epoch 17, Batch 47, Loss: 0.499\n",
      "Training: Epoch 17, Batch 48, Loss: 0.649\n",
      "Training: Epoch 17, Batch 49, Loss: 0.481\n",
      "Training: Epoch 17, Batch 50, Loss: 0.537\n",
      "Training: Epoch 17, Batch 51, Loss: 0.62\n",
      "Training: Epoch 17, Batch 52, Loss: 0.516\n",
      "Training: Epoch 17, Batch 53, Loss: 0.626\n",
      "Training: Epoch 17, Batch 54, Loss: 0.599\n",
      "Training: Epoch 17, Batch 55, Loss: 0.483\n",
      "Training: Epoch 17, Batch 56, Loss: 0.554\n",
      "Training: Epoch 17, Batch 57, Loss: 0.522\n",
      "Training: Epoch 17, Batch 58, Loss: 0.363\n",
      "Training: Epoch 17, Batch 59, Loss: 0.426\n",
      "Training: Epoch 17, Batch 60, Loss: 0.363\n",
      "Training: Epoch 17, Batch 61, Loss: 0.403\n",
      "Training: Epoch 17, Batch 62, Loss: 0.362\n",
      "Training: Epoch 17, Batch 63, Loss: 0.58\n",
      "Training: Epoch 17, Batch 64, Loss: 0.662\n",
      "Training: Epoch 17, Batch 65, Loss: 0.329\n",
      "Training: Epoch 17, Batch 66, Loss: 0.488\n",
      "Training: Epoch 17, Batch 67, Loss: 0.549\n",
      "Training: Epoch 17, Batch 68, Loss: 0.914\n",
      "Training: Epoch 17, Batch 69, Loss: 0.461\n",
      "Training: Epoch 17, Batch 70, Loss: 0.288\n",
      "Training: Epoch 17, Batch 71, Loss: 0.35\n",
      "Training: Epoch 17, Batch 72, Loss: 0.711\n",
      "Training: Epoch 17, Batch 73, Loss: 0.436\n",
      "Training: Epoch 17, Batch 74, Loss: 0.576\n",
      "Training: Epoch 17, Batch 75, Loss: 0.66\n",
      "Training: Epoch 17, Batch 76, Loss: 0.547\n",
      "Training: Epoch 17, Batch 77, Loss: 0.452\n",
      "Training: Epoch 17, Batch 78, Loss: 0.67\n",
      "Training: Epoch 17, Batch 79, Loss: 0.457\n",
      "Training: Epoch 17, Batch 80, Loss: 0.457\n",
      "Training: Epoch 17, Batch 81, Loss: 0.804\n",
      "Training: Epoch 17, Batch 82, Loss: 0.379\n",
      "Training: Epoch 17, Batch 83, Loss: 0.734\n",
      "Training: Epoch 17, Batch 84, Loss: 0.406\n",
      "Training: Epoch 17, Batch 85, Loss: 0.623\n",
      "Training: Epoch 17, Batch 86, Loss: 0.479\n",
      "Training: Epoch 17, Batch 87, Loss: 0.507\n",
      "Training: Epoch 17, Batch 88, Loss: 0.665\n",
      "Training: Epoch 17, Batch 89, Loss: 0.631\n",
      "Val: Epoch 17, Loss: 0.295\n",
      "Training: Epoch 18, Batch 0, Loss: 0.911\n",
      "Training: Epoch 18, Batch 1, Loss: 0.509\n",
      "Training: Epoch 18, Batch 2, Loss: 0.469\n",
      "Training: Epoch 18, Batch 3, Loss: 0.374\n",
      "Training: Epoch 18, Batch 4, Loss: 0.448\n",
      "Training: Epoch 18, Batch 5, Loss: 0.381\n",
      "Training: Epoch 18, Batch 6, Loss: 0.592\n",
      "Training: Epoch 18, Batch 7, Loss: 0.515\n",
      "Training: Epoch 18, Batch 8, Loss: 0.606\n",
      "Training: Epoch 18, Batch 9, Loss: 0.585\n",
      "Training: Epoch 18, Batch 10, Loss: 0.466\n",
      "Training: Epoch 18, Batch 11, Loss: 0.812\n",
      "Training: Epoch 18, Batch 12, Loss: 0.429\n",
      "Training: Epoch 18, Batch 13, Loss: 0.461\n",
      "Training: Epoch 18, Batch 14, Loss: 0.471\n",
      "Training: Epoch 18, Batch 15, Loss: 0.51\n",
      "Training: Epoch 18, Batch 16, Loss: 0.562\n",
      "Training: Epoch 18, Batch 17, Loss: 0.427\n",
      "Training: Epoch 18, Batch 18, Loss: 0.589\n",
      "Training: Epoch 18, Batch 19, Loss: 0.321\n",
      "Training: Epoch 18, Batch 20, Loss: 0.395\n",
      "Training: Epoch 18, Batch 21, Loss: 0.343\n",
      "Training: Epoch 18, Batch 22, Loss: 0.366\n",
      "Training: Epoch 18, Batch 23, Loss: 0.593\n",
      "Training: Epoch 18, Batch 24, Loss: 0.327\n",
      "Training: Epoch 18, Batch 25, Loss: 0.903\n",
      "Training: Epoch 18, Batch 26, Loss: 0.261\n",
      "Training: Epoch 18, Batch 27, Loss: 0.701\n",
      "Training: Epoch 18, Batch 28, Loss: 0.661\n",
      "Training: Epoch 18, Batch 29, Loss: 0.455\n",
      "Training: Epoch 18, Batch 30, Loss: 0.456\n",
      "Training: Epoch 18, Batch 31, Loss: 0.498\n",
      "Training: Epoch 18, Batch 32, Loss: 0.562\n",
      "Training: Epoch 18, Batch 33, Loss: 0.45\n",
      "Training: Epoch 18, Batch 34, Loss: 0.563\n",
      "Training: Epoch 18, Batch 35, Loss: 0.421\n",
      "Training: Epoch 18, Batch 36, Loss: 0.417\n",
      "Training: Epoch 18, Batch 37, Loss: 0.538\n",
      "Training: Epoch 18, Batch 38, Loss: 0.678\n",
      "Training: Epoch 18, Batch 39, Loss: 0.48\n",
      "Training: Epoch 18, Batch 40, Loss: 0.642\n",
      "Training: Epoch 18, Batch 41, Loss: 0.382\n",
      "Training: Epoch 18, Batch 42, Loss: 0.548\n",
      "Training: Epoch 18, Batch 43, Loss: 0.372\n",
      "Training: Epoch 18, Batch 44, Loss: 1.062\n",
      "Training: Epoch 18, Batch 45, Loss: 0.569\n",
      "Training: Epoch 18, Batch 46, Loss: 0.411\n",
      "Training: Epoch 18, Batch 47, Loss: 0.969\n",
      "Training: Epoch 18, Batch 48, Loss: 0.655\n",
      "Training: Epoch 18, Batch 49, Loss: 0.479\n",
      "Training: Epoch 18, Batch 50, Loss: 0.44\n",
      "Training: Epoch 18, Batch 51, Loss: 0.542\n",
      "Training: Epoch 18, Batch 52, Loss: 0.577\n",
      "Training: Epoch 18, Batch 53, Loss: 0.559\n",
      "Training: Epoch 18, Batch 54, Loss: 0.522\n",
      "Training: Epoch 18, Batch 55, Loss: 0.413\n",
      "Training: Epoch 18, Batch 56, Loss: 0.689\n",
      "Training: Epoch 18, Batch 57, Loss: 0.673\n",
      "Training: Epoch 18, Batch 58, Loss: 0.646\n",
      "Training: Epoch 18, Batch 59, Loss: 0.438\n",
      "Training: Epoch 18, Batch 60, Loss: 0.545\n",
      "Training: Epoch 18, Batch 61, Loss: 0.739\n",
      "Training: Epoch 18, Batch 62, Loss: 0.717\n",
      "Training: Epoch 18, Batch 63, Loss: 0.567\n",
      "Training: Epoch 18, Batch 64, Loss: 0.501\n",
      "Training: Epoch 18, Batch 65, Loss: 0.639\n",
      "Training: Epoch 18, Batch 66, Loss: 0.742\n",
      "Training: Epoch 18, Batch 67, Loss: 0.593\n",
      "Training: Epoch 18, Batch 68, Loss: 0.581\n",
      "Training: Epoch 18, Batch 69, Loss: 0.602\n",
      "Training: Epoch 18, Batch 70, Loss: 0.639\n",
      "Training: Epoch 18, Batch 71, Loss: 0.432\n",
      "Training: Epoch 18, Batch 72, Loss: 0.628\n",
      "Training: Epoch 18, Batch 73, Loss: 0.394\n",
      "Training: Epoch 18, Batch 74, Loss: 0.433\n",
      "Training: Epoch 18, Batch 75, Loss: 0.435\n",
      "Training: Epoch 18, Batch 76, Loss: 0.516\n",
      "Training: Epoch 18, Batch 77, Loss: 0.662\n",
      "Training: Epoch 18, Batch 78, Loss: 0.457\n",
      "Training: Epoch 18, Batch 79, Loss: 0.441\n",
      "Training: Epoch 18, Batch 80, Loss: 0.536\n",
      "Training: Epoch 18, Batch 81, Loss: 0.513\n",
      "Training: Epoch 18, Batch 82, Loss: 0.463\n",
      "Training: Epoch 18, Batch 83, Loss: 0.435\n",
      "Training: Epoch 18, Batch 84, Loss: 0.708\n",
      "Training: Epoch 18, Batch 85, Loss: 0.349\n",
      "Training: Epoch 18, Batch 86, Loss: 0.429\n",
      "Training: Epoch 18, Batch 87, Loss: 0.613\n",
      "Training: Epoch 18, Batch 88, Loss: 0.527\n",
      "Training: Epoch 18, Batch 89, Loss: 0.529\n",
      "Val: Epoch 18, Loss: 0.297\n",
      "Training: Epoch 19, Batch 0, Loss: 0.497\n",
      "Training: Epoch 19, Batch 1, Loss: 0.496\n",
      "Training: Epoch 19, Batch 2, Loss: 0.598\n",
      "Training: Epoch 19, Batch 3, Loss: 0.559\n",
      "Training: Epoch 19, Batch 4, Loss: 0.572\n",
      "Training: Epoch 19, Batch 5, Loss: 0.451\n",
      "Training: Epoch 19, Batch 6, Loss: 0.433\n",
      "Training: Epoch 19, Batch 7, Loss: 0.363\n",
      "Training: Epoch 19, Batch 8, Loss: 0.408\n",
      "Training: Epoch 19, Batch 9, Loss: 0.566\n",
      "Training: Epoch 19, Batch 10, Loss: 0.463\n",
      "Training: Epoch 19, Batch 11, Loss: 0.484\n",
      "Training: Epoch 19, Batch 12, Loss: 0.616\n",
      "Training: Epoch 19, Batch 13, Loss: 0.644\n",
      "Training: Epoch 19, Batch 14, Loss: 0.67\n",
      "Training: Epoch 19, Batch 15, Loss: 0.629\n",
      "Training: Epoch 19, Batch 16, Loss: 0.629\n",
      "Training: Epoch 19, Batch 17, Loss: 0.364\n",
      "Training: Epoch 19, Batch 18, Loss: 0.568\n",
      "Training: Epoch 19, Batch 19, Loss: 0.517\n",
      "Training: Epoch 19, Batch 20, Loss: 0.555\n",
      "Training: Epoch 19, Batch 21, Loss: 0.419\n",
      "Training: Epoch 19, Batch 22, Loss: 0.492\n",
      "Training: Epoch 19, Batch 23, Loss: 0.588\n",
      "Training: Epoch 19, Batch 24, Loss: 0.59\n",
      "Training: Epoch 19, Batch 25, Loss: 0.382\n",
      "Training: Epoch 19, Batch 26, Loss: 0.562\n",
      "Training: Epoch 19, Batch 27, Loss: 0.592\n",
      "Training: Epoch 19, Batch 28, Loss: 0.413\n",
      "Training: Epoch 19, Batch 29, Loss: 0.465\n",
      "Training: Epoch 19, Batch 30, Loss: 0.419\n",
      "Training: Epoch 19, Batch 31, Loss: 0.554\n",
      "Training: Epoch 19, Batch 32, Loss: 0.553\n",
      "Training: Epoch 19, Batch 33, Loss: 0.682\n",
      "Training: Epoch 19, Batch 34, Loss: 0.53\n",
      "Training: Epoch 19, Batch 35, Loss: 0.35\n",
      "Training: Epoch 19, Batch 36, Loss: 0.853\n",
      "Training: Epoch 19, Batch 37, Loss: 0.715\n",
      "Training: Epoch 19, Batch 38, Loss: 0.5\n",
      "Training: Epoch 19, Batch 39, Loss: 0.709\n",
      "Training: Epoch 19, Batch 40, Loss: 0.379\n",
      "Training: Epoch 19, Batch 41, Loss: 0.527\n",
      "Training: Epoch 19, Batch 42, Loss: 0.58\n",
      "Training: Epoch 19, Batch 43, Loss: 0.612\n",
      "Training: Epoch 19, Batch 44, Loss: 0.436\n",
      "Training: Epoch 19, Batch 45, Loss: 0.635\n",
      "Training: Epoch 19, Batch 46, Loss: 0.376\n",
      "Training: Epoch 19, Batch 47, Loss: 0.588\n",
      "Training: Epoch 19, Batch 48, Loss: 0.319\n",
      "Training: Epoch 19, Batch 49, Loss: 0.4\n",
      "Training: Epoch 19, Batch 50, Loss: 0.471\n",
      "Training: Epoch 19, Batch 51, Loss: 0.589\n",
      "Training: Epoch 19, Batch 52, Loss: 0.369\n",
      "Training: Epoch 19, Batch 53, Loss: 0.767\n",
      "Training: Epoch 19, Batch 54, Loss: 0.501\n",
      "Training: Epoch 19, Batch 55, Loss: 0.445\n",
      "Training: Epoch 19, Batch 56, Loss: 0.52\n",
      "Training: Epoch 19, Batch 57, Loss: 0.745\n",
      "Training: Epoch 19, Batch 58, Loss: 0.405\n",
      "Training: Epoch 19, Batch 59, Loss: 0.457\n",
      "Training: Epoch 19, Batch 60, Loss: 0.462\n",
      "Training: Epoch 19, Batch 61, Loss: 0.478\n",
      "Training: Epoch 19, Batch 62, Loss: 0.474\n",
      "Training: Epoch 19, Batch 63, Loss: 0.602\n",
      "Training: Epoch 19, Batch 64, Loss: 0.539\n",
      "Training: Epoch 19, Batch 65, Loss: 0.493\n",
      "Training: Epoch 19, Batch 66, Loss: 0.558\n",
      "Training: Epoch 19, Batch 67, Loss: 0.5\n",
      "Training: Epoch 19, Batch 68, Loss: 0.423\n",
      "Training: Epoch 19, Batch 69, Loss: 0.372\n",
      "Training: Epoch 19, Batch 70, Loss: 0.73\n",
      "Training: Epoch 19, Batch 71, Loss: 0.627\n",
      "Training: Epoch 19, Batch 72, Loss: 0.781\n",
      "Training: Epoch 19, Batch 73, Loss: 0.504\n",
      "Training: Epoch 19, Batch 74, Loss: 0.369\n",
      "Training: Epoch 19, Batch 75, Loss: 0.435\n",
      "Training: Epoch 19, Batch 76, Loss: 0.474\n",
      "Training: Epoch 19, Batch 77, Loss: 0.583\n",
      "Training: Epoch 19, Batch 78, Loss: 0.301\n",
      "Training: Epoch 19, Batch 79, Loss: 0.713\n",
      "Training: Epoch 19, Batch 80, Loss: 0.454\n",
      "Training: Epoch 19, Batch 81, Loss: 0.399\n",
      "Training: Epoch 19, Batch 82, Loss: 0.471\n",
      "Training: Epoch 19, Batch 83, Loss: 0.438\n",
      "Training: Epoch 19, Batch 84, Loss: 0.539\n",
      "Training: Epoch 19, Batch 85, Loss: 0.428\n",
      "Training: Epoch 19, Batch 86, Loss: 0.344\n",
      "Training: Epoch 19, Batch 87, Loss: 0.266\n",
      "Training: Epoch 19, Batch 88, Loss: 0.513\n",
      "Training: Epoch 19, Batch 89, Loss: 0.475\n",
      "Val: Epoch 19, Loss: 0.279\n",
      "Training: Epoch 20, Batch 0, Loss: 0.559\n",
      "Training: Epoch 20, Batch 1, Loss: 0.431\n",
      "Training: Epoch 20, Batch 2, Loss: 0.603\n",
      "Training: Epoch 20, Batch 3, Loss: 0.456\n",
      "Training: Epoch 20, Batch 4, Loss: 0.4\n",
      "Training: Epoch 20, Batch 5, Loss: 0.485\n",
      "Training: Epoch 20, Batch 6, Loss: 0.88\n",
      "Training: Epoch 20, Batch 7, Loss: 0.27\n",
      "Training: Epoch 20, Batch 8, Loss: 0.433\n",
      "Training: Epoch 20, Batch 9, Loss: 0.61\n",
      "Training: Epoch 20, Batch 10, Loss: 0.623\n",
      "Training: Epoch 20, Batch 11, Loss: 0.476\n",
      "Training: Epoch 20, Batch 12, Loss: 0.254\n",
      "Training: Epoch 20, Batch 13, Loss: 0.648\n",
      "Training: Epoch 20, Batch 14, Loss: 0.612\n",
      "Training: Epoch 20, Batch 15, Loss: 0.498\n",
      "Training: Epoch 20, Batch 16, Loss: 0.779\n",
      "Training: Epoch 20, Batch 17, Loss: 0.6\n",
      "Training: Epoch 20, Batch 18, Loss: 0.552\n",
      "Training: Epoch 20, Batch 19, Loss: 0.323\n",
      "Training: Epoch 20, Batch 20, Loss: 0.579\n",
      "Training: Epoch 20, Batch 21, Loss: 0.51\n",
      "Training: Epoch 20, Batch 22, Loss: 0.564\n",
      "Training: Epoch 20, Batch 23, Loss: 0.447\n",
      "Training: Epoch 20, Batch 24, Loss: 0.503\n",
      "Training: Epoch 20, Batch 25, Loss: 0.38\n",
      "Training: Epoch 20, Batch 26, Loss: 0.334\n",
      "Training: Epoch 20, Batch 27, Loss: 0.306\n",
      "Training: Epoch 20, Batch 28, Loss: 0.579\n",
      "Training: Epoch 20, Batch 29, Loss: 0.536\n",
      "Training: Epoch 20, Batch 30, Loss: 0.811\n",
      "Training: Epoch 20, Batch 31, Loss: 0.535\n",
      "Training: Epoch 20, Batch 32, Loss: 0.497\n",
      "Training: Epoch 20, Batch 33, Loss: 0.497\n",
      "Training: Epoch 20, Batch 34, Loss: 0.491\n",
      "Training: Epoch 20, Batch 35, Loss: 0.364\n",
      "Training: Epoch 20, Batch 36, Loss: 0.711\n",
      "Training: Epoch 20, Batch 37, Loss: 0.582\n",
      "Training: Epoch 20, Batch 38, Loss: 0.524\n",
      "Training: Epoch 20, Batch 39, Loss: 0.369\n",
      "Training: Epoch 20, Batch 40, Loss: 0.388\n",
      "Training: Epoch 20, Batch 41, Loss: 0.417\n",
      "Training: Epoch 20, Batch 42, Loss: 0.531\n",
      "Training: Epoch 20, Batch 43, Loss: 0.537\n",
      "Training: Epoch 20, Batch 44, Loss: 0.451\n",
      "Training: Epoch 20, Batch 45, Loss: 0.361\n",
      "Training: Epoch 20, Batch 46, Loss: 0.442\n",
      "Training: Epoch 20, Batch 47, Loss: 0.487\n",
      "Training: Epoch 20, Batch 48, Loss: 0.358\n",
      "Training: Epoch 20, Batch 49, Loss: 0.431\n",
      "Training: Epoch 20, Batch 50, Loss: 0.897\n",
      "Training: Epoch 20, Batch 51, Loss: 0.499\n",
      "Training: Epoch 20, Batch 52, Loss: 0.412\n",
      "Training: Epoch 20, Batch 53, Loss: 0.666\n",
      "Training: Epoch 20, Batch 54, Loss: 0.425\n",
      "Training: Epoch 20, Batch 55, Loss: 0.521\n",
      "Training: Epoch 20, Batch 56, Loss: 0.572\n",
      "Training: Epoch 20, Batch 57, Loss: 0.5\n",
      "Training: Epoch 20, Batch 58, Loss: 0.505\n",
      "Training: Epoch 20, Batch 59, Loss: 0.453\n",
      "Training: Epoch 20, Batch 60, Loss: 0.483\n",
      "Training: Epoch 20, Batch 61, Loss: 0.539\n",
      "Training: Epoch 20, Batch 62, Loss: 0.526\n",
      "Training: Epoch 20, Batch 63, Loss: 0.504\n",
      "Training: Epoch 20, Batch 64, Loss: 0.344\n",
      "Training: Epoch 20, Batch 65, Loss: 1.22\n",
      "Training: Epoch 20, Batch 66, Loss: 0.522\n",
      "Training: Epoch 20, Batch 67, Loss: 0.554\n",
      "Training: Epoch 20, Batch 68, Loss: 0.472\n",
      "Training: Epoch 20, Batch 69, Loss: 0.51\n",
      "Training: Epoch 20, Batch 70, Loss: 0.614\n",
      "Training: Epoch 20, Batch 71, Loss: 0.621\n",
      "Training: Epoch 20, Batch 72, Loss: 0.472\n",
      "Training: Epoch 20, Batch 73, Loss: 0.5\n",
      "Training: Epoch 20, Batch 74, Loss: 0.346\n",
      "Training: Epoch 20, Batch 75, Loss: 0.479\n",
      "Training: Epoch 20, Batch 76, Loss: 0.484\n",
      "Training: Epoch 20, Batch 77, Loss: 0.572\n",
      "Training: Epoch 20, Batch 78, Loss: 0.596\n",
      "Training: Epoch 20, Batch 79, Loss: 0.577\n",
      "Training: Epoch 20, Batch 80, Loss: 0.379\n",
      "Training: Epoch 20, Batch 81, Loss: 0.507\n",
      "Training: Epoch 20, Batch 82, Loss: 0.649\n",
      "Training: Epoch 20, Batch 83, Loss: 0.395\n",
      "Training: Epoch 20, Batch 84, Loss: 0.446\n",
      "Training: Epoch 20, Batch 85, Loss: 0.387\n",
      "Training: Epoch 20, Batch 86, Loss: 0.772\n",
      "Training: Epoch 20, Batch 87, Loss: 0.79\n",
      "Training: Epoch 20, Batch 88, Loss: 0.405\n",
      "Training: Epoch 20, Batch 89, Loss: 0.735\n",
      "Val: Epoch 20, Loss: 0.262\n",
      "Training: Epoch 21, Batch 0, Loss: 0.496\n",
      "Training: Epoch 21, Batch 1, Loss: 0.429\n",
      "Training: Epoch 21, Batch 2, Loss: 0.52\n",
      "Training: Epoch 21, Batch 3, Loss: 0.461\n",
      "Training: Epoch 21, Batch 4, Loss: 0.398\n",
      "Training: Epoch 21, Batch 5, Loss: 0.707\n",
      "Training: Epoch 21, Batch 6, Loss: 0.346\n",
      "Training: Epoch 21, Batch 7, Loss: 0.563\n",
      "Training: Epoch 21, Batch 8, Loss: 0.511\n",
      "Training: Epoch 21, Batch 9, Loss: 0.483\n",
      "Training: Epoch 21, Batch 10, Loss: 0.45\n",
      "Training: Epoch 21, Batch 11, Loss: 0.458\n",
      "Training: Epoch 21, Batch 12, Loss: 0.669\n",
      "Training: Epoch 21, Batch 13, Loss: 0.439\n",
      "Training: Epoch 21, Batch 14, Loss: 0.459\n",
      "Training: Epoch 21, Batch 15, Loss: 0.405\n",
      "Training: Epoch 21, Batch 16, Loss: 0.679\n",
      "Training: Epoch 21, Batch 17, Loss: 0.42\n",
      "Training: Epoch 21, Batch 18, Loss: 0.603\n",
      "Training: Epoch 21, Batch 19, Loss: 0.561\n",
      "Training: Epoch 21, Batch 20, Loss: 0.432\n",
      "Training: Epoch 21, Batch 21, Loss: 0.934\n",
      "Training: Epoch 21, Batch 22, Loss: 0.544\n",
      "Training: Epoch 21, Batch 23, Loss: 0.976\n",
      "Training: Epoch 21, Batch 24, Loss: 0.554\n",
      "Training: Epoch 21, Batch 25, Loss: 0.411\n",
      "Training: Epoch 21, Batch 26, Loss: 0.674\n",
      "Training: Epoch 21, Batch 27, Loss: 0.435\n",
      "Training: Epoch 21, Batch 28, Loss: 0.373\n",
      "Training: Epoch 21, Batch 29, Loss: 0.614\n",
      "Training: Epoch 21, Batch 30, Loss: 0.396\n",
      "Training: Epoch 21, Batch 31, Loss: 0.423\n",
      "Training: Epoch 21, Batch 32, Loss: 0.632\n",
      "Training: Epoch 21, Batch 33, Loss: 0.619\n",
      "Training: Epoch 21, Batch 34, Loss: 0.5\n",
      "Training: Epoch 21, Batch 35, Loss: 0.469\n",
      "Training: Epoch 21, Batch 36, Loss: 0.407\n",
      "Training: Epoch 21, Batch 37, Loss: 0.399\n",
      "Training: Epoch 21, Batch 38, Loss: 0.502\n",
      "Training: Epoch 21, Batch 39, Loss: 0.609\n",
      "Training: Epoch 21, Batch 40, Loss: 0.378\n",
      "Training: Epoch 21, Batch 41, Loss: 0.392\n",
      "Training: Epoch 21, Batch 42, Loss: 0.603\n",
      "Training: Epoch 21, Batch 43, Loss: 0.407\n",
      "Training: Epoch 21, Batch 44, Loss: 0.2\n",
      "Training: Epoch 21, Batch 45, Loss: 0.61\n",
      "Training: Epoch 21, Batch 46, Loss: 0.505\n",
      "Training: Epoch 21, Batch 47, Loss: 0.626\n",
      "Training: Epoch 21, Batch 48, Loss: 0.399\n",
      "Training: Epoch 21, Batch 49, Loss: 0.73\n",
      "Training: Epoch 21, Batch 50, Loss: 0.955\n",
      "Training: Epoch 21, Batch 51, Loss: 0.563\n",
      "Training: Epoch 21, Batch 52, Loss: 0.334\n",
      "Training: Epoch 21, Batch 53, Loss: 0.644\n",
      "Training: Epoch 21, Batch 54, Loss: 0.432\n",
      "Training: Epoch 21, Batch 55, Loss: 0.362\n",
      "Training: Epoch 21, Batch 56, Loss: 0.389\n",
      "Training: Epoch 21, Batch 57, Loss: 0.444\n",
      "Training: Epoch 21, Batch 58, Loss: 0.602\n",
      "Training: Epoch 21, Batch 59, Loss: 0.513\n",
      "Training: Epoch 21, Batch 60, Loss: 0.34\n",
      "Training: Epoch 21, Batch 61, Loss: 0.61\n",
      "Training: Epoch 21, Batch 62, Loss: 0.643\n",
      "Training: Epoch 21, Batch 63, Loss: 0.529\n",
      "Training: Epoch 21, Batch 64, Loss: 0.552\n",
      "Training: Epoch 21, Batch 65, Loss: 0.35\n",
      "Training: Epoch 21, Batch 66, Loss: 0.541\n",
      "Training: Epoch 21, Batch 67, Loss: 0.442\n",
      "Training: Epoch 21, Batch 68, Loss: 0.563\n",
      "Training: Epoch 21, Batch 69, Loss: 0.394\n",
      "Training: Epoch 21, Batch 70, Loss: 0.561\n",
      "Training: Epoch 21, Batch 71, Loss: 0.49\n",
      "Training: Epoch 21, Batch 72, Loss: 0.447\n",
      "Training: Epoch 21, Batch 73, Loss: 0.539\n",
      "Training: Epoch 21, Batch 74, Loss: 0.313\n",
      "Training: Epoch 21, Batch 75, Loss: 0.373\n",
      "Training: Epoch 21, Batch 76, Loss: 0.583\n",
      "Training: Epoch 21, Batch 77, Loss: 0.494\n",
      "Training: Epoch 21, Batch 78, Loss: 0.678\n",
      "Training: Epoch 21, Batch 79, Loss: 0.485\n",
      "Training: Epoch 21, Batch 80, Loss: 0.449\n",
      "Training: Epoch 21, Batch 81, Loss: 0.681\n",
      "Training: Epoch 21, Batch 82, Loss: 0.437\n",
      "Training: Epoch 21, Batch 83, Loss: 0.791\n",
      "Training: Epoch 21, Batch 84, Loss: 0.549\n",
      "Training: Epoch 21, Batch 85, Loss: 0.441\n",
      "Training: Epoch 21, Batch 86, Loss: 0.519\n",
      "Training: Epoch 21, Batch 87, Loss: 0.737\n",
      "Training: Epoch 21, Batch 88, Loss: 0.337\n",
      "Training: Epoch 21, Batch 89, Loss: 0.327\n",
      "Val: Epoch 21, Loss: 0.315\n",
      "Training: Epoch 22, Batch 0, Loss: 0.282\n",
      "Training: Epoch 22, Batch 1, Loss: 0.725\n",
      "Training: Epoch 22, Batch 2, Loss: 0.621\n",
      "Training: Epoch 22, Batch 3, Loss: 0.503\n",
      "Training: Epoch 22, Batch 4, Loss: 0.441\n",
      "Training: Epoch 22, Batch 5, Loss: 0.619\n",
      "Training: Epoch 22, Batch 6, Loss: 0.46\n",
      "Training: Epoch 22, Batch 7, Loss: 0.618\n",
      "Training: Epoch 22, Batch 8, Loss: 0.575\n",
      "Training: Epoch 22, Batch 9, Loss: 0.365\n",
      "Training: Epoch 22, Batch 10, Loss: 0.521\n",
      "Training: Epoch 22, Batch 11, Loss: 0.456\n",
      "Training: Epoch 22, Batch 12, Loss: 0.582\n",
      "Training: Epoch 22, Batch 13, Loss: 0.48\n",
      "Training: Epoch 22, Batch 14, Loss: 0.579\n",
      "Training: Epoch 22, Batch 15, Loss: 0.421\n",
      "Training: Epoch 22, Batch 16, Loss: 0.619\n",
      "Training: Epoch 22, Batch 17, Loss: 0.733\n",
      "Training: Epoch 22, Batch 18, Loss: 0.557\n",
      "Training: Epoch 22, Batch 19, Loss: 0.393\n",
      "Training: Epoch 22, Batch 20, Loss: 0.491\n",
      "Training: Epoch 22, Batch 21, Loss: 0.62\n",
      "Training: Epoch 22, Batch 22, Loss: 0.595\n",
      "Training: Epoch 22, Batch 23, Loss: 0.39\n",
      "Training: Epoch 22, Batch 24, Loss: 0.516\n",
      "Training: Epoch 22, Batch 25, Loss: 0.318\n",
      "Training: Epoch 22, Batch 26, Loss: 0.366\n",
      "Training: Epoch 22, Batch 27, Loss: 0.516\n",
      "Training: Epoch 22, Batch 28, Loss: 0.606\n",
      "Training: Epoch 22, Batch 29, Loss: 0.427\n",
      "Training: Epoch 22, Batch 30, Loss: 0.366\n",
      "Training: Epoch 22, Batch 31, Loss: 0.487\n",
      "Training: Epoch 22, Batch 32, Loss: 0.664\n",
      "Training: Epoch 22, Batch 33, Loss: 0.464\n",
      "Training: Epoch 22, Batch 34, Loss: 0.464\n",
      "Training: Epoch 22, Batch 35, Loss: 0.6\n",
      "Training: Epoch 22, Batch 36, Loss: 0.364\n",
      "Training: Epoch 22, Batch 37, Loss: 0.425\n",
      "Training: Epoch 22, Batch 38, Loss: 0.456\n",
      "Training: Epoch 22, Batch 39, Loss: 0.467\n",
      "Training: Epoch 22, Batch 40, Loss: 0.482\n",
      "Training: Epoch 22, Batch 41, Loss: 0.335\n",
      "Training: Epoch 22, Batch 42, Loss: 0.324\n",
      "Training: Epoch 22, Batch 43, Loss: 0.712\n",
      "Training: Epoch 22, Batch 44, Loss: 0.329\n",
      "Training: Epoch 22, Batch 45, Loss: 0.461\n",
      "Training: Epoch 22, Batch 46, Loss: 0.806\n",
      "Training: Epoch 22, Batch 47, Loss: 0.84\n",
      "Training: Epoch 22, Batch 48, Loss: 0.49\n",
      "Training: Epoch 22, Batch 49, Loss: 0.504\n",
      "Training: Epoch 22, Batch 50, Loss: 0.496\n",
      "Training: Epoch 22, Batch 51, Loss: 0.411\n",
      "Training: Epoch 22, Batch 52, Loss: 0.467\n",
      "Training: Epoch 22, Batch 53, Loss: 0.305\n",
      "Training: Epoch 22, Batch 54, Loss: 0.323\n",
      "Training: Epoch 22, Batch 55, Loss: 0.683\n",
      "Training: Epoch 22, Batch 56, Loss: 0.194\n",
      "Training: Epoch 22, Batch 57, Loss: 0.509\n",
      "Training: Epoch 22, Batch 58, Loss: 0.481\n",
      "Training: Epoch 22, Batch 59, Loss: 0.399\n",
      "Training: Epoch 22, Batch 60, Loss: 0.443\n",
      "Training: Epoch 22, Batch 61, Loss: 0.476\n",
      "Training: Epoch 22, Batch 62, Loss: 0.662\n",
      "Training: Epoch 22, Batch 63, Loss: 0.622\n",
      "Training: Epoch 22, Batch 64, Loss: 0.361\n",
      "Training: Epoch 22, Batch 65, Loss: 0.293\n",
      "Training: Epoch 22, Batch 66, Loss: 0.455\n",
      "Training: Epoch 22, Batch 67, Loss: 0.385\n",
      "Training: Epoch 22, Batch 68, Loss: 0.847\n",
      "Training: Epoch 22, Batch 69, Loss: 0.523\n",
      "Training: Epoch 22, Batch 70, Loss: 0.465\n",
      "Training: Epoch 22, Batch 71, Loss: 0.67\n",
      "Training: Epoch 22, Batch 72, Loss: 0.394\n",
      "Training: Epoch 22, Batch 73, Loss: 0.492\n",
      "Training: Epoch 22, Batch 74, Loss: 0.487\n",
      "Training: Epoch 22, Batch 75, Loss: 0.457\n",
      "Training: Epoch 22, Batch 76, Loss: 0.396\n",
      "Training: Epoch 22, Batch 77, Loss: 0.785\n",
      "Training: Epoch 22, Batch 78, Loss: 0.408\n",
      "Training: Epoch 22, Batch 79, Loss: 0.542\n",
      "Training: Epoch 22, Batch 80, Loss: 0.32\n",
      "Training: Epoch 22, Batch 81, Loss: 0.377\n",
      "Training: Epoch 22, Batch 82, Loss: 0.477\n",
      "Training: Epoch 22, Batch 83, Loss: 0.56\n",
      "Training: Epoch 22, Batch 84, Loss: 0.581\n",
      "Training: Epoch 22, Batch 85, Loss: 0.421\n",
      "Training: Epoch 22, Batch 86, Loss: 0.635\n",
      "Training: Epoch 22, Batch 87, Loss: 0.396\n",
      "Training: Epoch 22, Batch 88, Loss: 0.667\n",
      "Training: Epoch 22, Batch 89, Loss: 0.316\n",
      "Val: Epoch 22, Loss: 0.328\n",
      "Training: Epoch 23, Batch 0, Loss: 0.485\n",
      "Training: Epoch 23, Batch 1, Loss: 0.478\n",
      "Training: Epoch 23, Batch 2, Loss: 0.414\n",
      "Training: Epoch 23, Batch 3, Loss: 0.394\n",
      "Training: Epoch 23, Batch 4, Loss: 0.526\n",
      "Training: Epoch 23, Batch 5, Loss: 0.503\n",
      "Training: Epoch 23, Batch 6, Loss: 0.381\n",
      "Training: Epoch 23, Batch 7, Loss: 0.388\n",
      "Training: Epoch 23, Batch 8, Loss: 0.612\n",
      "Training: Epoch 23, Batch 9, Loss: 0.669\n",
      "Training: Epoch 23, Batch 10, Loss: 0.506\n",
      "Training: Epoch 23, Batch 11, Loss: 0.552\n",
      "Training: Epoch 23, Batch 12, Loss: 0.732\n",
      "Training: Epoch 23, Batch 13, Loss: 0.303\n",
      "Training: Epoch 23, Batch 14, Loss: 0.567\n",
      "Training: Epoch 23, Batch 15, Loss: 0.449\n",
      "Training: Epoch 23, Batch 16, Loss: 0.412\n",
      "Training: Epoch 23, Batch 17, Loss: 0.535\n",
      "Training: Epoch 23, Batch 18, Loss: 0.55\n",
      "Training: Epoch 23, Batch 19, Loss: 0.429\n",
      "Training: Epoch 23, Batch 20, Loss: 0.521\n",
      "Training: Epoch 23, Batch 21, Loss: 0.466\n",
      "Training: Epoch 23, Batch 22, Loss: 0.497\n",
      "Training: Epoch 23, Batch 23, Loss: 0.513\n",
      "Training: Epoch 23, Batch 24, Loss: 0.342\n",
      "Training: Epoch 23, Batch 25, Loss: 0.535\n",
      "Training: Epoch 23, Batch 26, Loss: 0.696\n",
      "Training: Epoch 23, Batch 27, Loss: 0.447\n",
      "Training: Epoch 23, Batch 28, Loss: 0.383\n",
      "Training: Epoch 23, Batch 29, Loss: 0.516\n",
      "Training: Epoch 23, Batch 30, Loss: 0.509\n",
      "Training: Epoch 23, Batch 31, Loss: 0.584\n",
      "Training: Epoch 23, Batch 32, Loss: 0.49\n",
      "Training: Epoch 23, Batch 33, Loss: 0.644\n",
      "Training: Epoch 23, Batch 34, Loss: 0.52\n",
      "Training: Epoch 23, Batch 35, Loss: 0.548\n",
      "Training: Epoch 23, Batch 36, Loss: 0.438\n",
      "Training: Epoch 23, Batch 37, Loss: 0.375\n",
      "Training: Epoch 23, Batch 38, Loss: 0.529\n",
      "Training: Epoch 23, Batch 39, Loss: 0.396\n",
      "Training: Epoch 23, Batch 40, Loss: 0.48\n",
      "Training: Epoch 23, Batch 41, Loss: 0.634\n",
      "Training: Epoch 23, Batch 42, Loss: 0.434\n",
      "Training: Epoch 23, Batch 43, Loss: 0.523\n",
      "Training: Epoch 23, Batch 44, Loss: 0.499\n",
      "Training: Epoch 23, Batch 45, Loss: 0.456\n",
      "Training: Epoch 23, Batch 46, Loss: 0.56\n",
      "Training: Epoch 23, Batch 47, Loss: 0.439\n",
      "Training: Epoch 23, Batch 48, Loss: 0.301\n",
      "Training: Epoch 23, Batch 49, Loss: 0.469\n",
      "Training: Epoch 23, Batch 50, Loss: 0.412\n",
      "Training: Epoch 23, Batch 51, Loss: 0.712\n",
      "Training: Epoch 23, Batch 52, Loss: 0.557\n",
      "Training: Epoch 23, Batch 53, Loss: 0.514\n",
      "Training: Epoch 23, Batch 54, Loss: 0.527\n",
      "Training: Epoch 23, Batch 55, Loss: 0.39\n",
      "Training: Epoch 23, Batch 56, Loss: 0.716\n",
      "Training: Epoch 23, Batch 57, Loss: 0.298\n",
      "Training: Epoch 23, Batch 58, Loss: 0.465\n",
      "Training: Epoch 23, Batch 59, Loss: 0.614\n",
      "Training: Epoch 23, Batch 60, Loss: 0.513\n",
      "Training: Epoch 23, Batch 61, Loss: 0.575\n",
      "Training: Epoch 23, Batch 62, Loss: 0.509\n",
      "Training: Epoch 23, Batch 63, Loss: 0.47\n",
      "Training: Epoch 23, Batch 64, Loss: 0.387\n",
      "Training: Epoch 23, Batch 65, Loss: 0.408\n",
      "Training: Epoch 23, Batch 66, Loss: 0.549\n",
      "Training: Epoch 23, Batch 67, Loss: 0.592\n",
      "Training: Epoch 23, Batch 68, Loss: 0.328\n",
      "Training: Epoch 23, Batch 69, Loss: 0.328\n",
      "Training: Epoch 23, Batch 70, Loss: 0.457\n",
      "Training: Epoch 23, Batch 71, Loss: 0.441\n",
      "Training: Epoch 23, Batch 72, Loss: 0.458\n",
      "Training: Epoch 23, Batch 73, Loss: 0.586\n",
      "Training: Epoch 23, Batch 74, Loss: 0.4\n",
      "Training: Epoch 23, Batch 75, Loss: 0.4\n",
      "Training: Epoch 23, Batch 76, Loss: 0.436\n",
      "Training: Epoch 23, Batch 77, Loss: 0.442\n",
      "Training: Epoch 23, Batch 78, Loss: 0.318\n",
      "Training: Epoch 23, Batch 79, Loss: 0.584\n",
      "Training: Epoch 23, Batch 80, Loss: 0.527\n",
      "Training: Epoch 23, Batch 81, Loss: 0.419\n",
      "Training: Epoch 23, Batch 82, Loss: 0.486\n",
      "Training: Epoch 23, Batch 83, Loss: 0.549\n",
      "Training: Epoch 23, Batch 84, Loss: 0.486\n",
      "Training: Epoch 23, Batch 85, Loss: 0.398\n",
      "Training: Epoch 23, Batch 86, Loss: 0.549\n",
      "Training: Epoch 23, Batch 87, Loss: 0.664\n",
      "Training: Epoch 23, Batch 88, Loss: 0.515\n",
      "Training: Epoch 23, Batch 89, Loss: 0.564\n",
      "Val: Epoch 23, Loss: 0.274\n",
      "Training: Epoch 24, Batch 0, Loss: 0.559\n",
      "Training: Epoch 24, Batch 1, Loss: 0.402\n",
      "Training: Epoch 24, Batch 2, Loss: 0.315\n",
      "Training: Epoch 24, Batch 3, Loss: 0.512\n",
      "Training: Epoch 24, Batch 4, Loss: 0.469\n",
      "Training: Epoch 24, Batch 5, Loss: 0.581\n",
      "Training: Epoch 24, Batch 6, Loss: 0.387\n",
      "Training: Epoch 24, Batch 7, Loss: 0.708\n",
      "Training: Epoch 24, Batch 8, Loss: 0.585\n",
      "Training: Epoch 24, Batch 9, Loss: 0.418\n",
      "Training: Epoch 24, Batch 10, Loss: 0.483\n",
      "Training: Epoch 24, Batch 11, Loss: 0.267\n",
      "Training: Epoch 24, Batch 12, Loss: 0.31\n",
      "Training: Epoch 24, Batch 13, Loss: 0.5\n",
      "Training: Epoch 24, Batch 14, Loss: 0.532\n",
      "Training: Epoch 24, Batch 15, Loss: 0.443\n",
      "Training: Epoch 24, Batch 16, Loss: 0.273\n",
      "Training: Epoch 24, Batch 17, Loss: 0.25\n",
      "Training: Epoch 24, Batch 18, Loss: 0.369\n",
      "Training: Epoch 24, Batch 19, Loss: 0.562\n",
      "Training: Epoch 24, Batch 20, Loss: 0.359\n",
      "Training: Epoch 24, Batch 21, Loss: 0.591\n",
      "Training: Epoch 24, Batch 22, Loss: 0.477\n",
      "Training: Epoch 24, Batch 23, Loss: 0.342\n",
      "Training: Epoch 24, Batch 24, Loss: 0.497\n",
      "Training: Epoch 24, Batch 25, Loss: 0.585\n",
      "Training: Epoch 24, Batch 26, Loss: 0.57\n",
      "Training: Epoch 24, Batch 27, Loss: 0.621\n",
      "Training: Epoch 24, Batch 28, Loss: 0.596\n",
      "Training: Epoch 24, Batch 29, Loss: 0.822\n",
      "Training: Epoch 24, Batch 30, Loss: 0.687\n",
      "Training: Epoch 24, Batch 31, Loss: 0.367\n",
      "Training: Epoch 24, Batch 32, Loss: 0.609\n",
      "Training: Epoch 24, Batch 33, Loss: 0.582\n",
      "Training: Epoch 24, Batch 34, Loss: 0.592\n",
      "Training: Epoch 24, Batch 35, Loss: 0.358\n",
      "Training: Epoch 24, Batch 36, Loss: 0.223\n",
      "Training: Epoch 24, Batch 37, Loss: 0.594\n",
      "Training: Epoch 24, Batch 38, Loss: 0.459\n",
      "Training: Epoch 24, Batch 39, Loss: 0.451\n",
      "Training: Epoch 24, Batch 40, Loss: 0.453\n",
      "Training: Epoch 24, Batch 41, Loss: 0.787\n",
      "Training: Epoch 24, Batch 42, Loss: 0.365\n",
      "Training: Epoch 24, Batch 43, Loss: 0.506\n",
      "Training: Epoch 24, Batch 44, Loss: 0.414\n",
      "Training: Epoch 24, Batch 45, Loss: 0.625\n",
      "Training: Epoch 24, Batch 46, Loss: 0.416\n",
      "Training: Epoch 24, Batch 47, Loss: 0.572\n",
      "Training: Epoch 24, Batch 48, Loss: 0.504\n",
      "Training: Epoch 24, Batch 49, Loss: 0.384\n",
      "Training: Epoch 24, Batch 50, Loss: 0.327\n",
      "Training: Epoch 24, Batch 51, Loss: 0.656\n",
      "Training: Epoch 24, Batch 52, Loss: 0.391\n",
      "Training: Epoch 24, Batch 53, Loss: 0.399\n",
      "Training: Epoch 24, Batch 54, Loss: 0.487\n",
      "Training: Epoch 24, Batch 55, Loss: 0.502\n",
      "Training: Epoch 24, Batch 56, Loss: 0.686\n",
      "Training: Epoch 24, Batch 57, Loss: 0.581\n",
      "Training: Epoch 24, Batch 58, Loss: 0.524\n",
      "Training: Epoch 24, Batch 59, Loss: 0.521\n",
      "Training: Epoch 24, Batch 60, Loss: 0.404\n",
      "Training: Epoch 24, Batch 61, Loss: 0.323\n",
      "Training: Epoch 24, Batch 62, Loss: 0.616\n",
      "Training: Epoch 24, Batch 63, Loss: 0.509\n",
      "Training: Epoch 24, Batch 64, Loss: 0.367\n",
      "Training: Epoch 24, Batch 65, Loss: 0.486\n",
      "Training: Epoch 24, Batch 66, Loss: 0.545\n",
      "Training: Epoch 24, Batch 67, Loss: 0.531\n",
      "Training: Epoch 24, Batch 68, Loss: 0.446\n",
      "Training: Epoch 24, Batch 69, Loss: 0.304\n",
      "Training: Epoch 24, Batch 70, Loss: 0.601\n",
      "Training: Epoch 24, Batch 71, Loss: 0.462\n",
      "Training: Epoch 24, Batch 72, Loss: 0.565\n",
      "Training: Epoch 24, Batch 73, Loss: 0.502\n",
      "Training: Epoch 24, Batch 74, Loss: 0.482\n",
      "Training: Epoch 24, Batch 75, Loss: 0.594\n",
      "Training: Epoch 24, Batch 76, Loss: 0.398\n",
      "Training: Epoch 24, Batch 77, Loss: 0.541\n",
      "Training: Epoch 24, Batch 78, Loss: 0.366\n",
      "Training: Epoch 24, Batch 79, Loss: 0.601\n",
      "Training: Epoch 24, Batch 80, Loss: 0.446\n",
      "Training: Epoch 24, Batch 81, Loss: 0.537\n",
      "Training: Epoch 24, Batch 82, Loss: 0.308\n",
      "Training: Epoch 24, Batch 83, Loss: 0.538\n",
      "Training: Epoch 24, Batch 84, Loss: 0.533\n",
      "Training: Epoch 24, Batch 85, Loss: 0.643\n",
      "Training: Epoch 24, Batch 86, Loss: 0.419\n",
      "Training: Epoch 24, Batch 87, Loss: 0.42\n",
      "Training: Epoch 24, Batch 88, Loss: 0.361\n",
      "Training: Epoch 24, Batch 89, Loss: 0.568\n",
      "Val: Epoch 24, Loss: 0.264\n",
      "Training: Epoch 25, Batch 0, Loss: 0.437\n",
      "Training: Epoch 25, Batch 1, Loss: 0.472\n",
      "Training: Epoch 25, Batch 2, Loss: 0.443\n",
      "Training: Epoch 25, Batch 3, Loss: 0.355\n",
      "Training: Epoch 25, Batch 4, Loss: 0.297\n",
      "Training: Epoch 25, Batch 5, Loss: 0.445\n",
      "Training: Epoch 25, Batch 6, Loss: 0.409\n",
      "Training: Epoch 25, Batch 7, Loss: 0.559\n",
      "Training: Epoch 25, Batch 8, Loss: 0.434\n",
      "Training: Epoch 25, Batch 9, Loss: 0.421\n",
      "Training: Epoch 25, Batch 10, Loss: 0.492\n",
      "Training: Epoch 25, Batch 11, Loss: 0.558\n",
      "Training: Epoch 25, Batch 12, Loss: 0.483\n",
      "Training: Epoch 25, Batch 13, Loss: 0.796\n",
      "Training: Epoch 25, Batch 14, Loss: 0.409\n",
      "Training: Epoch 25, Batch 15, Loss: 0.473\n",
      "Training: Epoch 25, Batch 16, Loss: 0.492\n",
      "Training: Epoch 25, Batch 17, Loss: 0.571\n",
      "Training: Epoch 25, Batch 18, Loss: 0.409\n",
      "Training: Epoch 25, Batch 19, Loss: 0.539\n",
      "Training: Epoch 25, Batch 20, Loss: 0.475\n",
      "Training: Epoch 25, Batch 21, Loss: 0.471\n",
      "Training: Epoch 25, Batch 22, Loss: 0.569\n",
      "Training: Epoch 25, Batch 23, Loss: 0.599\n",
      "Training: Epoch 25, Batch 24, Loss: 0.408\n",
      "Training: Epoch 25, Batch 25, Loss: 0.421\n",
      "Training: Epoch 25, Batch 26, Loss: 0.398\n",
      "Training: Epoch 25, Batch 27, Loss: 0.433\n",
      "Training: Epoch 25, Batch 28, Loss: 0.48\n",
      "Training: Epoch 25, Batch 29, Loss: 0.436\n",
      "Training: Epoch 25, Batch 30, Loss: 0.59\n",
      "Training: Epoch 25, Batch 31, Loss: 0.53\n",
      "Training: Epoch 25, Batch 32, Loss: 0.49\n",
      "Training: Epoch 25, Batch 33, Loss: 0.521\n",
      "Training: Epoch 25, Batch 34, Loss: 0.486\n",
      "Training: Epoch 25, Batch 35, Loss: 0.523\n",
      "Training: Epoch 25, Batch 36, Loss: 0.317\n",
      "Training: Epoch 25, Batch 37, Loss: 0.475\n",
      "Training: Epoch 25, Batch 38, Loss: 0.352\n",
      "Training: Epoch 25, Batch 39, Loss: 0.304\n",
      "Training: Epoch 25, Batch 40, Loss: 0.474\n",
      "Training: Epoch 25, Batch 41, Loss: 0.377\n",
      "Training: Epoch 25, Batch 42, Loss: 0.382\n",
      "Training: Epoch 25, Batch 43, Loss: 0.564\n",
      "Training: Epoch 25, Batch 44, Loss: 0.69\n",
      "Training: Epoch 25, Batch 45, Loss: 0.387\n",
      "Training: Epoch 25, Batch 46, Loss: 0.378\n",
      "Training: Epoch 25, Batch 47, Loss: 0.259\n",
      "Training: Epoch 25, Batch 48, Loss: 0.514\n",
      "Training: Epoch 25, Batch 49, Loss: 0.404\n",
      "Training: Epoch 25, Batch 50, Loss: 0.652\n",
      "Training: Epoch 25, Batch 51, Loss: 0.518\n",
      "Training: Epoch 25, Batch 52, Loss: 0.931\n",
      "Training: Epoch 25, Batch 53, Loss: 0.505\n",
      "Training: Epoch 25, Batch 54, Loss: 0.575\n",
      "Training: Epoch 25, Batch 55, Loss: 0.382\n",
      "Training: Epoch 25, Batch 56, Loss: 0.322\n",
      "Training: Epoch 25, Batch 57, Loss: 0.292\n",
      "Training: Epoch 25, Batch 58, Loss: 0.523\n",
      "Training: Epoch 25, Batch 59, Loss: 0.574\n",
      "Training: Epoch 25, Batch 60, Loss: 0.656\n",
      "Training: Epoch 25, Batch 61, Loss: 0.494\n",
      "Training: Epoch 25, Batch 62, Loss: 0.454\n",
      "Training: Epoch 25, Batch 63, Loss: 0.404\n",
      "Training: Epoch 25, Batch 64, Loss: 0.727\n",
      "Training: Epoch 25, Batch 65, Loss: 0.418\n",
      "Training: Epoch 25, Batch 66, Loss: 0.403\n",
      "Training: Epoch 25, Batch 67, Loss: 0.381\n",
      "Training: Epoch 25, Batch 68, Loss: 0.354\n",
      "Training: Epoch 25, Batch 69, Loss: 0.311\n",
      "Training: Epoch 25, Batch 70, Loss: 0.27\n",
      "Training: Epoch 25, Batch 71, Loss: 0.279\n",
      "Training: Epoch 25, Batch 72, Loss: 0.519\n",
      "Training: Epoch 25, Batch 73, Loss: 0.327\n",
      "Training: Epoch 25, Batch 74, Loss: 0.434\n",
      "Training: Epoch 25, Batch 75, Loss: 0.489\n",
      "Training: Epoch 25, Batch 76, Loss: 0.465\n",
      "Training: Epoch 25, Batch 77, Loss: 0.561\n",
      "Training: Epoch 25, Batch 78, Loss: 0.334\n",
      "Training: Epoch 25, Batch 79, Loss: 0.376\n",
      "Training: Epoch 25, Batch 80, Loss: 0.451\n",
      "Training: Epoch 25, Batch 81, Loss: 0.955\n",
      "Training: Epoch 25, Batch 82, Loss: 0.424\n",
      "Training: Epoch 25, Batch 83, Loss: 0.721\n",
      "Training: Epoch 25, Batch 84, Loss: 0.697\n",
      "Training: Epoch 25, Batch 85, Loss: 0.936\n",
      "Training: Epoch 25, Batch 86, Loss: 0.559\n",
      "Training: Epoch 25, Batch 87, Loss: 0.531\n",
      "Training: Epoch 25, Batch 88, Loss: 0.562\n",
      "Training: Epoch 25, Batch 89, Loss: 0.553\n",
      "Val: Epoch 25, Loss: 0.578\n",
      "Training: Epoch 26, Batch 0, Loss: 0.518\n",
      "Training: Epoch 26, Batch 1, Loss: 0.499\n",
      "Training: Epoch 26, Batch 2, Loss: 0.531\n",
      "Training: Epoch 26, Batch 3, Loss: 0.549\n",
      "Training: Epoch 26, Batch 4, Loss: 0.598\n",
      "Training: Epoch 26, Batch 5, Loss: 0.573\n",
      "Training: Epoch 26, Batch 6, Loss: 0.688\n",
      "Training: Epoch 26, Batch 7, Loss: 0.521\n",
      "Training: Epoch 26, Batch 8, Loss: 0.476\n",
      "Training: Epoch 26, Batch 9, Loss: 0.406\n",
      "Training: Epoch 26, Batch 10, Loss: 0.521\n",
      "Training: Epoch 26, Batch 11, Loss: 0.413\n",
      "Training: Epoch 26, Batch 12, Loss: 0.562\n",
      "Training: Epoch 26, Batch 13, Loss: 0.671\n",
      "Training: Epoch 26, Batch 14, Loss: 0.729\n",
      "Training: Epoch 26, Batch 15, Loss: 0.45\n",
      "Training: Epoch 26, Batch 16, Loss: 0.422\n",
      "Training: Epoch 26, Batch 17, Loss: 0.449\n",
      "Training: Epoch 26, Batch 18, Loss: 0.361\n",
      "Training: Epoch 26, Batch 19, Loss: 0.395\n",
      "Training: Epoch 26, Batch 20, Loss: 0.537\n",
      "Training: Epoch 26, Batch 21, Loss: 0.609\n",
      "Training: Epoch 26, Batch 22, Loss: 0.752\n",
      "Training: Epoch 26, Batch 23, Loss: 0.841\n",
      "Training: Epoch 26, Batch 24, Loss: 0.436\n",
      "Training: Epoch 26, Batch 25, Loss: 0.477\n",
      "Training: Epoch 26, Batch 26, Loss: 0.424\n",
      "Training: Epoch 26, Batch 27, Loss: 0.527\n",
      "Training: Epoch 26, Batch 28, Loss: 0.401\n",
      "Training: Epoch 26, Batch 29, Loss: 0.403\n",
      "Training: Epoch 26, Batch 30, Loss: 0.439\n",
      "Training: Epoch 26, Batch 31, Loss: 0.627\n",
      "Training: Epoch 26, Batch 32, Loss: 0.528\n",
      "Training: Epoch 26, Batch 33, Loss: 0.404\n",
      "Training: Epoch 26, Batch 34, Loss: 0.713\n",
      "Training: Epoch 26, Batch 35, Loss: 0.47\n",
      "Training: Epoch 26, Batch 36, Loss: 0.448\n",
      "Training: Epoch 26, Batch 37, Loss: 0.32\n",
      "Training: Epoch 26, Batch 38, Loss: 0.605\n",
      "Training: Epoch 26, Batch 39, Loss: 0.407\n",
      "Training: Epoch 26, Batch 40, Loss: 0.59\n",
      "Training: Epoch 26, Batch 41, Loss: 0.303\n",
      "Training: Epoch 26, Batch 42, Loss: 0.612\n",
      "Training: Epoch 26, Batch 43, Loss: 0.421\n",
      "Training: Epoch 26, Batch 44, Loss: 0.382\n",
      "Training: Epoch 26, Batch 45, Loss: 0.336\n",
      "Training: Epoch 26, Batch 46, Loss: 0.47\n",
      "Training: Epoch 26, Batch 47, Loss: 0.394\n",
      "Training: Epoch 26, Batch 48, Loss: 0.451\n",
      "Training: Epoch 26, Batch 49, Loss: 0.469\n",
      "Training: Epoch 26, Batch 50, Loss: 0.51\n",
      "Training: Epoch 26, Batch 51, Loss: 0.447\n",
      "Training: Epoch 26, Batch 52, Loss: 0.524\n",
      "Training: Epoch 26, Batch 53, Loss: 0.395\n",
      "Training: Epoch 26, Batch 54, Loss: 0.432\n",
      "Training: Epoch 26, Batch 55, Loss: 1.018\n",
      "Training: Epoch 26, Batch 56, Loss: 0.433\n",
      "Training: Epoch 26, Batch 57, Loss: 0.291\n",
      "Training: Epoch 26, Batch 58, Loss: 0.319\n",
      "Training: Epoch 26, Batch 59, Loss: 0.389\n",
      "Training: Epoch 26, Batch 60, Loss: 0.507\n",
      "Training: Epoch 26, Batch 61, Loss: 0.425\n",
      "Training: Epoch 26, Batch 62, Loss: 0.388\n",
      "Training: Epoch 26, Batch 63, Loss: 0.346\n",
      "Training: Epoch 26, Batch 64, Loss: 0.421\n",
      "Training: Epoch 26, Batch 65, Loss: 0.677\n",
      "Training: Epoch 26, Batch 66, Loss: 0.435\n",
      "Training: Epoch 26, Batch 67, Loss: 0.294\n",
      "Training: Epoch 26, Batch 68, Loss: 0.602\n",
      "Training: Epoch 26, Batch 69, Loss: 0.67\n",
      "Training: Epoch 26, Batch 70, Loss: 0.557\n",
      "Training: Epoch 26, Batch 71, Loss: 0.556\n",
      "Training: Epoch 26, Batch 72, Loss: 0.535\n",
      "Training: Epoch 26, Batch 73, Loss: 0.439\n",
      "Training: Epoch 26, Batch 74, Loss: 0.493\n",
      "Training: Epoch 26, Batch 75, Loss: 0.585\n",
      "Training: Epoch 26, Batch 76, Loss: 0.626\n",
      "Training: Epoch 26, Batch 77, Loss: 0.587\n",
      "Training: Epoch 26, Batch 78, Loss: 0.469\n",
      "Training: Epoch 26, Batch 79, Loss: 0.321\n",
      "Training: Epoch 26, Batch 80, Loss: 0.476\n",
      "Training: Epoch 26, Batch 81, Loss: 0.426\n",
      "Training: Epoch 26, Batch 82, Loss: 0.395\n",
      "Training: Epoch 26, Batch 83, Loss: 0.444\n",
      "Training: Epoch 26, Batch 84, Loss: 0.569\n",
      "Training: Epoch 26, Batch 85, Loss: 0.723\n",
      "Training: Epoch 26, Batch 86, Loss: 0.566\n",
      "Training: Epoch 26, Batch 87, Loss: 0.544\n",
      "Training: Epoch 26, Batch 88, Loss: 0.438\n",
      "Training: Epoch 26, Batch 89, Loss: 0.454\n",
      "Val: Epoch 26, Loss: 0.27\n",
      "Training: Epoch 27, Batch 0, Loss: 0.556\n",
      "Training: Epoch 27, Batch 1, Loss: 0.35\n",
      "Training: Epoch 27, Batch 2, Loss: 0.509\n",
      "Training: Epoch 27, Batch 3, Loss: 0.507\n",
      "Training: Epoch 27, Batch 4, Loss: 0.542\n",
      "Training: Epoch 27, Batch 5, Loss: 0.528\n",
      "Training: Epoch 27, Batch 6, Loss: 0.549\n",
      "Training: Epoch 27, Batch 7, Loss: 0.377\n",
      "Training: Epoch 27, Batch 8, Loss: 0.419\n",
      "Training: Epoch 27, Batch 9, Loss: 0.535\n",
      "Training: Epoch 27, Batch 10, Loss: 0.496\n",
      "Training: Epoch 27, Batch 11, Loss: 0.494\n",
      "Training: Epoch 27, Batch 12, Loss: 0.52\n",
      "Training: Epoch 27, Batch 13, Loss: 0.404\n",
      "Training: Epoch 27, Batch 14, Loss: 0.482\n",
      "Training: Epoch 27, Batch 15, Loss: 0.355\n",
      "Training: Epoch 27, Batch 16, Loss: 0.42\n",
      "Training: Epoch 27, Batch 17, Loss: 0.388\n",
      "Training: Epoch 27, Batch 18, Loss: 0.295\n",
      "Training: Epoch 27, Batch 19, Loss: 0.621\n",
      "Training: Epoch 27, Batch 20, Loss: 0.629\n",
      "Training: Epoch 27, Batch 21, Loss: 0.389\n",
      "Training: Epoch 27, Batch 22, Loss: 0.441\n",
      "Training: Epoch 27, Batch 23, Loss: 0.319\n",
      "Training: Epoch 27, Batch 24, Loss: 0.523\n",
      "Training: Epoch 27, Batch 25, Loss: 0.391\n",
      "Training: Epoch 27, Batch 26, Loss: 0.587\n",
      "Training: Epoch 27, Batch 27, Loss: 0.486\n",
      "Training: Epoch 27, Batch 28, Loss: 0.597\n",
      "Training: Epoch 27, Batch 29, Loss: 0.47\n",
      "Training: Epoch 27, Batch 30, Loss: 0.59\n",
      "Training: Epoch 27, Batch 31, Loss: 0.391\n",
      "Training: Epoch 27, Batch 32, Loss: 0.466\n",
      "Training: Epoch 27, Batch 33, Loss: 0.589\n",
      "Training: Epoch 27, Batch 34, Loss: 0.457\n",
      "Training: Epoch 27, Batch 35, Loss: 0.423\n",
      "Training: Epoch 27, Batch 36, Loss: 0.375\n",
      "Training: Epoch 27, Batch 37, Loss: 0.477\n",
      "Training: Epoch 27, Batch 38, Loss: 0.569\n",
      "Training: Epoch 27, Batch 39, Loss: 0.513\n",
      "Training: Epoch 27, Batch 40, Loss: 0.388\n",
      "Training: Epoch 27, Batch 41, Loss: 0.539\n",
      "Training: Epoch 27, Batch 42, Loss: 0.362\n",
      "Training: Epoch 27, Batch 43, Loss: 0.42\n",
      "Training: Epoch 27, Batch 44, Loss: 0.47\n",
      "Training: Epoch 27, Batch 45, Loss: 1.406\n",
      "Training: Epoch 27, Batch 46, Loss: 0.334\n",
      "Training: Epoch 27, Batch 47, Loss: 0.598\n",
      "Training: Epoch 27, Batch 48, Loss: 0.4\n",
      "Training: Epoch 27, Batch 49, Loss: 0.641\n",
      "Training: Epoch 27, Batch 50, Loss: 0.464\n",
      "Training: Epoch 27, Batch 51, Loss: 0.438\n",
      "Training: Epoch 27, Batch 52, Loss: 0.555\n",
      "Training: Epoch 27, Batch 53, Loss: 0.602\n",
      "Training: Epoch 27, Batch 54, Loss: 0.518\n",
      "Training: Epoch 27, Batch 55, Loss: 0.551\n",
      "Training: Epoch 27, Batch 56, Loss: 0.486\n",
      "Training: Epoch 27, Batch 57, Loss: 0.533\n",
      "Training: Epoch 27, Batch 58, Loss: 0.474\n",
      "Training: Epoch 27, Batch 59, Loss: 0.531\n",
      "Training: Epoch 27, Batch 60, Loss: 0.469\n",
      "Training: Epoch 27, Batch 61, Loss: 0.489\n",
      "Training: Epoch 27, Batch 62, Loss: 0.599\n",
      "Training: Epoch 27, Batch 63, Loss: 0.427\n",
      "Training: Epoch 27, Batch 64, Loss: 0.398\n",
      "Training: Epoch 27, Batch 65, Loss: 0.381\n",
      "Training: Epoch 27, Batch 66, Loss: 0.624\n",
      "Training: Epoch 27, Batch 67, Loss: 0.387\n",
      "Training: Epoch 27, Batch 68, Loss: 0.405\n",
      "Training: Epoch 27, Batch 69, Loss: 0.557\n",
      "Training: Epoch 27, Batch 70, Loss: 0.67\n",
      "Training: Epoch 27, Batch 71, Loss: 0.486\n",
      "Training: Epoch 27, Batch 72, Loss: 0.466\n",
      "Training: Epoch 27, Batch 73, Loss: 0.45\n",
      "Training: Epoch 27, Batch 74, Loss: 0.461\n",
      "Training: Epoch 27, Batch 75, Loss: 0.55\n",
      "Training: Epoch 27, Batch 76, Loss: 0.229\n",
      "Training: Epoch 27, Batch 77, Loss: 0.541\n",
      "Training: Epoch 27, Batch 78, Loss: 0.38\n",
      "Training: Epoch 27, Batch 79, Loss: 0.602\n",
      "Training: Epoch 27, Batch 80, Loss: 0.535\n",
      "Training: Epoch 27, Batch 81, Loss: 0.444\n",
      "Training: Epoch 27, Batch 82, Loss: 0.274\n",
      "Training: Epoch 27, Batch 83, Loss: 0.515\n",
      "Training: Epoch 27, Batch 84, Loss: 0.684\n",
      "Training: Epoch 27, Batch 85, Loss: 0.569\n",
      "Training: Epoch 27, Batch 86, Loss: 0.656\n",
      "Training: Epoch 27, Batch 87, Loss: 0.676\n",
      "Training: Epoch 27, Batch 88, Loss: 0.351\n",
      "Training: Epoch 27, Batch 89, Loss: 0.641\n",
      "Val: Epoch 27, Loss: 0.331\n",
      "Training: Epoch 28, Batch 0, Loss: 0.409\n",
      "Training: Epoch 28, Batch 1, Loss: 0.472\n",
      "Training: Epoch 28, Batch 2, Loss: 0.541\n",
      "Training: Epoch 28, Batch 3, Loss: 0.409\n",
      "Training: Epoch 28, Batch 4, Loss: 0.843\n",
      "Training: Epoch 28, Batch 5, Loss: 0.613\n",
      "Training: Epoch 28, Batch 6, Loss: 0.421\n",
      "Training: Epoch 28, Batch 7, Loss: 0.424\n",
      "Training: Epoch 28, Batch 8, Loss: 0.369\n",
      "Training: Epoch 28, Batch 9, Loss: 0.328\n",
      "Training: Epoch 28, Batch 10, Loss: 0.545\n",
      "Training: Epoch 28, Batch 11, Loss: 0.299\n",
      "Training: Epoch 28, Batch 12, Loss: 0.477\n",
      "Training: Epoch 28, Batch 13, Loss: 0.447\n",
      "Training: Epoch 28, Batch 14, Loss: 0.327\n",
      "Training: Epoch 28, Batch 15, Loss: 0.459\n",
      "Training: Epoch 28, Batch 16, Loss: 0.372\n",
      "Training: Epoch 28, Batch 17, Loss: 0.65\n",
      "Training: Epoch 28, Batch 18, Loss: 0.388\n",
      "Training: Epoch 28, Batch 19, Loss: 0.39\n",
      "Training: Epoch 28, Batch 20, Loss: 0.354\n",
      "Training: Epoch 28, Batch 21, Loss: 0.509\n",
      "Training: Epoch 28, Batch 22, Loss: 0.525\n",
      "Training: Epoch 28, Batch 23, Loss: 0.384\n",
      "Training: Epoch 28, Batch 24, Loss: 0.526\n",
      "Training: Epoch 28, Batch 25, Loss: 0.447\n",
      "Training: Epoch 28, Batch 26, Loss: 0.503\n",
      "Training: Epoch 28, Batch 27, Loss: 0.57\n",
      "Training: Epoch 28, Batch 28, Loss: 0.531\n",
      "Training: Epoch 28, Batch 29, Loss: 0.72\n",
      "Training: Epoch 28, Batch 30, Loss: 0.338\n",
      "Training: Epoch 28, Batch 31, Loss: 0.526\n",
      "Training: Epoch 28, Batch 32, Loss: 0.493\n",
      "Training: Epoch 28, Batch 33, Loss: 0.355\n",
      "Training: Epoch 28, Batch 34, Loss: 0.73\n",
      "Training: Epoch 28, Batch 35, Loss: 0.394\n",
      "Training: Epoch 28, Batch 36, Loss: 0.252\n",
      "Training: Epoch 28, Batch 37, Loss: 0.558\n",
      "Training: Epoch 28, Batch 38, Loss: 0.496\n",
      "Training: Epoch 28, Batch 39, Loss: 0.463\n",
      "Training: Epoch 28, Batch 40, Loss: 0.386\n",
      "Training: Epoch 28, Batch 41, Loss: 0.37\n",
      "Training: Epoch 28, Batch 42, Loss: 0.421\n",
      "Training: Epoch 28, Batch 43, Loss: 0.544\n",
      "Training: Epoch 28, Batch 44, Loss: 0.771\n",
      "Training: Epoch 28, Batch 45, Loss: 0.453\n",
      "Training: Epoch 28, Batch 46, Loss: 0.24\n",
      "Training: Epoch 28, Batch 47, Loss: 0.33\n",
      "Training: Epoch 28, Batch 48, Loss: 0.432\n",
      "Training: Epoch 28, Batch 49, Loss: 0.553\n",
      "Training: Epoch 28, Batch 50, Loss: 0.61\n",
      "Training: Epoch 28, Batch 51, Loss: 0.596\n",
      "Training: Epoch 28, Batch 52, Loss: 0.757\n",
      "Training: Epoch 28, Batch 53, Loss: 0.484\n",
      "Training: Epoch 28, Batch 54, Loss: 0.53\n",
      "Training: Epoch 28, Batch 55, Loss: 0.623\n",
      "Training: Epoch 28, Batch 56, Loss: 0.439\n",
      "Training: Epoch 28, Batch 57, Loss: 0.493\n",
      "Training: Epoch 28, Batch 58, Loss: 0.356\n",
      "Training: Epoch 28, Batch 59, Loss: 0.549\n",
      "Training: Epoch 28, Batch 60, Loss: 0.477\n",
      "Training: Epoch 28, Batch 61, Loss: 0.452\n",
      "Training: Epoch 28, Batch 62, Loss: 0.403\n",
      "Training: Epoch 28, Batch 63, Loss: 0.343\n",
      "Training: Epoch 28, Batch 64, Loss: 0.523\n",
      "Training: Epoch 28, Batch 65, Loss: 0.481\n",
      "Training: Epoch 28, Batch 66, Loss: 0.618\n",
      "Training: Epoch 28, Batch 67, Loss: 0.478\n",
      "Training: Epoch 28, Batch 68, Loss: 0.373\n",
      "Training: Epoch 28, Batch 69, Loss: 0.428\n",
      "Training: Epoch 28, Batch 70, Loss: 0.468\n",
      "Training: Epoch 28, Batch 71, Loss: 0.432\n",
      "Training: Epoch 28, Batch 72, Loss: 0.4\n",
      "Training: Epoch 28, Batch 73, Loss: 0.512\n",
      "Training: Epoch 28, Batch 74, Loss: 0.334\n",
      "Training: Epoch 28, Batch 75, Loss: 0.493\n",
      "Training: Epoch 28, Batch 76, Loss: 0.289\n",
      "Training: Epoch 28, Batch 77, Loss: 0.464\n",
      "Training: Epoch 28, Batch 78, Loss: 0.662\n",
      "Training: Epoch 28, Batch 79, Loss: 0.405\n",
      "Training: Epoch 28, Batch 80, Loss: 0.53\n",
      "Training: Epoch 28, Batch 81, Loss: 0.484\n",
      "Training: Epoch 28, Batch 82, Loss: 0.417\n",
      "Training: Epoch 28, Batch 83, Loss: 0.691\n",
      "Training: Epoch 28, Batch 84, Loss: 0.508\n",
      "Training: Epoch 28, Batch 85, Loss: 0.416\n",
      "Training: Epoch 28, Batch 86, Loss: 0.468\n",
      "Training: Epoch 28, Batch 87, Loss: 0.455\n",
      "Training: Epoch 28, Batch 88, Loss: 0.499\n",
      "Training: Epoch 28, Batch 89, Loss: 0.324\n",
      "Val: Epoch 28, Loss: 0.254\n",
      "Training: Epoch 29, Batch 0, Loss: 0.499\n",
      "Training: Epoch 29, Batch 1, Loss: 0.562\n",
      "Training: Epoch 29, Batch 2, Loss: 0.572\n",
      "Training: Epoch 29, Batch 3, Loss: 0.371\n",
      "Training: Epoch 29, Batch 4, Loss: 0.498\n",
      "Training: Epoch 29, Batch 5, Loss: 0.493\n",
      "Training: Epoch 29, Batch 6, Loss: 0.709\n",
      "Training: Epoch 29, Batch 7, Loss: 0.377\n",
      "Training: Epoch 29, Batch 8, Loss: 0.444\n",
      "Training: Epoch 29, Batch 9, Loss: 0.711\n",
      "Training: Epoch 29, Batch 10, Loss: 0.386\n",
      "Training: Epoch 29, Batch 11, Loss: 0.415\n",
      "Training: Epoch 29, Batch 12, Loss: 0.601\n",
      "Training: Epoch 29, Batch 13, Loss: 0.506\n",
      "Training: Epoch 29, Batch 14, Loss: 0.486\n",
      "Training: Epoch 29, Batch 15, Loss: 0.584\n",
      "Training: Epoch 29, Batch 16, Loss: 0.5\n",
      "Training: Epoch 29, Batch 17, Loss: 0.49\n",
      "Training: Epoch 29, Batch 18, Loss: 0.759\n",
      "Training: Epoch 29, Batch 19, Loss: 0.607\n",
      "Training: Epoch 29, Batch 20, Loss: 0.489\n",
      "Training: Epoch 29, Batch 21, Loss: 0.478\n",
      "Training: Epoch 29, Batch 22, Loss: 0.376\n",
      "Training: Epoch 29, Batch 23, Loss: 0.412\n",
      "Training: Epoch 29, Batch 24, Loss: 0.509\n",
      "Training: Epoch 29, Batch 25, Loss: 0.329\n",
      "Training: Epoch 29, Batch 26, Loss: 0.32\n",
      "Training: Epoch 29, Batch 27, Loss: 0.518\n",
      "Training: Epoch 29, Batch 28, Loss: 0.324\n",
      "Training: Epoch 29, Batch 29, Loss: 0.4\n",
      "Training: Epoch 29, Batch 30, Loss: 0.456\n",
      "Training: Epoch 29, Batch 31, Loss: 0.434\n",
      "Training: Epoch 29, Batch 32, Loss: 0.612\n",
      "Training: Epoch 29, Batch 33, Loss: 0.458\n",
      "Training: Epoch 29, Batch 34, Loss: 0.525\n",
      "Training: Epoch 29, Batch 35, Loss: 0.632\n",
      "Training: Epoch 29, Batch 36, Loss: 0.479\n",
      "Training: Epoch 29, Batch 37, Loss: 0.287\n",
      "Training: Epoch 29, Batch 38, Loss: 0.384\n",
      "Training: Epoch 29, Batch 39, Loss: 0.343\n",
      "Training: Epoch 29, Batch 40, Loss: 0.598\n",
      "Training: Epoch 29, Batch 41, Loss: 0.373\n",
      "Training: Epoch 29, Batch 42, Loss: 0.282\n",
      "Training: Epoch 29, Batch 43, Loss: 0.646\n",
      "Training: Epoch 29, Batch 44, Loss: 0.604\n",
      "Training: Epoch 29, Batch 45, Loss: 0.375\n",
      "Training: Epoch 29, Batch 46, Loss: 0.426\n",
      "Training: Epoch 29, Batch 47, Loss: 0.556\n",
      "Training: Epoch 29, Batch 48, Loss: 0.635\n",
      "Training: Epoch 29, Batch 49, Loss: 0.541\n",
      "Training: Epoch 29, Batch 50, Loss: 0.445\n",
      "Training: Epoch 29, Batch 51, Loss: 0.324\n",
      "Training: Epoch 29, Batch 52, Loss: 0.499\n",
      "Training: Epoch 29, Batch 53, Loss: 0.399\n",
      "Training: Epoch 29, Batch 54, Loss: 0.263\n",
      "Training: Epoch 29, Batch 55, Loss: 0.45\n",
      "Training: Epoch 29, Batch 56, Loss: 0.415\n",
      "Training: Epoch 29, Batch 57, Loss: 0.301\n",
      "Training: Epoch 29, Batch 58, Loss: 0.467\n",
      "Training: Epoch 29, Batch 59, Loss: 0.296\n",
      "Training: Epoch 29, Batch 60, Loss: 0.6\n",
      "Training: Epoch 29, Batch 61, Loss: 0.344\n",
      "Training: Epoch 29, Batch 62, Loss: 0.56\n",
      "Training: Epoch 29, Batch 63, Loss: 0.393\n",
      "Training: Epoch 29, Batch 64, Loss: 0.395\n",
      "Training: Epoch 29, Batch 65, Loss: 0.6\n",
      "Training: Epoch 29, Batch 66, Loss: 0.721\n",
      "Training: Epoch 29, Batch 67, Loss: 0.497\n",
      "Training: Epoch 29, Batch 68, Loss: 0.773\n",
      "Training: Epoch 29, Batch 69, Loss: 0.49\n",
      "Training: Epoch 29, Batch 70, Loss: 0.549\n",
      "Training: Epoch 29, Batch 71, Loss: 0.335\n",
      "Training: Epoch 29, Batch 72, Loss: 0.531\n",
      "Training: Epoch 29, Batch 73, Loss: 0.302\n",
      "Training: Epoch 29, Batch 74, Loss: 0.426\n",
      "Training: Epoch 29, Batch 75, Loss: 0.401\n",
      "Training: Epoch 29, Batch 76, Loss: 0.532\n",
      "Training: Epoch 29, Batch 77, Loss: 0.616\n",
      "Training: Epoch 29, Batch 78, Loss: 0.554\n",
      "Training: Epoch 29, Batch 79, Loss: 0.573\n",
      "Training: Epoch 29, Batch 80, Loss: 0.393\n",
      "Training: Epoch 29, Batch 81, Loss: 0.397\n",
      "Training: Epoch 29, Batch 82, Loss: 0.574\n",
      "Training: Epoch 29, Batch 83, Loss: 0.622\n",
      "Training: Epoch 29, Batch 84, Loss: 0.319\n",
      "Training: Epoch 29, Batch 85, Loss: 0.377\n",
      "Training: Epoch 29, Batch 86, Loss: 0.487\n",
      "Training: Epoch 29, Batch 87, Loss: 0.367\n",
      "Training: Epoch 29, Batch 88, Loss: 0.559\n",
      "Training: Epoch 29, Batch 89, Loss: 0.423\n",
      "Val: Epoch 29, Loss: 0.252\n",
      "Training: Epoch 30, Batch 0, Loss: 0.378\n",
      "Training: Epoch 30, Batch 1, Loss: 0.407\n",
      "Training: Epoch 30, Batch 2, Loss: 0.625\n",
      "Training: Epoch 30, Batch 3, Loss: 0.428\n",
      "Training: Epoch 30, Batch 4, Loss: 0.559\n",
      "Training: Epoch 30, Batch 5, Loss: 0.412\n",
      "Training: Epoch 30, Batch 6, Loss: 0.567\n",
      "Training: Epoch 30, Batch 7, Loss: 0.369\n",
      "Training: Epoch 30, Batch 8, Loss: 0.481\n",
      "Training: Epoch 30, Batch 9, Loss: 0.5\n",
      "Training: Epoch 30, Batch 10, Loss: 0.593\n",
      "Training: Epoch 30, Batch 11, Loss: 0.671\n",
      "Training: Epoch 30, Batch 12, Loss: 0.542\n",
      "Training: Epoch 30, Batch 13, Loss: 0.358\n",
      "Training: Epoch 30, Batch 14, Loss: 0.491\n",
      "Training: Epoch 30, Batch 15, Loss: 0.583\n",
      "Training: Epoch 30, Batch 16, Loss: 0.617\n",
      "Training: Epoch 30, Batch 17, Loss: 0.641\n",
      "Training: Epoch 30, Batch 18, Loss: 0.385\n",
      "Training: Epoch 30, Batch 19, Loss: 0.444\n",
      "Training: Epoch 30, Batch 20, Loss: 0.568\n",
      "Training: Epoch 30, Batch 21, Loss: 0.345\n",
      "Training: Epoch 30, Batch 22, Loss: 0.489\n",
      "Training: Epoch 30, Batch 23, Loss: 0.729\n",
      "Training: Epoch 30, Batch 24, Loss: 0.358\n",
      "Training: Epoch 30, Batch 25, Loss: 0.656\n",
      "Training: Epoch 30, Batch 26, Loss: 0.392\n",
      "Training: Epoch 30, Batch 27, Loss: 0.493\n",
      "Training: Epoch 30, Batch 28, Loss: 0.577\n",
      "Training: Epoch 30, Batch 29, Loss: 0.561\n",
      "Training: Epoch 30, Batch 30, Loss: 0.364\n",
      "Training: Epoch 30, Batch 31, Loss: 0.416\n",
      "Training: Epoch 30, Batch 32, Loss: 0.386\n",
      "Training: Epoch 30, Batch 33, Loss: 0.436\n",
      "Training: Epoch 30, Batch 34, Loss: 0.434\n",
      "Training: Epoch 30, Batch 35, Loss: 0.58\n",
      "Training: Epoch 30, Batch 36, Loss: 0.574\n",
      "Training: Epoch 30, Batch 37, Loss: 0.498\n",
      "Training: Epoch 30, Batch 38, Loss: 0.389\n",
      "Training: Epoch 30, Batch 39, Loss: 0.478\n",
      "Training: Epoch 30, Batch 40, Loss: 0.488\n",
      "Training: Epoch 30, Batch 41, Loss: 0.554\n",
      "Training: Epoch 30, Batch 42, Loss: 0.47\n",
      "Training: Epoch 30, Batch 43, Loss: 0.397\n",
      "Training: Epoch 30, Batch 44, Loss: 0.268\n",
      "Training: Epoch 30, Batch 45, Loss: 0.336\n",
      "Training: Epoch 30, Batch 46, Loss: 0.223\n",
      "Training: Epoch 30, Batch 47, Loss: 0.337\n",
      "Training: Epoch 30, Batch 48, Loss: 0.645\n",
      "Training: Epoch 30, Batch 49, Loss: 0.526\n",
      "Training: Epoch 30, Batch 50, Loss: 0.541\n",
      "Training: Epoch 30, Batch 51, Loss: 0.5\n",
      "Training: Epoch 30, Batch 52, Loss: 0.481\n",
      "Training: Epoch 30, Batch 53, Loss: 0.92\n",
      "Training: Epoch 30, Batch 54, Loss: 0.595\n",
      "Training: Epoch 30, Batch 55, Loss: 0.3\n",
      "Training: Epoch 30, Batch 56, Loss: 0.441\n",
      "Training: Epoch 30, Batch 57, Loss: 0.427\n",
      "Training: Epoch 30, Batch 58, Loss: 0.56\n",
      "Training: Epoch 30, Batch 59, Loss: 0.399\n",
      "Training: Epoch 30, Batch 60, Loss: 0.287\n",
      "Training: Epoch 30, Batch 61, Loss: 0.397\n",
      "Training: Epoch 30, Batch 62, Loss: 0.402\n",
      "Training: Epoch 30, Batch 63, Loss: 0.497\n",
      "Training: Epoch 30, Batch 64, Loss: 0.593\n",
      "Training: Epoch 30, Batch 65, Loss: 0.386\n",
      "Training: Epoch 30, Batch 66, Loss: 0.582\n",
      "Training: Epoch 30, Batch 67, Loss: 0.352\n",
      "Training: Epoch 30, Batch 68, Loss: 0.431\n",
      "Training: Epoch 30, Batch 69, Loss: 0.54\n",
      "Training: Epoch 30, Batch 70, Loss: 0.477\n",
      "Training: Epoch 30, Batch 71, Loss: 0.482\n",
      "Training: Epoch 30, Batch 72, Loss: 0.373\n",
      "Training: Epoch 30, Batch 73, Loss: 0.352\n",
      "Training: Epoch 30, Batch 74, Loss: 0.339\n",
      "Training: Epoch 30, Batch 75, Loss: 0.451\n",
      "Training: Epoch 30, Batch 76, Loss: 0.29\n",
      "Training: Epoch 30, Batch 77, Loss: 0.661\n",
      "Training: Epoch 30, Batch 78, Loss: 0.28\n",
      "Training: Epoch 30, Batch 79, Loss: 0.408\n",
      "Training: Epoch 30, Batch 80, Loss: 0.427\n",
      "Training: Epoch 30, Batch 81, Loss: 0.482\n",
      "Training: Epoch 30, Batch 82, Loss: 0.511\n",
      "Training: Epoch 30, Batch 83, Loss: 0.463\n",
      "Training: Epoch 30, Batch 84, Loss: 0.41\n",
      "Training: Epoch 30, Batch 85, Loss: 0.58\n",
      "Training: Epoch 30, Batch 86, Loss: 0.458\n",
      "Training: Epoch 30, Batch 87, Loss: 0.43\n",
      "Training: Epoch 30, Batch 88, Loss: 0.287\n",
      "Training: Epoch 30, Batch 89, Loss: 0.319\n",
      "Val: Epoch 30, Loss: 0.277\n",
      "Training: Epoch 31, Batch 0, Loss: 0.44\n",
      "Training: Epoch 31, Batch 1, Loss: 0.611\n",
      "Training: Epoch 31, Batch 2, Loss: 0.521\n",
      "Training: Epoch 31, Batch 3, Loss: 0.242\n",
      "Training: Epoch 31, Batch 4, Loss: 0.282\n",
      "Training: Epoch 31, Batch 5, Loss: 0.578\n",
      "Training: Epoch 31, Batch 6, Loss: 0.647\n",
      "Training: Epoch 31, Batch 7, Loss: 0.56\n",
      "Training: Epoch 31, Batch 8, Loss: 0.516\n",
      "Training: Epoch 31, Batch 9, Loss: 0.506\n",
      "Training: Epoch 31, Batch 10, Loss: 0.483\n",
      "Training: Epoch 31, Batch 11, Loss: 0.257\n",
      "Training: Epoch 31, Batch 12, Loss: 0.381\n",
      "Training: Epoch 31, Batch 13, Loss: 0.283\n",
      "Training: Epoch 31, Batch 14, Loss: 0.672\n",
      "Training: Epoch 31, Batch 15, Loss: 0.374\n",
      "Training: Epoch 31, Batch 16, Loss: 0.4\n",
      "Training: Epoch 31, Batch 17, Loss: 0.453\n",
      "Training: Epoch 31, Batch 18, Loss: 0.258\n",
      "Training: Epoch 31, Batch 19, Loss: 0.41\n",
      "Training: Epoch 31, Batch 20, Loss: 0.213\n",
      "Training: Epoch 31, Batch 21, Loss: 0.244\n",
      "Training: Epoch 31, Batch 22, Loss: 0.428\n",
      "Training: Epoch 31, Batch 23, Loss: 0.642\n",
      "Training: Epoch 31, Batch 24, Loss: 0.408\n",
      "Training: Epoch 31, Batch 25, Loss: 0.354\n",
      "Training: Epoch 31, Batch 26, Loss: 0.386\n",
      "Training: Epoch 31, Batch 27, Loss: 0.767\n",
      "Training: Epoch 31, Batch 28, Loss: 0.368\n",
      "Training: Epoch 31, Batch 29, Loss: 0.287\n",
      "Training: Epoch 31, Batch 30, Loss: 0.388\n",
      "Training: Epoch 31, Batch 31, Loss: 0.242\n",
      "Training: Epoch 31, Batch 32, Loss: 0.434\n",
      "Training: Epoch 31, Batch 33, Loss: 0.372\n",
      "Training: Epoch 31, Batch 34, Loss: 0.494\n",
      "Training: Epoch 31, Batch 35, Loss: 0.388\n",
      "Training: Epoch 31, Batch 36, Loss: 0.377\n",
      "Training: Epoch 31, Batch 37, Loss: 0.317\n",
      "Training: Epoch 31, Batch 38, Loss: 0.592\n",
      "Training: Epoch 31, Batch 39, Loss: 0.488\n",
      "Training: Epoch 31, Batch 40, Loss: 0.869\n",
      "Training: Epoch 31, Batch 41, Loss: 0.417\n",
      "Training: Epoch 31, Batch 42, Loss: 0.384\n",
      "Training: Epoch 31, Batch 43, Loss: 0.702\n",
      "Training: Epoch 31, Batch 44, Loss: 0.318\n",
      "Training: Epoch 31, Batch 45, Loss: 0.4\n",
      "Training: Epoch 31, Batch 46, Loss: 0.385\n",
      "Training: Epoch 31, Batch 47, Loss: 0.535\n",
      "Training: Epoch 31, Batch 48, Loss: 0.532\n",
      "Training: Epoch 31, Batch 49, Loss: 0.446\n",
      "Training: Epoch 31, Batch 50, Loss: 0.382\n",
      "Training: Epoch 31, Batch 51, Loss: 0.423\n",
      "Training: Epoch 31, Batch 52, Loss: 0.417\n",
      "Training: Epoch 31, Batch 53, Loss: 0.477\n",
      "Training: Epoch 31, Batch 54, Loss: 0.65\n",
      "Training: Epoch 31, Batch 55, Loss: 0.646\n",
      "Training: Epoch 31, Batch 56, Loss: 0.385\n",
      "Training: Epoch 31, Batch 57, Loss: 0.363\n",
      "Training: Epoch 31, Batch 58, Loss: 0.597\n",
      "Training: Epoch 31, Batch 59, Loss: 0.672\n",
      "Training: Epoch 31, Batch 60, Loss: 0.402\n",
      "Training: Epoch 31, Batch 61, Loss: 0.743\n",
      "Training: Epoch 31, Batch 62, Loss: 0.507\n",
      "Training: Epoch 31, Batch 63, Loss: 0.465\n",
      "Training: Epoch 31, Batch 64, Loss: 0.402\n",
      "Training: Epoch 31, Batch 65, Loss: 0.584\n",
      "Training: Epoch 31, Batch 66, Loss: 0.508\n",
      "Training: Epoch 31, Batch 67, Loss: 0.449\n",
      "Training: Epoch 31, Batch 68, Loss: 0.475\n",
      "Training: Epoch 31, Batch 69, Loss: 0.358\n",
      "Training: Epoch 31, Batch 70, Loss: 0.598\n",
      "Training: Epoch 31, Batch 71, Loss: 0.288\n",
      "Training: Epoch 31, Batch 72, Loss: 0.403\n",
      "Training: Epoch 31, Batch 73, Loss: 0.676\n",
      "Training: Epoch 31, Batch 74, Loss: 0.527\n",
      "Training: Epoch 31, Batch 75, Loss: 0.435\n",
      "Training: Epoch 31, Batch 76, Loss: 0.348\n",
      "Training: Epoch 31, Batch 77, Loss: 0.67\n",
      "Training: Epoch 31, Batch 78, Loss: 0.411\n",
      "Training: Epoch 31, Batch 79, Loss: 0.399\n",
      "Training: Epoch 31, Batch 80, Loss: 0.594\n",
      "Training: Epoch 31, Batch 81, Loss: 0.271\n",
      "Training: Epoch 31, Batch 82, Loss: 0.464\n",
      "Training: Epoch 31, Batch 83, Loss: 0.352\n",
      "Training: Epoch 31, Batch 84, Loss: 0.509\n",
      "Training: Epoch 31, Batch 85, Loss: 0.64\n",
      "Training: Epoch 31, Batch 86, Loss: 0.293\n",
      "Training: Epoch 31, Batch 87, Loss: 0.493\n",
      "Training: Epoch 31, Batch 88, Loss: 0.434\n",
      "Training: Epoch 31, Batch 89, Loss: 0.62\n",
      "Val: Epoch 31, Loss: 0.261\n",
      "Training: Epoch 32, Batch 0, Loss: 0.337\n",
      "Training: Epoch 32, Batch 1, Loss: 0.46\n",
      "Training: Epoch 32, Batch 2, Loss: 0.346\n",
      "Training: Epoch 32, Batch 3, Loss: 1.095\n",
      "Training: Epoch 32, Batch 4, Loss: 0.469\n",
      "Training: Epoch 32, Batch 5, Loss: 0.398\n",
      "Training: Epoch 32, Batch 6, Loss: 0.454\n",
      "Training: Epoch 32, Batch 7, Loss: 0.38\n",
      "Training: Epoch 32, Batch 8, Loss: 0.492\n",
      "Training: Epoch 32, Batch 9, Loss: 0.454\n",
      "Training: Epoch 32, Batch 10, Loss: 0.562\n",
      "Training: Epoch 32, Batch 11, Loss: 0.524\n",
      "Training: Epoch 32, Batch 12, Loss: 0.468\n",
      "Training: Epoch 32, Batch 13, Loss: 0.452\n",
      "Training: Epoch 32, Batch 14, Loss: 0.397\n",
      "Training: Epoch 32, Batch 15, Loss: 0.516\n",
      "Training: Epoch 32, Batch 16, Loss: 0.535\n",
      "Training: Epoch 32, Batch 17, Loss: 0.609\n",
      "Training: Epoch 32, Batch 18, Loss: 0.485\n",
      "Training: Epoch 32, Batch 19, Loss: 0.388\n",
      "Training: Epoch 32, Batch 20, Loss: 0.52\n",
      "Training: Epoch 32, Batch 21, Loss: 0.289\n",
      "Training: Epoch 32, Batch 22, Loss: 0.292\n",
      "Training: Epoch 32, Batch 23, Loss: 0.68\n",
      "Training: Epoch 32, Batch 24, Loss: 0.442\n",
      "Training: Epoch 32, Batch 25, Loss: 0.438\n",
      "Training: Epoch 32, Batch 26, Loss: 0.636\n",
      "Training: Epoch 32, Batch 27, Loss: 0.465\n",
      "Training: Epoch 32, Batch 28, Loss: 0.469\n",
      "Training: Epoch 32, Batch 29, Loss: 0.451\n",
      "Training: Epoch 32, Batch 30, Loss: 0.483\n",
      "Training: Epoch 32, Batch 31, Loss: 0.447\n",
      "Training: Epoch 32, Batch 32, Loss: 0.354\n",
      "Training: Epoch 32, Batch 33, Loss: 0.25\n",
      "Training: Epoch 32, Batch 34, Loss: 0.399\n",
      "Training: Epoch 32, Batch 35, Loss: 0.627\n",
      "Training: Epoch 32, Batch 36, Loss: 0.745\n",
      "Training: Epoch 32, Batch 37, Loss: 0.647\n",
      "Training: Epoch 32, Batch 38, Loss: 0.599\n",
      "Training: Epoch 32, Batch 39, Loss: 0.25\n",
      "Training: Epoch 32, Batch 40, Loss: 0.661\n",
      "Training: Epoch 32, Batch 41, Loss: 0.427\n",
      "Training: Epoch 32, Batch 42, Loss: 0.648\n",
      "Training: Epoch 32, Batch 43, Loss: 0.605\n",
      "Training: Epoch 32, Batch 44, Loss: 0.599\n",
      "Training: Epoch 32, Batch 45, Loss: 0.427\n",
      "Training: Epoch 32, Batch 46, Loss: 0.345\n",
      "Training: Epoch 32, Batch 47, Loss: 0.698\n",
      "Training: Epoch 32, Batch 48, Loss: 0.565\n",
      "Training: Epoch 32, Batch 49, Loss: 0.364\n",
      "Training: Epoch 32, Batch 50, Loss: 0.416\n",
      "Training: Epoch 32, Batch 51, Loss: 0.49\n",
      "Training: Epoch 32, Batch 52, Loss: 0.581\n",
      "Training: Epoch 32, Batch 53, Loss: 0.751\n",
      "Training: Epoch 32, Batch 54, Loss: 0.538\n",
      "Training: Epoch 32, Batch 55, Loss: 0.404\n",
      "Training: Epoch 32, Batch 56, Loss: 0.499\n",
      "Training: Epoch 32, Batch 57, Loss: 0.5\n",
      "Training: Epoch 32, Batch 58, Loss: 0.476\n",
      "Training: Epoch 32, Batch 59, Loss: 0.41\n",
      "Training: Epoch 32, Batch 60, Loss: 0.768\n",
      "Training: Epoch 32, Batch 61, Loss: 0.503\n",
      "Training: Epoch 32, Batch 62, Loss: 0.532\n",
      "Training: Epoch 32, Batch 63, Loss: 0.384\n",
      "Training: Epoch 32, Batch 64, Loss: 0.43\n",
      "Training: Epoch 32, Batch 65, Loss: 0.393\n",
      "Training: Epoch 32, Batch 66, Loss: 0.433\n",
      "Training: Epoch 32, Batch 67, Loss: 0.643\n",
      "Training: Epoch 32, Batch 68, Loss: 0.427\n",
      "Training: Epoch 32, Batch 69, Loss: 0.646\n",
      "Training: Epoch 32, Batch 70, Loss: 0.479\n",
      "Training: Epoch 32, Batch 71, Loss: 0.498\n",
      "Training: Epoch 32, Batch 72, Loss: 0.454\n",
      "Training: Epoch 32, Batch 73, Loss: 0.417\n",
      "Training: Epoch 32, Batch 74, Loss: 0.356\n",
      "Training: Epoch 32, Batch 75, Loss: 0.614\n",
      "Training: Epoch 32, Batch 76, Loss: 0.436\n",
      "Training: Epoch 32, Batch 77, Loss: 0.573\n",
      "Training: Epoch 32, Batch 78, Loss: 0.447\n",
      "Training: Epoch 32, Batch 79, Loss: 0.468\n",
      "Training: Epoch 32, Batch 80, Loss: 0.432\n",
      "Training: Epoch 32, Batch 81, Loss: 0.398\n",
      "Training: Epoch 32, Batch 82, Loss: 0.395\n",
      "Training: Epoch 32, Batch 83, Loss: 0.45\n",
      "Training: Epoch 32, Batch 84, Loss: 0.446\n",
      "Training: Epoch 32, Batch 85, Loss: 0.333\n",
      "Training: Epoch 32, Batch 86, Loss: 0.323\n",
      "Training: Epoch 32, Batch 87, Loss: 0.389\n",
      "Training: Epoch 32, Batch 88, Loss: 0.564\n",
      "Training: Epoch 32, Batch 89, Loss: 0.496\n",
      "Val: Epoch 32, Loss: 0.28\n",
      "Training: Epoch 33, Batch 0, Loss: 0.458\n",
      "Training: Epoch 33, Batch 1, Loss: 0.348\n",
      "Training: Epoch 33, Batch 2, Loss: 0.439\n",
      "Training: Epoch 33, Batch 3, Loss: 0.361\n",
      "Training: Epoch 33, Batch 4, Loss: 0.284\n",
      "Training: Epoch 33, Batch 5, Loss: 0.48\n",
      "Training: Epoch 33, Batch 6, Loss: 0.42\n",
      "Training: Epoch 33, Batch 7, Loss: 0.408\n",
      "Training: Epoch 33, Batch 8, Loss: 0.828\n",
      "Training: Epoch 33, Batch 9, Loss: 0.393\n",
      "Training: Epoch 33, Batch 10, Loss: 0.341\n",
      "Training: Epoch 33, Batch 11, Loss: 0.37\n",
      "Training: Epoch 33, Batch 12, Loss: 0.801\n",
      "Training: Epoch 33, Batch 13, Loss: 0.426\n",
      "Training: Epoch 33, Batch 14, Loss: 0.598\n",
      "Training: Epoch 33, Batch 15, Loss: 0.487\n",
      "Training: Epoch 33, Batch 16, Loss: 0.755\n",
      "Training: Epoch 33, Batch 17, Loss: 0.346\n",
      "Training: Epoch 33, Batch 18, Loss: 0.423\n",
      "Training: Epoch 33, Batch 19, Loss: 0.435\n",
      "Training: Epoch 33, Batch 20, Loss: 0.48\n",
      "Training: Epoch 33, Batch 21, Loss: 0.491\n",
      "Training: Epoch 33, Batch 22, Loss: 0.393\n",
      "Training: Epoch 33, Batch 23, Loss: 0.414\n",
      "Training: Epoch 33, Batch 24, Loss: 0.472\n",
      "Training: Epoch 33, Batch 25, Loss: 0.469\n",
      "Training: Epoch 33, Batch 26, Loss: 0.558\n",
      "Training: Epoch 33, Batch 27, Loss: 0.313\n",
      "Training: Epoch 33, Batch 28, Loss: 0.525\n",
      "Training: Epoch 33, Batch 29, Loss: 0.479\n",
      "Training: Epoch 33, Batch 30, Loss: 0.507\n",
      "Training: Epoch 33, Batch 31, Loss: 0.477\n",
      "Training: Epoch 33, Batch 32, Loss: 0.604\n",
      "Training: Epoch 33, Batch 33, Loss: 0.35\n",
      "Training: Epoch 33, Batch 34, Loss: 0.532\n",
      "Training: Epoch 33, Batch 35, Loss: 0.529\n",
      "Training: Epoch 33, Batch 36, Loss: 0.702\n",
      "Training: Epoch 33, Batch 37, Loss: 0.499\n",
      "Training: Epoch 33, Batch 38, Loss: 0.47\n",
      "Training: Epoch 33, Batch 39, Loss: 0.905\n",
      "Training: Epoch 33, Batch 40, Loss: 0.499\n",
      "Training: Epoch 33, Batch 41, Loss: 0.344\n",
      "Training: Epoch 33, Batch 42, Loss: 0.304\n",
      "Training: Epoch 33, Batch 43, Loss: 0.403\n",
      "Training: Epoch 33, Batch 44, Loss: 0.47\n",
      "Training: Epoch 33, Batch 45, Loss: 0.627\n",
      "Training: Epoch 33, Batch 46, Loss: 0.428\n",
      "Training: Epoch 33, Batch 47, Loss: 0.307\n",
      "Training: Epoch 33, Batch 48, Loss: 0.539\n",
      "Training: Epoch 33, Batch 49, Loss: 0.465\n",
      "Training: Epoch 33, Batch 50, Loss: 0.41\n",
      "Training: Epoch 33, Batch 51, Loss: 0.454\n",
      "Training: Epoch 33, Batch 52, Loss: 0.259\n",
      "Training: Epoch 33, Batch 53, Loss: 0.497\n",
      "Training: Epoch 33, Batch 54, Loss: 0.49\n",
      "Training: Epoch 33, Batch 55, Loss: 0.439\n",
      "Training: Epoch 33, Batch 56, Loss: 0.598\n",
      "Training: Epoch 33, Batch 57, Loss: 0.456\n",
      "Training: Epoch 33, Batch 58, Loss: 0.927\n",
      "Training: Epoch 33, Batch 59, Loss: 0.78\n",
      "Training: Epoch 33, Batch 60, Loss: 0.673\n",
      "Training: Epoch 33, Batch 61, Loss: 0.592\n",
      "Training: Epoch 33, Batch 62, Loss: 0.366\n",
      "Training: Epoch 33, Batch 63, Loss: 0.329\n",
      "Training: Epoch 33, Batch 64, Loss: 0.506\n",
      "Training: Epoch 33, Batch 65, Loss: 0.311\n",
      "Training: Epoch 33, Batch 66, Loss: 0.453\n",
      "Training: Epoch 33, Batch 67, Loss: 0.448\n",
      "Training: Epoch 33, Batch 68, Loss: 0.522\n",
      "Training: Epoch 33, Batch 69, Loss: 0.57\n",
      "Training: Epoch 33, Batch 70, Loss: 0.258\n",
      "Training: Epoch 33, Batch 71, Loss: 0.293\n",
      "Training: Epoch 33, Batch 72, Loss: 0.353\n",
      "Training: Epoch 33, Batch 73, Loss: 0.463\n",
      "Training: Epoch 33, Batch 74, Loss: 0.296\n",
      "Training: Epoch 33, Batch 75, Loss: 0.501\n",
      "Training: Epoch 33, Batch 76, Loss: 0.565\n",
      "Training: Epoch 33, Batch 77, Loss: 0.461\n",
      "Training: Epoch 33, Batch 78, Loss: 0.436\n",
      "Training: Epoch 33, Batch 79, Loss: 0.449\n",
      "Training: Epoch 33, Batch 80, Loss: 0.553\n",
      "Training: Epoch 33, Batch 81, Loss: 0.373\n",
      "Training: Epoch 33, Batch 82, Loss: 0.319\n",
      "Training: Epoch 33, Batch 83, Loss: 0.489\n",
      "Training: Epoch 33, Batch 84, Loss: 0.467\n",
      "Training: Epoch 33, Batch 85, Loss: 0.748\n",
      "Training: Epoch 33, Batch 86, Loss: 0.56\n",
      "Training: Epoch 33, Batch 87, Loss: 0.562\n",
      "Training: Epoch 33, Batch 88, Loss: 0.224\n",
      "Training: Epoch 33, Batch 89, Loss: 0.378\n",
      "Val: Epoch 33, Loss: 0.522\n",
      "Training: Epoch 34, Batch 0, Loss: 0.636\n",
      "Training: Epoch 34, Batch 1, Loss: 0.312\n",
      "Training: Epoch 34, Batch 2, Loss: 0.633\n",
      "Training: Epoch 34, Batch 3, Loss: 0.473\n",
      "Training: Epoch 34, Batch 4, Loss: 0.387\n",
      "Training: Epoch 34, Batch 5, Loss: 0.397\n",
      "Training: Epoch 34, Batch 6, Loss: 0.485\n",
      "Training: Epoch 34, Batch 7, Loss: 0.736\n",
      "Training: Epoch 34, Batch 8, Loss: 0.54\n",
      "Training: Epoch 34, Batch 9, Loss: 0.334\n",
      "Training: Epoch 34, Batch 10, Loss: 0.46\n",
      "Training: Epoch 34, Batch 11, Loss: 0.456\n",
      "Training: Epoch 34, Batch 12, Loss: 0.391\n",
      "Training: Epoch 34, Batch 13, Loss: 0.265\n",
      "Training: Epoch 34, Batch 14, Loss: 0.518\n",
      "Training: Epoch 34, Batch 15, Loss: 0.305\n",
      "Training: Epoch 34, Batch 16, Loss: 0.507\n",
      "Training: Epoch 34, Batch 17, Loss: 0.616\n",
      "Training: Epoch 34, Batch 18, Loss: 0.418\n",
      "Training: Epoch 34, Batch 19, Loss: 0.273\n",
      "Training: Epoch 34, Batch 20, Loss: 0.489\n",
      "Training: Epoch 34, Batch 21, Loss: 0.366\n",
      "Training: Epoch 34, Batch 22, Loss: 0.432\n",
      "Training: Epoch 34, Batch 23, Loss: 0.839\n",
      "Training: Epoch 34, Batch 24, Loss: 0.494\n",
      "Training: Epoch 34, Batch 25, Loss: 0.406\n",
      "Training: Epoch 34, Batch 26, Loss: 0.346\n",
      "Training: Epoch 34, Batch 27, Loss: 0.374\n",
      "Training: Epoch 34, Batch 28, Loss: 0.366\n",
      "Training: Epoch 34, Batch 29, Loss: 0.328\n",
      "Training: Epoch 34, Batch 30, Loss: 0.465\n",
      "Training: Epoch 34, Batch 31, Loss: 0.599\n",
      "Training: Epoch 34, Batch 32, Loss: 0.466\n",
      "Training: Epoch 34, Batch 33, Loss: 0.648\n",
      "Training: Epoch 34, Batch 34, Loss: 0.325\n",
      "Training: Epoch 34, Batch 35, Loss: 0.492\n",
      "Training: Epoch 34, Batch 36, Loss: 0.619\n",
      "Training: Epoch 34, Batch 37, Loss: 0.64\n",
      "Training: Epoch 34, Batch 38, Loss: 0.376\n",
      "Training: Epoch 34, Batch 39, Loss: 0.62\n",
      "Training: Epoch 34, Batch 40, Loss: 0.263\n",
      "Training: Epoch 34, Batch 41, Loss: 0.434\n",
      "Training: Epoch 34, Batch 42, Loss: 0.362\n",
      "Training: Epoch 34, Batch 43, Loss: 0.443\n",
      "Training: Epoch 34, Batch 44, Loss: 0.488\n",
      "Training: Epoch 34, Batch 45, Loss: 0.518\n",
      "Training: Epoch 34, Batch 46, Loss: 0.488\n",
      "Training: Epoch 34, Batch 47, Loss: 0.483\n",
      "Training: Epoch 34, Batch 48, Loss: 0.689\n",
      "Training: Epoch 34, Batch 49, Loss: 0.446\n",
      "Training: Epoch 34, Batch 50, Loss: 0.516\n",
      "Training: Epoch 34, Batch 51, Loss: 0.461\n",
      "Training: Epoch 34, Batch 52, Loss: 0.603\n",
      "Training: Epoch 34, Batch 53, Loss: 0.418\n",
      "Training: Epoch 34, Batch 54, Loss: 0.642\n",
      "Training: Epoch 34, Batch 55, Loss: 0.493\n",
      "Training: Epoch 34, Batch 56, Loss: 0.395\n",
      "Training: Epoch 34, Batch 57, Loss: 0.508\n",
      "Training: Epoch 34, Batch 58, Loss: 0.456\n",
      "Training: Epoch 34, Batch 59, Loss: 0.397\n",
      "Training: Epoch 34, Batch 60, Loss: 0.462\n",
      "Training: Epoch 34, Batch 61, Loss: 0.396\n",
      "Training: Epoch 34, Batch 62, Loss: 0.426\n",
      "Training: Epoch 34, Batch 63, Loss: 0.201\n",
      "Training: Epoch 34, Batch 64, Loss: 0.465\n",
      "Training: Epoch 34, Batch 65, Loss: 0.335\n",
      "Training: Epoch 34, Batch 66, Loss: 0.51\n",
      "Training: Epoch 34, Batch 67, Loss: 0.523\n",
      "Training: Epoch 34, Batch 68, Loss: 0.438\n",
      "Training: Epoch 34, Batch 69, Loss: 0.367\n",
      "Training: Epoch 34, Batch 70, Loss: 0.587\n",
      "Training: Epoch 34, Batch 71, Loss: 0.601\n",
      "Training: Epoch 34, Batch 72, Loss: 0.197\n",
      "Training: Epoch 34, Batch 73, Loss: 0.39\n",
      "Training: Epoch 34, Batch 74, Loss: 0.594\n",
      "Training: Epoch 34, Batch 75, Loss: 0.577\n",
      "Training: Epoch 34, Batch 76, Loss: 0.35\n",
      "Training: Epoch 34, Batch 77, Loss: 0.549\n",
      "Training: Epoch 34, Batch 78, Loss: 0.239\n",
      "Training: Epoch 34, Batch 79, Loss: 0.342\n",
      "Training: Epoch 34, Batch 80, Loss: 0.509\n",
      "Training: Epoch 34, Batch 81, Loss: 0.394\n",
      "Training: Epoch 34, Batch 82, Loss: 0.542\n",
      "Training: Epoch 34, Batch 83, Loss: 0.592\n",
      "Training: Epoch 34, Batch 84, Loss: 0.531\n",
      "Training: Epoch 34, Batch 85, Loss: 0.431\n",
      "Training: Epoch 34, Batch 86, Loss: 0.428\n",
      "Training: Epoch 34, Batch 87, Loss: 0.556\n",
      "Training: Epoch 34, Batch 88, Loss: 0.335\n",
      "Training: Epoch 34, Batch 89, Loss: 0.51\n",
      "Val: Epoch 34, Loss: 0.242\n",
      "Training: Epoch 35, Batch 0, Loss: 0.438\n",
      "Training: Epoch 35, Batch 1, Loss: 0.211\n",
      "Training: Epoch 35, Batch 2, Loss: 0.51\n",
      "Training: Epoch 35, Batch 3, Loss: 0.436\n",
      "Training: Epoch 35, Batch 4, Loss: 0.454\n",
      "Training: Epoch 35, Batch 5, Loss: 0.48\n",
      "Training: Epoch 35, Batch 6, Loss: 0.352\n",
      "Training: Epoch 35, Batch 7, Loss: 0.403\n",
      "Training: Epoch 35, Batch 8, Loss: 0.73\n",
      "Training: Epoch 35, Batch 9, Loss: 0.77\n",
      "Training: Epoch 35, Batch 10, Loss: 0.391\n",
      "Training: Epoch 35, Batch 11, Loss: 0.373\n",
      "Training: Epoch 35, Batch 12, Loss: 0.423\n",
      "Training: Epoch 35, Batch 13, Loss: 0.464\n",
      "Training: Epoch 35, Batch 14, Loss: 0.257\n",
      "Training: Epoch 35, Batch 15, Loss: 0.266\n",
      "Training: Epoch 35, Batch 16, Loss: 0.4\n",
      "Training: Epoch 35, Batch 17, Loss: 0.355\n",
      "Training: Epoch 35, Batch 18, Loss: 0.38\n",
      "Training: Epoch 35, Batch 19, Loss: 0.537\n",
      "Training: Epoch 35, Batch 20, Loss: 0.415\n",
      "Training: Epoch 35, Batch 21, Loss: 0.465\n",
      "Training: Epoch 35, Batch 22, Loss: 0.591\n",
      "Training: Epoch 35, Batch 23, Loss: 0.412\n",
      "Training: Epoch 35, Batch 24, Loss: 0.514\n",
      "Training: Epoch 35, Batch 25, Loss: 0.334\n",
      "Training: Epoch 35, Batch 26, Loss: 0.244\n",
      "Training: Epoch 35, Batch 27, Loss: 0.396\n",
      "Training: Epoch 35, Batch 28, Loss: 0.601\n",
      "Training: Epoch 35, Batch 29, Loss: 0.531\n",
      "Training: Epoch 35, Batch 30, Loss: 0.509\n",
      "Training: Epoch 35, Batch 31, Loss: 0.948\n",
      "Training: Epoch 35, Batch 32, Loss: 1.024\n",
      "Training: Epoch 35, Batch 33, Loss: 0.475\n",
      "Training: Epoch 35, Batch 34, Loss: 0.617\n",
      "Training: Epoch 35, Batch 35, Loss: 0.535\n",
      "Training: Epoch 35, Batch 36, Loss: 0.633\n",
      "Training: Epoch 35, Batch 37, Loss: 0.806\n",
      "Training: Epoch 35, Batch 38, Loss: 0.627\n",
      "Training: Epoch 35, Batch 39, Loss: 0.401\n",
      "Training: Epoch 35, Batch 40, Loss: 0.473\n",
      "Training: Epoch 35, Batch 41, Loss: 0.618\n",
      "Training: Epoch 35, Batch 42, Loss: 0.5\n",
      "Training: Epoch 35, Batch 43, Loss: 0.443\n",
      "Training: Epoch 35, Batch 44, Loss: 0.646\n",
      "Training: Epoch 35, Batch 45, Loss: 0.583\n",
      "Training: Epoch 35, Batch 46, Loss: 0.383\n",
      "Training: Epoch 35, Batch 47, Loss: 0.596\n",
      "Training: Epoch 35, Batch 48, Loss: 0.378\n",
      "Training: Epoch 35, Batch 49, Loss: 0.616\n",
      "Training: Epoch 35, Batch 50, Loss: 0.594\n",
      "Training: Epoch 35, Batch 51, Loss: 0.274\n",
      "Training: Epoch 35, Batch 52, Loss: 0.436\n",
      "Training: Epoch 35, Batch 53, Loss: 0.583\n",
      "Training: Epoch 35, Batch 54, Loss: 0.383\n",
      "Training: Epoch 35, Batch 55, Loss: 0.525\n",
      "Training: Epoch 35, Batch 56, Loss: 0.534\n",
      "Training: Epoch 35, Batch 57, Loss: 0.538\n",
      "Training: Epoch 35, Batch 58, Loss: 0.514\n",
      "Training: Epoch 35, Batch 59, Loss: 0.325\n",
      "Training: Epoch 35, Batch 60, Loss: 0.573\n",
      "Training: Epoch 35, Batch 61, Loss: 0.631\n",
      "Training: Epoch 35, Batch 62, Loss: 0.575\n",
      "Training: Epoch 35, Batch 63, Loss: 0.402\n",
      "Training: Epoch 35, Batch 64, Loss: 0.384\n",
      "Training: Epoch 35, Batch 65, Loss: 0.671\n",
      "Training: Epoch 35, Batch 66, Loss: 0.433\n",
      "Training: Epoch 35, Batch 67, Loss: 0.422\n",
      "Training: Epoch 35, Batch 68, Loss: 0.375\n",
      "Training: Epoch 35, Batch 69, Loss: 0.282\n",
      "Training: Epoch 35, Batch 70, Loss: 0.537\n",
      "Training: Epoch 35, Batch 71, Loss: 0.354\n",
      "Training: Epoch 35, Batch 72, Loss: 0.5\n",
      "Training: Epoch 35, Batch 73, Loss: 0.332\n",
      "Training: Epoch 35, Batch 74, Loss: 0.437\n",
      "Training: Epoch 35, Batch 75, Loss: 0.364\n",
      "Training: Epoch 35, Batch 76, Loss: 0.718\n",
      "Training: Epoch 35, Batch 77, Loss: 0.646\n",
      "Training: Epoch 35, Batch 78, Loss: 0.52\n",
      "Training: Epoch 35, Batch 79, Loss: 0.35\n",
      "Training: Epoch 35, Batch 80, Loss: 0.336\n",
      "Training: Epoch 35, Batch 81, Loss: 0.383\n",
      "Training: Epoch 35, Batch 82, Loss: 0.455\n",
      "Training: Epoch 35, Batch 83, Loss: 0.27\n",
      "Training: Epoch 35, Batch 84, Loss: 0.347\n",
      "Training: Epoch 35, Batch 85, Loss: 0.519\n",
      "Training: Epoch 35, Batch 86, Loss: 0.37\n",
      "Training: Epoch 35, Batch 87, Loss: 0.533\n",
      "Training: Epoch 35, Batch 88, Loss: 0.352\n",
      "Training: Epoch 35, Batch 89, Loss: 0.459\n",
      "Val: Epoch 35, Loss: 0.27\n",
      "Training: Epoch 36, Batch 0, Loss: 0.55\n",
      "Training: Epoch 36, Batch 1, Loss: 0.354\n",
      "Training: Epoch 36, Batch 2, Loss: 0.253\n",
      "Training: Epoch 36, Batch 3, Loss: 0.488\n",
      "Training: Epoch 36, Batch 4, Loss: 0.723\n",
      "Training: Epoch 36, Batch 5, Loss: 0.324\n",
      "Training: Epoch 36, Batch 6, Loss: 0.463\n",
      "Training: Epoch 36, Batch 7, Loss: 0.376\n",
      "Training: Epoch 36, Batch 8, Loss: 0.321\n",
      "Training: Epoch 36, Batch 9, Loss: 0.59\n",
      "Training: Epoch 36, Batch 10, Loss: 0.506\n",
      "Training: Epoch 36, Batch 11, Loss: 0.17\n",
      "Training: Epoch 36, Batch 12, Loss: 0.576\n",
      "Training: Epoch 36, Batch 13, Loss: 0.37\n",
      "Training: Epoch 36, Batch 14, Loss: 0.46\n",
      "Training: Epoch 36, Batch 15, Loss: 0.316\n",
      "Training: Epoch 36, Batch 16, Loss: 0.283\n",
      "Training: Epoch 36, Batch 17, Loss: 0.41\n",
      "Training: Epoch 36, Batch 18, Loss: 0.332\n",
      "Training: Epoch 36, Batch 19, Loss: 0.294\n",
      "Training: Epoch 36, Batch 20, Loss: 0.429\n",
      "Training: Epoch 36, Batch 21, Loss: 0.514\n",
      "Training: Epoch 36, Batch 22, Loss: 0.485\n",
      "Training: Epoch 36, Batch 23, Loss: 0.355\n",
      "Training: Epoch 36, Batch 24, Loss: 0.579\n",
      "Training: Epoch 36, Batch 25, Loss: 0.474\n",
      "Training: Epoch 36, Batch 26, Loss: 0.54\n",
      "Training: Epoch 36, Batch 27, Loss: 0.353\n",
      "Training: Epoch 36, Batch 28, Loss: 0.376\n",
      "Training: Epoch 36, Batch 29, Loss: 0.495\n",
      "Training: Epoch 36, Batch 30, Loss: 0.364\n",
      "Training: Epoch 36, Batch 31, Loss: 0.541\n",
      "Training: Epoch 36, Batch 32, Loss: 0.317\n",
      "Training: Epoch 36, Batch 33, Loss: 0.645\n",
      "Training: Epoch 36, Batch 34, Loss: 0.457\n",
      "Training: Epoch 36, Batch 35, Loss: 1.074\n",
      "Training: Epoch 36, Batch 36, Loss: 0.415\n",
      "Training: Epoch 36, Batch 37, Loss: 0.369\n",
      "Training: Epoch 36, Batch 38, Loss: 0.465\n",
      "Training: Epoch 36, Batch 39, Loss: 0.621\n",
      "Training: Epoch 36, Batch 40, Loss: 0.318\n",
      "Training: Epoch 36, Batch 41, Loss: 0.38\n",
      "Training: Epoch 36, Batch 42, Loss: 0.514\n",
      "Training: Epoch 36, Batch 43, Loss: 0.57\n",
      "Training: Epoch 36, Batch 44, Loss: 0.525\n",
      "Training: Epoch 36, Batch 45, Loss: 0.544\n",
      "Training: Epoch 36, Batch 46, Loss: 0.486\n",
      "Training: Epoch 36, Batch 47, Loss: 0.449\n",
      "Training: Epoch 36, Batch 48, Loss: 0.457\n",
      "Training: Epoch 36, Batch 49, Loss: 0.613\n",
      "Training: Epoch 36, Batch 50, Loss: 0.477\n",
      "Training: Epoch 36, Batch 51, Loss: 0.553\n",
      "Training: Epoch 36, Batch 52, Loss: 0.661\n",
      "Training: Epoch 36, Batch 53, Loss: 0.463\n",
      "Training: Epoch 36, Batch 54, Loss: 0.29\n",
      "Training: Epoch 36, Batch 55, Loss: 0.493\n",
      "Training: Epoch 36, Batch 56, Loss: 0.399\n",
      "Training: Epoch 36, Batch 57, Loss: 0.621\n",
      "Training: Epoch 36, Batch 58, Loss: 0.364\n",
      "Training: Epoch 36, Batch 59, Loss: 0.479\n",
      "Training: Epoch 36, Batch 60, Loss: 0.305\n",
      "Training: Epoch 36, Batch 61, Loss: 0.389\n",
      "Training: Epoch 36, Batch 62, Loss: 0.467\n",
      "Training: Epoch 36, Batch 63, Loss: 0.519\n",
      "Training: Epoch 36, Batch 64, Loss: 0.358\n",
      "Training: Epoch 36, Batch 65, Loss: 0.699\n",
      "Training: Epoch 36, Batch 66, Loss: 0.437\n",
      "Training: Epoch 36, Batch 67, Loss: 0.44\n",
      "Training: Epoch 36, Batch 68, Loss: 0.417\n",
      "Training: Epoch 36, Batch 69, Loss: 0.421\n",
      "Training: Epoch 36, Batch 70, Loss: 0.352\n",
      "Training: Epoch 36, Batch 71, Loss: 0.325\n",
      "Training: Epoch 36, Batch 72, Loss: 0.626\n",
      "Training: Epoch 36, Batch 73, Loss: 0.493\n",
      "Training: Epoch 36, Batch 74, Loss: 0.564\n",
      "Training: Epoch 36, Batch 75, Loss: 0.25\n",
      "Training: Epoch 36, Batch 76, Loss: 0.533\n",
      "Training: Epoch 36, Batch 77, Loss: 0.455\n",
      "Training: Epoch 36, Batch 78, Loss: 0.505\n",
      "Training: Epoch 36, Batch 79, Loss: 0.436\n",
      "Training: Epoch 36, Batch 80, Loss: 0.368\n",
      "Training: Epoch 36, Batch 81, Loss: 0.654\n",
      "Training: Epoch 36, Batch 82, Loss: 0.541\n",
      "Training: Epoch 36, Batch 83, Loss: 0.498\n",
      "Training: Epoch 36, Batch 84, Loss: 0.546\n",
      "Training: Epoch 36, Batch 85, Loss: 0.419\n",
      "Training: Epoch 36, Batch 86, Loss: 0.667\n",
      "Training: Epoch 36, Batch 87, Loss: 0.687\n",
      "Training: Epoch 36, Batch 88, Loss: 0.516\n",
      "Training: Epoch 36, Batch 89, Loss: 0.506\n",
      "Val: Epoch 36, Loss: 0.25\n",
      "Training: Epoch 37, Batch 0, Loss: 0.444\n",
      "Training: Epoch 37, Batch 1, Loss: 0.651\n",
      "Training: Epoch 37, Batch 2, Loss: 0.446\n",
      "Training: Epoch 37, Batch 3, Loss: 0.363\n",
      "Training: Epoch 37, Batch 4, Loss: 0.455\n",
      "Training: Epoch 37, Batch 5, Loss: 0.561\n",
      "Training: Epoch 37, Batch 6, Loss: 0.431\n",
      "Training: Epoch 37, Batch 7, Loss: 0.507\n",
      "Training: Epoch 37, Batch 8, Loss: 0.456\n",
      "Training: Epoch 37, Batch 9, Loss: 0.36\n",
      "Training: Epoch 37, Batch 10, Loss: 0.632\n",
      "Training: Epoch 37, Batch 11, Loss: 0.292\n",
      "Training: Epoch 37, Batch 12, Loss: 0.718\n",
      "Training: Epoch 37, Batch 13, Loss: 0.382\n",
      "Training: Epoch 37, Batch 14, Loss: 0.365\n",
      "Training: Epoch 37, Batch 15, Loss: 0.559\n",
      "Training: Epoch 37, Batch 16, Loss: 0.377\n",
      "Training: Epoch 37, Batch 17, Loss: 1.045\n",
      "Training: Epoch 37, Batch 18, Loss: 0.306\n",
      "Training: Epoch 37, Batch 19, Loss: 0.479\n",
      "Training: Epoch 37, Batch 20, Loss: 0.283\n",
      "Training: Epoch 37, Batch 21, Loss: 0.433\n",
      "Training: Epoch 37, Batch 22, Loss: 0.596\n",
      "Training: Epoch 37, Batch 23, Loss: 0.396\n",
      "Training: Epoch 37, Batch 24, Loss: 0.499\n",
      "Training: Epoch 37, Batch 25, Loss: 0.426\n",
      "Training: Epoch 37, Batch 26, Loss: 0.556\n",
      "Training: Epoch 37, Batch 27, Loss: 0.303\n",
      "Training: Epoch 37, Batch 28, Loss: 0.544\n",
      "Training: Epoch 37, Batch 29, Loss: 0.499\n",
      "Training: Epoch 37, Batch 30, Loss: 0.499\n",
      "Training: Epoch 37, Batch 31, Loss: 0.688\n",
      "Training: Epoch 37, Batch 32, Loss: 0.509\n",
      "Training: Epoch 37, Batch 33, Loss: 0.799\n",
      "Training: Epoch 37, Batch 34, Loss: 0.487\n",
      "Training: Epoch 37, Batch 35, Loss: 0.539\n",
      "Training: Epoch 37, Batch 36, Loss: 0.605\n",
      "Training: Epoch 37, Batch 37, Loss: 0.515\n",
      "Training: Epoch 37, Batch 38, Loss: 0.538\n",
      "Training: Epoch 37, Batch 39, Loss: 0.449\n",
      "Training: Epoch 37, Batch 40, Loss: 0.568\n",
      "Training: Epoch 37, Batch 41, Loss: 0.459\n",
      "Training: Epoch 37, Batch 42, Loss: 0.559\n",
      "Training: Epoch 37, Batch 43, Loss: 0.513\n",
      "Training: Epoch 37, Batch 44, Loss: 0.611\n",
      "Training: Epoch 37, Batch 45, Loss: 0.558\n",
      "Training: Epoch 37, Batch 46, Loss: 0.476\n",
      "Training: Epoch 37, Batch 47, Loss: 0.477\n",
      "Training: Epoch 37, Batch 48, Loss: 0.324\n",
      "Training: Epoch 37, Batch 49, Loss: 0.27\n",
      "Training: Epoch 37, Batch 50, Loss: 0.424\n",
      "Training: Epoch 37, Batch 51, Loss: 0.34\n",
      "Training: Epoch 37, Batch 52, Loss: 0.338\n",
      "Training: Epoch 37, Batch 53, Loss: 0.43\n",
      "Training: Epoch 37, Batch 54, Loss: 0.517\n",
      "Training: Epoch 37, Batch 55, Loss: 0.575\n",
      "Training: Epoch 37, Batch 56, Loss: 0.375\n",
      "Training: Epoch 37, Batch 57, Loss: 0.477\n",
      "Training: Epoch 37, Batch 58, Loss: 0.341\n",
      "Training: Epoch 37, Batch 59, Loss: 0.534\n",
      "Training: Epoch 37, Batch 60, Loss: 0.321\n",
      "Training: Epoch 37, Batch 61, Loss: 0.35\n",
      "Training: Epoch 37, Batch 62, Loss: 0.454\n",
      "Training: Epoch 37, Batch 63, Loss: 0.462\n",
      "Training: Epoch 37, Batch 64, Loss: 0.448\n",
      "Training: Epoch 37, Batch 65, Loss: 1.599\n",
      "Training: Epoch 37, Batch 66, Loss: 0.571\n",
      "Training: Epoch 37, Batch 67, Loss: 0.505\n",
      "Training: Epoch 37, Batch 68, Loss: 0.68\n",
      "Training: Epoch 37, Batch 69, Loss: 0.588\n",
      "Training: Epoch 37, Batch 70, Loss: 0.521\n",
      "Training: Epoch 37, Batch 71, Loss: 0.605\n",
      "Training: Epoch 37, Batch 72, Loss: 0.467\n",
      "Training: Epoch 37, Batch 73, Loss: 0.462\n",
      "Training: Epoch 37, Batch 74, Loss: 0.545\n",
      "Training: Epoch 37, Batch 75, Loss: 0.664\n",
      "Training: Epoch 37, Batch 76, Loss: 0.501\n",
      "Training: Epoch 37, Batch 77, Loss: 0.513\n",
      "Training: Epoch 37, Batch 78, Loss: 0.47\n",
      "Training: Epoch 37, Batch 79, Loss: 0.759\n",
      "Training: Epoch 37, Batch 80, Loss: 0.361\n",
      "Training: Epoch 37, Batch 81, Loss: 0.432\n",
      "Training: Epoch 37, Batch 82, Loss: 0.406\n",
      "Training: Epoch 37, Batch 83, Loss: 0.383\n",
      "Training: Epoch 37, Batch 84, Loss: 0.695\n",
      "Training: Epoch 37, Batch 85, Loss: 0.556\n",
      "Training: Epoch 37, Batch 86, Loss: 0.556\n",
      "Training: Epoch 37, Batch 87, Loss: 0.34\n",
      "Training: Epoch 37, Batch 88, Loss: 0.387\n",
      "Training: Epoch 37, Batch 89, Loss: 0.611\n",
      "Val: Epoch 37, Loss: 0.349\n",
      "Training: Epoch 38, Batch 0, Loss: 0.42\n",
      "Training: Epoch 38, Batch 1, Loss: 0.563\n",
      "Training: Epoch 38, Batch 2, Loss: 0.48\n",
      "Training: Epoch 38, Batch 3, Loss: 0.511\n",
      "Training: Epoch 38, Batch 4, Loss: 0.442\n",
      "Training: Epoch 38, Batch 5, Loss: 0.499\n",
      "Training: Epoch 38, Batch 6, Loss: 0.45\n",
      "Training: Epoch 38, Batch 7, Loss: 1.238\n",
      "Training: Epoch 38, Batch 8, Loss: 0.75\n",
      "Training: Epoch 38, Batch 9, Loss: 0.442\n",
      "Training: Epoch 38, Batch 10, Loss: 0.766\n",
      "Training: Epoch 38, Batch 11, Loss: 0.53\n",
      "Training: Epoch 38, Batch 12, Loss: 0.474\n",
      "Training: Epoch 38, Batch 13, Loss: 0.518\n",
      "Training: Epoch 38, Batch 14, Loss: 0.493\n",
      "Training: Epoch 38, Batch 15, Loss: 0.472\n",
      "Training: Epoch 38, Batch 16, Loss: 0.772\n",
      "Training: Epoch 38, Batch 17, Loss: 0.442\n",
      "Training: Epoch 38, Batch 18, Loss: 0.463\n",
      "Training: Epoch 38, Batch 19, Loss: 0.638\n",
      "Training: Epoch 38, Batch 20, Loss: 0.492\n",
      "Training: Epoch 38, Batch 21, Loss: 0.622\n",
      "Training: Epoch 38, Batch 22, Loss: 0.839\n",
      "Training: Epoch 38, Batch 23, Loss: 0.519\n",
      "Training: Epoch 38, Batch 24, Loss: 0.378\n",
      "Training: Epoch 38, Batch 25, Loss: 0.601\n",
      "Training: Epoch 38, Batch 26, Loss: 0.564\n",
      "Training: Epoch 38, Batch 27, Loss: 0.405\n",
      "Training: Epoch 38, Batch 28, Loss: 0.503\n",
      "Training: Epoch 38, Batch 29, Loss: 0.498\n",
      "Training: Epoch 38, Batch 30, Loss: 0.353\n",
      "Training: Epoch 38, Batch 31, Loss: 0.526\n",
      "Training: Epoch 38, Batch 32, Loss: 0.414\n",
      "Training: Epoch 38, Batch 33, Loss: 0.522\n",
      "Training: Epoch 38, Batch 34, Loss: 0.455\n",
      "Training: Epoch 38, Batch 35, Loss: 0.483\n",
      "Training: Epoch 38, Batch 36, Loss: 0.757\n",
      "Training: Epoch 38, Batch 37, Loss: 0.5\n",
      "Training: Epoch 38, Batch 38, Loss: 0.741\n",
      "Training: Epoch 38, Batch 39, Loss: 0.489\n",
      "Training: Epoch 38, Batch 40, Loss: 0.467\n",
      "Training: Epoch 38, Batch 41, Loss: 0.415\n",
      "Training: Epoch 38, Batch 42, Loss: 0.423\n",
      "Training: Epoch 38, Batch 43, Loss: 0.498\n",
      "Training: Epoch 38, Batch 44, Loss: 0.336\n",
      "Training: Epoch 38, Batch 45, Loss: 0.495\n",
      "Training: Epoch 38, Batch 46, Loss: 0.256\n",
      "Training: Epoch 38, Batch 47, Loss: 0.587\n",
      "Training: Epoch 38, Batch 48, Loss: 0.551\n",
      "Training: Epoch 38, Batch 49, Loss: 0.719\n",
      "Training: Epoch 38, Batch 50, Loss: 0.418\n",
      "Training: Epoch 38, Batch 51, Loss: 0.284\n",
      "Training: Epoch 38, Batch 52, Loss: 0.421\n",
      "Training: Epoch 38, Batch 53, Loss: 0.334\n",
      "Training: Epoch 38, Batch 54, Loss: 0.449\n",
      "Training: Epoch 38, Batch 55, Loss: 0.28\n",
      "Training: Epoch 38, Batch 56, Loss: 0.452\n",
      "Training: Epoch 38, Batch 57, Loss: 0.652\n",
      "Training: Epoch 38, Batch 58, Loss: 0.519\n",
      "Training: Epoch 38, Batch 59, Loss: 0.401\n",
      "Training: Epoch 38, Batch 60, Loss: 0.495\n",
      "Training: Epoch 38, Batch 61, Loss: 0.529\n",
      "Training: Epoch 38, Batch 62, Loss: 0.415\n",
      "Training: Epoch 38, Batch 63, Loss: 0.492\n",
      "Training: Epoch 38, Batch 64, Loss: 0.366\n",
      "Training: Epoch 38, Batch 65, Loss: 0.956\n",
      "Training: Epoch 38, Batch 66, Loss: 0.388\n",
      "Training: Epoch 38, Batch 67, Loss: 0.48\n",
      "Training: Epoch 38, Batch 68, Loss: 0.436\n",
      "Training: Epoch 38, Batch 69, Loss: 0.408\n",
      "Training: Epoch 38, Batch 70, Loss: 0.471\n",
      "Training: Epoch 38, Batch 71, Loss: 0.368\n",
      "Training: Epoch 38, Batch 72, Loss: 0.302\n",
      "Training: Epoch 38, Batch 73, Loss: 0.577\n",
      "Training: Epoch 38, Batch 74, Loss: 0.475\n",
      "Training: Epoch 38, Batch 75, Loss: 0.376\n",
      "Training: Epoch 38, Batch 76, Loss: 0.562\n",
      "Training: Epoch 38, Batch 77, Loss: 0.29\n",
      "Training: Epoch 38, Batch 78, Loss: 0.685\n",
      "Training: Epoch 38, Batch 79, Loss: 0.552\n",
      "Training: Epoch 38, Batch 80, Loss: 0.603\n",
      "Training: Epoch 38, Batch 81, Loss: 0.376\n",
      "Training: Epoch 38, Batch 82, Loss: 0.727\n",
      "Training: Epoch 38, Batch 83, Loss: 0.458\n",
      "Training: Epoch 38, Batch 84, Loss: 0.46\n",
      "Training: Epoch 38, Batch 85, Loss: 0.508\n",
      "Training: Epoch 38, Batch 86, Loss: 0.358\n",
      "Training: Epoch 38, Batch 87, Loss: 0.442\n",
      "Training: Epoch 38, Batch 88, Loss: 0.45\n",
      "Training: Epoch 38, Batch 89, Loss: 0.532\n",
      "Val: Epoch 38, Loss: 0.251\n",
      "Training: Epoch 39, Batch 0, Loss: 0.232\n",
      "Training: Epoch 39, Batch 1, Loss: 0.384\n",
      "Training: Epoch 39, Batch 2, Loss: 0.538\n",
      "Training: Epoch 39, Batch 3, Loss: 0.425\n",
      "Training: Epoch 39, Batch 4, Loss: 0.351\n",
      "Training: Epoch 39, Batch 5, Loss: 0.404\n",
      "Training: Epoch 39, Batch 6, Loss: 0.571\n",
      "Training: Epoch 39, Batch 7, Loss: 0.355\n",
      "Training: Epoch 39, Batch 8, Loss: 0.536\n",
      "Training: Epoch 39, Batch 9, Loss: 0.699\n",
      "Training: Epoch 39, Batch 10, Loss: 0.4\n",
      "Training: Epoch 39, Batch 11, Loss: 0.446\n",
      "Training: Epoch 39, Batch 12, Loss: 0.504\n",
      "Training: Epoch 39, Batch 13, Loss: 0.391\n",
      "Training: Epoch 39, Batch 14, Loss: 0.287\n",
      "Training: Epoch 39, Batch 15, Loss: 0.381\n",
      "Training: Epoch 39, Batch 16, Loss: 0.721\n",
      "Training: Epoch 39, Batch 17, Loss: 0.674\n",
      "Training: Epoch 39, Batch 18, Loss: 0.357\n",
      "Training: Epoch 39, Batch 19, Loss: 0.452\n",
      "Training: Epoch 39, Batch 20, Loss: 0.304\n",
      "Training: Epoch 39, Batch 21, Loss: 0.404\n",
      "Training: Epoch 39, Batch 22, Loss: 0.521\n",
      "Training: Epoch 39, Batch 23, Loss: 0.587\n",
      "Training: Epoch 39, Batch 24, Loss: 0.622\n",
      "Training: Epoch 39, Batch 25, Loss: 0.342\n",
      "Training: Epoch 39, Batch 26, Loss: 0.314\n",
      "Training: Epoch 39, Batch 27, Loss: 0.481\n",
      "Training: Epoch 39, Batch 28, Loss: 0.589\n",
      "Training: Epoch 39, Batch 29, Loss: 0.393\n",
      "Training: Epoch 39, Batch 30, Loss: 0.642\n",
      "Training: Epoch 39, Batch 31, Loss: 0.276\n",
      "Training: Epoch 39, Batch 32, Loss: 0.529\n",
      "Training: Epoch 39, Batch 33, Loss: 0.312\n",
      "Training: Epoch 39, Batch 34, Loss: 0.504\n",
      "Training: Epoch 39, Batch 35, Loss: 0.318\n",
      "Training: Epoch 39, Batch 36, Loss: 0.344\n",
      "Training: Epoch 39, Batch 37, Loss: 0.483\n",
      "Training: Epoch 39, Batch 38, Loss: 0.336\n",
      "Training: Epoch 39, Batch 39, Loss: 0.443\n",
      "Training: Epoch 39, Batch 40, Loss: 0.494\n",
      "Training: Epoch 39, Batch 41, Loss: 0.497\n",
      "Training: Epoch 39, Batch 42, Loss: 0.421\n",
      "Training: Epoch 39, Batch 43, Loss: 0.495\n",
      "Training: Epoch 39, Batch 44, Loss: 0.297\n",
      "Training: Epoch 39, Batch 45, Loss: 0.223\n",
      "Training: Epoch 39, Batch 46, Loss: 0.401\n",
      "Training: Epoch 39, Batch 47, Loss: 0.351\n",
      "Training: Epoch 39, Batch 48, Loss: 0.537\n",
      "Training: Epoch 39, Batch 49, Loss: 0.541\n",
      "Training: Epoch 39, Batch 50, Loss: 0.49\n",
      "Training: Epoch 39, Batch 51, Loss: 0.276\n",
      "Training: Epoch 39, Batch 52, Loss: 0.547\n",
      "Training: Epoch 39, Batch 53, Loss: 0.74\n",
      "Training: Epoch 39, Batch 54, Loss: 0.519\n",
      "Training: Epoch 39, Batch 55, Loss: 0.322\n",
      "Training: Epoch 39, Batch 56, Loss: 0.773\n",
      "Training: Epoch 39, Batch 57, Loss: 0.796\n",
      "Training: Epoch 39, Batch 58, Loss: 0.465\n",
      "Training: Epoch 39, Batch 59, Loss: 0.56\n",
      "Training: Epoch 39, Batch 60, Loss: 0.363\n",
      "Training: Epoch 39, Batch 61, Loss: 0.363\n",
      "Training: Epoch 39, Batch 62, Loss: 0.293\n",
      "Training: Epoch 39, Batch 63, Loss: 0.465\n",
      "Training: Epoch 39, Batch 64, Loss: 0.287\n",
      "Training: Epoch 39, Batch 65, Loss: 0.485\n",
      "Training: Epoch 39, Batch 66, Loss: 0.679\n",
      "Training: Epoch 39, Batch 67, Loss: 0.284\n",
      "Training: Epoch 39, Batch 68, Loss: 0.544\n",
      "Training: Epoch 39, Batch 69, Loss: 0.432\n",
      "Training: Epoch 39, Batch 70, Loss: 0.462\n",
      "Training: Epoch 39, Batch 71, Loss: 0.584\n",
      "Training: Epoch 39, Batch 72, Loss: 0.3\n",
      "Training: Epoch 39, Batch 73, Loss: 0.39\n",
      "Training: Epoch 39, Batch 74, Loss: 0.355\n",
      "Training: Epoch 39, Batch 75, Loss: 0.49\n",
      "Training: Epoch 39, Batch 76, Loss: 0.362\n",
      "Training: Epoch 39, Batch 77, Loss: 0.457\n",
      "Training: Epoch 39, Batch 78, Loss: 0.559\n",
      "Training: Epoch 39, Batch 79, Loss: 0.433\n",
      "Training: Epoch 39, Batch 80, Loss: 0.317\n",
      "Training: Epoch 39, Batch 81, Loss: 0.81\n",
      "Training: Epoch 39, Batch 82, Loss: 0.653\n",
      "Training: Epoch 39, Batch 83, Loss: 0.314\n",
      "Training: Epoch 39, Batch 84, Loss: 0.563\n",
      "Training: Epoch 39, Batch 85, Loss: 0.189\n",
      "Training: Epoch 39, Batch 86, Loss: 0.471\n",
      "Training: Epoch 39, Batch 87, Loss: 0.364\n",
      "Training: Epoch 39, Batch 88, Loss: 0.414\n",
      "Training: Epoch 39, Batch 89, Loss: 0.387\n",
      "Val: Epoch 39, Loss: 0.253\n",
      "Training: Epoch 40, Batch 0, Loss: 0.362\n",
      "Training: Epoch 40, Batch 1, Loss: 0.586\n",
      "Training: Epoch 40, Batch 2, Loss: 0.833\n",
      "Training: Epoch 40, Batch 3, Loss: 0.461\n",
      "Training: Epoch 40, Batch 4, Loss: 0.265\n",
      "Training: Epoch 40, Batch 5, Loss: 0.573\n",
      "Training: Epoch 40, Batch 6, Loss: 0.332\n",
      "Training: Epoch 40, Batch 7, Loss: 0.492\n",
      "Training: Epoch 40, Batch 8, Loss: 0.618\n",
      "Training: Epoch 40, Batch 9, Loss: 0.493\n",
      "Training: Epoch 40, Batch 10, Loss: 0.471\n",
      "Training: Epoch 40, Batch 11, Loss: 0.33\n",
      "Training: Epoch 40, Batch 12, Loss: 0.655\n",
      "Training: Epoch 40, Batch 13, Loss: 0.368\n",
      "Training: Epoch 40, Batch 14, Loss: 0.303\n",
      "Training: Epoch 40, Batch 15, Loss: 0.369\n",
      "Training: Epoch 40, Batch 16, Loss: 0.477\n",
      "Training: Epoch 40, Batch 17, Loss: 0.619\n",
      "Training: Epoch 40, Batch 18, Loss: 0.433\n",
      "Training: Epoch 40, Batch 19, Loss: 0.354\n",
      "Training: Epoch 40, Batch 20, Loss: 0.562\n",
      "Training: Epoch 40, Batch 21, Loss: 0.482\n",
      "Training: Epoch 40, Batch 22, Loss: 0.299\n",
      "Training: Epoch 40, Batch 23, Loss: 0.445\n",
      "Training: Epoch 40, Batch 24, Loss: 0.385\n",
      "Training: Epoch 40, Batch 25, Loss: 0.268\n",
      "Training: Epoch 40, Batch 26, Loss: 0.197\n",
      "Training: Epoch 40, Batch 27, Loss: 0.285\n",
      "Training: Epoch 40, Batch 28, Loss: 0.443\n",
      "Training: Epoch 40, Batch 29, Loss: 0.283\n",
      "Training: Epoch 40, Batch 30, Loss: 0.258\n",
      "Training: Epoch 40, Batch 31, Loss: 0.386\n",
      "Training: Epoch 40, Batch 32, Loss: 0.361\n",
      "Training: Epoch 40, Batch 33, Loss: 0.812\n",
      "Training: Epoch 40, Batch 34, Loss: 0.462\n",
      "Training: Epoch 40, Batch 35, Loss: 0.526\n",
      "Training: Epoch 40, Batch 36, Loss: 0.426\n",
      "Training: Epoch 40, Batch 37, Loss: 0.29\n",
      "Training: Epoch 40, Batch 38, Loss: 0.706\n",
      "Training: Epoch 40, Batch 39, Loss: 0.607\n",
      "Training: Epoch 40, Batch 40, Loss: 0.367\n",
      "Training: Epoch 40, Batch 41, Loss: 0.461\n",
      "Training: Epoch 40, Batch 42, Loss: 0.244\n",
      "Training: Epoch 40, Batch 43, Loss: 0.253\n",
      "Training: Epoch 40, Batch 44, Loss: 0.502\n",
      "Training: Epoch 40, Batch 45, Loss: 0.376\n",
      "Training: Epoch 40, Batch 46, Loss: 0.594\n",
      "Training: Epoch 40, Batch 47, Loss: 0.331\n",
      "Training: Epoch 40, Batch 48, Loss: 0.399\n",
      "Training: Epoch 40, Batch 49, Loss: 0.426\n",
      "Training: Epoch 40, Batch 50, Loss: 0.449\n",
      "Training: Epoch 40, Batch 51, Loss: 0.615\n",
      "Training: Epoch 40, Batch 52, Loss: 0.339\n",
      "Training: Epoch 40, Batch 53, Loss: 0.341\n",
      "Training: Epoch 40, Batch 54, Loss: 0.302\n",
      "Training: Epoch 40, Batch 55, Loss: 0.441\n",
      "Training: Epoch 40, Batch 56, Loss: 0.359\n",
      "Training: Epoch 40, Batch 57, Loss: 0.365\n",
      "Training: Epoch 40, Batch 58, Loss: 0.208\n",
      "Training: Epoch 40, Batch 59, Loss: 0.377\n",
      "Training: Epoch 40, Batch 60, Loss: 0.372\n",
      "Training: Epoch 40, Batch 61, Loss: 0.655\n",
      "Training: Epoch 40, Batch 62, Loss: 0.274\n",
      "Training: Epoch 40, Batch 63, Loss: 0.482\n",
      "Training: Epoch 40, Batch 64, Loss: 0.311\n",
      "Training: Epoch 40, Batch 65, Loss: 0.498\n",
      "Training: Epoch 40, Batch 66, Loss: 0.488\n",
      "Training: Epoch 40, Batch 67, Loss: 0.379\n",
      "Training: Epoch 40, Batch 68, Loss: 0.53\n",
      "Training: Epoch 40, Batch 69, Loss: 0.369\n",
      "Training: Epoch 40, Batch 70, Loss: 0.561\n",
      "Training: Epoch 40, Batch 71, Loss: 0.788\n",
      "Training: Epoch 40, Batch 72, Loss: 0.473\n",
      "Training: Epoch 40, Batch 73, Loss: 0.488\n",
      "Training: Epoch 40, Batch 74, Loss: 0.467\n",
      "Training: Epoch 40, Batch 75, Loss: 0.421\n",
      "Training: Epoch 40, Batch 76, Loss: 0.62\n",
      "Training: Epoch 40, Batch 77, Loss: 0.54\n",
      "Training: Epoch 40, Batch 78, Loss: 0.631\n",
      "Training: Epoch 40, Batch 79, Loss: 0.44\n",
      "Training: Epoch 40, Batch 80, Loss: 0.688\n",
      "Training: Epoch 40, Batch 81, Loss: 0.356\n",
      "Training: Epoch 40, Batch 82, Loss: 0.401\n",
      "Training: Epoch 40, Batch 83, Loss: 0.199\n",
      "Training: Epoch 40, Batch 84, Loss: 0.421\n",
      "Training: Epoch 40, Batch 85, Loss: 0.519\n",
      "Training: Epoch 40, Batch 86, Loss: 0.704\n",
      "Training: Epoch 40, Batch 87, Loss: 0.583\n",
      "Training: Epoch 40, Batch 88, Loss: 0.413\n",
      "Training: Epoch 40, Batch 89, Loss: 0.551\n",
      "Val: Epoch 40, Loss: 0.263\n",
      "Training: Epoch 41, Batch 0, Loss: 0.536\n",
      "Training: Epoch 41, Batch 1, Loss: 0.307\n",
      "Training: Epoch 41, Batch 2, Loss: 0.465\n",
      "Training: Epoch 41, Batch 3, Loss: 0.338\n",
      "Training: Epoch 41, Batch 4, Loss: 0.413\n",
      "Training: Epoch 41, Batch 5, Loss: 0.292\n",
      "Training: Epoch 41, Batch 6, Loss: 0.288\n",
      "Training: Epoch 41, Batch 7, Loss: 0.461\n",
      "Training: Epoch 41, Batch 8, Loss: 0.544\n",
      "Training: Epoch 41, Batch 9, Loss: 0.407\n",
      "Training: Epoch 41, Batch 10, Loss: 0.519\n",
      "Training: Epoch 41, Batch 11, Loss: 0.333\n",
      "Training: Epoch 41, Batch 12, Loss: 0.474\n",
      "Training: Epoch 41, Batch 13, Loss: 0.227\n",
      "Training: Epoch 41, Batch 14, Loss: 0.315\n",
      "Training: Epoch 41, Batch 15, Loss: 0.544\n",
      "Training: Epoch 41, Batch 16, Loss: 0.466\n",
      "Training: Epoch 41, Batch 17, Loss: 0.609\n",
      "Training: Epoch 41, Batch 18, Loss: 0.349\n",
      "Training: Epoch 41, Batch 19, Loss: 0.402\n",
      "Training: Epoch 41, Batch 20, Loss: 0.541\n",
      "Training: Epoch 41, Batch 21, Loss: 0.517\n",
      "Training: Epoch 41, Batch 22, Loss: 0.437\n",
      "Training: Epoch 41, Batch 23, Loss: 0.385\n",
      "Training: Epoch 41, Batch 24, Loss: 0.743\n",
      "Training: Epoch 41, Batch 25, Loss: 0.247\n",
      "Training: Epoch 41, Batch 26, Loss: 0.63\n",
      "Training: Epoch 41, Batch 27, Loss: 0.711\n",
      "Training: Epoch 41, Batch 28, Loss: 0.521\n",
      "Training: Epoch 41, Batch 29, Loss: 0.532\n",
      "Training: Epoch 41, Batch 30, Loss: 0.343\n",
      "Training: Epoch 41, Batch 31, Loss: 0.357\n",
      "Training: Epoch 41, Batch 32, Loss: 0.372\n",
      "Training: Epoch 41, Batch 33, Loss: 0.403\n",
      "Training: Epoch 41, Batch 34, Loss: 0.619\n",
      "Training: Epoch 41, Batch 35, Loss: 0.362\n",
      "Training: Epoch 41, Batch 36, Loss: 0.466\n",
      "Training: Epoch 41, Batch 37, Loss: 0.324\n",
      "Training: Epoch 41, Batch 38, Loss: 0.337\n",
      "Training: Epoch 41, Batch 39, Loss: 0.449\n",
      "Training: Epoch 41, Batch 40, Loss: 0.223\n",
      "Training: Epoch 41, Batch 41, Loss: 0.645\n",
      "Training: Epoch 41, Batch 42, Loss: 0.45\n",
      "Training: Epoch 41, Batch 43, Loss: 0.414\n",
      "Training: Epoch 41, Batch 44, Loss: 0.213\n",
      "Training: Epoch 41, Batch 45, Loss: 0.383\n",
      "Training: Epoch 41, Batch 46, Loss: 0.337\n",
      "Training: Epoch 41, Batch 47, Loss: 0.49\n",
      "Training: Epoch 41, Batch 48, Loss: 0.377\n",
      "Training: Epoch 41, Batch 49, Loss: 0.328\n",
      "Training: Epoch 41, Batch 50, Loss: 0.403\n",
      "Training: Epoch 41, Batch 51, Loss: 0.509\n",
      "Training: Epoch 41, Batch 52, Loss: 0.692\n",
      "Training: Epoch 41, Batch 53, Loss: 0.571\n",
      "Training: Epoch 41, Batch 54, Loss: 0.359\n",
      "Training: Epoch 41, Batch 55, Loss: 0.406\n",
      "Training: Epoch 41, Batch 56, Loss: 0.57\n",
      "Training: Epoch 41, Batch 57, Loss: 0.248\n",
      "Training: Epoch 41, Batch 58, Loss: 0.462\n",
      "Training: Epoch 41, Batch 59, Loss: 0.465\n",
      "Training: Epoch 41, Batch 60, Loss: 0.416\n",
      "Training: Epoch 41, Batch 61, Loss: 0.487\n",
      "Training: Epoch 41, Batch 62, Loss: 0.248\n",
      "Training: Epoch 41, Batch 63, Loss: 0.515\n",
      "Training: Epoch 41, Batch 64, Loss: 0.435\n",
      "Training: Epoch 41, Batch 65, Loss: 0.54\n",
      "Training: Epoch 41, Batch 66, Loss: 0.27\n",
      "Training: Epoch 41, Batch 67, Loss: 0.458\n",
      "Training: Epoch 41, Batch 68, Loss: 0.329\n",
      "Training: Epoch 41, Batch 69, Loss: 0.389\n",
      "Training: Epoch 41, Batch 70, Loss: 0.525\n",
      "Training: Epoch 41, Batch 71, Loss: 0.574\n",
      "Training: Epoch 41, Batch 72, Loss: 0.471\n",
      "Training: Epoch 41, Batch 73, Loss: 0.494\n",
      "Training: Epoch 41, Batch 74, Loss: 0.349\n",
      "Training: Epoch 41, Batch 75, Loss: 0.637\n",
      "Training: Epoch 41, Batch 76, Loss: 0.651\n",
      "Training: Epoch 41, Batch 77, Loss: 0.524\n",
      "Training: Epoch 41, Batch 78, Loss: 0.436\n",
      "Training: Epoch 41, Batch 79, Loss: 0.354\n",
      "Training: Epoch 41, Batch 80, Loss: 0.567\n",
      "Training: Epoch 41, Batch 81, Loss: 0.55\n",
      "Training: Epoch 41, Batch 82, Loss: 0.443\n",
      "Training: Epoch 41, Batch 83, Loss: 0.211\n",
      "Training: Epoch 41, Batch 84, Loss: 0.6\n",
      "Training: Epoch 41, Batch 85, Loss: 0.338\n",
      "Training: Epoch 41, Batch 86, Loss: 0.464\n",
      "Training: Epoch 41, Batch 87, Loss: 0.639\n",
      "Training: Epoch 41, Batch 88, Loss: 0.304\n",
      "Training: Epoch 41, Batch 89, Loss: 0.613\n",
      "Val: Epoch 41, Loss: 0.223\n",
      "Training: Epoch 42, Batch 0, Loss: 0.512\n",
      "Training: Epoch 42, Batch 1, Loss: 0.379\n",
      "Training: Epoch 42, Batch 2, Loss: 0.275\n",
      "Training: Epoch 42, Batch 3, Loss: 1.112\n",
      "Training: Epoch 42, Batch 4, Loss: 0.453\n",
      "Training: Epoch 42, Batch 5, Loss: 0.388\n",
      "Training: Epoch 42, Batch 6, Loss: 0.324\n",
      "Training: Epoch 42, Batch 7, Loss: 0.551\n",
      "Training: Epoch 42, Batch 8, Loss: 0.341\n",
      "Training: Epoch 42, Batch 9, Loss: 0.524\n",
      "Training: Epoch 42, Batch 10, Loss: 0.319\n",
      "Training: Epoch 42, Batch 11, Loss: 0.382\n",
      "Training: Epoch 42, Batch 12, Loss: 0.444\n",
      "Training: Epoch 42, Batch 13, Loss: 0.422\n",
      "Training: Epoch 42, Batch 14, Loss: 0.492\n",
      "Training: Epoch 42, Batch 15, Loss: 0.436\n",
      "Training: Epoch 42, Batch 16, Loss: 0.422\n",
      "Training: Epoch 42, Batch 17, Loss: 0.524\n",
      "Training: Epoch 42, Batch 18, Loss: 0.688\n",
      "Training: Epoch 42, Batch 19, Loss: 0.304\n",
      "Training: Epoch 42, Batch 20, Loss: 0.668\n",
      "Training: Epoch 42, Batch 21, Loss: 0.436\n",
      "Training: Epoch 42, Batch 22, Loss: 0.337\n",
      "Training: Epoch 42, Batch 23, Loss: 0.83\n",
      "Training: Epoch 42, Batch 24, Loss: 0.585\n",
      "Training: Epoch 42, Batch 25, Loss: 0.256\n",
      "Training: Epoch 42, Batch 26, Loss: 0.342\n",
      "Training: Epoch 42, Batch 27, Loss: 0.344\n",
      "Training: Epoch 42, Batch 28, Loss: 0.536\n",
      "Training: Epoch 42, Batch 29, Loss: 0.61\n",
      "Training: Epoch 42, Batch 30, Loss: 0.543\n",
      "Training: Epoch 42, Batch 31, Loss: 0.471\n",
      "Training: Epoch 42, Batch 32, Loss: 0.489\n",
      "Training: Epoch 42, Batch 33, Loss: 0.398\n",
      "Training: Epoch 42, Batch 34, Loss: 0.295\n",
      "Training: Epoch 42, Batch 35, Loss: 0.341\n",
      "Training: Epoch 42, Batch 36, Loss: 0.371\n",
      "Training: Epoch 42, Batch 37, Loss: 0.555\n",
      "Training: Epoch 42, Batch 38, Loss: 0.327\n",
      "Training: Epoch 42, Batch 39, Loss: 0.463\n",
      "Training: Epoch 42, Batch 40, Loss: 0.436\n",
      "Training: Epoch 42, Batch 41, Loss: 0.429\n",
      "Training: Epoch 42, Batch 42, Loss: 0.481\n",
      "Training: Epoch 42, Batch 43, Loss: 0.52\n",
      "Training: Epoch 42, Batch 44, Loss: 0.578\n",
      "Training: Epoch 42, Batch 45, Loss: 0.95\n",
      "Training: Epoch 42, Batch 46, Loss: 0.535\n",
      "Training: Epoch 42, Batch 47, Loss: 0.343\n",
      "Training: Epoch 42, Batch 48, Loss: 0.403\n",
      "Training: Epoch 42, Batch 49, Loss: 0.348\n",
      "Training: Epoch 42, Batch 50, Loss: 0.403\n",
      "Training: Epoch 42, Batch 51, Loss: 0.157\n",
      "Training: Epoch 42, Batch 52, Loss: 0.52\n",
      "Training: Epoch 42, Batch 53, Loss: 0.502\n",
      "Training: Epoch 42, Batch 54, Loss: 0.588\n",
      "Training: Epoch 42, Batch 55, Loss: 0.43\n",
      "Training: Epoch 42, Batch 56, Loss: 0.602\n",
      "Training: Epoch 42, Batch 57, Loss: 0.395\n",
      "Training: Epoch 42, Batch 58, Loss: 0.262\n",
      "Training: Epoch 42, Batch 59, Loss: 0.365\n",
      "Training: Epoch 42, Batch 60, Loss: 0.474\n",
      "Training: Epoch 42, Batch 61, Loss: 0.395\n",
      "Training: Epoch 42, Batch 62, Loss: 0.594\n",
      "Training: Epoch 42, Batch 63, Loss: 0.44\n",
      "Training: Epoch 42, Batch 64, Loss: 0.426\n",
      "Training: Epoch 42, Batch 65, Loss: 0.462\n",
      "Training: Epoch 42, Batch 66, Loss: 0.369\n",
      "Training: Epoch 42, Batch 67, Loss: 0.572\n",
      "Training: Epoch 42, Batch 68, Loss: 0.375\n",
      "Training: Epoch 42, Batch 69, Loss: 0.291\n",
      "Training: Epoch 42, Batch 70, Loss: 0.541\n",
      "Training: Epoch 42, Batch 71, Loss: 0.277\n",
      "Training: Epoch 42, Batch 72, Loss: 0.17\n",
      "Training: Epoch 42, Batch 73, Loss: 0.313\n",
      "Training: Epoch 42, Batch 74, Loss: 0.377\n",
      "Training: Epoch 42, Batch 75, Loss: 0.594\n",
      "Training: Epoch 42, Batch 76, Loss: 0.434\n",
      "Training: Epoch 42, Batch 77, Loss: 0.374\n",
      "Training: Epoch 42, Batch 78, Loss: 0.466\n",
      "Training: Epoch 42, Batch 79, Loss: 0.42\n",
      "Training: Epoch 42, Batch 80, Loss: 0.439\n",
      "Training: Epoch 42, Batch 81, Loss: 0.337\n",
      "Training: Epoch 42, Batch 82, Loss: 0.295\n",
      "Training: Epoch 42, Batch 83, Loss: 0.397\n",
      "Training: Epoch 42, Batch 84, Loss: 0.475\n",
      "Training: Epoch 42, Batch 85, Loss: 0.396\n",
      "Training: Epoch 42, Batch 86, Loss: 0.59\n",
      "Training: Epoch 42, Batch 87, Loss: 0.396\n",
      "Training: Epoch 42, Batch 88, Loss: 0.46\n",
      "Training: Epoch 42, Batch 89, Loss: 0.446\n",
      "Val: Epoch 42, Loss: 0.272\n",
      "Training: Epoch 43, Batch 0, Loss: 0.475\n",
      "Training: Epoch 43, Batch 1, Loss: 0.355\n",
      "Training: Epoch 43, Batch 2, Loss: 0.407\n",
      "Training: Epoch 43, Batch 3, Loss: 0.491\n",
      "Training: Epoch 43, Batch 4, Loss: 0.464\n",
      "Training: Epoch 43, Batch 5, Loss: 0.374\n",
      "Training: Epoch 43, Batch 6, Loss: 0.35\n",
      "Training: Epoch 43, Batch 7, Loss: 0.478\n",
      "Training: Epoch 43, Batch 8, Loss: 0.358\n",
      "Training: Epoch 43, Batch 9, Loss: 0.248\n",
      "Training: Epoch 43, Batch 10, Loss: 0.525\n",
      "Training: Epoch 43, Batch 11, Loss: 0.613\n",
      "Training: Epoch 43, Batch 12, Loss: 0.53\n",
      "Training: Epoch 43, Batch 13, Loss: 0.343\n",
      "Training: Epoch 43, Batch 14, Loss: 0.312\n",
      "Training: Epoch 43, Batch 15, Loss: 0.616\n",
      "Training: Epoch 43, Batch 16, Loss: 0.341\n",
      "Training: Epoch 43, Batch 17, Loss: 0.374\n",
      "Training: Epoch 43, Batch 18, Loss: 0.454\n",
      "Training: Epoch 43, Batch 19, Loss: 0.305\n",
      "Training: Epoch 43, Batch 20, Loss: 0.284\n",
      "Training: Epoch 43, Batch 21, Loss: 0.302\n",
      "Training: Epoch 43, Batch 22, Loss: 0.405\n",
      "Training: Epoch 43, Batch 23, Loss: 0.503\n",
      "Training: Epoch 43, Batch 24, Loss: 0.519\n",
      "Training: Epoch 43, Batch 25, Loss: 0.33\n",
      "Training: Epoch 43, Batch 26, Loss: 0.424\n",
      "Training: Epoch 43, Batch 27, Loss: 0.499\n",
      "Training: Epoch 43, Batch 28, Loss: 0.548\n",
      "Training: Epoch 43, Batch 29, Loss: 0.353\n",
      "Training: Epoch 43, Batch 30, Loss: 0.672\n",
      "Training: Epoch 43, Batch 31, Loss: 0.428\n",
      "Training: Epoch 43, Batch 32, Loss: 0.46\n",
      "Training: Epoch 43, Batch 33, Loss: 0.387\n",
      "Training: Epoch 43, Batch 34, Loss: 0.303\n",
      "Training: Epoch 43, Batch 35, Loss: 0.537\n",
      "Training: Epoch 43, Batch 36, Loss: 0.372\n",
      "Training: Epoch 43, Batch 37, Loss: 0.432\n",
      "Training: Epoch 43, Batch 38, Loss: 0.642\n",
      "Training: Epoch 43, Batch 39, Loss: 0.191\n",
      "Training: Epoch 43, Batch 40, Loss: 0.49\n",
      "Training: Epoch 43, Batch 41, Loss: 0.465\n",
      "Training: Epoch 43, Batch 42, Loss: 0.196\n",
      "Training: Epoch 43, Batch 43, Loss: 0.486\n",
      "Training: Epoch 43, Batch 44, Loss: 0.551\n",
      "Training: Epoch 43, Batch 45, Loss: 0.423\n",
      "Training: Epoch 43, Batch 46, Loss: 0.51\n",
      "Training: Epoch 43, Batch 47, Loss: 0.355\n",
      "Training: Epoch 43, Batch 48, Loss: 0.409\n",
      "Training: Epoch 43, Batch 49, Loss: 0.494\n",
      "Training: Epoch 43, Batch 50, Loss: 0.505\n",
      "Training: Epoch 43, Batch 51, Loss: 0.466\n",
      "Training: Epoch 43, Batch 52, Loss: 0.164\n",
      "Training: Epoch 43, Batch 53, Loss: 0.475\n",
      "Training: Epoch 43, Batch 54, Loss: 0.629\n",
      "Training: Epoch 43, Batch 55, Loss: 0.398\n",
      "Training: Epoch 43, Batch 56, Loss: 0.432\n",
      "Training: Epoch 43, Batch 57, Loss: 0.213\n",
      "Training: Epoch 43, Batch 58, Loss: 0.498\n",
      "Training: Epoch 43, Batch 59, Loss: 0.383\n",
      "Training: Epoch 43, Batch 60, Loss: 0.367\n",
      "Training: Epoch 43, Batch 61, Loss: 0.353\n",
      "Training: Epoch 43, Batch 62, Loss: 0.442\n",
      "Training: Epoch 43, Batch 63, Loss: 0.255\n",
      "Training: Epoch 43, Batch 64, Loss: 0.515\n",
      "Training: Epoch 43, Batch 65, Loss: 0.428\n",
      "Training: Epoch 43, Batch 66, Loss: 0.47\n",
      "Training: Epoch 43, Batch 67, Loss: 0.523\n",
      "Training: Epoch 43, Batch 68, Loss: 0.435\n",
      "Training: Epoch 43, Batch 69, Loss: 0.393\n",
      "Training: Epoch 43, Batch 70, Loss: 0.248\n",
      "Training: Epoch 43, Batch 71, Loss: 0.546\n",
      "Training: Epoch 43, Batch 72, Loss: 0.445\n",
      "Training: Epoch 43, Batch 73, Loss: 0.402\n",
      "Training: Epoch 43, Batch 74, Loss: 0.671\n",
      "Training: Epoch 43, Batch 75, Loss: 0.509\n",
      "Training: Epoch 43, Batch 76, Loss: 0.454\n",
      "Training: Epoch 43, Batch 77, Loss: 0.403\n",
      "Training: Epoch 43, Batch 78, Loss: 0.176\n",
      "Training: Epoch 43, Batch 79, Loss: 0.385\n",
      "Training: Epoch 43, Batch 80, Loss: 0.504\n",
      "Training: Epoch 43, Batch 81, Loss: 0.57\n",
      "Training: Epoch 43, Batch 82, Loss: 0.32\n",
      "Training: Epoch 43, Batch 83, Loss: 0.523\n",
      "Training: Epoch 43, Batch 84, Loss: 0.407\n",
      "Training: Epoch 43, Batch 85, Loss: 0.401\n",
      "Training: Epoch 43, Batch 86, Loss: 0.449\n",
      "Training: Epoch 43, Batch 87, Loss: 0.341\n",
      "Training: Epoch 43, Batch 88, Loss: 0.484\n",
      "Training: Epoch 43, Batch 89, Loss: 0.602\n",
      "Val: Epoch 43, Loss: 0.241\n",
      "Training: Epoch 44, Batch 0, Loss: 0.42\n",
      "Training: Epoch 44, Batch 1, Loss: 0.373\n",
      "Training: Epoch 44, Batch 2, Loss: 0.735\n",
      "Training: Epoch 44, Batch 3, Loss: 0.435\n",
      "Training: Epoch 44, Batch 4, Loss: 0.774\n",
      "Training: Epoch 44, Batch 5, Loss: 0.421\n",
      "Training: Epoch 44, Batch 6, Loss: 0.461\n",
      "Training: Epoch 44, Batch 7, Loss: 0.544\n",
      "Training: Epoch 44, Batch 8, Loss: 0.621\n",
      "Training: Epoch 44, Batch 9, Loss: 0.344\n",
      "Training: Epoch 44, Batch 10, Loss: 0.317\n",
      "Training: Epoch 44, Batch 11, Loss: 0.723\n",
      "Training: Epoch 44, Batch 12, Loss: 0.436\n",
      "Training: Epoch 44, Batch 13, Loss: 0.504\n",
      "Training: Epoch 44, Batch 14, Loss: 0.444\n",
      "Training: Epoch 44, Batch 15, Loss: 0.348\n",
      "Training: Epoch 44, Batch 16, Loss: 0.608\n",
      "Training: Epoch 44, Batch 17, Loss: 0.419\n",
      "Training: Epoch 44, Batch 18, Loss: 0.478\n",
      "Training: Epoch 44, Batch 19, Loss: 0.393\n",
      "Training: Epoch 44, Batch 20, Loss: 0.569\n",
      "Training: Epoch 44, Batch 21, Loss: 0.461\n",
      "Training: Epoch 44, Batch 22, Loss: 0.373\n",
      "Training: Epoch 44, Batch 23, Loss: 0.549\n",
      "Training: Epoch 44, Batch 24, Loss: 0.484\n",
      "Training: Epoch 44, Batch 25, Loss: 0.34\n",
      "Training: Epoch 44, Batch 26, Loss: 0.298\n",
      "Training: Epoch 44, Batch 27, Loss: 0.285\n",
      "Training: Epoch 44, Batch 28, Loss: 0.64\n",
      "Training: Epoch 44, Batch 29, Loss: 0.261\n",
      "Training: Epoch 44, Batch 30, Loss: 0.428\n",
      "Training: Epoch 44, Batch 31, Loss: 0.383\n",
      "Training: Epoch 44, Batch 32, Loss: 0.48\n",
      "Training: Epoch 44, Batch 33, Loss: 0.346\n",
      "Training: Epoch 44, Batch 34, Loss: 0.425\n",
      "Training: Epoch 44, Batch 35, Loss: 0.327\n",
      "Training: Epoch 44, Batch 36, Loss: 0.562\n",
      "Training: Epoch 44, Batch 37, Loss: 0.567\n",
      "Training: Epoch 44, Batch 38, Loss: 0.387\n",
      "Training: Epoch 44, Batch 39, Loss: 0.247\n",
      "Training: Epoch 44, Batch 40, Loss: 0.246\n",
      "Training: Epoch 44, Batch 41, Loss: 0.388\n",
      "Training: Epoch 44, Batch 42, Loss: 0.698\n",
      "Training: Epoch 44, Batch 43, Loss: 0.564\n",
      "Training: Epoch 44, Batch 44, Loss: 0.417\n",
      "Training: Epoch 44, Batch 45, Loss: 0.457\n",
      "Training: Epoch 44, Batch 46, Loss: 0.536\n",
      "Training: Epoch 44, Batch 47, Loss: 0.409\n",
      "Training: Epoch 44, Batch 48, Loss: 0.379\n",
      "Training: Epoch 44, Batch 49, Loss: 0.433\n",
      "Training: Epoch 44, Batch 50, Loss: 0.471\n",
      "Training: Epoch 44, Batch 51, Loss: 0.249\n",
      "Training: Epoch 44, Batch 52, Loss: 0.517\n",
      "Training: Epoch 44, Batch 53, Loss: 0.339\n",
      "Training: Epoch 44, Batch 54, Loss: 0.391\n",
      "Training: Epoch 44, Batch 55, Loss: 0.354\n",
      "Training: Epoch 44, Batch 56, Loss: 0.485\n",
      "Training: Epoch 44, Batch 57, Loss: 0.488\n",
      "Training: Epoch 44, Batch 58, Loss: 0.299\n",
      "Training: Epoch 44, Batch 59, Loss: 0.306\n",
      "Training: Epoch 44, Batch 60, Loss: 0.457\n",
      "Training: Epoch 44, Batch 61, Loss: 0.472\n",
      "Training: Epoch 44, Batch 62, Loss: 0.54\n",
      "Training: Epoch 44, Batch 63, Loss: 0.407\n",
      "Training: Epoch 44, Batch 64, Loss: 0.489\n",
      "Training: Epoch 44, Batch 65, Loss: 0.399\n",
      "Training: Epoch 44, Batch 66, Loss: 0.483\n",
      "Training: Epoch 44, Batch 67, Loss: 0.349\n",
      "Training: Epoch 44, Batch 68, Loss: 0.317\n",
      "Training: Epoch 44, Batch 69, Loss: 0.605\n",
      "Training: Epoch 44, Batch 70, Loss: 0.305\n",
      "Training: Epoch 44, Batch 71, Loss: 0.37\n",
      "Training: Epoch 44, Batch 72, Loss: 0.381\n",
      "Training: Epoch 44, Batch 73, Loss: 0.371\n",
      "Training: Epoch 44, Batch 74, Loss: 0.448\n",
      "Training: Epoch 44, Batch 75, Loss: 0.544\n",
      "Training: Epoch 44, Batch 76, Loss: 0.415\n",
      "Training: Epoch 44, Batch 77, Loss: 0.474\n",
      "Training: Epoch 44, Batch 78, Loss: 0.367\n",
      "Training: Epoch 44, Batch 79, Loss: 0.342\n",
      "Training: Epoch 44, Batch 80, Loss: 0.376\n",
      "Training: Epoch 44, Batch 81, Loss: 0.295\n",
      "Training: Epoch 44, Batch 82, Loss: 0.629\n",
      "Training: Epoch 44, Batch 83, Loss: 0.431\n",
      "Training: Epoch 44, Batch 84, Loss: 0.559\n",
      "Training: Epoch 44, Batch 85, Loss: 0.486\n",
      "Training: Epoch 44, Batch 86, Loss: 0.427\n",
      "Training: Epoch 44, Batch 87, Loss: 0.44\n",
      "Training: Epoch 44, Batch 88, Loss: 0.394\n",
      "Training: Epoch 44, Batch 89, Loss: 0.415\n",
      "Val: Epoch 44, Loss: 0.274\n",
      "Training: Epoch 45, Batch 0, Loss: 0.491\n",
      "Training: Epoch 45, Batch 1, Loss: 0.394\n",
      "Training: Epoch 45, Batch 2, Loss: 0.362\n",
      "Training: Epoch 45, Batch 3, Loss: 0.407\n",
      "Training: Epoch 45, Batch 4, Loss: 0.379\n",
      "Training: Epoch 45, Batch 5, Loss: 0.306\n",
      "Training: Epoch 45, Batch 6, Loss: 0.386\n",
      "Training: Epoch 45, Batch 7, Loss: 0.206\n",
      "Training: Epoch 45, Batch 8, Loss: 0.377\n",
      "Training: Epoch 45, Batch 9, Loss: 0.393\n",
      "Training: Epoch 45, Batch 10, Loss: 0.369\n",
      "Training: Epoch 45, Batch 11, Loss: 0.262\n",
      "Training: Epoch 45, Batch 12, Loss: 0.347\n",
      "Training: Epoch 45, Batch 13, Loss: 0.524\n",
      "Training: Epoch 45, Batch 14, Loss: 0.296\n",
      "Training: Epoch 45, Batch 15, Loss: 0.199\n",
      "Training: Epoch 45, Batch 16, Loss: 0.365\n",
      "Training: Epoch 45, Batch 17, Loss: 0.495\n",
      "Training: Epoch 45, Batch 18, Loss: 0.473\n",
      "Training: Epoch 45, Batch 19, Loss: 0.319\n",
      "Training: Epoch 45, Batch 20, Loss: 0.496\n",
      "Training: Epoch 45, Batch 21, Loss: 0.405\n",
      "Training: Epoch 45, Batch 22, Loss: 0.379\n",
      "Training: Epoch 45, Batch 23, Loss: 0.592\n",
      "Training: Epoch 45, Batch 24, Loss: 0.244\n",
      "Training: Epoch 45, Batch 25, Loss: 0.664\n",
      "Training: Epoch 45, Batch 26, Loss: 0.436\n",
      "Training: Epoch 45, Batch 27, Loss: 0.328\n",
      "Training: Epoch 45, Batch 28, Loss: 0.171\n",
      "Training: Epoch 45, Batch 29, Loss: 0.599\n",
      "Training: Epoch 45, Batch 30, Loss: 0.487\n",
      "Training: Epoch 45, Batch 31, Loss: 0.353\n",
      "Training: Epoch 45, Batch 32, Loss: 0.314\n",
      "Training: Epoch 45, Batch 33, Loss: 0.413\n",
      "Training: Epoch 45, Batch 34, Loss: 0.316\n",
      "Training: Epoch 45, Batch 35, Loss: 0.38\n",
      "Training: Epoch 45, Batch 36, Loss: 0.674\n",
      "Training: Epoch 45, Batch 37, Loss: 0.38\n",
      "Training: Epoch 45, Batch 38, Loss: 0.381\n",
      "Training: Epoch 45, Batch 39, Loss: 0.495\n",
      "Training: Epoch 45, Batch 40, Loss: 0.41\n",
      "Training: Epoch 45, Batch 41, Loss: 0.404\n",
      "Training: Epoch 45, Batch 42, Loss: 0.476\n",
      "Training: Epoch 45, Batch 43, Loss: 0.543\n",
      "Training: Epoch 45, Batch 44, Loss: 0.54\n",
      "Training: Epoch 45, Batch 45, Loss: 0.445\n",
      "Training: Epoch 45, Batch 46, Loss: 0.49\n",
      "Training: Epoch 45, Batch 47, Loss: 0.297\n",
      "Training: Epoch 45, Batch 48, Loss: 0.336\n",
      "Training: Epoch 45, Batch 49, Loss: 0.424\n",
      "Training: Epoch 45, Batch 50, Loss: 0.327\n",
      "Training: Epoch 45, Batch 51, Loss: 0.405\n",
      "Training: Epoch 45, Batch 52, Loss: 0.537\n",
      "Training: Epoch 45, Batch 53, Loss: 0.455\n",
      "Training: Epoch 45, Batch 54, Loss: 0.536\n",
      "Training: Epoch 45, Batch 55, Loss: 0.387\n",
      "Training: Epoch 45, Batch 56, Loss: 0.369\n",
      "Training: Epoch 45, Batch 57, Loss: 0.441\n",
      "Training: Epoch 45, Batch 58, Loss: 0.482\n",
      "Training: Epoch 45, Batch 59, Loss: 0.577\n",
      "Training: Epoch 45, Batch 60, Loss: 0.569\n",
      "Training: Epoch 45, Batch 61, Loss: 0.522\n",
      "Training: Epoch 45, Batch 62, Loss: 0.454\n",
      "Training: Epoch 45, Batch 63, Loss: 0.168\n",
      "Training: Epoch 45, Batch 64, Loss: 0.431\n",
      "Training: Epoch 45, Batch 65, Loss: 0.676\n",
      "Training: Epoch 45, Batch 66, Loss: 0.692\n",
      "Training: Epoch 45, Batch 67, Loss: 0.224\n",
      "Training: Epoch 45, Batch 68, Loss: 0.556\n",
      "Training: Epoch 45, Batch 69, Loss: 0.616\n",
      "Training: Epoch 45, Batch 70, Loss: 0.378\n",
      "Training: Epoch 45, Batch 71, Loss: 0.582\n",
      "Training: Epoch 45, Batch 72, Loss: 0.429\n",
      "Training: Epoch 45, Batch 73, Loss: 0.563\n",
      "Training: Epoch 45, Batch 74, Loss: 0.309\n",
      "Training: Epoch 45, Batch 75, Loss: 0.561\n",
      "Training: Epoch 45, Batch 76, Loss: 0.267\n",
      "Training: Epoch 45, Batch 77, Loss: 0.416\n",
      "Training: Epoch 45, Batch 78, Loss: 0.532\n",
      "Training: Epoch 45, Batch 79, Loss: 0.729\n",
      "Training: Epoch 45, Batch 80, Loss: 0.431\n",
      "Training: Epoch 45, Batch 81, Loss: 0.351\n",
      "Training: Epoch 45, Batch 82, Loss: 0.337\n",
      "Training: Epoch 45, Batch 83, Loss: 0.392\n",
      "Training: Epoch 45, Batch 84, Loss: 0.228\n",
      "Training: Epoch 45, Batch 85, Loss: 0.54\n",
      "Training: Epoch 45, Batch 86, Loss: 0.592\n",
      "Training: Epoch 45, Batch 87, Loss: 0.464\n",
      "Training: Epoch 45, Batch 88, Loss: 0.313\n",
      "Training: Epoch 45, Batch 89, Loss: 0.224\n",
      "Val: Epoch 45, Loss: 0.241\n",
      "Training: Epoch 46, Batch 0, Loss: 0.646\n",
      "Training: Epoch 46, Batch 1, Loss: 0.325\n",
      "Training: Epoch 46, Batch 2, Loss: 0.689\n",
      "Training: Epoch 46, Batch 3, Loss: 0.373\n",
      "Training: Epoch 46, Batch 4, Loss: 0.39\n",
      "Training: Epoch 46, Batch 5, Loss: 0.415\n",
      "Training: Epoch 46, Batch 6, Loss: 0.49\n",
      "Training: Epoch 46, Batch 7, Loss: 0.222\n",
      "Training: Epoch 46, Batch 8, Loss: 0.359\n",
      "Training: Epoch 46, Batch 9, Loss: 0.739\n",
      "Training: Epoch 46, Batch 10, Loss: 0.447\n",
      "Training: Epoch 46, Batch 11, Loss: 0.367\n",
      "Training: Epoch 46, Batch 12, Loss: 0.311\n",
      "Training: Epoch 46, Batch 13, Loss: 0.517\n",
      "Training: Epoch 46, Batch 14, Loss: 0.202\n",
      "Training: Epoch 46, Batch 15, Loss: 0.393\n",
      "Training: Epoch 46, Batch 16, Loss: 0.424\n",
      "Training: Epoch 46, Batch 17, Loss: 0.47\n",
      "Training: Epoch 46, Batch 18, Loss: 0.468\n",
      "Training: Epoch 46, Batch 19, Loss: 0.448\n",
      "Training: Epoch 46, Batch 20, Loss: 0.727\n",
      "Training: Epoch 46, Batch 21, Loss: 0.575\n",
      "Training: Epoch 46, Batch 22, Loss: 0.241\n",
      "Training: Epoch 46, Batch 23, Loss: 0.395\n",
      "Training: Epoch 46, Batch 24, Loss: 0.677\n",
      "Training: Epoch 46, Batch 25, Loss: 0.56\n",
      "Training: Epoch 46, Batch 26, Loss: 0.359\n",
      "Training: Epoch 46, Batch 27, Loss: 0.395\n",
      "Training: Epoch 46, Batch 28, Loss: 0.316\n",
      "Training: Epoch 46, Batch 29, Loss: 0.493\n",
      "Training: Epoch 46, Batch 30, Loss: 0.36\n",
      "Training: Epoch 46, Batch 31, Loss: 0.555\n",
      "Training: Epoch 46, Batch 32, Loss: 0.623\n",
      "Training: Epoch 46, Batch 33, Loss: 0.54\n",
      "Training: Epoch 46, Batch 34, Loss: 0.37\n",
      "Training: Epoch 46, Batch 35, Loss: 0.381\n",
      "Training: Epoch 46, Batch 36, Loss: 0.295\n",
      "Training: Epoch 46, Batch 37, Loss: 0.252\n",
      "Training: Epoch 46, Batch 38, Loss: 0.536\n",
      "Training: Epoch 46, Batch 39, Loss: 0.637\n",
      "Training: Epoch 46, Batch 40, Loss: 0.484\n",
      "Training: Epoch 46, Batch 41, Loss: 0.552\n",
      "Training: Epoch 46, Batch 42, Loss: 0.519\n",
      "Training: Epoch 46, Batch 43, Loss: 0.586\n",
      "Training: Epoch 46, Batch 44, Loss: 0.491\n",
      "Training: Epoch 46, Batch 45, Loss: 0.225\n",
      "Training: Epoch 46, Batch 46, Loss: 0.435\n",
      "Training: Epoch 46, Batch 47, Loss: 0.464\n",
      "Training: Epoch 46, Batch 48, Loss: 0.384\n",
      "Training: Epoch 46, Batch 49, Loss: 0.632\n",
      "Training: Epoch 46, Batch 50, Loss: 0.638\n",
      "Training: Epoch 46, Batch 51, Loss: 0.622\n",
      "Training: Epoch 46, Batch 52, Loss: 0.412\n",
      "Training: Epoch 46, Batch 53, Loss: 0.383\n",
      "Training: Epoch 46, Batch 54, Loss: 0.517\n",
      "Training: Epoch 46, Batch 55, Loss: 0.478\n",
      "Training: Epoch 46, Batch 56, Loss: 0.608\n",
      "Training: Epoch 46, Batch 57, Loss: 0.467\n",
      "Training: Epoch 46, Batch 58, Loss: 0.438\n",
      "Training: Epoch 46, Batch 59, Loss: 0.49\n",
      "Training: Epoch 46, Batch 60, Loss: 0.241\n",
      "Training: Epoch 46, Batch 61, Loss: 0.248\n",
      "Training: Epoch 46, Batch 62, Loss: 0.46\n",
      "Training: Epoch 46, Batch 63, Loss: 0.371\n",
      "Training: Epoch 46, Batch 64, Loss: 0.534\n",
      "Training: Epoch 46, Batch 65, Loss: 0.527\n",
      "Training: Epoch 46, Batch 66, Loss: 0.44\n",
      "Training: Epoch 46, Batch 67, Loss: 0.45\n",
      "Training: Epoch 46, Batch 68, Loss: 0.392\n",
      "Training: Epoch 46, Batch 69, Loss: 0.76\n",
      "Training: Epoch 46, Batch 70, Loss: 0.554\n",
      "Training: Epoch 46, Batch 71, Loss: 0.358\n",
      "Training: Epoch 46, Batch 72, Loss: 0.249\n",
      "Training: Epoch 46, Batch 73, Loss: 0.435\n",
      "Training: Epoch 46, Batch 74, Loss: 0.436\n",
      "Training: Epoch 46, Batch 75, Loss: 0.509\n",
      "Training: Epoch 46, Batch 76, Loss: 0.319\n",
      "Training: Epoch 46, Batch 77, Loss: 0.365\n",
      "Training: Epoch 46, Batch 78, Loss: 0.426\n",
      "Training: Epoch 46, Batch 79, Loss: 0.227\n",
      "Training: Epoch 46, Batch 80, Loss: 0.38\n",
      "Training: Epoch 46, Batch 81, Loss: 0.541\n",
      "Training: Epoch 46, Batch 82, Loss: 0.38\n",
      "Training: Epoch 46, Batch 83, Loss: 0.386\n",
      "Training: Epoch 46, Batch 84, Loss: 0.231\n",
      "Training: Epoch 46, Batch 85, Loss: 0.393\n",
      "Training: Epoch 46, Batch 86, Loss: 0.39\n",
      "Training: Epoch 46, Batch 87, Loss: 0.426\n",
      "Training: Epoch 46, Batch 88, Loss: 0.66\n",
      "Training: Epoch 46, Batch 89, Loss: 0.319\n",
      "Val: Epoch 46, Loss: 0.264\n",
      "Training: Epoch 47, Batch 0, Loss: 0.361\n",
      "Training: Epoch 47, Batch 1, Loss: 0.223\n",
      "Training: Epoch 47, Batch 2, Loss: 0.493\n",
      "Training: Epoch 47, Batch 3, Loss: 0.252\n",
      "Training: Epoch 47, Batch 4, Loss: 0.442\n",
      "Training: Epoch 47, Batch 5, Loss: 0.374\n",
      "Training: Epoch 47, Batch 6, Loss: 0.254\n",
      "Training: Epoch 47, Batch 7, Loss: 0.327\n",
      "Training: Epoch 47, Batch 8, Loss: 0.35\n",
      "Training: Epoch 47, Batch 9, Loss: 0.385\n",
      "Training: Epoch 47, Batch 10, Loss: 0.404\n",
      "Training: Epoch 47, Batch 11, Loss: 0.583\n",
      "Training: Epoch 47, Batch 12, Loss: 0.584\n",
      "Training: Epoch 47, Batch 13, Loss: 0.476\n",
      "Training: Epoch 47, Batch 14, Loss: 0.509\n",
      "Training: Epoch 47, Batch 15, Loss: 0.338\n",
      "Training: Epoch 47, Batch 16, Loss: 0.234\n",
      "Training: Epoch 47, Batch 17, Loss: 0.327\n",
      "Training: Epoch 47, Batch 18, Loss: 0.442\n",
      "Training: Epoch 47, Batch 19, Loss: 0.558\n",
      "Training: Epoch 47, Batch 20, Loss: 0.433\n",
      "Training: Epoch 47, Batch 21, Loss: 0.451\n",
      "Training: Epoch 47, Batch 22, Loss: 0.392\n",
      "Training: Epoch 47, Batch 23, Loss: 0.485\n",
      "Training: Epoch 47, Batch 24, Loss: 0.421\n",
      "Training: Epoch 47, Batch 25, Loss: 0.443\n",
      "Training: Epoch 47, Batch 26, Loss: 0.435\n",
      "Training: Epoch 47, Batch 27, Loss: 0.228\n",
      "Training: Epoch 47, Batch 28, Loss: 0.338\n",
      "Training: Epoch 47, Batch 29, Loss: 0.365\n",
      "Training: Epoch 47, Batch 30, Loss: 0.491\n",
      "Training: Epoch 47, Batch 31, Loss: 0.379\n",
      "Training: Epoch 47, Batch 32, Loss: 0.331\n",
      "Training: Epoch 47, Batch 33, Loss: 0.346\n",
      "Training: Epoch 47, Batch 34, Loss: 0.599\n",
      "Training: Epoch 47, Batch 35, Loss: 0.397\n",
      "Training: Epoch 47, Batch 36, Loss: 0.566\n",
      "Training: Epoch 47, Batch 37, Loss: 0.305\n",
      "Training: Epoch 47, Batch 38, Loss: 0.53\n",
      "Training: Epoch 47, Batch 39, Loss: 0.448\n",
      "Training: Epoch 47, Batch 40, Loss: 0.228\n",
      "Training: Epoch 47, Batch 41, Loss: 0.293\n",
      "Training: Epoch 47, Batch 42, Loss: 0.336\n",
      "Training: Epoch 47, Batch 43, Loss: 0.382\n",
      "Training: Epoch 47, Batch 44, Loss: 0.572\n",
      "Training: Epoch 47, Batch 45, Loss: 0.577\n",
      "Training: Epoch 47, Batch 46, Loss: 0.442\n",
      "Training: Epoch 47, Batch 47, Loss: 0.481\n",
      "Training: Epoch 47, Batch 48, Loss: 0.442\n",
      "Training: Epoch 47, Batch 49, Loss: 0.662\n",
      "Training: Epoch 47, Batch 50, Loss: 0.434\n",
      "Training: Epoch 47, Batch 51, Loss: 0.41\n",
      "Training: Epoch 47, Batch 52, Loss: 0.461\n",
      "Training: Epoch 47, Batch 53, Loss: 0.272\n",
      "Training: Epoch 47, Batch 54, Loss: 0.514\n",
      "Training: Epoch 47, Batch 55, Loss: 0.288\n",
      "Training: Epoch 47, Batch 56, Loss: 0.41\n",
      "Training: Epoch 47, Batch 57, Loss: 0.396\n",
      "Training: Epoch 47, Batch 58, Loss: 0.484\n",
      "Training: Epoch 47, Batch 59, Loss: 0.305\n",
      "Training: Epoch 47, Batch 60, Loss: 0.526\n",
      "Training: Epoch 47, Batch 61, Loss: 0.282\n",
      "Training: Epoch 47, Batch 62, Loss: 0.484\n",
      "Training: Epoch 47, Batch 63, Loss: 0.4\n",
      "Training: Epoch 47, Batch 64, Loss: 0.495\n",
      "Training: Epoch 47, Batch 65, Loss: 0.37\n",
      "Training: Epoch 47, Batch 66, Loss: 0.536\n",
      "Training: Epoch 47, Batch 67, Loss: 0.448\n",
      "Training: Epoch 47, Batch 68, Loss: 0.456\n",
      "Training: Epoch 47, Batch 69, Loss: 0.662\n",
      "Training: Epoch 47, Batch 70, Loss: 0.373\n",
      "Training: Epoch 47, Batch 71, Loss: 0.478\n",
      "Training: Epoch 47, Batch 72, Loss: 0.507\n",
      "Training: Epoch 47, Batch 73, Loss: 0.261\n",
      "Training: Epoch 47, Batch 74, Loss: 0.342\n",
      "Training: Epoch 47, Batch 75, Loss: 0.284\n",
      "Training: Epoch 47, Batch 76, Loss: 0.334\n",
      "Training: Epoch 47, Batch 77, Loss: 0.572\n",
      "Training: Epoch 47, Batch 78, Loss: 0.331\n",
      "Training: Epoch 47, Batch 79, Loss: 0.374\n",
      "Training: Epoch 47, Batch 80, Loss: 0.395\n",
      "Training: Epoch 47, Batch 81, Loss: 0.512\n",
      "Training: Epoch 47, Batch 82, Loss: 0.605\n",
      "Training: Epoch 47, Batch 83, Loss: 0.389\n",
      "Training: Epoch 47, Batch 84, Loss: 0.359\n",
      "Training: Epoch 47, Batch 85, Loss: 0.27\n",
      "Training: Epoch 47, Batch 86, Loss: 0.452\n",
      "Training: Epoch 47, Batch 87, Loss: 0.422\n",
      "Training: Epoch 47, Batch 88, Loss: 0.482\n",
      "Training: Epoch 47, Batch 89, Loss: 0.339\n",
      "Val: Epoch 47, Loss: 0.256\n",
      "Training: Epoch 48, Batch 0, Loss: 0.357\n",
      "Training: Epoch 48, Batch 1, Loss: 0.364\n",
      "Training: Epoch 48, Batch 2, Loss: 0.46\n",
      "Training: Epoch 48, Batch 3, Loss: 0.179\n",
      "Training: Epoch 48, Batch 4, Loss: 0.304\n",
      "Training: Epoch 48, Batch 5, Loss: 0.53\n",
      "Training: Epoch 48, Batch 6, Loss: 0.432\n",
      "Training: Epoch 48, Batch 7, Loss: 0.3\n",
      "Training: Epoch 48, Batch 8, Loss: 0.33\n",
      "Training: Epoch 48, Batch 9, Loss: 0.432\n",
      "Training: Epoch 48, Batch 10, Loss: 0.189\n",
      "Training: Epoch 48, Batch 11, Loss: 0.524\n",
      "Training: Epoch 48, Batch 12, Loss: 0.306\n",
      "Training: Epoch 48, Batch 13, Loss: 0.603\n",
      "Training: Epoch 48, Batch 14, Loss: 0.285\n",
      "Training: Epoch 48, Batch 15, Loss: 0.284\n",
      "Training: Epoch 48, Batch 16, Loss: 0.561\n",
      "Training: Epoch 48, Batch 17, Loss: 0.342\n",
      "Training: Epoch 48, Batch 18, Loss: 0.417\n",
      "Training: Epoch 48, Batch 19, Loss: 0.493\n",
      "Training: Epoch 48, Batch 20, Loss: 0.425\n",
      "Training: Epoch 48, Batch 21, Loss: 0.425\n",
      "Training: Epoch 48, Batch 22, Loss: 0.336\n",
      "Training: Epoch 48, Batch 23, Loss: 0.444\n",
      "Training: Epoch 48, Batch 24, Loss: 0.516\n",
      "Training: Epoch 48, Batch 25, Loss: 0.502\n",
      "Training: Epoch 48, Batch 26, Loss: 0.292\n",
      "Training: Epoch 48, Batch 27, Loss: 0.398\n",
      "Training: Epoch 48, Batch 28, Loss: 0.283\n",
      "Training: Epoch 48, Batch 29, Loss: 0.32\n",
      "Training: Epoch 48, Batch 30, Loss: 0.369\n",
      "Training: Epoch 48, Batch 31, Loss: 0.516\n",
      "Training: Epoch 48, Batch 32, Loss: 0.36\n",
      "Training: Epoch 48, Batch 33, Loss: 0.468\n",
      "Training: Epoch 48, Batch 34, Loss: 0.288\n",
      "Training: Epoch 48, Batch 35, Loss: 0.35\n",
      "Training: Epoch 48, Batch 36, Loss: 0.274\n",
      "Training: Epoch 48, Batch 37, Loss: 0.415\n",
      "Training: Epoch 48, Batch 38, Loss: 0.569\n",
      "Training: Epoch 48, Batch 39, Loss: 0.476\n",
      "Training: Epoch 48, Batch 40, Loss: 0.403\n",
      "Training: Epoch 48, Batch 41, Loss: 0.526\n",
      "Training: Epoch 48, Batch 42, Loss: 0.502\n",
      "Training: Epoch 48, Batch 43, Loss: 0.246\n",
      "Training: Epoch 48, Batch 44, Loss: 0.663\n",
      "Training: Epoch 48, Batch 45, Loss: 0.503\n",
      "Training: Epoch 48, Batch 46, Loss: 0.464\n",
      "Training: Epoch 48, Batch 47, Loss: 0.277\n",
      "Training: Epoch 48, Batch 48, Loss: 0.476\n",
      "Training: Epoch 48, Batch 49, Loss: 0.374\n",
      "Training: Epoch 48, Batch 50, Loss: 0.246\n",
      "Training: Epoch 48, Batch 51, Loss: 0.533\n",
      "Training: Epoch 48, Batch 52, Loss: 0.433\n",
      "Training: Epoch 48, Batch 53, Loss: 0.327\n",
      "Training: Epoch 48, Batch 54, Loss: 0.229\n",
      "Training: Epoch 48, Batch 55, Loss: 0.416\n",
      "Training: Epoch 48, Batch 56, Loss: 0.293\n",
      "Training: Epoch 48, Batch 57, Loss: 0.476\n",
      "Training: Epoch 48, Batch 58, Loss: 0.409\n",
      "Training: Epoch 48, Batch 59, Loss: 0.477\n",
      "Training: Epoch 48, Batch 60, Loss: 0.379\n",
      "Training: Epoch 48, Batch 61, Loss: 0.41\n",
      "Training: Epoch 48, Batch 62, Loss: 0.374\n",
      "Training: Epoch 48, Batch 63, Loss: 0.356\n",
      "Training: Epoch 48, Batch 64, Loss: 0.445\n",
      "Training: Epoch 48, Batch 65, Loss: 0.544\n",
      "Training: Epoch 48, Batch 66, Loss: 0.454\n",
      "Training: Epoch 48, Batch 67, Loss: 0.474\n",
      "Training: Epoch 48, Batch 68, Loss: 0.296\n",
      "Training: Epoch 48, Batch 69, Loss: 0.318\n",
      "Training: Epoch 48, Batch 70, Loss: 0.556\n",
      "Training: Epoch 48, Batch 71, Loss: 0.711\n",
      "Training: Epoch 48, Batch 72, Loss: 0.379\n",
      "Training: Epoch 48, Batch 73, Loss: 0.481\n",
      "Training: Epoch 48, Batch 74, Loss: 0.339\n",
      "Training: Epoch 48, Batch 75, Loss: 0.46\n",
      "Training: Epoch 48, Batch 76, Loss: 0.504\n",
      "Training: Epoch 48, Batch 77, Loss: 0.311\n",
      "Training: Epoch 48, Batch 78, Loss: 0.501\n",
      "Training: Epoch 48, Batch 79, Loss: 0.502\n",
      "Training: Epoch 48, Batch 80, Loss: 0.505\n",
      "Training: Epoch 48, Batch 81, Loss: 0.324\n",
      "Training: Epoch 48, Batch 82, Loss: 0.437\n",
      "Training: Epoch 48, Batch 83, Loss: 0.307\n",
      "Training: Epoch 48, Batch 84, Loss: 0.354\n",
      "Training: Epoch 48, Batch 85, Loss: 0.357\n",
      "Training: Epoch 48, Batch 86, Loss: 0.391\n",
      "Training: Epoch 48, Batch 87, Loss: 0.548\n",
      "Training: Epoch 48, Batch 88, Loss: 0.375\n",
      "Training: Epoch 48, Batch 89, Loss: 0.648\n",
      "Val: Epoch 48, Loss: 0.272\n",
      "Training: Epoch 49, Batch 0, Loss: 0.62\n",
      "Training: Epoch 49, Batch 1, Loss: 0.439\n",
      "Training: Epoch 49, Batch 2, Loss: 0.352\n",
      "Training: Epoch 49, Batch 3, Loss: 0.471\n",
      "Training: Epoch 49, Batch 4, Loss: 0.376\n",
      "Training: Epoch 49, Batch 5, Loss: 0.533\n",
      "Training: Epoch 49, Batch 6, Loss: 0.399\n",
      "Training: Epoch 49, Batch 7, Loss: 0.676\n",
      "Training: Epoch 49, Batch 8, Loss: 0.441\n",
      "Training: Epoch 49, Batch 9, Loss: 0.642\n",
      "Training: Epoch 49, Batch 10, Loss: 0.62\n",
      "Training: Epoch 49, Batch 11, Loss: 0.285\n",
      "Training: Epoch 49, Batch 12, Loss: 0.635\n",
      "Training: Epoch 49, Batch 13, Loss: 0.313\n",
      "Training: Epoch 49, Batch 14, Loss: 0.32\n",
      "Training: Epoch 49, Batch 15, Loss: 0.471\n",
      "Training: Epoch 49, Batch 16, Loss: 0.636\n",
      "Training: Epoch 49, Batch 17, Loss: 0.353\n",
      "Training: Epoch 49, Batch 18, Loss: 0.264\n",
      "Training: Epoch 49, Batch 19, Loss: 0.401\n",
      "Training: Epoch 49, Batch 20, Loss: 0.26\n",
      "Training: Epoch 49, Batch 21, Loss: 0.62\n",
      "Training: Epoch 49, Batch 22, Loss: 0.495\n",
      "Training: Epoch 49, Batch 23, Loss: 0.334\n",
      "Training: Epoch 49, Batch 24, Loss: 0.435\n",
      "Training: Epoch 49, Batch 25, Loss: 0.354\n",
      "Training: Epoch 49, Batch 26, Loss: 0.458\n",
      "Training: Epoch 49, Batch 27, Loss: 0.334\n",
      "Training: Epoch 49, Batch 28, Loss: 0.326\n",
      "Training: Epoch 49, Batch 29, Loss: 0.472\n",
      "Training: Epoch 49, Batch 30, Loss: 0.131\n",
      "Training: Epoch 49, Batch 31, Loss: 0.433\n",
      "Training: Epoch 49, Batch 32, Loss: 0.242\n",
      "Training: Epoch 49, Batch 33, Loss: 0.288\n",
      "Training: Epoch 49, Batch 34, Loss: 0.48\n",
      "Training: Epoch 49, Batch 35, Loss: 0.475\n",
      "Training: Epoch 49, Batch 36, Loss: 0.352\n",
      "Training: Epoch 49, Batch 37, Loss: 0.369\n",
      "Training: Epoch 49, Batch 38, Loss: 0.64\n",
      "Training: Epoch 49, Batch 39, Loss: 0.552\n",
      "Training: Epoch 49, Batch 40, Loss: 0.614\n",
      "Training: Epoch 49, Batch 41, Loss: 0.256\n",
      "Training: Epoch 49, Batch 42, Loss: 0.19\n",
      "Training: Epoch 49, Batch 43, Loss: 0.438\n",
      "Training: Epoch 49, Batch 44, Loss: 0.622\n",
      "Training: Epoch 49, Batch 45, Loss: 0.311\n",
      "Training: Epoch 49, Batch 46, Loss: 0.418\n",
      "Training: Epoch 49, Batch 47, Loss: 0.464\n",
      "Training: Epoch 49, Batch 48, Loss: 0.228\n",
      "Training: Epoch 49, Batch 49, Loss: 0.545\n",
      "Training: Epoch 49, Batch 50, Loss: 0.493\n",
      "Training: Epoch 49, Batch 51, Loss: 0.378\n",
      "Training: Epoch 49, Batch 52, Loss: 0.409\n",
      "Training: Epoch 49, Batch 53, Loss: 0.342\n",
      "Training: Epoch 49, Batch 54, Loss: 0.192\n",
      "Training: Epoch 49, Batch 55, Loss: 0.505\n",
      "Training: Epoch 49, Batch 56, Loss: 0.549\n",
      "Training: Epoch 49, Batch 57, Loss: 0.27\n",
      "Training: Epoch 49, Batch 58, Loss: 0.728\n",
      "Training: Epoch 49, Batch 59, Loss: 0.329\n",
      "Training: Epoch 49, Batch 60, Loss: 0.336\n",
      "Training: Epoch 49, Batch 61, Loss: 0.227\n",
      "Training: Epoch 49, Batch 62, Loss: 0.397\n",
      "Training: Epoch 49, Batch 63, Loss: 0.385\n",
      "Training: Epoch 49, Batch 64, Loss: 0.5\n",
      "Training: Epoch 49, Batch 65, Loss: 0.61\n",
      "Training: Epoch 49, Batch 66, Loss: 0.367\n",
      "Training: Epoch 49, Batch 67, Loss: 0.2\n",
      "Training: Epoch 49, Batch 68, Loss: 0.266\n",
      "Training: Epoch 49, Batch 69, Loss: 0.312\n",
      "Training: Epoch 49, Batch 70, Loss: 0.411\n",
      "Training: Epoch 49, Batch 71, Loss: 0.457\n",
      "Training: Epoch 49, Batch 72, Loss: 0.232\n",
      "Training: Epoch 49, Batch 73, Loss: 0.465\n",
      "Training: Epoch 49, Batch 74, Loss: 0.538\n",
      "Training: Epoch 49, Batch 75, Loss: 0.442\n",
      "Training: Epoch 49, Batch 76, Loss: 0.298\n",
      "Training: Epoch 49, Batch 77, Loss: 0.526\n",
      "Training: Epoch 49, Batch 78, Loss: 0.297\n",
      "Training: Epoch 49, Batch 79, Loss: 0.579\n",
      "Training: Epoch 49, Batch 80, Loss: 0.23\n",
      "Training: Epoch 49, Batch 81, Loss: 0.29\n",
      "Training: Epoch 49, Batch 82, Loss: 0.427\n",
      "Training: Epoch 49, Batch 83, Loss: 0.305\n",
      "Training: Epoch 49, Batch 84, Loss: 0.463\n",
      "Training: Epoch 49, Batch 85, Loss: 0.474\n",
      "Training: Epoch 49, Batch 86, Loss: 0.506\n",
      "Training: Epoch 49, Batch 87, Loss: 0.381\n",
      "Training: Epoch 49, Batch 88, Loss: 0.165\n",
      "Training: Epoch 49, Batch 89, Loss: 0.37\n",
      "Val: Epoch 49, Loss: 0.263\n",
      "Training: Epoch 50, Batch 0, Loss: 0.587\n",
      "Training: Epoch 50, Batch 1, Loss: 0.504\n",
      "Training: Epoch 50, Batch 2, Loss: 0.431\n",
      "Training: Epoch 50, Batch 3, Loss: 0.366\n",
      "Training: Epoch 50, Batch 4, Loss: 0.429\n",
      "Training: Epoch 50, Batch 5, Loss: 0.44\n",
      "Training: Epoch 50, Batch 6, Loss: 0.559\n",
      "Training: Epoch 50, Batch 7, Loss: 0.27\n",
      "Training: Epoch 50, Batch 8, Loss: 0.34\n",
      "Training: Epoch 50, Batch 9, Loss: 0.241\n",
      "Training: Epoch 50, Batch 10, Loss: 0.523\n",
      "Training: Epoch 50, Batch 11, Loss: 0.432\n",
      "Training: Epoch 50, Batch 12, Loss: 0.342\n",
      "Training: Epoch 50, Batch 13, Loss: 0.312\n",
      "Training: Epoch 50, Batch 14, Loss: 0.444\n",
      "Training: Epoch 50, Batch 15, Loss: 0.524\n",
      "Training: Epoch 50, Batch 16, Loss: 0.338\n",
      "Training: Epoch 50, Batch 17, Loss: 0.525\n",
      "Training: Epoch 50, Batch 18, Loss: 0.475\n",
      "Training: Epoch 50, Batch 19, Loss: 0.397\n",
      "Training: Epoch 50, Batch 20, Loss: 0.383\n",
      "Training: Epoch 50, Batch 21, Loss: 0.301\n",
      "Training: Epoch 50, Batch 22, Loss: 0.447\n",
      "Training: Epoch 50, Batch 23, Loss: 0.285\n",
      "Training: Epoch 50, Batch 24, Loss: 0.215\n",
      "Training: Epoch 50, Batch 25, Loss: 0.313\n",
      "Training: Epoch 50, Batch 26, Loss: 0.148\n",
      "Training: Epoch 50, Batch 27, Loss: 0.251\n",
      "Training: Epoch 50, Batch 28, Loss: 0.631\n",
      "Training: Epoch 50, Batch 29, Loss: 0.48\n",
      "Training: Epoch 50, Batch 30, Loss: 0.34\n",
      "Training: Epoch 50, Batch 31, Loss: 0.449\n",
      "Training: Epoch 50, Batch 32, Loss: 0.688\n",
      "Training: Epoch 50, Batch 33, Loss: 0.365\n",
      "Training: Epoch 50, Batch 34, Loss: 0.435\n",
      "Training: Epoch 50, Batch 35, Loss: 0.327\n",
      "Training: Epoch 50, Batch 36, Loss: 0.448\n",
      "Training: Epoch 50, Batch 37, Loss: 0.409\n",
      "Training: Epoch 50, Batch 38, Loss: 0.345\n",
      "Training: Epoch 50, Batch 39, Loss: 0.351\n",
      "Training: Epoch 50, Batch 40, Loss: 0.555\n",
      "Training: Epoch 50, Batch 41, Loss: 0.323\n",
      "Training: Epoch 50, Batch 42, Loss: 0.16\n",
      "Training: Epoch 50, Batch 43, Loss: 0.307\n",
      "Training: Epoch 50, Batch 44, Loss: 0.494\n",
      "Training: Epoch 50, Batch 45, Loss: 0.343\n",
      "Training: Epoch 50, Batch 46, Loss: 0.242\n",
      "Training: Epoch 50, Batch 47, Loss: 0.582\n",
      "Training: Epoch 50, Batch 48, Loss: 0.526\n",
      "Training: Epoch 50, Batch 49, Loss: 0.354\n",
      "Training: Epoch 50, Batch 50, Loss: 0.632\n",
      "Training: Epoch 50, Batch 51, Loss: 0.383\n",
      "Training: Epoch 50, Batch 52, Loss: 0.335\n",
      "Training: Epoch 50, Batch 53, Loss: 0.549\n",
      "Training: Epoch 50, Batch 54, Loss: 0.365\n",
      "Training: Epoch 50, Batch 55, Loss: 0.493\n",
      "Training: Epoch 50, Batch 56, Loss: 0.364\n",
      "Training: Epoch 50, Batch 57, Loss: 0.448\n",
      "Training: Epoch 50, Batch 58, Loss: 0.26\n",
      "Training: Epoch 50, Batch 59, Loss: 0.16\n",
      "Training: Epoch 50, Batch 60, Loss: 0.572\n",
      "Training: Epoch 50, Batch 61, Loss: 0.675\n",
      "Training: Epoch 50, Batch 62, Loss: 0.445\n",
      "Training: Epoch 50, Batch 63, Loss: 0.404\n",
      "Training: Epoch 50, Batch 64, Loss: 0.401\n",
      "Training: Epoch 50, Batch 65, Loss: 0.346\n",
      "Training: Epoch 50, Batch 66, Loss: 0.442\n",
      "Training: Epoch 50, Batch 67, Loss: 0.285\n",
      "Training: Epoch 50, Batch 68, Loss: 0.348\n",
      "Training: Epoch 50, Batch 69, Loss: 0.494\n",
      "Training: Epoch 50, Batch 70, Loss: 0.431\n",
      "Training: Epoch 50, Batch 71, Loss: 0.379\n",
      "Training: Epoch 50, Batch 72, Loss: 0.364\n",
      "Training: Epoch 50, Batch 73, Loss: 0.373\n",
      "Training: Epoch 50, Batch 74, Loss: 0.33\n",
      "Training: Epoch 50, Batch 75, Loss: 0.589\n",
      "Training: Epoch 50, Batch 76, Loss: 0.556\n",
      "Training: Epoch 50, Batch 77, Loss: 0.562\n",
      "Training: Epoch 50, Batch 78, Loss: 0.236\n",
      "Training: Epoch 50, Batch 79, Loss: 0.468\n",
      "Training: Epoch 50, Batch 80, Loss: 0.369\n",
      "Training: Epoch 50, Batch 81, Loss: 0.449\n",
      "Training: Epoch 50, Batch 82, Loss: 0.513\n",
      "Training: Epoch 50, Batch 83, Loss: 0.377\n",
      "Training: Epoch 50, Batch 84, Loss: 0.222\n",
      "Training: Epoch 50, Batch 85, Loss: 0.375\n",
      "Training: Epoch 50, Batch 86, Loss: 0.479\n",
      "Training: Epoch 50, Batch 87, Loss: 0.548\n",
      "Training: Epoch 50, Batch 88, Loss: 0.481\n",
      "Training: Epoch 50, Batch 89, Loss: 0.557\n",
      "Val: Epoch 50, Loss: 0.272\n",
      "Training: Epoch 51, Batch 0, Loss: 0.381\n",
      "Training: Epoch 51, Batch 1, Loss: 0.473\n",
      "Training: Epoch 51, Batch 2, Loss: 0.25\n",
      "Training: Epoch 51, Batch 3, Loss: 0.461\n",
      "Training: Epoch 51, Batch 4, Loss: 0.494\n",
      "Training: Epoch 51, Batch 5, Loss: 0.459\n",
      "Training: Epoch 51, Batch 6, Loss: 0.255\n",
      "Training: Epoch 51, Batch 7, Loss: 0.361\n",
      "Training: Epoch 51, Batch 8, Loss: 0.563\n",
      "Training: Epoch 51, Batch 9, Loss: 0.336\n",
      "Training: Epoch 51, Batch 10, Loss: 0.53\n",
      "Training: Epoch 51, Batch 11, Loss: 0.585\n",
      "Training: Epoch 51, Batch 12, Loss: 0.353\n",
      "Training: Epoch 51, Batch 13, Loss: 0.474\n",
      "Training: Epoch 51, Batch 14, Loss: 0.277\n",
      "Training: Epoch 51, Batch 15, Loss: 0.446\n",
      "Training: Epoch 51, Batch 16, Loss: 0.596\n",
      "Training: Epoch 51, Batch 17, Loss: 0.324\n",
      "Training: Epoch 51, Batch 18, Loss: 0.478\n",
      "Training: Epoch 51, Batch 19, Loss: 0.658\n",
      "Training: Epoch 51, Batch 20, Loss: 0.584\n",
      "Training: Epoch 51, Batch 21, Loss: 0.425\n",
      "Training: Epoch 51, Batch 22, Loss: 0.323\n",
      "Training: Epoch 51, Batch 23, Loss: 0.374\n",
      "Training: Epoch 51, Batch 24, Loss: 0.285\n",
      "Training: Epoch 51, Batch 25, Loss: 0.472\n",
      "Training: Epoch 51, Batch 26, Loss: 0.395\n",
      "Training: Epoch 51, Batch 27, Loss: 0.36\n",
      "Training: Epoch 51, Batch 28, Loss: 0.45\n",
      "Training: Epoch 51, Batch 29, Loss: 0.262\n",
      "Training: Epoch 51, Batch 30, Loss: 0.351\n",
      "Training: Epoch 51, Batch 31, Loss: 0.472\n",
      "Training: Epoch 51, Batch 32, Loss: 0.414\n",
      "Training: Epoch 51, Batch 33, Loss: 0.426\n",
      "Training: Epoch 51, Batch 34, Loss: 0.414\n",
      "Training: Epoch 51, Batch 35, Loss: 0.346\n",
      "Training: Epoch 51, Batch 36, Loss: 0.448\n",
      "Training: Epoch 51, Batch 37, Loss: 0.371\n",
      "Training: Epoch 51, Batch 38, Loss: 0.328\n",
      "Training: Epoch 51, Batch 39, Loss: 0.318\n",
      "Training: Epoch 51, Batch 40, Loss: 0.527\n",
      "Training: Epoch 51, Batch 41, Loss: 0.208\n",
      "Training: Epoch 51, Batch 42, Loss: 0.469\n",
      "Training: Epoch 51, Batch 43, Loss: 0.434\n",
      "Training: Epoch 51, Batch 44, Loss: 0.434\n",
      "Training: Epoch 51, Batch 45, Loss: 0.441\n",
      "Training: Epoch 51, Batch 46, Loss: 0.376\n",
      "Training: Epoch 51, Batch 47, Loss: 0.469\n",
      "Training: Epoch 51, Batch 48, Loss: 0.422\n",
      "Training: Epoch 51, Batch 49, Loss: 0.338\n",
      "Training: Epoch 51, Batch 50, Loss: 0.467\n",
      "Training: Epoch 51, Batch 51, Loss: 0.417\n",
      "Training: Epoch 51, Batch 52, Loss: 0.223\n",
      "Training: Epoch 51, Batch 53, Loss: 0.509\n",
      "Training: Epoch 51, Batch 54, Loss: 0.288\n",
      "Training: Epoch 51, Batch 55, Loss: 0.376\n",
      "Training: Epoch 51, Batch 56, Loss: 0.385\n",
      "Training: Epoch 51, Batch 57, Loss: 0.287\n",
      "Training: Epoch 51, Batch 58, Loss: 0.248\n",
      "Training: Epoch 51, Batch 59, Loss: 0.393\n",
      "Training: Epoch 51, Batch 60, Loss: 0.306\n",
      "Training: Epoch 51, Batch 61, Loss: 0.199\n",
      "Training: Epoch 51, Batch 62, Loss: 0.518\n",
      "Training: Epoch 51, Batch 63, Loss: 0.577\n",
      "Training: Epoch 51, Batch 64, Loss: 0.609\n",
      "Training: Epoch 51, Batch 65, Loss: 0.507\n",
      "Training: Epoch 51, Batch 66, Loss: 0.531\n",
      "Training: Epoch 51, Batch 67, Loss: 0.332\n",
      "Training: Epoch 51, Batch 68, Loss: 0.195\n",
      "Training: Epoch 51, Batch 69, Loss: 0.611\n",
      "Training: Epoch 51, Batch 70, Loss: 0.5\n",
      "Training: Epoch 51, Batch 71, Loss: 0.392\n",
      "Training: Epoch 51, Batch 72, Loss: 0.338\n",
      "Training: Epoch 51, Batch 73, Loss: 0.348\n",
      "Training: Epoch 51, Batch 74, Loss: 0.66\n",
      "Training: Epoch 51, Batch 75, Loss: 0.257\n",
      "Training: Epoch 51, Batch 76, Loss: 0.24\n",
      "Training: Epoch 51, Batch 77, Loss: 0.444\n",
      "Training: Epoch 51, Batch 78, Loss: 0.431\n",
      "Training: Epoch 51, Batch 79, Loss: 0.54\n",
      "Training: Epoch 51, Batch 80, Loss: 0.331\n",
      "Training: Epoch 51, Batch 81, Loss: 0.329\n",
      "Training: Epoch 51, Batch 82, Loss: 0.507\n",
      "Training: Epoch 51, Batch 83, Loss: 0.487\n",
      "Training: Epoch 51, Batch 84, Loss: 0.259\n",
      "Training: Epoch 51, Batch 85, Loss: 0.448\n",
      "Training: Epoch 51, Batch 86, Loss: 0.474\n",
      "Training: Epoch 51, Batch 87, Loss: 0.447\n",
      "Training: Epoch 51, Batch 88, Loss: 0.674\n",
      "Training: Epoch 51, Batch 89, Loss: 0.227\n",
      "Val: Epoch 51, Loss: 0.25\n",
      "Training: Epoch 52, Batch 0, Loss: 0.512\n",
      "Training: Epoch 52, Batch 1, Loss: 0.169\n",
      "Training: Epoch 52, Batch 2, Loss: 0.403\n",
      "Training: Epoch 52, Batch 3, Loss: 0.552\n",
      "Training: Epoch 52, Batch 4, Loss: 0.48\n",
      "Training: Epoch 52, Batch 5, Loss: 0.326\n",
      "Training: Epoch 52, Batch 6, Loss: 0.478\n",
      "Training: Epoch 52, Batch 7, Loss: 0.406\n",
      "Training: Epoch 52, Batch 8, Loss: 0.396\n",
      "Training: Epoch 52, Batch 9, Loss: 0.51\n",
      "Training: Epoch 52, Batch 10, Loss: 0.342\n",
      "Training: Epoch 52, Batch 11, Loss: 0.397\n",
      "Training: Epoch 52, Batch 12, Loss: 0.371\n",
      "Training: Epoch 52, Batch 13, Loss: 0.501\n",
      "Training: Epoch 52, Batch 14, Loss: 0.267\n",
      "Training: Epoch 52, Batch 15, Loss: 0.409\n",
      "Training: Epoch 52, Batch 16, Loss: 0.36\n",
      "Training: Epoch 52, Batch 17, Loss: 0.386\n",
      "Training: Epoch 52, Batch 18, Loss: 0.326\n",
      "Training: Epoch 52, Batch 19, Loss: 0.247\n",
      "Training: Epoch 52, Batch 20, Loss: 0.431\n",
      "Training: Epoch 52, Batch 21, Loss: 0.467\n",
      "Training: Epoch 52, Batch 22, Loss: 0.543\n",
      "Training: Epoch 52, Batch 23, Loss: 0.622\n",
      "Training: Epoch 52, Batch 24, Loss: 0.134\n",
      "Training: Epoch 52, Batch 25, Loss: 0.474\n",
      "Training: Epoch 52, Batch 26, Loss: 0.529\n",
      "Training: Epoch 52, Batch 27, Loss: 0.534\n",
      "Training: Epoch 52, Batch 28, Loss: 0.424\n",
      "Training: Epoch 52, Batch 29, Loss: 0.34\n",
      "Training: Epoch 52, Batch 30, Loss: 0.458\n",
      "Training: Epoch 52, Batch 31, Loss: 0.658\n",
      "Training: Epoch 52, Batch 32, Loss: 0.572\n",
      "Training: Epoch 52, Batch 33, Loss: 0.544\n",
      "Training: Epoch 52, Batch 34, Loss: 0.323\n",
      "Training: Epoch 52, Batch 35, Loss: 0.463\n",
      "Training: Epoch 52, Batch 36, Loss: 0.262\n",
      "Training: Epoch 52, Batch 37, Loss: 0.409\n",
      "Training: Epoch 52, Batch 38, Loss: 0.412\n",
      "Training: Epoch 52, Batch 39, Loss: 0.486\n",
      "Training: Epoch 52, Batch 40, Loss: 0.454\n",
      "Training: Epoch 52, Batch 41, Loss: 0.394\n",
      "Training: Epoch 52, Batch 42, Loss: 0.405\n",
      "Training: Epoch 52, Batch 43, Loss: 0.517\n",
      "Training: Epoch 52, Batch 44, Loss: 0.257\n",
      "Training: Epoch 52, Batch 45, Loss: 0.486\n",
      "Training: Epoch 52, Batch 46, Loss: 0.248\n",
      "Training: Epoch 52, Batch 47, Loss: 0.366\n",
      "Training: Epoch 52, Batch 48, Loss: 0.332\n",
      "Training: Epoch 52, Batch 49, Loss: 0.234\n",
      "Training: Epoch 52, Batch 50, Loss: 0.307\n",
      "Training: Epoch 52, Batch 51, Loss: 0.652\n",
      "Training: Epoch 52, Batch 52, Loss: 0.565\n",
      "Training: Epoch 52, Batch 53, Loss: 0.324\n",
      "Training: Epoch 52, Batch 54, Loss: 0.347\n",
      "Training: Epoch 52, Batch 55, Loss: 0.46\n",
      "Training: Epoch 52, Batch 56, Loss: 0.392\n",
      "Training: Epoch 52, Batch 57, Loss: 0.36\n",
      "Training: Epoch 52, Batch 58, Loss: 0.343\n",
      "Training: Epoch 52, Batch 59, Loss: 0.36\n",
      "Training: Epoch 52, Batch 60, Loss: 0.55\n",
      "Training: Epoch 52, Batch 61, Loss: 0.369\n",
      "Training: Epoch 52, Batch 62, Loss: 0.357\n",
      "Training: Epoch 52, Batch 63, Loss: 0.432\n",
      "Training: Epoch 52, Batch 64, Loss: 0.275\n",
      "Training: Epoch 52, Batch 65, Loss: 0.34\n",
      "Training: Epoch 52, Batch 66, Loss: 0.447\n",
      "Training: Epoch 52, Batch 67, Loss: 0.319\n",
      "Training: Epoch 52, Batch 68, Loss: 0.336\n",
      "Training: Epoch 52, Batch 69, Loss: 0.427\n",
      "Training: Epoch 52, Batch 70, Loss: 0.53\n",
      "Training: Epoch 52, Batch 71, Loss: 0.535\n",
      "Training: Epoch 52, Batch 72, Loss: 0.41\n",
      "Training: Epoch 52, Batch 73, Loss: 0.466\n",
      "Training: Epoch 52, Batch 74, Loss: 0.355\n",
      "Training: Epoch 52, Batch 75, Loss: 0.37\n",
      "Training: Epoch 52, Batch 76, Loss: 0.519\n",
      "Training: Epoch 52, Batch 77, Loss: 0.356\n",
      "Training: Epoch 52, Batch 78, Loss: 0.432\n",
      "Training: Epoch 52, Batch 79, Loss: 0.161\n",
      "Training: Epoch 52, Batch 80, Loss: 0.216\n",
      "Training: Epoch 52, Batch 81, Loss: 0.231\n",
      "Training: Epoch 52, Batch 82, Loss: 0.446\n",
      "Training: Epoch 52, Batch 83, Loss: 0.361\n",
      "Training: Epoch 52, Batch 84, Loss: 0.452\n",
      "Training: Epoch 52, Batch 85, Loss: 0.36\n",
      "Training: Epoch 52, Batch 86, Loss: 0.436\n",
      "Training: Epoch 52, Batch 87, Loss: 0.201\n",
      "Training: Epoch 52, Batch 88, Loss: 0.61\n",
      "Training: Epoch 52, Batch 89, Loss: 0.486\n",
      "Val: Epoch 52, Loss: 0.251\n",
      "Training: Epoch 53, Batch 0, Loss: 0.385\n",
      "Training: Epoch 53, Batch 1, Loss: 0.465\n",
      "Training: Epoch 53, Batch 2, Loss: 0.433\n",
      "Training: Epoch 53, Batch 3, Loss: 0.319\n",
      "Training: Epoch 53, Batch 4, Loss: 0.514\n",
      "Training: Epoch 53, Batch 5, Loss: 0.531\n",
      "Training: Epoch 53, Batch 6, Loss: 0.349\n",
      "Training: Epoch 53, Batch 7, Loss: 0.366\n",
      "Training: Epoch 53, Batch 8, Loss: 0.398\n",
      "Training: Epoch 53, Batch 9, Loss: 0.282\n",
      "Training: Epoch 53, Batch 10, Loss: 0.431\n",
      "Training: Epoch 53, Batch 11, Loss: 0.426\n",
      "Training: Epoch 53, Batch 12, Loss: 0.366\n",
      "Training: Epoch 53, Batch 13, Loss: 0.25\n",
      "Training: Epoch 53, Batch 14, Loss: 0.441\n",
      "Training: Epoch 53, Batch 15, Loss: 0.275\n",
      "Training: Epoch 53, Batch 16, Loss: 0.332\n",
      "Training: Epoch 53, Batch 17, Loss: 0.439\n",
      "Training: Epoch 53, Batch 18, Loss: 0.463\n",
      "Training: Epoch 53, Batch 19, Loss: 0.552\n",
      "Training: Epoch 53, Batch 20, Loss: 0.404\n",
      "Training: Epoch 53, Batch 21, Loss: 0.349\n",
      "Training: Epoch 53, Batch 22, Loss: 0.376\n",
      "Training: Epoch 53, Batch 23, Loss: 0.422\n",
      "Training: Epoch 53, Batch 24, Loss: 0.183\n",
      "Training: Epoch 53, Batch 25, Loss: 0.613\n",
      "Training: Epoch 53, Batch 26, Loss: 0.361\n",
      "Training: Epoch 53, Batch 27, Loss: 0.413\n",
      "Training: Epoch 53, Batch 28, Loss: 0.413\n",
      "Training: Epoch 53, Batch 29, Loss: 0.313\n",
      "Training: Epoch 53, Batch 30, Loss: 0.209\n",
      "Training: Epoch 53, Batch 31, Loss: 0.305\n",
      "Training: Epoch 53, Batch 32, Loss: 0.388\n",
      "Training: Epoch 53, Batch 33, Loss: 0.2\n",
      "Training: Epoch 53, Batch 34, Loss: 0.657\n",
      "Training: Epoch 53, Batch 35, Loss: 0.428\n",
      "Training: Epoch 53, Batch 36, Loss: 0.322\n",
      "Training: Epoch 53, Batch 37, Loss: 0.543\n",
      "Training: Epoch 53, Batch 38, Loss: 0.255\n",
      "Training: Epoch 53, Batch 39, Loss: 0.454\n",
      "Training: Epoch 53, Batch 40, Loss: 0.455\n",
      "Training: Epoch 53, Batch 41, Loss: 0.355\n",
      "Training: Epoch 53, Batch 42, Loss: 0.538\n",
      "Training: Epoch 53, Batch 43, Loss: 0.627\n",
      "Training: Epoch 53, Batch 44, Loss: 0.472\n",
      "Training: Epoch 53, Batch 45, Loss: 0.709\n",
      "Training: Epoch 53, Batch 46, Loss: 0.315\n",
      "Training: Epoch 53, Batch 47, Loss: 0.23\n",
      "Training: Epoch 53, Batch 48, Loss: 0.349\n",
      "Training: Epoch 53, Batch 49, Loss: 0.423\n",
      "Training: Epoch 53, Batch 50, Loss: 0.356\n",
      "Training: Epoch 53, Batch 51, Loss: 0.299\n",
      "Training: Epoch 53, Batch 52, Loss: 0.366\n",
      "Training: Epoch 53, Batch 53, Loss: 0.623\n",
      "Training: Epoch 53, Batch 54, Loss: 0.406\n",
      "Training: Epoch 53, Batch 55, Loss: 0.411\n",
      "Training: Epoch 53, Batch 56, Loss: 0.38\n",
      "Training: Epoch 53, Batch 57, Loss: 0.579\n",
      "Training: Epoch 53, Batch 58, Loss: 0.42\n",
      "Training: Epoch 53, Batch 59, Loss: 0.408\n",
      "Training: Epoch 53, Batch 60, Loss: 0.437\n",
      "Training: Epoch 53, Batch 61, Loss: 0.417\n",
      "Training: Epoch 53, Batch 62, Loss: 0.287\n",
      "Training: Epoch 53, Batch 63, Loss: 0.486\n",
      "Training: Epoch 53, Batch 64, Loss: 0.296\n",
      "Training: Epoch 53, Batch 65, Loss: 0.44\n",
      "Training: Epoch 53, Batch 66, Loss: 0.356\n",
      "Training: Epoch 53, Batch 67, Loss: 0.525\n",
      "Training: Epoch 53, Batch 68, Loss: 0.451\n",
      "Training: Epoch 53, Batch 69, Loss: 0.606\n",
      "Training: Epoch 53, Batch 70, Loss: 0.257\n",
      "Training: Epoch 53, Batch 71, Loss: 0.402\n",
      "Training: Epoch 53, Batch 72, Loss: 0.379\n",
      "Training: Epoch 53, Batch 73, Loss: 0.474\n",
      "Training: Epoch 53, Batch 74, Loss: 0.379\n",
      "Training: Epoch 53, Batch 75, Loss: 0.391\n",
      "Training: Epoch 53, Batch 76, Loss: 0.48\n",
      "Training: Epoch 53, Batch 77, Loss: 0.2\n",
      "Training: Epoch 53, Batch 78, Loss: 0.404\n",
      "Training: Epoch 53, Batch 79, Loss: 0.682\n",
      "Training: Epoch 53, Batch 80, Loss: 0.405\n",
      "Training: Epoch 53, Batch 81, Loss: 0.314\n",
      "Training: Epoch 53, Batch 82, Loss: 0.433\n",
      "Training: Epoch 53, Batch 83, Loss: 0.444\n",
      "Training: Epoch 53, Batch 84, Loss: 0.406\n",
      "Training: Epoch 53, Batch 85, Loss: 0.422\n",
      "Training: Epoch 53, Batch 86, Loss: 0.478\n",
      "Training: Epoch 53, Batch 87, Loss: 0.367\n",
      "Training: Epoch 53, Batch 88, Loss: 0.429\n",
      "Training: Epoch 53, Batch 89, Loss: 0.377\n",
      "Val: Epoch 53, Loss: 0.503\n",
      "Training: Epoch 54, Batch 0, Loss: 0.285\n",
      "Training: Epoch 54, Batch 1, Loss: 0.514\n",
      "Training: Epoch 54, Batch 2, Loss: 0.316\n",
      "Training: Epoch 54, Batch 3, Loss: 0.479\n",
      "Training: Epoch 54, Batch 4, Loss: 0.406\n",
      "Training: Epoch 54, Batch 5, Loss: 0.176\n",
      "Training: Epoch 54, Batch 6, Loss: 0.612\n",
      "Training: Epoch 54, Batch 7, Loss: 0.286\n",
      "Training: Epoch 54, Batch 8, Loss: 0.468\n",
      "Training: Epoch 54, Batch 9, Loss: 0.444\n",
      "Training: Epoch 54, Batch 10, Loss: 0.504\n",
      "Training: Epoch 54, Batch 11, Loss: 0.771\n",
      "Training: Epoch 54, Batch 12, Loss: 0.36\n",
      "Training: Epoch 54, Batch 13, Loss: 0.229\n",
      "Training: Epoch 54, Batch 14, Loss: 0.529\n",
      "Training: Epoch 54, Batch 15, Loss: 0.371\n",
      "Training: Epoch 54, Batch 16, Loss: 0.375\n",
      "Training: Epoch 54, Batch 17, Loss: 0.651\n",
      "Training: Epoch 54, Batch 18, Loss: 0.48\n",
      "Training: Epoch 54, Batch 19, Loss: 0.347\n",
      "Training: Epoch 54, Batch 20, Loss: 0.54\n",
      "Training: Epoch 54, Batch 21, Loss: 0.499\n",
      "Training: Epoch 54, Batch 22, Loss: 0.474\n",
      "Training: Epoch 54, Batch 23, Loss: 0.443\n",
      "Training: Epoch 54, Batch 24, Loss: 0.235\n",
      "Training: Epoch 54, Batch 25, Loss: 0.36\n",
      "Training: Epoch 54, Batch 26, Loss: 0.621\n",
      "Training: Epoch 54, Batch 27, Loss: 0.26\n",
      "Training: Epoch 54, Batch 28, Loss: 0.403\n",
      "Training: Epoch 54, Batch 29, Loss: 0.436\n",
      "Training: Epoch 54, Batch 30, Loss: 0.411\n",
      "Training: Epoch 54, Batch 31, Loss: 0.359\n",
      "Training: Epoch 54, Batch 32, Loss: 0.276\n",
      "Training: Epoch 54, Batch 33, Loss: 0.37\n",
      "Training: Epoch 54, Batch 34, Loss: 0.329\n",
      "Training: Epoch 54, Batch 35, Loss: 0.417\n",
      "Training: Epoch 54, Batch 36, Loss: 0.415\n",
      "Training: Epoch 54, Batch 37, Loss: 0.437\n",
      "Training: Epoch 54, Batch 38, Loss: 0.254\n",
      "Training: Epoch 54, Batch 39, Loss: 0.471\n",
      "Training: Epoch 54, Batch 40, Loss: 0.494\n",
      "Training: Epoch 54, Batch 41, Loss: 0.568\n",
      "Training: Epoch 54, Batch 42, Loss: 0.232\n",
      "Training: Epoch 54, Batch 43, Loss: 0.138\n",
      "Training: Epoch 54, Batch 44, Loss: 0.331\n",
      "Training: Epoch 54, Batch 45, Loss: 0.536\n",
      "Training: Epoch 54, Batch 46, Loss: 0.338\n",
      "Training: Epoch 54, Batch 47, Loss: 0.246\n",
      "Training: Epoch 54, Batch 48, Loss: 0.331\n",
      "Training: Epoch 54, Batch 49, Loss: 0.402\n",
      "Training: Epoch 54, Batch 50, Loss: 0.498\n",
      "Training: Epoch 54, Batch 51, Loss: 0.236\n",
      "Training: Epoch 54, Batch 52, Loss: 0.414\n",
      "Training: Epoch 54, Batch 53, Loss: 0.252\n",
      "Training: Epoch 54, Batch 54, Loss: 0.323\n",
      "Training: Epoch 54, Batch 55, Loss: 0.496\n",
      "Training: Epoch 54, Batch 56, Loss: 0.217\n",
      "Training: Epoch 54, Batch 57, Loss: 0.521\n",
      "Training: Epoch 54, Batch 58, Loss: 0.343\n",
      "Training: Epoch 54, Batch 59, Loss: 0.349\n",
      "Training: Epoch 54, Batch 60, Loss: 0.375\n",
      "Training: Epoch 54, Batch 61, Loss: 0.553\n",
      "Training: Epoch 54, Batch 62, Loss: 0.351\n",
      "Training: Epoch 54, Batch 63, Loss: 0.523\n",
      "Training: Epoch 54, Batch 64, Loss: 0.259\n",
      "Training: Epoch 54, Batch 65, Loss: 0.418\n",
      "Training: Epoch 54, Batch 66, Loss: 0.336\n",
      "Training: Epoch 54, Batch 67, Loss: 0.245\n",
      "Training: Epoch 54, Batch 68, Loss: 0.562\n",
      "Training: Epoch 54, Batch 69, Loss: 0.234\n",
      "Training: Epoch 54, Batch 70, Loss: 0.35\n",
      "Training: Epoch 54, Batch 71, Loss: 0.515\n",
      "Training: Epoch 54, Batch 72, Loss: 0.313\n",
      "Training: Epoch 54, Batch 73, Loss: 0.7\n",
      "Training: Epoch 54, Batch 74, Loss: 0.369\n",
      "Training: Epoch 54, Batch 75, Loss: 0.331\n",
      "Training: Epoch 54, Batch 76, Loss: 0.442\n",
      "Training: Epoch 54, Batch 77, Loss: 0.257\n",
      "Training: Epoch 54, Batch 78, Loss: 0.298\n",
      "Training: Epoch 54, Batch 79, Loss: 0.459\n",
      "Training: Epoch 54, Batch 80, Loss: 0.358\n",
      "Training: Epoch 54, Batch 81, Loss: 0.265\n",
      "Training: Epoch 54, Batch 82, Loss: 0.314\n",
      "Training: Epoch 54, Batch 83, Loss: 0.33\n",
      "Training: Epoch 54, Batch 84, Loss: 0.469\n",
      "Training: Epoch 54, Batch 85, Loss: 0.538\n",
      "Training: Epoch 54, Batch 86, Loss: 0.414\n",
      "Training: Epoch 54, Batch 87, Loss: 0.417\n",
      "Training: Epoch 54, Batch 88, Loss: 0.426\n",
      "Training: Epoch 54, Batch 89, Loss: 0.456\n",
      "Val: Epoch 54, Loss: 0.27\n",
      "Training: Epoch 55, Batch 0, Loss: 0.478\n",
      "Training: Epoch 55, Batch 1, Loss: 0.58\n",
      "Training: Epoch 55, Batch 2, Loss: 0.324\n",
      "Training: Epoch 55, Batch 3, Loss: 0.473\n",
      "Training: Epoch 55, Batch 4, Loss: 0.25\n",
      "Training: Epoch 55, Batch 5, Loss: 0.411\n",
      "Training: Epoch 55, Batch 6, Loss: 0.212\n",
      "Training: Epoch 55, Batch 7, Loss: 0.583\n",
      "Training: Epoch 55, Batch 8, Loss: 0.367\n",
      "Training: Epoch 55, Batch 9, Loss: 0.382\n",
      "Training: Epoch 55, Batch 10, Loss: 0.39\n",
      "Training: Epoch 55, Batch 11, Loss: 0.373\n",
      "Training: Epoch 55, Batch 12, Loss: 0.553\n",
      "Training: Epoch 55, Batch 13, Loss: 0.297\n",
      "Training: Epoch 55, Batch 14, Loss: 0.267\n",
      "Training: Epoch 55, Batch 15, Loss: 0.221\n",
      "Training: Epoch 55, Batch 16, Loss: 0.534\n",
      "Training: Epoch 55, Batch 17, Loss: 0.311\n",
      "Training: Epoch 55, Batch 18, Loss: 0.707\n",
      "Training: Epoch 55, Batch 19, Loss: 0.311\n",
      "Training: Epoch 55, Batch 20, Loss: 0.289\n",
      "Training: Epoch 55, Batch 21, Loss: 0.473\n",
      "Training: Epoch 55, Batch 22, Loss: 0.557\n",
      "Training: Epoch 55, Batch 23, Loss: 0.317\n",
      "Training: Epoch 55, Batch 24, Loss: 0.328\n",
      "Training: Epoch 55, Batch 25, Loss: 0.329\n",
      "Training: Epoch 55, Batch 26, Loss: 0.324\n",
      "Training: Epoch 55, Batch 27, Loss: 0.437\n",
      "Training: Epoch 55, Batch 28, Loss: 0.484\n",
      "Training: Epoch 55, Batch 29, Loss: 0.24\n",
      "Training: Epoch 55, Batch 30, Loss: 0.409\n",
      "Training: Epoch 55, Batch 31, Loss: 0.593\n",
      "Training: Epoch 55, Batch 32, Loss: 0.45\n",
      "Training: Epoch 55, Batch 33, Loss: 0.251\n",
      "Training: Epoch 55, Batch 34, Loss: 0.403\n",
      "Training: Epoch 55, Batch 35, Loss: 0.275\n",
      "Training: Epoch 55, Batch 36, Loss: 0.408\n",
      "Training: Epoch 55, Batch 37, Loss: 0.313\n",
      "Training: Epoch 55, Batch 38, Loss: 0.576\n",
      "Training: Epoch 55, Batch 39, Loss: 0.509\n",
      "Training: Epoch 55, Batch 40, Loss: 0.452\n",
      "Training: Epoch 55, Batch 41, Loss: 0.453\n",
      "Training: Epoch 55, Batch 42, Loss: 0.412\n",
      "Training: Epoch 55, Batch 43, Loss: 0.721\n",
      "Training: Epoch 55, Batch 44, Loss: 0.353\n",
      "Training: Epoch 55, Batch 45, Loss: 0.315\n",
      "Training: Epoch 55, Batch 46, Loss: 0.547\n",
      "Training: Epoch 55, Batch 47, Loss: 0.46\n",
      "Training: Epoch 55, Batch 48, Loss: 0.188\n",
      "Training: Epoch 55, Batch 49, Loss: 0.523\n",
      "Training: Epoch 55, Batch 50, Loss: 0.402\n",
      "Training: Epoch 55, Batch 51, Loss: 0.312\n",
      "Training: Epoch 55, Batch 52, Loss: 0.262\n",
      "Training: Epoch 55, Batch 53, Loss: 0.195\n",
      "Training: Epoch 55, Batch 54, Loss: 0.545\n",
      "Training: Epoch 55, Batch 55, Loss: 0.328\n",
      "Training: Epoch 55, Batch 56, Loss: 0.455\n",
      "Training: Epoch 55, Batch 57, Loss: 0.314\n",
      "Training: Epoch 55, Batch 58, Loss: 0.373\n",
      "Training: Epoch 55, Batch 59, Loss: 0.428\n",
      "Training: Epoch 55, Batch 60, Loss: 0.517\n",
      "Training: Epoch 55, Batch 61, Loss: 0.302\n",
      "Training: Epoch 55, Batch 62, Loss: 0.3\n",
      "Training: Epoch 55, Batch 63, Loss: 0.396\n",
      "Training: Epoch 55, Batch 64, Loss: 0.445\n",
      "Training: Epoch 55, Batch 65, Loss: 0.434\n",
      "Training: Epoch 55, Batch 66, Loss: 0.473\n",
      "Training: Epoch 55, Batch 67, Loss: 0.405\n",
      "Training: Epoch 55, Batch 68, Loss: 0.154\n",
      "Training: Epoch 55, Batch 69, Loss: 0.259\n",
      "Training: Epoch 55, Batch 70, Loss: 0.471\n",
      "Training: Epoch 55, Batch 71, Loss: 0.496\n",
      "Training: Epoch 55, Batch 72, Loss: 0.444\n",
      "Training: Epoch 55, Batch 73, Loss: 0.458\n",
      "Training: Epoch 55, Batch 74, Loss: 0.51\n",
      "Training: Epoch 55, Batch 75, Loss: 0.498\n",
      "Training: Epoch 55, Batch 76, Loss: 0.492\n",
      "Training: Epoch 55, Batch 77, Loss: 0.543\n",
      "Training: Epoch 55, Batch 78, Loss: 0.314\n",
      "Training: Epoch 55, Batch 79, Loss: 0.474\n",
      "Training: Epoch 55, Batch 80, Loss: 0.342\n",
      "Training: Epoch 55, Batch 81, Loss: 0.602\n",
      "Training: Epoch 55, Batch 82, Loss: 0.321\n",
      "Training: Epoch 55, Batch 83, Loss: 0.406\n",
      "Training: Epoch 55, Batch 84, Loss: 0.452\n",
      "Training: Epoch 55, Batch 85, Loss: 0.326\n",
      "Training: Epoch 55, Batch 86, Loss: 0.503\n",
      "Training: Epoch 55, Batch 87, Loss: 0.279\n",
      "Training: Epoch 55, Batch 88, Loss: 0.425\n",
      "Training: Epoch 55, Batch 89, Loss: 0.599\n",
      "Val: Epoch 55, Loss: 0.241\n",
      "Training: Epoch 56, Batch 0, Loss: 0.431\n",
      "Training: Epoch 56, Batch 1, Loss: 0.392\n",
      "Training: Epoch 56, Batch 2, Loss: 0.246\n",
      "Training: Epoch 56, Batch 3, Loss: 0.356\n",
      "Training: Epoch 56, Batch 4, Loss: 0.375\n",
      "Training: Epoch 56, Batch 5, Loss: 0.494\n",
      "Training: Epoch 56, Batch 6, Loss: 0.347\n",
      "Training: Epoch 56, Batch 7, Loss: 0.236\n",
      "Training: Epoch 56, Batch 8, Loss: 0.462\n",
      "Training: Epoch 56, Batch 9, Loss: 0.297\n",
      "Training: Epoch 56, Batch 10, Loss: 0.622\n",
      "Training: Epoch 56, Batch 11, Loss: 0.263\n",
      "Training: Epoch 56, Batch 12, Loss: 0.423\n",
      "Training: Epoch 56, Batch 13, Loss: 0.444\n",
      "Training: Epoch 56, Batch 14, Loss: 0.442\n",
      "Training: Epoch 56, Batch 15, Loss: 0.176\n",
      "Training: Epoch 56, Batch 16, Loss: 0.808\n",
      "Training: Epoch 56, Batch 17, Loss: 0.361\n",
      "Training: Epoch 56, Batch 18, Loss: 0.547\n",
      "Training: Epoch 56, Batch 19, Loss: 0.365\n",
      "Training: Epoch 56, Batch 20, Loss: 0.486\n",
      "Training: Epoch 56, Batch 21, Loss: 0.493\n",
      "Training: Epoch 56, Batch 22, Loss: 0.368\n",
      "Training: Epoch 56, Batch 23, Loss: 0.444\n",
      "Training: Epoch 56, Batch 24, Loss: 0.345\n",
      "Training: Epoch 56, Batch 25, Loss: 0.596\n",
      "Training: Epoch 56, Batch 26, Loss: 0.638\n",
      "Training: Epoch 56, Batch 27, Loss: 0.335\n",
      "Training: Epoch 56, Batch 28, Loss: 0.331\n",
      "Training: Epoch 56, Batch 29, Loss: 0.468\n",
      "Training: Epoch 56, Batch 30, Loss: 0.364\n",
      "Training: Epoch 56, Batch 31, Loss: 0.437\n",
      "Training: Epoch 56, Batch 32, Loss: 0.405\n",
      "Training: Epoch 56, Batch 33, Loss: 0.407\n",
      "Training: Epoch 56, Batch 34, Loss: 0.246\n",
      "Training: Epoch 56, Batch 35, Loss: 0.231\n",
      "Training: Epoch 56, Batch 36, Loss: 0.354\n",
      "Training: Epoch 56, Batch 37, Loss: 0.442\n",
      "Training: Epoch 56, Batch 38, Loss: 0.348\n",
      "Training: Epoch 56, Batch 39, Loss: 0.364\n",
      "Training: Epoch 56, Batch 40, Loss: 0.33\n",
      "Training: Epoch 56, Batch 41, Loss: 0.45\n",
      "Training: Epoch 56, Batch 42, Loss: 0.621\n",
      "Training: Epoch 56, Batch 43, Loss: 0.473\n",
      "Training: Epoch 56, Batch 44, Loss: 0.249\n",
      "Training: Epoch 56, Batch 45, Loss: 0.437\n",
      "Training: Epoch 56, Batch 46, Loss: 0.363\n",
      "Training: Epoch 56, Batch 47, Loss: 0.466\n",
      "Training: Epoch 56, Batch 48, Loss: 0.674\n",
      "Training: Epoch 56, Batch 49, Loss: 0.258\n",
      "Training: Epoch 56, Batch 50, Loss: 0.169\n",
      "Training: Epoch 56, Batch 51, Loss: 0.533\n",
      "Training: Epoch 56, Batch 52, Loss: 0.296\n",
      "Training: Epoch 56, Batch 53, Loss: 0.471\n",
      "Training: Epoch 56, Batch 54, Loss: 0.395\n",
      "Training: Epoch 56, Batch 55, Loss: 0.194\n",
      "Training: Epoch 56, Batch 56, Loss: 0.506\n",
      "Training: Epoch 56, Batch 57, Loss: 0.232\n",
      "Training: Epoch 56, Batch 58, Loss: 0.4\n",
      "Training: Epoch 56, Batch 59, Loss: 0.252\n",
      "Training: Epoch 56, Batch 60, Loss: 0.377\n",
      "Training: Epoch 56, Batch 61, Loss: 0.414\n",
      "Training: Epoch 56, Batch 62, Loss: 0.313\n",
      "Training: Epoch 56, Batch 63, Loss: 0.283\n",
      "Training: Epoch 56, Batch 64, Loss: 0.512\n",
      "Training: Epoch 56, Batch 65, Loss: 0.369\n",
      "Training: Epoch 56, Batch 66, Loss: 0.331\n",
      "Training: Epoch 56, Batch 67, Loss: 0.303\n",
      "Training: Epoch 56, Batch 68, Loss: 0.45\n",
      "Training: Epoch 56, Batch 69, Loss: 0.404\n",
      "Training: Epoch 56, Batch 70, Loss: 0.615\n",
      "Training: Epoch 56, Batch 71, Loss: 0.458\n",
      "Training: Epoch 56, Batch 72, Loss: 0.317\n",
      "Training: Epoch 56, Batch 73, Loss: 0.283\n",
      "Training: Epoch 56, Batch 74, Loss: 0.379\n",
      "Training: Epoch 56, Batch 75, Loss: 0.551\n",
      "Training: Epoch 56, Batch 76, Loss: 0.443\n",
      "Training: Epoch 56, Batch 77, Loss: 0.447\n",
      "Training: Epoch 56, Batch 78, Loss: 0.32\n",
      "Training: Epoch 56, Batch 79, Loss: 0.346\n",
      "Training: Epoch 56, Batch 80, Loss: 0.325\n",
      "Training: Epoch 56, Batch 81, Loss: 0.442\n",
      "Training: Epoch 56, Batch 82, Loss: 0.631\n",
      "Training: Epoch 56, Batch 83, Loss: 0.35\n",
      "Training: Epoch 56, Batch 84, Loss: 0.41\n",
      "Training: Epoch 56, Batch 85, Loss: 0.402\n",
      "Training: Epoch 56, Batch 86, Loss: 0.258\n",
      "Training: Epoch 56, Batch 87, Loss: 0.372\n",
      "Training: Epoch 56, Batch 88, Loss: 0.424\n",
      "Training: Epoch 56, Batch 89, Loss: 0.284\n",
      "Val: Epoch 56, Loss: 0.262\n",
      "Training: Epoch 57, Batch 0, Loss: 0.444\n",
      "Training: Epoch 57, Batch 1, Loss: 0.446\n",
      "Training: Epoch 57, Batch 2, Loss: 0.244\n",
      "Training: Epoch 57, Batch 3, Loss: 0.519\n",
      "Training: Epoch 57, Batch 4, Loss: 0.249\n",
      "Training: Epoch 57, Batch 5, Loss: 0.485\n",
      "Training: Epoch 57, Batch 6, Loss: 0.487\n",
      "Training: Epoch 57, Batch 7, Loss: 0.447\n",
      "Training: Epoch 57, Batch 8, Loss: 0.256\n",
      "Training: Epoch 57, Batch 9, Loss: 0.371\n",
      "Training: Epoch 57, Batch 10, Loss: 0.254\n",
      "Training: Epoch 57, Batch 11, Loss: 0.24\n",
      "Training: Epoch 57, Batch 12, Loss: 0.427\n",
      "Training: Epoch 57, Batch 13, Loss: 0.491\n",
      "Training: Epoch 57, Batch 14, Loss: 0.236\n",
      "Training: Epoch 57, Batch 15, Loss: 0.393\n",
      "Training: Epoch 57, Batch 16, Loss: 0.363\n",
      "Training: Epoch 57, Batch 17, Loss: 0.511\n",
      "Training: Epoch 57, Batch 18, Loss: 0.317\n",
      "Training: Epoch 57, Batch 19, Loss: 0.445\n",
      "Training: Epoch 57, Batch 20, Loss: 0.217\n",
      "Training: Epoch 57, Batch 21, Loss: 0.646\n",
      "Training: Epoch 57, Batch 22, Loss: 0.39\n",
      "Training: Epoch 57, Batch 23, Loss: 0.355\n",
      "Training: Epoch 57, Batch 24, Loss: 0.404\n",
      "Training: Epoch 57, Batch 25, Loss: 0.437\n",
      "Training: Epoch 57, Batch 26, Loss: 0.54\n",
      "Training: Epoch 57, Batch 27, Loss: 0.228\n",
      "Training: Epoch 57, Batch 28, Loss: 0.305\n",
      "Training: Epoch 57, Batch 29, Loss: 0.442\n",
      "Training: Epoch 57, Batch 30, Loss: 0.323\n",
      "Training: Epoch 57, Batch 31, Loss: 0.616\n",
      "Training: Epoch 57, Batch 32, Loss: 0.356\n",
      "Training: Epoch 57, Batch 33, Loss: 0.383\n",
      "Training: Epoch 57, Batch 34, Loss: 0.42\n",
      "Training: Epoch 57, Batch 35, Loss: 0.513\n",
      "Training: Epoch 57, Batch 36, Loss: 0.491\n",
      "Training: Epoch 57, Batch 37, Loss: 0.523\n",
      "Training: Epoch 57, Batch 38, Loss: 0.228\n",
      "Training: Epoch 57, Batch 39, Loss: 0.285\n",
      "Training: Epoch 57, Batch 40, Loss: 0.446\n",
      "Training: Epoch 57, Batch 41, Loss: 0.412\n",
      "Training: Epoch 57, Batch 42, Loss: 0.489\n",
      "Training: Epoch 57, Batch 43, Loss: 0.162\n",
      "Training: Epoch 57, Batch 44, Loss: 0.343\n",
      "Training: Epoch 57, Batch 45, Loss: 0.264\n",
      "Training: Epoch 57, Batch 46, Loss: 0.247\n",
      "Training: Epoch 57, Batch 47, Loss: 0.478\n",
      "Training: Epoch 57, Batch 48, Loss: 0.417\n",
      "Training: Epoch 57, Batch 49, Loss: 0.43\n",
      "Training: Epoch 57, Batch 50, Loss: 0.592\n",
      "Training: Epoch 57, Batch 51, Loss: 0.348\n",
      "Training: Epoch 57, Batch 52, Loss: 0.452\n",
      "Training: Epoch 57, Batch 53, Loss: 0.45\n",
      "Training: Epoch 57, Batch 54, Loss: 0.608\n",
      "Training: Epoch 57, Batch 55, Loss: 0.392\n",
      "Training: Epoch 57, Batch 56, Loss: 0.427\n",
      "Training: Epoch 57, Batch 57, Loss: 0.509\n",
      "Training: Epoch 57, Batch 58, Loss: 0.322\n",
      "Training: Epoch 57, Batch 59, Loss: 0.449\n",
      "Training: Epoch 57, Batch 60, Loss: 0.438\n",
      "Training: Epoch 57, Batch 61, Loss: 0.311\n",
      "Training: Epoch 57, Batch 62, Loss: 0.326\n",
      "Training: Epoch 57, Batch 63, Loss: 0.392\n",
      "Training: Epoch 57, Batch 64, Loss: 0.293\n",
      "Training: Epoch 57, Batch 65, Loss: 0.547\n",
      "Training: Epoch 57, Batch 66, Loss: 0.361\n",
      "Training: Epoch 57, Batch 67, Loss: 0.564\n",
      "Training: Epoch 57, Batch 68, Loss: 0.41\n",
      "Training: Epoch 57, Batch 69, Loss: 0.283\n",
      "Training: Epoch 57, Batch 70, Loss: 0.53\n",
      "Training: Epoch 57, Batch 71, Loss: 0.303\n",
      "Training: Epoch 57, Batch 72, Loss: 0.308\n",
      "Training: Epoch 57, Batch 73, Loss: 0.152\n",
      "Training: Epoch 57, Batch 74, Loss: 0.283\n",
      "Training: Epoch 57, Batch 75, Loss: 0.232\n",
      "Training: Epoch 57, Batch 76, Loss: 0.358\n",
      "Training: Epoch 57, Batch 77, Loss: 0.756\n",
      "Training: Epoch 57, Batch 78, Loss: 0.247\n",
      "Training: Epoch 57, Batch 79, Loss: 0.342\n",
      "Training: Epoch 57, Batch 80, Loss: 0.37\n",
      "Training: Epoch 57, Batch 81, Loss: 0.192\n",
      "Training: Epoch 57, Batch 82, Loss: 0.446\n",
      "Training: Epoch 57, Batch 83, Loss: 0.41\n",
      "Training: Epoch 57, Batch 84, Loss: 0.322\n",
      "Training: Epoch 57, Batch 85, Loss: 0.472\n",
      "Training: Epoch 57, Batch 86, Loss: 0.474\n",
      "Training: Epoch 57, Batch 87, Loss: 0.241\n",
      "Training: Epoch 57, Batch 88, Loss: 0.318\n",
      "Training: Epoch 57, Batch 89, Loss: 0.537\n",
      "Val: Epoch 57, Loss: 0.258\n",
      "Training: Epoch 58, Batch 0, Loss: 0.505\n",
      "Training: Epoch 58, Batch 1, Loss: 0.586\n",
      "Training: Epoch 58, Batch 2, Loss: 0.254\n",
      "Training: Epoch 58, Batch 3, Loss: 0.512\n",
      "Training: Epoch 58, Batch 4, Loss: 0.465\n",
      "Training: Epoch 58, Batch 5, Loss: 0.236\n",
      "Training: Epoch 58, Batch 6, Loss: 0.477\n",
      "Training: Epoch 58, Batch 7, Loss: 0.317\n",
      "Training: Epoch 58, Batch 8, Loss: 0.212\n",
      "Training: Epoch 58, Batch 9, Loss: 0.309\n",
      "Training: Epoch 58, Batch 10, Loss: 0.249\n",
      "Training: Epoch 58, Batch 11, Loss: 0.345\n",
      "Training: Epoch 58, Batch 12, Loss: 0.346\n",
      "Training: Epoch 58, Batch 13, Loss: 0.32\n",
      "Training: Epoch 58, Batch 14, Loss: 0.313\n",
      "Training: Epoch 58, Batch 15, Loss: 0.459\n",
      "Training: Epoch 58, Batch 16, Loss: 0.32\n",
      "Training: Epoch 58, Batch 17, Loss: 0.311\n",
      "Training: Epoch 58, Batch 18, Loss: 0.236\n",
      "Training: Epoch 58, Batch 19, Loss: 0.492\n",
      "Training: Epoch 58, Batch 20, Loss: 0.381\n",
      "Training: Epoch 58, Batch 21, Loss: 0.366\n",
      "Training: Epoch 58, Batch 22, Loss: 0.646\n",
      "Training: Epoch 58, Batch 23, Loss: 0.382\n",
      "Training: Epoch 58, Batch 24, Loss: 0.325\n",
      "Training: Epoch 58, Batch 25, Loss: 0.55\n",
      "Training: Epoch 58, Batch 26, Loss: 0.366\n",
      "Training: Epoch 58, Batch 27, Loss: 0.451\n",
      "Training: Epoch 58, Batch 28, Loss: 0.371\n",
      "Training: Epoch 58, Batch 29, Loss: 0.437\n",
      "Training: Epoch 58, Batch 30, Loss: 0.309\n",
      "Training: Epoch 58, Batch 31, Loss: 0.557\n",
      "Training: Epoch 58, Batch 32, Loss: 0.515\n",
      "Training: Epoch 58, Batch 33, Loss: 0.346\n",
      "Training: Epoch 58, Batch 34, Loss: 0.513\n",
      "Training: Epoch 58, Batch 35, Loss: 0.406\n",
      "Training: Epoch 58, Batch 36, Loss: 0.305\n",
      "Training: Epoch 58, Batch 37, Loss: 0.446\n",
      "Training: Epoch 58, Batch 38, Loss: 0.217\n",
      "Training: Epoch 58, Batch 39, Loss: 0.424\n",
      "Training: Epoch 58, Batch 40, Loss: 0.683\n",
      "Training: Epoch 58, Batch 41, Loss: 0.45\n",
      "Training: Epoch 58, Batch 42, Loss: 0.365\n",
      "Training: Epoch 58, Batch 43, Loss: 0.482\n",
      "Training: Epoch 58, Batch 44, Loss: 0.238\n",
      "Training: Epoch 58, Batch 45, Loss: 0.321\n",
      "Training: Epoch 58, Batch 46, Loss: 0.56\n",
      "Training: Epoch 58, Batch 47, Loss: 0.397\n",
      "Training: Epoch 58, Batch 48, Loss: 0.538\n",
      "Training: Epoch 58, Batch 49, Loss: 0.466\n",
      "Training: Epoch 58, Batch 50, Loss: 0.251\n",
      "Training: Epoch 58, Batch 51, Loss: 0.358\n",
      "Training: Epoch 58, Batch 52, Loss: 0.503\n",
      "Training: Epoch 58, Batch 53, Loss: 0.512\n",
      "Training: Epoch 58, Batch 54, Loss: 0.391\n",
      "Training: Epoch 58, Batch 55, Loss: 0.458\n",
      "Training: Epoch 58, Batch 56, Loss: 0.333\n",
      "Training: Epoch 58, Batch 57, Loss: 0.479\n",
      "Training: Epoch 58, Batch 58, Loss: 0.443\n",
      "Training: Epoch 58, Batch 59, Loss: 0.27\n",
      "Training: Epoch 58, Batch 60, Loss: 0.166\n",
      "Training: Epoch 58, Batch 61, Loss: 0.371\n",
      "Training: Epoch 58, Batch 62, Loss: 0.384\n",
      "Training: Epoch 58, Batch 63, Loss: 0.42\n",
      "Training: Epoch 58, Batch 64, Loss: 0.43\n",
      "Training: Epoch 58, Batch 65, Loss: 0.221\n",
      "Training: Epoch 58, Batch 66, Loss: 0.432\n",
      "Training: Epoch 58, Batch 67, Loss: 0.494\n",
      "Training: Epoch 58, Batch 68, Loss: 0.465\n",
      "Training: Epoch 58, Batch 69, Loss: 0.583\n",
      "Training: Epoch 58, Batch 70, Loss: 0.29\n",
      "Training: Epoch 58, Batch 71, Loss: 0.374\n",
      "Training: Epoch 58, Batch 72, Loss: 0.267\n",
      "Training: Epoch 58, Batch 73, Loss: 0.638\n",
      "Training: Epoch 58, Batch 74, Loss: 0.503\n",
      "Training: Epoch 58, Batch 75, Loss: 0.336\n",
      "Training: Epoch 58, Batch 76, Loss: 0.248\n",
      "Training: Epoch 58, Batch 77, Loss: 0.456\n",
      "Training: Epoch 58, Batch 78, Loss: 0.193\n",
      "Training: Epoch 58, Batch 79, Loss: 0.434\n",
      "Training: Epoch 58, Batch 80, Loss: 0.361\n",
      "Training: Epoch 58, Batch 81, Loss: 0.407\n",
      "Training: Epoch 58, Batch 82, Loss: 0.442\n",
      "Training: Epoch 58, Batch 83, Loss: 0.321\n",
      "Training: Epoch 58, Batch 84, Loss: 0.489\n",
      "Training: Epoch 58, Batch 85, Loss: 0.43\n",
      "Training: Epoch 58, Batch 86, Loss: 0.381\n",
      "Training: Epoch 58, Batch 87, Loss: 0.302\n",
      "Training: Epoch 58, Batch 88, Loss: 0.378\n",
      "Training: Epoch 58, Batch 89, Loss: 0.348\n",
      "Val: Epoch 58, Loss: 0.305\n",
      "Training: Epoch 59, Batch 0, Loss: 0.25\n",
      "Training: Epoch 59, Batch 1, Loss: 0.648\n",
      "Training: Epoch 59, Batch 2, Loss: 0.364\n",
      "Training: Epoch 59, Batch 3, Loss: 0.448\n",
      "Training: Epoch 59, Batch 4, Loss: 0.404\n",
      "Training: Epoch 59, Batch 5, Loss: 0.25\n",
      "Training: Epoch 59, Batch 6, Loss: 0.196\n",
      "Training: Epoch 59, Batch 7, Loss: 0.593\n",
      "Training: Epoch 59, Batch 8, Loss: 0.233\n",
      "Training: Epoch 59, Batch 9, Loss: 0.456\n",
      "Training: Epoch 59, Batch 10, Loss: 0.263\n",
      "Training: Epoch 59, Batch 11, Loss: 0.216\n",
      "Training: Epoch 59, Batch 12, Loss: 0.581\n",
      "Training: Epoch 59, Batch 13, Loss: 0.261\n",
      "Training: Epoch 59, Batch 14, Loss: 0.361\n",
      "Training: Epoch 59, Batch 15, Loss: 0.353\n",
      "Training: Epoch 59, Batch 16, Loss: 0.232\n",
      "Training: Epoch 59, Batch 17, Loss: 0.437\n",
      "Training: Epoch 59, Batch 18, Loss: 0.31\n",
      "Training: Epoch 59, Batch 19, Loss: 0.552\n",
      "Training: Epoch 59, Batch 20, Loss: 0.421\n",
      "Training: Epoch 59, Batch 21, Loss: 0.349\n",
      "Training: Epoch 59, Batch 22, Loss: 0.394\n",
      "Training: Epoch 59, Batch 23, Loss: 0.663\n",
      "Training: Epoch 59, Batch 24, Loss: 0.406\n",
      "Training: Epoch 59, Batch 25, Loss: 0.291\n",
      "Training: Epoch 59, Batch 26, Loss: 0.304\n",
      "Training: Epoch 59, Batch 27, Loss: 0.331\n",
      "Training: Epoch 59, Batch 28, Loss: 0.483\n",
      "Training: Epoch 59, Batch 29, Loss: 0.227\n",
      "Training: Epoch 59, Batch 30, Loss: 0.322\n",
      "Training: Epoch 59, Batch 31, Loss: 0.228\n",
      "Training: Epoch 59, Batch 32, Loss: 0.418\n",
      "Training: Epoch 59, Batch 33, Loss: 0.378\n",
      "Training: Epoch 59, Batch 34, Loss: 0.551\n",
      "Training: Epoch 59, Batch 35, Loss: 0.436\n",
      "Training: Epoch 59, Batch 36, Loss: 0.514\n",
      "Training: Epoch 59, Batch 37, Loss: 0.401\n",
      "Training: Epoch 59, Batch 38, Loss: 0.415\n",
      "Training: Epoch 59, Batch 39, Loss: 0.404\n",
      "Training: Epoch 59, Batch 40, Loss: 0.305\n",
      "Training: Epoch 59, Batch 41, Loss: 0.387\n",
      "Training: Epoch 59, Batch 42, Loss: 0.472\n",
      "Training: Epoch 59, Batch 43, Loss: 0.431\n",
      "Training: Epoch 59, Batch 44, Loss: 0.557\n",
      "Training: Epoch 59, Batch 45, Loss: 0.436\n",
      "Training: Epoch 59, Batch 46, Loss: 0.462\n",
      "Training: Epoch 59, Batch 47, Loss: 0.33\n",
      "Training: Epoch 59, Batch 48, Loss: 0.481\n",
      "Training: Epoch 59, Batch 49, Loss: 0.387\n",
      "Training: Epoch 59, Batch 50, Loss: 0.524\n",
      "Training: Epoch 59, Batch 51, Loss: 0.754\n",
      "Training: Epoch 59, Batch 52, Loss: 0.633\n",
      "Training: Epoch 59, Batch 53, Loss: 0.224\n",
      "Training: Epoch 59, Batch 54, Loss: 0.312\n",
      "Training: Epoch 59, Batch 55, Loss: 0.266\n",
      "Training: Epoch 59, Batch 56, Loss: 0.521\n",
      "Training: Epoch 59, Batch 57, Loss: 0.404\n",
      "Training: Epoch 59, Batch 58, Loss: 0.369\n",
      "Training: Epoch 59, Batch 59, Loss: 0.596\n",
      "Training: Epoch 59, Batch 60, Loss: 0.311\n",
      "Training: Epoch 59, Batch 61, Loss: 0.381\n",
      "Training: Epoch 59, Batch 62, Loss: 0.599\n",
      "Training: Epoch 59, Batch 63, Loss: 0.249\n",
      "Training: Epoch 59, Batch 64, Loss: 0.355\n",
      "Training: Epoch 59, Batch 65, Loss: 0.334\n",
      "Training: Epoch 59, Batch 66, Loss: 0.447\n",
      "Training: Epoch 59, Batch 67, Loss: 0.307\n",
      "Training: Epoch 59, Batch 68, Loss: 0.231\n",
      "Training: Epoch 59, Batch 69, Loss: 0.203\n",
      "Training: Epoch 59, Batch 70, Loss: 0.317\n",
      "Training: Epoch 59, Batch 71, Loss: 0.297\n",
      "Training: Epoch 59, Batch 72, Loss: 0.534\n",
      "Training: Epoch 59, Batch 73, Loss: 0.413\n",
      "Training: Epoch 59, Batch 74, Loss: 0.492\n",
      "Training: Epoch 59, Batch 75, Loss: 0.294\n",
      "Training: Epoch 59, Batch 76, Loss: 0.377\n",
      "Training: Epoch 59, Batch 77, Loss: 0.497\n",
      "Training: Epoch 59, Batch 78, Loss: 0.421\n",
      "Training: Epoch 59, Batch 79, Loss: 0.351\n",
      "Training: Epoch 59, Batch 80, Loss: 0.334\n",
      "Training: Epoch 59, Batch 81, Loss: 0.409\n",
      "Training: Epoch 59, Batch 82, Loss: 0.422\n",
      "Training: Epoch 59, Batch 83, Loss: 0.284\n",
      "Training: Epoch 59, Batch 84, Loss: 0.368\n",
      "Training: Epoch 59, Batch 85, Loss: 0.461\n",
      "Training: Epoch 59, Batch 86, Loss: 0.364\n",
      "Training: Epoch 59, Batch 87, Loss: 0.272\n",
      "Training: Epoch 59, Batch 88, Loss: 0.238\n",
      "Training: Epoch 59, Batch 89, Loss: 0.5\n",
      "Val: Epoch 59, Loss: 0.297\n",
      "Training: Epoch 60, Batch 0, Loss: 0.551\n",
      "Training: Epoch 60, Batch 1, Loss: 0.328\n",
      "Training: Epoch 60, Batch 2, Loss: 0.379\n",
      "Training: Epoch 60, Batch 3, Loss: 0.499\n",
      "Training: Epoch 60, Batch 4, Loss: 0.508\n",
      "Training: Epoch 60, Batch 5, Loss: 0.363\n",
      "Training: Epoch 60, Batch 6, Loss: 0.546\n",
      "Training: Epoch 60, Batch 7, Loss: 0.536\n",
      "Training: Epoch 60, Batch 8, Loss: 0.559\n",
      "Training: Epoch 60, Batch 9, Loss: 0.415\n",
      "Training: Epoch 60, Batch 10, Loss: 0.222\n",
      "Training: Epoch 60, Batch 11, Loss: 0.334\n",
      "Training: Epoch 60, Batch 12, Loss: 0.156\n",
      "Training: Epoch 60, Batch 13, Loss: 0.241\n",
      "Training: Epoch 60, Batch 14, Loss: 0.394\n",
      "Training: Epoch 60, Batch 15, Loss: 0.547\n",
      "Training: Epoch 60, Batch 16, Loss: 0.793\n",
      "Training: Epoch 60, Batch 17, Loss: 0.331\n",
      "Training: Epoch 60, Batch 18, Loss: 0.439\n",
      "Training: Epoch 60, Batch 19, Loss: 0.554\n",
      "Training: Epoch 60, Batch 20, Loss: 0.544\n",
      "Training: Epoch 60, Batch 21, Loss: 0.419\n",
      "Training: Epoch 60, Batch 22, Loss: 0.594\n",
      "Training: Epoch 60, Batch 23, Loss: 0.526\n",
      "Training: Epoch 60, Batch 24, Loss: 0.372\n",
      "Training: Epoch 60, Batch 25, Loss: 0.467\n",
      "Training: Epoch 60, Batch 26, Loss: 0.461\n",
      "Training: Epoch 60, Batch 27, Loss: 0.401\n",
      "Training: Epoch 60, Batch 28, Loss: 0.428\n",
      "Training: Epoch 60, Batch 29, Loss: 0.699\n",
      "Training: Epoch 60, Batch 30, Loss: 0.418\n",
      "Training: Epoch 60, Batch 31, Loss: 0.444\n",
      "Training: Epoch 60, Batch 32, Loss: 0.255\n",
      "Training: Epoch 60, Batch 33, Loss: 0.224\n",
      "Training: Epoch 60, Batch 34, Loss: 0.401\n",
      "Training: Epoch 60, Batch 35, Loss: 0.382\n",
      "Training: Epoch 60, Batch 36, Loss: 0.461\n",
      "Training: Epoch 60, Batch 37, Loss: 0.565\n",
      "Training: Epoch 60, Batch 38, Loss: 0.589\n",
      "Training: Epoch 60, Batch 39, Loss: 0.496\n",
      "Training: Epoch 60, Batch 40, Loss: 0.361\n",
      "Training: Epoch 60, Batch 41, Loss: 0.467\n",
      "Training: Epoch 60, Batch 42, Loss: 0.652\n",
      "Training: Epoch 60, Batch 43, Loss: 0.472\n",
      "Training: Epoch 60, Batch 44, Loss: 0.36\n",
      "Training: Epoch 60, Batch 45, Loss: 0.307\n",
      "Training: Epoch 60, Batch 46, Loss: 0.295\n",
      "Training: Epoch 60, Batch 47, Loss: 0.206\n",
      "Training: Epoch 60, Batch 48, Loss: 0.27\n",
      "Training: Epoch 60, Batch 49, Loss: 0.226\n",
      "Training: Epoch 60, Batch 50, Loss: 0.438\n",
      "Training: Epoch 60, Batch 51, Loss: 0.628\n",
      "Training: Epoch 60, Batch 52, Loss: 0.313\n",
      "Training: Epoch 60, Batch 53, Loss: 0.293\n",
      "Training: Epoch 60, Batch 54, Loss: 0.312\n",
      "Training: Epoch 60, Batch 55, Loss: 0.447\n",
      "Training: Epoch 60, Batch 56, Loss: 0.397\n",
      "Training: Epoch 60, Batch 57, Loss: 0.219\n",
      "Training: Epoch 60, Batch 58, Loss: 0.473\n",
      "Training: Epoch 60, Batch 59, Loss: 0.492\n",
      "Training: Epoch 60, Batch 60, Loss: 0.352\n",
      "Training: Epoch 60, Batch 61, Loss: 0.233\n",
      "Training: Epoch 60, Batch 62, Loss: 0.427\n",
      "Training: Epoch 60, Batch 63, Loss: 0.64\n",
      "Training: Epoch 60, Batch 64, Loss: 0.298\n",
      "Training: Epoch 60, Batch 65, Loss: 0.518\n",
      "Training: Epoch 60, Batch 66, Loss: 0.306\n",
      "Training: Epoch 60, Batch 67, Loss: 0.255\n",
      "Training: Epoch 60, Batch 68, Loss: 0.291\n",
      "Training: Epoch 60, Batch 69, Loss: 0.56\n",
      "Training: Epoch 60, Batch 70, Loss: 0.451\n",
      "Training: Epoch 60, Batch 71, Loss: 0.428\n",
      "Training: Epoch 60, Batch 72, Loss: 0.363\n",
      "Training: Epoch 60, Batch 73, Loss: 0.356\n",
      "Training: Epoch 60, Batch 74, Loss: 0.212\n",
      "Training: Epoch 60, Batch 75, Loss: 0.35\n",
      "Training: Epoch 60, Batch 76, Loss: 0.333\n",
      "Training: Epoch 60, Batch 77, Loss: 0.325\n",
      "Training: Epoch 60, Batch 78, Loss: 0.295\n",
      "Training: Epoch 60, Batch 79, Loss: 0.135\n",
      "Training: Epoch 60, Batch 80, Loss: 0.391\n",
      "Training: Epoch 60, Batch 81, Loss: 0.406\n",
      "Training: Epoch 60, Batch 82, Loss: 0.246\n",
      "Training: Epoch 60, Batch 83, Loss: 0.409\n",
      "Training: Epoch 60, Batch 84, Loss: 0.362\n",
      "Training: Epoch 60, Batch 85, Loss: 0.24\n",
      "Training: Epoch 60, Batch 86, Loss: 0.326\n",
      "Training: Epoch 60, Batch 87, Loss: 0.341\n",
      "Training: Epoch 60, Batch 88, Loss: 0.417\n",
      "Training: Epoch 60, Batch 89, Loss: 0.374\n",
      "Val: Epoch 60, Loss: 0.27\n",
      "Training: Epoch 61, Batch 0, Loss: 0.235\n",
      "Training: Epoch 61, Batch 1, Loss: 0.18\n",
      "Training: Epoch 61, Batch 2, Loss: 0.432\n",
      "Training: Epoch 61, Batch 3, Loss: 0.374\n",
      "Training: Epoch 61, Batch 4, Loss: 0.217\n",
      "Training: Epoch 61, Batch 5, Loss: 0.453\n",
      "Training: Epoch 61, Batch 6, Loss: 0.617\n",
      "Training: Epoch 61, Batch 7, Loss: 0.373\n",
      "Training: Epoch 61, Batch 8, Loss: 0.234\n",
      "Training: Epoch 61, Batch 9, Loss: 0.394\n",
      "Training: Epoch 61, Batch 10, Loss: 0.497\n",
      "Training: Epoch 61, Batch 11, Loss: 0.486\n",
      "Training: Epoch 61, Batch 12, Loss: 0.752\n",
      "Training: Epoch 61, Batch 13, Loss: 0.231\n",
      "Training: Epoch 61, Batch 14, Loss: 0.342\n",
      "Training: Epoch 61, Batch 15, Loss: 0.457\n",
      "Training: Epoch 61, Batch 16, Loss: 0.343\n",
      "Training: Epoch 61, Batch 17, Loss: 0.571\n",
      "Training: Epoch 61, Batch 18, Loss: 0.425\n",
      "Training: Epoch 61, Batch 19, Loss: 0.285\n",
      "Training: Epoch 61, Batch 20, Loss: 0.228\n",
      "Training: Epoch 61, Batch 21, Loss: 0.426\n",
      "Training: Epoch 61, Batch 22, Loss: 0.502\n",
      "Training: Epoch 61, Batch 23, Loss: 0.248\n",
      "Training: Epoch 61, Batch 24, Loss: 0.476\n",
      "Training: Epoch 61, Batch 25, Loss: 0.315\n",
      "Training: Epoch 61, Batch 26, Loss: 0.341\n",
      "Training: Epoch 61, Batch 27, Loss: 0.563\n",
      "Training: Epoch 61, Batch 28, Loss: 0.347\n",
      "Training: Epoch 61, Batch 29, Loss: 0.679\n",
      "Training: Epoch 61, Batch 30, Loss: 0.213\n",
      "Training: Epoch 61, Batch 31, Loss: 0.522\n",
      "Training: Epoch 61, Batch 32, Loss: 0.402\n",
      "Training: Epoch 61, Batch 33, Loss: 0.316\n",
      "Training: Epoch 61, Batch 34, Loss: 0.443\n",
      "Training: Epoch 61, Batch 35, Loss: 0.358\n",
      "Training: Epoch 61, Batch 36, Loss: 0.189\n",
      "Training: Epoch 61, Batch 37, Loss: 0.407\n",
      "Training: Epoch 61, Batch 38, Loss: 0.295\n",
      "Training: Epoch 61, Batch 39, Loss: 0.42\n",
      "Training: Epoch 61, Batch 40, Loss: 0.519\n",
      "Training: Epoch 61, Batch 41, Loss: 0.366\n",
      "Training: Epoch 61, Batch 42, Loss: 0.352\n",
      "Training: Epoch 61, Batch 43, Loss: 0.494\n",
      "Training: Epoch 61, Batch 44, Loss: 0.389\n",
      "Training: Epoch 61, Batch 45, Loss: 0.366\n",
      "Training: Epoch 61, Batch 46, Loss: 0.276\n",
      "Training: Epoch 61, Batch 47, Loss: 0.389\n",
      "Training: Epoch 61, Batch 48, Loss: 0.498\n",
      "Training: Epoch 61, Batch 49, Loss: 0.336\n",
      "Training: Epoch 61, Batch 50, Loss: 0.485\n",
      "Training: Epoch 61, Batch 51, Loss: 0.404\n",
      "Training: Epoch 61, Batch 52, Loss: 0.333\n",
      "Training: Epoch 61, Batch 53, Loss: 0.387\n",
      "Training: Epoch 61, Batch 54, Loss: 0.372\n",
      "Training: Epoch 61, Batch 55, Loss: 0.573\n",
      "Training: Epoch 61, Batch 56, Loss: 0.449\n",
      "Training: Epoch 61, Batch 57, Loss: 0.412\n",
      "Training: Epoch 61, Batch 58, Loss: 0.3\n",
      "Training: Epoch 61, Batch 59, Loss: 0.194\n",
      "Training: Epoch 61, Batch 60, Loss: 0.521\n",
      "Training: Epoch 61, Batch 61, Loss: 0.387\n",
      "Training: Epoch 61, Batch 62, Loss: 0.171\n",
      "Training: Epoch 61, Batch 63, Loss: 0.467\n",
      "Training: Epoch 61, Batch 64, Loss: 0.545\n",
      "Training: Epoch 61, Batch 65, Loss: 0.352\n",
      "Training: Epoch 61, Batch 66, Loss: 0.352\n",
      "Training: Epoch 61, Batch 67, Loss: 0.162\n",
      "Training: Epoch 61, Batch 68, Loss: 0.434\n",
      "Training: Epoch 61, Batch 69, Loss: 0.296\n",
      "Training: Epoch 61, Batch 70, Loss: 0.238\n",
      "Training: Epoch 61, Batch 71, Loss: 0.515\n",
      "Training: Epoch 61, Batch 72, Loss: 0.246\n",
      "Training: Epoch 61, Batch 73, Loss: 0.294\n",
      "Training: Epoch 61, Batch 74, Loss: 0.284\n",
      "Training: Epoch 61, Batch 75, Loss: 0.327\n",
      "Training: Epoch 61, Batch 76, Loss: 0.234\n",
      "Training: Epoch 61, Batch 77, Loss: 0.296\n",
      "Training: Epoch 61, Batch 78, Loss: 0.466\n",
      "Training: Epoch 61, Batch 79, Loss: 0.487\n",
      "Training: Epoch 61, Batch 80, Loss: 0.495\n",
      "Training: Epoch 61, Batch 81, Loss: 0.418\n",
      "Training: Epoch 61, Batch 82, Loss: 0.448\n",
      "Training: Epoch 61, Batch 83, Loss: 0.507\n",
      "Training: Epoch 61, Batch 84, Loss: 0.418\n",
      "Training: Epoch 61, Batch 85, Loss: 0.297\n",
      "Training: Epoch 61, Batch 86, Loss: 0.236\n",
      "Training: Epoch 61, Batch 87, Loss: 0.432\n",
      "Training: Epoch 61, Batch 88, Loss: 0.4\n",
      "Training: Epoch 61, Batch 89, Loss: 0.455\n",
      "Val: Epoch 61, Loss: 0.291\n",
      "Training: Epoch 62, Batch 0, Loss: 0.453\n",
      "Training: Epoch 62, Batch 1, Loss: 0.268\n",
      "Training: Epoch 62, Batch 2, Loss: 0.459\n",
      "Training: Epoch 62, Batch 3, Loss: 0.298\n",
      "Training: Epoch 62, Batch 4, Loss: 0.404\n",
      "Training: Epoch 62, Batch 5, Loss: 0.297\n",
      "Training: Epoch 62, Batch 6, Loss: 0.469\n",
      "Training: Epoch 62, Batch 7, Loss: 0.415\n",
      "Training: Epoch 62, Batch 8, Loss: 0.212\n",
      "Training: Epoch 62, Batch 9, Loss: 0.35\n",
      "Training: Epoch 62, Batch 10, Loss: 0.359\n",
      "Training: Epoch 62, Batch 11, Loss: 0.418\n",
      "Training: Epoch 62, Batch 12, Loss: 0.466\n",
      "Training: Epoch 62, Batch 13, Loss: 0.518\n",
      "Training: Epoch 62, Batch 14, Loss: 0.288\n",
      "Training: Epoch 62, Batch 15, Loss: 0.477\n",
      "Training: Epoch 62, Batch 16, Loss: 0.366\n",
      "Training: Epoch 62, Batch 17, Loss: 0.405\n",
      "Training: Epoch 62, Batch 18, Loss: 0.333\n",
      "Training: Epoch 62, Batch 19, Loss: 0.555\n",
      "Training: Epoch 62, Batch 20, Loss: 0.265\n",
      "Training: Epoch 62, Batch 21, Loss: 0.371\n",
      "Training: Epoch 62, Batch 22, Loss: 0.455\n",
      "Training: Epoch 62, Batch 23, Loss: 0.163\n",
      "Training: Epoch 62, Batch 24, Loss: 0.639\n",
      "Training: Epoch 62, Batch 25, Loss: 0.496\n",
      "Training: Epoch 62, Batch 26, Loss: 0.378\n",
      "Training: Epoch 62, Batch 27, Loss: 0.332\n",
      "Training: Epoch 62, Batch 28, Loss: 0.238\n",
      "Training: Epoch 62, Batch 29, Loss: 0.433\n",
      "Training: Epoch 62, Batch 30, Loss: 0.253\n",
      "Training: Epoch 62, Batch 31, Loss: 0.237\n",
      "Training: Epoch 62, Batch 32, Loss: 0.369\n",
      "Training: Epoch 62, Batch 33, Loss: 0.274\n",
      "Training: Epoch 62, Batch 34, Loss: 0.323\n",
      "Training: Epoch 62, Batch 35, Loss: 0.395\n",
      "Training: Epoch 62, Batch 36, Loss: 0.172\n",
      "Training: Epoch 62, Batch 37, Loss: 0.38\n",
      "Training: Epoch 62, Batch 38, Loss: 0.369\n",
      "Training: Epoch 62, Batch 39, Loss: 0.307\n",
      "Training: Epoch 62, Batch 40, Loss: 0.376\n",
      "Training: Epoch 62, Batch 41, Loss: 0.387\n",
      "Training: Epoch 62, Batch 42, Loss: 0.481\n",
      "Training: Epoch 62, Batch 43, Loss: 0.402\n",
      "Training: Epoch 62, Batch 44, Loss: 0.263\n",
      "Training: Epoch 62, Batch 45, Loss: 0.353\n",
      "Training: Epoch 62, Batch 46, Loss: 0.481\n",
      "Training: Epoch 62, Batch 47, Loss: 0.415\n",
      "Training: Epoch 62, Batch 48, Loss: 0.447\n",
      "Training: Epoch 62, Batch 49, Loss: 0.433\n",
      "Training: Epoch 62, Batch 50, Loss: 0.23\n",
      "Training: Epoch 62, Batch 51, Loss: 0.246\n",
      "Training: Epoch 62, Batch 52, Loss: 0.463\n",
      "Training: Epoch 62, Batch 53, Loss: 0.581\n",
      "Training: Epoch 62, Batch 54, Loss: 0.394\n",
      "Training: Epoch 62, Batch 55, Loss: 0.345\n",
      "Training: Epoch 62, Batch 56, Loss: 0.47\n",
      "Training: Epoch 62, Batch 57, Loss: 0.415\n",
      "Training: Epoch 62, Batch 58, Loss: 0.365\n",
      "Training: Epoch 62, Batch 59, Loss: 0.367\n",
      "Training: Epoch 62, Batch 60, Loss: 0.323\n",
      "Training: Epoch 62, Batch 61, Loss: 0.391\n",
      "Training: Epoch 62, Batch 62, Loss: 0.324\n",
      "Training: Epoch 62, Batch 63, Loss: 0.405\n",
      "Training: Epoch 62, Batch 64, Loss: 0.38\n",
      "Training: Epoch 62, Batch 65, Loss: 0.496\n",
      "Training: Epoch 62, Batch 66, Loss: 0.391\n",
      "Training: Epoch 62, Batch 67, Loss: 0.375\n",
      "Training: Epoch 62, Batch 68, Loss: 0.233\n",
      "Training: Epoch 62, Batch 69, Loss: 0.393\n",
      "Training: Epoch 62, Batch 70, Loss: 0.215\n",
      "Training: Epoch 62, Batch 71, Loss: 0.293\n",
      "Training: Epoch 62, Batch 72, Loss: 0.364\n",
      "Training: Epoch 62, Batch 73, Loss: 0.439\n",
      "Training: Epoch 62, Batch 74, Loss: 0.236\n",
      "Training: Epoch 62, Batch 75, Loss: 0.338\n",
      "Training: Epoch 62, Batch 76, Loss: 0.277\n",
      "Training: Epoch 62, Batch 77, Loss: 0.324\n",
      "Training: Epoch 62, Batch 78, Loss: 0.422\n",
      "Training: Epoch 62, Batch 79, Loss: 0.473\n",
      "Training: Epoch 62, Batch 80, Loss: 0.382\n",
      "Training: Epoch 62, Batch 81, Loss: 0.432\n",
      "Training: Epoch 62, Batch 82, Loss: 0.515\n",
      "Training: Epoch 62, Batch 83, Loss: 0.306\n",
      "Training: Epoch 62, Batch 84, Loss: 0.377\n",
      "Training: Epoch 62, Batch 85, Loss: 0.376\n",
      "Training: Epoch 62, Batch 86, Loss: 0.495\n",
      "Training: Epoch 62, Batch 87, Loss: 0.49\n",
      "Training: Epoch 62, Batch 88, Loss: 0.417\n",
      "Training: Epoch 62, Batch 89, Loss: 0.35\n",
      "Val: Epoch 62, Loss: 0.242\n",
      "Training: Epoch 63, Batch 0, Loss: 0.432\n",
      "Training: Epoch 63, Batch 1, Loss: 0.19\n",
      "Training: Epoch 63, Batch 2, Loss: 0.452\n",
      "Training: Epoch 63, Batch 3, Loss: 0.605\n",
      "Training: Epoch 63, Batch 4, Loss: 0.597\n",
      "Training: Epoch 63, Batch 5, Loss: 0.405\n",
      "Training: Epoch 63, Batch 6, Loss: 0.406\n",
      "Training: Epoch 63, Batch 7, Loss: 0.516\n",
      "Training: Epoch 63, Batch 8, Loss: 0.592\n",
      "Training: Epoch 63, Batch 9, Loss: 0.329\n",
      "Training: Epoch 63, Batch 10, Loss: 0.282\n",
      "Training: Epoch 63, Batch 11, Loss: 0.337\n",
      "Training: Epoch 63, Batch 12, Loss: 0.539\n",
      "Training: Epoch 63, Batch 13, Loss: 0.371\n",
      "Training: Epoch 63, Batch 14, Loss: 0.368\n",
      "Training: Epoch 63, Batch 15, Loss: 0.692\n",
      "Training: Epoch 63, Batch 16, Loss: 0.247\n",
      "Training: Epoch 63, Batch 17, Loss: 0.542\n",
      "Training: Epoch 63, Batch 18, Loss: 0.416\n",
      "Training: Epoch 63, Batch 19, Loss: 0.211\n",
      "Training: Epoch 63, Batch 20, Loss: 0.236\n",
      "Training: Epoch 63, Batch 21, Loss: 0.476\n",
      "Training: Epoch 63, Batch 22, Loss: 0.455\n",
      "Training: Epoch 63, Batch 23, Loss: 0.393\n",
      "Training: Epoch 63, Batch 24, Loss: 0.265\n",
      "Training: Epoch 63, Batch 25, Loss: 0.263\n",
      "Training: Epoch 63, Batch 26, Loss: 0.277\n",
      "Training: Epoch 63, Batch 27, Loss: 0.466\n",
      "Training: Epoch 63, Batch 28, Loss: 0.594\n",
      "Training: Epoch 63, Batch 29, Loss: 0.344\n",
      "Training: Epoch 63, Batch 30, Loss: 0.278\n",
      "Training: Epoch 63, Batch 31, Loss: 0.444\n",
      "Training: Epoch 63, Batch 32, Loss: 0.449\n",
      "Training: Epoch 63, Batch 33, Loss: 0.39\n",
      "Training: Epoch 63, Batch 34, Loss: 0.578\n",
      "Training: Epoch 63, Batch 35, Loss: 0.295\n",
      "Training: Epoch 63, Batch 36, Loss: 0.436\n",
      "Training: Epoch 63, Batch 37, Loss: 0.495\n",
      "Training: Epoch 63, Batch 38, Loss: 0.625\n",
      "Training: Epoch 63, Batch 39, Loss: 0.256\n",
      "Training: Epoch 63, Batch 40, Loss: 0.387\n",
      "Training: Epoch 63, Batch 41, Loss: 0.312\n",
      "Training: Epoch 63, Batch 42, Loss: 0.347\n",
      "Training: Epoch 63, Batch 43, Loss: 0.317\n",
      "Training: Epoch 63, Batch 44, Loss: 0.27\n",
      "Training: Epoch 63, Batch 45, Loss: 0.366\n",
      "Training: Epoch 63, Batch 46, Loss: 0.478\n",
      "Training: Epoch 63, Batch 47, Loss: 0.465\n",
      "Training: Epoch 63, Batch 48, Loss: 0.313\n",
      "Training: Epoch 63, Batch 49, Loss: 0.438\n",
      "Training: Epoch 63, Batch 50, Loss: 0.229\n",
      "Training: Epoch 63, Batch 51, Loss: 0.296\n",
      "Training: Epoch 63, Batch 52, Loss: 0.39\n",
      "Training: Epoch 63, Batch 53, Loss: 0.38\n",
      "Training: Epoch 63, Batch 54, Loss: 0.328\n",
      "Training: Epoch 63, Batch 55, Loss: 0.334\n",
      "Training: Epoch 63, Batch 56, Loss: 0.492\n",
      "Training: Epoch 63, Batch 57, Loss: 0.425\n",
      "Training: Epoch 63, Batch 58, Loss: 0.586\n",
      "Training: Epoch 63, Batch 59, Loss: 0.286\n",
      "Training: Epoch 63, Batch 60, Loss: 0.383\n",
      "Training: Epoch 63, Batch 61, Loss: 0.342\n",
      "Training: Epoch 63, Batch 62, Loss: 0.478\n",
      "Training: Epoch 63, Batch 63, Loss: 0.3\n",
      "Training: Epoch 63, Batch 64, Loss: 0.549\n",
      "Training: Epoch 63, Batch 65, Loss: 0.244\n",
      "Training: Epoch 63, Batch 66, Loss: 0.234\n",
      "Training: Epoch 63, Batch 67, Loss: 0.376\n",
      "Training: Epoch 63, Batch 68, Loss: 0.339\n",
      "Training: Epoch 63, Batch 69, Loss: 0.303\n",
      "Training: Epoch 63, Batch 70, Loss: 0.233\n",
      "Training: Epoch 63, Batch 71, Loss: 0.387\n",
      "Training: Epoch 63, Batch 72, Loss: 0.398\n",
      "Training: Epoch 63, Batch 73, Loss: 0.179\n",
      "Training: Epoch 63, Batch 74, Loss: 0.521\n",
      "Training: Epoch 63, Batch 75, Loss: 0.318\n",
      "Training: Epoch 63, Batch 76, Loss: 0.503\n",
      "Training: Epoch 63, Batch 77, Loss: 0.153\n",
      "Training: Epoch 63, Batch 78, Loss: 0.227\n",
      "Training: Epoch 63, Batch 79, Loss: 0.208\n",
      "Training: Epoch 63, Batch 80, Loss: 0.391\n",
      "Training: Epoch 63, Batch 81, Loss: 0.364\n",
      "Training: Epoch 63, Batch 82, Loss: 0.36\n",
      "Training: Epoch 63, Batch 83, Loss: 0.425\n",
      "Training: Epoch 63, Batch 84, Loss: 0.149\n",
      "Training: Epoch 63, Batch 85, Loss: 0.303\n",
      "Training: Epoch 63, Batch 86, Loss: 0.297\n",
      "Training: Epoch 63, Batch 87, Loss: 0.403\n",
      "Training: Epoch 63, Batch 88, Loss: 0.727\n",
      "Training: Epoch 63, Batch 89, Loss: 0.432\n",
      "Val: Epoch 63, Loss: 0.249\n",
      "Training: Epoch 64, Batch 0, Loss: 0.448\n",
      "Training: Epoch 64, Batch 1, Loss: 0.323\n",
      "Training: Epoch 64, Batch 2, Loss: 0.313\n",
      "Training: Epoch 64, Batch 3, Loss: 0.333\n",
      "Training: Epoch 64, Batch 4, Loss: 0.353\n",
      "Training: Epoch 64, Batch 5, Loss: 0.431\n",
      "Training: Epoch 64, Batch 6, Loss: 0.454\n",
      "Training: Epoch 64, Batch 7, Loss: 0.644\n",
      "Training: Epoch 64, Batch 8, Loss: 0.312\n",
      "Training: Epoch 64, Batch 9, Loss: 0.443\n",
      "Training: Epoch 64, Batch 10, Loss: 0.168\n",
      "Training: Epoch 64, Batch 11, Loss: 0.246\n",
      "Training: Epoch 64, Batch 12, Loss: 0.326\n",
      "Training: Epoch 64, Batch 13, Loss: 0.365\n",
      "Training: Epoch 64, Batch 14, Loss: 0.311\n",
      "Training: Epoch 64, Batch 15, Loss: 0.416\n",
      "Training: Epoch 64, Batch 16, Loss: 0.3\n",
      "Training: Epoch 64, Batch 17, Loss: 0.388\n",
      "Training: Epoch 64, Batch 18, Loss: 0.18\n",
      "Training: Epoch 64, Batch 19, Loss: 0.32\n",
      "Training: Epoch 64, Batch 20, Loss: 0.429\n",
      "Training: Epoch 64, Batch 21, Loss: 0.449\n",
      "Training: Epoch 64, Batch 22, Loss: 0.243\n",
      "Training: Epoch 64, Batch 23, Loss: 0.406\n",
      "Training: Epoch 64, Batch 24, Loss: 0.187\n",
      "Training: Epoch 64, Batch 25, Loss: 0.241\n",
      "Training: Epoch 64, Batch 26, Loss: 0.415\n",
      "Training: Epoch 64, Batch 27, Loss: 0.572\n",
      "Training: Epoch 64, Batch 28, Loss: 0.327\n",
      "Training: Epoch 64, Batch 29, Loss: 0.572\n",
      "Training: Epoch 64, Batch 30, Loss: 0.434\n",
      "Training: Epoch 64, Batch 31, Loss: 0.271\n",
      "Training: Epoch 64, Batch 32, Loss: 0.415\n",
      "Training: Epoch 64, Batch 33, Loss: 0.298\n",
      "Training: Epoch 64, Batch 34, Loss: 0.292\n",
      "Training: Epoch 64, Batch 35, Loss: 0.298\n",
      "Training: Epoch 64, Batch 36, Loss: 0.308\n",
      "Training: Epoch 64, Batch 37, Loss: 0.388\n",
      "Training: Epoch 64, Batch 38, Loss: 0.555\n",
      "Training: Epoch 64, Batch 39, Loss: 0.292\n",
      "Training: Epoch 64, Batch 40, Loss: 0.358\n",
      "Training: Epoch 64, Batch 41, Loss: 0.283\n",
      "Training: Epoch 64, Batch 42, Loss: 0.51\n",
      "Training: Epoch 64, Batch 43, Loss: 0.317\n",
      "Training: Epoch 64, Batch 44, Loss: 0.47\n",
      "Training: Epoch 64, Batch 45, Loss: 0.251\n",
      "Training: Epoch 64, Batch 46, Loss: 0.383\n",
      "Training: Epoch 64, Batch 47, Loss: 0.33\n",
      "Training: Epoch 64, Batch 48, Loss: 0.455\n",
      "Training: Epoch 64, Batch 49, Loss: 0.485\n",
      "Training: Epoch 64, Batch 50, Loss: 0.355\n",
      "Training: Epoch 64, Batch 51, Loss: 0.43\n",
      "Training: Epoch 64, Batch 52, Loss: 0.651\n",
      "Training: Epoch 64, Batch 53, Loss: 0.351\n",
      "Training: Epoch 64, Batch 54, Loss: 0.482\n",
      "Training: Epoch 64, Batch 55, Loss: 0.398\n",
      "Training: Epoch 64, Batch 56, Loss: 0.319\n",
      "Training: Epoch 64, Batch 57, Loss: 0.274\n",
      "Training: Epoch 64, Batch 58, Loss: 0.597\n",
      "Training: Epoch 64, Batch 59, Loss: 0.193\n",
      "Training: Epoch 64, Batch 60, Loss: 0.351\n",
      "Training: Epoch 64, Batch 61, Loss: 0.392\n",
      "Training: Epoch 64, Batch 62, Loss: 0.472\n",
      "Training: Epoch 64, Batch 63, Loss: 0.501\n",
      "Training: Epoch 64, Batch 64, Loss: 0.279\n",
      "Training: Epoch 64, Batch 65, Loss: 0.496\n",
      "Training: Epoch 64, Batch 66, Loss: 0.482\n",
      "Training: Epoch 64, Batch 67, Loss: 0.24\n",
      "Training: Epoch 64, Batch 68, Loss: 0.355\n",
      "Training: Epoch 64, Batch 69, Loss: 0.365\n",
      "Training: Epoch 64, Batch 70, Loss: 0.415\n",
      "Training: Epoch 64, Batch 71, Loss: 0.472\n",
      "Training: Epoch 64, Batch 72, Loss: 0.451\n",
      "Training: Epoch 64, Batch 73, Loss: 0.292\n",
      "Training: Epoch 64, Batch 74, Loss: 0.449\n",
      "Training: Epoch 64, Batch 75, Loss: 0.598\n",
      "Training: Epoch 64, Batch 76, Loss: 0.334\n",
      "Training: Epoch 64, Batch 77, Loss: 0.362\n",
      "Training: Epoch 64, Batch 78, Loss: 0.173\n",
      "Training: Epoch 64, Batch 79, Loss: 0.387\n",
      "Training: Epoch 64, Batch 80, Loss: 0.403\n",
      "Training: Epoch 64, Batch 81, Loss: 0.411\n",
      "Training: Epoch 64, Batch 82, Loss: 0.361\n",
      "Training: Epoch 64, Batch 83, Loss: 0.462\n",
      "Training: Epoch 64, Batch 84, Loss: 0.323\n",
      "Training: Epoch 64, Batch 85, Loss: 0.533\n",
      "Training: Epoch 64, Batch 86, Loss: 0.386\n",
      "Training: Epoch 64, Batch 87, Loss: 0.194\n",
      "Training: Epoch 64, Batch 88, Loss: 0.238\n",
      "Training: Epoch 64, Batch 89, Loss: 0.473\n",
      "Val: Epoch 64, Loss: 0.341\n",
      "Training: Epoch 65, Batch 0, Loss: 0.219\n",
      "Training: Epoch 65, Batch 1, Loss: 0.335\n",
      "Training: Epoch 65, Batch 2, Loss: 0.333\n",
      "Training: Epoch 65, Batch 3, Loss: 0.515\n",
      "Training: Epoch 65, Batch 4, Loss: 0.333\n",
      "Training: Epoch 65, Batch 5, Loss: 0.195\n",
      "Training: Epoch 65, Batch 6, Loss: 0.337\n",
      "Training: Epoch 65, Batch 7, Loss: 0.295\n",
      "Training: Epoch 65, Batch 8, Loss: 0.269\n",
      "Training: Epoch 65, Batch 9, Loss: 0.394\n",
      "Training: Epoch 65, Batch 10, Loss: 0.592\n",
      "Training: Epoch 65, Batch 11, Loss: 0.112\n",
      "Training: Epoch 65, Batch 12, Loss: 0.452\n",
      "Training: Epoch 65, Batch 13, Loss: 0.321\n",
      "Training: Epoch 65, Batch 14, Loss: 0.439\n",
      "Training: Epoch 65, Batch 15, Loss: 0.397\n",
      "Training: Epoch 65, Batch 16, Loss: 0.431\n",
      "Training: Epoch 65, Batch 17, Loss: 0.42\n",
      "Training: Epoch 65, Batch 18, Loss: 0.366\n",
      "Training: Epoch 65, Batch 19, Loss: 0.245\n",
      "Training: Epoch 65, Batch 20, Loss: 0.404\n",
      "Training: Epoch 65, Batch 21, Loss: 0.206\n",
      "Training: Epoch 65, Batch 22, Loss: 0.494\n",
      "Training: Epoch 65, Batch 23, Loss: 0.228\n",
      "Training: Epoch 65, Batch 24, Loss: 0.238\n",
      "Training: Epoch 65, Batch 25, Loss: 0.424\n",
      "Training: Epoch 65, Batch 26, Loss: 0.349\n",
      "Training: Epoch 65, Batch 27, Loss: 0.396\n",
      "Training: Epoch 65, Batch 28, Loss: 0.133\n",
      "Training: Epoch 65, Batch 29, Loss: 0.329\n",
      "Training: Epoch 65, Batch 30, Loss: 0.46\n",
      "Training: Epoch 65, Batch 31, Loss: 0.531\n",
      "Training: Epoch 65, Batch 32, Loss: 0.436\n",
      "Training: Epoch 65, Batch 33, Loss: 0.274\n",
      "Training: Epoch 65, Batch 34, Loss: 0.239\n",
      "Training: Epoch 65, Batch 35, Loss: 0.408\n",
      "Training: Epoch 65, Batch 36, Loss: 0.245\n",
      "Training: Epoch 65, Batch 37, Loss: 0.542\n",
      "Training: Epoch 65, Batch 38, Loss: 0.454\n",
      "Training: Epoch 65, Batch 39, Loss: 0.408\n",
      "Training: Epoch 65, Batch 40, Loss: 0.375\n",
      "Training: Epoch 65, Batch 41, Loss: 0.334\n",
      "Training: Epoch 65, Batch 42, Loss: 0.474\n",
      "Training: Epoch 65, Batch 43, Loss: 0.496\n",
      "Training: Epoch 65, Batch 44, Loss: 0.455\n",
      "Training: Epoch 65, Batch 45, Loss: 0.407\n",
      "Training: Epoch 65, Batch 46, Loss: 0.439\n",
      "Training: Epoch 65, Batch 47, Loss: 0.293\n",
      "Training: Epoch 65, Batch 48, Loss: 0.255\n",
      "Training: Epoch 65, Batch 49, Loss: 0.437\n",
      "Training: Epoch 65, Batch 50, Loss: 0.494\n",
      "Training: Epoch 65, Batch 51, Loss: 0.448\n",
      "Training: Epoch 65, Batch 52, Loss: 0.271\n",
      "Training: Epoch 65, Batch 53, Loss: 0.467\n",
      "Training: Epoch 65, Batch 54, Loss: 0.398\n",
      "Training: Epoch 65, Batch 55, Loss: 0.457\n",
      "Training: Epoch 65, Batch 56, Loss: 0.384\n",
      "Training: Epoch 65, Batch 57, Loss: 0.471\n",
      "Training: Epoch 65, Batch 58, Loss: 0.433\n",
      "Training: Epoch 65, Batch 59, Loss: 0.263\n",
      "Training: Epoch 65, Batch 60, Loss: 0.264\n",
      "Training: Epoch 65, Batch 61, Loss: 0.432\n",
      "Training: Epoch 65, Batch 62, Loss: 0.55\n",
      "Training: Epoch 65, Batch 63, Loss: 0.347\n",
      "Training: Epoch 65, Batch 64, Loss: 0.331\n",
      "Training: Epoch 65, Batch 65, Loss: 0.293\n",
      "Training: Epoch 65, Batch 66, Loss: 0.54\n",
      "Training: Epoch 65, Batch 67, Loss: 0.241\n",
      "Training: Epoch 65, Batch 68, Loss: 0.158\n",
      "Training: Epoch 65, Batch 69, Loss: 0.34\n",
      "Training: Epoch 65, Batch 70, Loss: 0.482\n",
      "Training: Epoch 65, Batch 71, Loss: 0.466\n",
      "Training: Epoch 65, Batch 72, Loss: 0.332\n",
      "Training: Epoch 65, Batch 73, Loss: 0.43\n",
      "Training: Epoch 65, Batch 74, Loss: 0.623\n",
      "Training: Epoch 65, Batch 75, Loss: 0.476\n",
      "Training: Epoch 65, Batch 76, Loss: 0.487\n",
      "Training: Epoch 65, Batch 77, Loss: 0.372\n",
      "Training: Epoch 65, Batch 78, Loss: 0.348\n",
      "Training: Epoch 65, Batch 79, Loss: 0.437\n",
      "Training: Epoch 65, Batch 80, Loss: 0.47\n",
      "Training: Epoch 65, Batch 81, Loss: 0.336\n",
      "Training: Epoch 65, Batch 82, Loss: 0.581\n",
      "Training: Epoch 65, Batch 83, Loss: 0.292\n",
      "Training: Epoch 65, Batch 84, Loss: 0.471\n",
      "Training: Epoch 65, Batch 85, Loss: 0.553\n",
      "Training: Epoch 65, Batch 86, Loss: 0.376\n",
      "Training: Epoch 65, Batch 87, Loss: 0.223\n",
      "Training: Epoch 65, Batch 88, Loss: 0.426\n",
      "Training: Epoch 65, Batch 89, Loss: 0.545\n",
      "Val: Epoch 65, Loss: 0.244\n",
      "Training: Epoch 66, Batch 0, Loss: 0.484\n",
      "Training: Epoch 66, Batch 1, Loss: 0.462\n",
      "Training: Epoch 66, Batch 2, Loss: 0.222\n",
      "Training: Epoch 66, Batch 3, Loss: 0.317\n",
      "Training: Epoch 66, Batch 4, Loss: 0.305\n",
      "Training: Epoch 66, Batch 5, Loss: 0.414\n",
      "Training: Epoch 66, Batch 6, Loss: 0.469\n",
      "Training: Epoch 66, Batch 7, Loss: 0.373\n",
      "Training: Epoch 66, Batch 8, Loss: 0.368\n",
      "Training: Epoch 66, Batch 9, Loss: 0.176\n",
      "Training: Epoch 66, Batch 10, Loss: 0.401\n",
      "Training: Epoch 66, Batch 11, Loss: 0.383\n",
      "Training: Epoch 66, Batch 12, Loss: 0.317\n",
      "Training: Epoch 66, Batch 13, Loss: 0.389\n",
      "Training: Epoch 66, Batch 14, Loss: 0.381\n",
      "Training: Epoch 66, Batch 15, Loss: 0.369\n",
      "Training: Epoch 66, Batch 16, Loss: 0.4\n",
      "Training: Epoch 66, Batch 17, Loss: 0.352\n",
      "Training: Epoch 66, Batch 18, Loss: 0.303\n",
      "Training: Epoch 66, Batch 19, Loss: 0.402\n",
      "Training: Epoch 66, Batch 20, Loss: 0.444\n",
      "Training: Epoch 66, Batch 21, Loss: 0.35\n",
      "Training: Epoch 66, Batch 22, Loss: 0.36\n",
      "Training: Epoch 66, Batch 23, Loss: 0.39\n",
      "Training: Epoch 66, Batch 24, Loss: 0.245\n",
      "Training: Epoch 66, Batch 25, Loss: 0.266\n",
      "Training: Epoch 66, Batch 26, Loss: 0.436\n",
      "Training: Epoch 66, Batch 27, Loss: 0.159\n",
      "Training: Epoch 66, Batch 28, Loss: 0.292\n",
      "Training: Epoch 66, Batch 29, Loss: 0.318\n",
      "Training: Epoch 66, Batch 30, Loss: 0.325\n",
      "Training: Epoch 66, Batch 31, Loss: 0.392\n",
      "Training: Epoch 66, Batch 32, Loss: 0.265\n",
      "Training: Epoch 66, Batch 33, Loss: 0.418\n",
      "Training: Epoch 66, Batch 34, Loss: 0.497\n",
      "Training: Epoch 66, Batch 35, Loss: 0.355\n",
      "Training: Epoch 66, Batch 36, Loss: 0.397\n",
      "Training: Epoch 66, Batch 37, Loss: 0.305\n",
      "Training: Epoch 66, Batch 38, Loss: 0.487\n",
      "Training: Epoch 66, Batch 39, Loss: 0.517\n",
      "Training: Epoch 66, Batch 40, Loss: 0.345\n",
      "Training: Epoch 66, Batch 41, Loss: 0.392\n",
      "Training: Epoch 66, Batch 42, Loss: 0.479\n",
      "Training: Epoch 66, Batch 43, Loss: 0.407\n",
      "Training: Epoch 66, Batch 44, Loss: 0.365\n",
      "Training: Epoch 66, Batch 45, Loss: 0.591\n",
      "Training: Epoch 66, Batch 46, Loss: 0.31\n",
      "Training: Epoch 66, Batch 47, Loss: 0.375\n",
      "Training: Epoch 66, Batch 48, Loss: 0.394\n",
      "Training: Epoch 66, Batch 49, Loss: 0.499\n",
      "Training: Epoch 66, Batch 50, Loss: 0.474\n",
      "Training: Epoch 66, Batch 51, Loss: 0.209\n",
      "Training: Epoch 66, Batch 52, Loss: 0.414\n",
      "Training: Epoch 66, Batch 53, Loss: 0.424\n",
      "Training: Epoch 66, Batch 54, Loss: 0.294\n",
      "Training: Epoch 66, Batch 55, Loss: 0.529\n",
      "Training: Epoch 66, Batch 56, Loss: 0.21\n",
      "Training: Epoch 66, Batch 57, Loss: 0.237\n",
      "Training: Epoch 66, Batch 58, Loss: 0.387\n",
      "Training: Epoch 66, Batch 59, Loss: 0.373\n",
      "Training: Epoch 66, Batch 60, Loss: 0.305\n",
      "Training: Epoch 66, Batch 61, Loss: 0.584\n",
      "Training: Epoch 66, Batch 62, Loss: 0.334\n",
      "Training: Epoch 66, Batch 63, Loss: 0.293\n",
      "Training: Epoch 66, Batch 64, Loss: 0.339\n",
      "Training: Epoch 66, Batch 65, Loss: 0.226\n",
      "Training: Epoch 66, Batch 66, Loss: 0.316\n",
      "Training: Epoch 66, Batch 67, Loss: 0.238\n",
      "Training: Epoch 66, Batch 68, Loss: 0.514\n",
      "Training: Epoch 66, Batch 69, Loss: 0.329\n",
      "Training: Epoch 66, Batch 70, Loss: 0.676\n",
      "Training: Epoch 66, Batch 71, Loss: 0.456\n",
      "Training: Epoch 66, Batch 72, Loss: 0.259\n",
      "Training: Epoch 66, Batch 73, Loss: 0.626\n",
      "Training: Epoch 66, Batch 74, Loss: 0.288\n",
      "Training: Epoch 66, Batch 75, Loss: 0.616\n",
      "Training: Epoch 66, Batch 76, Loss: 0.336\n",
      "Training: Epoch 66, Batch 77, Loss: 0.518\n",
      "Training: Epoch 66, Batch 78, Loss: 0.287\n",
      "Training: Epoch 66, Batch 79, Loss: 0.213\n",
      "Training: Epoch 66, Batch 80, Loss: 0.56\n",
      "Training: Epoch 66, Batch 81, Loss: 0.395\n",
      "Training: Epoch 66, Batch 82, Loss: 0.299\n",
      "Training: Epoch 66, Batch 83, Loss: 0.337\n",
      "Training: Epoch 66, Batch 84, Loss: 0.398\n",
      "Training: Epoch 66, Batch 85, Loss: 0.394\n",
      "Training: Epoch 66, Batch 86, Loss: 0.362\n",
      "Training: Epoch 66, Batch 87, Loss: 0.559\n",
      "Training: Epoch 66, Batch 88, Loss: 0.369\n",
      "Training: Epoch 66, Batch 89, Loss: 0.357\n",
      "Val: Epoch 66, Loss: 0.274\n",
      "Training: Epoch 67, Batch 0, Loss: 0.485\n",
      "Training: Epoch 67, Batch 1, Loss: 0.454\n",
      "Training: Epoch 67, Batch 2, Loss: 0.383\n",
      "Training: Epoch 67, Batch 3, Loss: 0.291\n",
      "Training: Epoch 67, Batch 4, Loss: 0.447\n",
      "Training: Epoch 67, Batch 5, Loss: 0.469\n",
      "Training: Epoch 67, Batch 6, Loss: 0.38\n",
      "Training: Epoch 67, Batch 7, Loss: 0.354\n",
      "Training: Epoch 67, Batch 8, Loss: 0.306\n",
      "Training: Epoch 67, Batch 9, Loss: 0.236\n",
      "Training: Epoch 67, Batch 10, Loss: 0.285\n",
      "Training: Epoch 67, Batch 11, Loss: 0.321\n",
      "Training: Epoch 67, Batch 12, Loss: 0.416\n",
      "Training: Epoch 67, Batch 13, Loss: 0.25\n",
      "Training: Epoch 67, Batch 14, Loss: 0.152\n",
      "Training: Epoch 67, Batch 15, Loss: 0.498\n",
      "Training: Epoch 67, Batch 16, Loss: 0.643\n",
      "Training: Epoch 67, Batch 17, Loss: 0.333\n",
      "Training: Epoch 67, Batch 18, Loss: 0.586\n",
      "Training: Epoch 67, Batch 19, Loss: 0.28\n",
      "Training: Epoch 67, Batch 20, Loss: 0.233\n",
      "Training: Epoch 67, Batch 21, Loss: 0.535\n",
      "Training: Epoch 67, Batch 22, Loss: 0.459\n",
      "Training: Epoch 67, Batch 23, Loss: 0.374\n",
      "Training: Epoch 67, Batch 24, Loss: 0.458\n",
      "Training: Epoch 67, Batch 25, Loss: 0.218\n",
      "Training: Epoch 67, Batch 26, Loss: 0.307\n",
      "Training: Epoch 67, Batch 27, Loss: 0.382\n",
      "Training: Epoch 67, Batch 28, Loss: 0.385\n",
      "Training: Epoch 67, Batch 29, Loss: 0.352\n",
      "Training: Epoch 67, Batch 30, Loss: 0.244\n",
      "Training: Epoch 67, Batch 31, Loss: 0.461\n",
      "Training: Epoch 67, Batch 32, Loss: 0.342\n",
      "Training: Epoch 67, Batch 33, Loss: 0.374\n",
      "Training: Epoch 67, Batch 34, Loss: 0.308\n",
      "Training: Epoch 67, Batch 35, Loss: 0.271\n",
      "Training: Epoch 67, Batch 36, Loss: 0.268\n",
      "Training: Epoch 67, Batch 37, Loss: 0.266\n",
      "Training: Epoch 67, Batch 38, Loss: 0.339\n",
      "Training: Epoch 67, Batch 39, Loss: 0.263\n",
      "Training: Epoch 67, Batch 40, Loss: 0.41\n",
      "Training: Epoch 67, Batch 41, Loss: 0.356\n",
      "Training: Epoch 67, Batch 42, Loss: 0.617\n",
      "Training: Epoch 67, Batch 43, Loss: 0.306\n",
      "Training: Epoch 67, Batch 44, Loss: 0.364\n",
      "Training: Epoch 67, Batch 45, Loss: 0.448\n",
      "Training: Epoch 67, Batch 46, Loss: 0.34\n",
      "Training: Epoch 67, Batch 47, Loss: 0.473\n",
      "Training: Epoch 67, Batch 48, Loss: 0.4\n",
      "Training: Epoch 67, Batch 49, Loss: 0.134\n",
      "Training: Epoch 67, Batch 50, Loss: 0.547\n",
      "Training: Epoch 67, Batch 51, Loss: 0.359\n",
      "Training: Epoch 67, Batch 52, Loss: 0.317\n",
      "Training: Epoch 67, Batch 53, Loss: 0.398\n",
      "Training: Epoch 67, Batch 54, Loss: 0.39\n",
      "Training: Epoch 67, Batch 55, Loss: 0.21\n",
      "Training: Epoch 67, Batch 56, Loss: 0.155\n",
      "Training: Epoch 67, Batch 57, Loss: 0.409\n",
      "Training: Epoch 67, Batch 58, Loss: 0.264\n",
      "Training: Epoch 67, Batch 59, Loss: 0.24\n",
      "Training: Epoch 67, Batch 60, Loss: 0.216\n",
      "Training: Epoch 67, Batch 61, Loss: 0.374\n",
      "Training: Epoch 67, Batch 62, Loss: 0.322\n",
      "Training: Epoch 67, Batch 63, Loss: 0.407\n",
      "Training: Epoch 67, Batch 64, Loss: 0.244\n",
      "Training: Epoch 67, Batch 65, Loss: 0.382\n",
      "Training: Epoch 67, Batch 66, Loss: 0.291\n",
      "Training: Epoch 67, Batch 67, Loss: 0.511\n",
      "Training: Epoch 67, Batch 68, Loss: 0.417\n",
      "Training: Epoch 67, Batch 69, Loss: 0.489\n",
      "Training: Epoch 67, Batch 70, Loss: 0.383\n",
      "Training: Epoch 67, Batch 71, Loss: 0.467\n",
      "Training: Epoch 67, Batch 72, Loss: 0.544\n",
      "Training: Epoch 67, Batch 73, Loss: 0.314\n",
      "Training: Epoch 67, Batch 74, Loss: 0.391\n",
      "Training: Epoch 67, Batch 75, Loss: 0.387\n",
      "Training: Epoch 67, Batch 76, Loss: 0.22\n",
      "Training: Epoch 67, Batch 77, Loss: 0.448\n",
      "Training: Epoch 67, Batch 78, Loss: 0.47\n",
      "Training: Epoch 67, Batch 79, Loss: 0.395\n",
      "Training: Epoch 67, Batch 80, Loss: 0.579\n",
      "Training: Epoch 67, Batch 81, Loss: 0.387\n",
      "Training: Epoch 67, Batch 82, Loss: 0.415\n",
      "Training: Epoch 67, Batch 83, Loss: 0.285\n",
      "Training: Epoch 67, Batch 84, Loss: 0.445\n",
      "Training: Epoch 67, Batch 85, Loss: 0.469\n",
      "Training: Epoch 67, Batch 86, Loss: 0.272\n",
      "Training: Epoch 67, Batch 87, Loss: 0.286\n",
      "Training: Epoch 67, Batch 88, Loss: 0.363\n",
      "Training: Epoch 67, Batch 89, Loss: 0.244\n",
      "Val: Epoch 67, Loss: 0.262\n",
      "Training: Epoch 68, Batch 0, Loss: 0.275\n",
      "Training: Epoch 68, Batch 1, Loss: 0.348\n",
      "Training: Epoch 68, Batch 2, Loss: 0.539\n",
      "Training: Epoch 68, Batch 3, Loss: 0.207\n",
      "Training: Epoch 68, Batch 4, Loss: 0.376\n",
      "Training: Epoch 68, Batch 5, Loss: 0.331\n",
      "Training: Epoch 68, Batch 6, Loss: 0.405\n",
      "Training: Epoch 68, Batch 7, Loss: 0.314\n",
      "Training: Epoch 68, Batch 8, Loss: 0.302\n",
      "Training: Epoch 68, Batch 9, Loss: 0.313\n",
      "Training: Epoch 68, Batch 10, Loss: 0.36\n",
      "Training: Epoch 68, Batch 11, Loss: 0.286\n",
      "Training: Epoch 68, Batch 12, Loss: 0.286\n",
      "Training: Epoch 68, Batch 13, Loss: 0.502\n",
      "Training: Epoch 68, Batch 14, Loss: 0.429\n",
      "Training: Epoch 68, Batch 15, Loss: 0.365\n",
      "Training: Epoch 68, Batch 16, Loss: 0.121\n",
      "Training: Epoch 68, Batch 17, Loss: 0.443\n",
      "Training: Epoch 68, Batch 18, Loss: 0.337\n",
      "Training: Epoch 68, Batch 19, Loss: 0.361\n",
      "Training: Epoch 68, Batch 20, Loss: 0.2\n",
      "Training: Epoch 68, Batch 21, Loss: 0.392\n",
      "Training: Epoch 68, Batch 22, Loss: 0.364\n",
      "Training: Epoch 68, Batch 23, Loss: 0.274\n",
      "Training: Epoch 68, Batch 24, Loss: 0.367\n",
      "Training: Epoch 68, Batch 25, Loss: 0.35\n",
      "Training: Epoch 68, Batch 26, Loss: 0.51\n",
      "Training: Epoch 68, Batch 27, Loss: 0.5\n",
      "Training: Epoch 68, Batch 28, Loss: 0.323\n",
      "Training: Epoch 68, Batch 29, Loss: 0.481\n",
      "Training: Epoch 68, Batch 30, Loss: 0.4\n",
      "Training: Epoch 68, Batch 31, Loss: 0.222\n",
      "Training: Epoch 68, Batch 32, Loss: 0.437\n",
      "Training: Epoch 68, Batch 33, Loss: 0.381\n",
      "Training: Epoch 68, Batch 34, Loss: 0.325\n",
      "Training: Epoch 68, Batch 35, Loss: 0.359\n",
      "Training: Epoch 68, Batch 36, Loss: 0.395\n",
      "Training: Epoch 68, Batch 37, Loss: 0.315\n",
      "Training: Epoch 68, Batch 38, Loss: 0.322\n",
      "Training: Epoch 68, Batch 39, Loss: 0.257\n",
      "Training: Epoch 68, Batch 40, Loss: 0.395\n",
      "Training: Epoch 68, Batch 41, Loss: 0.336\n",
      "Training: Epoch 68, Batch 42, Loss: 0.44\n",
      "Training: Epoch 68, Batch 43, Loss: 0.289\n",
      "Training: Epoch 68, Batch 44, Loss: 0.25\n",
      "Training: Epoch 68, Batch 45, Loss: 0.268\n",
      "Training: Epoch 68, Batch 46, Loss: 0.194\n",
      "Training: Epoch 68, Batch 47, Loss: 0.365\n",
      "Training: Epoch 68, Batch 48, Loss: 0.455\n",
      "Training: Epoch 68, Batch 49, Loss: 0.352\n",
      "Training: Epoch 68, Batch 50, Loss: 0.377\n",
      "Training: Epoch 68, Batch 51, Loss: 0.382\n",
      "Training: Epoch 68, Batch 52, Loss: 0.263\n",
      "Training: Epoch 68, Batch 53, Loss: 0.61\n",
      "Training: Epoch 68, Batch 54, Loss: 0.294\n",
      "Training: Epoch 68, Batch 55, Loss: 0.343\n",
      "Training: Epoch 68, Batch 56, Loss: 0.134\n",
      "Training: Epoch 68, Batch 57, Loss: 0.308\n",
      "Training: Epoch 68, Batch 58, Loss: 0.429\n",
      "Training: Epoch 68, Batch 59, Loss: 0.21\n",
      "Training: Epoch 68, Batch 60, Loss: 0.428\n",
      "Training: Epoch 68, Batch 61, Loss: 0.493\n",
      "Training: Epoch 68, Batch 62, Loss: 0.719\n",
      "Training: Epoch 68, Batch 63, Loss: 0.38\n",
      "Training: Epoch 68, Batch 64, Loss: 0.373\n",
      "Training: Epoch 68, Batch 65, Loss: 0.33\n",
      "Training: Epoch 68, Batch 66, Loss: 0.453\n",
      "Training: Epoch 68, Batch 67, Loss: 0.427\n",
      "Training: Epoch 68, Batch 68, Loss: 0.263\n",
      "Training: Epoch 68, Batch 69, Loss: 0.31\n",
      "Training: Epoch 68, Batch 70, Loss: 0.4\n",
      "Training: Epoch 68, Batch 71, Loss: 0.151\n",
      "Training: Epoch 68, Batch 72, Loss: 0.413\n",
      "Training: Epoch 68, Batch 73, Loss: 0.384\n",
      "Training: Epoch 68, Batch 74, Loss: 0.315\n",
      "Training: Epoch 68, Batch 75, Loss: 0.437\n",
      "Training: Epoch 68, Batch 76, Loss: 0.691\n",
      "Training: Epoch 68, Batch 77, Loss: 0.679\n",
      "Training: Epoch 68, Batch 78, Loss: 0.688\n",
      "Training: Epoch 68, Batch 79, Loss: 0.473\n",
      "Training: Epoch 68, Batch 80, Loss: 0.487\n",
      "Training: Epoch 68, Batch 81, Loss: 0.303\n",
      "Training: Epoch 68, Batch 82, Loss: 0.451\n",
      "Training: Epoch 68, Batch 83, Loss: 0.27\n",
      "Training: Epoch 68, Batch 84, Loss: 0.417\n",
      "Training: Epoch 68, Batch 85, Loss: 0.396\n",
      "Training: Epoch 68, Batch 86, Loss: 0.279\n",
      "Training: Epoch 68, Batch 87, Loss: 0.235\n",
      "Training: Epoch 68, Batch 88, Loss: 0.506\n",
      "Training: Epoch 68, Batch 89, Loss: 0.444\n",
      "Val: Epoch 68, Loss: 0.259\n",
      "Training: Epoch 69, Batch 0, Loss: 0.493\n",
      "Training: Epoch 69, Batch 1, Loss: 0.329\n",
      "Training: Epoch 69, Batch 2, Loss: 0.271\n",
      "Training: Epoch 69, Batch 3, Loss: 0.429\n",
      "Training: Epoch 69, Batch 4, Loss: 0.274\n",
      "Training: Epoch 69, Batch 5, Loss: 0.418\n",
      "Training: Epoch 69, Batch 6, Loss: 0.224\n",
      "Training: Epoch 69, Batch 7, Loss: 0.588\n",
      "Training: Epoch 69, Batch 8, Loss: 0.242\n",
      "Training: Epoch 69, Batch 9, Loss: 0.349\n",
      "Training: Epoch 69, Batch 10, Loss: 0.424\n",
      "Training: Epoch 69, Batch 11, Loss: 0.338\n",
      "Training: Epoch 69, Batch 12, Loss: 0.308\n",
      "Training: Epoch 69, Batch 13, Loss: 0.27\n",
      "Training: Epoch 69, Batch 14, Loss: 0.456\n",
      "Training: Epoch 69, Batch 15, Loss: 0.312\n",
      "Training: Epoch 69, Batch 16, Loss: 0.456\n",
      "Training: Epoch 69, Batch 17, Loss: 0.396\n",
      "Training: Epoch 69, Batch 18, Loss: 0.341\n",
      "Training: Epoch 69, Batch 19, Loss: 0.286\n",
      "Training: Epoch 69, Batch 20, Loss: 0.294\n",
      "Training: Epoch 69, Batch 21, Loss: 0.492\n",
      "Training: Epoch 69, Batch 22, Loss: 0.405\n",
      "Training: Epoch 69, Batch 23, Loss: 0.272\n",
      "Training: Epoch 69, Batch 24, Loss: 0.204\n",
      "Training: Epoch 69, Batch 25, Loss: 0.406\n",
      "Training: Epoch 69, Batch 26, Loss: 0.346\n",
      "Training: Epoch 69, Batch 27, Loss: 0.255\n",
      "Training: Epoch 69, Batch 28, Loss: 0.321\n",
      "Training: Epoch 69, Batch 29, Loss: 0.428\n",
      "Training: Epoch 69, Batch 30, Loss: 0.148\n",
      "Training: Epoch 69, Batch 31, Loss: 0.257\n",
      "Training: Epoch 69, Batch 32, Loss: 0.544\n",
      "Training: Epoch 69, Batch 33, Loss: 0.391\n",
      "Training: Epoch 69, Batch 34, Loss: 0.395\n",
      "Training: Epoch 69, Batch 35, Loss: 0.435\n",
      "Training: Epoch 69, Batch 36, Loss: 0.339\n",
      "Training: Epoch 69, Batch 37, Loss: 0.502\n",
      "Training: Epoch 69, Batch 38, Loss: 0.188\n",
      "Training: Epoch 69, Batch 39, Loss: 0.414\n",
      "Training: Epoch 69, Batch 40, Loss: 0.438\n",
      "Training: Epoch 69, Batch 41, Loss: 0.395\n",
      "Training: Epoch 69, Batch 42, Loss: 0.258\n",
      "Training: Epoch 69, Batch 43, Loss: 0.474\n",
      "Training: Epoch 69, Batch 44, Loss: 0.523\n",
      "Training: Epoch 69, Batch 45, Loss: 0.421\n",
      "Training: Epoch 69, Batch 46, Loss: 0.436\n",
      "Training: Epoch 69, Batch 47, Loss: 0.507\n",
      "Training: Epoch 69, Batch 48, Loss: 0.274\n",
      "Training: Epoch 69, Batch 49, Loss: 0.217\n",
      "Training: Epoch 69, Batch 50, Loss: 0.371\n",
      "Training: Epoch 69, Batch 51, Loss: 0.323\n",
      "Training: Epoch 69, Batch 52, Loss: 0.324\n",
      "Training: Epoch 69, Batch 53, Loss: 0.468\n",
      "Training: Epoch 69, Batch 54, Loss: 0.322\n",
      "Training: Epoch 69, Batch 55, Loss: 0.364\n",
      "Training: Epoch 69, Batch 56, Loss: 0.433\n",
      "Training: Epoch 69, Batch 57, Loss: 0.547\n",
      "Training: Epoch 69, Batch 58, Loss: 0.339\n",
      "Training: Epoch 69, Batch 59, Loss: 0.262\n",
      "Training: Epoch 69, Batch 60, Loss: 0.381\n",
      "Training: Epoch 69, Batch 61, Loss: 0.228\n",
      "Training: Epoch 69, Batch 62, Loss: 0.426\n",
      "Training: Epoch 69, Batch 63, Loss: 0.3\n",
      "Training: Epoch 69, Batch 64, Loss: 0.242\n",
      "Training: Epoch 69, Batch 65, Loss: 0.218\n",
      "Training: Epoch 69, Batch 66, Loss: 0.308\n",
      "Training: Epoch 69, Batch 67, Loss: 0.335\n",
      "Training: Epoch 69, Batch 68, Loss: 0.35\n",
      "Training: Epoch 69, Batch 69, Loss: 0.509\n",
      "Training: Epoch 69, Batch 70, Loss: 0.473\n",
      "Training: Epoch 69, Batch 71, Loss: 0.61\n",
      "Training: Epoch 69, Batch 72, Loss: 0.38\n",
      "Training: Epoch 69, Batch 73, Loss: 0.315\n",
      "Training: Epoch 69, Batch 74, Loss: 0.511\n",
      "Training: Epoch 69, Batch 75, Loss: 0.281\n",
      "Training: Epoch 69, Batch 76, Loss: 0.271\n",
      "Training: Epoch 69, Batch 77, Loss: 0.321\n",
      "Training: Epoch 69, Batch 78, Loss: 0.422\n",
      "Training: Epoch 69, Batch 79, Loss: 0.362\n",
      "Training: Epoch 69, Batch 80, Loss: 0.339\n",
      "Training: Epoch 69, Batch 81, Loss: 0.413\n",
      "Training: Epoch 69, Batch 82, Loss: 0.435\n",
      "Training: Epoch 69, Batch 83, Loss: 0.364\n",
      "Training: Epoch 69, Batch 84, Loss: 0.292\n",
      "Training: Epoch 69, Batch 85, Loss: 0.406\n",
      "Training: Epoch 69, Batch 86, Loss: 0.399\n",
      "Training: Epoch 69, Batch 87, Loss: 0.34\n",
      "Training: Epoch 69, Batch 88, Loss: 0.459\n",
      "Training: Epoch 69, Batch 89, Loss: 0.347\n",
      "Val: Epoch 69, Loss: 0.257\n",
      "Training: Epoch 70, Batch 0, Loss: 0.308\n",
      "Training: Epoch 70, Batch 1, Loss: 0.191\n",
      "Training: Epoch 70, Batch 2, Loss: 0.373\n",
      "Training: Epoch 70, Batch 3, Loss: 0.349\n",
      "Training: Epoch 70, Batch 4, Loss: 0.371\n",
      "Training: Epoch 70, Batch 5, Loss: 0.587\n",
      "Training: Epoch 70, Batch 6, Loss: 0.302\n",
      "Training: Epoch 70, Batch 7, Loss: 0.363\n",
      "Training: Epoch 70, Batch 8, Loss: 0.324\n",
      "Training: Epoch 70, Batch 9, Loss: 0.558\n",
      "Training: Epoch 70, Batch 10, Loss: 0.228\n",
      "Training: Epoch 70, Batch 11, Loss: 0.306\n",
      "Training: Epoch 70, Batch 12, Loss: 0.37\n",
      "Training: Epoch 70, Batch 13, Loss: 0.385\n",
      "Training: Epoch 70, Batch 14, Loss: 0.582\n",
      "Training: Epoch 70, Batch 15, Loss: 0.373\n",
      "Training: Epoch 70, Batch 16, Loss: 0.548\n",
      "Training: Epoch 70, Batch 17, Loss: 0.433\n",
      "Training: Epoch 70, Batch 18, Loss: 0.413\n",
      "Training: Epoch 70, Batch 19, Loss: 0.287\n",
      "Training: Epoch 70, Batch 20, Loss: 0.462\n",
      "Training: Epoch 70, Batch 21, Loss: 0.137\n",
      "Training: Epoch 70, Batch 22, Loss: 0.312\n",
      "Training: Epoch 70, Batch 23, Loss: 0.288\n",
      "Training: Epoch 70, Batch 24, Loss: 0.356\n",
      "Training: Epoch 70, Batch 25, Loss: 0.484\n",
      "Training: Epoch 70, Batch 26, Loss: 0.308\n",
      "Training: Epoch 70, Batch 27, Loss: 0.569\n",
      "Training: Epoch 70, Batch 28, Loss: 0.413\n",
      "Training: Epoch 70, Batch 29, Loss: 0.504\n",
      "Training: Epoch 70, Batch 30, Loss: 0.394\n",
      "Training: Epoch 70, Batch 31, Loss: 0.366\n",
      "Training: Epoch 70, Batch 32, Loss: 0.466\n",
      "Training: Epoch 70, Batch 33, Loss: 0.143\n",
      "Training: Epoch 70, Batch 34, Loss: 0.322\n",
      "Training: Epoch 70, Batch 35, Loss: 0.416\n",
      "Training: Epoch 70, Batch 36, Loss: 0.207\n",
      "Training: Epoch 70, Batch 37, Loss: 0.444\n",
      "Training: Epoch 70, Batch 38, Loss: 0.627\n",
      "Training: Epoch 70, Batch 39, Loss: 0.339\n",
      "Training: Epoch 70, Batch 40, Loss: 0.381\n",
      "Training: Epoch 70, Batch 41, Loss: 0.206\n",
      "Training: Epoch 70, Batch 42, Loss: 0.219\n",
      "Training: Epoch 70, Batch 43, Loss: 0.353\n",
      "Training: Epoch 70, Batch 44, Loss: 0.398\n",
      "Training: Epoch 70, Batch 45, Loss: 0.347\n",
      "Training: Epoch 70, Batch 46, Loss: 0.405\n",
      "Training: Epoch 70, Batch 47, Loss: 0.305\n",
      "Training: Epoch 70, Batch 48, Loss: 0.229\n",
      "Training: Epoch 70, Batch 49, Loss: 0.147\n",
      "Training: Epoch 70, Batch 50, Loss: 0.319\n",
      "Training: Epoch 70, Batch 51, Loss: 0.303\n",
      "Training: Epoch 70, Batch 52, Loss: 0.289\n",
      "Training: Epoch 70, Batch 53, Loss: 0.369\n",
      "Training: Epoch 70, Batch 54, Loss: 0.432\n",
      "Training: Epoch 70, Batch 55, Loss: 0.261\n",
      "Training: Epoch 70, Batch 56, Loss: 0.445\n",
      "Training: Epoch 70, Batch 57, Loss: 0.424\n",
      "Training: Epoch 70, Batch 58, Loss: 0.287\n",
      "Training: Epoch 70, Batch 59, Loss: 0.352\n",
      "Training: Epoch 70, Batch 60, Loss: 0.54\n",
      "Training: Epoch 70, Batch 61, Loss: 0.601\n",
      "Training: Epoch 70, Batch 62, Loss: 0.391\n",
      "Training: Epoch 70, Batch 63, Loss: 0.423\n",
      "Training: Epoch 70, Batch 64, Loss: 0.371\n",
      "Training: Epoch 70, Batch 65, Loss: 0.351\n",
      "Training: Epoch 70, Batch 66, Loss: 0.431\n",
      "Training: Epoch 70, Batch 67, Loss: 0.438\n",
      "Training: Epoch 70, Batch 68, Loss: 0.487\n",
      "Training: Epoch 70, Batch 69, Loss: 0.547\n",
      "Training: Epoch 70, Batch 70, Loss: 0.39\n",
      "Training: Epoch 70, Batch 71, Loss: 0.338\n",
      "Training: Epoch 70, Batch 72, Loss: 0.37\n",
      "Training: Epoch 70, Batch 73, Loss: 0.204\n",
      "Training: Epoch 70, Batch 74, Loss: 0.454\n",
      "Training: Epoch 70, Batch 75, Loss: 0.344\n",
      "Training: Epoch 70, Batch 76, Loss: 0.395\n",
      "Training: Epoch 70, Batch 77, Loss: 0.207\n",
      "Training: Epoch 70, Batch 78, Loss: 0.341\n",
      "Training: Epoch 70, Batch 79, Loss: 0.424\n",
      "Training: Epoch 70, Batch 80, Loss: 0.366\n",
      "Training: Epoch 70, Batch 81, Loss: 0.545\n",
      "Training: Epoch 70, Batch 82, Loss: 0.217\n",
      "Training: Epoch 70, Batch 83, Loss: 0.287\n",
      "Training: Epoch 70, Batch 84, Loss: 0.362\n",
      "Training: Epoch 70, Batch 85, Loss: 0.178\n",
      "Training: Epoch 70, Batch 86, Loss: 0.238\n",
      "Training: Epoch 70, Batch 87, Loss: 0.151\n",
      "Training: Epoch 70, Batch 88, Loss: 0.28\n",
      "Training: Epoch 70, Batch 89, Loss: 0.232\n",
      "Val: Epoch 70, Loss: 0.246\n",
      "Training: Epoch 71, Batch 0, Loss: 0.337\n",
      "Training: Epoch 71, Batch 1, Loss: 0.263\n",
      "Training: Epoch 71, Batch 2, Loss: 0.315\n",
      "Training: Epoch 71, Batch 3, Loss: 0.17\n",
      "Training: Epoch 71, Batch 4, Loss: 0.201\n",
      "Training: Epoch 71, Batch 5, Loss: 0.279\n",
      "Training: Epoch 71, Batch 6, Loss: 0.471\n",
      "Training: Epoch 71, Batch 7, Loss: 0.412\n",
      "Training: Epoch 71, Batch 8, Loss: 0.275\n",
      "Training: Epoch 71, Batch 9, Loss: 0.293\n",
      "Training: Epoch 71, Batch 10, Loss: 0.289\n",
      "Training: Epoch 71, Batch 11, Loss: 0.4\n",
      "Training: Epoch 71, Batch 12, Loss: 0.322\n",
      "Training: Epoch 71, Batch 13, Loss: 0.335\n",
      "Training: Epoch 71, Batch 14, Loss: 0.513\n",
      "Training: Epoch 71, Batch 15, Loss: 0.215\n",
      "Training: Epoch 71, Batch 16, Loss: 0.528\n",
      "Training: Epoch 71, Batch 17, Loss: 0.377\n",
      "Training: Epoch 71, Batch 18, Loss: 0.196\n",
      "Training: Epoch 71, Batch 19, Loss: 0.246\n",
      "Training: Epoch 71, Batch 20, Loss: 0.232\n",
      "Training: Epoch 71, Batch 21, Loss: 0.303\n",
      "Training: Epoch 71, Batch 22, Loss: 0.286\n",
      "Training: Epoch 71, Batch 23, Loss: 0.391\n",
      "Training: Epoch 71, Batch 24, Loss: 0.495\n",
      "Training: Epoch 71, Batch 25, Loss: 0.267\n",
      "Training: Epoch 71, Batch 26, Loss: 0.279\n",
      "Training: Epoch 71, Batch 27, Loss: 0.549\n",
      "Training: Epoch 71, Batch 28, Loss: 0.382\n",
      "Training: Epoch 71, Batch 29, Loss: 0.373\n",
      "Training: Epoch 71, Batch 30, Loss: 0.374\n",
      "Training: Epoch 71, Batch 31, Loss: 0.372\n",
      "Training: Epoch 71, Batch 32, Loss: 0.441\n",
      "Training: Epoch 71, Batch 33, Loss: 0.471\n",
      "Training: Epoch 71, Batch 34, Loss: 0.377\n",
      "Training: Epoch 71, Batch 35, Loss: 0.251\n",
      "Training: Epoch 71, Batch 36, Loss: 0.345\n",
      "Training: Epoch 71, Batch 37, Loss: 0.39\n",
      "Training: Epoch 71, Batch 38, Loss: 0.248\n",
      "Training: Epoch 71, Batch 39, Loss: 0.44\n",
      "Training: Epoch 71, Batch 40, Loss: 0.213\n",
      "Training: Epoch 71, Batch 41, Loss: 0.32\n",
      "Training: Epoch 71, Batch 42, Loss: 0.277\n",
      "Training: Epoch 71, Batch 43, Loss: 0.261\n",
      "Training: Epoch 71, Batch 44, Loss: 0.581\n",
      "Training: Epoch 71, Batch 45, Loss: 0.414\n",
      "Training: Epoch 71, Batch 46, Loss: 0.333\n",
      "Training: Epoch 71, Batch 47, Loss: 0.159\n",
      "Training: Epoch 71, Batch 48, Loss: 0.533\n",
      "Training: Epoch 71, Batch 49, Loss: 0.4\n",
      "Training: Epoch 71, Batch 50, Loss: 0.232\n",
      "Training: Epoch 71, Batch 51, Loss: 0.516\n",
      "Training: Epoch 71, Batch 52, Loss: 0.269\n",
      "Training: Epoch 71, Batch 53, Loss: 0.464\n",
      "Training: Epoch 71, Batch 54, Loss: 0.413\n",
      "Training: Epoch 71, Batch 55, Loss: 0.158\n",
      "Training: Epoch 71, Batch 56, Loss: 0.328\n",
      "Training: Epoch 71, Batch 57, Loss: 0.154\n",
      "Training: Epoch 71, Batch 58, Loss: 0.439\n",
      "Training: Epoch 71, Batch 59, Loss: 0.534\n",
      "Training: Epoch 71, Batch 60, Loss: 0.421\n",
      "Training: Epoch 71, Batch 61, Loss: 0.303\n",
      "Training: Epoch 71, Batch 62, Loss: 0.477\n",
      "Training: Epoch 71, Batch 63, Loss: 0.307\n",
      "Training: Epoch 71, Batch 64, Loss: 0.323\n",
      "Training: Epoch 71, Batch 65, Loss: 0.299\n",
      "Training: Epoch 71, Batch 66, Loss: 0.279\n",
      "Training: Epoch 71, Batch 67, Loss: 0.404\n",
      "Training: Epoch 71, Batch 68, Loss: 0.242\n",
      "Training: Epoch 71, Batch 69, Loss: 0.242\n",
      "Training: Epoch 71, Batch 70, Loss: 0.22\n",
      "Training: Epoch 71, Batch 71, Loss: 0.475\n",
      "Training: Epoch 71, Batch 72, Loss: 0.242\n",
      "Training: Epoch 71, Batch 73, Loss: 0.383\n",
      "Training: Epoch 71, Batch 74, Loss: 0.531\n",
      "Training: Epoch 71, Batch 75, Loss: 0.374\n",
      "Training: Epoch 71, Batch 76, Loss: 0.463\n",
      "Training: Epoch 71, Batch 77, Loss: 0.49\n",
      "Training: Epoch 71, Batch 78, Loss: 0.443\n",
      "Training: Epoch 71, Batch 79, Loss: 0.39\n",
      "Training: Epoch 71, Batch 80, Loss: 0.411\n",
      "Training: Epoch 71, Batch 81, Loss: 0.336\n",
      "Training: Epoch 71, Batch 82, Loss: 0.417\n",
      "Training: Epoch 71, Batch 83, Loss: 0.557\n",
      "Training: Epoch 71, Batch 84, Loss: 0.272\n",
      "Training: Epoch 71, Batch 85, Loss: 0.245\n",
      "Training: Epoch 71, Batch 86, Loss: 0.696\n",
      "Training: Epoch 71, Batch 87, Loss: 0.366\n",
      "Training: Epoch 71, Batch 88, Loss: 0.329\n",
      "Training: Epoch 71, Batch 89, Loss: 0.198\n",
      "Val: Epoch 71, Loss: 0.267\n",
      "Training: Epoch 72, Batch 0, Loss: 0.287\n",
      "Training: Epoch 72, Batch 1, Loss: 0.427\n",
      "Training: Epoch 72, Batch 2, Loss: 0.333\n",
      "Training: Epoch 72, Batch 3, Loss: 0.344\n",
      "Training: Epoch 72, Batch 4, Loss: 0.514\n",
      "Training: Epoch 72, Batch 5, Loss: 0.21\n",
      "Training: Epoch 72, Batch 6, Loss: 0.248\n",
      "Training: Epoch 72, Batch 7, Loss: 0.383\n",
      "Training: Epoch 72, Batch 8, Loss: 0.368\n",
      "Training: Epoch 72, Batch 9, Loss: 0.476\n",
      "Training: Epoch 72, Batch 10, Loss: 0.383\n",
      "Training: Epoch 72, Batch 11, Loss: 0.266\n",
      "Training: Epoch 72, Batch 12, Loss: 0.323\n",
      "Training: Epoch 72, Batch 13, Loss: 0.371\n",
      "Training: Epoch 72, Batch 14, Loss: 0.38\n",
      "Training: Epoch 72, Batch 15, Loss: 0.292\n",
      "Training: Epoch 72, Batch 16, Loss: 0.341\n",
      "Training: Epoch 72, Batch 17, Loss: 0.235\n",
      "Training: Epoch 72, Batch 18, Loss: 0.3\n",
      "Training: Epoch 72, Batch 19, Loss: 0.294\n",
      "Training: Epoch 72, Batch 20, Loss: 0.249\n",
      "Training: Epoch 72, Batch 21, Loss: 0.323\n",
      "Training: Epoch 72, Batch 22, Loss: 0.406\n",
      "Training: Epoch 72, Batch 23, Loss: 0.484\n",
      "Training: Epoch 72, Batch 24, Loss: 0.342\n",
      "Training: Epoch 72, Batch 25, Loss: 0.35\n",
      "Training: Epoch 72, Batch 26, Loss: 0.275\n",
      "Training: Epoch 72, Batch 27, Loss: 0.234\n",
      "Training: Epoch 72, Batch 28, Loss: 0.269\n",
      "Training: Epoch 72, Batch 29, Loss: 0.343\n",
      "Training: Epoch 72, Batch 30, Loss: 0.327\n",
      "Training: Epoch 72, Batch 31, Loss: 0.54\n",
      "Training: Epoch 72, Batch 32, Loss: 0.273\n",
      "Training: Epoch 72, Batch 33, Loss: 0.31\n",
      "Training: Epoch 72, Batch 34, Loss: 0.352\n",
      "Training: Epoch 72, Batch 35, Loss: 0.128\n",
      "Training: Epoch 72, Batch 36, Loss: 0.165\n",
      "Training: Epoch 72, Batch 37, Loss: 0.145\n",
      "Training: Epoch 72, Batch 38, Loss: 0.33\n",
      "Training: Epoch 72, Batch 39, Loss: 0.317\n",
      "Training: Epoch 72, Batch 40, Loss: 0.565\n",
      "Training: Epoch 72, Batch 41, Loss: 0.32\n",
      "Training: Epoch 72, Batch 42, Loss: 0.387\n",
      "Training: Epoch 72, Batch 43, Loss: 0.596\n",
      "Training: Epoch 72, Batch 44, Loss: 0.272\n",
      "Training: Epoch 72, Batch 45, Loss: 0.443\n",
      "Training: Epoch 72, Batch 46, Loss: 0.391\n",
      "Training: Epoch 72, Batch 47, Loss: 0.275\n",
      "Training: Epoch 72, Batch 48, Loss: 0.276\n",
      "Training: Epoch 72, Batch 49, Loss: 0.491\n",
      "Training: Epoch 72, Batch 50, Loss: 0.317\n",
      "Training: Epoch 72, Batch 51, Loss: 0.358\n",
      "Training: Epoch 72, Batch 52, Loss: 0.328\n",
      "Training: Epoch 72, Batch 53, Loss: 0.347\n",
      "Training: Epoch 72, Batch 54, Loss: 0.301\n",
      "Training: Epoch 72, Batch 55, Loss: 0.314\n",
      "Training: Epoch 72, Batch 56, Loss: 0.17\n",
      "Training: Epoch 72, Batch 57, Loss: 0.279\n",
      "Training: Epoch 72, Batch 58, Loss: 0.178\n",
      "Training: Epoch 72, Batch 59, Loss: 0.478\n",
      "Training: Epoch 72, Batch 60, Loss: 0.43\n",
      "Training: Epoch 72, Batch 61, Loss: 0.363\n",
      "Training: Epoch 72, Batch 62, Loss: 0.38\n",
      "Training: Epoch 72, Batch 63, Loss: 0.385\n",
      "Training: Epoch 72, Batch 64, Loss: 0.312\n",
      "Training: Epoch 72, Batch 65, Loss: 0.321\n",
      "Training: Epoch 72, Batch 66, Loss: 0.365\n",
      "Training: Epoch 72, Batch 67, Loss: 0.551\n",
      "Training: Epoch 72, Batch 68, Loss: 0.198\n",
      "Training: Epoch 72, Batch 69, Loss: 0.598\n",
      "Training: Epoch 72, Batch 70, Loss: 0.175\n",
      "Training: Epoch 72, Batch 71, Loss: 0.23\n",
      "Training: Epoch 72, Batch 72, Loss: 0.277\n",
      "Training: Epoch 72, Batch 73, Loss: 0.467\n",
      "Training: Epoch 72, Batch 74, Loss: 0.349\n",
      "Training: Epoch 72, Batch 75, Loss: 0.49\n",
      "Training: Epoch 72, Batch 76, Loss: 0.365\n",
      "Training: Epoch 72, Batch 77, Loss: 0.596\n",
      "Training: Epoch 72, Batch 78, Loss: 0.233\n",
      "Training: Epoch 72, Batch 79, Loss: 0.478\n",
      "Training: Epoch 72, Batch 80, Loss: 0.422\n",
      "Training: Epoch 72, Batch 81, Loss: 0.278\n",
      "Training: Epoch 72, Batch 82, Loss: 0.292\n",
      "Training: Epoch 72, Batch 83, Loss: 0.417\n",
      "Training: Epoch 72, Batch 84, Loss: 0.478\n",
      "Training: Epoch 72, Batch 85, Loss: 0.398\n",
      "Training: Epoch 72, Batch 86, Loss: 0.184\n",
      "Training: Epoch 72, Batch 87, Loss: 0.364\n",
      "Training: Epoch 72, Batch 88, Loss: 0.341\n",
      "Training: Epoch 72, Batch 89, Loss: 0.48\n",
      "Val: Epoch 72, Loss: 0.282\n",
      "Training: Epoch 73, Batch 0, Loss: 0.189\n",
      "Training: Epoch 73, Batch 1, Loss: 0.308\n",
      "Training: Epoch 73, Batch 2, Loss: 0.248\n",
      "Training: Epoch 73, Batch 3, Loss: 0.23\n",
      "Training: Epoch 73, Batch 4, Loss: 0.21\n",
      "Training: Epoch 73, Batch 5, Loss: 0.47\n",
      "Training: Epoch 73, Batch 6, Loss: 0.262\n",
      "Training: Epoch 73, Batch 7, Loss: 0.358\n",
      "Training: Epoch 73, Batch 8, Loss: 0.34\n",
      "Training: Epoch 73, Batch 9, Loss: 0.41\n",
      "Training: Epoch 73, Batch 10, Loss: 0.489\n",
      "Training: Epoch 73, Batch 11, Loss: 0.376\n",
      "Training: Epoch 73, Batch 12, Loss: 0.467\n",
      "Training: Epoch 73, Batch 13, Loss: 0.492\n",
      "Training: Epoch 73, Batch 14, Loss: 0.432\n",
      "Training: Epoch 73, Batch 15, Loss: 0.244\n",
      "Training: Epoch 73, Batch 16, Loss: 0.302\n",
      "Training: Epoch 73, Batch 17, Loss: 0.301\n",
      "Training: Epoch 73, Batch 18, Loss: 0.394\n",
      "Training: Epoch 73, Batch 19, Loss: 0.316\n",
      "Training: Epoch 73, Batch 20, Loss: 0.512\n",
      "Training: Epoch 73, Batch 21, Loss: 0.255\n",
      "Training: Epoch 73, Batch 22, Loss: 0.498\n",
      "Training: Epoch 73, Batch 23, Loss: 0.23\n",
      "Training: Epoch 73, Batch 24, Loss: 0.205\n",
      "Training: Epoch 73, Batch 25, Loss: 0.376\n",
      "Training: Epoch 73, Batch 26, Loss: 0.422\n",
      "Training: Epoch 73, Batch 27, Loss: 0.158\n",
      "Training: Epoch 73, Batch 28, Loss: 0.484\n",
      "Training: Epoch 73, Batch 29, Loss: 0.637\n",
      "Training: Epoch 73, Batch 30, Loss: 0.294\n",
      "Training: Epoch 73, Batch 31, Loss: 0.484\n",
      "Training: Epoch 73, Batch 32, Loss: 0.392\n",
      "Training: Epoch 73, Batch 33, Loss: 0.726\n",
      "Training: Epoch 73, Batch 34, Loss: 0.426\n",
      "Training: Epoch 73, Batch 35, Loss: 0.35\n",
      "Training: Epoch 73, Batch 36, Loss: 0.559\n",
      "Training: Epoch 73, Batch 37, Loss: 0.5\n",
      "Training: Epoch 73, Batch 38, Loss: 0.361\n",
      "Training: Epoch 73, Batch 39, Loss: 0.321\n",
      "Training: Epoch 73, Batch 40, Loss: 0.203\n",
      "Training: Epoch 73, Batch 41, Loss: 0.483\n",
      "Training: Epoch 73, Batch 42, Loss: 0.213\n",
      "Training: Epoch 73, Batch 43, Loss: 0.458\n",
      "Training: Epoch 73, Batch 44, Loss: 0.299\n",
      "Training: Epoch 73, Batch 45, Loss: 0.369\n",
      "Training: Epoch 73, Batch 46, Loss: 0.206\n",
      "Training: Epoch 73, Batch 47, Loss: 0.419\n",
      "Training: Epoch 73, Batch 48, Loss: 0.253\n",
      "Training: Epoch 73, Batch 49, Loss: 0.187\n",
      "Training: Epoch 73, Batch 50, Loss: 0.259\n",
      "Training: Epoch 73, Batch 51, Loss: 0.198\n",
      "Training: Epoch 73, Batch 52, Loss: 0.263\n",
      "Training: Epoch 73, Batch 53, Loss: 0.548\n",
      "Training: Epoch 73, Batch 54, Loss: 0.227\n",
      "Training: Epoch 73, Batch 55, Loss: 0.285\n",
      "Training: Epoch 73, Batch 56, Loss: 0.483\n",
      "Training: Epoch 73, Batch 57, Loss: 0.246\n",
      "Training: Epoch 73, Batch 58, Loss: 0.405\n",
      "Training: Epoch 73, Batch 59, Loss: 0.472\n",
      "Training: Epoch 73, Batch 60, Loss: 0.295\n",
      "Training: Epoch 73, Batch 61, Loss: 0.312\n",
      "Training: Epoch 73, Batch 62, Loss: 0.157\n",
      "Training: Epoch 73, Batch 63, Loss: 0.357\n",
      "Training: Epoch 73, Batch 64, Loss: 0.331\n",
      "Training: Epoch 73, Batch 65, Loss: 0.344\n",
      "Training: Epoch 73, Batch 66, Loss: 0.335\n",
      "Training: Epoch 73, Batch 67, Loss: 0.354\n",
      "Training: Epoch 73, Batch 68, Loss: 0.326\n",
      "Training: Epoch 73, Batch 69, Loss: 0.312\n",
      "Training: Epoch 73, Batch 70, Loss: 0.407\n",
      "Training: Epoch 73, Batch 71, Loss: 0.221\n",
      "Training: Epoch 73, Batch 72, Loss: 0.186\n",
      "Training: Epoch 73, Batch 73, Loss: 0.313\n",
      "Training: Epoch 73, Batch 74, Loss: 0.333\n",
      "Training: Epoch 73, Batch 75, Loss: 0.418\n",
      "Training: Epoch 73, Batch 76, Loss: 0.277\n",
      "Training: Epoch 73, Batch 77, Loss: 0.21\n",
      "Training: Epoch 73, Batch 78, Loss: 0.281\n",
      "Training: Epoch 73, Batch 79, Loss: 0.366\n",
      "Training: Epoch 73, Batch 80, Loss: 0.31\n",
      "Training: Epoch 73, Batch 81, Loss: 0.382\n",
      "Training: Epoch 73, Batch 82, Loss: 0.343\n",
      "Training: Epoch 73, Batch 83, Loss: 0.518\n",
      "Training: Epoch 73, Batch 84, Loss: 0.333\n",
      "Training: Epoch 73, Batch 85, Loss: 0.432\n",
      "Training: Epoch 73, Batch 86, Loss: 0.349\n",
      "Training: Epoch 73, Batch 87, Loss: 0.632\n",
      "Training: Epoch 73, Batch 88, Loss: 0.252\n",
      "Training: Epoch 73, Batch 89, Loss: 0.413\n",
      "Val: Epoch 73, Loss: 0.263\n",
      "Training: Epoch 74, Batch 0, Loss: 0.205\n",
      "Training: Epoch 74, Batch 1, Loss: 0.403\n",
      "Training: Epoch 74, Batch 2, Loss: 0.311\n",
      "Training: Epoch 74, Batch 3, Loss: 0.465\n",
      "Training: Epoch 74, Batch 4, Loss: 0.317\n",
      "Training: Epoch 74, Batch 5, Loss: 0.371\n",
      "Training: Epoch 74, Batch 6, Loss: 0.279\n",
      "Training: Epoch 74, Batch 7, Loss: 0.23\n",
      "Training: Epoch 74, Batch 8, Loss: 0.559\n",
      "Training: Epoch 74, Batch 9, Loss: 0.125\n",
      "Training: Epoch 74, Batch 10, Loss: 0.422\n",
      "Training: Epoch 74, Batch 11, Loss: 0.35\n",
      "Training: Epoch 74, Batch 12, Loss: 0.362\n",
      "Training: Epoch 74, Batch 13, Loss: 0.435\n",
      "Training: Epoch 74, Batch 14, Loss: 0.524\n",
      "Training: Epoch 74, Batch 15, Loss: 0.312\n",
      "Training: Epoch 74, Batch 16, Loss: 0.301\n",
      "Training: Epoch 74, Batch 17, Loss: 0.401\n",
      "Training: Epoch 74, Batch 18, Loss: 0.413\n",
      "Training: Epoch 74, Batch 19, Loss: 0.28\n",
      "Training: Epoch 74, Batch 20, Loss: 0.318\n",
      "Training: Epoch 74, Batch 21, Loss: 0.34\n",
      "Training: Epoch 74, Batch 22, Loss: 0.548\n",
      "Training: Epoch 74, Batch 23, Loss: 0.215\n",
      "Training: Epoch 74, Batch 24, Loss: 0.361\n",
      "Training: Epoch 74, Batch 25, Loss: 0.387\n",
      "Training: Epoch 74, Batch 26, Loss: 0.349\n",
      "Training: Epoch 74, Batch 27, Loss: 0.337\n",
      "Training: Epoch 74, Batch 28, Loss: 0.364\n",
      "Training: Epoch 74, Batch 29, Loss: 0.318\n",
      "Training: Epoch 74, Batch 30, Loss: 0.378\n",
      "Training: Epoch 74, Batch 31, Loss: 0.311\n",
      "Training: Epoch 74, Batch 32, Loss: 0.302\n",
      "Training: Epoch 74, Batch 33, Loss: 0.433\n",
      "Training: Epoch 74, Batch 34, Loss: 0.508\n",
      "Training: Epoch 74, Batch 35, Loss: 0.52\n",
      "Training: Epoch 74, Batch 36, Loss: 0.204\n",
      "Training: Epoch 74, Batch 37, Loss: 0.517\n",
      "Training: Epoch 74, Batch 38, Loss: 0.543\n",
      "Training: Epoch 74, Batch 39, Loss: 0.356\n",
      "Training: Epoch 74, Batch 40, Loss: 0.51\n",
      "Training: Epoch 74, Batch 41, Loss: 0.387\n",
      "Training: Epoch 74, Batch 42, Loss: 0.295\n",
      "Training: Epoch 74, Batch 43, Loss: 0.149\n",
      "Training: Epoch 74, Batch 44, Loss: 0.405\n",
      "Training: Epoch 74, Batch 45, Loss: 0.332\n",
      "Training: Epoch 74, Batch 46, Loss: 0.289\n",
      "Training: Epoch 74, Batch 47, Loss: 0.149\n",
      "Training: Epoch 74, Batch 48, Loss: 0.19\n",
      "Training: Epoch 74, Batch 49, Loss: 0.435\n",
      "Training: Epoch 74, Batch 50, Loss: 0.366\n",
      "Training: Epoch 74, Batch 51, Loss: 0.231\n",
      "Training: Epoch 74, Batch 52, Loss: 0.478\n",
      "Training: Epoch 74, Batch 53, Loss: 0.311\n",
      "Training: Epoch 74, Batch 54, Loss: 0.448\n",
      "Training: Epoch 74, Batch 55, Loss: 0.343\n",
      "Training: Epoch 74, Batch 56, Loss: 0.164\n",
      "Training: Epoch 74, Batch 57, Loss: 0.447\n",
      "Training: Epoch 74, Batch 58, Loss: 0.262\n",
      "Training: Epoch 74, Batch 59, Loss: 0.331\n",
      "Training: Epoch 74, Batch 60, Loss: 0.391\n",
      "Training: Epoch 74, Batch 61, Loss: 0.231\n",
      "Training: Epoch 74, Batch 62, Loss: 0.414\n",
      "Training: Epoch 74, Batch 63, Loss: 0.398\n",
      "Training: Epoch 74, Batch 64, Loss: 0.312\n",
      "Training: Epoch 74, Batch 65, Loss: 0.328\n",
      "Training: Epoch 74, Batch 66, Loss: 0.302\n",
      "Training: Epoch 74, Batch 67, Loss: 0.253\n",
      "Training: Epoch 74, Batch 68, Loss: 0.383\n",
      "Training: Epoch 74, Batch 69, Loss: 0.385\n",
      "Training: Epoch 74, Batch 70, Loss: 0.194\n",
      "Training: Epoch 74, Batch 71, Loss: 0.465\n",
      "Training: Epoch 74, Batch 72, Loss: 0.336\n",
      "Training: Epoch 74, Batch 73, Loss: 0.474\n",
      "Training: Epoch 74, Batch 74, Loss: 0.354\n",
      "Training: Epoch 74, Batch 75, Loss: 0.558\n",
      "Training: Epoch 74, Batch 76, Loss: 0.544\n",
      "Training: Epoch 74, Batch 77, Loss: 0.321\n",
      "Training: Epoch 74, Batch 78, Loss: 0.229\n",
      "Training: Epoch 74, Batch 79, Loss: 0.294\n",
      "Training: Epoch 74, Batch 80, Loss: 0.316\n",
      "Training: Epoch 74, Batch 81, Loss: 0.478\n",
      "Training: Epoch 74, Batch 82, Loss: 0.182\n",
      "Training: Epoch 74, Batch 83, Loss: 0.274\n",
      "Training: Epoch 74, Batch 84, Loss: 0.289\n",
      "Training: Epoch 74, Batch 85, Loss: 0.282\n",
      "Training: Epoch 74, Batch 86, Loss: 0.403\n",
      "Training: Epoch 74, Batch 87, Loss: 0.389\n",
      "Training: Epoch 74, Batch 88, Loss: 0.381\n",
      "Training: Epoch 74, Batch 89, Loss: 0.202\n",
      "Val: Epoch 74, Loss: 1.626\n",
      "Training: Epoch 75, Batch 0, Loss: 0.409\n",
      "Training: Epoch 75, Batch 1, Loss: 0.4\n",
      "Training: Epoch 75, Batch 2, Loss: 0.407\n",
      "Training: Epoch 75, Batch 3, Loss: 0.431\n",
      "Training: Epoch 75, Batch 4, Loss: 0.332\n",
      "Training: Epoch 75, Batch 5, Loss: 0.342\n",
      "Training: Epoch 75, Batch 6, Loss: 0.408\n",
      "Training: Epoch 75, Batch 7, Loss: 0.274\n",
      "Training: Epoch 75, Batch 8, Loss: 0.333\n",
      "Training: Epoch 75, Batch 9, Loss: 0.51\n",
      "Training: Epoch 75, Batch 10, Loss: 0.421\n",
      "Training: Epoch 75, Batch 11, Loss: 0.303\n",
      "Training: Epoch 75, Batch 12, Loss: 0.343\n",
      "Training: Epoch 75, Batch 13, Loss: 0.197\n",
      "Training: Epoch 75, Batch 14, Loss: 0.282\n",
      "Training: Epoch 75, Batch 15, Loss: 0.241\n",
      "Training: Epoch 75, Batch 16, Loss: 0.458\n",
      "Training: Epoch 75, Batch 17, Loss: 0.253\n",
      "Training: Epoch 75, Batch 18, Loss: 0.38\n",
      "Training: Epoch 75, Batch 19, Loss: 0.362\n",
      "Training: Epoch 75, Batch 20, Loss: 0.313\n",
      "Training: Epoch 75, Batch 21, Loss: 0.259\n",
      "Training: Epoch 75, Batch 22, Loss: 0.495\n",
      "Training: Epoch 75, Batch 23, Loss: 0.465\n",
      "Training: Epoch 75, Batch 24, Loss: 0.526\n",
      "Training: Epoch 75, Batch 25, Loss: 0.354\n",
      "Training: Epoch 75, Batch 26, Loss: 0.384\n",
      "Training: Epoch 75, Batch 27, Loss: 0.463\n",
      "Training: Epoch 75, Batch 28, Loss: 0.18\n",
      "Training: Epoch 75, Batch 29, Loss: 0.349\n",
      "Training: Epoch 75, Batch 30, Loss: 0.219\n",
      "Training: Epoch 75, Batch 31, Loss: 0.3\n",
      "Training: Epoch 75, Batch 32, Loss: 0.468\n",
      "Training: Epoch 75, Batch 33, Loss: 0.325\n",
      "Training: Epoch 75, Batch 34, Loss: 0.349\n",
      "Training: Epoch 75, Batch 35, Loss: 0.394\n",
      "Training: Epoch 75, Batch 36, Loss: 0.602\n",
      "Training: Epoch 75, Batch 37, Loss: 0.362\n",
      "Training: Epoch 75, Batch 38, Loss: 0.284\n",
      "Training: Epoch 75, Batch 39, Loss: 0.189\n",
      "Training: Epoch 75, Batch 40, Loss: 0.437\n",
      "Training: Epoch 75, Batch 41, Loss: 0.149\n",
      "Training: Epoch 75, Batch 42, Loss: 0.432\n",
      "Training: Epoch 75, Batch 43, Loss: 0.567\n",
      "Training: Epoch 75, Batch 44, Loss: 0.429\n",
      "Training: Epoch 75, Batch 45, Loss: 0.276\n",
      "Training: Epoch 75, Batch 46, Loss: 0.261\n",
      "Training: Epoch 75, Batch 47, Loss: 0.28\n",
      "Training: Epoch 75, Batch 48, Loss: 0.343\n",
      "Training: Epoch 75, Batch 49, Loss: 0.431\n",
      "Training: Epoch 75, Batch 50, Loss: 0.29\n",
      "Training: Epoch 75, Batch 51, Loss: 0.178\n",
      "Training: Epoch 75, Batch 52, Loss: 0.252\n",
      "Training: Epoch 75, Batch 53, Loss: 0.281\n",
      "Training: Epoch 75, Batch 54, Loss: 0.351\n",
      "Training: Epoch 75, Batch 55, Loss: 0.294\n",
      "Training: Epoch 75, Batch 56, Loss: 0.495\n",
      "Training: Epoch 75, Batch 57, Loss: 0.337\n",
      "Training: Epoch 75, Batch 58, Loss: 0.513\n",
      "Training: Epoch 75, Batch 59, Loss: 0.455\n",
      "Training: Epoch 75, Batch 60, Loss: 0.367\n",
      "Training: Epoch 75, Batch 61, Loss: 0.303\n",
      "Training: Epoch 75, Batch 62, Loss: 0.352\n",
      "Training: Epoch 75, Batch 63, Loss: 0.14\n",
      "Training: Epoch 75, Batch 64, Loss: 0.273\n",
      "Training: Epoch 75, Batch 65, Loss: 0.376\n",
      "Training: Epoch 75, Batch 66, Loss: 0.353\n",
      "Training: Epoch 75, Batch 67, Loss: 0.201\n",
      "Training: Epoch 75, Batch 68, Loss: 0.402\n",
      "Training: Epoch 75, Batch 69, Loss: 0.262\n",
      "Training: Epoch 75, Batch 70, Loss: 0.424\n",
      "Training: Epoch 75, Batch 71, Loss: 0.402\n",
      "Training: Epoch 75, Batch 72, Loss: 0.129\n",
      "Training: Epoch 75, Batch 73, Loss: 0.414\n",
      "Training: Epoch 75, Batch 74, Loss: 0.425\n",
      "Training: Epoch 75, Batch 75, Loss: 0.361\n",
      "Training: Epoch 75, Batch 76, Loss: 0.479\n",
      "Training: Epoch 75, Batch 77, Loss: 0.285\n",
      "Training: Epoch 75, Batch 78, Loss: 0.299\n",
      "Training: Epoch 75, Batch 79, Loss: 0.358\n",
      "Training: Epoch 75, Batch 80, Loss: 0.242\n",
      "Training: Epoch 75, Batch 81, Loss: 0.487\n",
      "Training: Epoch 75, Batch 82, Loss: 0.464\n",
      "Training: Epoch 75, Batch 83, Loss: 0.404\n",
      "Training: Epoch 75, Batch 84, Loss: 0.266\n",
      "Training: Epoch 75, Batch 85, Loss: 0.359\n",
      "Training: Epoch 75, Batch 86, Loss: 0.269\n",
      "Training: Epoch 75, Batch 87, Loss: 0.162\n",
      "Training: Epoch 75, Batch 88, Loss: 0.366\n",
      "Training: Epoch 75, Batch 89, Loss: 0.214\n",
      "Val: Epoch 75, Loss: 0.275\n",
      "Training: Epoch 76, Batch 0, Loss: 0.427\n",
      "Training: Epoch 76, Batch 1, Loss: 0.347\n",
      "Training: Epoch 76, Batch 2, Loss: 0.325\n",
      "Training: Epoch 76, Batch 3, Loss: 0.346\n",
      "Training: Epoch 76, Batch 4, Loss: 0.366\n",
      "Training: Epoch 76, Batch 5, Loss: 0.265\n",
      "Training: Epoch 76, Batch 6, Loss: 0.284\n",
      "Training: Epoch 76, Batch 7, Loss: 0.356\n",
      "Training: Epoch 76, Batch 8, Loss: 0.133\n",
      "Training: Epoch 76, Batch 9, Loss: 0.334\n",
      "Training: Epoch 76, Batch 10, Loss: 0.25\n",
      "Training: Epoch 76, Batch 11, Loss: 0.356\n",
      "Training: Epoch 76, Batch 12, Loss: 0.278\n",
      "Training: Epoch 76, Batch 13, Loss: 0.282\n",
      "Training: Epoch 76, Batch 14, Loss: 0.316\n",
      "Training: Epoch 76, Batch 15, Loss: 0.332\n",
      "Training: Epoch 76, Batch 16, Loss: 0.405\n",
      "Training: Epoch 76, Batch 17, Loss: 0.21\n",
      "Training: Epoch 76, Batch 18, Loss: 0.231\n",
      "Training: Epoch 76, Batch 19, Loss: 0.432\n",
      "Training: Epoch 76, Batch 20, Loss: 0.198\n",
      "Training: Epoch 76, Batch 21, Loss: 0.347\n",
      "Training: Epoch 76, Batch 22, Loss: 0.305\n",
      "Training: Epoch 76, Batch 23, Loss: 0.327\n",
      "Training: Epoch 76, Batch 24, Loss: 0.24\n",
      "Training: Epoch 76, Batch 25, Loss: 0.266\n",
      "Training: Epoch 76, Batch 26, Loss: 0.189\n",
      "Training: Epoch 76, Batch 27, Loss: 0.467\n",
      "Training: Epoch 76, Batch 28, Loss: 0.256\n",
      "Training: Epoch 76, Batch 29, Loss: 0.333\n",
      "Training: Epoch 76, Batch 30, Loss: 0.518\n",
      "Training: Epoch 76, Batch 31, Loss: 0.315\n",
      "Training: Epoch 76, Batch 32, Loss: 0.502\n",
      "Training: Epoch 76, Batch 33, Loss: 0.455\n",
      "Training: Epoch 76, Batch 34, Loss: 0.205\n",
      "Training: Epoch 76, Batch 35, Loss: 0.396\n",
      "Training: Epoch 76, Batch 36, Loss: 0.396\n",
      "Training: Epoch 76, Batch 37, Loss: 0.351\n",
      "Training: Epoch 76, Batch 38, Loss: 0.305\n",
      "Training: Epoch 76, Batch 39, Loss: 0.332\n",
      "Training: Epoch 76, Batch 40, Loss: 0.315\n",
      "Training: Epoch 76, Batch 41, Loss: 0.498\n",
      "Training: Epoch 76, Batch 42, Loss: 0.579\n",
      "Training: Epoch 76, Batch 43, Loss: 0.311\n",
      "Training: Epoch 76, Batch 44, Loss: 0.256\n",
      "Training: Epoch 76, Batch 45, Loss: 0.264\n",
      "Training: Epoch 76, Batch 46, Loss: 0.399\n",
      "Training: Epoch 76, Batch 47, Loss: 0.349\n",
      "Training: Epoch 76, Batch 48, Loss: 0.38\n",
      "Training: Epoch 76, Batch 49, Loss: 0.396\n",
      "Training: Epoch 76, Batch 50, Loss: 0.317\n",
      "Training: Epoch 76, Batch 51, Loss: 0.336\n",
      "Training: Epoch 76, Batch 52, Loss: 0.241\n",
      "Training: Epoch 76, Batch 53, Loss: 0.614\n",
      "Training: Epoch 76, Batch 54, Loss: 0.371\n",
      "Training: Epoch 76, Batch 55, Loss: 0.439\n",
      "Training: Epoch 76, Batch 56, Loss: 0.314\n",
      "Training: Epoch 76, Batch 57, Loss: 0.363\n",
      "Training: Epoch 76, Batch 58, Loss: 0.216\n",
      "Training: Epoch 76, Batch 59, Loss: 0.471\n",
      "Training: Epoch 76, Batch 60, Loss: 0.356\n",
      "Training: Epoch 76, Batch 61, Loss: 0.47\n",
      "Training: Epoch 76, Batch 62, Loss: 0.275\n",
      "Training: Epoch 76, Batch 63, Loss: 0.288\n",
      "Training: Epoch 76, Batch 64, Loss: 0.137\n",
      "Training: Epoch 76, Batch 65, Loss: 0.327\n",
      "Training: Epoch 76, Batch 66, Loss: 0.314\n",
      "Training: Epoch 76, Batch 67, Loss: 0.375\n",
      "Training: Epoch 76, Batch 68, Loss: 0.238\n",
      "Training: Epoch 76, Batch 69, Loss: 0.141\n",
      "Training: Epoch 76, Batch 70, Loss: 0.268\n",
      "Training: Epoch 76, Batch 71, Loss: 0.26\n",
      "Training: Epoch 76, Batch 72, Loss: 0.319\n",
      "Training: Epoch 76, Batch 73, Loss: 0.176\n",
      "Training: Epoch 76, Batch 74, Loss: 0.346\n",
      "Training: Epoch 76, Batch 75, Loss: 0.399\n",
      "Training: Epoch 76, Batch 76, Loss: 0.434\n",
      "Training: Epoch 76, Batch 77, Loss: 0.289\n",
      "Training: Epoch 76, Batch 78, Loss: 0.387\n",
      "Training: Epoch 76, Batch 79, Loss: 0.368\n",
      "Training: Epoch 76, Batch 80, Loss: 0.452\n",
      "Training: Epoch 76, Batch 81, Loss: 0.344\n",
      "Training: Epoch 76, Batch 82, Loss: 0.424\n",
      "Training: Epoch 76, Batch 83, Loss: 0.307\n",
      "Training: Epoch 76, Batch 84, Loss: 0.34\n",
      "Training: Epoch 76, Batch 85, Loss: 0.256\n",
      "Training: Epoch 76, Batch 86, Loss: 0.388\n",
      "Training: Epoch 76, Batch 87, Loss: 0.308\n",
      "Training: Epoch 76, Batch 88, Loss: 0.224\n",
      "Training: Epoch 76, Batch 89, Loss: 0.434\n",
      "Val: Epoch 76, Loss: 0.272\n",
      "Training: Epoch 77, Batch 0, Loss: 0.239\n",
      "Training: Epoch 77, Batch 1, Loss: 0.34\n",
      "Training: Epoch 77, Batch 2, Loss: 0.418\n",
      "Training: Epoch 77, Batch 3, Loss: 0.199\n",
      "Training: Epoch 77, Batch 4, Loss: 0.309\n",
      "Training: Epoch 77, Batch 5, Loss: 0.25\n",
      "Training: Epoch 77, Batch 6, Loss: 0.26\n",
      "Training: Epoch 77, Batch 7, Loss: 0.312\n",
      "Training: Epoch 77, Batch 8, Loss: 0.268\n",
      "Training: Epoch 77, Batch 9, Loss: 0.383\n",
      "Training: Epoch 77, Batch 10, Loss: 0.307\n",
      "Training: Epoch 77, Batch 11, Loss: 0.248\n",
      "Training: Epoch 77, Batch 12, Loss: 0.611\n",
      "Training: Epoch 77, Batch 13, Loss: 0.296\n",
      "Training: Epoch 77, Batch 14, Loss: 0.397\n",
      "Training: Epoch 77, Batch 15, Loss: 0.442\n",
      "Training: Epoch 77, Batch 16, Loss: 0.376\n",
      "Training: Epoch 77, Batch 17, Loss: 0.153\n",
      "Training: Epoch 77, Batch 18, Loss: 0.336\n",
      "Training: Epoch 77, Batch 19, Loss: 0.176\n",
      "Training: Epoch 77, Batch 20, Loss: 0.548\n",
      "Training: Epoch 77, Batch 21, Loss: 0.237\n",
      "Training: Epoch 77, Batch 22, Loss: 0.427\n",
      "Training: Epoch 77, Batch 23, Loss: 0.236\n",
      "Training: Epoch 77, Batch 24, Loss: 0.223\n",
      "Training: Epoch 77, Batch 25, Loss: 0.33\n",
      "Training: Epoch 77, Batch 26, Loss: 0.299\n",
      "Training: Epoch 77, Batch 27, Loss: 0.493\n",
      "Training: Epoch 77, Batch 28, Loss: 0.35\n",
      "Training: Epoch 77, Batch 29, Loss: 0.204\n",
      "Training: Epoch 77, Batch 30, Loss: 0.449\n",
      "Training: Epoch 77, Batch 31, Loss: 0.381\n",
      "Training: Epoch 77, Batch 32, Loss: 0.136\n",
      "Training: Epoch 77, Batch 33, Loss: 0.412\n",
      "Training: Epoch 77, Batch 34, Loss: 0.177\n",
      "Training: Epoch 77, Batch 35, Loss: 0.284\n",
      "Training: Epoch 77, Batch 36, Loss: 0.288\n",
      "Training: Epoch 77, Batch 37, Loss: 0.325\n",
      "Training: Epoch 77, Batch 38, Loss: 0.265\n",
      "Training: Epoch 77, Batch 39, Loss: 0.341\n",
      "Training: Epoch 77, Batch 40, Loss: 0.289\n",
      "Training: Epoch 77, Batch 41, Loss: 0.413\n",
      "Training: Epoch 77, Batch 42, Loss: 0.385\n",
      "Training: Epoch 77, Batch 43, Loss: 0.369\n",
      "Training: Epoch 77, Batch 44, Loss: 0.27\n",
      "Training: Epoch 77, Batch 45, Loss: 0.378\n",
      "Training: Epoch 77, Batch 46, Loss: 0.27\n",
      "Training: Epoch 77, Batch 47, Loss: 0.389\n",
      "Training: Epoch 77, Batch 48, Loss: 0.297\n",
      "Training: Epoch 77, Batch 49, Loss: 0.469\n",
      "Training: Epoch 77, Batch 50, Loss: 0.376\n",
      "Training: Epoch 77, Batch 51, Loss: 0.237\n",
      "Training: Epoch 77, Batch 52, Loss: 0.391\n",
      "Training: Epoch 77, Batch 53, Loss: 0.415\n",
      "Training: Epoch 77, Batch 54, Loss: 0.283\n",
      "Training: Epoch 77, Batch 55, Loss: 0.217\n",
      "Training: Epoch 77, Batch 56, Loss: 0.266\n",
      "Training: Epoch 77, Batch 57, Loss: 0.117\n",
      "Training: Epoch 77, Batch 58, Loss: 0.25\n",
      "Training: Epoch 77, Batch 59, Loss: 0.224\n",
      "Training: Epoch 77, Batch 60, Loss: 0.66\n",
      "Training: Epoch 77, Batch 61, Loss: 0.349\n",
      "Training: Epoch 77, Batch 62, Loss: 0.187\n",
      "Training: Epoch 77, Batch 63, Loss: 0.298\n",
      "Training: Epoch 77, Batch 64, Loss: 0.278\n",
      "Training: Epoch 77, Batch 65, Loss: 0.485\n",
      "Training: Epoch 77, Batch 66, Loss: 0.331\n",
      "Training: Epoch 77, Batch 67, Loss: 0.418\n",
      "Training: Epoch 77, Batch 68, Loss: 0.324\n",
      "Training: Epoch 77, Batch 69, Loss: 0.39\n",
      "Training: Epoch 77, Batch 70, Loss: 0.431\n",
      "Training: Epoch 77, Batch 71, Loss: 0.286\n",
      "Training: Epoch 77, Batch 72, Loss: 0.234\n",
      "Training: Epoch 77, Batch 73, Loss: 0.391\n",
      "Training: Epoch 77, Batch 74, Loss: 0.379\n",
      "Training: Epoch 77, Batch 75, Loss: 0.138\n",
      "Training: Epoch 77, Batch 76, Loss: 0.319\n",
      "Training: Epoch 77, Batch 77, Loss: 0.265\n",
      "Training: Epoch 77, Batch 78, Loss: 0.275\n",
      "Training: Epoch 77, Batch 79, Loss: 0.443\n",
      "Training: Epoch 77, Batch 80, Loss: 0.121\n",
      "Training: Epoch 77, Batch 81, Loss: 0.399\n",
      "Training: Epoch 77, Batch 82, Loss: 0.229\n",
      "Training: Epoch 77, Batch 83, Loss: 0.352\n",
      "Training: Epoch 77, Batch 84, Loss: 0.195\n",
      "Training: Epoch 77, Batch 85, Loss: 0.543\n",
      "Training: Epoch 77, Batch 86, Loss: 0.366\n",
      "Training: Epoch 77, Batch 87, Loss: 0.362\n",
      "Training: Epoch 77, Batch 88, Loss: 0.33\n",
      "Training: Epoch 77, Batch 89, Loss: 0.163\n",
      "Val: Epoch 77, Loss: 0.275\n",
      "Training: Epoch 78, Batch 0, Loss: 0.419\n",
      "Training: Epoch 78, Batch 1, Loss: 0.248\n",
      "Training: Epoch 78, Batch 2, Loss: 0.536\n",
      "Training: Epoch 78, Batch 3, Loss: 0.125\n",
      "Training: Epoch 78, Batch 4, Loss: 0.268\n",
      "Training: Epoch 78, Batch 5, Loss: 0.405\n",
      "Training: Epoch 78, Batch 6, Loss: 0.243\n",
      "Training: Epoch 78, Batch 7, Loss: 0.374\n",
      "Training: Epoch 78, Batch 8, Loss: 0.262\n",
      "Training: Epoch 78, Batch 9, Loss: 0.288\n",
      "Training: Epoch 78, Batch 10, Loss: 0.288\n",
      "Training: Epoch 78, Batch 11, Loss: 0.245\n",
      "Training: Epoch 78, Batch 12, Loss: 0.31\n",
      "Training: Epoch 78, Batch 13, Loss: 0.328\n",
      "Training: Epoch 78, Batch 14, Loss: 0.334\n",
      "Training: Epoch 78, Batch 15, Loss: 0.19\n",
      "Training: Epoch 78, Batch 16, Loss: 0.249\n",
      "Training: Epoch 78, Batch 17, Loss: 0.223\n",
      "Training: Epoch 78, Batch 18, Loss: 0.42\n",
      "Training: Epoch 78, Batch 19, Loss: 0.296\n",
      "Training: Epoch 78, Batch 20, Loss: 0.299\n",
      "Training: Epoch 78, Batch 21, Loss: 0.342\n",
      "Training: Epoch 78, Batch 22, Loss: 0.231\n",
      "Training: Epoch 78, Batch 23, Loss: 0.409\n",
      "Training: Epoch 78, Batch 24, Loss: 0.14\n",
      "Training: Epoch 78, Batch 25, Loss: 0.405\n",
      "Training: Epoch 78, Batch 26, Loss: 0.329\n",
      "Training: Epoch 78, Batch 27, Loss: 0.387\n",
      "Training: Epoch 78, Batch 28, Loss: 0.429\n",
      "Training: Epoch 78, Batch 29, Loss: 0.301\n",
      "Training: Epoch 78, Batch 30, Loss: 0.31\n",
      "Training: Epoch 78, Batch 31, Loss: 0.248\n",
      "Training: Epoch 78, Batch 32, Loss: 0.517\n",
      "Training: Epoch 78, Batch 33, Loss: 0.222\n",
      "Training: Epoch 78, Batch 34, Loss: 0.461\n",
      "Training: Epoch 78, Batch 35, Loss: 0.199\n",
      "Training: Epoch 78, Batch 36, Loss: 0.363\n",
      "Training: Epoch 78, Batch 37, Loss: 0.399\n",
      "Training: Epoch 78, Batch 38, Loss: 0.173\n",
      "Training: Epoch 78, Batch 39, Loss: 0.309\n",
      "Training: Epoch 78, Batch 40, Loss: 0.232\n",
      "Training: Epoch 78, Batch 41, Loss: 0.277\n",
      "Training: Epoch 78, Batch 42, Loss: 0.179\n",
      "Training: Epoch 78, Batch 43, Loss: 0.305\n",
      "Training: Epoch 78, Batch 44, Loss: 0.428\n",
      "Training: Epoch 78, Batch 45, Loss: 0.367\n",
      "Training: Epoch 78, Batch 46, Loss: 0.239\n",
      "Training: Epoch 78, Batch 47, Loss: 0.374\n",
      "Training: Epoch 78, Batch 48, Loss: 0.254\n",
      "Training: Epoch 78, Batch 49, Loss: 0.244\n",
      "Training: Epoch 78, Batch 50, Loss: 0.326\n",
      "Training: Epoch 78, Batch 51, Loss: 0.24\n",
      "Training: Epoch 78, Batch 52, Loss: 0.294\n",
      "Training: Epoch 78, Batch 53, Loss: 0.307\n",
      "Training: Epoch 78, Batch 54, Loss: 0.397\n",
      "Training: Epoch 78, Batch 55, Loss: 0.349\n",
      "Training: Epoch 78, Batch 56, Loss: 0.308\n",
      "Training: Epoch 78, Batch 57, Loss: 0.161\n",
      "Training: Epoch 78, Batch 58, Loss: 0.321\n",
      "Training: Epoch 78, Batch 59, Loss: 0.265\n",
      "Training: Epoch 78, Batch 60, Loss: 0.448\n",
      "Training: Epoch 78, Batch 61, Loss: 0.313\n",
      "Training: Epoch 78, Batch 62, Loss: 0.295\n",
      "Training: Epoch 78, Batch 63, Loss: 0.213\n",
      "Training: Epoch 78, Batch 64, Loss: 0.413\n",
      "Training: Epoch 78, Batch 65, Loss: 0.222\n",
      "Training: Epoch 78, Batch 66, Loss: 0.238\n",
      "Training: Epoch 78, Batch 67, Loss: 0.4\n",
      "Training: Epoch 78, Batch 68, Loss: 0.344\n",
      "Training: Epoch 78, Batch 69, Loss: 0.249\n",
      "Training: Epoch 78, Batch 70, Loss: 0.134\n",
      "Training: Epoch 78, Batch 71, Loss: 0.204\n",
      "Training: Epoch 78, Batch 72, Loss: 0.318\n",
      "Training: Epoch 78, Batch 73, Loss: 0.236\n",
      "Training: Epoch 78, Batch 74, Loss: 0.213\n",
      "Training: Epoch 78, Batch 75, Loss: 0.135\n",
      "Training: Epoch 78, Batch 76, Loss: 0.252\n",
      "Training: Epoch 78, Batch 77, Loss: 0.262\n",
      "Training: Epoch 78, Batch 78, Loss: 0.346\n",
      "Training: Epoch 78, Batch 79, Loss: 0.558\n",
      "Training: Epoch 78, Batch 80, Loss: 0.205\n",
      "Training: Epoch 78, Batch 81, Loss: 0.272\n",
      "Training: Epoch 78, Batch 82, Loss: 0.277\n",
      "Training: Epoch 78, Batch 83, Loss: 0.258\n",
      "Training: Epoch 78, Batch 84, Loss: 0.313\n",
      "Training: Epoch 78, Batch 85, Loss: 0.226\n",
      "Training: Epoch 78, Batch 86, Loss: 0.153\n",
      "Training: Epoch 78, Batch 87, Loss: 0.45\n",
      "Training: Epoch 78, Batch 88, Loss: 0.331\n",
      "Training: Epoch 78, Batch 89, Loss: 0.339\n",
      "Val: Epoch 78, Loss: 0.268\n",
      "Training: Epoch 79, Batch 0, Loss: 0.241\n",
      "Training: Epoch 79, Batch 1, Loss: 0.345\n",
      "Training: Epoch 79, Batch 2, Loss: 0.217\n",
      "Training: Epoch 79, Batch 3, Loss: 0.298\n",
      "Training: Epoch 79, Batch 4, Loss: 0.271\n",
      "Training: Epoch 79, Batch 5, Loss: 0.27\n",
      "Training: Epoch 79, Batch 6, Loss: 0.303\n",
      "Training: Epoch 79, Batch 7, Loss: 0.208\n",
      "Training: Epoch 79, Batch 8, Loss: 0.208\n",
      "Training: Epoch 79, Batch 9, Loss: 0.352\n",
      "Training: Epoch 79, Batch 10, Loss: 0.187\n",
      "Training: Epoch 79, Batch 11, Loss: 0.19\n",
      "Training: Epoch 79, Batch 12, Loss: 0.276\n",
      "Training: Epoch 79, Batch 13, Loss: 0.284\n",
      "Training: Epoch 79, Batch 14, Loss: 0.28\n",
      "Training: Epoch 79, Batch 15, Loss: 0.31\n",
      "Training: Epoch 79, Batch 16, Loss: 0.315\n",
      "Training: Epoch 79, Batch 17, Loss: 0.128\n",
      "Training: Epoch 79, Batch 18, Loss: 0.306\n",
      "Training: Epoch 79, Batch 19, Loss: 0.401\n",
      "Training: Epoch 79, Batch 20, Loss: 0.405\n",
      "Training: Epoch 79, Batch 21, Loss: 0.256\n",
      "Training: Epoch 79, Batch 22, Loss: 0.39\n",
      "Training: Epoch 79, Batch 23, Loss: 0.264\n",
      "Training: Epoch 79, Batch 24, Loss: 0.194\n",
      "Training: Epoch 79, Batch 25, Loss: 0.258\n",
      "Training: Epoch 79, Batch 26, Loss: 0.353\n",
      "Training: Epoch 79, Batch 27, Loss: 0.207\n",
      "Training: Epoch 79, Batch 28, Loss: 0.25\n",
      "Training: Epoch 79, Batch 29, Loss: 0.349\n",
      "Training: Epoch 79, Batch 30, Loss: 0.188\n",
      "Training: Epoch 79, Batch 31, Loss: 0.273\n",
      "Training: Epoch 79, Batch 32, Loss: 0.158\n",
      "Training: Epoch 79, Batch 33, Loss: 0.258\n",
      "Training: Epoch 79, Batch 34, Loss: 0.211\n",
      "Training: Epoch 79, Batch 35, Loss: 0.225\n",
      "Training: Epoch 79, Batch 36, Loss: 0.161\n",
      "Training: Epoch 79, Batch 37, Loss: 0.403\n",
      "Training: Epoch 79, Batch 38, Loss: 0.34\n",
      "Training: Epoch 79, Batch 39, Loss: 0.371\n",
      "Training: Epoch 79, Batch 40, Loss: 0.232\n",
      "Training: Epoch 79, Batch 41, Loss: 0.156\n",
      "Training: Epoch 79, Batch 42, Loss: 0.177\n",
      "Training: Epoch 79, Batch 43, Loss: 0.28\n",
      "Training: Epoch 79, Batch 44, Loss: 0.431\n",
      "Training: Epoch 79, Batch 45, Loss: 0.26\n",
      "Training: Epoch 79, Batch 46, Loss: 0.336\n",
      "Training: Epoch 79, Batch 47, Loss: 0.253\n",
      "Training: Epoch 79, Batch 48, Loss: 0.129\n",
      "Training: Epoch 79, Batch 49, Loss: 0.312\n",
      "Training: Epoch 79, Batch 50, Loss: 0.301\n",
      "Training: Epoch 79, Batch 51, Loss: 0.405\n",
      "Training: Epoch 79, Batch 52, Loss: 0.314\n",
      "Training: Epoch 79, Batch 53, Loss: 0.294\n",
      "Training: Epoch 79, Batch 54, Loss: 0.347\n",
      "Training: Epoch 79, Batch 55, Loss: 0.304\n",
      "Training: Epoch 79, Batch 56, Loss: 0.307\n",
      "Training: Epoch 79, Batch 57, Loss: 0.328\n",
      "Training: Epoch 79, Batch 58, Loss: 0.287\n",
      "Training: Epoch 79, Batch 59, Loss: 0.779\n",
      "Training: Epoch 79, Batch 60, Loss: 0.482\n",
      "Training: Epoch 79, Batch 61, Loss: 0.283\n",
      "Training: Epoch 79, Batch 62, Loss: 0.319\n",
      "Training: Epoch 79, Batch 63, Loss: 0.503\n",
      "Training: Epoch 79, Batch 64, Loss: 0.423\n",
      "Training: Epoch 79, Batch 65, Loss: 0.341\n",
      "Training: Epoch 79, Batch 66, Loss: 0.212\n",
      "Training: Epoch 79, Batch 67, Loss: 0.255\n",
      "Training: Epoch 79, Batch 68, Loss: 0.335\n",
      "Training: Epoch 79, Batch 69, Loss: 0.229\n",
      "Training: Epoch 79, Batch 70, Loss: 0.391\n",
      "Training: Epoch 79, Batch 71, Loss: 0.447\n",
      "Training: Epoch 79, Batch 72, Loss: 0.216\n",
      "Training: Epoch 79, Batch 73, Loss: 0.372\n",
      "Training: Epoch 79, Batch 74, Loss: 0.281\n",
      "Training: Epoch 79, Batch 75, Loss: 0.335\n",
      "Training: Epoch 79, Batch 76, Loss: 0.392\n",
      "Training: Epoch 79, Batch 77, Loss: 0.336\n",
      "Training: Epoch 79, Batch 78, Loss: 0.283\n",
      "Training: Epoch 79, Batch 79, Loss: 0.132\n",
      "Training: Epoch 79, Batch 80, Loss: 0.298\n",
      "Training: Epoch 79, Batch 81, Loss: 0.41\n",
      "Training: Epoch 79, Batch 82, Loss: 0.195\n",
      "Training: Epoch 79, Batch 83, Loss: 0.358\n",
      "Training: Epoch 79, Batch 84, Loss: 0.273\n",
      "Training: Epoch 79, Batch 85, Loss: 0.261\n",
      "Training: Epoch 79, Batch 86, Loss: 0.445\n",
      "Training: Epoch 79, Batch 87, Loss: 0.224\n",
      "Training: Epoch 79, Batch 88, Loss: 0.274\n",
      "Training: Epoch 79, Batch 89, Loss: 0.269\n",
      "Val: Epoch 79, Loss: 0.271\n",
      "Training: Epoch 80, Batch 0, Loss: 0.167\n",
      "Training: Epoch 80, Batch 1, Loss: 0.215\n",
      "Training: Epoch 80, Batch 2, Loss: 0.319\n",
      "Training: Epoch 80, Batch 3, Loss: 0.325\n",
      "Training: Epoch 80, Batch 4, Loss: 0.736\n",
      "Training: Epoch 80, Batch 5, Loss: 0.4\n",
      "Training: Epoch 80, Batch 6, Loss: 0.362\n",
      "Training: Epoch 80, Batch 7, Loss: 0.489\n",
      "Training: Epoch 80, Batch 8, Loss: 0.595\n",
      "Training: Epoch 80, Batch 9, Loss: 0.553\n",
      "Training: Epoch 80, Batch 10, Loss: 0.449\n",
      "Training: Epoch 80, Batch 11, Loss: 0.458\n",
      "Training: Epoch 80, Batch 12, Loss: 0.504\n",
      "Training: Epoch 80, Batch 13, Loss: 0.366\n",
      "Training: Epoch 80, Batch 14, Loss: 0.394\n",
      "Training: Epoch 80, Batch 15, Loss: 0.231\n",
      "Training: Epoch 80, Batch 16, Loss: 0.277\n",
      "Training: Epoch 80, Batch 17, Loss: 0.496\n",
      "Training: Epoch 80, Batch 18, Loss: 0.356\n",
      "Training: Epoch 80, Batch 19, Loss: 0.36\n",
      "Training: Epoch 80, Batch 20, Loss: 0.523\n",
      "Training: Epoch 80, Batch 21, Loss: 0.491\n",
      "Training: Epoch 80, Batch 22, Loss: 0.342\n",
      "Training: Epoch 80, Batch 23, Loss: 0.26\n",
      "Training: Epoch 80, Batch 24, Loss: 0.362\n",
      "Training: Epoch 80, Batch 25, Loss: 0.268\n",
      "Training: Epoch 80, Batch 26, Loss: 0.327\n",
      "Training: Epoch 80, Batch 27, Loss: 0.36\n",
      "Training: Epoch 80, Batch 28, Loss: 0.205\n",
      "Training: Epoch 80, Batch 29, Loss: 0.269\n",
      "Training: Epoch 80, Batch 30, Loss: 0.467\n",
      "Training: Epoch 80, Batch 31, Loss: 0.306\n",
      "Training: Epoch 80, Batch 32, Loss: 0.253\n",
      "Training: Epoch 80, Batch 33, Loss: 0.342\n",
      "Training: Epoch 80, Batch 34, Loss: 0.185\n",
      "Training: Epoch 80, Batch 35, Loss: 0.379\n",
      "Training: Epoch 80, Batch 36, Loss: 0.255\n",
      "Training: Epoch 80, Batch 37, Loss: 0.456\n",
      "Training: Epoch 80, Batch 38, Loss: 0.238\n",
      "Training: Epoch 80, Batch 39, Loss: 0.364\n",
      "Training: Epoch 80, Batch 40, Loss: 0.412\n",
      "Training: Epoch 80, Batch 41, Loss: 0.393\n",
      "Training: Epoch 80, Batch 42, Loss: 0.157\n",
      "Training: Epoch 80, Batch 43, Loss: 0.146\n",
      "Training: Epoch 80, Batch 44, Loss: 0.352\n",
      "Training: Epoch 80, Batch 45, Loss: 0.378\n",
      "Training: Epoch 80, Batch 46, Loss: 0.458\n",
      "Training: Epoch 80, Batch 47, Loss: 0.232\n",
      "Training: Epoch 80, Batch 48, Loss: 0.361\n",
      "Training: Epoch 80, Batch 49, Loss: 0.38\n",
      "Training: Epoch 80, Batch 50, Loss: 0.281\n",
      "Training: Epoch 80, Batch 51, Loss: 0.481\n",
      "Training: Epoch 80, Batch 52, Loss: 0.564\n",
      "Training: Epoch 80, Batch 53, Loss: 0.463\n",
      "Training: Epoch 80, Batch 54, Loss: 0.289\n",
      "Training: Epoch 80, Batch 55, Loss: 0.338\n",
      "Training: Epoch 80, Batch 56, Loss: 0.604\n",
      "Training: Epoch 80, Batch 57, Loss: 0.209\n",
      "Training: Epoch 80, Batch 58, Loss: 0.312\n",
      "Training: Epoch 80, Batch 59, Loss: 0.282\n",
      "Training: Epoch 80, Batch 60, Loss: 0.408\n",
      "Training: Epoch 80, Batch 61, Loss: 0.202\n",
      "Training: Epoch 80, Batch 62, Loss: 0.305\n",
      "Training: Epoch 80, Batch 63, Loss: 0.206\n",
      "Training: Epoch 80, Batch 64, Loss: 0.409\n",
      "Training: Epoch 80, Batch 65, Loss: 0.347\n",
      "Training: Epoch 80, Batch 66, Loss: 0.457\n",
      "Training: Epoch 80, Batch 67, Loss: 0.355\n",
      "Training: Epoch 80, Batch 68, Loss: 0.196\n",
      "Training: Epoch 80, Batch 69, Loss: 0.265\n",
      "Training: Epoch 80, Batch 70, Loss: 0.246\n",
      "Training: Epoch 80, Batch 71, Loss: 0.382\n",
      "Training: Epoch 80, Batch 72, Loss: 0.34\n",
      "Training: Epoch 80, Batch 73, Loss: 0.247\n",
      "Training: Epoch 80, Batch 74, Loss: 0.219\n",
      "Training: Epoch 80, Batch 75, Loss: 0.323\n",
      "Training: Epoch 80, Batch 76, Loss: 0.345\n",
      "Training: Epoch 80, Batch 77, Loss: 0.28\n",
      "Training: Epoch 80, Batch 78, Loss: 0.363\n",
      "Training: Epoch 80, Batch 79, Loss: 0.201\n",
      "Training: Epoch 80, Batch 80, Loss: 0.202\n",
      "Training: Epoch 80, Batch 81, Loss: 0.295\n",
      "Training: Epoch 80, Batch 82, Loss: 0.236\n",
      "Training: Epoch 80, Batch 83, Loss: 0.223\n",
      "Training: Epoch 80, Batch 84, Loss: 0.321\n",
      "Training: Epoch 80, Batch 85, Loss: 0.311\n",
      "Training: Epoch 80, Batch 86, Loss: 0.449\n",
      "Training: Epoch 80, Batch 87, Loss: 0.198\n",
      "Training: Epoch 80, Batch 88, Loss: 0.217\n",
      "Training: Epoch 80, Batch 89, Loss: 0.252\n",
      "Val: Epoch 80, Loss: 0.266\n",
      "Training: Epoch 81, Batch 0, Loss: 0.309\n",
      "Training: Epoch 81, Batch 1, Loss: 0.17\n",
      "Training: Epoch 81, Batch 2, Loss: 0.259\n",
      "Training: Epoch 81, Batch 3, Loss: 0.208\n",
      "Training: Epoch 81, Batch 4, Loss: 0.246\n",
      "Training: Epoch 81, Batch 5, Loss: 0.131\n",
      "Training: Epoch 81, Batch 6, Loss: 0.184\n",
      "Training: Epoch 81, Batch 7, Loss: 0.267\n",
      "Training: Epoch 81, Batch 8, Loss: 0.272\n",
      "Training: Epoch 81, Batch 9, Loss: 0.2\n",
      "Training: Epoch 81, Batch 10, Loss: 0.236\n",
      "Training: Epoch 81, Batch 11, Loss: 0.176\n",
      "Training: Epoch 81, Batch 12, Loss: 0.2\n",
      "Training: Epoch 81, Batch 13, Loss: 0.301\n",
      "Training: Epoch 81, Batch 14, Loss: 0.208\n",
      "Training: Epoch 81, Batch 15, Loss: 0.241\n",
      "Training: Epoch 81, Batch 16, Loss: 0.265\n",
      "Training: Epoch 81, Batch 17, Loss: 0.204\n",
      "Training: Epoch 81, Batch 18, Loss: 0.243\n",
      "Training: Epoch 81, Batch 19, Loss: 0.291\n",
      "Training: Epoch 81, Batch 20, Loss: 0.194\n",
      "Training: Epoch 81, Batch 21, Loss: 0.39\n",
      "Training: Epoch 81, Batch 22, Loss: 0.165\n",
      "Training: Epoch 81, Batch 23, Loss: 0.215\n",
      "Training: Epoch 81, Batch 24, Loss: 0.194\n",
      "Training: Epoch 81, Batch 25, Loss: 0.385\n",
      "Training: Epoch 81, Batch 26, Loss: 0.367\n",
      "Training: Epoch 81, Batch 27, Loss: 0.257\n",
      "Training: Epoch 81, Batch 28, Loss: 0.261\n",
      "Training: Epoch 81, Batch 29, Loss: 0.275\n",
      "Training: Epoch 81, Batch 30, Loss: 0.315\n",
      "Training: Epoch 81, Batch 31, Loss: 0.259\n",
      "Training: Epoch 81, Batch 32, Loss: 0.176\n",
      "Training: Epoch 81, Batch 33, Loss: 0.354\n",
      "Training: Epoch 81, Batch 34, Loss: 0.307\n",
      "Training: Epoch 81, Batch 35, Loss: 0.3\n",
      "Training: Epoch 81, Batch 36, Loss: 0.178\n",
      "Training: Epoch 81, Batch 37, Loss: 0.382\n",
      "Training: Epoch 81, Batch 38, Loss: 0.196\n",
      "Training: Epoch 81, Batch 39, Loss: 0.245\n",
      "Training: Epoch 81, Batch 40, Loss: 0.365\n",
      "Training: Epoch 81, Batch 41, Loss: 0.312\n",
      "Training: Epoch 81, Batch 42, Loss: 0.17\n",
      "Training: Epoch 81, Batch 43, Loss: 0.324\n",
      "Training: Epoch 81, Batch 44, Loss: 0.223\n",
      "Training: Epoch 81, Batch 45, Loss: 0.433\n",
      "Training: Epoch 81, Batch 46, Loss: 0.314\n",
      "Training: Epoch 81, Batch 47, Loss: 0.25\n",
      "Training: Epoch 81, Batch 48, Loss: 0.271\n",
      "Training: Epoch 81, Batch 49, Loss: 0.346\n",
      "Training: Epoch 81, Batch 50, Loss: 0.227\n",
      "Training: Epoch 81, Batch 51, Loss: 0.263\n",
      "Training: Epoch 81, Batch 52, Loss: 0.342\n",
      "Training: Epoch 81, Batch 53, Loss: 0.26\n",
      "Training: Epoch 81, Batch 54, Loss: 0.191\n",
      "Training: Epoch 81, Batch 55, Loss: 0.241\n",
      "Training: Epoch 81, Batch 56, Loss: 0.275\n",
      "Training: Epoch 81, Batch 57, Loss: 0.35\n",
      "Training: Epoch 81, Batch 58, Loss: 0.233\n",
      "Training: Epoch 81, Batch 59, Loss: 0.171\n",
      "Training: Epoch 81, Batch 60, Loss: 0.129\n",
      "Training: Epoch 81, Batch 61, Loss: 0.436\n",
      "Training: Epoch 81, Batch 62, Loss: 0.242\n",
      "Training: Epoch 81, Batch 63, Loss: 0.18\n",
      "Training: Epoch 81, Batch 64, Loss: 0.445\n",
      "Training: Epoch 81, Batch 65, Loss: 0.218\n",
      "Training: Epoch 81, Batch 66, Loss: 0.243\n",
      "Training: Epoch 81, Batch 67, Loss: 0.28\n",
      "Training: Epoch 81, Batch 68, Loss: 0.209\n",
      "Training: Epoch 81, Batch 69, Loss: 0.197\n",
      "Training: Epoch 81, Batch 70, Loss: 0.44\n",
      "Training: Epoch 81, Batch 71, Loss: 0.323\n",
      "Training: Epoch 81, Batch 72, Loss: 0.35\n",
      "Training: Epoch 81, Batch 73, Loss: 0.189\n",
      "Training: Epoch 81, Batch 74, Loss: 0.249\n",
      "Training: Epoch 81, Batch 75, Loss: 0.44\n",
      "Training: Epoch 81, Batch 76, Loss: 0.308\n",
      "Training: Epoch 81, Batch 77, Loss: 0.27\n",
      "Training: Epoch 81, Batch 78, Loss: 0.324\n",
      "Training: Epoch 81, Batch 79, Loss: 0.271\n",
      "Training: Epoch 81, Batch 80, Loss: 0.271\n",
      "Training: Epoch 81, Batch 81, Loss: 0.231\n",
      "Training: Epoch 81, Batch 82, Loss: 0.465\n",
      "Training: Epoch 81, Batch 83, Loss: 0.218\n",
      "Training: Epoch 81, Batch 84, Loss: 0.344\n",
      "Training: Epoch 81, Batch 85, Loss: 0.329\n",
      "Training: Epoch 81, Batch 86, Loss: 0.283\n",
      "Training: Epoch 81, Batch 87, Loss: 0.317\n",
      "Training: Epoch 81, Batch 88, Loss: 0.352\n",
      "Training: Epoch 81, Batch 89, Loss: 0.473\n",
      "Val: Epoch 81, Loss: 0.259\n",
      "Training: Epoch 82, Batch 0, Loss: 0.302\n",
      "Training: Epoch 82, Batch 1, Loss: 0.204\n",
      "Training: Epoch 82, Batch 2, Loss: 0.358\n",
      "Training: Epoch 82, Batch 3, Loss: 0.127\n",
      "Training: Epoch 82, Batch 4, Loss: 0.404\n",
      "Training: Epoch 82, Batch 5, Loss: 0.284\n",
      "Training: Epoch 82, Batch 6, Loss: 0.279\n",
      "Training: Epoch 82, Batch 7, Loss: 0.274\n",
      "Training: Epoch 82, Batch 8, Loss: 0.138\n",
      "Training: Epoch 82, Batch 9, Loss: 0.268\n",
      "Training: Epoch 82, Batch 10, Loss: 0.236\n",
      "Training: Epoch 82, Batch 11, Loss: 0.223\n",
      "Training: Epoch 82, Batch 12, Loss: 0.3\n",
      "Training: Epoch 82, Batch 13, Loss: 0.219\n",
      "Training: Epoch 82, Batch 14, Loss: 0.196\n",
      "Training: Epoch 82, Batch 15, Loss: 0.354\n",
      "Training: Epoch 82, Batch 16, Loss: 0.174\n",
      "Training: Epoch 82, Batch 17, Loss: 0.3\n",
      "Training: Epoch 82, Batch 18, Loss: 0.273\n",
      "Training: Epoch 82, Batch 19, Loss: 0.3\n",
      "Training: Epoch 82, Batch 20, Loss: 0.278\n",
      "Training: Epoch 82, Batch 21, Loss: 0.3\n",
      "Training: Epoch 82, Batch 22, Loss: 0.275\n",
      "Training: Epoch 82, Batch 23, Loss: 0.292\n",
      "Training: Epoch 82, Batch 24, Loss: 0.19\n",
      "Training: Epoch 82, Batch 25, Loss: 0.207\n",
      "Training: Epoch 82, Batch 26, Loss: 0.244\n",
      "Training: Epoch 82, Batch 27, Loss: 0.257\n",
      "Training: Epoch 82, Batch 28, Loss: 0.236\n",
      "Training: Epoch 82, Batch 29, Loss: 0.284\n",
      "Training: Epoch 82, Batch 30, Loss: 0.17\n",
      "Training: Epoch 82, Batch 31, Loss: 0.206\n",
      "Training: Epoch 82, Batch 32, Loss: 0.233\n",
      "Training: Epoch 82, Batch 33, Loss: 0.22\n",
      "Training: Epoch 82, Batch 34, Loss: 0.37\n",
      "Training: Epoch 82, Batch 35, Loss: 0.205\n",
      "Training: Epoch 82, Batch 36, Loss: 0.267\n",
      "Training: Epoch 82, Batch 37, Loss: 0.182\n",
      "Training: Epoch 82, Batch 38, Loss: 0.242\n",
      "Training: Epoch 82, Batch 39, Loss: 0.235\n",
      "Training: Epoch 82, Batch 40, Loss: 0.253\n",
      "Training: Epoch 82, Batch 41, Loss: 0.224\n",
      "Training: Epoch 82, Batch 42, Loss: 0.312\n",
      "Training: Epoch 82, Batch 43, Loss: 0.138\n",
      "Training: Epoch 82, Batch 44, Loss: 0.166\n",
      "Training: Epoch 82, Batch 45, Loss: 0.226\n",
      "Training: Epoch 82, Batch 46, Loss: 0.285\n",
      "Training: Epoch 82, Batch 47, Loss: 0.225\n",
      "Training: Epoch 82, Batch 48, Loss: 0.215\n",
      "Training: Epoch 82, Batch 49, Loss: 0.283\n",
      "Training: Epoch 82, Batch 50, Loss: 0.244\n",
      "Training: Epoch 82, Batch 51, Loss: 0.198\n",
      "Training: Epoch 82, Batch 52, Loss: 0.297\n",
      "Training: Epoch 82, Batch 53, Loss: 0.273\n",
      "Training: Epoch 82, Batch 54, Loss: 0.234\n",
      "Training: Epoch 82, Batch 55, Loss: 0.296\n",
      "Training: Epoch 82, Batch 56, Loss: 0.509\n",
      "Training: Epoch 82, Batch 57, Loss: 0.345\n",
      "Training: Epoch 82, Batch 58, Loss: 0.188\n",
      "Training: Epoch 82, Batch 59, Loss: 0.243\n",
      "Training: Epoch 82, Batch 60, Loss: 0.356\n",
      "Training: Epoch 82, Batch 61, Loss: 0.233\n",
      "Training: Epoch 82, Batch 62, Loss: 0.236\n",
      "Training: Epoch 82, Batch 63, Loss: 0.266\n",
      "Training: Epoch 82, Batch 64, Loss: 0.296\n",
      "Training: Epoch 82, Batch 65, Loss: 0.34\n",
      "Training: Epoch 82, Batch 66, Loss: 0.439\n",
      "Training: Epoch 82, Batch 67, Loss: 0.257\n",
      "Training: Epoch 82, Batch 68, Loss: 0.285\n",
      "Training: Epoch 82, Batch 69, Loss: 0.267\n",
      "Training: Epoch 82, Batch 70, Loss: 0.256\n",
      "Training: Epoch 82, Batch 71, Loss: 0.309\n",
      "Training: Epoch 82, Batch 72, Loss: 0.338\n",
      "Training: Epoch 82, Batch 73, Loss: 0.255\n",
      "Training: Epoch 82, Batch 74, Loss: 0.338\n",
      "Training: Epoch 82, Batch 75, Loss: 0.283\n",
      "Training: Epoch 82, Batch 76, Loss: 0.278\n",
      "Training: Epoch 82, Batch 77, Loss: 0.386\n",
      "Training: Epoch 82, Batch 78, Loss: 0.28\n",
      "Training: Epoch 82, Batch 79, Loss: 0.318\n",
      "Training: Epoch 82, Batch 80, Loss: 0.29\n",
      "Training: Epoch 82, Batch 81, Loss: 0.192\n",
      "Training: Epoch 82, Batch 82, Loss: 0.3\n",
      "Training: Epoch 82, Batch 83, Loss: 0.246\n",
      "Training: Epoch 82, Batch 84, Loss: 0.175\n",
      "Training: Epoch 82, Batch 85, Loss: 0.177\n",
      "Training: Epoch 82, Batch 86, Loss: 0.487\n",
      "Training: Epoch 82, Batch 87, Loss: 0.311\n",
      "Training: Epoch 82, Batch 88, Loss: 0.185\n",
      "Training: Epoch 82, Batch 89, Loss: 0.237\n",
      "Val: Epoch 82, Loss: 0.289\n",
      "Training: Epoch 83, Batch 0, Loss: 0.157\n",
      "Training: Epoch 83, Batch 1, Loss: 0.235\n",
      "Training: Epoch 83, Batch 2, Loss: 0.253\n",
      "Training: Epoch 83, Batch 3, Loss: 0.173\n",
      "Training: Epoch 83, Batch 4, Loss: 0.198\n",
      "Training: Epoch 83, Batch 5, Loss: 0.225\n",
      "Training: Epoch 83, Batch 6, Loss: 0.254\n",
      "Training: Epoch 83, Batch 7, Loss: 0.188\n",
      "Training: Epoch 83, Batch 8, Loss: 0.388\n",
      "Training: Epoch 83, Batch 9, Loss: 0.377\n",
      "Training: Epoch 83, Batch 10, Loss: 0.432\n",
      "Training: Epoch 83, Batch 11, Loss: 0.191\n",
      "Training: Epoch 83, Batch 12, Loss: 0.197\n",
      "Training: Epoch 83, Batch 13, Loss: 0.219\n",
      "Training: Epoch 83, Batch 14, Loss: 0.241\n",
      "Training: Epoch 83, Batch 15, Loss: 0.175\n",
      "Training: Epoch 83, Batch 16, Loss: 0.15\n",
      "Training: Epoch 83, Batch 17, Loss: 0.277\n",
      "Training: Epoch 83, Batch 18, Loss: 0.264\n",
      "Training: Epoch 83, Batch 19, Loss: 0.31\n",
      "Training: Epoch 83, Batch 20, Loss: 0.17\n",
      "Training: Epoch 83, Batch 21, Loss: 0.152\n",
      "Training: Epoch 83, Batch 22, Loss: 0.2\n",
      "Training: Epoch 83, Batch 23, Loss: 0.281\n",
      "Training: Epoch 83, Batch 24, Loss: 0.229\n",
      "Training: Epoch 83, Batch 25, Loss: 0.193\n",
      "Training: Epoch 83, Batch 26, Loss: 0.221\n",
      "Training: Epoch 83, Batch 27, Loss: 0.357\n",
      "Training: Epoch 83, Batch 28, Loss: 0.225\n",
      "Training: Epoch 83, Batch 29, Loss: 0.285\n",
      "Training: Epoch 83, Batch 30, Loss: 0.36\n",
      "Training: Epoch 83, Batch 31, Loss: 0.176\n",
      "Training: Epoch 83, Batch 32, Loss: 0.222\n",
      "Training: Epoch 83, Batch 33, Loss: 0.372\n",
      "Training: Epoch 83, Batch 34, Loss: 0.267\n",
      "Training: Epoch 83, Batch 35, Loss: 0.229\n",
      "Training: Epoch 83, Batch 36, Loss: 0.324\n",
      "Training: Epoch 83, Batch 37, Loss: 0.189\n",
      "Training: Epoch 83, Batch 38, Loss: 0.303\n",
      "Training: Epoch 83, Batch 39, Loss: 0.267\n",
      "Training: Epoch 83, Batch 40, Loss: 0.262\n",
      "Training: Epoch 83, Batch 41, Loss: 0.188\n",
      "Training: Epoch 83, Batch 42, Loss: 0.259\n",
      "Training: Epoch 83, Batch 43, Loss: 0.351\n",
      "Training: Epoch 83, Batch 44, Loss: 0.212\n",
      "Training: Epoch 83, Batch 45, Loss: 0.152\n",
      "Training: Epoch 83, Batch 46, Loss: 0.136\n",
      "Training: Epoch 83, Batch 47, Loss: 0.281\n",
      "Training: Epoch 83, Batch 48, Loss: 0.254\n",
      "Training: Epoch 83, Batch 49, Loss: 0.2\n",
      "Training: Epoch 83, Batch 50, Loss: 0.183\n",
      "Training: Epoch 83, Batch 51, Loss: 0.272\n",
      "Training: Epoch 83, Batch 52, Loss: 0.339\n",
      "Training: Epoch 83, Batch 53, Loss: 0.358\n",
      "Training: Epoch 83, Batch 54, Loss: 0.297\n",
      "Training: Epoch 83, Batch 55, Loss: 0.253\n",
      "Training: Epoch 83, Batch 56, Loss: 0.215\n",
      "Training: Epoch 83, Batch 57, Loss: 0.303\n",
      "Training: Epoch 83, Batch 58, Loss: 0.196\n",
      "Training: Epoch 83, Batch 59, Loss: 0.218\n",
      "Training: Epoch 83, Batch 60, Loss: 0.239\n",
      "Training: Epoch 83, Batch 61, Loss: 0.289\n",
      "Training: Epoch 83, Batch 62, Loss: 0.238\n",
      "Training: Epoch 83, Batch 63, Loss: 0.215\n",
      "Training: Epoch 83, Batch 64, Loss: 0.216\n",
      "Training: Epoch 83, Batch 65, Loss: 0.286\n",
      "Training: Epoch 83, Batch 66, Loss: 0.29\n",
      "Training: Epoch 83, Batch 67, Loss: 0.181\n",
      "Training: Epoch 83, Batch 68, Loss: 0.268\n",
      "Training: Epoch 83, Batch 69, Loss: 0.215\n",
      "Training: Epoch 83, Batch 70, Loss: 0.255\n",
      "Training: Epoch 83, Batch 71, Loss: 0.265\n",
      "Training: Epoch 83, Batch 72, Loss: 0.23\n",
      "Training: Epoch 83, Batch 73, Loss: 0.33\n",
      "Training: Epoch 83, Batch 74, Loss: 0.343\n",
      "Training: Epoch 83, Batch 75, Loss: 0.432\n",
      "Training: Epoch 83, Batch 76, Loss: 0.267\n",
      "Training: Epoch 83, Batch 77, Loss: 0.272\n",
      "Training: Epoch 83, Batch 78, Loss: 0.165\n",
      "Training: Epoch 83, Batch 79, Loss: 0.16\n",
      "Training: Epoch 83, Batch 80, Loss: 0.247\n",
      "Training: Epoch 83, Batch 81, Loss: 0.295\n",
      "Training: Epoch 83, Batch 82, Loss: 0.211\n",
      "Training: Epoch 83, Batch 83, Loss: 0.318\n",
      "Training: Epoch 83, Batch 84, Loss: 0.317\n",
      "Training: Epoch 83, Batch 85, Loss: 0.396\n",
      "Training: Epoch 83, Batch 86, Loss: 0.302\n",
      "Training: Epoch 83, Batch 87, Loss: 0.287\n",
      "Training: Epoch 83, Batch 88, Loss: 0.245\n",
      "Training: Epoch 83, Batch 89, Loss: 0.4\n",
      "Val: Epoch 83, Loss: 0.256\n",
      "Training: Epoch 84, Batch 0, Loss: 0.203\n",
      "Training: Epoch 84, Batch 1, Loss: 0.116\n",
      "Training: Epoch 84, Batch 2, Loss: 0.258\n",
      "Training: Epoch 84, Batch 3, Loss: 0.262\n",
      "Training: Epoch 84, Batch 4, Loss: 0.327\n",
      "Training: Epoch 84, Batch 5, Loss: 0.372\n",
      "Training: Epoch 84, Batch 6, Loss: 0.197\n",
      "Training: Epoch 84, Batch 7, Loss: 0.214\n",
      "Training: Epoch 84, Batch 8, Loss: 0.415\n",
      "Training: Epoch 84, Batch 9, Loss: 0.322\n",
      "Training: Epoch 84, Batch 10, Loss: 0.219\n",
      "Training: Epoch 84, Batch 11, Loss: 0.243\n",
      "Training: Epoch 84, Batch 12, Loss: 0.219\n",
      "Training: Epoch 84, Batch 13, Loss: 0.29\n",
      "Training: Epoch 84, Batch 14, Loss: 0.311\n",
      "Training: Epoch 84, Batch 15, Loss: 0.32\n",
      "Training: Epoch 84, Batch 16, Loss: 0.246\n",
      "Training: Epoch 84, Batch 17, Loss: 0.155\n",
      "Training: Epoch 84, Batch 18, Loss: 0.183\n",
      "Training: Epoch 84, Batch 19, Loss: 0.267\n",
      "Training: Epoch 84, Batch 20, Loss: 0.379\n",
      "Training: Epoch 84, Batch 21, Loss: 0.28\n",
      "Training: Epoch 84, Batch 22, Loss: 0.22\n",
      "Training: Epoch 84, Batch 23, Loss: 0.253\n",
      "Training: Epoch 84, Batch 24, Loss: 0.179\n",
      "Training: Epoch 84, Batch 25, Loss: 0.185\n",
      "Training: Epoch 84, Batch 26, Loss: 0.303\n",
      "Training: Epoch 84, Batch 27, Loss: 0.196\n",
      "Training: Epoch 84, Batch 28, Loss: 0.228\n",
      "Training: Epoch 84, Batch 29, Loss: 0.195\n",
      "Training: Epoch 84, Batch 30, Loss: 0.236\n",
      "Training: Epoch 84, Batch 31, Loss: 0.179\n",
      "Training: Epoch 84, Batch 32, Loss: 0.297\n",
      "Training: Epoch 84, Batch 33, Loss: 0.213\n",
      "Training: Epoch 84, Batch 34, Loss: 0.192\n",
      "Training: Epoch 84, Batch 35, Loss: 0.297\n",
      "Training: Epoch 84, Batch 36, Loss: 0.238\n",
      "Training: Epoch 84, Batch 37, Loss: 0.208\n",
      "Training: Epoch 84, Batch 38, Loss: 0.165\n",
      "Training: Epoch 84, Batch 39, Loss: 0.139\n",
      "Training: Epoch 84, Batch 40, Loss: 0.295\n",
      "Training: Epoch 84, Batch 41, Loss: 0.237\n",
      "Training: Epoch 84, Batch 42, Loss: 0.267\n",
      "Training: Epoch 84, Batch 43, Loss: 0.252\n",
      "Training: Epoch 84, Batch 44, Loss: 0.114\n",
      "Training: Epoch 84, Batch 45, Loss: 0.243\n",
      "Training: Epoch 84, Batch 46, Loss: 0.168\n",
      "Training: Epoch 84, Batch 47, Loss: 0.271\n",
      "Training: Epoch 84, Batch 48, Loss: 0.27\n",
      "Training: Epoch 84, Batch 49, Loss: 0.356\n",
      "Training: Epoch 84, Batch 50, Loss: 0.253\n",
      "Training: Epoch 84, Batch 51, Loss: 0.214\n",
      "Training: Epoch 84, Batch 52, Loss: 0.264\n",
      "Training: Epoch 84, Batch 53, Loss: 0.238\n",
      "Training: Epoch 84, Batch 54, Loss: 0.315\n",
      "Training: Epoch 84, Batch 55, Loss: 0.245\n",
      "Training: Epoch 84, Batch 56, Loss: 0.291\n",
      "Training: Epoch 84, Batch 57, Loss: 0.292\n",
      "Training: Epoch 84, Batch 58, Loss: 0.258\n",
      "Training: Epoch 84, Batch 59, Loss: 0.274\n",
      "Training: Epoch 84, Batch 60, Loss: 0.222\n",
      "Training: Epoch 84, Batch 61, Loss: 0.215\n",
      "Training: Epoch 84, Batch 62, Loss: 0.283\n",
      "Training: Epoch 84, Batch 63, Loss: 0.36\n",
      "Training: Epoch 84, Batch 64, Loss: 0.28\n",
      "Training: Epoch 84, Batch 65, Loss: 0.243\n",
      "Training: Epoch 84, Batch 66, Loss: 0.242\n",
      "Training: Epoch 84, Batch 67, Loss: 0.263\n",
      "Training: Epoch 84, Batch 68, Loss: 0.247\n",
      "Training: Epoch 84, Batch 69, Loss: 0.296\n",
      "Training: Epoch 84, Batch 70, Loss: 0.244\n",
      "Training: Epoch 84, Batch 71, Loss: 0.23\n",
      "Training: Epoch 84, Batch 72, Loss: 0.195\n",
      "Training: Epoch 84, Batch 73, Loss: 0.222\n",
      "Training: Epoch 84, Batch 74, Loss: 0.267\n",
      "Training: Epoch 84, Batch 75, Loss: 0.324\n",
      "Training: Epoch 84, Batch 76, Loss: 0.276\n",
      "Training: Epoch 84, Batch 77, Loss: 0.213\n",
      "Training: Epoch 84, Batch 78, Loss: 0.174\n",
      "Training: Epoch 84, Batch 79, Loss: 0.246\n",
      "Training: Epoch 84, Batch 80, Loss: 0.221\n",
      "Training: Epoch 84, Batch 81, Loss: 0.102\n",
      "Training: Epoch 84, Batch 82, Loss: 0.154\n",
      "Training: Epoch 84, Batch 83, Loss: 0.358\n",
      "Training: Epoch 84, Batch 84, Loss: 0.198\n",
      "Training: Epoch 84, Batch 85, Loss: 0.232\n",
      "Training: Epoch 84, Batch 86, Loss: 0.154\n",
      "Training: Epoch 84, Batch 87, Loss: 0.284\n",
      "Training: Epoch 84, Batch 88, Loss: 0.349\n",
      "Training: Epoch 84, Batch 89, Loss: 0.278\n",
      "Val: Epoch 84, Loss: 1.233\n",
      "Training: Epoch 85, Batch 0, Loss: 0.202\n",
      "Training: Epoch 85, Batch 1, Loss: 0.221\n",
      "Training: Epoch 85, Batch 2, Loss: 0.154\n",
      "Training: Epoch 85, Batch 3, Loss: 0.186\n",
      "Training: Epoch 85, Batch 4, Loss: 0.237\n",
      "Training: Epoch 85, Batch 5, Loss: 0.237\n",
      "Training: Epoch 85, Batch 6, Loss: 0.164\n",
      "Training: Epoch 85, Batch 7, Loss: 0.271\n",
      "Training: Epoch 85, Batch 8, Loss: 0.212\n",
      "Training: Epoch 85, Batch 9, Loss: 0.229\n",
      "Training: Epoch 85, Batch 10, Loss: 0.177\n",
      "Training: Epoch 85, Batch 11, Loss: 0.269\n",
      "Training: Epoch 85, Batch 12, Loss: 0.227\n",
      "Training: Epoch 85, Batch 13, Loss: 0.345\n",
      "Training: Epoch 85, Batch 14, Loss: 0.224\n",
      "Training: Epoch 85, Batch 15, Loss: 0.313\n",
      "Training: Epoch 85, Batch 16, Loss: 0.309\n",
      "Training: Epoch 85, Batch 17, Loss: 0.24\n",
      "Training: Epoch 85, Batch 18, Loss: 0.226\n",
      "Training: Epoch 85, Batch 19, Loss: 0.214\n",
      "Training: Epoch 85, Batch 20, Loss: 0.234\n",
      "Training: Epoch 85, Batch 21, Loss: 0.174\n",
      "Training: Epoch 85, Batch 22, Loss: 0.176\n",
      "Training: Epoch 85, Batch 23, Loss: 0.183\n",
      "Training: Epoch 85, Batch 24, Loss: 0.254\n",
      "Training: Epoch 85, Batch 25, Loss: 0.319\n",
      "Training: Epoch 85, Batch 26, Loss: 0.17\n",
      "Training: Epoch 85, Batch 27, Loss: 0.197\n",
      "Training: Epoch 85, Batch 28, Loss: 0.263\n",
      "Training: Epoch 85, Batch 29, Loss: 0.354\n",
      "Training: Epoch 85, Batch 30, Loss: 0.167\n",
      "Training: Epoch 85, Batch 31, Loss: 0.28\n",
      "Training: Epoch 85, Batch 32, Loss: 0.312\n",
      "Training: Epoch 85, Batch 33, Loss: 0.174\n",
      "Training: Epoch 85, Batch 34, Loss: 0.282\n",
      "Training: Epoch 85, Batch 35, Loss: 0.177\n",
      "Training: Epoch 85, Batch 36, Loss: 0.292\n",
      "Training: Epoch 85, Batch 37, Loss: 0.168\n",
      "Training: Epoch 85, Batch 38, Loss: 0.292\n",
      "Training: Epoch 85, Batch 39, Loss: 0.221\n",
      "Training: Epoch 85, Batch 40, Loss: 0.273\n",
      "Training: Epoch 85, Batch 41, Loss: 0.205\n",
      "Training: Epoch 85, Batch 42, Loss: 0.305\n",
      "Training: Epoch 85, Batch 43, Loss: 0.154\n",
      "Training: Epoch 85, Batch 44, Loss: 0.302\n",
      "Training: Epoch 85, Batch 45, Loss: 0.187\n",
      "Training: Epoch 85, Batch 46, Loss: 0.271\n",
      "Training: Epoch 85, Batch 47, Loss: 0.226\n",
      "Training: Epoch 85, Batch 48, Loss: 0.184\n",
      "Training: Epoch 85, Batch 49, Loss: 0.215\n",
      "Training: Epoch 85, Batch 50, Loss: 0.243\n",
      "Training: Epoch 85, Batch 51, Loss: 0.217\n",
      "Training: Epoch 85, Batch 52, Loss: 0.191\n",
      "Training: Epoch 85, Batch 53, Loss: 0.218\n",
      "Training: Epoch 85, Batch 54, Loss: 0.159\n",
      "Training: Epoch 85, Batch 55, Loss: 0.203\n",
      "Training: Epoch 85, Batch 56, Loss: 0.288\n",
      "Training: Epoch 85, Batch 57, Loss: 0.3\n",
      "Training: Epoch 85, Batch 58, Loss: 0.293\n",
      "Training: Epoch 85, Batch 59, Loss: 0.26\n",
      "Training: Epoch 85, Batch 60, Loss: 0.353\n",
      "Training: Epoch 85, Batch 61, Loss: 0.557\n",
      "Training: Epoch 85, Batch 62, Loss: 0.437\n",
      "Training: Epoch 85, Batch 63, Loss: 0.216\n",
      "Training: Epoch 85, Batch 64, Loss: 0.307\n",
      "Training: Epoch 85, Batch 65, Loss: 0.298\n",
      "Training: Epoch 85, Batch 66, Loss: 0.267\n",
      "Training: Epoch 85, Batch 67, Loss: 0.326\n",
      "Training: Epoch 85, Batch 68, Loss: 0.317\n",
      "Training: Epoch 85, Batch 69, Loss: 0.259\n",
      "Training: Epoch 85, Batch 70, Loss: 0.302\n",
      "Training: Epoch 85, Batch 71, Loss: 0.214\n",
      "Training: Epoch 85, Batch 72, Loss: 0.304\n",
      "Training: Epoch 85, Batch 73, Loss: 0.323\n",
      "Training: Epoch 85, Batch 74, Loss: 0.224\n",
      "Training: Epoch 85, Batch 75, Loss: 0.276\n",
      "Training: Epoch 85, Batch 76, Loss: 0.233\n",
      "Training: Epoch 85, Batch 77, Loss: 0.304\n",
      "Training: Epoch 85, Batch 78, Loss: 0.125\n",
      "Training: Epoch 85, Batch 79, Loss: 0.284\n",
      "Training: Epoch 85, Batch 80, Loss: 0.29\n",
      "Training: Epoch 85, Batch 81, Loss: 0.234\n",
      "Training: Epoch 85, Batch 82, Loss: 0.272\n",
      "Training: Epoch 85, Batch 83, Loss: 0.125\n",
      "Training: Epoch 85, Batch 84, Loss: 0.314\n",
      "Training: Epoch 85, Batch 85, Loss: 0.342\n",
      "Training: Epoch 85, Batch 86, Loss: 0.203\n",
      "Training: Epoch 85, Batch 87, Loss: 0.222\n",
      "Training: Epoch 85, Batch 88, Loss: 0.31\n",
      "Training: Epoch 85, Batch 89, Loss: 0.34\n",
      "Val: Epoch 85, Loss: 0.323\n",
      "Training: Epoch 86, Batch 0, Loss: 0.273\n",
      "Training: Epoch 86, Batch 1, Loss: 0.298\n",
      "Training: Epoch 86, Batch 2, Loss: 0.257\n",
      "Training: Epoch 86, Batch 3, Loss: 0.278\n",
      "Training: Epoch 86, Batch 4, Loss: 0.243\n",
      "Training: Epoch 86, Batch 5, Loss: 0.253\n",
      "Training: Epoch 86, Batch 6, Loss: 0.226\n",
      "Training: Epoch 86, Batch 7, Loss: 0.161\n",
      "Training: Epoch 86, Batch 8, Loss: 0.206\n",
      "Training: Epoch 86, Batch 9, Loss: 0.17\n",
      "Training: Epoch 86, Batch 10, Loss: 0.211\n",
      "Training: Epoch 86, Batch 11, Loss: 0.248\n",
      "Training: Epoch 86, Batch 12, Loss: 0.214\n",
      "Training: Epoch 86, Batch 13, Loss: 0.318\n",
      "Training: Epoch 86, Batch 14, Loss: 0.253\n",
      "Training: Epoch 86, Batch 15, Loss: 0.302\n",
      "Training: Epoch 86, Batch 16, Loss: 0.253\n",
      "Training: Epoch 86, Batch 17, Loss: 0.324\n",
      "Training: Epoch 86, Batch 18, Loss: 0.289\n",
      "Training: Epoch 86, Batch 19, Loss: 0.202\n",
      "Training: Epoch 86, Batch 20, Loss: 0.226\n",
      "Training: Epoch 86, Batch 21, Loss: 0.232\n",
      "Training: Epoch 86, Batch 22, Loss: 0.388\n",
      "Training: Epoch 86, Batch 23, Loss: 0.246\n",
      "Training: Epoch 86, Batch 24, Loss: 0.287\n",
      "Training: Epoch 86, Batch 25, Loss: 0.195\n",
      "Training: Epoch 86, Batch 26, Loss: 0.324\n",
      "Training: Epoch 86, Batch 27, Loss: 0.244\n",
      "Training: Epoch 86, Batch 28, Loss: 0.256\n",
      "Training: Epoch 86, Batch 29, Loss: 0.277\n",
      "Training: Epoch 86, Batch 30, Loss: 0.322\n",
      "Training: Epoch 86, Batch 31, Loss: 0.198\n",
      "Training: Epoch 86, Batch 32, Loss: 0.183\n",
      "Training: Epoch 86, Batch 33, Loss: 0.348\n",
      "Training: Epoch 86, Batch 34, Loss: 0.2\n",
      "Training: Epoch 86, Batch 35, Loss: 0.307\n",
      "Training: Epoch 86, Batch 36, Loss: 0.229\n",
      "Training: Epoch 86, Batch 37, Loss: 0.261\n",
      "Training: Epoch 86, Batch 38, Loss: 0.182\n",
      "Training: Epoch 86, Batch 39, Loss: 0.335\n",
      "Training: Epoch 86, Batch 40, Loss: 0.217\n",
      "Training: Epoch 86, Batch 41, Loss: 0.211\n",
      "Training: Epoch 86, Batch 42, Loss: 0.186\n",
      "Training: Epoch 86, Batch 43, Loss: 0.267\n",
      "Training: Epoch 86, Batch 44, Loss: 0.238\n",
      "Training: Epoch 86, Batch 45, Loss: 0.211\n",
      "Training: Epoch 86, Batch 46, Loss: 0.202\n",
      "Training: Epoch 86, Batch 47, Loss: 0.223\n",
      "Training: Epoch 86, Batch 48, Loss: 0.222\n",
      "Training: Epoch 86, Batch 49, Loss: 0.18\n",
      "Training: Epoch 86, Batch 50, Loss: 0.216\n",
      "Training: Epoch 86, Batch 51, Loss: 0.254\n",
      "Training: Epoch 86, Batch 52, Loss: 0.181\n",
      "Training: Epoch 86, Batch 53, Loss: 0.256\n",
      "Training: Epoch 86, Batch 54, Loss: 0.239\n",
      "Training: Epoch 86, Batch 55, Loss: 0.221\n",
      "Training: Epoch 86, Batch 56, Loss: 0.132\n",
      "Training: Epoch 86, Batch 57, Loss: 0.257\n",
      "Training: Epoch 86, Batch 58, Loss: 0.346\n",
      "Training: Epoch 86, Batch 59, Loss: 0.206\n",
      "Training: Epoch 86, Batch 60, Loss: 0.235\n",
      "Training: Epoch 86, Batch 61, Loss: 0.239\n",
      "Training: Epoch 86, Batch 62, Loss: 0.224\n",
      "Training: Epoch 86, Batch 63, Loss: 0.482\n",
      "Training: Epoch 86, Batch 64, Loss: 0.348\n",
      "Training: Epoch 86, Batch 65, Loss: 0.267\n",
      "Training: Epoch 86, Batch 66, Loss: 0.337\n",
      "Training: Epoch 86, Batch 67, Loss: 0.322\n",
      "Training: Epoch 86, Batch 68, Loss: 0.568\n",
      "Training: Epoch 86, Batch 69, Loss: 0.202\n",
      "Training: Epoch 86, Batch 70, Loss: 0.228\n",
      "Training: Epoch 86, Batch 71, Loss: 0.21\n",
      "Training: Epoch 86, Batch 72, Loss: 0.235\n",
      "Training: Epoch 86, Batch 73, Loss: 0.262\n",
      "Training: Epoch 86, Batch 74, Loss: 0.261\n",
      "Training: Epoch 86, Batch 75, Loss: 0.256\n",
      "Training: Epoch 86, Batch 76, Loss: 0.24\n",
      "Training: Epoch 86, Batch 77, Loss: 0.244\n",
      "Training: Epoch 86, Batch 78, Loss: 0.313\n",
      "Training: Epoch 86, Batch 79, Loss: 0.196\n",
      "Training: Epoch 86, Batch 80, Loss: 0.317\n",
      "Training: Epoch 86, Batch 81, Loss: 0.172\n",
      "Training: Epoch 86, Batch 82, Loss: 0.215\n",
      "Training: Epoch 86, Batch 83, Loss: 0.329\n",
      "Training: Epoch 86, Batch 84, Loss: 0.29\n",
      "Training: Epoch 86, Batch 85, Loss: 0.285\n",
      "Training: Epoch 86, Batch 86, Loss: 0.3\n",
      "Training: Epoch 86, Batch 87, Loss: 0.161\n",
      "Training: Epoch 86, Batch 88, Loss: 0.152\n",
      "Training: Epoch 86, Batch 89, Loss: 0.247\n",
      "Val: Epoch 86, Loss: 0.32\n",
      "Training: Epoch 87, Batch 0, Loss: 0.298\n",
      "Training: Epoch 87, Batch 1, Loss: 0.206\n",
      "Training: Epoch 87, Batch 2, Loss: 0.368\n",
      "Training: Epoch 87, Batch 3, Loss: 0.367\n",
      "Training: Epoch 87, Batch 4, Loss: 0.255\n",
      "Training: Epoch 87, Batch 5, Loss: 0.25\n",
      "Training: Epoch 87, Batch 6, Loss: 0.21\n",
      "Training: Epoch 87, Batch 7, Loss: 0.25\n",
      "Training: Epoch 87, Batch 8, Loss: 0.279\n",
      "Training: Epoch 87, Batch 9, Loss: 0.243\n",
      "Training: Epoch 87, Batch 10, Loss: 0.215\n",
      "Training: Epoch 87, Batch 11, Loss: 0.352\n",
      "Training: Epoch 87, Batch 12, Loss: 0.211\n",
      "Training: Epoch 87, Batch 13, Loss: 0.23\n",
      "Training: Epoch 87, Batch 14, Loss: 0.159\n",
      "Training: Epoch 87, Batch 15, Loss: 0.209\n",
      "Training: Epoch 87, Batch 16, Loss: 0.197\n",
      "Training: Epoch 87, Batch 17, Loss: 0.234\n",
      "Training: Epoch 87, Batch 18, Loss: 0.23\n",
      "Training: Epoch 87, Batch 19, Loss: 0.286\n",
      "Training: Epoch 87, Batch 20, Loss: 0.248\n",
      "Training: Epoch 87, Batch 21, Loss: 0.261\n",
      "Training: Epoch 87, Batch 22, Loss: 0.231\n",
      "Training: Epoch 87, Batch 23, Loss: 0.179\n",
      "Training: Epoch 87, Batch 24, Loss: 0.286\n",
      "Training: Epoch 87, Batch 25, Loss: 0.264\n",
      "Training: Epoch 87, Batch 26, Loss: 0.299\n",
      "Training: Epoch 87, Batch 27, Loss: 0.302\n",
      "Training: Epoch 87, Batch 28, Loss: 0.176\n",
      "Training: Epoch 87, Batch 29, Loss: 0.213\n",
      "Training: Epoch 87, Batch 30, Loss: 0.18\n",
      "Training: Epoch 87, Batch 31, Loss: 0.24\n",
      "Training: Epoch 87, Batch 32, Loss: 0.238\n",
      "Training: Epoch 87, Batch 33, Loss: 0.264\n",
      "Training: Epoch 87, Batch 34, Loss: 0.216\n",
      "Training: Epoch 87, Batch 35, Loss: 0.189\n",
      "Training: Epoch 87, Batch 36, Loss: 0.277\n",
      "Training: Epoch 87, Batch 37, Loss: 0.306\n",
      "Training: Epoch 87, Batch 38, Loss: 0.255\n",
      "Training: Epoch 87, Batch 39, Loss: 0.185\n",
      "Training: Epoch 87, Batch 40, Loss: 0.213\n",
      "Training: Epoch 87, Batch 41, Loss: 0.269\n",
      "Training: Epoch 87, Batch 42, Loss: 0.3\n",
      "Training: Epoch 87, Batch 43, Loss: 0.179\n",
      "Training: Epoch 87, Batch 44, Loss: 0.168\n",
      "Training: Epoch 87, Batch 45, Loss: 0.172\n",
      "Training: Epoch 87, Batch 46, Loss: 0.227\n",
      "Training: Epoch 87, Batch 47, Loss: 0.215\n",
      "Training: Epoch 87, Batch 48, Loss: 0.145\n",
      "Training: Epoch 87, Batch 49, Loss: 0.262\n",
      "Training: Epoch 87, Batch 50, Loss: 0.29\n",
      "Training: Epoch 87, Batch 51, Loss: 0.276\n",
      "Training: Epoch 87, Batch 52, Loss: 0.256\n",
      "Training: Epoch 87, Batch 53, Loss: 0.169\n",
      "Training: Epoch 87, Batch 54, Loss: 0.241\n",
      "Training: Epoch 87, Batch 55, Loss: 0.189\n",
      "Training: Epoch 87, Batch 56, Loss: 0.361\n",
      "Training: Epoch 87, Batch 57, Loss: 0.333\n",
      "Training: Epoch 87, Batch 58, Loss: 0.289\n",
      "Training: Epoch 87, Batch 59, Loss: 0.227\n",
      "Training: Epoch 87, Batch 60, Loss: 0.207\n",
      "Training: Epoch 87, Batch 61, Loss: 0.281\n",
      "Training: Epoch 87, Batch 62, Loss: 0.283\n",
      "Training: Epoch 87, Batch 63, Loss: 0.328\n",
      "Training: Epoch 87, Batch 64, Loss: 0.329\n",
      "Training: Epoch 87, Batch 65, Loss: 0.241\n",
      "Training: Epoch 87, Batch 66, Loss: 0.331\n",
      "Training: Epoch 87, Batch 67, Loss: 0.144\n",
      "Training: Epoch 87, Batch 68, Loss: 0.314\n",
      "Training: Epoch 87, Batch 69, Loss: 0.291\n",
      "Training: Epoch 87, Batch 70, Loss: 0.32\n",
      "Training: Epoch 87, Batch 71, Loss: 0.258\n",
      "Training: Epoch 87, Batch 72, Loss: 0.177\n",
      "Training: Epoch 87, Batch 73, Loss: 0.187\n",
      "Training: Epoch 87, Batch 74, Loss: 0.204\n",
      "Training: Epoch 87, Batch 75, Loss: 0.216\n",
      "Training: Epoch 87, Batch 76, Loss: 0.198\n",
      "Training: Epoch 87, Batch 77, Loss: 0.282\n",
      "Training: Epoch 87, Batch 78, Loss: 0.19\n",
      "Training: Epoch 87, Batch 79, Loss: 0.188\n",
      "Training: Epoch 87, Batch 80, Loss: 0.25\n",
      "Training: Epoch 87, Batch 81, Loss: 0.24\n",
      "Training: Epoch 87, Batch 82, Loss: 0.242\n",
      "Training: Epoch 87, Batch 83, Loss: 0.207\n",
      "Training: Epoch 87, Batch 84, Loss: 0.376\n",
      "Training: Epoch 87, Batch 85, Loss: 0.308\n",
      "Training: Epoch 87, Batch 86, Loss: 0.203\n",
      "Training: Epoch 87, Batch 87, Loss: 0.305\n",
      "Training: Epoch 87, Batch 88, Loss: 0.182\n",
      "Training: Epoch 87, Batch 89, Loss: 0.243\n",
      "Val: Epoch 87, Loss: 0.272\n",
      "Training: Epoch 88, Batch 0, Loss: 0.318\n",
      "Training: Epoch 88, Batch 1, Loss: 0.142\n",
      "Training: Epoch 88, Batch 2, Loss: 0.221\n",
      "Training: Epoch 88, Batch 3, Loss: 0.379\n",
      "Training: Epoch 88, Batch 4, Loss: 0.276\n",
      "Training: Epoch 88, Batch 5, Loss: 0.407\n",
      "Training: Epoch 88, Batch 6, Loss: 0.272\n",
      "Training: Epoch 88, Batch 7, Loss: 0.323\n",
      "Training: Epoch 88, Batch 8, Loss: 0.223\n",
      "Training: Epoch 88, Batch 9, Loss: 0.12\n",
      "Training: Epoch 88, Batch 10, Loss: 0.219\n",
      "Training: Epoch 88, Batch 11, Loss: 0.192\n",
      "Training: Epoch 88, Batch 12, Loss: 0.211\n",
      "Training: Epoch 88, Batch 13, Loss: 0.217\n",
      "Training: Epoch 88, Batch 14, Loss: 0.2\n",
      "Training: Epoch 88, Batch 15, Loss: 0.144\n",
      "Training: Epoch 88, Batch 16, Loss: 0.183\n",
      "Training: Epoch 88, Batch 17, Loss: 0.184\n",
      "Training: Epoch 88, Batch 18, Loss: 0.235\n",
      "Training: Epoch 88, Batch 19, Loss: 0.201\n",
      "Training: Epoch 88, Batch 20, Loss: 0.128\n",
      "Training: Epoch 88, Batch 21, Loss: 0.239\n",
      "Training: Epoch 88, Batch 22, Loss: 0.295\n",
      "Training: Epoch 88, Batch 23, Loss: 0.234\n",
      "Training: Epoch 88, Batch 24, Loss: 0.181\n",
      "Training: Epoch 88, Batch 25, Loss: 0.216\n",
      "Training: Epoch 88, Batch 26, Loss: 0.192\n",
      "Training: Epoch 88, Batch 27, Loss: 0.258\n",
      "Training: Epoch 88, Batch 28, Loss: 0.283\n",
      "Training: Epoch 88, Batch 29, Loss: 0.266\n",
      "Training: Epoch 88, Batch 30, Loss: 0.219\n",
      "Training: Epoch 88, Batch 31, Loss: 0.196\n",
      "Training: Epoch 88, Batch 32, Loss: 0.218\n",
      "Training: Epoch 88, Batch 33, Loss: 0.205\n",
      "Training: Epoch 88, Batch 34, Loss: 0.278\n",
      "Training: Epoch 88, Batch 35, Loss: 0.22\n",
      "Training: Epoch 88, Batch 36, Loss: 0.32\n",
      "Training: Epoch 88, Batch 37, Loss: 0.27\n",
      "Training: Epoch 88, Batch 38, Loss: 0.214\n",
      "Training: Epoch 88, Batch 39, Loss: 0.252\n",
      "Training: Epoch 88, Batch 40, Loss: 0.248\n",
      "Training: Epoch 88, Batch 41, Loss: 0.147\n",
      "Training: Epoch 88, Batch 42, Loss: 0.307\n",
      "Training: Epoch 88, Batch 43, Loss: 0.205\n",
      "Training: Epoch 88, Batch 44, Loss: 0.153\n",
      "Training: Epoch 88, Batch 45, Loss: 0.231\n",
      "Training: Epoch 88, Batch 46, Loss: 0.359\n",
      "Training: Epoch 88, Batch 47, Loss: 0.299\n",
      "Training: Epoch 88, Batch 48, Loss: 0.2\n",
      "Training: Epoch 88, Batch 49, Loss: 0.176\n",
      "Training: Epoch 88, Batch 50, Loss: 0.264\n",
      "Training: Epoch 88, Batch 51, Loss: 0.263\n",
      "Training: Epoch 88, Batch 52, Loss: 0.416\n",
      "Training: Epoch 88, Batch 53, Loss: 0.198\n",
      "Training: Epoch 88, Batch 54, Loss: 0.233\n",
      "Training: Epoch 88, Batch 55, Loss: 0.193\n",
      "Training: Epoch 88, Batch 56, Loss: 0.184\n",
      "Training: Epoch 88, Batch 57, Loss: 0.193\n",
      "Training: Epoch 88, Batch 58, Loss: 0.255\n",
      "Training: Epoch 88, Batch 59, Loss: 0.429\n",
      "Training: Epoch 88, Batch 60, Loss: 0.277\n",
      "Training: Epoch 88, Batch 61, Loss: 0.365\n",
      "Training: Epoch 88, Batch 62, Loss: 0.262\n",
      "Training: Epoch 88, Batch 63, Loss: 0.171\n",
      "Training: Epoch 88, Batch 64, Loss: 0.277\n",
      "Training: Epoch 88, Batch 65, Loss: 0.261\n",
      "Training: Epoch 88, Batch 66, Loss: 0.243\n",
      "Training: Epoch 88, Batch 67, Loss: 0.164\n",
      "Training: Epoch 88, Batch 68, Loss: 0.29\n",
      "Training: Epoch 88, Batch 69, Loss: 0.186\n",
      "Training: Epoch 88, Batch 70, Loss: 0.198\n",
      "Training: Epoch 88, Batch 71, Loss: 0.28\n",
      "Training: Epoch 88, Batch 72, Loss: 0.369\n",
      "Training: Epoch 88, Batch 73, Loss: 0.27\n",
      "Training: Epoch 88, Batch 74, Loss: 0.22\n",
      "Training: Epoch 88, Batch 75, Loss: 0.133\n",
      "Training: Epoch 88, Batch 76, Loss: 0.203\n",
      "Training: Epoch 88, Batch 77, Loss: 0.243\n",
      "Training: Epoch 88, Batch 78, Loss: 0.234\n",
      "Training: Epoch 88, Batch 79, Loss: 0.326\n",
      "Training: Epoch 88, Batch 80, Loss: 0.307\n",
      "Training: Epoch 88, Batch 81, Loss: 0.171\n",
      "Training: Epoch 88, Batch 82, Loss: 0.196\n",
      "Training: Epoch 88, Batch 83, Loss: 0.234\n",
      "Training: Epoch 88, Batch 84, Loss: 0.18\n",
      "Training: Epoch 88, Batch 85, Loss: 0.234\n",
      "Training: Epoch 88, Batch 86, Loss: 0.126\n",
      "Training: Epoch 88, Batch 87, Loss: 0.235\n",
      "Training: Epoch 88, Batch 88, Loss: 0.252\n",
      "Training: Epoch 88, Batch 89, Loss: 0.178\n",
      "Val: Epoch 88, Loss: 0.249\n",
      "Training: Epoch 89, Batch 0, Loss: 0.224\n",
      "Training: Epoch 89, Batch 1, Loss: 0.22\n",
      "Training: Epoch 89, Batch 2, Loss: 0.186\n",
      "Training: Epoch 89, Batch 3, Loss: 0.272\n",
      "Training: Epoch 89, Batch 4, Loss: 0.186\n",
      "Training: Epoch 89, Batch 5, Loss: 0.243\n",
      "Training: Epoch 89, Batch 6, Loss: 0.244\n",
      "Training: Epoch 89, Batch 7, Loss: 0.152\n",
      "Training: Epoch 89, Batch 8, Loss: 0.237\n",
      "Training: Epoch 89, Batch 9, Loss: 0.215\n",
      "Training: Epoch 89, Batch 10, Loss: 0.185\n",
      "Training: Epoch 89, Batch 11, Loss: 0.236\n",
      "Training: Epoch 89, Batch 12, Loss: 0.184\n",
      "Training: Epoch 89, Batch 13, Loss: 0.36\n",
      "Training: Epoch 89, Batch 14, Loss: 0.173\n",
      "Training: Epoch 89, Batch 15, Loss: 0.216\n",
      "Training: Epoch 89, Batch 16, Loss: 0.282\n",
      "Training: Epoch 89, Batch 17, Loss: 0.234\n",
      "Training: Epoch 89, Batch 18, Loss: 0.173\n",
      "Training: Epoch 89, Batch 19, Loss: 0.292\n",
      "Training: Epoch 89, Batch 20, Loss: 0.28\n",
      "Training: Epoch 89, Batch 21, Loss: 0.162\n",
      "Training: Epoch 89, Batch 22, Loss: 0.149\n",
      "Training: Epoch 89, Batch 23, Loss: 0.261\n",
      "Training: Epoch 89, Batch 24, Loss: 0.155\n",
      "Training: Epoch 89, Batch 25, Loss: 0.129\n",
      "Training: Epoch 89, Batch 26, Loss: 0.224\n",
      "Training: Epoch 89, Batch 27, Loss: 0.203\n",
      "Training: Epoch 89, Batch 28, Loss: 0.228\n",
      "Training: Epoch 89, Batch 29, Loss: 0.277\n",
      "Training: Epoch 89, Batch 30, Loss: 0.244\n",
      "Training: Epoch 89, Batch 31, Loss: 0.214\n",
      "Training: Epoch 89, Batch 32, Loss: 0.187\n",
      "Training: Epoch 89, Batch 33, Loss: 0.147\n",
      "Training: Epoch 89, Batch 34, Loss: 0.184\n",
      "Training: Epoch 89, Batch 35, Loss: 0.173\n",
      "Training: Epoch 89, Batch 36, Loss: 0.177\n",
      "Training: Epoch 89, Batch 37, Loss: 0.185\n",
      "Training: Epoch 89, Batch 38, Loss: 0.206\n",
      "Training: Epoch 89, Batch 39, Loss: 0.331\n",
      "Training: Epoch 89, Batch 40, Loss: 0.214\n",
      "Training: Epoch 89, Batch 41, Loss: 0.285\n",
      "Training: Epoch 89, Batch 42, Loss: 0.207\n",
      "Training: Epoch 89, Batch 43, Loss: 0.229\n",
      "Training: Epoch 89, Batch 44, Loss: 0.123\n",
      "Training: Epoch 89, Batch 45, Loss: 0.25\n",
      "Training: Epoch 89, Batch 46, Loss: 0.26\n",
      "Training: Epoch 89, Batch 47, Loss: 0.266\n",
      "Training: Epoch 89, Batch 48, Loss: 0.26\n",
      "Training: Epoch 89, Batch 49, Loss: 0.214\n",
      "Training: Epoch 89, Batch 50, Loss: 0.219\n",
      "Training: Epoch 89, Batch 51, Loss: 0.157\n",
      "Training: Epoch 89, Batch 52, Loss: 0.178\n",
      "Training: Epoch 89, Batch 53, Loss: 0.119\n",
      "Training: Epoch 89, Batch 54, Loss: 0.232\n",
      "Training: Epoch 89, Batch 55, Loss: 0.146\n",
      "Training: Epoch 89, Batch 56, Loss: 0.348\n",
      "Training: Epoch 89, Batch 57, Loss: 0.156\n",
      "Training: Epoch 89, Batch 58, Loss: 0.146\n",
      "Training: Epoch 89, Batch 59, Loss: 0.16\n",
      "Training: Epoch 89, Batch 60, Loss: 0.214\n",
      "Training: Epoch 89, Batch 61, Loss: 0.225\n",
      "Training: Epoch 89, Batch 62, Loss: 0.251\n",
      "Training: Epoch 89, Batch 63, Loss: 0.125\n",
      "Training: Epoch 89, Batch 64, Loss: 0.2\n",
      "Training: Epoch 89, Batch 65, Loss: 0.304\n",
      "Training: Epoch 89, Batch 66, Loss: 0.16\n",
      "Training: Epoch 89, Batch 67, Loss: 0.274\n",
      "Training: Epoch 89, Batch 68, Loss: 0.263\n",
      "Training: Epoch 89, Batch 69, Loss: 0.217\n",
      "Training: Epoch 89, Batch 70, Loss: 0.213\n",
      "Training: Epoch 89, Batch 71, Loss: 0.237\n",
      "Training: Epoch 89, Batch 72, Loss: 0.22\n",
      "Training: Epoch 89, Batch 73, Loss: 0.197\n",
      "Training: Epoch 89, Batch 74, Loss: 0.269\n",
      "Training: Epoch 89, Batch 75, Loss: 0.214\n",
      "Training: Epoch 89, Batch 76, Loss: 0.215\n",
      "Training: Epoch 89, Batch 77, Loss: 0.198\n",
      "Training: Epoch 89, Batch 78, Loss: 0.164\n",
      "Training: Epoch 89, Batch 79, Loss: 0.194\n",
      "Training: Epoch 89, Batch 80, Loss: 0.188\n",
      "Training: Epoch 89, Batch 81, Loss: 0.224\n",
      "Training: Epoch 89, Batch 82, Loss: 0.15\n",
      "Training: Epoch 89, Batch 83, Loss: 0.231\n",
      "Training: Epoch 89, Batch 84, Loss: 0.142\n",
      "Training: Epoch 89, Batch 85, Loss: 0.235\n",
      "Training: Epoch 89, Batch 86, Loss: 0.257\n",
      "Training: Epoch 89, Batch 87, Loss: 0.223\n",
      "Training: Epoch 89, Batch 88, Loss: 0.188\n",
      "Training: Epoch 89, Batch 89, Loss: 0.258\n",
      "Val: Epoch 89, Loss: 0.257\n",
      "Training: Epoch 90, Batch 0, Loss: 0.238\n",
      "Training: Epoch 90, Batch 1, Loss: 0.134\n",
      "Training: Epoch 90, Batch 2, Loss: 0.201\n",
      "Training: Epoch 90, Batch 3, Loss: 0.211\n",
      "Training: Epoch 90, Batch 4, Loss: 0.192\n",
      "Training: Epoch 90, Batch 5, Loss: 0.198\n",
      "Training: Epoch 90, Batch 6, Loss: 0.246\n",
      "Training: Epoch 90, Batch 7, Loss: 0.2\n",
      "Training: Epoch 90, Batch 8, Loss: 0.344\n",
      "Training: Epoch 90, Batch 9, Loss: 0.16\n",
      "Training: Epoch 90, Batch 10, Loss: 0.206\n",
      "Training: Epoch 90, Batch 11, Loss: 0.145\n",
      "Training: Epoch 90, Batch 12, Loss: 0.227\n",
      "Training: Epoch 90, Batch 13, Loss: 0.222\n",
      "Training: Epoch 90, Batch 14, Loss: 0.184\n",
      "Training: Epoch 90, Batch 15, Loss: 0.183\n",
      "Training: Epoch 90, Batch 16, Loss: 0.227\n",
      "Training: Epoch 90, Batch 17, Loss: 0.197\n",
      "Training: Epoch 90, Batch 18, Loss: 0.128\n",
      "Training: Epoch 90, Batch 19, Loss: 0.183\n",
      "Training: Epoch 90, Batch 20, Loss: 0.236\n",
      "Training: Epoch 90, Batch 21, Loss: 0.239\n",
      "Training: Epoch 90, Batch 22, Loss: 0.17\n",
      "Training: Epoch 90, Batch 23, Loss: 0.265\n",
      "Training: Epoch 90, Batch 24, Loss: 0.18\n",
      "Training: Epoch 90, Batch 25, Loss: 0.251\n",
      "Training: Epoch 90, Batch 26, Loss: 0.175\n",
      "Training: Epoch 90, Batch 27, Loss: 0.253\n",
      "Training: Epoch 90, Batch 28, Loss: 0.23\n",
      "Training: Epoch 90, Batch 29, Loss: 0.194\n",
      "Training: Epoch 90, Batch 30, Loss: 0.167\n",
      "Training: Epoch 90, Batch 31, Loss: 0.188\n",
      "Training: Epoch 90, Batch 32, Loss: 0.275\n",
      "Training: Epoch 90, Batch 33, Loss: 0.125\n",
      "Training: Epoch 90, Batch 34, Loss: 0.133\n",
      "Training: Epoch 90, Batch 35, Loss: 0.225\n",
      "Training: Epoch 90, Batch 36, Loss: 0.133\n",
      "Training: Epoch 90, Batch 37, Loss: 0.179\n",
      "Training: Epoch 90, Batch 38, Loss: 0.188\n",
      "Training: Epoch 90, Batch 39, Loss: 0.307\n",
      "Training: Epoch 90, Batch 40, Loss: 0.241\n",
      "Training: Epoch 90, Batch 41, Loss: 0.252\n",
      "Training: Epoch 90, Batch 42, Loss: 0.19\n",
      "Training: Epoch 90, Batch 43, Loss: 0.196\n",
      "Training: Epoch 90, Batch 44, Loss: 0.24\n",
      "Training: Epoch 90, Batch 45, Loss: 0.185\n",
      "Training: Epoch 90, Batch 46, Loss: 0.205\n",
      "Training: Epoch 90, Batch 47, Loss: 0.224\n",
      "Training: Epoch 90, Batch 48, Loss: 0.266\n",
      "Training: Epoch 90, Batch 49, Loss: 0.262\n",
      "Training: Epoch 90, Batch 50, Loss: 0.145\n",
      "Training: Epoch 90, Batch 51, Loss: 0.203\n",
      "Training: Epoch 90, Batch 52, Loss: 0.301\n",
      "Training: Epoch 90, Batch 53, Loss: 0.232\n",
      "Training: Epoch 90, Batch 54, Loss: 0.157\n",
      "Training: Epoch 90, Batch 55, Loss: 0.195\n",
      "Training: Epoch 90, Batch 56, Loss: 0.265\n",
      "Training: Epoch 90, Batch 57, Loss: 0.192\n",
      "Training: Epoch 90, Batch 58, Loss: 0.253\n",
      "Training: Epoch 90, Batch 59, Loss: 0.21\n",
      "Training: Epoch 90, Batch 60, Loss: 0.196\n",
      "Training: Epoch 90, Batch 61, Loss: 0.15\n",
      "Training: Epoch 90, Batch 62, Loss: 0.179\n",
      "Training: Epoch 90, Batch 63, Loss: 0.234\n",
      "Training: Epoch 90, Batch 64, Loss: 0.195\n",
      "Training: Epoch 90, Batch 65, Loss: 0.161\n",
      "Training: Epoch 90, Batch 66, Loss: 0.137\n",
      "Training: Epoch 90, Batch 67, Loss: 0.431\n",
      "Training: Epoch 90, Batch 68, Loss: 0.162\n",
      "Training: Epoch 90, Batch 69, Loss: 0.158\n",
      "Training: Epoch 90, Batch 70, Loss: 0.197\n",
      "Training: Epoch 90, Batch 71, Loss: 0.23\n",
      "Training: Epoch 90, Batch 72, Loss: 0.147\n",
      "Training: Epoch 90, Batch 73, Loss: 0.205\n",
      "Training: Epoch 90, Batch 74, Loss: 0.247\n",
      "Training: Epoch 90, Batch 75, Loss: 0.251\n",
      "Training: Epoch 90, Batch 76, Loss: 0.22\n",
      "Training: Epoch 90, Batch 77, Loss: 0.157\n",
      "Training: Epoch 90, Batch 78, Loss: 0.211\n",
      "Training: Epoch 90, Batch 79, Loss: 0.311\n",
      "Training: Epoch 90, Batch 80, Loss: 0.187\n",
      "Training: Epoch 90, Batch 81, Loss: 0.116\n",
      "Training: Epoch 90, Batch 82, Loss: 0.207\n",
      "Training: Epoch 90, Batch 83, Loss: 0.179\n",
      "Training: Epoch 90, Batch 84, Loss: 0.279\n",
      "Training: Epoch 90, Batch 85, Loss: 0.221\n",
      "Training: Epoch 90, Batch 86, Loss: 0.188\n",
      "Training: Epoch 90, Batch 87, Loss: 0.215\n",
      "Training: Epoch 90, Batch 88, Loss: 0.173\n",
      "Training: Epoch 90, Batch 89, Loss: 0.146\n",
      "Val: Epoch 90, Loss: 0.297\n",
      "Training: Epoch 91, Batch 0, Loss: 0.193\n",
      "Training: Epoch 91, Batch 1, Loss: 0.176\n",
      "Training: Epoch 91, Batch 2, Loss: 0.194\n",
      "Training: Epoch 91, Batch 3, Loss: 0.162\n",
      "Training: Epoch 91, Batch 4, Loss: 0.24\n",
      "Training: Epoch 91, Batch 5, Loss: 0.223\n",
      "Training: Epoch 91, Batch 6, Loss: 0.205\n",
      "Training: Epoch 91, Batch 7, Loss: 0.193\n",
      "Training: Epoch 91, Batch 8, Loss: 0.253\n",
      "Training: Epoch 91, Batch 9, Loss: 0.181\n",
      "Training: Epoch 91, Batch 10, Loss: 0.154\n",
      "Training: Epoch 91, Batch 11, Loss: 0.197\n",
      "Training: Epoch 91, Batch 12, Loss: 0.205\n",
      "Training: Epoch 91, Batch 13, Loss: 0.162\n",
      "Training: Epoch 91, Batch 14, Loss: 0.265\n",
      "Training: Epoch 91, Batch 15, Loss: 0.207\n",
      "Training: Epoch 91, Batch 16, Loss: 0.21\n",
      "Training: Epoch 91, Batch 17, Loss: 0.106\n",
      "Training: Epoch 91, Batch 18, Loss: 0.16\n",
      "Training: Epoch 91, Batch 19, Loss: 0.2\n",
      "Training: Epoch 91, Batch 20, Loss: 0.168\n",
      "Training: Epoch 91, Batch 21, Loss: 0.192\n",
      "Training: Epoch 91, Batch 22, Loss: 0.211\n",
      "Training: Epoch 91, Batch 23, Loss: 0.137\n",
      "Training: Epoch 91, Batch 24, Loss: 0.206\n",
      "Training: Epoch 91, Batch 25, Loss: 0.159\n",
      "Training: Epoch 91, Batch 26, Loss: 0.2\n",
      "Training: Epoch 91, Batch 27, Loss: 0.19\n",
      "Training: Epoch 91, Batch 28, Loss: 0.249\n",
      "Training: Epoch 91, Batch 29, Loss: 0.269\n",
      "Training: Epoch 91, Batch 30, Loss: 0.234\n",
      "Training: Epoch 91, Batch 31, Loss: 0.121\n",
      "Training: Epoch 91, Batch 32, Loss: 0.262\n",
      "Training: Epoch 91, Batch 33, Loss: 0.207\n",
      "Training: Epoch 91, Batch 34, Loss: 0.167\n",
      "Training: Epoch 91, Batch 35, Loss: 0.162\n",
      "Training: Epoch 91, Batch 36, Loss: 0.216\n",
      "Training: Epoch 91, Batch 37, Loss: 0.207\n",
      "Training: Epoch 91, Batch 38, Loss: 0.206\n",
      "Training: Epoch 91, Batch 39, Loss: 0.23\n",
      "Training: Epoch 91, Batch 40, Loss: 0.246\n",
      "Training: Epoch 91, Batch 41, Loss: 0.235\n",
      "Training: Epoch 91, Batch 42, Loss: 0.204\n",
      "Training: Epoch 91, Batch 43, Loss: 0.338\n",
      "Training: Epoch 91, Batch 44, Loss: 0.203\n",
      "Training: Epoch 91, Batch 45, Loss: 0.177\n",
      "Training: Epoch 91, Batch 46, Loss: 0.184\n",
      "Training: Epoch 91, Batch 47, Loss: 0.265\n",
      "Training: Epoch 91, Batch 48, Loss: 0.237\n",
      "Training: Epoch 91, Batch 49, Loss: 0.21\n",
      "Training: Epoch 91, Batch 50, Loss: 0.128\n",
      "Training: Epoch 91, Batch 51, Loss: 0.23\n",
      "Training: Epoch 91, Batch 52, Loss: 0.168\n",
      "Training: Epoch 91, Batch 53, Loss: 0.235\n",
      "Training: Epoch 91, Batch 54, Loss: 0.213\n",
      "Training: Epoch 91, Batch 55, Loss: 0.284\n",
      "Training: Epoch 91, Batch 56, Loss: 0.21\n",
      "Training: Epoch 91, Batch 57, Loss: 0.229\n",
      "Training: Epoch 91, Batch 58, Loss: 0.179\n",
      "Training: Epoch 91, Batch 59, Loss: 0.169\n",
      "Training: Epoch 91, Batch 60, Loss: 0.217\n",
      "Training: Epoch 91, Batch 61, Loss: 0.163\n",
      "Training: Epoch 91, Batch 62, Loss: 0.144\n",
      "Training: Epoch 91, Batch 63, Loss: 0.191\n",
      "Training: Epoch 91, Batch 64, Loss: 0.202\n",
      "Training: Epoch 91, Batch 65, Loss: 0.173\n",
      "Training: Epoch 91, Batch 66, Loss: 0.222\n",
      "Training: Epoch 91, Batch 67, Loss: 0.269\n",
      "Training: Epoch 91, Batch 68, Loss: 0.177\n",
      "Training: Epoch 91, Batch 69, Loss: 0.255\n",
      "Training: Epoch 91, Batch 70, Loss: 0.147\n",
      "Training: Epoch 91, Batch 71, Loss: 0.146\n",
      "Training: Epoch 91, Batch 72, Loss: 0.182\n",
      "Training: Epoch 91, Batch 73, Loss: 0.427\n",
      "Training: Epoch 91, Batch 74, Loss: 0.209\n",
      "Training: Epoch 91, Batch 75, Loss: 0.159\n",
      "Training: Epoch 91, Batch 76, Loss: 0.161\n",
      "Training: Epoch 91, Batch 77, Loss: 0.16\n",
      "Training: Epoch 91, Batch 78, Loss: 0.165\n",
      "Training: Epoch 91, Batch 79, Loss: 0.256\n",
      "Training: Epoch 91, Batch 80, Loss: 0.243\n",
      "Training: Epoch 91, Batch 81, Loss: 0.201\n",
      "Training: Epoch 91, Batch 82, Loss: 0.189\n",
      "Training: Epoch 91, Batch 83, Loss: 0.233\n",
      "Training: Epoch 91, Batch 84, Loss: 0.209\n",
      "Training: Epoch 91, Batch 85, Loss: 0.207\n",
      "Training: Epoch 91, Batch 86, Loss: 0.243\n",
      "Training: Epoch 91, Batch 87, Loss: 0.23\n",
      "Training: Epoch 91, Batch 88, Loss: 0.248\n",
      "Training: Epoch 91, Batch 89, Loss: 0.26\n",
      "Val: Epoch 91, Loss: 0.246\n",
      "Training: Epoch 92, Batch 0, Loss: 0.221\n",
      "Training: Epoch 92, Batch 1, Loss: 0.266\n",
      "Training: Epoch 92, Batch 2, Loss: 0.175\n",
      "Training: Epoch 92, Batch 3, Loss: 0.213\n",
      "Training: Epoch 92, Batch 4, Loss: 0.185\n",
      "Training: Epoch 92, Batch 5, Loss: 0.261\n",
      "Training: Epoch 92, Batch 6, Loss: 0.308\n",
      "Training: Epoch 92, Batch 7, Loss: 0.227\n",
      "Training: Epoch 92, Batch 8, Loss: 0.227\n",
      "Training: Epoch 92, Batch 9, Loss: 0.221\n",
      "Training: Epoch 92, Batch 10, Loss: 0.222\n",
      "Training: Epoch 92, Batch 11, Loss: 0.219\n",
      "Training: Epoch 92, Batch 12, Loss: 0.108\n",
      "Training: Epoch 92, Batch 13, Loss: 0.184\n",
      "Training: Epoch 92, Batch 14, Loss: 0.312\n",
      "Training: Epoch 92, Batch 15, Loss: 0.176\n",
      "Training: Epoch 92, Batch 16, Loss: 0.272\n",
      "Training: Epoch 92, Batch 17, Loss: 0.124\n",
      "Training: Epoch 92, Batch 18, Loss: 0.162\n",
      "Training: Epoch 92, Batch 19, Loss: 0.213\n",
      "Training: Epoch 92, Batch 20, Loss: 0.15\n",
      "Training: Epoch 92, Batch 21, Loss: 0.111\n",
      "Training: Epoch 92, Batch 22, Loss: 0.174\n",
      "Training: Epoch 92, Batch 23, Loss: 0.143\n",
      "Training: Epoch 92, Batch 24, Loss: 0.224\n",
      "Training: Epoch 92, Batch 25, Loss: 0.158\n",
      "Training: Epoch 92, Batch 26, Loss: 0.122\n",
      "Training: Epoch 92, Batch 27, Loss: 0.153\n",
      "Training: Epoch 92, Batch 28, Loss: 0.209\n",
      "Training: Epoch 92, Batch 29, Loss: 0.196\n",
      "Training: Epoch 92, Batch 30, Loss: 0.197\n",
      "Training: Epoch 92, Batch 31, Loss: 0.241\n",
      "Training: Epoch 92, Batch 32, Loss: 0.218\n",
      "Training: Epoch 92, Batch 33, Loss: 0.161\n",
      "Training: Epoch 92, Batch 34, Loss: 0.198\n",
      "Training: Epoch 92, Batch 35, Loss: 0.218\n",
      "Training: Epoch 92, Batch 36, Loss: 0.239\n",
      "Training: Epoch 92, Batch 37, Loss: 0.294\n",
      "Training: Epoch 92, Batch 38, Loss: 0.198\n",
      "Training: Epoch 92, Batch 39, Loss: 0.205\n",
      "Training: Epoch 92, Batch 40, Loss: 0.178\n",
      "Training: Epoch 92, Batch 41, Loss: 0.124\n",
      "Training: Epoch 92, Batch 42, Loss: 0.296\n",
      "Training: Epoch 92, Batch 43, Loss: 0.19\n",
      "Training: Epoch 92, Batch 44, Loss: 0.149\n",
      "Training: Epoch 92, Batch 45, Loss: 0.165\n",
      "Training: Epoch 92, Batch 46, Loss: 0.179\n",
      "Training: Epoch 92, Batch 47, Loss: 0.191\n",
      "Training: Epoch 92, Batch 48, Loss: 0.165\n",
      "Training: Epoch 92, Batch 49, Loss: 0.278\n",
      "Training: Epoch 92, Batch 50, Loss: 0.186\n",
      "Training: Epoch 92, Batch 51, Loss: 0.166\n",
      "Training: Epoch 92, Batch 52, Loss: 0.184\n",
      "Training: Epoch 92, Batch 53, Loss: 0.243\n",
      "Training: Epoch 92, Batch 54, Loss: 0.201\n",
      "Training: Epoch 92, Batch 55, Loss: 0.234\n",
      "Training: Epoch 92, Batch 56, Loss: 0.211\n",
      "Training: Epoch 92, Batch 57, Loss: 0.162\n",
      "Training: Epoch 92, Batch 58, Loss: 0.184\n",
      "Training: Epoch 92, Batch 59, Loss: 0.136\n",
      "Training: Epoch 92, Batch 60, Loss: 0.201\n",
      "Training: Epoch 92, Batch 61, Loss: 0.209\n",
      "Training: Epoch 92, Batch 62, Loss: 0.202\n",
      "Training: Epoch 92, Batch 63, Loss: 0.255\n",
      "Training: Epoch 92, Batch 64, Loss: 0.149\n",
      "Training: Epoch 92, Batch 65, Loss: 0.199\n",
      "Training: Epoch 92, Batch 66, Loss: 0.138\n",
      "Training: Epoch 92, Batch 67, Loss: 0.27\n",
      "Training: Epoch 92, Batch 68, Loss: 0.167\n",
      "Training: Epoch 92, Batch 69, Loss: 0.236\n",
      "Training: Epoch 92, Batch 70, Loss: 0.112\n",
      "Training: Epoch 92, Batch 71, Loss: 0.212\n",
      "Training: Epoch 92, Batch 72, Loss: 0.188\n",
      "Training: Epoch 92, Batch 73, Loss: 0.171\n",
      "Training: Epoch 92, Batch 74, Loss: 0.23\n",
      "Training: Epoch 92, Batch 75, Loss: 0.129\n",
      "Training: Epoch 92, Batch 76, Loss: 0.217\n",
      "Training: Epoch 92, Batch 77, Loss: 0.252\n",
      "Training: Epoch 92, Batch 78, Loss: 0.204\n",
      "Training: Epoch 92, Batch 79, Loss: 0.193\n",
      "Training: Epoch 92, Batch 80, Loss: 0.206\n",
      "Training: Epoch 92, Batch 81, Loss: 0.197\n",
      "Training: Epoch 92, Batch 82, Loss: 0.138\n",
      "Training: Epoch 92, Batch 83, Loss: 0.233\n",
      "Training: Epoch 92, Batch 84, Loss: 0.177\n",
      "Training: Epoch 92, Batch 85, Loss: 0.216\n",
      "Training: Epoch 92, Batch 86, Loss: 0.181\n",
      "Training: Epoch 92, Batch 87, Loss: 0.215\n",
      "Training: Epoch 92, Batch 88, Loss: 0.136\n",
      "Training: Epoch 92, Batch 89, Loss: 0.241\n",
      "Val: Epoch 92, Loss: 0.275\n",
      "Training: Epoch 93, Batch 0, Loss: 0.147\n",
      "Training: Epoch 93, Batch 1, Loss: 0.193\n",
      "Training: Epoch 93, Batch 2, Loss: 0.159\n",
      "Training: Epoch 93, Batch 3, Loss: 0.197\n",
      "Training: Epoch 93, Batch 4, Loss: 0.23\n",
      "Training: Epoch 93, Batch 5, Loss: 0.23\n",
      "Training: Epoch 93, Batch 6, Loss: 0.216\n",
      "Training: Epoch 93, Batch 7, Loss: 0.221\n",
      "Training: Epoch 93, Batch 8, Loss: 0.205\n",
      "Training: Epoch 93, Batch 9, Loss: 0.196\n",
      "Training: Epoch 93, Batch 10, Loss: 0.219\n",
      "Training: Epoch 93, Batch 11, Loss: 0.184\n",
      "Training: Epoch 93, Batch 12, Loss: 0.151\n",
      "Training: Epoch 93, Batch 13, Loss: 0.223\n",
      "Training: Epoch 93, Batch 14, Loss: 0.178\n",
      "Training: Epoch 93, Batch 15, Loss: 0.215\n",
      "Training: Epoch 93, Batch 16, Loss: 0.142\n",
      "Training: Epoch 93, Batch 17, Loss: 0.254\n",
      "Training: Epoch 93, Batch 18, Loss: 0.137\n",
      "Training: Epoch 93, Batch 19, Loss: 0.141\n",
      "Training: Epoch 93, Batch 20, Loss: 0.174\n",
      "Training: Epoch 93, Batch 21, Loss: 0.186\n",
      "Training: Epoch 93, Batch 22, Loss: 0.145\n",
      "Training: Epoch 93, Batch 23, Loss: 0.14\n",
      "Training: Epoch 93, Batch 24, Loss: 0.186\n",
      "Training: Epoch 93, Batch 25, Loss: 0.179\n",
      "Training: Epoch 93, Batch 26, Loss: 0.156\n",
      "Training: Epoch 93, Batch 27, Loss: 0.228\n",
      "Training: Epoch 93, Batch 28, Loss: 0.233\n",
      "Training: Epoch 93, Batch 29, Loss: 0.281\n",
      "Training: Epoch 93, Batch 30, Loss: 0.185\n",
      "Training: Epoch 93, Batch 31, Loss: 0.19\n",
      "Training: Epoch 93, Batch 32, Loss: 0.236\n",
      "Training: Epoch 93, Batch 33, Loss: 0.155\n",
      "Training: Epoch 93, Batch 34, Loss: 0.142\n",
      "Training: Epoch 93, Batch 35, Loss: 0.121\n",
      "Training: Epoch 93, Batch 36, Loss: 0.209\n",
      "Training: Epoch 93, Batch 37, Loss: 0.22\n",
      "Training: Epoch 93, Batch 38, Loss: 0.199\n",
      "Training: Epoch 93, Batch 39, Loss: 0.224\n",
      "Training: Epoch 93, Batch 40, Loss: 0.16\n",
      "Training: Epoch 93, Batch 41, Loss: 0.228\n",
      "Training: Epoch 93, Batch 42, Loss: 0.248\n",
      "Training: Epoch 93, Batch 43, Loss: 0.191\n",
      "Training: Epoch 93, Batch 44, Loss: 0.156\n",
      "Training: Epoch 93, Batch 45, Loss: 0.152\n",
      "Training: Epoch 93, Batch 46, Loss: 0.215\n",
      "Training: Epoch 93, Batch 47, Loss: 0.17\n",
      "Training: Epoch 93, Batch 48, Loss: 0.172\n",
      "Training: Epoch 93, Batch 49, Loss: 0.147\n",
      "Training: Epoch 93, Batch 50, Loss: 0.181\n",
      "Training: Epoch 93, Batch 51, Loss: 0.187\n",
      "Training: Epoch 93, Batch 52, Loss: 0.195\n",
      "Training: Epoch 93, Batch 53, Loss: 0.195\n",
      "Training: Epoch 93, Batch 54, Loss: 0.186\n",
      "Training: Epoch 93, Batch 55, Loss: 0.238\n",
      "Training: Epoch 93, Batch 56, Loss: 0.228\n",
      "Training: Epoch 93, Batch 57, Loss: 0.204\n",
      "Training: Epoch 93, Batch 58, Loss: 0.161\n",
      "Training: Epoch 93, Batch 59, Loss: 0.342\n",
      "Training: Epoch 93, Batch 60, Loss: 0.2\n",
      "Training: Epoch 93, Batch 61, Loss: 0.174\n",
      "Training: Epoch 93, Batch 62, Loss: 0.188\n",
      "Training: Epoch 93, Batch 63, Loss: 0.194\n",
      "Training: Epoch 93, Batch 64, Loss: 0.179\n",
      "Training: Epoch 93, Batch 65, Loss: 0.237\n",
      "Training: Epoch 93, Batch 66, Loss: 0.266\n",
      "Training: Epoch 93, Batch 67, Loss: 0.214\n",
      "Training: Epoch 93, Batch 68, Loss: 0.108\n",
      "Training: Epoch 93, Batch 69, Loss: 0.194\n",
      "Training: Epoch 93, Batch 70, Loss: 0.131\n",
      "Training: Epoch 93, Batch 71, Loss: 0.183\n",
      "Training: Epoch 93, Batch 72, Loss: 0.223\n",
      "Training: Epoch 93, Batch 73, Loss: 0.164\n",
      "Training: Epoch 93, Batch 74, Loss: 0.17\n",
      "Training: Epoch 93, Batch 75, Loss: 0.148\n",
      "Training: Epoch 93, Batch 76, Loss: 0.119\n",
      "Training: Epoch 93, Batch 77, Loss: 0.192\n",
      "Training: Epoch 93, Batch 78, Loss: 0.159\n",
      "Training: Epoch 93, Batch 79, Loss: 0.179\n",
      "Training: Epoch 93, Batch 80, Loss: 0.174\n",
      "Training: Epoch 93, Batch 81, Loss: 0.203\n",
      "Training: Epoch 93, Batch 82, Loss: 0.211\n",
      "Training: Epoch 93, Batch 83, Loss: 0.173\n",
      "Training: Epoch 93, Batch 84, Loss: 0.187\n",
      "Training: Epoch 93, Batch 85, Loss: 0.175\n",
      "Training: Epoch 93, Batch 86, Loss: 0.131\n",
      "Training: Epoch 93, Batch 87, Loss: 0.158\n",
      "Training: Epoch 93, Batch 88, Loss: 0.164\n",
      "Training: Epoch 93, Batch 89, Loss: 0.273\n",
      "Val: Epoch 93, Loss: 0.255\n",
      "Training: Epoch 94, Batch 0, Loss: 0.222\n",
      "Training: Epoch 94, Batch 1, Loss: 0.159\n",
      "Training: Epoch 94, Batch 2, Loss: 0.223\n",
      "Training: Epoch 94, Batch 3, Loss: 0.171\n",
      "Training: Epoch 94, Batch 4, Loss: 0.174\n",
      "Training: Epoch 94, Batch 5, Loss: 0.138\n",
      "Training: Epoch 94, Batch 6, Loss: 0.144\n",
      "Training: Epoch 94, Batch 7, Loss: 0.199\n",
      "Training: Epoch 94, Batch 8, Loss: 0.167\n",
      "Training: Epoch 94, Batch 9, Loss: 0.145\n",
      "Training: Epoch 94, Batch 10, Loss: 0.191\n",
      "Training: Epoch 94, Batch 11, Loss: 0.148\n",
      "Training: Epoch 94, Batch 12, Loss: 0.114\n",
      "Training: Epoch 94, Batch 13, Loss: 0.265\n",
      "Training: Epoch 94, Batch 14, Loss: 0.224\n",
      "Training: Epoch 94, Batch 15, Loss: 0.17\n",
      "Training: Epoch 94, Batch 16, Loss: 0.17\n",
      "Training: Epoch 94, Batch 17, Loss: 0.176\n",
      "Training: Epoch 94, Batch 18, Loss: 0.197\n",
      "Training: Epoch 94, Batch 19, Loss: 0.193\n",
      "Training: Epoch 94, Batch 20, Loss: 0.297\n",
      "Training: Epoch 94, Batch 21, Loss: 0.189\n",
      "Training: Epoch 94, Batch 22, Loss: 0.153\n",
      "Training: Epoch 94, Batch 23, Loss: 0.203\n",
      "Training: Epoch 94, Batch 24, Loss: 0.202\n",
      "Training: Epoch 94, Batch 25, Loss: 0.217\n",
      "Training: Epoch 94, Batch 26, Loss: 0.183\n",
      "Training: Epoch 94, Batch 27, Loss: 0.207\n",
      "Training: Epoch 94, Batch 28, Loss: 0.156\n",
      "Training: Epoch 94, Batch 29, Loss: 0.18\n",
      "Training: Epoch 94, Batch 30, Loss: 0.187\n",
      "Training: Epoch 94, Batch 31, Loss: 0.144\n",
      "Training: Epoch 94, Batch 32, Loss: 0.226\n",
      "Training: Epoch 94, Batch 33, Loss: 0.147\n",
      "Training: Epoch 94, Batch 34, Loss: 0.16\n",
      "Training: Epoch 94, Batch 35, Loss: 0.184\n",
      "Training: Epoch 94, Batch 36, Loss: 0.234\n",
      "Training: Epoch 94, Batch 37, Loss: 0.186\n",
      "Training: Epoch 94, Batch 38, Loss: 0.161\n",
      "Training: Epoch 94, Batch 39, Loss: 0.183\n",
      "Training: Epoch 94, Batch 40, Loss: 0.185\n",
      "Training: Epoch 94, Batch 41, Loss: 0.187\n",
      "Training: Epoch 94, Batch 42, Loss: 0.209\n",
      "Training: Epoch 94, Batch 43, Loss: 0.219\n",
      "Training: Epoch 94, Batch 44, Loss: 0.163\n",
      "Training: Epoch 94, Batch 45, Loss: 0.196\n",
      "Training: Epoch 94, Batch 46, Loss: 0.225\n",
      "Training: Epoch 94, Batch 47, Loss: 0.237\n",
      "Training: Epoch 94, Batch 48, Loss: 0.167\n",
      "Training: Epoch 94, Batch 49, Loss: 0.142\n",
      "Training: Epoch 94, Batch 50, Loss: 0.184\n",
      "Training: Epoch 94, Batch 51, Loss: 0.158\n",
      "Training: Epoch 94, Batch 52, Loss: 0.212\n",
      "Training: Epoch 94, Batch 53, Loss: 0.18\n",
      "Training: Epoch 94, Batch 54, Loss: 0.176\n",
      "Training: Epoch 94, Batch 55, Loss: 0.196\n",
      "Training: Epoch 94, Batch 56, Loss: 0.172\n",
      "Training: Epoch 94, Batch 57, Loss: 0.138\n",
      "Training: Epoch 94, Batch 58, Loss: 0.218\n",
      "Training: Epoch 94, Batch 59, Loss: 0.202\n",
      "Training: Epoch 94, Batch 60, Loss: 0.157\n",
      "Training: Epoch 94, Batch 61, Loss: 0.247\n",
      "Training: Epoch 94, Batch 62, Loss: 0.237\n",
      "Training: Epoch 94, Batch 63, Loss: 0.171\n",
      "Training: Epoch 94, Batch 64, Loss: 0.124\n",
      "Training: Epoch 94, Batch 65, Loss: 0.185\n",
      "Training: Epoch 94, Batch 66, Loss: 0.182\n",
      "Training: Epoch 94, Batch 67, Loss: 0.246\n",
      "Training: Epoch 94, Batch 68, Loss: 0.151\n",
      "Training: Epoch 94, Batch 69, Loss: 0.2\n",
      "Training: Epoch 94, Batch 70, Loss: 0.21\n",
      "Training: Epoch 94, Batch 71, Loss: 0.174\n",
      "Training: Epoch 94, Batch 72, Loss: 0.303\n",
      "Training: Epoch 94, Batch 73, Loss: 0.163\n",
      "Training: Epoch 94, Batch 74, Loss: 0.171\n",
      "Training: Epoch 94, Batch 75, Loss: 0.17\n",
      "Training: Epoch 94, Batch 76, Loss: 0.147\n",
      "Training: Epoch 94, Batch 77, Loss: 0.173\n",
      "Training: Epoch 94, Batch 78, Loss: 0.224\n",
      "Training: Epoch 94, Batch 79, Loss: 0.159\n",
      "Training: Epoch 94, Batch 80, Loss: 0.268\n",
      "Training: Epoch 94, Batch 81, Loss: 0.187\n",
      "Training: Epoch 94, Batch 82, Loss: 0.308\n",
      "Training: Epoch 94, Batch 83, Loss: 0.167\n",
      "Training: Epoch 94, Batch 84, Loss: 0.153\n",
      "Training: Epoch 94, Batch 85, Loss: 0.221\n",
      "Training: Epoch 94, Batch 86, Loss: 0.188\n",
      "Training: Epoch 94, Batch 87, Loss: 0.181\n",
      "Training: Epoch 94, Batch 88, Loss: 0.231\n",
      "Training: Epoch 94, Batch 89, Loss: 0.131\n",
      "Val: Epoch 94, Loss: 0.266\n",
      "Training: Epoch 95, Batch 0, Loss: 0.163\n",
      "Training: Epoch 95, Batch 1, Loss: 0.242\n",
      "Training: Epoch 95, Batch 2, Loss: 0.224\n",
      "Training: Epoch 95, Batch 3, Loss: 0.125\n",
      "Training: Epoch 95, Batch 4, Loss: 0.188\n",
      "Training: Epoch 95, Batch 5, Loss: 0.267\n",
      "Training: Epoch 95, Batch 6, Loss: 0.289\n",
      "Training: Epoch 95, Batch 7, Loss: 0.12\n",
      "Training: Epoch 95, Batch 8, Loss: 0.137\n",
      "Training: Epoch 95, Batch 9, Loss: 0.161\n",
      "Training: Epoch 95, Batch 10, Loss: 0.245\n",
      "Training: Epoch 95, Batch 11, Loss: 0.176\n",
      "Training: Epoch 95, Batch 12, Loss: 0.24\n",
      "Training: Epoch 95, Batch 13, Loss: 0.144\n",
      "Training: Epoch 95, Batch 14, Loss: 0.107\n",
      "Training: Epoch 95, Batch 15, Loss: 0.152\n",
      "Training: Epoch 95, Batch 16, Loss: 0.168\n",
      "Training: Epoch 95, Batch 17, Loss: 0.194\n",
      "Training: Epoch 95, Batch 18, Loss: 0.203\n",
      "Training: Epoch 95, Batch 19, Loss: 0.191\n",
      "Training: Epoch 95, Batch 20, Loss: 0.14\n",
      "Training: Epoch 95, Batch 21, Loss: 0.274\n",
      "Training: Epoch 95, Batch 22, Loss: 0.195\n",
      "Training: Epoch 95, Batch 23, Loss: 0.139\n",
      "Training: Epoch 95, Batch 24, Loss: 0.142\n",
      "Training: Epoch 95, Batch 25, Loss: 0.187\n",
      "Training: Epoch 95, Batch 26, Loss: 0.195\n",
      "Training: Epoch 95, Batch 27, Loss: 0.148\n",
      "Training: Epoch 95, Batch 28, Loss: 0.127\n",
      "Training: Epoch 95, Batch 29, Loss: 0.174\n",
      "Training: Epoch 95, Batch 30, Loss: 0.131\n",
      "Training: Epoch 95, Batch 31, Loss: 0.171\n",
      "Training: Epoch 95, Batch 32, Loss: 0.169\n",
      "Training: Epoch 95, Batch 33, Loss: 0.26\n",
      "Training: Epoch 95, Batch 34, Loss: 0.203\n",
      "Training: Epoch 95, Batch 35, Loss: 0.111\n",
      "Training: Epoch 95, Batch 36, Loss: 0.177\n",
      "Training: Epoch 95, Batch 37, Loss: 0.136\n",
      "Training: Epoch 95, Batch 38, Loss: 0.123\n",
      "Training: Epoch 95, Batch 39, Loss: 0.514\n",
      "Training: Epoch 95, Batch 40, Loss: 0.137\n",
      "Training: Epoch 95, Batch 41, Loss: 0.188\n",
      "Training: Epoch 95, Batch 42, Loss: 0.241\n",
      "Training: Epoch 95, Batch 43, Loss: 0.38\n",
      "Training: Epoch 95, Batch 44, Loss: 0.235\n",
      "Training: Epoch 95, Batch 45, Loss: 0.148\n",
      "Training: Epoch 95, Batch 46, Loss: 0.268\n",
      "Training: Epoch 95, Batch 47, Loss: 0.191\n",
      "Training: Epoch 95, Batch 48, Loss: 0.216\n",
      "Training: Epoch 95, Batch 49, Loss: 0.219\n",
      "Training: Epoch 95, Batch 50, Loss: 0.292\n",
      "Training: Epoch 95, Batch 51, Loss: 0.415\n",
      "Training: Epoch 95, Batch 52, Loss: 0.215\n",
      "Training: Epoch 95, Batch 53, Loss: 0.261\n",
      "Training: Epoch 95, Batch 54, Loss: 0.219\n",
      "Training: Epoch 95, Batch 55, Loss: 0.261\n",
      "Training: Epoch 95, Batch 56, Loss: 0.208\n",
      "Training: Epoch 95, Batch 57, Loss: 0.215\n",
      "Training: Epoch 95, Batch 58, Loss: 0.333\n",
      "Training: Epoch 95, Batch 59, Loss: 0.187\n",
      "Training: Epoch 95, Batch 60, Loss: 0.17\n",
      "Training: Epoch 95, Batch 61, Loss: 0.235\n",
      "Training: Epoch 95, Batch 62, Loss: 0.282\n",
      "Training: Epoch 95, Batch 63, Loss: 0.255\n",
      "Training: Epoch 95, Batch 64, Loss: 0.142\n",
      "Training: Epoch 95, Batch 65, Loss: 0.177\n",
      "Training: Epoch 95, Batch 66, Loss: 0.231\n",
      "Training: Epoch 95, Batch 67, Loss: 0.204\n",
      "Training: Epoch 95, Batch 68, Loss: 0.146\n",
      "Training: Epoch 95, Batch 69, Loss: 0.212\n",
      "Training: Epoch 95, Batch 70, Loss: 0.26\n",
      "Training: Epoch 95, Batch 71, Loss: 0.241\n",
      "Training: Epoch 95, Batch 72, Loss: 0.308\n",
      "Training: Epoch 95, Batch 73, Loss: 0.147\n",
      "Training: Epoch 95, Batch 74, Loss: 0.28\n",
      "Training: Epoch 95, Batch 75, Loss: 0.169\n",
      "Training: Epoch 95, Batch 76, Loss: 0.173\n",
      "Training: Epoch 95, Batch 77, Loss: 0.163\n",
      "Training: Epoch 95, Batch 78, Loss: 0.241\n",
      "Training: Epoch 95, Batch 79, Loss: 0.185\n",
      "Training: Epoch 95, Batch 80, Loss: 0.171\n",
      "Training: Epoch 95, Batch 81, Loss: 0.182\n",
      "Training: Epoch 95, Batch 82, Loss: 0.201\n",
      "Training: Epoch 95, Batch 83, Loss: 0.193\n",
      "Training: Epoch 95, Batch 84, Loss: 0.184\n",
      "Training: Epoch 95, Batch 85, Loss: 0.228\n",
      "Training: Epoch 95, Batch 86, Loss: 0.207\n",
      "Training: Epoch 95, Batch 87, Loss: 0.188\n",
      "Training: Epoch 95, Batch 88, Loss: 0.192\n",
      "Training: Epoch 95, Batch 89, Loss: 0.147\n",
      "Val: Epoch 95, Loss: 0.291\n",
      "Training: Epoch 96, Batch 0, Loss: 0.205\n",
      "Training: Epoch 96, Batch 1, Loss: 0.187\n",
      "Training: Epoch 96, Batch 2, Loss: 0.228\n",
      "Training: Epoch 96, Batch 3, Loss: 0.249\n",
      "Training: Epoch 96, Batch 4, Loss: 0.155\n",
      "Training: Epoch 96, Batch 5, Loss: 0.18\n",
      "Training: Epoch 96, Batch 6, Loss: 0.198\n",
      "Training: Epoch 96, Batch 7, Loss: 0.16\n",
      "Training: Epoch 96, Batch 8, Loss: 0.203\n",
      "Training: Epoch 96, Batch 9, Loss: 0.143\n",
      "Training: Epoch 96, Batch 10, Loss: 0.207\n",
      "Training: Epoch 96, Batch 11, Loss: 0.246\n",
      "Training: Epoch 96, Batch 12, Loss: 0.17\n",
      "Training: Epoch 96, Batch 13, Loss: 0.18\n",
      "Training: Epoch 96, Batch 14, Loss: 0.116\n",
      "Training: Epoch 96, Batch 15, Loss: 0.205\n",
      "Training: Epoch 96, Batch 16, Loss: 0.191\n",
      "Training: Epoch 96, Batch 17, Loss: 0.212\n",
      "Training: Epoch 96, Batch 18, Loss: 0.197\n",
      "Training: Epoch 96, Batch 19, Loss: 0.229\n",
      "Training: Epoch 96, Batch 20, Loss: 0.18\n",
      "Training: Epoch 96, Batch 21, Loss: 0.19\n",
      "Training: Epoch 96, Batch 22, Loss: 0.194\n",
      "Training: Epoch 96, Batch 23, Loss: 0.258\n",
      "Training: Epoch 96, Batch 24, Loss: 0.204\n",
      "Training: Epoch 96, Batch 25, Loss: 0.237\n",
      "Training: Epoch 96, Batch 26, Loss: 0.217\n",
      "Training: Epoch 96, Batch 27, Loss: 0.184\n",
      "Training: Epoch 96, Batch 28, Loss: 0.194\n",
      "Training: Epoch 96, Batch 29, Loss: 0.262\n",
      "Training: Epoch 96, Batch 30, Loss: 0.163\n",
      "Training: Epoch 96, Batch 31, Loss: 0.247\n",
      "Training: Epoch 96, Batch 32, Loss: 0.172\n",
      "Training: Epoch 96, Batch 33, Loss: 0.136\n",
      "Training: Epoch 96, Batch 34, Loss: 0.182\n",
      "Training: Epoch 96, Batch 35, Loss: 0.167\n",
      "Training: Epoch 96, Batch 36, Loss: 0.159\n",
      "Training: Epoch 96, Batch 37, Loss: 0.195\n",
      "Training: Epoch 96, Batch 38, Loss: 0.206\n",
      "Training: Epoch 96, Batch 39, Loss: 0.216\n",
      "Training: Epoch 96, Batch 40, Loss: 0.13\n",
      "Training: Epoch 96, Batch 41, Loss: 0.132\n",
      "Training: Epoch 96, Batch 42, Loss: 0.204\n",
      "Training: Epoch 96, Batch 43, Loss: 0.178\n",
      "Training: Epoch 96, Batch 44, Loss: 0.177\n",
      "Training: Epoch 96, Batch 45, Loss: 0.151\n",
      "Training: Epoch 96, Batch 46, Loss: 0.193\n",
      "Training: Epoch 96, Batch 47, Loss: 0.178\n",
      "Training: Epoch 96, Batch 48, Loss: 0.143\n",
      "Training: Epoch 96, Batch 49, Loss: 0.211\n",
      "Training: Epoch 96, Batch 50, Loss: 0.189\n",
      "Training: Epoch 96, Batch 51, Loss: 0.201\n",
      "Training: Epoch 96, Batch 52, Loss: 0.235\n",
      "Training: Epoch 96, Batch 53, Loss: 0.196\n",
      "Training: Epoch 96, Batch 54, Loss: 0.194\n",
      "Training: Epoch 96, Batch 55, Loss: 0.18\n",
      "Training: Epoch 96, Batch 56, Loss: 0.281\n",
      "Training: Epoch 96, Batch 57, Loss: 0.201\n",
      "Training: Epoch 96, Batch 58, Loss: 0.23\n",
      "Training: Epoch 96, Batch 59, Loss: 0.178\n",
      "Training: Epoch 96, Batch 60, Loss: 0.254\n",
      "Training: Epoch 96, Batch 61, Loss: 0.192\n",
      "Training: Epoch 96, Batch 62, Loss: 0.23\n",
      "Training: Epoch 96, Batch 63, Loss: 0.212\n",
      "Training: Epoch 96, Batch 64, Loss: 0.128\n",
      "Training: Epoch 96, Batch 65, Loss: 0.204\n",
      "Training: Epoch 96, Batch 66, Loss: 0.185\n",
      "Training: Epoch 96, Batch 67, Loss: 0.173\n",
      "Training: Epoch 96, Batch 68, Loss: 0.154\n",
      "Training: Epoch 96, Batch 69, Loss: 0.167\n",
      "Training: Epoch 96, Batch 70, Loss: 0.153\n",
      "Training: Epoch 96, Batch 71, Loss: 0.254\n",
      "Training: Epoch 96, Batch 72, Loss: 0.249\n",
      "Training: Epoch 96, Batch 73, Loss: 0.195\n",
      "Training: Epoch 96, Batch 74, Loss: 0.164\n",
      "Training: Epoch 96, Batch 75, Loss: 0.139\n",
      "Training: Epoch 96, Batch 76, Loss: 0.158\n",
      "Training: Epoch 96, Batch 77, Loss: 0.141\n",
      "Training: Epoch 96, Batch 78, Loss: 0.134\n",
      "Training: Epoch 96, Batch 79, Loss: 0.204\n",
      "Training: Epoch 96, Batch 80, Loss: 0.154\n",
      "Training: Epoch 96, Batch 81, Loss: 0.216\n",
      "Training: Epoch 96, Batch 82, Loss: 0.165\n",
      "Training: Epoch 96, Batch 83, Loss: 0.132\n",
      "Training: Epoch 96, Batch 84, Loss: 0.225\n",
      "Training: Epoch 96, Batch 85, Loss: 0.221\n",
      "Training: Epoch 96, Batch 86, Loss: 0.239\n",
      "Training: Epoch 96, Batch 87, Loss: 0.236\n",
      "Training: Epoch 96, Batch 88, Loss: 0.183\n",
      "Training: Epoch 96, Batch 89, Loss: 0.153\n",
      "Val: Epoch 96, Loss: 0.284\n",
      "Training: Epoch 97, Batch 0, Loss: 0.197\n",
      "Training: Epoch 97, Batch 1, Loss: 0.211\n",
      "Training: Epoch 97, Batch 2, Loss: 0.214\n",
      "Training: Epoch 97, Batch 3, Loss: 0.132\n",
      "Training: Epoch 97, Batch 4, Loss: 0.28\n",
      "Training: Epoch 97, Batch 5, Loss: 0.204\n",
      "Training: Epoch 97, Batch 6, Loss: 0.148\n",
      "Training: Epoch 97, Batch 7, Loss: 0.111\n",
      "Training: Epoch 97, Batch 8, Loss: 0.194\n",
      "Training: Epoch 97, Batch 9, Loss: 0.156\n",
      "Training: Epoch 97, Batch 10, Loss: 0.195\n",
      "Training: Epoch 97, Batch 11, Loss: 0.156\n",
      "Training: Epoch 97, Batch 12, Loss: 0.256\n",
      "Training: Epoch 97, Batch 13, Loss: 0.154\n",
      "Training: Epoch 97, Batch 14, Loss: 0.162\n",
      "Training: Epoch 97, Batch 15, Loss: 0.197\n",
      "Training: Epoch 97, Batch 16, Loss: 0.158\n",
      "Training: Epoch 97, Batch 17, Loss: 0.163\n",
      "Training: Epoch 97, Batch 18, Loss: 0.136\n",
      "Training: Epoch 97, Batch 19, Loss: 0.167\n",
      "Training: Epoch 97, Batch 20, Loss: 0.196\n",
      "Training: Epoch 97, Batch 21, Loss: 0.144\n",
      "Training: Epoch 97, Batch 22, Loss: 0.268\n",
      "Training: Epoch 97, Batch 23, Loss: 0.183\n",
      "Training: Epoch 97, Batch 24, Loss: 0.198\n",
      "Training: Epoch 97, Batch 25, Loss: 0.166\n",
      "Training: Epoch 97, Batch 26, Loss: 0.133\n",
      "Training: Epoch 97, Batch 27, Loss: 0.177\n",
      "Training: Epoch 97, Batch 28, Loss: 0.158\n",
      "Training: Epoch 97, Batch 29, Loss: 0.19\n",
      "Training: Epoch 97, Batch 30, Loss: 0.211\n",
      "Training: Epoch 97, Batch 31, Loss: 0.208\n",
      "Training: Epoch 97, Batch 32, Loss: 0.205\n",
      "Training: Epoch 97, Batch 33, Loss: 0.171\n",
      "Training: Epoch 97, Batch 34, Loss: 0.168\n",
      "Training: Epoch 97, Batch 35, Loss: 0.179\n",
      "Training: Epoch 97, Batch 36, Loss: 0.215\n",
      "Training: Epoch 97, Batch 37, Loss: 0.176\n",
      "Training: Epoch 97, Batch 38, Loss: 0.17\n",
      "Training: Epoch 97, Batch 39, Loss: 0.158\n",
      "Training: Epoch 97, Batch 40, Loss: 0.18\n",
      "Training: Epoch 97, Batch 41, Loss: 0.212\n",
      "Training: Epoch 97, Batch 42, Loss: 0.231\n",
      "Training: Epoch 97, Batch 43, Loss: 0.186\n",
      "Training: Epoch 97, Batch 44, Loss: 0.145\n",
      "Training: Epoch 97, Batch 45, Loss: 0.19\n",
      "Training: Epoch 97, Batch 46, Loss: 0.167\n",
      "Training: Epoch 97, Batch 47, Loss: 0.17\n",
      "Training: Epoch 97, Batch 48, Loss: 0.166\n",
      "Training: Epoch 97, Batch 49, Loss: 0.206\n",
      "Training: Epoch 97, Batch 50, Loss: 0.17\n",
      "Training: Epoch 97, Batch 51, Loss: 0.152\n",
      "Training: Epoch 97, Batch 52, Loss: 0.192\n",
      "Training: Epoch 97, Batch 53, Loss: 0.158\n",
      "Training: Epoch 97, Batch 54, Loss: 0.14\n",
      "Training: Epoch 97, Batch 55, Loss: 0.178\n",
      "Training: Epoch 97, Batch 56, Loss: 0.135\n",
      "Training: Epoch 97, Batch 57, Loss: 0.128\n",
      "Training: Epoch 97, Batch 58, Loss: 0.172\n",
      "Training: Epoch 97, Batch 59, Loss: 0.209\n",
      "Training: Epoch 97, Batch 60, Loss: 0.133\n",
      "Training: Epoch 97, Batch 61, Loss: 0.141\n",
      "Training: Epoch 97, Batch 62, Loss: 0.144\n",
      "Training: Epoch 97, Batch 63, Loss: 0.195\n",
      "Training: Epoch 97, Batch 64, Loss: 0.279\n",
      "Training: Epoch 97, Batch 65, Loss: 0.226\n",
      "Training: Epoch 97, Batch 66, Loss: 0.165\n",
      "Training: Epoch 97, Batch 67, Loss: 0.167\n",
      "Training: Epoch 97, Batch 68, Loss: 0.251\n",
      "Training: Epoch 97, Batch 69, Loss: 0.187\n",
      "Training: Epoch 97, Batch 70, Loss: 0.135\n",
      "Training: Epoch 97, Batch 71, Loss: 0.203\n",
      "Training: Epoch 97, Batch 72, Loss: 0.183\n",
      "Training: Epoch 97, Batch 73, Loss: 0.128\n",
      "Training: Epoch 97, Batch 74, Loss: 0.211\n",
      "Training: Epoch 97, Batch 75, Loss: 0.129\n",
      "Training: Epoch 97, Batch 76, Loss: 0.179\n",
      "Training: Epoch 97, Batch 77, Loss: 0.119\n",
      "Training: Epoch 97, Batch 78, Loss: 0.252\n",
      "Training: Epoch 97, Batch 79, Loss: 0.212\n",
      "Training: Epoch 97, Batch 80, Loss: 0.18\n",
      "Training: Epoch 97, Batch 81, Loss: 0.187\n",
      "Training: Epoch 97, Batch 82, Loss: 0.205\n",
      "Training: Epoch 97, Batch 83, Loss: 0.188\n",
      "Training: Epoch 97, Batch 84, Loss: 0.143\n",
      "Training: Epoch 97, Batch 85, Loss: 0.241\n",
      "Training: Epoch 97, Batch 86, Loss: 0.125\n",
      "Training: Epoch 97, Batch 87, Loss: 0.207\n",
      "Training: Epoch 97, Batch 88, Loss: 0.252\n",
      "Training: Epoch 97, Batch 89, Loss: 0.23\n",
      "Val: Epoch 97, Loss: 0.303\n",
      "Training: Epoch 98, Batch 0, Loss: 0.185\n",
      "Training: Epoch 98, Batch 1, Loss: 0.121\n",
      "Training: Epoch 98, Batch 2, Loss: 0.138\n",
      "Training: Epoch 98, Batch 3, Loss: 0.128\n",
      "Training: Epoch 98, Batch 4, Loss: 0.185\n",
      "Training: Epoch 98, Batch 5, Loss: 0.19\n",
      "Training: Epoch 98, Batch 6, Loss: 0.209\n",
      "Training: Epoch 98, Batch 7, Loss: 0.138\n",
      "Training: Epoch 98, Batch 8, Loss: 0.204\n",
      "Training: Epoch 98, Batch 9, Loss: 0.111\n",
      "Training: Epoch 98, Batch 10, Loss: 0.132\n",
      "Training: Epoch 98, Batch 11, Loss: 0.186\n",
      "Training: Epoch 98, Batch 12, Loss: 0.208\n",
      "Training: Epoch 98, Batch 13, Loss: 0.143\n",
      "Training: Epoch 98, Batch 14, Loss: 0.195\n",
      "Training: Epoch 98, Batch 15, Loss: 0.2\n",
      "Training: Epoch 98, Batch 16, Loss: 0.186\n",
      "Training: Epoch 98, Batch 17, Loss: 0.181\n",
      "Training: Epoch 98, Batch 18, Loss: 0.165\n",
      "Training: Epoch 98, Batch 19, Loss: 0.147\n",
      "Training: Epoch 98, Batch 20, Loss: 0.219\n",
      "Training: Epoch 98, Batch 21, Loss: 0.181\n",
      "Training: Epoch 98, Batch 22, Loss: 0.16\n",
      "Training: Epoch 98, Batch 23, Loss: 0.163\n",
      "Training: Epoch 98, Batch 24, Loss: 0.165\n",
      "Training: Epoch 98, Batch 25, Loss: 0.169\n",
      "Training: Epoch 98, Batch 26, Loss: 0.21\n",
      "Training: Epoch 98, Batch 27, Loss: 0.16\n",
      "Training: Epoch 98, Batch 28, Loss: 0.232\n",
      "Training: Epoch 98, Batch 29, Loss: 0.121\n",
      "Training: Epoch 98, Batch 30, Loss: 0.168\n",
      "Training: Epoch 98, Batch 31, Loss: 0.128\n",
      "Training: Epoch 98, Batch 32, Loss: 0.168\n",
      "Training: Epoch 98, Batch 33, Loss: 0.164\n",
      "Training: Epoch 98, Batch 34, Loss: 0.153\n",
      "Training: Epoch 98, Batch 35, Loss: 0.185\n",
      "Training: Epoch 98, Batch 36, Loss: 0.144\n",
      "Training: Epoch 98, Batch 37, Loss: 0.134\n",
      "Training: Epoch 98, Batch 38, Loss: 0.166\n",
      "Training: Epoch 98, Batch 39, Loss: 0.181\n",
      "Training: Epoch 98, Batch 40, Loss: 0.183\n",
      "Training: Epoch 98, Batch 41, Loss: 0.219\n",
      "Training: Epoch 98, Batch 42, Loss: 0.25\n",
      "Training: Epoch 98, Batch 43, Loss: 0.198\n",
      "Training: Epoch 98, Batch 44, Loss: 0.16\n",
      "Training: Epoch 98, Batch 45, Loss: 0.187\n",
      "Training: Epoch 98, Batch 46, Loss: 0.165\n",
      "Training: Epoch 98, Batch 47, Loss: 0.137\n",
      "Training: Epoch 98, Batch 48, Loss: 0.147\n",
      "Training: Epoch 98, Batch 49, Loss: 0.2\n",
      "Training: Epoch 98, Batch 50, Loss: 0.207\n",
      "Training: Epoch 98, Batch 51, Loss: 0.185\n",
      "Training: Epoch 98, Batch 52, Loss: 0.167\n",
      "Training: Epoch 98, Batch 53, Loss: 0.182\n",
      "Training: Epoch 98, Batch 54, Loss: 0.213\n",
      "Training: Epoch 98, Batch 55, Loss: 0.119\n",
      "Training: Epoch 98, Batch 56, Loss: 0.129\n",
      "Training: Epoch 98, Batch 57, Loss: 0.141\n",
      "Training: Epoch 98, Batch 58, Loss: 0.161\n",
      "Training: Epoch 98, Batch 59, Loss: 0.15\n",
      "Training: Epoch 98, Batch 60, Loss: 0.212\n",
      "Training: Epoch 98, Batch 61, Loss: 0.194\n",
      "Training: Epoch 98, Batch 62, Loss: 0.19\n",
      "Training: Epoch 98, Batch 63, Loss: 0.219\n",
      "Training: Epoch 98, Batch 64, Loss: 0.159\n",
      "Training: Epoch 98, Batch 65, Loss: 0.147\n",
      "Training: Epoch 98, Batch 66, Loss: 0.159\n",
      "Training: Epoch 98, Batch 67, Loss: 0.189\n",
      "Training: Epoch 98, Batch 68, Loss: 0.249\n",
      "Training: Epoch 98, Batch 69, Loss: 0.188\n",
      "Training: Epoch 98, Batch 70, Loss: 0.22\n",
      "Training: Epoch 98, Batch 71, Loss: 0.237\n",
      "Training: Epoch 98, Batch 72, Loss: 0.212\n",
      "Training: Epoch 98, Batch 73, Loss: 0.202\n",
      "Training: Epoch 98, Batch 74, Loss: 0.173\n",
      "Training: Epoch 98, Batch 75, Loss: 0.205\n",
      "Training: Epoch 98, Batch 76, Loss: 0.175\n",
      "Training: Epoch 98, Batch 77, Loss: 0.191\n",
      "Training: Epoch 98, Batch 78, Loss: 0.141\n",
      "Training: Epoch 98, Batch 79, Loss: 0.171\n",
      "Training: Epoch 98, Batch 80, Loss: 0.194\n",
      "Training: Epoch 98, Batch 81, Loss: 0.166\n",
      "Training: Epoch 98, Batch 82, Loss: 0.203\n",
      "Training: Epoch 98, Batch 83, Loss: 0.223\n",
      "Training: Epoch 98, Batch 84, Loss: 0.149\n",
      "Training: Epoch 98, Batch 85, Loss: 0.136\n",
      "Training: Epoch 98, Batch 86, Loss: 0.132\n",
      "Training: Epoch 98, Batch 87, Loss: 0.252\n",
      "Training: Epoch 98, Batch 88, Loss: 0.182\n",
      "Training: Epoch 98, Batch 89, Loss: 0.143\n",
      "Val: Epoch 98, Loss: 0.292\n",
      "Training: Epoch 99, Batch 0, Loss: 0.211\n",
      "Training: Epoch 99, Batch 1, Loss: 0.248\n",
      "Training: Epoch 99, Batch 2, Loss: 0.158\n",
      "Training: Epoch 99, Batch 3, Loss: 0.163\n",
      "Training: Epoch 99, Batch 4, Loss: 0.132\n",
      "Training: Epoch 99, Batch 5, Loss: 0.17\n",
      "Training: Epoch 99, Batch 6, Loss: 0.151\n",
      "Training: Epoch 99, Batch 7, Loss: 0.126\n",
      "Training: Epoch 99, Batch 8, Loss: 0.182\n",
      "Training: Epoch 99, Batch 9, Loss: 0.127\n",
      "Training: Epoch 99, Batch 10, Loss: 0.143\n",
      "Training: Epoch 99, Batch 11, Loss: 0.183\n",
      "Training: Epoch 99, Batch 12, Loss: 0.128\n",
      "Training: Epoch 99, Batch 13, Loss: 0.182\n",
      "Training: Epoch 99, Batch 14, Loss: 0.182\n",
      "Training: Epoch 99, Batch 15, Loss: 0.152\n",
      "Training: Epoch 99, Batch 16, Loss: 0.234\n",
      "Training: Epoch 99, Batch 17, Loss: 0.192\n",
      "Training: Epoch 99, Batch 18, Loss: 0.165\n",
      "Training: Epoch 99, Batch 19, Loss: 0.169\n",
      "Training: Epoch 99, Batch 20, Loss: 0.18\n",
      "Training: Epoch 99, Batch 21, Loss: 0.131\n",
      "Training: Epoch 99, Batch 22, Loss: 0.186\n",
      "Training: Epoch 99, Batch 23, Loss: 0.171\n",
      "Training: Epoch 99, Batch 24, Loss: 0.158\n",
      "Training: Epoch 99, Batch 25, Loss: 0.234\n",
      "Training: Epoch 99, Batch 26, Loss: 0.208\n",
      "Training: Epoch 99, Batch 27, Loss: 0.214\n",
      "Training: Epoch 99, Batch 28, Loss: 0.162\n",
      "Training: Epoch 99, Batch 29, Loss: 0.214\n",
      "Training: Epoch 99, Batch 30, Loss: 0.274\n",
      "Training: Epoch 99, Batch 31, Loss: 0.162\n",
      "Training: Epoch 99, Batch 32, Loss: 0.166\n",
      "Training: Epoch 99, Batch 33, Loss: 0.185\n",
      "Training: Epoch 99, Batch 34, Loss: 0.183\n",
      "Training: Epoch 99, Batch 35, Loss: 0.178\n",
      "Training: Epoch 99, Batch 36, Loss: 0.189\n",
      "Training: Epoch 99, Batch 37, Loss: 0.148\n",
      "Training: Epoch 99, Batch 38, Loss: 0.241\n",
      "Training: Epoch 99, Batch 39, Loss: 0.15\n",
      "Training: Epoch 99, Batch 40, Loss: 0.172\n",
      "Training: Epoch 99, Batch 41, Loss: 0.136\n",
      "Training: Epoch 99, Batch 42, Loss: 0.154\n",
      "Training: Epoch 99, Batch 43, Loss: 0.21\n",
      "Training: Epoch 99, Batch 44, Loss: 0.131\n",
      "Training: Epoch 99, Batch 45, Loss: 0.196\n",
      "Training: Epoch 99, Batch 46, Loss: 0.196\n",
      "Training: Epoch 99, Batch 47, Loss: 0.191\n",
      "Training: Epoch 99, Batch 48, Loss: 0.178\n",
      "Training: Epoch 99, Batch 49, Loss: 0.114\n",
      "Training: Epoch 99, Batch 50, Loss: 0.144\n",
      "Training: Epoch 99, Batch 51, Loss: 0.14\n",
      "Training: Epoch 99, Batch 52, Loss: 0.218\n",
      "Training: Epoch 99, Batch 53, Loss: 0.114\n",
      "Training: Epoch 99, Batch 54, Loss: 0.127\n",
      "Training: Epoch 99, Batch 55, Loss: 0.149\n",
      "Training: Epoch 99, Batch 56, Loss: 0.202\n",
      "Training: Epoch 99, Batch 57, Loss: 0.173\n",
      "Training: Epoch 99, Batch 58, Loss: 0.156\n",
      "Training: Epoch 99, Batch 59, Loss: 0.166\n",
      "Training: Epoch 99, Batch 60, Loss: 0.163\n",
      "Training: Epoch 99, Batch 61, Loss: 0.141\n",
      "Training: Epoch 99, Batch 62, Loss: 0.215\n",
      "Training: Epoch 99, Batch 63, Loss: 0.162\n",
      "Training: Epoch 99, Batch 64, Loss: 0.136\n",
      "Training: Epoch 99, Batch 65, Loss: 0.201\n",
      "Training: Epoch 99, Batch 66, Loss: 0.14\n",
      "Training: Epoch 99, Batch 67, Loss: 0.223\n",
      "Training: Epoch 99, Batch 68, Loss: 0.172\n",
      "Training: Epoch 99, Batch 69, Loss: 0.163\n",
      "Training: Epoch 99, Batch 70, Loss: 0.241\n",
      "Training: Epoch 99, Batch 71, Loss: 0.243\n",
      "Training: Epoch 99, Batch 72, Loss: 0.221\n",
      "Training: Epoch 99, Batch 73, Loss: 0.139\n",
      "Training: Epoch 99, Batch 74, Loss: 0.172\n",
      "Training: Epoch 99, Batch 75, Loss: 0.212\n",
      "Training: Epoch 99, Batch 76, Loss: 0.193\n",
      "Training: Epoch 99, Batch 77, Loss: 0.201\n",
      "Training: Epoch 99, Batch 78, Loss: 0.221\n",
      "Training: Epoch 99, Batch 79, Loss: 0.227\n",
      "Training: Epoch 99, Batch 80, Loss: 0.153\n",
      "Training: Epoch 99, Batch 81, Loss: 0.114\n",
      "Training: Epoch 99, Batch 82, Loss: 0.139\n",
      "Training: Epoch 99, Batch 83, Loss: 0.158\n",
      "Training: Epoch 99, Batch 84, Loss: 0.138\n",
      "Training: Epoch 99, Batch 85, Loss: 0.176\n",
      "Training: Epoch 99, Batch 86, Loss: 0.142\n",
      "Training: Epoch 99, Batch 87, Loss: 0.17\n",
      "Training: Epoch 99, Batch 88, Loss: 0.175\n",
      "Training: Epoch 99, Batch 89, Loss: 0.169\n",
      "Val: Epoch 99, Loss: 0.292\n",
      "Training: Epoch 100, Batch 0, Loss: 0.186\n",
      "Training: Epoch 100, Batch 1, Loss: 0.262\n",
      "Training: Epoch 100, Batch 2, Loss: 0.14\n",
      "Training: Epoch 100, Batch 3, Loss: 0.15\n",
      "Training: Epoch 100, Batch 4, Loss: 0.189\n",
      "Training: Epoch 100, Batch 5, Loss: 0.198\n",
      "Training: Epoch 100, Batch 6, Loss: 0.178\n",
      "Training: Epoch 100, Batch 7, Loss: 0.121\n",
      "Training: Epoch 100, Batch 8, Loss: 0.143\n",
      "Training: Epoch 100, Batch 9, Loss: 0.127\n",
      "Training: Epoch 100, Batch 10, Loss: 0.105\n",
      "Training: Epoch 100, Batch 11, Loss: 0.184\n",
      "Training: Epoch 100, Batch 12, Loss: 0.26\n",
      "Training: Epoch 100, Batch 13, Loss: 0.156\n",
      "Training: Epoch 100, Batch 14, Loss: 0.15\n",
      "Training: Epoch 100, Batch 15, Loss: 0.192\n",
      "Training: Epoch 100, Batch 16, Loss: 0.158\n",
      "Training: Epoch 100, Batch 17, Loss: 0.165\n",
      "Training: Epoch 100, Batch 18, Loss: 0.213\n",
      "Training: Epoch 100, Batch 19, Loss: 0.225\n",
      "Training: Epoch 100, Batch 20, Loss: 0.148\n",
      "Training: Epoch 100, Batch 21, Loss: 0.295\n",
      "Training: Epoch 100, Batch 22, Loss: 0.143\n",
      "Training: Epoch 100, Batch 23, Loss: 0.209\n",
      "Training: Epoch 100, Batch 24, Loss: 0.154\n",
      "Training: Epoch 100, Batch 25, Loss: 0.196\n",
      "Training: Epoch 100, Batch 26, Loss: 0.14\n",
      "Training: Epoch 100, Batch 27, Loss: 0.177\n",
      "Training: Epoch 100, Batch 28, Loss: 0.228\n",
      "Training: Epoch 100, Batch 29, Loss: 0.153\n",
      "Training: Epoch 100, Batch 30, Loss: 0.244\n",
      "Training: Epoch 100, Batch 31, Loss: 0.133\n",
      "Training: Epoch 100, Batch 32, Loss: 0.146\n",
      "Training: Epoch 100, Batch 33, Loss: 0.168\n",
      "Training: Epoch 100, Batch 34, Loss: 0.134\n",
      "Training: Epoch 100, Batch 35, Loss: 0.123\n",
      "Training: Epoch 100, Batch 36, Loss: 0.197\n",
      "Training: Epoch 100, Batch 37, Loss: 0.164\n",
      "Training: Epoch 100, Batch 38, Loss: 0.131\n",
      "Training: Epoch 100, Batch 39, Loss: 0.233\n",
      "Training: Epoch 100, Batch 40, Loss: 0.168\n",
      "Training: Epoch 100, Batch 41, Loss: 0.205\n",
      "Training: Epoch 100, Batch 42, Loss: 0.181\n",
      "Training: Epoch 100, Batch 43, Loss: 0.177\n",
      "Training: Epoch 100, Batch 44, Loss: 0.14\n",
      "Training: Epoch 100, Batch 45, Loss: 0.207\n",
      "Training: Epoch 100, Batch 46, Loss: 0.139\n",
      "Training: Epoch 100, Batch 47, Loss: 0.209\n",
      "Training: Epoch 100, Batch 48, Loss: 0.239\n",
      "Training: Epoch 100, Batch 49, Loss: 0.163\n",
      "Training: Epoch 100, Batch 50, Loss: 0.145\n",
      "Training: Epoch 100, Batch 51, Loss: 0.164\n",
      "Training: Epoch 100, Batch 52, Loss: 0.187\n",
      "Training: Epoch 100, Batch 53, Loss: 0.149\n",
      "Training: Epoch 100, Batch 54, Loss: 0.234\n",
      "Training: Epoch 100, Batch 55, Loss: 0.155\n",
      "Training: Epoch 100, Batch 56, Loss: 0.209\n",
      "Training: Epoch 100, Batch 57, Loss: 0.193\n",
      "Training: Epoch 100, Batch 58, Loss: 0.194\n",
      "Training: Epoch 100, Batch 59, Loss: 0.148\n",
      "Training: Epoch 100, Batch 60, Loss: 0.217\n",
      "Training: Epoch 100, Batch 61, Loss: 0.252\n",
      "Training: Epoch 100, Batch 62, Loss: 0.165\n",
      "Training: Epoch 100, Batch 63, Loss: 0.214\n",
      "Training: Epoch 100, Batch 64, Loss: 0.125\n",
      "Training: Epoch 100, Batch 65, Loss: 0.126\n",
      "Training: Epoch 100, Batch 66, Loss: 0.153\n",
      "Training: Epoch 100, Batch 67, Loss: 0.177\n",
      "Training: Epoch 100, Batch 68, Loss: 0.172\n",
      "Training: Epoch 100, Batch 69, Loss: 0.192\n",
      "Training: Epoch 100, Batch 70, Loss: 0.173\n",
      "Training: Epoch 100, Batch 71, Loss: 0.209\n",
      "Training: Epoch 100, Batch 72, Loss: 0.157\n",
      "Training: Epoch 100, Batch 73, Loss: 0.147\n",
      "Training: Epoch 100, Batch 74, Loss: 0.186\n",
      "Training: Epoch 100, Batch 75, Loss: 0.159\n",
      "Training: Epoch 100, Batch 76, Loss: 0.285\n",
      "Training: Epoch 100, Batch 77, Loss: 0.199\n",
      "Training: Epoch 100, Batch 78, Loss: 0.182\n",
      "Training: Epoch 100, Batch 79, Loss: 0.194\n",
      "Training: Epoch 100, Batch 80, Loss: 0.226\n",
      "Training: Epoch 100, Batch 81, Loss: 0.208\n",
      "Training: Epoch 100, Batch 82, Loss: 0.229\n",
      "Training: Epoch 100, Batch 83, Loss: 0.164\n",
      "Training: Epoch 100, Batch 84, Loss: 0.218\n",
      "Training: Epoch 100, Batch 85, Loss: 0.202\n",
      "Training: Epoch 100, Batch 86, Loss: 0.264\n",
      "Training: Epoch 100, Batch 87, Loss: 0.224\n",
      "Training: Epoch 100, Batch 88, Loss: 0.185\n",
      "Training: Epoch 100, Batch 89, Loss: 0.155\n",
      "Val: Epoch 100, Loss: 0.301\n",
      "Training: Epoch 101, Batch 0, Loss: 0.124\n",
      "Training: Epoch 101, Batch 1, Loss: 0.153\n",
      "Training: Epoch 101, Batch 2, Loss: 0.228\n",
      "Training: Epoch 101, Batch 3, Loss: 0.165\n",
      "Training: Epoch 101, Batch 4, Loss: 0.184\n",
      "Training: Epoch 101, Batch 5, Loss: 0.181\n",
      "Training: Epoch 101, Batch 6, Loss: 0.215\n",
      "Training: Epoch 101, Batch 7, Loss: 0.157\n",
      "Training: Epoch 101, Batch 8, Loss: 0.204\n",
      "Training: Epoch 101, Batch 9, Loss: 0.182\n",
      "Training: Epoch 101, Batch 10, Loss: 0.168\n",
      "Training: Epoch 101, Batch 11, Loss: 0.202\n",
      "Training: Epoch 101, Batch 12, Loss: 0.16\n",
      "Training: Epoch 101, Batch 13, Loss: 0.143\n",
      "Training: Epoch 101, Batch 14, Loss: 0.206\n",
      "Training: Epoch 101, Batch 15, Loss: 0.213\n",
      "Training: Epoch 101, Batch 16, Loss: 0.175\n",
      "Training: Epoch 101, Batch 17, Loss: 0.099\n",
      "Training: Epoch 101, Batch 18, Loss: 0.178\n",
      "Training: Epoch 101, Batch 19, Loss: 0.144\n",
      "Training: Epoch 101, Batch 20, Loss: 0.174\n",
      "Training: Epoch 101, Batch 21, Loss: 0.232\n",
      "Training: Epoch 101, Batch 22, Loss: 0.119\n",
      "Training: Epoch 101, Batch 23, Loss: 0.193\n",
      "Training: Epoch 101, Batch 24, Loss: 0.136\n",
      "Training: Epoch 101, Batch 25, Loss: 0.194\n",
      "Training: Epoch 101, Batch 26, Loss: 0.152\n",
      "Training: Epoch 101, Batch 27, Loss: 0.158\n",
      "Training: Epoch 101, Batch 28, Loss: 0.159\n",
      "Training: Epoch 101, Batch 29, Loss: 0.155\n",
      "Training: Epoch 101, Batch 30, Loss: 0.157\n",
      "Training: Epoch 101, Batch 31, Loss: 0.156\n",
      "Training: Epoch 101, Batch 32, Loss: 0.183\n",
      "Training: Epoch 101, Batch 33, Loss: 0.257\n",
      "Training: Epoch 101, Batch 34, Loss: 0.156\n",
      "Training: Epoch 101, Batch 35, Loss: 0.157\n",
      "Training: Epoch 101, Batch 36, Loss: 0.163\n",
      "Training: Epoch 101, Batch 37, Loss: 0.131\n",
      "Training: Epoch 101, Batch 38, Loss: 0.155\n",
      "Training: Epoch 101, Batch 39, Loss: 0.125\n",
      "Training: Epoch 101, Batch 40, Loss: 0.232\n",
      "Training: Epoch 101, Batch 41, Loss: 0.239\n",
      "Training: Epoch 101, Batch 42, Loss: 0.156\n",
      "Training: Epoch 101, Batch 43, Loss: 0.189\n",
      "Training: Epoch 101, Batch 44, Loss: 0.224\n",
      "Training: Epoch 101, Batch 45, Loss: 0.17\n",
      "Training: Epoch 101, Batch 46, Loss: 0.146\n",
      "Training: Epoch 101, Batch 47, Loss: 0.213\n",
      "Training: Epoch 101, Batch 48, Loss: 0.143\n",
      "Training: Epoch 101, Batch 49, Loss: 0.151\n",
      "Training: Epoch 101, Batch 50, Loss: 0.188\n",
      "Training: Epoch 101, Batch 51, Loss: 0.139\n",
      "Training: Epoch 101, Batch 52, Loss: 0.137\n",
      "Training: Epoch 101, Batch 53, Loss: 0.189\n",
      "Training: Epoch 101, Batch 54, Loss: 0.178\n",
      "Training: Epoch 101, Batch 55, Loss: 0.193\n",
      "Training: Epoch 101, Batch 56, Loss: 0.176\n",
      "Training: Epoch 101, Batch 57, Loss: 0.167\n",
      "Training: Epoch 101, Batch 58, Loss: 0.114\n",
      "Training: Epoch 101, Batch 59, Loss: 0.145\n",
      "Training: Epoch 101, Batch 60, Loss: 0.176\n",
      "Training: Epoch 101, Batch 61, Loss: 0.145\n",
      "Training: Epoch 101, Batch 62, Loss: 0.139\n",
      "Training: Epoch 101, Batch 63, Loss: 0.281\n",
      "Training: Epoch 101, Batch 64, Loss: 0.16\n",
      "Training: Epoch 101, Batch 65, Loss: 0.184\n",
      "Training: Epoch 101, Batch 66, Loss: 0.134\n",
      "Training: Epoch 101, Batch 67, Loss: 0.151\n",
      "Training: Epoch 101, Batch 68, Loss: 0.172\n",
      "Training: Epoch 101, Batch 69, Loss: 0.209\n",
      "Training: Epoch 101, Batch 70, Loss: 0.171\n",
      "Training: Epoch 101, Batch 71, Loss: 0.172\n",
      "Training: Epoch 101, Batch 72, Loss: 0.191\n",
      "Training: Epoch 101, Batch 73, Loss: 0.201\n",
      "Training: Epoch 101, Batch 74, Loss: 0.256\n",
      "Training: Epoch 101, Batch 75, Loss: 0.243\n",
      "Training: Epoch 101, Batch 76, Loss: 0.162\n",
      "Training: Epoch 101, Batch 77, Loss: 0.16\n",
      "Training: Epoch 101, Batch 78, Loss: 0.274\n",
      "Training: Epoch 101, Batch 79, Loss: 0.218\n",
      "Training: Epoch 101, Batch 80, Loss: 0.169\n",
      "Training: Epoch 101, Batch 81, Loss: 0.24\n",
      "Training: Epoch 101, Batch 82, Loss: 0.203\n",
      "Training: Epoch 101, Batch 83, Loss: 0.145\n",
      "Training: Epoch 101, Batch 84, Loss: 0.105\n",
      "Training: Epoch 101, Batch 85, Loss: 0.187\n",
      "Training: Epoch 101, Batch 86, Loss: 0.24\n",
      "Training: Epoch 101, Batch 87, Loss: 0.176\n",
      "Training: Epoch 101, Batch 88, Loss: 0.128\n",
      "Training: Epoch 101, Batch 89, Loss: 0.173\n",
      "Val: Epoch 101, Loss: 0.284\n",
      "Training: Epoch 102, Batch 0, Loss: 0.149\n",
      "Training: Epoch 102, Batch 1, Loss: 0.21\n",
      "Training: Epoch 102, Batch 2, Loss: 0.135\n",
      "Training: Epoch 102, Batch 3, Loss: 0.223\n",
      "Training: Epoch 102, Batch 4, Loss: 0.152\n",
      "Training: Epoch 102, Batch 5, Loss: 0.184\n",
      "Training: Epoch 102, Batch 6, Loss: 0.203\n",
      "Training: Epoch 102, Batch 7, Loss: 0.155\n",
      "Training: Epoch 102, Batch 8, Loss: 0.215\n",
      "Training: Epoch 102, Batch 9, Loss: 0.219\n",
      "Training: Epoch 102, Batch 10, Loss: 0.199\n",
      "Training: Epoch 102, Batch 11, Loss: 0.204\n",
      "Training: Epoch 102, Batch 12, Loss: 0.17\n",
      "Training: Epoch 102, Batch 13, Loss: 0.203\n",
      "Training: Epoch 102, Batch 14, Loss: 0.098\n",
      "Training: Epoch 102, Batch 15, Loss: 0.234\n",
      "Training: Epoch 102, Batch 16, Loss: 0.161\n",
      "Training: Epoch 102, Batch 17, Loss: 0.103\n",
      "Training: Epoch 102, Batch 18, Loss: 0.116\n",
      "Training: Epoch 102, Batch 19, Loss: 0.198\n",
      "Training: Epoch 102, Batch 20, Loss: 0.146\n",
      "Training: Epoch 102, Batch 21, Loss: 0.171\n",
      "Training: Epoch 102, Batch 22, Loss: 0.159\n",
      "Training: Epoch 102, Batch 23, Loss: 0.119\n",
      "Training: Epoch 102, Batch 24, Loss: 0.218\n",
      "Training: Epoch 102, Batch 25, Loss: 0.133\n",
      "Training: Epoch 102, Batch 26, Loss: 0.133\n",
      "Training: Epoch 102, Batch 27, Loss: 0.191\n",
      "Training: Epoch 102, Batch 28, Loss: 0.165\n",
      "Training: Epoch 102, Batch 29, Loss: 0.219\n",
      "Training: Epoch 102, Batch 30, Loss: 0.194\n",
      "Training: Epoch 102, Batch 31, Loss: 0.179\n",
      "Training: Epoch 102, Batch 32, Loss: 0.218\n",
      "Training: Epoch 102, Batch 33, Loss: 0.19\n",
      "Training: Epoch 102, Batch 34, Loss: 0.157\n",
      "Training: Epoch 102, Batch 35, Loss: 0.167\n",
      "Training: Epoch 102, Batch 36, Loss: 0.294\n",
      "Training: Epoch 102, Batch 37, Loss: 0.169\n",
      "Training: Epoch 102, Batch 38, Loss: 0.199\n",
      "Training: Epoch 102, Batch 39, Loss: 0.155\n",
      "Training: Epoch 102, Batch 40, Loss: 0.149\n",
      "Training: Epoch 102, Batch 41, Loss: 0.171\n",
      "Training: Epoch 102, Batch 42, Loss: 0.213\n",
      "Training: Epoch 102, Batch 43, Loss: 0.242\n",
      "Training: Epoch 102, Batch 44, Loss: 0.236\n",
      "Training: Epoch 102, Batch 45, Loss: 0.196\n",
      "Training: Epoch 102, Batch 46, Loss: 0.222\n",
      "Training: Epoch 102, Batch 47, Loss: 0.147\n",
      "Training: Epoch 102, Batch 48, Loss: 0.139\n",
      "Training: Epoch 102, Batch 49, Loss: 0.238\n",
      "Training: Epoch 102, Batch 50, Loss: 0.182\n",
      "Training: Epoch 102, Batch 51, Loss: 0.133\n",
      "Training: Epoch 102, Batch 52, Loss: 0.203\n",
      "Training: Epoch 102, Batch 53, Loss: 0.145\n",
      "Training: Epoch 102, Batch 54, Loss: 0.141\n",
      "Training: Epoch 102, Batch 55, Loss: 0.223\n",
      "Training: Epoch 102, Batch 56, Loss: 0.351\n",
      "Training: Epoch 102, Batch 57, Loss: 0.173\n",
      "Training: Epoch 102, Batch 58, Loss: 0.188\n",
      "Training: Epoch 102, Batch 59, Loss: 0.263\n",
      "Training: Epoch 102, Batch 60, Loss: 0.185\n",
      "Training: Epoch 102, Batch 61, Loss: 0.205\n",
      "Training: Epoch 102, Batch 62, Loss: 0.227\n",
      "Training: Epoch 102, Batch 63, Loss: 0.219\n",
      "Training: Epoch 102, Batch 64, Loss: 0.167\n",
      "Training: Epoch 102, Batch 65, Loss: 0.122\n",
      "Training: Epoch 102, Batch 66, Loss: 0.146\n",
      "Training: Epoch 102, Batch 67, Loss: 0.24\n",
      "Training: Epoch 102, Batch 68, Loss: 0.17\n",
      "Training: Epoch 102, Batch 69, Loss: 0.158\n",
      "Training: Epoch 102, Batch 70, Loss: 0.215\n",
      "Training: Epoch 102, Batch 71, Loss: 0.161\n",
      "Training: Epoch 102, Batch 72, Loss: 0.15\n",
      "Training: Epoch 102, Batch 73, Loss: 0.159\n",
      "Training: Epoch 102, Batch 74, Loss: 0.18\n",
      "Training: Epoch 102, Batch 75, Loss: 0.155\n",
      "Training: Epoch 102, Batch 76, Loss: 0.202\n",
      "Training: Epoch 102, Batch 77, Loss: 0.22\n",
      "Training: Epoch 102, Batch 78, Loss: 0.125\n",
      "Training: Epoch 102, Batch 79, Loss: 0.176\n",
      "Training: Epoch 102, Batch 80, Loss: 0.185\n",
      "Training: Epoch 102, Batch 81, Loss: 0.159\n",
      "Training: Epoch 102, Batch 82, Loss: 0.227\n",
      "Training: Epoch 102, Batch 83, Loss: 0.185\n",
      "Training: Epoch 102, Batch 84, Loss: 0.171\n",
      "Training: Epoch 102, Batch 85, Loss: 0.129\n",
      "Training: Epoch 102, Batch 86, Loss: 0.188\n",
      "Training: Epoch 102, Batch 87, Loss: 0.176\n",
      "Training: Epoch 102, Batch 88, Loss: 0.182\n",
      "Training: Epoch 102, Batch 89, Loss: 0.208\n",
      "Val: Epoch 102, Loss: 0.26\n",
      "Training: Epoch 103, Batch 0, Loss: 0.188\n",
      "Training: Epoch 103, Batch 1, Loss: 0.144\n",
      "Training: Epoch 103, Batch 2, Loss: 0.186\n",
      "Training: Epoch 103, Batch 3, Loss: 0.138\n",
      "Training: Epoch 103, Batch 4, Loss: 0.131\n",
      "Training: Epoch 103, Batch 5, Loss: 0.124\n",
      "Training: Epoch 103, Batch 6, Loss: 0.23\n",
      "Training: Epoch 103, Batch 7, Loss: 0.229\n",
      "Training: Epoch 103, Batch 8, Loss: 0.141\n",
      "Training: Epoch 103, Batch 9, Loss: 0.155\n",
      "Training: Epoch 103, Batch 10, Loss: 0.214\n",
      "Training: Epoch 103, Batch 11, Loss: 0.168\n",
      "Training: Epoch 103, Batch 12, Loss: 0.097\n",
      "Training: Epoch 103, Batch 13, Loss: 0.191\n",
      "Training: Epoch 103, Batch 14, Loss: 0.12\n",
      "Training: Epoch 103, Batch 15, Loss: 0.127\n",
      "Training: Epoch 103, Batch 16, Loss: 0.249\n",
      "Training: Epoch 103, Batch 17, Loss: 0.18\n",
      "Training: Epoch 103, Batch 18, Loss: 0.163\n",
      "Training: Epoch 103, Batch 19, Loss: 0.164\n",
      "Training: Epoch 103, Batch 20, Loss: 0.152\n",
      "Training: Epoch 103, Batch 21, Loss: 0.16\n",
      "Training: Epoch 103, Batch 22, Loss: 0.163\n",
      "Training: Epoch 103, Batch 23, Loss: 0.144\n",
      "Training: Epoch 103, Batch 24, Loss: 0.178\n",
      "Training: Epoch 103, Batch 25, Loss: 0.178\n",
      "Training: Epoch 103, Batch 26, Loss: 0.138\n",
      "Training: Epoch 103, Batch 27, Loss: 0.2\n",
      "Training: Epoch 103, Batch 28, Loss: 0.153\n",
      "Training: Epoch 103, Batch 29, Loss: 0.118\n",
      "Training: Epoch 103, Batch 30, Loss: 0.172\n",
      "Training: Epoch 103, Batch 31, Loss: 0.165\n",
      "Training: Epoch 103, Batch 32, Loss: 0.158\n",
      "Training: Epoch 103, Batch 33, Loss: 0.148\n",
      "Training: Epoch 103, Batch 34, Loss: 0.267\n",
      "Training: Epoch 103, Batch 35, Loss: 0.149\n",
      "Training: Epoch 103, Batch 36, Loss: 0.144\n",
      "Training: Epoch 103, Batch 37, Loss: 0.146\n",
      "Training: Epoch 103, Batch 38, Loss: 0.141\n",
      "Training: Epoch 103, Batch 39, Loss: 0.136\n",
      "Training: Epoch 103, Batch 40, Loss: 0.124\n",
      "Training: Epoch 103, Batch 41, Loss: 0.147\n",
      "Training: Epoch 103, Batch 42, Loss: 0.126\n",
      "Training: Epoch 103, Batch 43, Loss: 0.211\n",
      "Training: Epoch 103, Batch 44, Loss: 0.172\n",
      "Training: Epoch 103, Batch 45, Loss: 0.165\n",
      "Training: Epoch 103, Batch 46, Loss: 0.135\n",
      "Training: Epoch 103, Batch 47, Loss: 0.181\n",
      "Training: Epoch 103, Batch 48, Loss: 0.128\n",
      "Training: Epoch 103, Batch 49, Loss: 0.218\n",
      "Training: Epoch 103, Batch 50, Loss: 0.192\n",
      "Training: Epoch 103, Batch 51, Loss: 0.155\n",
      "Training: Epoch 103, Batch 52, Loss: 0.166\n",
      "Training: Epoch 103, Batch 53, Loss: 0.189\n",
      "Training: Epoch 103, Batch 54, Loss: 0.142\n",
      "Training: Epoch 103, Batch 55, Loss: 0.208\n",
      "Training: Epoch 103, Batch 56, Loss: 0.181\n",
      "Training: Epoch 103, Batch 57, Loss: 0.182\n",
      "Training: Epoch 103, Batch 58, Loss: 0.157\n",
      "Training: Epoch 103, Batch 59, Loss: 0.149\n",
      "Training: Epoch 103, Batch 60, Loss: 0.167\n",
      "Training: Epoch 103, Batch 61, Loss: 0.205\n",
      "Training: Epoch 103, Batch 62, Loss: 0.203\n",
      "Training: Epoch 103, Batch 63, Loss: 0.179\n",
      "Training: Epoch 103, Batch 64, Loss: 0.139\n",
      "Training: Epoch 103, Batch 65, Loss: 0.178\n",
      "Training: Epoch 103, Batch 66, Loss: 0.182\n",
      "Training: Epoch 103, Batch 67, Loss: 0.234\n",
      "Training: Epoch 103, Batch 68, Loss: 0.175\n",
      "Training: Epoch 103, Batch 69, Loss: 0.146\n",
      "Training: Epoch 103, Batch 70, Loss: 0.184\n",
      "Training: Epoch 103, Batch 71, Loss: 0.215\n",
      "Training: Epoch 103, Batch 72, Loss: 0.163\n",
      "Training: Epoch 103, Batch 73, Loss: 0.2\n",
      "Training: Epoch 103, Batch 74, Loss: 0.177\n",
      "Training: Epoch 103, Batch 75, Loss: 0.172\n",
      "Training: Epoch 103, Batch 76, Loss: 0.154\n",
      "Training: Epoch 103, Batch 77, Loss: 0.195\n",
      "Training: Epoch 103, Batch 78, Loss: 0.145\n",
      "Training: Epoch 103, Batch 79, Loss: 0.132\n",
      "Training: Epoch 103, Batch 80, Loss: 0.131\n",
      "Training: Epoch 103, Batch 81, Loss: 0.211\n",
      "Training: Epoch 103, Batch 82, Loss: 0.184\n",
      "Training: Epoch 103, Batch 83, Loss: 0.234\n",
      "Training: Epoch 103, Batch 84, Loss: 0.198\n",
      "Training: Epoch 103, Batch 85, Loss: 0.189\n",
      "Training: Epoch 103, Batch 86, Loss: 0.167\n",
      "Training: Epoch 103, Batch 87, Loss: 0.175\n",
      "Training: Epoch 103, Batch 88, Loss: 0.168\n",
      "Training: Epoch 103, Batch 89, Loss: 0.17\n",
      "Val: Epoch 103, Loss: 0.34\n",
      "Training: Epoch 104, Batch 0, Loss: 0.163\n",
      "Training: Epoch 104, Batch 1, Loss: 0.193\n",
      "Training: Epoch 104, Batch 2, Loss: 0.207\n",
      "Training: Epoch 104, Batch 3, Loss: 0.203\n",
      "Training: Epoch 104, Batch 4, Loss: 0.146\n",
      "Training: Epoch 104, Batch 5, Loss: 0.187\n",
      "Training: Epoch 104, Batch 6, Loss: 0.154\n",
      "Training: Epoch 104, Batch 7, Loss: 0.154\n",
      "Training: Epoch 104, Batch 8, Loss: 0.186\n",
      "Training: Epoch 104, Batch 9, Loss: 0.127\n",
      "Training: Epoch 104, Batch 10, Loss: 0.172\n",
      "Training: Epoch 104, Batch 11, Loss: 0.177\n",
      "Training: Epoch 104, Batch 12, Loss: 0.16\n",
      "Training: Epoch 104, Batch 13, Loss: 0.145\n",
      "Training: Epoch 104, Batch 14, Loss: 0.15\n",
      "Training: Epoch 104, Batch 15, Loss: 0.126\n",
      "Training: Epoch 104, Batch 16, Loss: 0.137\n",
      "Training: Epoch 104, Batch 17, Loss: 0.131\n",
      "Training: Epoch 104, Batch 18, Loss: 0.177\n",
      "Training: Epoch 104, Batch 19, Loss: 0.135\n",
      "Training: Epoch 104, Batch 20, Loss: 0.185\n",
      "Training: Epoch 104, Batch 21, Loss: 0.132\n",
      "Training: Epoch 104, Batch 22, Loss: 0.161\n",
      "Training: Epoch 104, Batch 23, Loss: 0.138\n",
      "Training: Epoch 104, Batch 24, Loss: 0.151\n",
      "Training: Epoch 104, Batch 25, Loss: 0.183\n",
      "Training: Epoch 104, Batch 26, Loss: 0.15\n",
      "Training: Epoch 104, Batch 27, Loss: 0.158\n",
      "Training: Epoch 104, Batch 28, Loss: 0.148\n",
      "Training: Epoch 104, Batch 29, Loss: 0.208\n",
      "Training: Epoch 104, Batch 30, Loss: 0.142\n",
      "Training: Epoch 104, Batch 31, Loss: 0.228\n",
      "Training: Epoch 104, Batch 32, Loss: 0.155\n",
      "Training: Epoch 104, Batch 33, Loss: 0.237\n",
      "Training: Epoch 104, Batch 34, Loss: 0.167\n",
      "Training: Epoch 104, Batch 35, Loss: 0.192\n",
      "Training: Epoch 104, Batch 36, Loss: 0.181\n",
      "Training: Epoch 104, Batch 37, Loss: 0.164\n",
      "Training: Epoch 104, Batch 38, Loss: 0.126\n",
      "Training: Epoch 104, Batch 39, Loss: 0.123\n",
      "Training: Epoch 104, Batch 40, Loss: 0.131\n",
      "Training: Epoch 104, Batch 41, Loss: 0.162\n",
      "Training: Epoch 104, Batch 42, Loss: 0.222\n",
      "Training: Epoch 104, Batch 43, Loss: 0.17\n",
      "Training: Epoch 104, Batch 44, Loss: 0.31\n",
      "Training: Epoch 104, Batch 45, Loss: 0.216\n",
      "Training: Epoch 104, Batch 46, Loss: 0.154\n",
      "Training: Epoch 104, Batch 47, Loss: 0.165\n",
      "Training: Epoch 104, Batch 48, Loss: 0.189\n",
      "Training: Epoch 104, Batch 49, Loss: 0.157\n",
      "Training: Epoch 104, Batch 50, Loss: 0.196\n",
      "Training: Epoch 104, Batch 51, Loss: 0.148\n",
      "Training: Epoch 104, Batch 52, Loss: 0.133\n",
      "Training: Epoch 104, Batch 53, Loss: 0.184\n",
      "Training: Epoch 104, Batch 54, Loss: 0.169\n",
      "Training: Epoch 104, Batch 55, Loss: 0.115\n",
      "Training: Epoch 104, Batch 56, Loss: 0.145\n",
      "Training: Epoch 104, Batch 57, Loss: 0.182\n",
      "Training: Epoch 104, Batch 58, Loss: 0.247\n",
      "Training: Epoch 104, Batch 59, Loss: 0.16\n",
      "Training: Epoch 104, Batch 60, Loss: 0.195\n",
      "Training: Epoch 104, Batch 61, Loss: 0.149\n",
      "Training: Epoch 104, Batch 62, Loss: 0.193\n",
      "Training: Epoch 104, Batch 63, Loss: 0.2\n",
      "Training: Epoch 104, Batch 64, Loss: 0.213\n",
      "Training: Epoch 104, Batch 65, Loss: 0.154\n",
      "Training: Epoch 104, Batch 66, Loss: 0.176\n",
      "Training: Epoch 104, Batch 67, Loss: 0.172\n",
      "Training: Epoch 104, Batch 68, Loss: 0.158\n",
      "Training: Epoch 104, Batch 69, Loss: 0.18\n",
      "Training: Epoch 104, Batch 70, Loss: 0.161\n",
      "Training: Epoch 104, Batch 71, Loss: 0.14\n",
      "Training: Epoch 104, Batch 72, Loss: 0.143\n",
      "Training: Epoch 104, Batch 73, Loss: 0.155\n",
      "Training: Epoch 104, Batch 74, Loss: 0.141\n",
      "Training: Epoch 104, Batch 75, Loss: 0.112\n",
      "Training: Epoch 104, Batch 76, Loss: 0.162\n",
      "Training: Epoch 104, Batch 77, Loss: 0.172\n",
      "Training: Epoch 104, Batch 78, Loss: 0.148\n",
      "Training: Epoch 104, Batch 79, Loss: 0.151\n",
      "Training: Epoch 104, Batch 80, Loss: 0.137\n",
      "Training: Epoch 104, Batch 81, Loss: 0.165\n",
      "Training: Epoch 104, Batch 82, Loss: 0.146\n",
      "Training: Epoch 104, Batch 83, Loss: 0.138\n",
      "Training: Epoch 104, Batch 84, Loss: 0.125\n",
      "Training: Epoch 104, Batch 85, Loss: 0.171\n",
      "Training: Epoch 104, Batch 86, Loss: 0.109\n",
      "Training: Epoch 104, Batch 87, Loss: 0.159\n",
      "Training: Epoch 104, Batch 88, Loss: 0.126\n",
      "Training: Epoch 104, Batch 89, Loss: 0.168\n",
      "Val: Epoch 104, Loss: 0.251\n",
      "Training: Epoch 105, Batch 0, Loss: 0.201\n",
      "Training: Epoch 105, Batch 1, Loss: 0.117\n",
      "Training: Epoch 105, Batch 2, Loss: 0.147\n",
      "Training: Epoch 105, Batch 3, Loss: 0.198\n",
      "Training: Epoch 105, Batch 4, Loss: 0.111\n",
      "Training: Epoch 105, Batch 5, Loss: 0.195\n",
      "Training: Epoch 105, Batch 6, Loss: 0.131\n",
      "Training: Epoch 105, Batch 7, Loss: 0.186\n",
      "Training: Epoch 105, Batch 8, Loss: 0.153\n",
      "Training: Epoch 105, Batch 9, Loss: 0.116\n",
      "Training: Epoch 105, Batch 10, Loss: 0.114\n",
      "Training: Epoch 105, Batch 11, Loss: 0.177\n",
      "Training: Epoch 105, Batch 12, Loss: 0.172\n",
      "Training: Epoch 105, Batch 13, Loss: 0.13\n",
      "Training: Epoch 105, Batch 14, Loss: 0.138\n",
      "Training: Epoch 105, Batch 15, Loss: 0.163\n",
      "Training: Epoch 105, Batch 16, Loss: 0.123\n",
      "Training: Epoch 105, Batch 17, Loss: 0.164\n",
      "Training: Epoch 105, Batch 18, Loss: 0.234\n",
      "Training: Epoch 105, Batch 19, Loss: 0.113\n",
      "Training: Epoch 105, Batch 20, Loss: 0.128\n",
      "Training: Epoch 105, Batch 21, Loss: 0.13\n",
      "Training: Epoch 105, Batch 22, Loss: 0.21\n",
      "Training: Epoch 105, Batch 23, Loss: 0.104\n",
      "Training: Epoch 105, Batch 24, Loss: 0.151\n",
      "Training: Epoch 105, Batch 25, Loss: 0.155\n",
      "Training: Epoch 105, Batch 26, Loss: 0.176\n",
      "Training: Epoch 105, Batch 27, Loss: 0.147\n",
      "Training: Epoch 105, Batch 28, Loss: 0.163\n",
      "Training: Epoch 105, Batch 29, Loss: 0.162\n",
      "Training: Epoch 105, Batch 30, Loss: 0.182\n",
      "Training: Epoch 105, Batch 31, Loss: 0.143\n",
      "Training: Epoch 105, Batch 32, Loss: 0.157\n",
      "Training: Epoch 105, Batch 33, Loss: 0.147\n",
      "Training: Epoch 105, Batch 34, Loss: 0.137\n",
      "Training: Epoch 105, Batch 35, Loss: 0.156\n",
      "Training: Epoch 105, Batch 36, Loss: 0.149\n",
      "Training: Epoch 105, Batch 37, Loss: 0.19\n",
      "Training: Epoch 105, Batch 38, Loss: 0.173\n",
      "Training: Epoch 105, Batch 39, Loss: 0.137\n",
      "Training: Epoch 105, Batch 40, Loss: 0.205\n",
      "Training: Epoch 105, Batch 41, Loss: 0.104\n",
      "Training: Epoch 105, Batch 42, Loss: 0.16\n",
      "Training: Epoch 105, Batch 43, Loss: 0.129\n",
      "Training: Epoch 105, Batch 44, Loss: 0.124\n",
      "Training: Epoch 105, Batch 45, Loss: 0.121\n",
      "Training: Epoch 105, Batch 46, Loss: 0.226\n",
      "Training: Epoch 105, Batch 47, Loss: 0.131\n",
      "Training: Epoch 105, Batch 48, Loss: 0.199\n",
      "Training: Epoch 105, Batch 49, Loss: 0.151\n",
      "Training: Epoch 105, Batch 50, Loss: 0.106\n",
      "Training: Epoch 105, Batch 51, Loss: 0.112\n",
      "Training: Epoch 105, Batch 52, Loss: 0.166\n",
      "Training: Epoch 105, Batch 53, Loss: 0.202\n",
      "Training: Epoch 105, Batch 54, Loss: 0.18\n",
      "Training: Epoch 105, Batch 55, Loss: 0.184\n",
      "Training: Epoch 105, Batch 56, Loss: 0.141\n",
      "Training: Epoch 105, Batch 57, Loss: 0.124\n",
      "Training: Epoch 105, Batch 58, Loss: 0.15\n",
      "Training: Epoch 105, Batch 59, Loss: 0.114\n",
      "Training: Epoch 105, Batch 60, Loss: 0.17\n",
      "Training: Epoch 105, Batch 61, Loss: 0.165\n",
      "Training: Epoch 105, Batch 62, Loss: 0.1\n",
      "Training: Epoch 105, Batch 63, Loss: 0.143\n",
      "Training: Epoch 105, Batch 64, Loss: 0.111\n",
      "Training: Epoch 105, Batch 65, Loss: 0.12\n",
      "Training: Epoch 105, Batch 66, Loss: 0.15\n",
      "Training: Epoch 105, Batch 67, Loss: 0.149\n",
      "Training: Epoch 105, Batch 68, Loss: 0.182\n",
      "Training: Epoch 105, Batch 69, Loss: 0.113\n",
      "Training: Epoch 105, Batch 70, Loss: 0.177\n",
      "Training: Epoch 105, Batch 71, Loss: 0.143\n",
      "Training: Epoch 105, Batch 72, Loss: 0.183\n",
      "Training: Epoch 105, Batch 73, Loss: 0.192\n",
      "Training: Epoch 105, Batch 74, Loss: 0.17\n",
      "Training: Epoch 105, Batch 75, Loss: 0.191\n",
      "Training: Epoch 105, Batch 76, Loss: 0.18\n",
      "Training: Epoch 105, Batch 77, Loss: 0.125\n",
      "Training: Epoch 105, Batch 78, Loss: 0.162\n",
      "Training: Epoch 105, Batch 79, Loss: 0.152\n",
      "Training: Epoch 105, Batch 80, Loss: 0.23\n",
      "Training: Epoch 105, Batch 81, Loss: 0.119\n",
      "Training: Epoch 105, Batch 82, Loss: 0.112\n",
      "Training: Epoch 105, Batch 83, Loss: 0.136\n",
      "Training: Epoch 105, Batch 84, Loss: 0.175\n",
      "Training: Epoch 105, Batch 85, Loss: 0.154\n",
      "Training: Epoch 105, Batch 86, Loss: 0.197\n",
      "Training: Epoch 105, Batch 87, Loss: 0.188\n",
      "Training: Epoch 105, Batch 88, Loss: 0.132\n",
      "Training: Epoch 105, Batch 89, Loss: 0.132\n",
      "Val: Epoch 105, Loss: 0.427\n",
      "Training: Epoch 106, Batch 0, Loss: 0.172\n",
      "Training: Epoch 106, Batch 1, Loss: 0.153\n",
      "Training: Epoch 106, Batch 2, Loss: 0.228\n",
      "Training: Epoch 106, Batch 3, Loss: 0.142\n",
      "Training: Epoch 106, Batch 4, Loss: 0.105\n",
      "Training: Epoch 106, Batch 5, Loss: 0.117\n",
      "Training: Epoch 106, Batch 6, Loss: 0.179\n",
      "Training: Epoch 106, Batch 7, Loss: 0.132\n",
      "Training: Epoch 106, Batch 8, Loss: 0.157\n",
      "Training: Epoch 106, Batch 9, Loss: 0.175\n",
      "Training: Epoch 106, Batch 10, Loss: 0.167\n",
      "Training: Epoch 106, Batch 11, Loss: 0.135\n",
      "Training: Epoch 106, Batch 12, Loss: 0.115\n",
      "Training: Epoch 106, Batch 13, Loss: 0.142\n",
      "Training: Epoch 106, Batch 14, Loss: 0.205\n",
      "Training: Epoch 106, Batch 15, Loss: 0.187\n",
      "Training: Epoch 106, Batch 16, Loss: 0.141\n",
      "Training: Epoch 106, Batch 17, Loss: 0.165\n",
      "Training: Epoch 106, Batch 18, Loss: 0.158\n",
      "Training: Epoch 106, Batch 19, Loss: 0.113\n",
      "Training: Epoch 106, Batch 20, Loss: 0.128\n",
      "Training: Epoch 106, Batch 21, Loss: 0.176\n",
      "Training: Epoch 106, Batch 22, Loss: 0.126\n",
      "Training: Epoch 106, Batch 23, Loss: 0.133\n",
      "Training: Epoch 106, Batch 24, Loss: 0.153\n",
      "Training: Epoch 106, Batch 25, Loss: 0.182\n",
      "Training: Epoch 106, Batch 26, Loss: 0.169\n",
      "Training: Epoch 106, Batch 27, Loss: 0.144\n",
      "Training: Epoch 106, Batch 28, Loss: 0.158\n",
      "Training: Epoch 106, Batch 29, Loss: 0.123\n",
      "Training: Epoch 106, Batch 30, Loss: 0.176\n",
      "Training: Epoch 106, Batch 31, Loss: 0.176\n",
      "Training: Epoch 106, Batch 32, Loss: 0.173\n",
      "Training: Epoch 106, Batch 33, Loss: 0.22\n",
      "Training: Epoch 106, Batch 34, Loss: 0.133\n",
      "Training: Epoch 106, Batch 35, Loss: 0.113\n",
      "Training: Epoch 106, Batch 36, Loss: 0.151\n",
      "Training: Epoch 106, Batch 37, Loss: 0.196\n",
      "Training: Epoch 106, Batch 38, Loss: 0.133\n",
      "Training: Epoch 106, Batch 39, Loss: 0.165\n",
      "Training: Epoch 106, Batch 40, Loss: 0.127\n",
      "Training: Epoch 106, Batch 41, Loss: 0.141\n",
      "Training: Epoch 106, Batch 42, Loss: 0.155\n",
      "Training: Epoch 106, Batch 43, Loss: 0.146\n",
      "Training: Epoch 106, Batch 44, Loss: 0.138\n",
      "Training: Epoch 106, Batch 45, Loss: 0.142\n",
      "Training: Epoch 106, Batch 46, Loss: 0.125\n",
      "Training: Epoch 106, Batch 47, Loss: 0.185\n",
      "Training: Epoch 106, Batch 48, Loss: 0.169\n",
      "Training: Epoch 106, Batch 49, Loss: 0.182\n",
      "Training: Epoch 106, Batch 50, Loss: 0.149\n",
      "Training: Epoch 106, Batch 51, Loss: 0.155\n",
      "Training: Epoch 106, Batch 52, Loss: 0.16\n",
      "Training: Epoch 106, Batch 53, Loss: 0.109\n",
      "Training: Epoch 106, Batch 54, Loss: 0.126\n",
      "Training: Epoch 106, Batch 55, Loss: 0.179\n",
      "Training: Epoch 106, Batch 56, Loss: 0.118\n",
      "Training: Epoch 106, Batch 57, Loss: 0.168\n",
      "Training: Epoch 106, Batch 58, Loss: 0.125\n",
      "Training: Epoch 106, Batch 59, Loss: 0.115\n",
      "Training: Epoch 106, Batch 60, Loss: 0.117\n",
      "Training: Epoch 106, Batch 61, Loss: 0.099\n",
      "Training: Epoch 106, Batch 62, Loss: 0.131\n",
      "Training: Epoch 106, Batch 63, Loss: 0.2\n",
      "Training: Epoch 106, Batch 64, Loss: 0.132\n",
      "Training: Epoch 106, Batch 65, Loss: 0.129\n",
      "Training: Epoch 106, Batch 66, Loss: 0.137\n",
      "Training: Epoch 106, Batch 67, Loss: 0.138\n",
      "Training: Epoch 106, Batch 68, Loss: 0.134\n",
      "Training: Epoch 106, Batch 69, Loss: 0.15\n",
      "Training: Epoch 106, Batch 70, Loss: 0.113\n",
      "Training: Epoch 106, Batch 71, Loss: 0.179\n",
      "Training: Epoch 106, Batch 72, Loss: 0.112\n",
      "Training: Epoch 106, Batch 73, Loss: 0.205\n",
      "Training: Epoch 106, Batch 74, Loss: 0.158\n",
      "Training: Epoch 106, Batch 75, Loss: 0.141\n",
      "Training: Epoch 106, Batch 76, Loss: 0.111\n",
      "Training: Epoch 106, Batch 77, Loss: 0.157\n",
      "Training: Epoch 106, Batch 78, Loss: 0.144\n",
      "Training: Epoch 106, Batch 79, Loss: 0.158\n",
      "Training: Epoch 106, Batch 80, Loss: 0.137\n",
      "Training: Epoch 106, Batch 81, Loss: 0.141\n",
      "Training: Epoch 106, Batch 82, Loss: 0.155\n",
      "Training: Epoch 106, Batch 83, Loss: 0.175\n",
      "Training: Epoch 106, Batch 84, Loss: 0.149\n",
      "Training: Epoch 106, Batch 85, Loss: 0.145\n",
      "Training: Epoch 106, Batch 86, Loss: 0.137\n",
      "Training: Epoch 106, Batch 87, Loss: 0.18\n",
      "Training: Epoch 106, Batch 88, Loss: 0.165\n",
      "Training: Epoch 106, Batch 89, Loss: 0.211\n",
      "Val: Epoch 106, Loss: 0.261\n",
      "Training: Epoch 107, Batch 0, Loss: 0.185\n",
      "Training: Epoch 107, Batch 1, Loss: 0.13\n",
      "Training: Epoch 107, Batch 2, Loss: 0.115\n",
      "Training: Epoch 107, Batch 3, Loss: 0.147\n",
      "Training: Epoch 107, Batch 4, Loss: 0.124\n",
      "Training: Epoch 107, Batch 5, Loss: 0.143\n",
      "Training: Epoch 107, Batch 6, Loss: 0.172\n",
      "Training: Epoch 107, Batch 7, Loss: 0.167\n",
      "Training: Epoch 107, Batch 8, Loss: 0.107\n",
      "Training: Epoch 107, Batch 9, Loss: 0.125\n",
      "Training: Epoch 107, Batch 10, Loss: 0.112\n",
      "Training: Epoch 107, Batch 11, Loss: 0.12\n",
      "Training: Epoch 107, Batch 12, Loss: 0.155\n",
      "Training: Epoch 107, Batch 13, Loss: 0.109\n",
      "Training: Epoch 107, Batch 14, Loss: 0.148\n",
      "Training: Epoch 107, Batch 15, Loss: 0.111\n",
      "Training: Epoch 107, Batch 16, Loss: 0.202\n",
      "Training: Epoch 107, Batch 17, Loss: 0.222\n",
      "Training: Epoch 107, Batch 18, Loss: 0.145\n",
      "Training: Epoch 107, Batch 19, Loss: 0.097\n",
      "Training: Epoch 107, Batch 20, Loss: 0.183\n",
      "Training: Epoch 107, Batch 21, Loss: 0.182\n",
      "Training: Epoch 107, Batch 22, Loss: 0.131\n",
      "Training: Epoch 107, Batch 23, Loss: 0.199\n",
      "Training: Epoch 107, Batch 24, Loss: 0.144\n",
      "Training: Epoch 107, Batch 25, Loss: 0.152\n",
      "Training: Epoch 107, Batch 26, Loss: 0.148\n",
      "Training: Epoch 107, Batch 27, Loss: 0.184\n",
      "Training: Epoch 107, Batch 28, Loss: 0.175\n",
      "Training: Epoch 107, Batch 29, Loss: 0.163\n",
      "Training: Epoch 107, Batch 30, Loss: 0.148\n",
      "Training: Epoch 107, Batch 31, Loss: 0.244\n",
      "Training: Epoch 107, Batch 32, Loss: 0.166\n",
      "Training: Epoch 107, Batch 33, Loss: 0.164\n",
      "Training: Epoch 107, Batch 34, Loss: 0.136\n",
      "Training: Epoch 107, Batch 35, Loss: 0.162\n",
      "Training: Epoch 107, Batch 36, Loss: 0.171\n",
      "Training: Epoch 107, Batch 37, Loss: 0.167\n",
      "Training: Epoch 107, Batch 38, Loss: 0.156\n",
      "Training: Epoch 107, Batch 39, Loss: 0.119\n",
      "Training: Epoch 107, Batch 40, Loss: 0.1\n",
      "Training: Epoch 107, Batch 41, Loss: 0.124\n",
      "Training: Epoch 107, Batch 42, Loss: 0.127\n",
      "Training: Epoch 107, Batch 43, Loss: 0.126\n",
      "Training: Epoch 107, Batch 44, Loss: 0.12\n",
      "Training: Epoch 107, Batch 45, Loss: 0.108\n",
      "Training: Epoch 107, Batch 46, Loss: 0.199\n",
      "Training: Epoch 107, Batch 47, Loss: 0.153\n",
      "Training: Epoch 107, Batch 48, Loss: 0.116\n",
      "Training: Epoch 107, Batch 49, Loss: 0.13\n",
      "Training: Epoch 107, Batch 50, Loss: 0.135\n",
      "Training: Epoch 107, Batch 51, Loss: 0.198\n",
      "Training: Epoch 107, Batch 52, Loss: 0.222\n",
      "Training: Epoch 107, Batch 53, Loss: 0.124\n",
      "Training: Epoch 107, Batch 54, Loss: 0.174\n",
      "Training: Epoch 107, Batch 55, Loss: 0.141\n",
      "Training: Epoch 107, Batch 56, Loss: 0.164\n",
      "Training: Epoch 107, Batch 57, Loss: 0.17\n",
      "Training: Epoch 107, Batch 58, Loss: 0.12\n",
      "Training: Epoch 107, Batch 59, Loss: 0.163\n",
      "Training: Epoch 107, Batch 60, Loss: 0.203\n",
      "Training: Epoch 107, Batch 61, Loss: 0.152\n",
      "Training: Epoch 107, Batch 62, Loss: 0.151\n",
      "Training: Epoch 107, Batch 63, Loss: 0.132\n",
      "Training: Epoch 107, Batch 64, Loss: 0.131\n",
      "Training: Epoch 107, Batch 65, Loss: 0.118\n",
      "Training: Epoch 107, Batch 66, Loss: 0.158\n",
      "Training: Epoch 107, Batch 67, Loss: 0.149\n",
      "Training: Epoch 107, Batch 68, Loss: 0.144\n",
      "Training: Epoch 107, Batch 69, Loss: 0.129\n",
      "Training: Epoch 107, Batch 70, Loss: 0.146\n",
      "Training: Epoch 107, Batch 71, Loss: 0.121\n",
      "Training: Epoch 107, Batch 72, Loss: 0.161\n",
      "Training: Epoch 107, Batch 73, Loss: 0.132\n",
      "Training: Epoch 107, Batch 74, Loss: 0.167\n",
      "Training: Epoch 107, Batch 75, Loss: 0.124\n",
      "Training: Epoch 107, Batch 76, Loss: 0.111\n",
      "Training: Epoch 107, Batch 77, Loss: 0.157\n",
      "Training: Epoch 107, Batch 78, Loss: 0.164\n",
      "Training: Epoch 107, Batch 79, Loss: 0.142\n",
      "Training: Epoch 107, Batch 80, Loss: 0.15\n",
      "Training: Epoch 107, Batch 81, Loss: 0.179\n",
      "Training: Epoch 107, Batch 82, Loss: 0.17\n",
      "Training: Epoch 107, Batch 83, Loss: 0.204\n",
      "Training: Epoch 107, Batch 84, Loss: 0.144\n",
      "Training: Epoch 107, Batch 85, Loss: 0.101\n",
      "Training: Epoch 107, Batch 86, Loss: 0.182\n",
      "Training: Epoch 107, Batch 87, Loss: 0.198\n",
      "Training: Epoch 107, Batch 88, Loss: 0.198\n",
      "Training: Epoch 107, Batch 89, Loss: 0.189\n",
      "Val: Epoch 107, Loss: 0.271\n",
      "Training: Epoch 108, Batch 0, Loss: 0.157\n",
      "Training: Epoch 108, Batch 1, Loss: 0.175\n",
      "Training: Epoch 108, Batch 2, Loss: 0.223\n",
      "Training: Epoch 108, Batch 3, Loss: 0.144\n",
      "Training: Epoch 108, Batch 4, Loss: 0.112\n",
      "Training: Epoch 108, Batch 5, Loss: 0.126\n",
      "Training: Epoch 108, Batch 6, Loss: 0.144\n",
      "Training: Epoch 108, Batch 7, Loss: 0.131\n",
      "Training: Epoch 108, Batch 8, Loss: 0.125\n",
      "Training: Epoch 108, Batch 9, Loss: 0.113\n",
      "Training: Epoch 108, Batch 10, Loss: 0.161\n",
      "Training: Epoch 108, Batch 11, Loss: 0.163\n",
      "Training: Epoch 108, Batch 12, Loss: 0.113\n",
      "Training: Epoch 108, Batch 13, Loss: 0.114\n",
      "Training: Epoch 108, Batch 14, Loss: 0.164\n",
      "Training: Epoch 108, Batch 15, Loss: 0.122\n",
      "Training: Epoch 108, Batch 16, Loss: 0.169\n",
      "Training: Epoch 108, Batch 17, Loss: 0.14\n",
      "Training: Epoch 108, Batch 18, Loss: 0.159\n",
      "Training: Epoch 108, Batch 19, Loss: 0.19\n",
      "Training: Epoch 108, Batch 20, Loss: 0.108\n",
      "Training: Epoch 108, Batch 21, Loss: 0.19\n",
      "Training: Epoch 108, Batch 22, Loss: 0.121\n",
      "Training: Epoch 108, Batch 23, Loss: 0.199\n",
      "Training: Epoch 108, Batch 24, Loss: 0.146\n",
      "Training: Epoch 108, Batch 25, Loss: 0.126\n",
      "Training: Epoch 108, Batch 26, Loss: 0.147\n",
      "Training: Epoch 108, Batch 27, Loss: 0.123\n",
      "Training: Epoch 108, Batch 28, Loss: 0.148\n",
      "Training: Epoch 108, Batch 29, Loss: 0.127\n",
      "Training: Epoch 108, Batch 30, Loss: 0.16\n",
      "Training: Epoch 108, Batch 31, Loss: 0.153\n",
      "Training: Epoch 108, Batch 32, Loss: 0.129\n",
      "Training: Epoch 108, Batch 33, Loss: 0.141\n",
      "Training: Epoch 108, Batch 34, Loss: 0.219\n",
      "Training: Epoch 108, Batch 35, Loss: 0.115\n",
      "Training: Epoch 108, Batch 36, Loss: 0.187\n",
      "Training: Epoch 108, Batch 37, Loss: 0.175\n",
      "Training: Epoch 108, Batch 38, Loss: 0.131\n",
      "Training: Epoch 108, Batch 39, Loss: 0.185\n",
      "Training: Epoch 108, Batch 40, Loss: 0.192\n",
      "Training: Epoch 108, Batch 41, Loss: 0.135\n",
      "Training: Epoch 108, Batch 42, Loss: 0.142\n",
      "Training: Epoch 108, Batch 43, Loss: 0.145\n",
      "Training: Epoch 108, Batch 44, Loss: 0.126\n",
      "Training: Epoch 108, Batch 45, Loss: 0.139\n",
      "Training: Epoch 108, Batch 46, Loss: 0.182\n",
      "Training: Epoch 108, Batch 47, Loss: 0.15\n",
      "Training: Epoch 108, Batch 48, Loss: 0.127\n",
      "Training: Epoch 108, Batch 49, Loss: 0.188\n",
      "Training: Epoch 108, Batch 50, Loss: 0.182\n",
      "Training: Epoch 108, Batch 51, Loss: 0.156\n",
      "Training: Epoch 108, Batch 52, Loss: 0.176\n",
      "Training: Epoch 108, Batch 53, Loss: 0.185\n",
      "Training: Epoch 108, Batch 54, Loss: 0.133\n",
      "Training: Epoch 108, Batch 55, Loss: 0.163\n",
      "Training: Epoch 108, Batch 56, Loss: 0.153\n",
      "Training: Epoch 108, Batch 57, Loss: 0.134\n",
      "Training: Epoch 108, Batch 58, Loss: 0.18\n",
      "Training: Epoch 108, Batch 59, Loss: 0.13\n",
      "Training: Epoch 108, Batch 60, Loss: 0.137\n",
      "Training: Epoch 108, Batch 61, Loss: 0.135\n",
      "Training: Epoch 108, Batch 62, Loss: 0.102\n",
      "Training: Epoch 108, Batch 63, Loss: 0.121\n",
      "Training: Epoch 108, Batch 64, Loss: 0.165\n",
      "Training: Epoch 108, Batch 65, Loss: 0.147\n",
      "Training: Epoch 108, Batch 66, Loss: 0.102\n",
      "Training: Epoch 108, Batch 67, Loss: 0.199\n",
      "Training: Epoch 108, Batch 68, Loss: 0.188\n",
      "Training: Epoch 108, Batch 69, Loss: 0.153\n",
      "Training: Epoch 108, Batch 70, Loss: 0.186\n",
      "Training: Epoch 108, Batch 71, Loss: 0.142\n",
      "Training: Epoch 108, Batch 72, Loss: 0.198\n",
      "Training: Epoch 108, Batch 73, Loss: 0.167\n",
      "Training: Epoch 108, Batch 74, Loss: 0.156\n",
      "Training: Epoch 108, Batch 75, Loss: 0.182\n",
      "Training: Epoch 108, Batch 76, Loss: 0.182\n",
      "Training: Epoch 108, Batch 77, Loss: 0.127\n",
      "Training: Epoch 108, Batch 78, Loss: 0.122\n",
      "Training: Epoch 108, Batch 79, Loss: 0.172\n",
      "Training: Epoch 108, Batch 80, Loss: 0.148\n",
      "Training: Epoch 108, Batch 81, Loss: 0.157\n",
      "Training: Epoch 108, Batch 82, Loss: 0.148\n",
      "Training: Epoch 108, Batch 83, Loss: 0.096\n",
      "Training: Epoch 108, Batch 84, Loss: 0.148\n",
      "Training: Epoch 108, Batch 85, Loss: 0.165\n",
      "Training: Epoch 108, Batch 86, Loss: 0.123\n",
      "Training: Epoch 108, Batch 87, Loss: 0.181\n",
      "Training: Epoch 108, Batch 88, Loss: 0.103\n",
      "Training: Epoch 108, Batch 89, Loss: 0.159\n",
      "Val: Epoch 108, Loss: 0.282\n",
      "Training: Epoch 109, Batch 0, Loss: 0.096\n",
      "Training: Epoch 109, Batch 1, Loss: 0.153\n",
      "Training: Epoch 109, Batch 2, Loss: 0.114\n",
      "Training: Epoch 109, Batch 3, Loss: 0.139\n",
      "Training: Epoch 109, Batch 4, Loss: 0.128\n",
      "Training: Epoch 109, Batch 5, Loss: 0.145\n",
      "Training: Epoch 109, Batch 6, Loss: 0.157\n",
      "Training: Epoch 109, Batch 7, Loss: 0.139\n",
      "Training: Epoch 109, Batch 8, Loss: 0.134\n",
      "Training: Epoch 109, Batch 9, Loss: 0.127\n",
      "Training: Epoch 109, Batch 10, Loss: 0.166\n",
      "Training: Epoch 109, Batch 11, Loss: 0.149\n",
      "Training: Epoch 109, Batch 12, Loss: 0.145\n",
      "Training: Epoch 109, Batch 13, Loss: 0.158\n",
      "Training: Epoch 109, Batch 14, Loss: 0.138\n",
      "Training: Epoch 109, Batch 15, Loss: 0.131\n",
      "Training: Epoch 109, Batch 16, Loss: 0.095\n",
      "Training: Epoch 109, Batch 17, Loss: 0.153\n",
      "Training: Epoch 109, Batch 18, Loss: 0.138\n",
      "Training: Epoch 109, Batch 19, Loss: 0.122\n",
      "Training: Epoch 109, Batch 20, Loss: 0.158\n",
      "Training: Epoch 109, Batch 21, Loss: 0.108\n",
      "Training: Epoch 109, Batch 22, Loss: 0.117\n",
      "Training: Epoch 109, Batch 23, Loss: 0.186\n",
      "Training: Epoch 109, Batch 24, Loss: 0.129\n",
      "Training: Epoch 109, Batch 25, Loss: 0.1\n",
      "Training: Epoch 109, Batch 26, Loss: 0.137\n",
      "Training: Epoch 109, Batch 27, Loss: 0.161\n",
      "Training: Epoch 109, Batch 28, Loss: 0.115\n",
      "Training: Epoch 109, Batch 29, Loss: 0.164\n",
      "Training: Epoch 109, Batch 30, Loss: 0.152\n",
      "Training: Epoch 109, Batch 31, Loss: 0.094\n",
      "Training: Epoch 109, Batch 32, Loss: 0.211\n",
      "Training: Epoch 109, Batch 33, Loss: 0.103\n",
      "Training: Epoch 109, Batch 34, Loss: 0.139\n",
      "Training: Epoch 109, Batch 35, Loss: 0.122\n",
      "Training: Epoch 109, Batch 36, Loss: 0.205\n",
      "Training: Epoch 109, Batch 37, Loss: 0.163\n",
      "Training: Epoch 109, Batch 38, Loss: 0.165\n",
      "Training: Epoch 109, Batch 39, Loss: 0.166\n",
      "Training: Epoch 109, Batch 40, Loss: 0.19\n",
      "Training: Epoch 109, Batch 41, Loss: 0.129\n",
      "Training: Epoch 109, Batch 42, Loss: 0.126\n",
      "Training: Epoch 109, Batch 43, Loss: 0.201\n",
      "Training: Epoch 109, Batch 44, Loss: 0.149\n",
      "Training: Epoch 109, Batch 45, Loss: 0.166\n",
      "Training: Epoch 109, Batch 46, Loss: 0.11\n",
      "Training: Epoch 109, Batch 47, Loss: 0.139\n",
      "Training: Epoch 109, Batch 48, Loss: 0.148\n",
      "Training: Epoch 109, Batch 49, Loss: 0.094\n",
      "Training: Epoch 109, Batch 50, Loss: 0.232\n",
      "Training: Epoch 109, Batch 51, Loss: 0.197\n",
      "Training: Epoch 109, Batch 52, Loss: 0.217\n",
      "Training: Epoch 109, Batch 53, Loss: 0.127\n",
      "Training: Epoch 109, Batch 54, Loss: 0.135\n",
      "Training: Epoch 109, Batch 55, Loss: 0.103\n",
      "Training: Epoch 109, Batch 56, Loss: 0.159\n",
      "Training: Epoch 109, Batch 57, Loss: 0.128\n",
      "Training: Epoch 109, Batch 58, Loss: 0.106\n",
      "Training: Epoch 109, Batch 59, Loss: 0.15\n",
      "Training: Epoch 109, Batch 60, Loss: 0.156\n",
      "Training: Epoch 109, Batch 61, Loss: 0.136\n",
      "Training: Epoch 109, Batch 62, Loss: 0.151\n",
      "Training: Epoch 109, Batch 63, Loss: 0.146\n",
      "Training: Epoch 109, Batch 64, Loss: 0.12\n",
      "Training: Epoch 109, Batch 65, Loss: 0.2\n",
      "Training: Epoch 109, Batch 66, Loss: 0.115\n",
      "Training: Epoch 109, Batch 67, Loss: 0.178\n",
      "Training: Epoch 109, Batch 68, Loss: 0.094\n",
      "Training: Epoch 109, Batch 69, Loss: 0.16\n",
      "Training: Epoch 109, Batch 70, Loss: 0.17\n",
      "Training: Epoch 109, Batch 71, Loss: 0.116\n",
      "Training: Epoch 109, Batch 72, Loss: 0.147\n",
      "Training: Epoch 109, Batch 73, Loss: 0.139\n",
      "Training: Epoch 109, Batch 74, Loss: 0.092\n",
      "Training: Epoch 109, Batch 75, Loss: 0.213\n",
      "Training: Epoch 109, Batch 76, Loss: 0.134\n",
      "Training: Epoch 109, Batch 77, Loss: 0.131\n",
      "Training: Epoch 109, Batch 78, Loss: 0.195\n",
      "Training: Epoch 109, Batch 79, Loss: 0.12\n",
      "Training: Epoch 109, Batch 80, Loss: 0.11\n",
      "Training: Epoch 109, Batch 81, Loss: 0.168\n",
      "Training: Epoch 109, Batch 82, Loss: 0.189\n",
      "Training: Epoch 109, Batch 83, Loss: 0.167\n",
      "Training: Epoch 109, Batch 84, Loss: 0.129\n",
      "Training: Epoch 109, Batch 85, Loss: 0.174\n",
      "Training: Epoch 109, Batch 86, Loss: 0.125\n",
      "Training: Epoch 109, Batch 87, Loss: 0.147\n",
      "Training: Epoch 109, Batch 88, Loss: 0.163\n",
      "Training: Epoch 109, Batch 89, Loss: 0.217\n",
      "Val: Epoch 109, Loss: 0.267\n",
      "Training: Epoch 110, Batch 0, Loss: 0.118\n",
      "Training: Epoch 110, Batch 1, Loss: 0.166\n",
      "Training: Epoch 110, Batch 2, Loss: 0.116\n",
      "Training: Epoch 110, Batch 3, Loss: 0.173\n",
      "Training: Epoch 110, Batch 4, Loss: 0.122\n",
      "Training: Epoch 110, Batch 5, Loss: 0.146\n",
      "Training: Epoch 110, Batch 6, Loss: 0.107\n",
      "Training: Epoch 110, Batch 7, Loss: 0.106\n",
      "Training: Epoch 110, Batch 8, Loss: 0.125\n",
      "Training: Epoch 110, Batch 9, Loss: 0.119\n",
      "Training: Epoch 110, Batch 10, Loss: 0.128\n",
      "Training: Epoch 110, Batch 11, Loss: 0.166\n",
      "Training: Epoch 110, Batch 12, Loss: 0.159\n",
      "Training: Epoch 110, Batch 13, Loss: 0.148\n",
      "Training: Epoch 110, Batch 14, Loss: 0.114\n",
      "Training: Epoch 110, Batch 15, Loss: 0.131\n",
      "Training: Epoch 110, Batch 16, Loss: 0.188\n",
      "Training: Epoch 110, Batch 17, Loss: 0.121\n",
      "Training: Epoch 110, Batch 18, Loss: 0.136\n",
      "Training: Epoch 110, Batch 19, Loss: 0.178\n",
      "Training: Epoch 110, Batch 20, Loss: 0.121\n",
      "Training: Epoch 110, Batch 21, Loss: 0.16\n",
      "Training: Epoch 110, Batch 22, Loss: 0.108\n",
      "Training: Epoch 110, Batch 23, Loss: 0.141\n",
      "Training: Epoch 110, Batch 24, Loss: 0.12\n",
      "Training: Epoch 110, Batch 25, Loss: 0.141\n",
      "Training: Epoch 110, Batch 26, Loss: 0.137\n",
      "Training: Epoch 110, Batch 27, Loss: 0.15\n",
      "Training: Epoch 110, Batch 28, Loss: 0.121\n",
      "Training: Epoch 110, Batch 29, Loss: 0.143\n",
      "Training: Epoch 110, Batch 30, Loss: 0.137\n",
      "Training: Epoch 110, Batch 31, Loss: 0.133\n",
      "Training: Epoch 110, Batch 32, Loss: 0.183\n",
      "Training: Epoch 110, Batch 33, Loss: 0.164\n",
      "Training: Epoch 110, Batch 34, Loss: 0.149\n",
      "Training: Epoch 110, Batch 35, Loss: 0.242\n",
      "Training: Epoch 110, Batch 36, Loss: 0.124\n",
      "Training: Epoch 110, Batch 37, Loss: 0.165\n",
      "Training: Epoch 110, Batch 38, Loss: 0.147\n",
      "Training: Epoch 110, Batch 39, Loss: 0.212\n",
      "Training: Epoch 110, Batch 40, Loss: 0.142\n",
      "Training: Epoch 110, Batch 41, Loss: 0.142\n",
      "Training: Epoch 110, Batch 42, Loss: 0.122\n",
      "Training: Epoch 110, Batch 43, Loss: 0.139\n",
      "Training: Epoch 110, Batch 44, Loss: 0.122\n",
      "Training: Epoch 110, Batch 45, Loss: 0.171\n",
      "Training: Epoch 110, Batch 46, Loss: 0.187\n",
      "Training: Epoch 110, Batch 47, Loss: 0.147\n",
      "Training: Epoch 110, Batch 48, Loss: 0.184\n",
      "Training: Epoch 110, Batch 49, Loss: 0.151\n",
      "Training: Epoch 110, Batch 50, Loss: 0.149\n",
      "Training: Epoch 110, Batch 51, Loss: 0.135\n",
      "Training: Epoch 110, Batch 52, Loss: 0.145\n",
      "Training: Epoch 110, Batch 53, Loss: 0.126\n",
      "Training: Epoch 110, Batch 54, Loss: 0.107\n",
      "Training: Epoch 110, Batch 55, Loss: 0.164\n",
      "Training: Epoch 110, Batch 56, Loss: 0.153\n",
      "Training: Epoch 110, Batch 57, Loss: 0.145\n",
      "Training: Epoch 110, Batch 58, Loss: 0.141\n",
      "Training: Epoch 110, Batch 59, Loss: 0.161\n",
      "Training: Epoch 110, Batch 60, Loss: 0.126\n",
      "Training: Epoch 110, Batch 61, Loss: 0.131\n",
      "Training: Epoch 110, Batch 62, Loss: 0.119\n",
      "Training: Epoch 110, Batch 63, Loss: 0.171\n",
      "Training: Epoch 110, Batch 64, Loss: 0.154\n",
      "Training: Epoch 110, Batch 65, Loss: 0.13\n",
      "Training: Epoch 110, Batch 66, Loss: 0.128\n",
      "Training: Epoch 110, Batch 67, Loss: 0.339\n",
      "Training: Epoch 110, Batch 68, Loss: 0.146\n",
      "Training: Epoch 110, Batch 69, Loss: 0.178\n",
      "Training: Epoch 110, Batch 70, Loss: 0.098\n",
      "Training: Epoch 110, Batch 71, Loss: 0.18\n",
      "Training: Epoch 110, Batch 72, Loss: 0.126\n",
      "Training: Epoch 110, Batch 73, Loss: 0.154\n",
      "Training: Epoch 110, Batch 74, Loss: 0.114\n",
      "Training: Epoch 110, Batch 75, Loss: 0.117\n",
      "Training: Epoch 110, Batch 76, Loss: 0.089\n",
      "Training: Epoch 110, Batch 77, Loss: 0.235\n",
      "Training: Epoch 110, Batch 78, Loss: 0.165\n",
      "Training: Epoch 110, Batch 79, Loss: 0.178\n",
      "Training: Epoch 110, Batch 80, Loss: 0.162\n",
      "Training: Epoch 110, Batch 81, Loss: 0.21\n",
      "Training: Epoch 110, Batch 82, Loss: 0.109\n",
      "Training: Epoch 110, Batch 83, Loss: 0.167\n",
      "Training: Epoch 110, Batch 84, Loss: 0.135\n",
      "Training: Epoch 110, Batch 85, Loss: 0.161\n",
      "Training: Epoch 110, Batch 86, Loss: 0.138\n",
      "Training: Epoch 110, Batch 87, Loss: 0.154\n",
      "Training: Epoch 110, Batch 88, Loss: 0.144\n",
      "Training: Epoch 110, Batch 89, Loss: 0.12\n",
      "Val: Epoch 110, Loss: 0.258\n",
      "Training: Epoch 111, Batch 0, Loss: 0.14\n",
      "Training: Epoch 111, Batch 1, Loss: 0.133\n",
      "Training: Epoch 111, Batch 2, Loss: 0.126\n",
      "Training: Epoch 111, Batch 3, Loss: 0.116\n",
      "Training: Epoch 111, Batch 4, Loss: 0.152\n",
      "Training: Epoch 111, Batch 5, Loss: 0.119\n",
      "Training: Epoch 111, Batch 6, Loss: 0.126\n",
      "Training: Epoch 111, Batch 7, Loss: 0.128\n",
      "Training: Epoch 111, Batch 8, Loss: 0.175\n",
      "Training: Epoch 111, Batch 9, Loss: 0.095\n",
      "Training: Epoch 111, Batch 10, Loss: 0.134\n",
      "Training: Epoch 111, Batch 11, Loss: 0.13\n",
      "Training: Epoch 111, Batch 12, Loss: 0.192\n",
      "Training: Epoch 111, Batch 13, Loss: 0.097\n",
      "Training: Epoch 111, Batch 14, Loss: 0.123\n",
      "Training: Epoch 111, Batch 15, Loss: 0.108\n",
      "Training: Epoch 111, Batch 16, Loss: 0.152\n",
      "Training: Epoch 111, Batch 17, Loss: 0.139\n",
      "Training: Epoch 111, Batch 18, Loss: 0.167\n",
      "Training: Epoch 111, Batch 19, Loss: 0.169\n",
      "Training: Epoch 111, Batch 20, Loss: 0.147\n",
      "Training: Epoch 111, Batch 21, Loss: 0.174\n",
      "Training: Epoch 111, Batch 22, Loss: 0.114\n",
      "Training: Epoch 111, Batch 23, Loss: 0.165\n",
      "Training: Epoch 111, Batch 24, Loss: 0.137\n",
      "Training: Epoch 111, Batch 25, Loss: 0.147\n",
      "Training: Epoch 111, Batch 26, Loss: 0.12\n",
      "Training: Epoch 111, Batch 27, Loss: 0.121\n",
      "Training: Epoch 111, Batch 28, Loss: 0.135\n",
      "Training: Epoch 111, Batch 29, Loss: 0.149\n",
      "Training: Epoch 111, Batch 30, Loss: 0.137\n",
      "Training: Epoch 111, Batch 31, Loss: 0.119\n",
      "Training: Epoch 111, Batch 32, Loss: 0.167\n",
      "Training: Epoch 111, Batch 33, Loss: 0.162\n",
      "Training: Epoch 111, Batch 34, Loss: 0.105\n",
      "Training: Epoch 111, Batch 35, Loss: 0.169\n",
      "Training: Epoch 111, Batch 36, Loss: 0.128\n",
      "Training: Epoch 111, Batch 37, Loss: 0.147\n",
      "Training: Epoch 111, Batch 38, Loss: 0.135\n",
      "Training: Epoch 111, Batch 39, Loss: 0.125\n",
      "Training: Epoch 111, Batch 40, Loss: 0.121\n",
      "Training: Epoch 111, Batch 41, Loss: 0.168\n",
      "Training: Epoch 111, Batch 42, Loss: 0.171\n",
      "Training: Epoch 111, Batch 43, Loss: 0.119\n",
      "Training: Epoch 111, Batch 44, Loss: 0.109\n",
      "Training: Epoch 111, Batch 45, Loss: 0.148\n",
      "Training: Epoch 111, Batch 46, Loss: 0.116\n",
      "Training: Epoch 111, Batch 47, Loss: 0.137\n",
      "Training: Epoch 111, Batch 48, Loss: 0.149\n",
      "Training: Epoch 111, Batch 49, Loss: 0.109\n",
      "Training: Epoch 111, Batch 50, Loss: 0.156\n",
      "Training: Epoch 111, Batch 51, Loss: 0.157\n",
      "Training: Epoch 111, Batch 52, Loss: 0.133\n",
      "Training: Epoch 111, Batch 53, Loss: 0.212\n",
      "Training: Epoch 111, Batch 54, Loss: 0.098\n",
      "Training: Epoch 111, Batch 55, Loss: 0.178\n",
      "Training: Epoch 111, Batch 56, Loss: 0.112\n",
      "Training: Epoch 111, Batch 57, Loss: 0.128\n",
      "Training: Epoch 111, Batch 58, Loss: 0.111\n",
      "Training: Epoch 111, Batch 59, Loss: 0.167\n",
      "Training: Epoch 111, Batch 60, Loss: 0.095\n",
      "Training: Epoch 111, Batch 61, Loss: 0.148\n",
      "Training: Epoch 111, Batch 62, Loss: 0.182\n",
      "Training: Epoch 111, Batch 63, Loss: 0.159\n",
      "Training: Epoch 111, Batch 64, Loss: 0.151\n",
      "Training: Epoch 111, Batch 65, Loss: 0.148\n",
      "Training: Epoch 111, Batch 66, Loss: 0.117\n",
      "Training: Epoch 111, Batch 67, Loss: 0.117\n",
      "Training: Epoch 111, Batch 68, Loss: 0.131\n",
      "Training: Epoch 111, Batch 69, Loss: 0.132\n",
      "Training: Epoch 111, Batch 70, Loss: 0.131\n",
      "Training: Epoch 111, Batch 71, Loss: 0.175\n",
      "Training: Epoch 111, Batch 72, Loss: 0.179\n",
      "Training: Epoch 111, Batch 73, Loss: 0.154\n",
      "Training: Epoch 111, Batch 74, Loss: 0.209\n",
      "Training: Epoch 111, Batch 75, Loss: 0.142\n",
      "Training: Epoch 111, Batch 76, Loss: 0.195\n",
      "Training: Epoch 111, Batch 77, Loss: 0.147\n",
      "Training: Epoch 111, Batch 78, Loss: 0.15\n",
      "Training: Epoch 111, Batch 79, Loss: 0.146\n",
      "Training: Epoch 111, Batch 80, Loss: 0.182\n",
      "Training: Epoch 111, Batch 81, Loss: 0.116\n",
      "Training: Epoch 111, Batch 82, Loss: 0.151\n",
      "Training: Epoch 111, Batch 83, Loss: 0.136\n",
      "Training: Epoch 111, Batch 84, Loss: 0.146\n",
      "Training: Epoch 111, Batch 85, Loss: 0.109\n",
      "Training: Epoch 111, Batch 86, Loss: 0.135\n",
      "Training: Epoch 111, Batch 87, Loss: 0.114\n",
      "Training: Epoch 111, Batch 88, Loss: 0.139\n",
      "Training: Epoch 111, Batch 89, Loss: 0.108\n",
      "Val: Epoch 111, Loss: 0.313\n",
      "Training: Epoch 112, Batch 0, Loss: 0.135\n",
      "Training: Epoch 112, Batch 1, Loss: 0.169\n",
      "Training: Epoch 112, Batch 2, Loss: 0.136\n",
      "Training: Epoch 112, Batch 3, Loss: 0.127\n",
      "Training: Epoch 112, Batch 4, Loss: 0.109\n",
      "Training: Epoch 112, Batch 5, Loss: 0.115\n",
      "Training: Epoch 112, Batch 6, Loss: 0.189\n",
      "Training: Epoch 112, Batch 7, Loss: 0.116\n",
      "Training: Epoch 112, Batch 8, Loss: 0.173\n",
      "Training: Epoch 112, Batch 9, Loss: 0.131\n",
      "Training: Epoch 112, Batch 10, Loss: 0.159\n",
      "Training: Epoch 112, Batch 11, Loss: 0.161\n",
      "Training: Epoch 112, Batch 12, Loss: 0.139\n",
      "Training: Epoch 112, Batch 13, Loss: 0.16\n",
      "Training: Epoch 112, Batch 14, Loss: 0.099\n",
      "Training: Epoch 112, Batch 15, Loss: 0.133\n",
      "Training: Epoch 112, Batch 16, Loss: 0.122\n",
      "Training: Epoch 112, Batch 17, Loss: 0.161\n",
      "Training: Epoch 112, Batch 18, Loss: 0.141\n",
      "Training: Epoch 112, Batch 19, Loss: 0.134\n",
      "Training: Epoch 112, Batch 20, Loss: 0.135\n",
      "Training: Epoch 112, Batch 21, Loss: 0.156\n",
      "Training: Epoch 112, Batch 22, Loss: 0.198\n",
      "Training: Epoch 112, Batch 23, Loss: 0.171\n",
      "Training: Epoch 112, Batch 24, Loss: 0.13\n",
      "Training: Epoch 112, Batch 25, Loss: 0.117\n",
      "Training: Epoch 112, Batch 26, Loss: 0.167\n",
      "Training: Epoch 112, Batch 27, Loss: 0.19\n",
      "Training: Epoch 112, Batch 28, Loss: 0.134\n",
      "Training: Epoch 112, Batch 29, Loss: 0.109\n",
      "Training: Epoch 112, Batch 30, Loss: 0.109\n",
      "Training: Epoch 112, Batch 31, Loss: 0.106\n",
      "Training: Epoch 112, Batch 32, Loss: 0.134\n",
      "Training: Epoch 112, Batch 33, Loss: 0.15\n",
      "Training: Epoch 112, Batch 34, Loss: 0.123\n",
      "Training: Epoch 112, Batch 35, Loss: 0.144\n",
      "Training: Epoch 112, Batch 36, Loss: 0.095\n",
      "Training: Epoch 112, Batch 37, Loss: 0.112\n",
      "Training: Epoch 112, Batch 38, Loss: 0.102\n",
      "Training: Epoch 112, Batch 39, Loss: 0.108\n",
      "Training: Epoch 112, Batch 40, Loss: 0.165\n",
      "Training: Epoch 112, Batch 41, Loss: 0.151\n",
      "Training: Epoch 112, Batch 42, Loss: 0.12\n",
      "Training: Epoch 112, Batch 43, Loss: 0.148\n",
      "Training: Epoch 112, Batch 44, Loss: 0.125\n",
      "Training: Epoch 112, Batch 45, Loss: 0.17\n",
      "Training: Epoch 112, Batch 46, Loss: 0.203\n",
      "Training: Epoch 112, Batch 47, Loss: 0.124\n",
      "Training: Epoch 112, Batch 48, Loss: 0.131\n",
      "Training: Epoch 112, Batch 49, Loss: 0.152\n",
      "Training: Epoch 112, Batch 50, Loss: 0.106\n",
      "Training: Epoch 112, Batch 51, Loss: 0.141\n",
      "Training: Epoch 112, Batch 52, Loss: 0.163\n",
      "Training: Epoch 112, Batch 53, Loss: 0.151\n",
      "Training: Epoch 112, Batch 54, Loss: 0.149\n",
      "Training: Epoch 112, Batch 55, Loss: 0.117\n",
      "Training: Epoch 112, Batch 56, Loss: 0.114\n",
      "Training: Epoch 112, Batch 57, Loss: 0.139\n",
      "Training: Epoch 112, Batch 58, Loss: 0.128\n",
      "Training: Epoch 112, Batch 59, Loss: 0.108\n",
      "Training: Epoch 112, Batch 60, Loss: 0.131\n",
      "Training: Epoch 112, Batch 61, Loss: 0.156\n",
      "Training: Epoch 112, Batch 62, Loss: 0.167\n",
      "Training: Epoch 112, Batch 63, Loss: 0.176\n",
      "Training: Epoch 112, Batch 64, Loss: 0.148\n",
      "Training: Epoch 112, Batch 65, Loss: 0.124\n",
      "Training: Epoch 112, Batch 66, Loss: 0.146\n",
      "Training: Epoch 112, Batch 67, Loss: 0.126\n",
      "Training: Epoch 112, Batch 68, Loss: 0.116\n",
      "Training: Epoch 112, Batch 69, Loss: 0.128\n",
      "Training: Epoch 112, Batch 70, Loss: 0.159\n",
      "Training: Epoch 112, Batch 71, Loss: 0.181\n",
      "Training: Epoch 112, Batch 72, Loss: 0.181\n",
      "Training: Epoch 112, Batch 73, Loss: 0.172\n",
      "Training: Epoch 112, Batch 74, Loss: 0.177\n",
      "Training: Epoch 112, Batch 75, Loss: 0.165\n",
      "Training: Epoch 112, Batch 76, Loss: 0.136\n",
      "Training: Epoch 112, Batch 77, Loss: 0.12\n",
      "Training: Epoch 112, Batch 78, Loss: 0.117\n",
      "Training: Epoch 112, Batch 79, Loss: 0.147\n",
      "Training: Epoch 112, Batch 80, Loss: 0.18\n",
      "Training: Epoch 112, Batch 81, Loss: 0.15\n",
      "Training: Epoch 112, Batch 82, Loss: 0.188\n",
      "Training: Epoch 112, Batch 83, Loss: 0.129\n",
      "Training: Epoch 112, Batch 84, Loss: 0.105\n",
      "Training: Epoch 112, Batch 85, Loss: 0.137\n",
      "Training: Epoch 112, Batch 86, Loss: 0.183\n",
      "Training: Epoch 112, Batch 87, Loss: 0.156\n",
      "Training: Epoch 112, Batch 88, Loss: 0.1\n",
      "Training: Epoch 112, Batch 89, Loss: 0.163\n",
      "Val: Epoch 112, Loss: 0.262\n",
      "Training: Epoch 113, Batch 0, Loss: 0.149\n",
      "Training: Epoch 113, Batch 1, Loss: 0.089\n",
      "Training: Epoch 113, Batch 2, Loss: 0.218\n",
      "Training: Epoch 113, Batch 3, Loss: 0.15\n",
      "Training: Epoch 113, Batch 4, Loss: 0.104\n",
      "Training: Epoch 113, Batch 5, Loss: 0.118\n",
      "Training: Epoch 113, Batch 6, Loss: 0.113\n",
      "Training: Epoch 113, Batch 7, Loss: 0.148\n",
      "Training: Epoch 113, Batch 8, Loss: 0.122\n",
      "Training: Epoch 113, Batch 9, Loss: 0.134\n",
      "Training: Epoch 113, Batch 10, Loss: 0.148\n",
      "Training: Epoch 113, Batch 11, Loss: 0.12\n",
      "Training: Epoch 113, Batch 12, Loss: 0.158\n",
      "Training: Epoch 113, Batch 13, Loss: 0.127\n",
      "Training: Epoch 113, Batch 14, Loss: 0.11\n",
      "Training: Epoch 113, Batch 15, Loss: 0.111\n",
      "Training: Epoch 113, Batch 16, Loss: 0.101\n",
      "Training: Epoch 113, Batch 17, Loss: 0.128\n",
      "Training: Epoch 113, Batch 18, Loss: 0.156\n",
      "Training: Epoch 113, Batch 19, Loss: 0.167\n",
      "Training: Epoch 113, Batch 20, Loss: 0.155\n",
      "Training: Epoch 113, Batch 21, Loss: 0.156\n",
      "Training: Epoch 113, Batch 22, Loss: 0.111\n",
      "Training: Epoch 113, Batch 23, Loss: 0.164\n",
      "Training: Epoch 113, Batch 24, Loss: 0.142\n",
      "Training: Epoch 113, Batch 25, Loss: 0.126\n",
      "Training: Epoch 113, Batch 26, Loss: 0.12\n",
      "Training: Epoch 113, Batch 27, Loss: 0.161\n",
      "Training: Epoch 113, Batch 28, Loss: 0.16\n",
      "Training: Epoch 113, Batch 29, Loss: 0.133\n",
      "Training: Epoch 113, Batch 30, Loss: 0.123\n",
      "Training: Epoch 113, Batch 31, Loss: 0.095\n",
      "Training: Epoch 113, Batch 32, Loss: 0.195\n",
      "Training: Epoch 113, Batch 33, Loss: 0.13\n",
      "Training: Epoch 113, Batch 34, Loss: 0.117\n",
      "Training: Epoch 113, Batch 35, Loss: 0.101\n",
      "Training: Epoch 113, Batch 36, Loss: 0.126\n",
      "Training: Epoch 113, Batch 37, Loss: 0.207\n",
      "Training: Epoch 113, Batch 38, Loss: 0.166\n",
      "Training: Epoch 113, Batch 39, Loss: 0.199\n",
      "Training: Epoch 113, Batch 40, Loss: 0.151\n",
      "Training: Epoch 113, Batch 41, Loss: 0.184\n",
      "Training: Epoch 113, Batch 42, Loss: 0.123\n",
      "Training: Epoch 113, Batch 43, Loss: 0.146\n",
      "Training: Epoch 113, Batch 44, Loss: 0.118\n",
      "Training: Epoch 113, Batch 45, Loss: 0.171\n",
      "Training: Epoch 113, Batch 46, Loss: 0.154\n",
      "Training: Epoch 113, Batch 47, Loss: 0.189\n",
      "Training: Epoch 113, Batch 48, Loss: 0.154\n",
      "Training: Epoch 113, Batch 49, Loss: 0.123\n",
      "Training: Epoch 113, Batch 50, Loss: 0.122\n",
      "Training: Epoch 113, Batch 51, Loss: 0.241\n",
      "Training: Epoch 113, Batch 52, Loss: 0.116\n",
      "Training: Epoch 113, Batch 53, Loss: 0.179\n",
      "Training: Epoch 113, Batch 54, Loss: 0.136\n",
      "Training: Epoch 113, Batch 55, Loss: 0.13\n",
      "Training: Epoch 113, Batch 56, Loss: 0.183\n",
      "Training: Epoch 113, Batch 57, Loss: 0.158\n",
      "Training: Epoch 113, Batch 58, Loss: 0.147\n",
      "Training: Epoch 113, Batch 59, Loss: 0.139\n",
      "Training: Epoch 113, Batch 60, Loss: 0.101\n",
      "Training: Epoch 113, Batch 61, Loss: 0.149\n",
      "Training: Epoch 113, Batch 62, Loss: 0.136\n",
      "Training: Epoch 113, Batch 63, Loss: 0.193\n",
      "Training: Epoch 113, Batch 64, Loss: 0.124\n",
      "Training: Epoch 113, Batch 65, Loss: 0.155\n",
      "Training: Epoch 113, Batch 66, Loss: 0.133\n",
      "Training: Epoch 113, Batch 67, Loss: 0.13\n",
      "Training: Epoch 113, Batch 68, Loss: 0.114\n",
      "Training: Epoch 113, Batch 69, Loss: 0.128\n",
      "Training: Epoch 113, Batch 70, Loss: 0.154\n",
      "Training: Epoch 113, Batch 71, Loss: 0.128\n",
      "Training: Epoch 113, Batch 72, Loss: 0.175\n",
      "Training: Epoch 113, Batch 73, Loss: 0.136\n",
      "Training: Epoch 113, Batch 74, Loss: 0.164\n",
      "Training: Epoch 113, Batch 75, Loss: 0.108\n",
      "Training: Epoch 113, Batch 76, Loss: 0.135\n",
      "Training: Epoch 113, Batch 77, Loss: 0.143\n",
      "Training: Epoch 113, Batch 78, Loss: 0.138\n",
      "Training: Epoch 113, Batch 79, Loss: 0.128\n",
      "Training: Epoch 113, Batch 80, Loss: 0.119\n",
      "Training: Epoch 113, Batch 81, Loss: 0.196\n",
      "Training: Epoch 113, Batch 82, Loss: 0.21\n",
      "Training: Epoch 113, Batch 83, Loss: 0.132\n",
      "Training: Epoch 113, Batch 84, Loss: 0.149\n",
      "Training: Epoch 113, Batch 85, Loss: 0.11\n",
      "Training: Epoch 113, Batch 86, Loss: 0.13\n",
      "Training: Epoch 113, Batch 87, Loss: 0.128\n",
      "Training: Epoch 113, Batch 88, Loss: 0.118\n",
      "Training: Epoch 113, Batch 89, Loss: 0.103\n",
      "Val: Epoch 113, Loss: 0.249\n",
      "Training: Epoch 114, Batch 0, Loss: 0.112\n",
      "Training: Epoch 114, Batch 1, Loss: 0.231\n",
      "Training: Epoch 114, Batch 2, Loss: 0.118\n",
      "Training: Epoch 114, Batch 3, Loss: 0.159\n",
      "Training: Epoch 114, Batch 4, Loss: 0.144\n",
      "Training: Epoch 114, Batch 5, Loss: 0.171\n",
      "Training: Epoch 114, Batch 6, Loss: 0.127\n",
      "Training: Epoch 114, Batch 7, Loss: 0.175\n",
      "Training: Epoch 114, Batch 8, Loss: 0.119\n",
      "Training: Epoch 114, Batch 9, Loss: 0.12\n",
      "Training: Epoch 114, Batch 10, Loss: 0.145\n",
      "Training: Epoch 114, Batch 11, Loss: 0.177\n",
      "Training: Epoch 114, Batch 12, Loss: 0.124\n",
      "Training: Epoch 114, Batch 13, Loss: 0.145\n",
      "Training: Epoch 114, Batch 14, Loss: 0.169\n",
      "Training: Epoch 114, Batch 15, Loss: 0.149\n",
      "Training: Epoch 114, Batch 16, Loss: 0.131\n",
      "Training: Epoch 114, Batch 17, Loss: 0.116\n",
      "Training: Epoch 114, Batch 18, Loss: 0.136\n",
      "Training: Epoch 114, Batch 19, Loss: 0.116\n",
      "Training: Epoch 114, Batch 20, Loss: 0.124\n",
      "Training: Epoch 114, Batch 21, Loss: 0.18\n",
      "Training: Epoch 114, Batch 22, Loss: 0.143\n",
      "Training: Epoch 114, Batch 23, Loss: 0.155\n",
      "Training: Epoch 114, Batch 24, Loss: 0.126\n",
      "Training: Epoch 114, Batch 25, Loss: 0.12\n",
      "Training: Epoch 114, Batch 26, Loss: 0.133\n",
      "Training: Epoch 114, Batch 27, Loss: 0.171\n",
      "Training: Epoch 114, Batch 28, Loss: 0.11\n",
      "Training: Epoch 114, Batch 29, Loss: 0.154\n",
      "Training: Epoch 114, Batch 30, Loss: 0.13\n",
      "Training: Epoch 114, Batch 31, Loss: 0.102\n",
      "Training: Epoch 114, Batch 32, Loss: 0.144\n",
      "Training: Epoch 114, Batch 33, Loss: 0.143\n",
      "Training: Epoch 114, Batch 34, Loss: 0.126\n",
      "Training: Epoch 114, Batch 35, Loss: 0.122\n",
      "Training: Epoch 114, Batch 36, Loss: 0.156\n",
      "Training: Epoch 114, Batch 37, Loss: 0.117\n",
      "Training: Epoch 114, Batch 38, Loss: 0.129\n",
      "Training: Epoch 114, Batch 39, Loss: 0.177\n",
      "Training: Epoch 114, Batch 40, Loss: 0.134\n",
      "Training: Epoch 114, Batch 41, Loss: 0.167\n",
      "Training: Epoch 114, Batch 42, Loss: 0.163\n",
      "Training: Epoch 114, Batch 43, Loss: 0.153\n",
      "Training: Epoch 114, Batch 44, Loss: 0.134\n",
      "Training: Epoch 114, Batch 45, Loss: 0.142\n",
      "Training: Epoch 114, Batch 46, Loss: 0.146\n",
      "Training: Epoch 114, Batch 47, Loss: 0.133\n",
      "Training: Epoch 114, Batch 48, Loss: 0.119\n",
      "Training: Epoch 114, Batch 49, Loss: 0.127\n",
      "Training: Epoch 114, Batch 50, Loss: 0.149\n",
      "Training: Epoch 114, Batch 51, Loss: 0.163\n",
      "Training: Epoch 114, Batch 52, Loss: 0.17\n",
      "Training: Epoch 114, Batch 53, Loss: 0.114\n",
      "Training: Epoch 114, Batch 54, Loss: 0.155\n",
      "Training: Epoch 114, Batch 55, Loss: 0.141\n",
      "Training: Epoch 114, Batch 56, Loss: 0.118\n",
      "Training: Epoch 114, Batch 57, Loss: 0.098\n",
      "Training: Epoch 114, Batch 58, Loss: 0.097\n",
      "Training: Epoch 114, Batch 59, Loss: 0.125\n",
      "Training: Epoch 114, Batch 60, Loss: 0.164\n",
      "Training: Epoch 114, Batch 61, Loss: 0.21\n",
      "Training: Epoch 114, Batch 62, Loss: 0.121\n",
      "Training: Epoch 114, Batch 63, Loss: 0.104\n",
      "Training: Epoch 114, Batch 64, Loss: 0.138\n",
      "Training: Epoch 114, Batch 65, Loss: 0.122\n",
      "Training: Epoch 114, Batch 66, Loss: 0.121\n",
      "Training: Epoch 114, Batch 67, Loss: 0.165\n",
      "Training: Epoch 114, Batch 68, Loss: 0.17\n",
      "Training: Epoch 114, Batch 69, Loss: 0.139\n",
      "Training: Epoch 114, Batch 70, Loss: 0.148\n",
      "Training: Epoch 114, Batch 71, Loss: 0.114\n",
      "Training: Epoch 114, Batch 72, Loss: 0.148\n",
      "Training: Epoch 114, Batch 73, Loss: 0.124\n",
      "Training: Epoch 114, Batch 74, Loss: 0.098\n",
      "Training: Epoch 114, Batch 75, Loss: 0.116\n",
      "Training: Epoch 114, Batch 76, Loss: 0.208\n",
      "Training: Epoch 114, Batch 77, Loss: 0.168\n",
      "Training: Epoch 114, Batch 78, Loss: 0.097\n",
      "Training: Epoch 114, Batch 79, Loss: 0.1\n",
      "Training: Epoch 114, Batch 80, Loss: 0.14\n",
      "Training: Epoch 114, Batch 81, Loss: 0.109\n",
      "Training: Epoch 114, Batch 82, Loss: 0.211\n",
      "Training: Epoch 114, Batch 83, Loss: 0.117\n",
      "Training: Epoch 114, Batch 84, Loss: 0.142\n",
      "Training: Epoch 114, Batch 85, Loss: 0.125\n",
      "Training: Epoch 114, Batch 86, Loss: 0.106\n",
      "Training: Epoch 114, Batch 87, Loss: 0.127\n",
      "Training: Epoch 114, Batch 88, Loss: 0.087\n",
      "Training: Epoch 114, Batch 89, Loss: 0.16\n",
      "Val: Epoch 114, Loss: 0.277\n",
      "Training: Epoch 115, Batch 0, Loss: 0.122\n",
      "Training: Epoch 115, Batch 1, Loss: 0.187\n",
      "Training: Epoch 115, Batch 2, Loss: 0.179\n",
      "Training: Epoch 115, Batch 3, Loss: 0.13\n",
      "Training: Epoch 115, Batch 4, Loss: 0.173\n",
      "Training: Epoch 115, Batch 5, Loss: 0.204\n",
      "Training: Epoch 115, Batch 6, Loss: 0.129\n",
      "Training: Epoch 115, Batch 7, Loss: 0.146\n",
      "Training: Epoch 115, Batch 8, Loss: 0.137\n",
      "Training: Epoch 115, Batch 9, Loss: 0.092\n",
      "Training: Epoch 115, Batch 10, Loss: 0.154\n",
      "Training: Epoch 115, Batch 11, Loss: 0.132\n",
      "Training: Epoch 115, Batch 12, Loss: 0.131\n",
      "Training: Epoch 115, Batch 13, Loss: 0.139\n",
      "Training: Epoch 115, Batch 14, Loss: 0.111\n",
      "Training: Epoch 115, Batch 15, Loss: 0.156\n",
      "Training: Epoch 115, Batch 16, Loss: 0.156\n",
      "Training: Epoch 115, Batch 17, Loss: 0.112\n",
      "Training: Epoch 115, Batch 18, Loss: 0.157\n",
      "Training: Epoch 115, Batch 19, Loss: 0.105\n",
      "Training: Epoch 115, Batch 20, Loss: 0.12\n",
      "Training: Epoch 115, Batch 21, Loss: 0.169\n",
      "Training: Epoch 115, Batch 22, Loss: 0.135\n",
      "Training: Epoch 115, Batch 23, Loss: 0.102\n",
      "Training: Epoch 115, Batch 24, Loss: 0.113\n",
      "Training: Epoch 115, Batch 25, Loss: 0.192\n",
      "Training: Epoch 115, Batch 26, Loss: 0.104\n",
      "Training: Epoch 115, Batch 27, Loss: 0.12\n",
      "Training: Epoch 115, Batch 28, Loss: 0.142\n",
      "Training: Epoch 115, Batch 29, Loss: 0.122\n",
      "Training: Epoch 115, Batch 30, Loss: 0.196\n",
      "Training: Epoch 115, Batch 31, Loss: 0.106\n",
      "Training: Epoch 115, Batch 32, Loss: 0.15\n",
      "Training: Epoch 115, Batch 33, Loss: 0.121\n",
      "Training: Epoch 115, Batch 34, Loss: 0.099\n",
      "Training: Epoch 115, Batch 35, Loss: 0.114\n",
      "Training: Epoch 115, Batch 36, Loss: 0.14\n",
      "Training: Epoch 115, Batch 37, Loss: 0.165\n",
      "Training: Epoch 115, Batch 38, Loss: 0.114\n",
      "Training: Epoch 115, Batch 39, Loss: 0.109\n",
      "Training: Epoch 115, Batch 40, Loss: 0.11\n",
      "Training: Epoch 115, Batch 41, Loss: 0.152\n",
      "Training: Epoch 115, Batch 42, Loss: 0.205\n",
      "Training: Epoch 115, Batch 43, Loss: 0.153\n",
      "Training: Epoch 115, Batch 44, Loss: 0.118\n",
      "Training: Epoch 115, Batch 45, Loss: 0.14\n",
      "Training: Epoch 115, Batch 46, Loss: 0.134\n",
      "Training: Epoch 115, Batch 47, Loss: 0.122\n",
      "Training: Epoch 115, Batch 48, Loss: 0.091\n",
      "Training: Epoch 115, Batch 49, Loss: 0.132\n",
      "Training: Epoch 115, Batch 50, Loss: 0.151\n",
      "Training: Epoch 115, Batch 51, Loss: 0.213\n",
      "Training: Epoch 115, Batch 52, Loss: 0.133\n",
      "Training: Epoch 115, Batch 53, Loss: 0.15\n",
      "Training: Epoch 115, Batch 54, Loss: 0.131\n",
      "Training: Epoch 115, Batch 55, Loss: 0.169\n",
      "Training: Epoch 115, Batch 56, Loss: 0.124\n",
      "Training: Epoch 115, Batch 57, Loss: 0.223\n",
      "Training: Epoch 115, Batch 58, Loss: 0.193\n",
      "Training: Epoch 115, Batch 59, Loss: 0.175\n",
      "Training: Epoch 115, Batch 60, Loss: 0.125\n",
      "Training: Epoch 115, Batch 61, Loss: 0.156\n",
      "Training: Epoch 115, Batch 62, Loss: 0.181\n",
      "Training: Epoch 115, Batch 63, Loss: 0.118\n",
      "Training: Epoch 115, Batch 64, Loss: 0.11\n",
      "Training: Epoch 115, Batch 65, Loss: 0.13\n",
      "Training: Epoch 115, Batch 66, Loss: 0.215\n",
      "Training: Epoch 115, Batch 67, Loss: 0.111\n",
      "Training: Epoch 115, Batch 68, Loss: 0.085\n",
      "Training: Epoch 115, Batch 69, Loss: 0.165\n",
      "Training: Epoch 115, Batch 70, Loss: 0.163\n",
      "Training: Epoch 115, Batch 71, Loss: 0.193\n",
      "Training: Epoch 115, Batch 72, Loss: 0.139\n",
      "Training: Epoch 115, Batch 73, Loss: 0.118\n",
      "Training: Epoch 115, Batch 74, Loss: 0.125\n",
      "Training: Epoch 115, Batch 75, Loss: 0.127\n",
      "Training: Epoch 115, Batch 76, Loss: 0.117\n",
      "Training: Epoch 115, Batch 77, Loss: 0.168\n",
      "Training: Epoch 115, Batch 78, Loss: 0.147\n",
      "Training: Epoch 115, Batch 79, Loss: 0.133\n",
      "Training: Epoch 115, Batch 80, Loss: 0.13\n",
      "Training: Epoch 115, Batch 81, Loss: 0.195\n",
      "Training: Epoch 115, Batch 82, Loss: 0.127\n",
      "Training: Epoch 115, Batch 83, Loss: 0.099\n",
      "Training: Epoch 115, Batch 84, Loss: 0.147\n",
      "Training: Epoch 115, Batch 85, Loss: 0.124\n",
      "Training: Epoch 115, Batch 86, Loss: 0.151\n",
      "Training: Epoch 115, Batch 87, Loss: 0.158\n",
      "Training: Epoch 115, Batch 88, Loss: 0.131\n",
      "Training: Epoch 115, Batch 89, Loss: 0.108\n",
      "Val: Epoch 115, Loss: 0.305\n",
      "Training: Epoch 116, Batch 0, Loss: 0.154\n",
      "Training: Epoch 116, Batch 1, Loss: 0.133\n",
      "Training: Epoch 116, Batch 2, Loss: 0.145\n",
      "Training: Epoch 116, Batch 3, Loss: 0.164\n",
      "Training: Epoch 116, Batch 4, Loss: 0.133\n",
      "Training: Epoch 116, Batch 5, Loss: 0.119\n",
      "Training: Epoch 116, Batch 6, Loss: 0.11\n",
      "Training: Epoch 116, Batch 7, Loss: 0.152\n",
      "Training: Epoch 116, Batch 8, Loss: 0.127\n",
      "Training: Epoch 116, Batch 9, Loss: 0.116\n",
      "Training: Epoch 116, Batch 10, Loss: 0.088\n",
      "Training: Epoch 116, Batch 11, Loss: 0.129\n",
      "Training: Epoch 116, Batch 12, Loss: 0.154\n",
      "Training: Epoch 116, Batch 13, Loss: 0.127\n",
      "Training: Epoch 116, Batch 14, Loss: 0.093\n",
      "Training: Epoch 116, Batch 15, Loss: 0.086\n",
      "Training: Epoch 116, Batch 16, Loss: 0.082\n",
      "Training: Epoch 116, Batch 17, Loss: 0.195\n",
      "Training: Epoch 116, Batch 18, Loss: 0.107\n",
      "Training: Epoch 116, Batch 19, Loss: 0.13\n",
      "Training: Epoch 116, Batch 20, Loss: 0.126\n",
      "Training: Epoch 116, Batch 21, Loss: 0.151\n",
      "Training: Epoch 116, Batch 22, Loss: 0.147\n",
      "Training: Epoch 116, Batch 23, Loss: 0.152\n",
      "Training: Epoch 116, Batch 24, Loss: 0.138\n",
      "Training: Epoch 116, Batch 25, Loss: 0.118\n",
      "Training: Epoch 116, Batch 26, Loss: 0.127\n",
      "Training: Epoch 116, Batch 27, Loss: 0.127\n",
      "Training: Epoch 116, Batch 28, Loss: 0.106\n",
      "Training: Epoch 116, Batch 29, Loss: 0.12\n",
      "Training: Epoch 116, Batch 30, Loss: 0.155\n",
      "Training: Epoch 116, Batch 31, Loss: 0.167\n",
      "Training: Epoch 116, Batch 32, Loss: 0.187\n",
      "Training: Epoch 116, Batch 33, Loss: 0.112\n",
      "Training: Epoch 116, Batch 34, Loss: 0.113\n",
      "Training: Epoch 116, Batch 35, Loss: 0.117\n",
      "Training: Epoch 116, Batch 36, Loss: 0.129\n",
      "Training: Epoch 116, Batch 37, Loss: 0.11\n",
      "Training: Epoch 116, Batch 38, Loss: 0.161\n",
      "Training: Epoch 116, Batch 39, Loss: 0.106\n",
      "Training: Epoch 116, Batch 40, Loss: 0.105\n",
      "Training: Epoch 116, Batch 41, Loss: 0.115\n",
      "Training: Epoch 116, Batch 42, Loss: 0.13\n",
      "Training: Epoch 116, Batch 43, Loss: 0.2\n",
      "Training: Epoch 116, Batch 44, Loss: 0.125\n",
      "Training: Epoch 116, Batch 45, Loss: 0.116\n",
      "Training: Epoch 116, Batch 46, Loss: 0.144\n",
      "Training: Epoch 116, Batch 47, Loss: 0.116\n",
      "Training: Epoch 116, Batch 48, Loss: 0.133\n",
      "Training: Epoch 116, Batch 49, Loss: 0.125\n",
      "Training: Epoch 116, Batch 50, Loss: 0.139\n",
      "Training: Epoch 116, Batch 51, Loss: 0.218\n",
      "Training: Epoch 116, Batch 52, Loss: 0.117\n",
      "Training: Epoch 116, Batch 53, Loss: 0.121\n",
      "Training: Epoch 116, Batch 54, Loss: 0.114\n",
      "Training: Epoch 116, Batch 55, Loss: 0.127\n",
      "Training: Epoch 116, Batch 56, Loss: 0.118\n",
      "Training: Epoch 116, Batch 57, Loss: 0.193\n",
      "Training: Epoch 116, Batch 58, Loss: 0.136\n",
      "Training: Epoch 116, Batch 59, Loss: 0.163\n",
      "Training: Epoch 116, Batch 60, Loss: 0.102\n",
      "Training: Epoch 116, Batch 61, Loss: 0.213\n",
      "Training: Epoch 116, Batch 62, Loss: 0.114\n",
      "Training: Epoch 116, Batch 63, Loss: 0.173\n",
      "Training: Epoch 116, Batch 64, Loss: 0.144\n",
      "Training: Epoch 116, Batch 65, Loss: 0.114\n",
      "Training: Epoch 116, Batch 66, Loss: 0.147\n",
      "Training: Epoch 116, Batch 67, Loss: 0.131\n",
      "Training: Epoch 116, Batch 68, Loss: 0.087\n",
      "Training: Epoch 116, Batch 69, Loss: 0.153\n",
      "Training: Epoch 116, Batch 70, Loss: 0.139\n",
      "Training: Epoch 116, Batch 71, Loss: 0.113\n",
      "Training: Epoch 116, Batch 72, Loss: 0.14\n",
      "Training: Epoch 116, Batch 73, Loss: 0.121\n",
      "Training: Epoch 116, Batch 74, Loss: 0.124\n",
      "Training: Epoch 116, Batch 75, Loss: 0.161\n",
      "Training: Epoch 116, Batch 76, Loss: 0.209\n",
      "Training: Epoch 116, Batch 77, Loss: 0.196\n",
      "Training: Epoch 116, Batch 78, Loss: 0.114\n",
      "Training: Epoch 116, Batch 79, Loss: 0.161\n",
      "Training: Epoch 116, Batch 80, Loss: 0.151\n",
      "Training: Epoch 116, Batch 81, Loss: 0.119\n",
      "Training: Epoch 116, Batch 82, Loss: 0.106\n",
      "Training: Epoch 116, Batch 83, Loss: 0.174\n",
      "Training: Epoch 116, Batch 84, Loss: 0.099\n",
      "Training: Epoch 116, Batch 85, Loss: 0.104\n",
      "Training: Epoch 116, Batch 86, Loss: 0.113\n",
      "Training: Epoch 116, Batch 87, Loss: 0.156\n",
      "Training: Epoch 116, Batch 88, Loss: 0.183\n",
      "Training: Epoch 116, Batch 89, Loss: 0.133\n",
      "Val: Epoch 116, Loss: 0.26\n",
      "Training: Epoch 117, Batch 0, Loss: 0.176\n",
      "Training: Epoch 117, Batch 1, Loss: 0.127\n",
      "Training: Epoch 117, Batch 2, Loss: 0.11\n",
      "Training: Epoch 117, Batch 3, Loss: 0.15\n",
      "Training: Epoch 117, Batch 4, Loss: 0.109\n",
      "Training: Epoch 117, Batch 5, Loss: 0.142\n",
      "Training: Epoch 117, Batch 6, Loss: 0.142\n",
      "Training: Epoch 117, Batch 7, Loss: 0.135\n",
      "Training: Epoch 117, Batch 8, Loss: 0.104\n",
      "Training: Epoch 117, Batch 9, Loss: 0.109\n",
      "Training: Epoch 117, Batch 10, Loss: 0.108\n",
      "Training: Epoch 117, Batch 11, Loss: 0.16\n",
      "Training: Epoch 117, Batch 12, Loss: 0.173\n",
      "Training: Epoch 117, Batch 13, Loss: 0.111\n",
      "Training: Epoch 117, Batch 14, Loss: 0.165\n",
      "Training: Epoch 117, Batch 15, Loss: 0.134\n",
      "Training: Epoch 117, Batch 16, Loss: 0.138\n",
      "Training: Epoch 117, Batch 17, Loss: 0.194\n",
      "Training: Epoch 117, Batch 18, Loss: 0.104\n",
      "Training: Epoch 117, Batch 19, Loss: 0.126\n",
      "Training: Epoch 117, Batch 20, Loss: 0.172\n",
      "Training: Epoch 117, Batch 21, Loss: 0.104\n",
      "Training: Epoch 117, Batch 22, Loss: 0.143\n",
      "Training: Epoch 117, Batch 23, Loss: 0.105\n",
      "Training: Epoch 117, Batch 24, Loss: 0.119\n",
      "Training: Epoch 117, Batch 25, Loss: 0.147\n",
      "Training: Epoch 117, Batch 26, Loss: 0.162\n",
      "Training: Epoch 117, Batch 27, Loss: 0.135\n",
      "Training: Epoch 117, Batch 28, Loss: 0.143\n",
      "Training: Epoch 117, Batch 29, Loss: 0.177\n",
      "Training: Epoch 117, Batch 30, Loss: 0.151\n",
      "Training: Epoch 117, Batch 31, Loss: 0.151\n",
      "Training: Epoch 117, Batch 32, Loss: 0.128\n",
      "Training: Epoch 117, Batch 33, Loss: 0.098\n",
      "Training: Epoch 117, Batch 34, Loss: 0.17\n",
      "Training: Epoch 117, Batch 35, Loss: 0.187\n",
      "Training: Epoch 117, Batch 36, Loss: 0.174\n",
      "Training: Epoch 117, Batch 37, Loss: 0.092\n",
      "Training: Epoch 117, Batch 38, Loss: 0.138\n",
      "Training: Epoch 117, Batch 39, Loss: 0.1\n",
      "Training: Epoch 117, Batch 40, Loss: 0.15\n",
      "Training: Epoch 117, Batch 41, Loss: 0.14\n",
      "Training: Epoch 117, Batch 42, Loss: 0.129\n",
      "Training: Epoch 117, Batch 43, Loss: 0.152\n",
      "Training: Epoch 117, Batch 44, Loss: 0.129\n",
      "Training: Epoch 117, Batch 45, Loss: 0.142\n",
      "Training: Epoch 117, Batch 46, Loss: 0.122\n",
      "Training: Epoch 117, Batch 47, Loss: 0.154\n",
      "Training: Epoch 117, Batch 48, Loss: 0.128\n",
      "Training: Epoch 117, Batch 49, Loss: 0.134\n",
      "Training: Epoch 117, Batch 50, Loss: 0.118\n",
      "Training: Epoch 117, Batch 51, Loss: 0.122\n",
      "Training: Epoch 117, Batch 52, Loss: 0.161\n",
      "Training: Epoch 117, Batch 53, Loss: 0.122\n",
      "Training: Epoch 117, Batch 54, Loss: 0.119\n",
      "Training: Epoch 117, Batch 55, Loss: 0.139\n",
      "Training: Epoch 117, Batch 56, Loss: 0.111\n",
      "Training: Epoch 117, Batch 57, Loss: 0.136\n",
      "Training: Epoch 117, Batch 58, Loss: 0.141\n",
      "Training: Epoch 117, Batch 59, Loss: 0.087\n",
      "Training: Epoch 117, Batch 60, Loss: 0.127\n",
      "Training: Epoch 117, Batch 61, Loss: 0.131\n",
      "Training: Epoch 117, Batch 62, Loss: 0.101\n",
      "Training: Epoch 117, Batch 63, Loss: 0.105\n",
      "Training: Epoch 117, Batch 64, Loss: 0.141\n",
      "Training: Epoch 117, Batch 65, Loss: 0.112\n",
      "Training: Epoch 117, Batch 66, Loss: 0.131\n",
      "Training: Epoch 117, Batch 67, Loss: 0.117\n",
      "Training: Epoch 117, Batch 68, Loss: 0.126\n",
      "Training: Epoch 117, Batch 69, Loss: 0.11\n",
      "Training: Epoch 117, Batch 70, Loss: 0.126\n",
      "Training: Epoch 117, Batch 71, Loss: 0.086\n",
      "Training: Epoch 117, Batch 72, Loss: 0.167\n",
      "Training: Epoch 117, Batch 73, Loss: 0.117\n",
      "Training: Epoch 117, Batch 74, Loss: 0.105\n",
      "Training: Epoch 117, Batch 75, Loss: 0.101\n",
      "Training: Epoch 117, Batch 76, Loss: 0.123\n",
      "Training: Epoch 117, Batch 77, Loss: 0.142\n",
      "Training: Epoch 117, Batch 78, Loss: 0.131\n",
      "Training: Epoch 117, Batch 79, Loss: 0.151\n",
      "Training: Epoch 117, Batch 80, Loss: 0.152\n",
      "Training: Epoch 117, Batch 81, Loss: 0.115\n",
      "Training: Epoch 117, Batch 82, Loss: 0.102\n",
      "Training: Epoch 117, Batch 83, Loss: 0.113\n",
      "Training: Epoch 117, Batch 84, Loss: 0.115\n",
      "Training: Epoch 117, Batch 85, Loss: 0.147\n",
      "Training: Epoch 117, Batch 86, Loss: 0.104\n",
      "Training: Epoch 117, Batch 87, Loss: 0.146\n",
      "Training: Epoch 117, Batch 88, Loss: 0.119\n",
      "Training: Epoch 117, Batch 89, Loss: 0.118\n",
      "Val: Epoch 117, Loss: 0.265\n",
      "Training: Epoch 118, Batch 0, Loss: 0.164\n",
      "Training: Epoch 118, Batch 1, Loss: 0.08\n",
      "Training: Epoch 118, Batch 2, Loss: 0.14\n",
      "Training: Epoch 118, Batch 3, Loss: 0.15\n",
      "Training: Epoch 118, Batch 4, Loss: 0.106\n",
      "Training: Epoch 118, Batch 5, Loss: 0.146\n",
      "Training: Epoch 118, Batch 6, Loss: 0.123\n",
      "Training: Epoch 118, Batch 7, Loss: 0.107\n",
      "Training: Epoch 118, Batch 8, Loss: 0.121\n",
      "Training: Epoch 118, Batch 9, Loss: 0.127\n",
      "Training: Epoch 118, Batch 10, Loss: 0.133\n",
      "Training: Epoch 118, Batch 11, Loss: 0.171\n",
      "Training: Epoch 118, Batch 12, Loss: 0.166\n",
      "Training: Epoch 118, Batch 13, Loss: 0.156\n",
      "Training: Epoch 118, Batch 14, Loss: 0.182\n",
      "Training: Epoch 118, Batch 15, Loss: 0.113\n",
      "Training: Epoch 118, Batch 16, Loss: 0.15\n",
      "Training: Epoch 118, Batch 17, Loss: 0.121\n",
      "Training: Epoch 118, Batch 18, Loss: 0.153\n",
      "Training: Epoch 118, Batch 19, Loss: 0.186\n",
      "Training: Epoch 118, Batch 20, Loss: 0.14\n",
      "Training: Epoch 118, Batch 21, Loss: 0.125\n",
      "Training: Epoch 118, Batch 22, Loss: 0.103\n",
      "Training: Epoch 118, Batch 23, Loss: 0.141\n",
      "Training: Epoch 118, Batch 24, Loss: 0.118\n",
      "Training: Epoch 118, Batch 25, Loss: 0.164\n",
      "Training: Epoch 118, Batch 26, Loss: 0.083\n",
      "Training: Epoch 118, Batch 27, Loss: 0.154\n",
      "Training: Epoch 118, Batch 28, Loss: 0.102\n",
      "Training: Epoch 118, Batch 29, Loss: 0.111\n",
      "Training: Epoch 118, Batch 30, Loss: 0.137\n",
      "Training: Epoch 118, Batch 31, Loss: 0.141\n",
      "Training: Epoch 118, Batch 32, Loss: 0.19\n",
      "Training: Epoch 118, Batch 33, Loss: 0.123\n",
      "Training: Epoch 118, Batch 34, Loss: 0.156\n",
      "Training: Epoch 118, Batch 35, Loss: 0.145\n",
      "Training: Epoch 118, Batch 36, Loss: 0.149\n",
      "Training: Epoch 118, Batch 37, Loss: 0.098\n",
      "Training: Epoch 118, Batch 38, Loss: 0.19\n",
      "Training: Epoch 118, Batch 39, Loss: 0.097\n",
      "Training: Epoch 118, Batch 40, Loss: 0.231\n",
      "Training: Epoch 118, Batch 41, Loss: 0.106\n",
      "Training: Epoch 118, Batch 42, Loss: 0.139\n",
      "Training: Epoch 118, Batch 43, Loss: 0.144\n",
      "Training: Epoch 118, Batch 44, Loss: 0.135\n",
      "Training: Epoch 118, Batch 45, Loss: 0.111\n",
      "Training: Epoch 118, Batch 46, Loss: 0.107\n",
      "Training: Epoch 118, Batch 47, Loss: 0.111\n",
      "Training: Epoch 118, Batch 48, Loss: 0.141\n",
      "Training: Epoch 118, Batch 49, Loss: 0.13\n",
      "Training: Epoch 118, Batch 50, Loss: 0.089\n",
      "Training: Epoch 118, Batch 51, Loss: 0.123\n",
      "Training: Epoch 118, Batch 52, Loss: 0.093\n",
      "Training: Epoch 118, Batch 53, Loss: 0.169\n",
      "Training: Epoch 118, Batch 54, Loss: 0.11\n",
      "Training: Epoch 118, Batch 55, Loss: 0.2\n",
      "Training: Epoch 118, Batch 56, Loss: 0.152\n",
      "Training: Epoch 118, Batch 57, Loss: 0.086\n",
      "Training: Epoch 118, Batch 58, Loss: 0.15\n",
      "Training: Epoch 118, Batch 59, Loss: 0.123\n",
      "Training: Epoch 118, Batch 60, Loss: 0.108\n",
      "Training: Epoch 118, Batch 61, Loss: 0.129\n",
      "Training: Epoch 118, Batch 62, Loss: 0.102\n",
      "Training: Epoch 118, Batch 63, Loss: 0.138\n",
      "Training: Epoch 118, Batch 64, Loss: 0.152\n",
      "Training: Epoch 118, Batch 65, Loss: 0.123\n",
      "Training: Epoch 118, Batch 66, Loss: 0.16\n",
      "Training: Epoch 118, Batch 67, Loss: 0.105\n",
      "Training: Epoch 118, Batch 68, Loss: 0.153\n",
      "Training: Epoch 118, Batch 69, Loss: 0.121\n",
      "Training: Epoch 118, Batch 70, Loss: 0.144\n",
      "Training: Epoch 118, Batch 71, Loss: 0.159\n",
      "Training: Epoch 118, Batch 72, Loss: 0.112\n",
      "Training: Epoch 118, Batch 73, Loss: 0.148\n",
      "Training: Epoch 118, Batch 74, Loss: 0.107\n",
      "Training: Epoch 118, Batch 75, Loss: 0.1\n",
      "Training: Epoch 118, Batch 76, Loss: 0.144\n",
      "Training: Epoch 118, Batch 77, Loss: 0.134\n",
      "Training: Epoch 118, Batch 78, Loss: 0.131\n",
      "Training: Epoch 118, Batch 79, Loss: 0.108\n",
      "Training: Epoch 118, Batch 80, Loss: 0.114\n",
      "Training: Epoch 118, Batch 81, Loss: 0.121\n",
      "Training: Epoch 118, Batch 82, Loss: 0.159\n",
      "Training: Epoch 118, Batch 83, Loss: 0.13\n",
      "Training: Epoch 118, Batch 84, Loss: 0.109\n",
      "Training: Epoch 118, Batch 85, Loss: 0.108\n",
      "Training: Epoch 118, Batch 86, Loss: 0.081\n",
      "Training: Epoch 118, Batch 87, Loss: 0.126\n",
      "Training: Epoch 118, Batch 88, Loss: 0.104\n",
      "Training: Epoch 118, Batch 89, Loss: 0.136\n",
      "Val: Epoch 118, Loss: 0.268\n",
      "Training: Epoch 119, Batch 0, Loss: 0.148\n",
      "Training: Epoch 119, Batch 1, Loss: 0.155\n",
      "Training: Epoch 119, Batch 2, Loss: 0.11\n",
      "Training: Epoch 119, Batch 3, Loss: 0.15\n",
      "Training: Epoch 119, Batch 4, Loss: 0.112\n",
      "Training: Epoch 119, Batch 5, Loss: 0.163\n",
      "Training: Epoch 119, Batch 6, Loss: 0.165\n",
      "Training: Epoch 119, Batch 7, Loss: 0.104\n",
      "Training: Epoch 119, Batch 8, Loss: 0.107\n",
      "Training: Epoch 119, Batch 9, Loss: 0.139\n",
      "Training: Epoch 119, Batch 10, Loss: 0.139\n",
      "Training: Epoch 119, Batch 11, Loss: 0.125\n",
      "Training: Epoch 119, Batch 12, Loss: 0.118\n",
      "Training: Epoch 119, Batch 13, Loss: 0.119\n",
      "Training: Epoch 119, Batch 14, Loss: 0.112\n",
      "Training: Epoch 119, Batch 15, Loss: 0.109\n",
      "Training: Epoch 119, Batch 16, Loss: 0.118\n",
      "Training: Epoch 119, Batch 17, Loss: 0.105\n",
      "Training: Epoch 119, Batch 18, Loss: 0.143\n",
      "Training: Epoch 119, Batch 19, Loss: 0.123\n",
      "Training: Epoch 119, Batch 20, Loss: 0.134\n",
      "Training: Epoch 119, Batch 21, Loss: 0.079\n",
      "Training: Epoch 119, Batch 22, Loss: 0.151\n",
      "Training: Epoch 119, Batch 23, Loss: 0.15\n",
      "Training: Epoch 119, Batch 24, Loss: 0.114\n",
      "Training: Epoch 119, Batch 25, Loss: 0.113\n",
      "Training: Epoch 119, Batch 26, Loss: 0.11\n",
      "Training: Epoch 119, Batch 27, Loss: 0.108\n",
      "Training: Epoch 119, Batch 28, Loss: 0.166\n",
      "Training: Epoch 119, Batch 29, Loss: 0.1\n",
      "Training: Epoch 119, Batch 30, Loss: 0.144\n",
      "Training: Epoch 119, Batch 31, Loss: 0.115\n",
      "Training: Epoch 119, Batch 32, Loss: 0.116\n",
      "Training: Epoch 119, Batch 33, Loss: 0.167\n",
      "Training: Epoch 119, Batch 34, Loss: 0.142\n",
      "Training: Epoch 119, Batch 35, Loss: 0.149\n",
      "Training: Epoch 119, Batch 36, Loss: 0.097\n",
      "Training: Epoch 119, Batch 37, Loss: 0.104\n",
      "Training: Epoch 119, Batch 38, Loss: 0.095\n",
      "Training: Epoch 119, Batch 39, Loss: 0.127\n",
      "Training: Epoch 119, Batch 40, Loss: 0.121\n",
      "Training: Epoch 119, Batch 41, Loss: 0.172\n",
      "Training: Epoch 119, Batch 42, Loss: 0.142\n",
      "Training: Epoch 119, Batch 43, Loss: 0.073\n",
      "Training: Epoch 119, Batch 44, Loss: 0.108\n",
      "Training: Epoch 119, Batch 45, Loss: 0.168\n",
      "Training: Epoch 119, Batch 46, Loss: 0.104\n",
      "Training: Epoch 119, Batch 47, Loss: 0.131\n",
      "Training: Epoch 119, Batch 48, Loss: 0.156\n",
      "Training: Epoch 119, Batch 49, Loss: 0.178\n",
      "Training: Epoch 119, Batch 50, Loss: 0.102\n",
      "Training: Epoch 119, Batch 51, Loss: 0.131\n",
      "Training: Epoch 119, Batch 52, Loss: 0.114\n",
      "Training: Epoch 119, Batch 53, Loss: 0.148\n",
      "Training: Epoch 119, Batch 54, Loss: 0.152\n",
      "Training: Epoch 119, Batch 55, Loss: 0.129\n",
      "Training: Epoch 119, Batch 56, Loss: 0.09\n",
      "Training: Epoch 119, Batch 57, Loss: 0.11\n",
      "Training: Epoch 119, Batch 58, Loss: 0.113\n",
      "Training: Epoch 119, Batch 59, Loss: 0.102\n",
      "Training: Epoch 119, Batch 60, Loss: 0.114\n",
      "Training: Epoch 119, Batch 61, Loss: 0.105\n",
      "Training: Epoch 119, Batch 62, Loss: 0.156\n",
      "Training: Epoch 119, Batch 63, Loss: 0.135\n",
      "Training: Epoch 119, Batch 64, Loss: 0.14\n",
      "Training: Epoch 119, Batch 65, Loss: 0.133\n",
      "Training: Epoch 119, Batch 66, Loss: 0.133\n",
      "Training: Epoch 119, Batch 67, Loss: 0.135\n",
      "Training: Epoch 119, Batch 68, Loss: 0.089\n",
      "Training: Epoch 119, Batch 69, Loss: 0.111\n",
      "Training: Epoch 119, Batch 70, Loss: 0.105\n",
      "Training: Epoch 119, Batch 71, Loss: 0.133\n",
      "Training: Epoch 119, Batch 72, Loss: 0.12\n",
      "Training: Epoch 119, Batch 73, Loss: 0.123\n",
      "Training: Epoch 119, Batch 74, Loss: 0.159\n",
      "Training: Epoch 119, Batch 75, Loss: 0.116\n",
      "Training: Epoch 119, Batch 76, Loss: 0.162\n",
      "Training: Epoch 119, Batch 77, Loss: 0.139\n",
      "Training: Epoch 119, Batch 78, Loss: 0.101\n",
      "Training: Epoch 119, Batch 79, Loss: 0.148\n",
      "Training: Epoch 119, Batch 80, Loss: 0.173\n",
      "Training: Epoch 119, Batch 81, Loss: 0.108\n",
      "Training: Epoch 119, Batch 82, Loss: 0.123\n",
      "Training: Epoch 119, Batch 83, Loss: 0.171\n",
      "Training: Epoch 119, Batch 84, Loss: 0.154\n",
      "Training: Epoch 119, Batch 85, Loss: 0.144\n",
      "Training: Epoch 119, Batch 86, Loss: 0.12\n",
      "Training: Epoch 119, Batch 87, Loss: 0.132\n",
      "Training: Epoch 119, Batch 88, Loss: 0.122\n",
      "Training: Epoch 119, Batch 89, Loss: 0.181\n",
      "Val: Epoch 119, Loss: 0.275\n",
      "Training: Epoch 120, Batch 0, Loss: 0.097\n",
      "Training: Epoch 120, Batch 1, Loss: 0.135\n",
      "Training: Epoch 120, Batch 2, Loss: 0.133\n",
      "Training: Epoch 120, Batch 3, Loss: 0.109\n",
      "Training: Epoch 120, Batch 4, Loss: 0.109\n",
      "Training: Epoch 120, Batch 5, Loss: 0.098\n",
      "Training: Epoch 120, Batch 6, Loss: 0.196\n",
      "Training: Epoch 120, Batch 7, Loss: 0.146\n",
      "Training: Epoch 120, Batch 8, Loss: 0.14\n",
      "Training: Epoch 120, Batch 9, Loss: 0.122\n",
      "Training: Epoch 120, Batch 10, Loss: 0.099\n",
      "Training: Epoch 120, Batch 11, Loss: 0.096\n",
      "Training: Epoch 120, Batch 12, Loss: 0.171\n",
      "Training: Epoch 120, Batch 13, Loss: 0.153\n",
      "Training: Epoch 120, Batch 14, Loss: 0.1\n",
      "Training: Epoch 120, Batch 15, Loss: 0.101\n",
      "Training: Epoch 120, Batch 16, Loss: 0.114\n",
      "Training: Epoch 120, Batch 17, Loss: 0.118\n",
      "Training: Epoch 120, Batch 18, Loss: 0.112\n",
      "Training: Epoch 120, Batch 19, Loss: 0.152\n",
      "Training: Epoch 120, Batch 20, Loss: 0.133\n",
      "Training: Epoch 120, Batch 21, Loss: 0.138\n",
      "Training: Epoch 120, Batch 22, Loss: 0.117\n",
      "Training: Epoch 120, Batch 23, Loss: 0.127\n",
      "Training: Epoch 120, Batch 24, Loss: 0.133\n",
      "Training: Epoch 120, Batch 25, Loss: 0.114\n",
      "Training: Epoch 120, Batch 26, Loss: 0.117\n",
      "Training: Epoch 120, Batch 27, Loss: 0.119\n",
      "Training: Epoch 120, Batch 28, Loss: 0.088\n",
      "Training: Epoch 120, Batch 29, Loss: 0.19\n",
      "Training: Epoch 120, Batch 30, Loss: 0.108\n",
      "Training: Epoch 120, Batch 31, Loss: 0.119\n",
      "Training: Epoch 120, Batch 32, Loss: 0.084\n",
      "Training: Epoch 120, Batch 33, Loss: 0.175\n",
      "Training: Epoch 120, Batch 34, Loss: 0.137\n",
      "Training: Epoch 120, Batch 35, Loss: 0.108\n",
      "Training: Epoch 120, Batch 36, Loss: 0.108\n",
      "Training: Epoch 120, Batch 37, Loss: 0.096\n",
      "Training: Epoch 120, Batch 38, Loss: 0.117\n",
      "Training: Epoch 120, Batch 39, Loss: 0.134\n",
      "Training: Epoch 120, Batch 40, Loss: 0.105\n",
      "Training: Epoch 120, Batch 41, Loss: 0.151\n",
      "Training: Epoch 120, Batch 42, Loss: 0.117\n",
      "Training: Epoch 120, Batch 43, Loss: 0.128\n",
      "Training: Epoch 120, Batch 44, Loss: 0.155\n",
      "Training: Epoch 120, Batch 45, Loss: 0.079\n",
      "Training: Epoch 120, Batch 46, Loss: 0.113\n",
      "Training: Epoch 120, Batch 47, Loss: 0.129\n",
      "Training: Epoch 120, Batch 48, Loss: 0.085\n",
      "Training: Epoch 120, Batch 49, Loss: 0.117\n",
      "Training: Epoch 120, Batch 50, Loss: 0.15\n",
      "Training: Epoch 120, Batch 51, Loss: 0.176\n",
      "Training: Epoch 120, Batch 52, Loss: 0.118\n",
      "Training: Epoch 120, Batch 53, Loss: 0.105\n",
      "Training: Epoch 120, Batch 54, Loss: 0.14\n",
      "Training: Epoch 120, Batch 55, Loss: 0.109\n",
      "Training: Epoch 120, Batch 56, Loss: 0.149\n",
      "Training: Epoch 120, Batch 57, Loss: 0.147\n",
      "Training: Epoch 120, Batch 58, Loss: 0.159\n",
      "Training: Epoch 120, Batch 59, Loss: 0.145\n",
      "Training: Epoch 120, Batch 60, Loss: 0.156\n",
      "Training: Epoch 120, Batch 61, Loss: 0.107\n",
      "Training: Epoch 120, Batch 62, Loss: 0.111\n",
      "Training: Epoch 120, Batch 63, Loss: 0.116\n",
      "Training: Epoch 120, Batch 64, Loss: 0.114\n",
      "Training: Epoch 120, Batch 65, Loss: 0.122\n",
      "Training: Epoch 120, Batch 66, Loss: 0.159\n",
      "Training: Epoch 120, Batch 67, Loss: 0.102\n",
      "Training: Epoch 120, Batch 68, Loss: 0.113\n",
      "Training: Epoch 120, Batch 69, Loss: 0.117\n",
      "Training: Epoch 120, Batch 70, Loss: 0.124\n",
      "Training: Epoch 120, Batch 71, Loss: 0.094\n",
      "Training: Epoch 120, Batch 72, Loss: 0.124\n",
      "Training: Epoch 120, Batch 73, Loss: 0.123\n",
      "Training: Epoch 120, Batch 74, Loss: 0.168\n",
      "Training: Epoch 120, Batch 75, Loss: 0.132\n",
      "Training: Epoch 120, Batch 76, Loss: 0.147\n",
      "Training: Epoch 120, Batch 77, Loss: 0.195\n",
      "Training: Epoch 120, Batch 78, Loss: 0.123\n",
      "Training: Epoch 120, Batch 79, Loss: 0.184\n",
      "Training: Epoch 120, Batch 80, Loss: 0.115\n",
      "Training: Epoch 120, Batch 81, Loss: 0.167\n",
      "Training: Epoch 120, Batch 82, Loss: 0.113\n",
      "Training: Epoch 120, Batch 83, Loss: 0.122\n",
      "Training: Epoch 120, Batch 84, Loss: 0.149\n",
      "Training: Epoch 120, Batch 85, Loss: 0.124\n",
      "Training: Epoch 120, Batch 86, Loss: 0.13\n",
      "Training: Epoch 120, Batch 87, Loss: 0.146\n",
      "Training: Epoch 120, Batch 88, Loss: 0.113\n",
      "Training: Epoch 120, Batch 89, Loss: 0.135\n",
      "Val: Epoch 120, Loss: 0.266\n",
      "Training: Epoch 121, Batch 0, Loss: 0.116\n",
      "Training: Epoch 121, Batch 1, Loss: 0.134\n",
      "Training: Epoch 121, Batch 2, Loss: 0.183\n",
      "Training: Epoch 121, Batch 3, Loss: 0.162\n",
      "Training: Epoch 121, Batch 4, Loss: 0.126\n",
      "Training: Epoch 121, Batch 5, Loss: 0.135\n",
      "Training: Epoch 121, Batch 6, Loss: 0.103\n",
      "Training: Epoch 121, Batch 7, Loss: 0.157\n",
      "Training: Epoch 121, Batch 8, Loss: 0.11\n",
      "Training: Epoch 121, Batch 9, Loss: 0.11\n",
      "Training: Epoch 121, Batch 10, Loss: 0.141\n",
      "Training: Epoch 121, Batch 11, Loss: 0.101\n",
      "Training: Epoch 121, Batch 12, Loss: 0.096\n",
      "Training: Epoch 121, Batch 13, Loss: 0.14\n",
      "Training: Epoch 121, Batch 14, Loss: 0.129\n",
      "Training: Epoch 121, Batch 15, Loss: 0.148\n",
      "Training: Epoch 121, Batch 16, Loss: 0.125\n",
      "Training: Epoch 121, Batch 17, Loss: 0.107\n",
      "Training: Epoch 121, Batch 18, Loss: 0.111\n",
      "Training: Epoch 121, Batch 19, Loss: 0.142\n",
      "Training: Epoch 121, Batch 20, Loss: 0.136\n",
      "Training: Epoch 121, Batch 21, Loss: 0.119\n",
      "Training: Epoch 121, Batch 22, Loss: 0.118\n",
      "Training: Epoch 121, Batch 23, Loss: 0.145\n",
      "Training: Epoch 121, Batch 24, Loss: 0.09\n",
      "Training: Epoch 121, Batch 25, Loss: 0.135\n",
      "Training: Epoch 121, Batch 26, Loss: 0.166\n",
      "Training: Epoch 121, Batch 27, Loss: 0.155\n",
      "Training: Epoch 121, Batch 28, Loss: 0.144\n",
      "Training: Epoch 121, Batch 29, Loss: 0.089\n",
      "Training: Epoch 121, Batch 30, Loss: 0.099\n",
      "Training: Epoch 121, Batch 31, Loss: 0.105\n",
      "Training: Epoch 121, Batch 32, Loss: 0.103\n",
      "Training: Epoch 121, Batch 33, Loss: 0.141\n",
      "Training: Epoch 121, Batch 34, Loss: 0.165\n",
      "Training: Epoch 121, Batch 35, Loss: 0.139\n",
      "Training: Epoch 121, Batch 36, Loss: 0.13\n",
      "Training: Epoch 121, Batch 37, Loss: 0.119\n",
      "Training: Epoch 121, Batch 38, Loss: 0.129\n",
      "Training: Epoch 121, Batch 39, Loss: 0.117\n",
      "Training: Epoch 121, Batch 40, Loss: 0.122\n",
      "Training: Epoch 121, Batch 41, Loss: 0.136\n",
      "Training: Epoch 121, Batch 42, Loss: 0.187\n",
      "Training: Epoch 121, Batch 43, Loss: 0.149\n",
      "Training: Epoch 121, Batch 44, Loss: 0.095\n",
      "Training: Epoch 121, Batch 45, Loss: 0.131\n",
      "Training: Epoch 121, Batch 46, Loss: 0.12\n",
      "Training: Epoch 121, Batch 47, Loss: 0.105\n",
      "Training: Epoch 121, Batch 48, Loss: 0.155\n",
      "Training: Epoch 121, Batch 49, Loss: 0.116\n",
      "Training: Epoch 121, Batch 50, Loss: 0.107\n",
      "Training: Epoch 121, Batch 51, Loss: 0.093\n",
      "Training: Epoch 121, Batch 52, Loss: 0.108\n",
      "Training: Epoch 121, Batch 53, Loss: 0.12\n",
      "Training: Epoch 121, Batch 54, Loss: 0.116\n",
      "Training: Epoch 121, Batch 55, Loss: 0.161\n",
      "Training: Epoch 121, Batch 56, Loss: 0.149\n",
      "Training: Epoch 121, Batch 57, Loss: 0.142\n",
      "Training: Epoch 121, Batch 58, Loss: 0.143\n",
      "Training: Epoch 121, Batch 59, Loss: 0.122\n",
      "Training: Epoch 121, Batch 60, Loss: 0.142\n",
      "Training: Epoch 121, Batch 61, Loss: 0.093\n",
      "Training: Epoch 121, Batch 62, Loss: 0.148\n",
      "Training: Epoch 121, Batch 63, Loss: 0.125\n",
      "Training: Epoch 121, Batch 64, Loss: 0.157\n",
      "Training: Epoch 121, Batch 65, Loss: 0.103\n",
      "Training: Epoch 121, Batch 66, Loss: 0.201\n",
      "Training: Epoch 121, Batch 67, Loss: 0.136\n",
      "Training: Epoch 121, Batch 68, Loss: 0.103\n",
      "Training: Epoch 121, Batch 69, Loss: 0.123\n",
      "Training: Epoch 121, Batch 70, Loss: 0.131\n",
      "Training: Epoch 121, Batch 71, Loss: 0.101\n",
      "Training: Epoch 121, Batch 72, Loss: 0.158\n",
      "Training: Epoch 121, Batch 73, Loss: 0.098\n",
      "Training: Epoch 121, Batch 74, Loss: 0.107\n",
      "Training: Epoch 121, Batch 75, Loss: 0.101\n",
      "Training: Epoch 121, Batch 76, Loss: 0.12\n",
      "Training: Epoch 121, Batch 77, Loss: 0.099\n",
      "Training: Epoch 121, Batch 78, Loss: 0.134\n",
      "Training: Epoch 121, Batch 79, Loss: 0.116\n",
      "Training: Epoch 121, Batch 80, Loss: 0.125\n",
      "Training: Epoch 121, Batch 81, Loss: 0.144\n",
      "Training: Epoch 121, Batch 82, Loss: 0.144\n",
      "Training: Epoch 121, Batch 83, Loss: 0.096\n",
      "Training: Epoch 121, Batch 84, Loss: 0.128\n",
      "Training: Epoch 121, Batch 85, Loss: 0.118\n",
      "Training: Epoch 121, Batch 86, Loss: 0.137\n",
      "Training: Epoch 121, Batch 87, Loss: 0.123\n",
      "Training: Epoch 121, Batch 88, Loss: 0.106\n",
      "Training: Epoch 121, Batch 89, Loss: 0.117\n",
      "Val: Epoch 121, Loss: 0.277\n",
      "Training: Epoch 122, Batch 0, Loss: 0.116\n",
      "Training: Epoch 122, Batch 1, Loss: 0.101\n",
      "Training: Epoch 122, Batch 2, Loss: 0.137\n",
      "Training: Epoch 122, Batch 3, Loss: 0.145\n",
      "Training: Epoch 122, Batch 4, Loss: 0.095\n",
      "Training: Epoch 122, Batch 5, Loss: 0.125\n",
      "Training: Epoch 122, Batch 6, Loss: 0.16\n",
      "Training: Epoch 122, Batch 7, Loss: 0.103\n",
      "Training: Epoch 122, Batch 8, Loss: 0.171\n",
      "Training: Epoch 122, Batch 9, Loss: 0.097\n",
      "Training: Epoch 122, Batch 10, Loss: 0.112\n",
      "Training: Epoch 122, Batch 11, Loss: 0.125\n",
      "Training: Epoch 122, Batch 12, Loss: 0.092\n",
      "Training: Epoch 122, Batch 13, Loss: 0.19\n",
      "Training: Epoch 122, Batch 14, Loss: 0.148\n",
      "Training: Epoch 122, Batch 15, Loss: 0.126\n",
      "Training: Epoch 122, Batch 16, Loss: 0.113\n",
      "Training: Epoch 122, Batch 17, Loss: 0.157\n",
      "Training: Epoch 122, Batch 18, Loss: 0.146\n",
      "Training: Epoch 122, Batch 19, Loss: 0.135\n",
      "Training: Epoch 122, Batch 20, Loss: 0.13\n",
      "Training: Epoch 122, Batch 21, Loss: 0.129\n",
      "Training: Epoch 122, Batch 22, Loss: 0.149\n",
      "Training: Epoch 122, Batch 23, Loss: 0.132\n",
      "Training: Epoch 122, Batch 24, Loss: 0.125\n",
      "Training: Epoch 122, Batch 25, Loss: 0.195\n",
      "Training: Epoch 122, Batch 26, Loss: 0.17\n",
      "Training: Epoch 122, Batch 27, Loss: 0.12\n",
      "Training: Epoch 122, Batch 28, Loss: 0.081\n",
      "Training: Epoch 122, Batch 29, Loss: 0.149\n",
      "Training: Epoch 122, Batch 30, Loss: 0.112\n",
      "Training: Epoch 122, Batch 31, Loss: 0.108\n",
      "Training: Epoch 122, Batch 32, Loss: 0.102\n",
      "Training: Epoch 122, Batch 33, Loss: 0.085\n",
      "Training: Epoch 122, Batch 34, Loss: 0.127\n",
      "Training: Epoch 122, Batch 35, Loss: 0.112\n",
      "Training: Epoch 122, Batch 36, Loss: 0.136\n",
      "Training: Epoch 122, Batch 37, Loss: 0.096\n",
      "Training: Epoch 122, Batch 38, Loss: 0.168\n",
      "Training: Epoch 122, Batch 39, Loss: 0.092\n",
      "Training: Epoch 122, Batch 40, Loss: 0.143\n",
      "Training: Epoch 122, Batch 41, Loss: 0.109\n",
      "Training: Epoch 122, Batch 42, Loss: 0.101\n",
      "Training: Epoch 122, Batch 43, Loss: 0.131\n",
      "Training: Epoch 122, Batch 44, Loss: 0.099\n",
      "Training: Epoch 122, Batch 45, Loss: 0.132\n",
      "Training: Epoch 122, Batch 46, Loss: 0.136\n",
      "Training: Epoch 122, Batch 47, Loss: 0.078\n",
      "Training: Epoch 122, Batch 48, Loss: 0.143\n",
      "Training: Epoch 122, Batch 49, Loss: 0.107\n",
      "Training: Epoch 122, Batch 50, Loss: 0.126\n",
      "Training: Epoch 122, Batch 51, Loss: 0.125\n",
      "Training: Epoch 122, Batch 52, Loss: 0.127\n",
      "Training: Epoch 122, Batch 53, Loss: 0.092\n",
      "Training: Epoch 122, Batch 54, Loss: 0.083\n",
      "Training: Epoch 122, Batch 55, Loss: 0.14\n",
      "Training: Epoch 122, Batch 56, Loss: 0.113\n",
      "Training: Epoch 122, Batch 57, Loss: 0.108\n",
      "Training: Epoch 122, Batch 58, Loss: 0.1\n",
      "Training: Epoch 122, Batch 59, Loss: 0.123\n",
      "Training: Epoch 122, Batch 60, Loss: 0.137\n",
      "Training: Epoch 122, Batch 61, Loss: 0.135\n",
      "Training: Epoch 122, Batch 62, Loss: 0.123\n",
      "Training: Epoch 122, Batch 63, Loss: 0.182\n",
      "Training: Epoch 122, Batch 64, Loss: 0.09\n",
      "Training: Epoch 122, Batch 65, Loss: 0.109\n",
      "Training: Epoch 122, Batch 66, Loss: 0.127\n",
      "Training: Epoch 122, Batch 67, Loss: 0.101\n",
      "Training: Epoch 122, Batch 68, Loss: 0.127\n",
      "Training: Epoch 122, Batch 69, Loss: 0.125\n",
      "Training: Epoch 122, Batch 70, Loss: 0.095\n",
      "Training: Epoch 122, Batch 71, Loss: 0.101\n",
      "Training: Epoch 122, Batch 72, Loss: 0.102\n",
      "Training: Epoch 122, Batch 73, Loss: 0.111\n",
      "Training: Epoch 122, Batch 74, Loss: 0.143\n",
      "Training: Epoch 122, Batch 75, Loss: 0.142\n",
      "Training: Epoch 122, Batch 76, Loss: 0.121\n",
      "Training: Epoch 122, Batch 77, Loss: 0.132\n",
      "Training: Epoch 122, Batch 78, Loss: 0.124\n",
      "Training: Epoch 122, Batch 79, Loss: 0.091\n",
      "Training: Epoch 122, Batch 80, Loss: 0.127\n",
      "Training: Epoch 122, Batch 81, Loss: 0.181\n",
      "Training: Epoch 122, Batch 82, Loss: 0.147\n",
      "Training: Epoch 122, Batch 83, Loss: 0.154\n",
      "Training: Epoch 122, Batch 84, Loss: 0.114\n",
      "Training: Epoch 122, Batch 85, Loss: 0.105\n",
      "Training: Epoch 122, Batch 86, Loss: 0.11\n",
      "Training: Epoch 122, Batch 87, Loss: 0.09\n",
      "Training: Epoch 122, Batch 88, Loss: 0.134\n",
      "Training: Epoch 122, Batch 89, Loss: 0.139\n",
      "Val: Epoch 122, Loss: 0.268\n",
      "Training: Epoch 123, Batch 0, Loss: 0.118\n",
      "Training: Epoch 123, Batch 1, Loss: 0.098\n",
      "Training: Epoch 123, Batch 2, Loss: 0.143\n",
      "Training: Epoch 123, Batch 3, Loss: 0.116\n",
      "Training: Epoch 123, Batch 4, Loss: 0.102\n",
      "Training: Epoch 123, Batch 5, Loss: 0.122\n",
      "Training: Epoch 123, Batch 6, Loss: 0.175\n",
      "Training: Epoch 123, Batch 7, Loss: 0.097\n",
      "Training: Epoch 123, Batch 8, Loss: 0.109\n",
      "Training: Epoch 123, Batch 9, Loss: 0.151\n",
      "Training: Epoch 123, Batch 10, Loss: 0.158\n",
      "Training: Epoch 123, Batch 11, Loss: 0.104\n",
      "Training: Epoch 123, Batch 12, Loss: 0.131\n",
      "Training: Epoch 123, Batch 13, Loss: 0.107\n",
      "Training: Epoch 123, Batch 14, Loss: 0.135\n",
      "Training: Epoch 123, Batch 15, Loss: 0.103\n",
      "Training: Epoch 123, Batch 16, Loss: 0.112\n",
      "Training: Epoch 123, Batch 17, Loss: 0.139\n",
      "Training: Epoch 123, Batch 18, Loss: 0.113\n",
      "Training: Epoch 123, Batch 19, Loss: 0.106\n",
      "Training: Epoch 123, Batch 20, Loss: 0.127\n",
      "Training: Epoch 123, Batch 21, Loss: 0.11\n",
      "Training: Epoch 123, Batch 22, Loss: 0.165\n",
      "Training: Epoch 123, Batch 23, Loss: 0.098\n",
      "Training: Epoch 123, Batch 24, Loss: 0.138\n",
      "Training: Epoch 123, Batch 25, Loss: 0.111\n",
      "Training: Epoch 123, Batch 26, Loss: 0.146\n",
      "Training: Epoch 123, Batch 27, Loss: 0.107\n",
      "Training: Epoch 123, Batch 28, Loss: 0.133\n",
      "Training: Epoch 123, Batch 29, Loss: 0.139\n",
      "Training: Epoch 123, Batch 30, Loss: 0.11\n",
      "Training: Epoch 123, Batch 31, Loss: 0.114\n",
      "Training: Epoch 123, Batch 32, Loss: 0.129\n",
      "Training: Epoch 123, Batch 33, Loss: 0.115\n",
      "Training: Epoch 123, Batch 34, Loss: 0.126\n",
      "Training: Epoch 123, Batch 35, Loss: 0.096\n",
      "Training: Epoch 123, Batch 36, Loss: 0.137\n",
      "Training: Epoch 123, Batch 37, Loss: 0.116\n",
      "Training: Epoch 123, Batch 38, Loss: 0.135\n",
      "Training: Epoch 123, Batch 39, Loss: 0.139\n",
      "Training: Epoch 123, Batch 40, Loss: 0.088\n",
      "Training: Epoch 123, Batch 41, Loss: 0.116\n",
      "Training: Epoch 123, Batch 42, Loss: 0.135\n",
      "Training: Epoch 123, Batch 43, Loss: 0.153\n",
      "Training: Epoch 123, Batch 44, Loss: 0.139\n",
      "Training: Epoch 123, Batch 45, Loss: 0.118\n",
      "Training: Epoch 123, Batch 46, Loss: 0.121\n",
      "Training: Epoch 123, Batch 47, Loss: 0.148\n",
      "Training: Epoch 123, Batch 48, Loss: 0.116\n",
      "Training: Epoch 123, Batch 49, Loss: 0.078\n",
      "Training: Epoch 123, Batch 50, Loss: 0.119\n",
      "Training: Epoch 123, Batch 51, Loss: 0.098\n",
      "Training: Epoch 123, Batch 52, Loss: 0.095\n",
      "Training: Epoch 123, Batch 53, Loss: 0.125\n",
      "Training: Epoch 123, Batch 54, Loss: 0.131\n",
      "Training: Epoch 123, Batch 55, Loss: 0.122\n",
      "Training: Epoch 123, Batch 56, Loss: 0.109\n",
      "Training: Epoch 123, Batch 57, Loss: 0.102\n",
      "Training: Epoch 123, Batch 58, Loss: 0.114\n",
      "Training: Epoch 123, Batch 59, Loss: 0.142\n",
      "Training: Epoch 123, Batch 60, Loss: 0.126\n",
      "Training: Epoch 123, Batch 61, Loss: 0.161\n",
      "Training: Epoch 123, Batch 62, Loss: 0.11\n",
      "Training: Epoch 123, Batch 63, Loss: 0.11\n",
      "Training: Epoch 123, Batch 64, Loss: 0.094\n",
      "Training: Epoch 123, Batch 65, Loss: 0.165\n",
      "Training: Epoch 123, Batch 66, Loss: 0.177\n",
      "Training: Epoch 123, Batch 67, Loss: 0.133\n",
      "Training: Epoch 123, Batch 68, Loss: 0.116\n",
      "Training: Epoch 123, Batch 69, Loss: 0.153\n",
      "Training: Epoch 123, Batch 70, Loss: 0.076\n",
      "Training: Epoch 123, Batch 71, Loss: 0.082\n",
      "Training: Epoch 123, Batch 72, Loss: 0.167\n",
      "Training: Epoch 123, Batch 73, Loss: 0.089\n",
      "Training: Epoch 123, Batch 74, Loss: 0.097\n",
      "Training: Epoch 123, Batch 75, Loss: 0.177\n",
      "Training: Epoch 123, Batch 76, Loss: 0.098\n",
      "Training: Epoch 123, Batch 77, Loss: 0.127\n",
      "Training: Epoch 123, Batch 78, Loss: 0.134\n",
      "Training: Epoch 123, Batch 79, Loss: 0.094\n",
      "Training: Epoch 123, Batch 80, Loss: 0.121\n",
      "Training: Epoch 123, Batch 81, Loss: 0.076\n",
      "Training: Epoch 123, Batch 82, Loss: 0.149\n",
      "Training: Epoch 123, Batch 83, Loss: 0.091\n",
      "Training: Epoch 123, Batch 84, Loss: 0.119\n",
      "Training: Epoch 123, Batch 85, Loss: 0.093\n",
      "Training: Epoch 123, Batch 86, Loss: 0.106\n",
      "Training: Epoch 123, Batch 87, Loss: 0.083\n",
      "Training: Epoch 123, Batch 88, Loss: 0.115\n",
      "Training: Epoch 123, Batch 89, Loss: 0.146\n",
      "Val: Epoch 123, Loss: 0.273\n",
      "Training: Epoch 124, Batch 0, Loss: 0.131\n",
      "Training: Epoch 124, Batch 1, Loss: 0.124\n",
      "Training: Epoch 124, Batch 2, Loss: 0.101\n",
      "Training: Epoch 124, Batch 3, Loss: 0.114\n",
      "Training: Epoch 124, Batch 4, Loss: 0.128\n",
      "Training: Epoch 124, Batch 5, Loss: 0.11\n",
      "Training: Epoch 124, Batch 6, Loss: 0.081\n",
      "Training: Epoch 124, Batch 7, Loss: 0.138\n",
      "Training: Epoch 124, Batch 8, Loss: 0.111\n",
      "Training: Epoch 124, Batch 9, Loss: 0.138\n",
      "Training: Epoch 124, Batch 10, Loss: 0.151\n",
      "Training: Epoch 124, Batch 11, Loss: 0.16\n",
      "Training: Epoch 124, Batch 12, Loss: 0.108\n",
      "Training: Epoch 124, Batch 13, Loss: 0.141\n",
      "Training: Epoch 124, Batch 14, Loss: 0.118\n",
      "Training: Epoch 124, Batch 15, Loss: 0.112\n",
      "Training: Epoch 124, Batch 16, Loss: 0.129\n",
      "Training: Epoch 124, Batch 17, Loss: 0.098\n",
      "Training: Epoch 124, Batch 18, Loss: 0.114\n",
      "Training: Epoch 124, Batch 19, Loss: 0.182\n",
      "Training: Epoch 124, Batch 20, Loss: 0.127\n",
      "Training: Epoch 124, Batch 21, Loss: 0.148\n",
      "Training: Epoch 124, Batch 22, Loss: 0.094\n",
      "Training: Epoch 124, Batch 23, Loss: 0.117\n",
      "Training: Epoch 124, Batch 24, Loss: 0.124\n",
      "Training: Epoch 124, Batch 25, Loss: 0.111\n",
      "Training: Epoch 124, Batch 26, Loss: 0.099\n",
      "Training: Epoch 124, Batch 27, Loss: 0.115\n",
      "Training: Epoch 124, Batch 28, Loss: 0.148\n",
      "Training: Epoch 124, Batch 29, Loss: 0.101\n",
      "Training: Epoch 124, Batch 30, Loss: 0.149\n",
      "Training: Epoch 124, Batch 31, Loss: 0.088\n",
      "Training: Epoch 124, Batch 32, Loss: 0.12\n",
      "Training: Epoch 124, Batch 33, Loss: 0.106\n",
      "Training: Epoch 124, Batch 34, Loss: 0.139\n",
      "Training: Epoch 124, Batch 35, Loss: 0.119\n",
      "Training: Epoch 124, Batch 36, Loss: 0.132\n",
      "Training: Epoch 124, Batch 37, Loss: 0.112\n",
      "Training: Epoch 124, Batch 38, Loss: 0.128\n",
      "Training: Epoch 124, Batch 39, Loss: 0.142\n",
      "Training: Epoch 124, Batch 40, Loss: 0.122\n",
      "Training: Epoch 124, Batch 41, Loss: 0.174\n",
      "Training: Epoch 124, Batch 42, Loss: 0.111\n",
      "Training: Epoch 124, Batch 43, Loss: 0.177\n",
      "Training: Epoch 124, Batch 44, Loss: 0.113\n",
      "Training: Epoch 124, Batch 45, Loss: 0.104\n",
      "Training: Epoch 124, Batch 46, Loss: 0.085\n",
      "Training: Epoch 124, Batch 47, Loss: 0.101\n",
      "Training: Epoch 124, Batch 48, Loss: 0.113\n",
      "Training: Epoch 124, Batch 49, Loss: 0.141\n",
      "Training: Epoch 124, Batch 50, Loss: 0.127\n",
      "Training: Epoch 124, Batch 51, Loss: 0.118\n",
      "Training: Epoch 124, Batch 52, Loss: 0.149\n",
      "Training: Epoch 124, Batch 53, Loss: 0.116\n",
      "Training: Epoch 124, Batch 54, Loss: 0.129\n",
      "Training: Epoch 124, Batch 55, Loss: 0.124\n",
      "Training: Epoch 124, Batch 56, Loss: 0.109\n",
      "Training: Epoch 124, Batch 57, Loss: 0.109\n",
      "Training: Epoch 124, Batch 58, Loss: 0.119\n",
      "Training: Epoch 124, Batch 59, Loss: 0.162\n",
      "Training: Epoch 124, Batch 60, Loss: 0.146\n",
      "Training: Epoch 124, Batch 61, Loss: 0.092\n",
      "Training: Epoch 124, Batch 62, Loss: 0.103\n",
      "Training: Epoch 124, Batch 63, Loss: 0.086\n",
      "Training: Epoch 124, Batch 64, Loss: 0.121\n",
      "Training: Epoch 124, Batch 65, Loss: 0.186\n",
      "Training: Epoch 124, Batch 66, Loss: 0.134\n",
      "Training: Epoch 124, Batch 67, Loss: 0.102\n",
      "Training: Epoch 124, Batch 68, Loss: 0.127\n",
      "Training: Epoch 124, Batch 69, Loss: 0.144\n",
      "Training: Epoch 124, Batch 70, Loss: 0.117\n",
      "Training: Epoch 124, Batch 71, Loss: 0.13\n",
      "Training: Epoch 124, Batch 72, Loss: 0.149\n",
      "Training: Epoch 124, Batch 73, Loss: 0.132\n",
      "Training: Epoch 124, Batch 74, Loss: 0.104\n",
      "Training: Epoch 124, Batch 75, Loss: 0.109\n",
      "Training: Epoch 124, Batch 76, Loss: 0.091\n",
      "Training: Epoch 124, Batch 77, Loss: 0.131\n",
      "Training: Epoch 124, Batch 78, Loss: 0.137\n",
      "Training: Epoch 124, Batch 79, Loss: 0.117\n",
      "Training: Epoch 124, Batch 80, Loss: 0.127\n",
      "Training: Epoch 124, Batch 81, Loss: 0.108\n",
      "Training: Epoch 124, Batch 82, Loss: 0.135\n",
      "Training: Epoch 124, Batch 83, Loss: 0.119\n",
      "Training: Epoch 124, Batch 84, Loss: 0.124\n",
      "Training: Epoch 124, Batch 85, Loss: 0.081\n",
      "Training: Epoch 124, Batch 86, Loss: 0.132\n",
      "Training: Epoch 124, Batch 87, Loss: 0.152\n",
      "Training: Epoch 124, Batch 88, Loss: 0.103\n",
      "Training: Epoch 124, Batch 89, Loss: 0.124\n",
      "Val: Epoch 124, Loss: 0.274\n",
      "Training: Epoch 125, Batch 0, Loss: 0.117\n",
      "Training: Epoch 125, Batch 1, Loss: 0.129\n",
      "Training: Epoch 125, Batch 2, Loss: 0.122\n",
      "Training: Epoch 125, Batch 3, Loss: 0.129\n",
      "Training: Epoch 125, Batch 4, Loss: 0.119\n",
      "Training: Epoch 125, Batch 5, Loss: 0.114\n",
      "Training: Epoch 125, Batch 6, Loss: 0.097\n",
      "Training: Epoch 125, Batch 7, Loss: 0.109\n",
      "Training: Epoch 125, Batch 8, Loss: 0.144\n",
      "Training: Epoch 125, Batch 9, Loss: 0.108\n",
      "Training: Epoch 125, Batch 10, Loss: 0.138\n",
      "Training: Epoch 125, Batch 11, Loss: 0.09\n",
      "Training: Epoch 125, Batch 12, Loss: 0.161\n",
      "Training: Epoch 125, Batch 13, Loss: 0.109\n",
      "Training: Epoch 125, Batch 14, Loss: 0.11\n",
      "Training: Epoch 125, Batch 15, Loss: 0.123\n",
      "Training: Epoch 125, Batch 16, Loss: 0.126\n",
      "Training: Epoch 125, Batch 17, Loss: 0.123\n",
      "Training: Epoch 125, Batch 18, Loss: 0.098\n",
      "Training: Epoch 125, Batch 19, Loss: 0.15\n",
      "Training: Epoch 125, Batch 20, Loss: 0.115\n",
      "Training: Epoch 125, Batch 21, Loss: 0.121\n",
      "Training: Epoch 125, Batch 22, Loss: 0.097\n",
      "Training: Epoch 125, Batch 23, Loss: 0.097\n",
      "Training: Epoch 125, Batch 24, Loss: 0.111\n",
      "Training: Epoch 125, Batch 25, Loss: 0.086\n",
      "Training: Epoch 125, Batch 26, Loss: 0.111\n",
      "Training: Epoch 125, Batch 27, Loss: 0.102\n",
      "Training: Epoch 125, Batch 28, Loss: 0.118\n",
      "Training: Epoch 125, Batch 29, Loss: 0.164\n",
      "Training: Epoch 125, Batch 30, Loss: 0.105\n",
      "Training: Epoch 125, Batch 31, Loss: 0.107\n",
      "Training: Epoch 125, Batch 32, Loss: 0.122\n",
      "Training: Epoch 125, Batch 33, Loss: 0.14\n",
      "Training: Epoch 125, Batch 34, Loss: 0.123\n",
      "Training: Epoch 125, Batch 35, Loss: 0.126\n",
      "Training: Epoch 125, Batch 36, Loss: 0.079\n",
      "Training: Epoch 125, Batch 37, Loss: 0.113\n",
      "Training: Epoch 125, Batch 38, Loss: 0.109\n",
      "Training: Epoch 125, Batch 39, Loss: 0.117\n",
      "Training: Epoch 125, Batch 40, Loss: 0.114\n",
      "Training: Epoch 125, Batch 41, Loss: 0.12\n",
      "Training: Epoch 125, Batch 42, Loss: 0.154\n",
      "Training: Epoch 125, Batch 43, Loss: 0.117\n",
      "Training: Epoch 125, Batch 44, Loss: 0.142\n",
      "Training: Epoch 125, Batch 45, Loss: 0.145\n",
      "Training: Epoch 125, Batch 46, Loss: 0.152\n",
      "Training: Epoch 125, Batch 47, Loss: 0.115\n",
      "Training: Epoch 125, Batch 48, Loss: 0.091\n",
      "Training: Epoch 125, Batch 49, Loss: 0.104\n",
      "Training: Epoch 125, Batch 50, Loss: 0.109\n",
      "Training: Epoch 125, Batch 51, Loss: 0.094\n",
      "Training: Epoch 125, Batch 52, Loss: 0.119\n",
      "Training: Epoch 125, Batch 53, Loss: 0.083\n",
      "Training: Epoch 125, Batch 54, Loss: 0.118\n",
      "Training: Epoch 125, Batch 55, Loss: 0.126\n",
      "Training: Epoch 125, Batch 56, Loss: 0.146\n",
      "Training: Epoch 125, Batch 57, Loss: 0.106\n",
      "Training: Epoch 125, Batch 58, Loss: 0.126\n",
      "Training: Epoch 125, Batch 59, Loss: 0.075\n",
      "Training: Epoch 125, Batch 60, Loss: 0.152\n",
      "Training: Epoch 125, Batch 61, Loss: 0.139\n",
      "Training: Epoch 125, Batch 62, Loss: 0.09\n",
      "Training: Epoch 125, Batch 63, Loss: 0.129\n",
      "Training: Epoch 125, Batch 64, Loss: 0.099\n",
      "Training: Epoch 125, Batch 65, Loss: 0.122\n",
      "Training: Epoch 125, Batch 66, Loss: 0.109\n",
      "Training: Epoch 125, Batch 67, Loss: 0.105\n",
      "Training: Epoch 125, Batch 68, Loss: 0.117\n",
      "Training: Epoch 125, Batch 69, Loss: 0.104\n",
      "Training: Epoch 125, Batch 70, Loss: 0.141\n",
      "Training: Epoch 125, Batch 71, Loss: 0.181\n",
      "Training: Epoch 125, Batch 72, Loss: 0.134\n",
      "Training: Epoch 125, Batch 73, Loss: 0.082\n",
      "Training: Epoch 125, Batch 74, Loss: 0.146\n",
      "Training: Epoch 125, Batch 75, Loss: 0.105\n",
      "Training: Epoch 125, Batch 76, Loss: 0.106\n",
      "Training: Epoch 125, Batch 77, Loss: 0.113\n",
      "Training: Epoch 125, Batch 78, Loss: 0.095\n",
      "Training: Epoch 125, Batch 79, Loss: 0.164\n",
      "Training: Epoch 125, Batch 80, Loss: 0.145\n",
      "Training: Epoch 125, Batch 81, Loss: 0.105\n",
      "Training: Epoch 125, Batch 82, Loss: 0.125\n",
      "Training: Epoch 125, Batch 83, Loss: 0.14\n",
      "Training: Epoch 125, Batch 84, Loss: 0.094\n",
      "Training: Epoch 125, Batch 85, Loss: 0.104\n",
      "Training: Epoch 125, Batch 86, Loss: 0.125\n",
      "Training: Epoch 125, Batch 87, Loss: 0.102\n",
      "Training: Epoch 125, Batch 88, Loss: 0.114\n",
      "Training: Epoch 125, Batch 89, Loss: 0.138\n",
      "Val: Epoch 125, Loss: 0.268\n",
      "Training: Epoch 126, Batch 0, Loss: 0.122\n",
      "Training: Epoch 126, Batch 1, Loss: 0.119\n",
      "Training: Epoch 126, Batch 2, Loss: 0.106\n",
      "Training: Epoch 126, Batch 3, Loss: 0.156\n",
      "Training: Epoch 126, Batch 4, Loss: 0.191\n",
      "Training: Epoch 126, Batch 5, Loss: 0.108\n",
      "Training: Epoch 126, Batch 6, Loss: 0.153\n",
      "Training: Epoch 126, Batch 7, Loss: 0.12\n",
      "Training: Epoch 126, Batch 8, Loss: 0.14\n",
      "Training: Epoch 126, Batch 9, Loss: 0.124\n",
      "Training: Epoch 126, Batch 10, Loss: 0.103\n",
      "Training: Epoch 126, Batch 11, Loss: 0.138\n",
      "Training: Epoch 126, Batch 12, Loss: 0.149\n",
      "Training: Epoch 126, Batch 13, Loss: 0.126\n",
      "Training: Epoch 126, Batch 14, Loss: 0.169\n",
      "Training: Epoch 126, Batch 15, Loss: 0.175\n",
      "Training: Epoch 126, Batch 16, Loss: 0.103\n",
      "Training: Epoch 126, Batch 17, Loss: 0.147\n",
      "Training: Epoch 126, Batch 18, Loss: 0.106\n",
      "Training: Epoch 126, Batch 19, Loss: 0.114\n",
      "Training: Epoch 126, Batch 20, Loss: 0.102\n",
      "Training: Epoch 126, Batch 21, Loss: 0.095\n",
      "Training: Epoch 126, Batch 22, Loss: 0.117\n",
      "Training: Epoch 126, Batch 23, Loss: 0.11\n",
      "Training: Epoch 126, Batch 24, Loss: 0.099\n",
      "Training: Epoch 126, Batch 25, Loss: 0.113\n",
      "Training: Epoch 126, Batch 26, Loss: 0.125\n",
      "Training: Epoch 126, Batch 27, Loss: 0.108\n",
      "Training: Epoch 126, Batch 28, Loss: 0.166\n",
      "Training: Epoch 126, Batch 29, Loss: 0.108\n",
      "Training: Epoch 126, Batch 30, Loss: 0.083\n",
      "Training: Epoch 126, Batch 31, Loss: 0.108\n",
      "Training: Epoch 126, Batch 32, Loss: 0.117\n",
      "Training: Epoch 126, Batch 33, Loss: 0.113\n",
      "Training: Epoch 126, Batch 34, Loss: 0.114\n",
      "Training: Epoch 126, Batch 35, Loss: 0.092\n",
      "Training: Epoch 126, Batch 36, Loss: 0.147\n",
      "Training: Epoch 126, Batch 37, Loss: 0.131\n",
      "Training: Epoch 126, Batch 38, Loss: 0.121\n",
      "Training: Epoch 126, Batch 39, Loss: 0.107\n",
      "Training: Epoch 126, Batch 40, Loss: 0.12\n",
      "Training: Epoch 126, Batch 41, Loss: 0.1\n",
      "Training: Epoch 126, Batch 42, Loss: 0.134\n",
      "Training: Epoch 126, Batch 43, Loss: 0.124\n",
      "Training: Epoch 126, Batch 44, Loss: 0.133\n",
      "Training: Epoch 126, Batch 45, Loss: 0.088\n",
      "Training: Epoch 126, Batch 46, Loss: 0.104\n",
      "Training: Epoch 126, Batch 47, Loss: 0.155\n",
      "Training: Epoch 126, Batch 48, Loss: 0.154\n",
      "Training: Epoch 126, Batch 49, Loss: 0.078\n",
      "Training: Epoch 126, Batch 50, Loss: 0.156\n",
      "Training: Epoch 126, Batch 51, Loss: 0.095\n",
      "Training: Epoch 126, Batch 52, Loss: 0.088\n",
      "Training: Epoch 126, Batch 53, Loss: 0.113\n",
      "Training: Epoch 126, Batch 54, Loss: 0.138\n",
      "Training: Epoch 126, Batch 55, Loss: 0.096\n",
      "Training: Epoch 126, Batch 56, Loss: 0.11\n",
      "Training: Epoch 126, Batch 57, Loss: 0.076\n",
      "Training: Epoch 126, Batch 58, Loss: 0.143\n",
      "Training: Epoch 126, Batch 59, Loss: 0.134\n",
      "Training: Epoch 126, Batch 60, Loss: 0.115\n",
      "Training: Epoch 126, Batch 61, Loss: 0.133\n",
      "Training: Epoch 126, Batch 62, Loss: 0.126\n",
      "Training: Epoch 126, Batch 63, Loss: 0.095\n",
      "Training: Epoch 126, Batch 64, Loss: 0.112\n",
      "Training: Epoch 126, Batch 65, Loss: 0.187\n",
      "Training: Epoch 126, Batch 66, Loss: 0.105\n",
      "Training: Epoch 126, Batch 67, Loss: 0.112\n",
      "Training: Epoch 126, Batch 68, Loss: 0.114\n",
      "Training: Epoch 126, Batch 69, Loss: 0.076\n",
      "Training: Epoch 126, Batch 70, Loss: 0.109\n",
      "Training: Epoch 126, Batch 71, Loss: 0.116\n",
      "Training: Epoch 126, Batch 72, Loss: 0.12\n",
      "Training: Epoch 126, Batch 73, Loss: 0.102\n",
      "Training: Epoch 126, Batch 74, Loss: 0.118\n",
      "Training: Epoch 126, Batch 75, Loss: 0.107\n",
      "Training: Epoch 126, Batch 76, Loss: 0.113\n",
      "Training: Epoch 126, Batch 77, Loss: 0.109\n",
      "Training: Epoch 126, Batch 78, Loss: 0.118\n",
      "Training: Epoch 126, Batch 79, Loss: 0.112\n",
      "Training: Epoch 126, Batch 80, Loss: 0.111\n",
      "Training: Epoch 126, Batch 81, Loss: 0.102\n",
      "Training: Epoch 126, Batch 82, Loss: 0.101\n",
      "Training: Epoch 126, Batch 83, Loss: 0.134\n",
      "Training: Epoch 126, Batch 84, Loss: 0.105\n",
      "Training: Epoch 126, Batch 85, Loss: 0.082\n",
      "Training: Epoch 126, Batch 86, Loss: 0.133\n",
      "Training: Epoch 126, Batch 87, Loss: 0.12\n",
      "Training: Epoch 126, Batch 88, Loss: 0.108\n",
      "Training: Epoch 126, Batch 89, Loss: 0.149\n",
      "Val: Epoch 126, Loss: 0.255\n",
      "Training: Epoch 127, Batch 0, Loss: 0.079\n",
      "Training: Epoch 127, Batch 1, Loss: 0.129\n",
      "Training: Epoch 127, Batch 2, Loss: 0.128\n",
      "Training: Epoch 127, Batch 3, Loss: 0.124\n",
      "Training: Epoch 127, Batch 4, Loss: 0.106\n",
      "Training: Epoch 127, Batch 5, Loss: 0.102\n",
      "Training: Epoch 127, Batch 6, Loss: 0.108\n",
      "Training: Epoch 127, Batch 7, Loss: 0.132\n",
      "Training: Epoch 127, Batch 8, Loss: 0.154\n",
      "Training: Epoch 127, Batch 9, Loss: 0.122\n",
      "Training: Epoch 127, Batch 10, Loss: 0.136\n",
      "Training: Epoch 127, Batch 11, Loss: 0.122\n",
      "Training: Epoch 127, Batch 12, Loss: 0.093\n",
      "Training: Epoch 127, Batch 13, Loss: 0.101\n",
      "Training: Epoch 127, Batch 14, Loss: 0.099\n",
      "Training: Epoch 127, Batch 15, Loss: 0.125\n",
      "Training: Epoch 127, Batch 16, Loss: 0.124\n",
      "Training: Epoch 127, Batch 17, Loss: 0.124\n",
      "Training: Epoch 127, Batch 18, Loss: 0.099\n",
      "Training: Epoch 127, Batch 19, Loss: 0.165\n",
      "Training: Epoch 127, Batch 20, Loss: 0.113\n",
      "Training: Epoch 127, Batch 21, Loss: 0.148\n",
      "Training: Epoch 127, Batch 22, Loss: 0.139\n",
      "Training: Epoch 127, Batch 23, Loss: 0.106\n",
      "Training: Epoch 127, Batch 24, Loss: 0.127\n",
      "Training: Epoch 127, Batch 25, Loss: 0.111\n",
      "Training: Epoch 127, Batch 26, Loss: 0.111\n",
      "Training: Epoch 127, Batch 27, Loss: 0.113\n",
      "Training: Epoch 127, Batch 28, Loss: 0.117\n",
      "Training: Epoch 127, Batch 29, Loss: 0.089\n",
      "Training: Epoch 127, Batch 30, Loss: 0.141\n",
      "Training: Epoch 127, Batch 31, Loss: 0.113\n",
      "Training: Epoch 127, Batch 32, Loss: 0.113\n",
      "Training: Epoch 127, Batch 33, Loss: 0.103\n",
      "Training: Epoch 127, Batch 34, Loss: 0.087\n",
      "Training: Epoch 127, Batch 35, Loss: 0.146\n",
      "Training: Epoch 127, Batch 36, Loss: 0.121\n",
      "Training: Epoch 127, Batch 37, Loss: 0.133\n",
      "Training: Epoch 127, Batch 38, Loss: 0.127\n",
      "Training: Epoch 127, Batch 39, Loss: 0.124\n",
      "Training: Epoch 127, Batch 40, Loss: 0.147\n",
      "Training: Epoch 127, Batch 41, Loss: 0.128\n",
      "Training: Epoch 127, Batch 42, Loss: 0.09\n",
      "Training: Epoch 127, Batch 43, Loss: 0.143\n",
      "Training: Epoch 127, Batch 44, Loss: 0.164\n",
      "Training: Epoch 127, Batch 45, Loss: 0.114\n",
      "Training: Epoch 127, Batch 46, Loss: 0.105\n",
      "Training: Epoch 127, Batch 47, Loss: 0.085\n",
      "Training: Epoch 127, Batch 48, Loss: 0.102\n",
      "Training: Epoch 127, Batch 49, Loss: 0.112\n",
      "Training: Epoch 127, Batch 50, Loss: 0.076\n",
      "Training: Epoch 127, Batch 51, Loss: 0.122\n",
      "Training: Epoch 127, Batch 52, Loss: 0.076\n",
      "Training: Epoch 127, Batch 53, Loss: 0.091\n",
      "Training: Epoch 127, Batch 54, Loss: 0.11\n",
      "Training: Epoch 127, Batch 55, Loss: 0.101\n",
      "Training: Epoch 127, Batch 56, Loss: 0.121\n",
      "Training: Epoch 127, Batch 57, Loss: 0.149\n",
      "Training: Epoch 127, Batch 58, Loss: 0.119\n",
      "Training: Epoch 127, Batch 59, Loss: 0.126\n",
      "Training: Epoch 127, Batch 60, Loss: 0.086\n",
      "Training: Epoch 127, Batch 61, Loss: 0.117\n",
      "Training: Epoch 127, Batch 62, Loss: 0.136\n",
      "Training: Epoch 127, Batch 63, Loss: 0.169\n",
      "Training: Epoch 127, Batch 64, Loss: 0.091\n",
      "Training: Epoch 127, Batch 65, Loss: 0.084\n",
      "Training: Epoch 127, Batch 66, Loss: 0.163\n",
      "Training: Epoch 127, Batch 67, Loss: 0.113\n",
      "Training: Epoch 127, Batch 68, Loss: 0.108\n",
      "Training: Epoch 127, Batch 69, Loss: 0.141\n",
      "Training: Epoch 127, Batch 70, Loss: 0.076\n",
      "Training: Epoch 127, Batch 71, Loss: 0.17\n",
      "Training: Epoch 127, Batch 72, Loss: 0.115\n",
      "Training: Epoch 127, Batch 73, Loss: 0.115\n",
      "Training: Epoch 127, Batch 74, Loss: 0.104\n",
      "Training: Epoch 127, Batch 75, Loss: 0.149\n",
      "Training: Epoch 127, Batch 76, Loss: 0.084\n",
      "Training: Epoch 127, Batch 77, Loss: 0.105\n",
      "Training: Epoch 127, Batch 78, Loss: 0.141\n",
      "Training: Epoch 127, Batch 79, Loss: 0.151\n",
      "Training: Epoch 127, Batch 80, Loss: 0.158\n",
      "Training: Epoch 127, Batch 81, Loss: 0.091\n",
      "Training: Epoch 127, Batch 82, Loss: 0.111\n",
      "Training: Epoch 127, Batch 83, Loss: 0.098\n",
      "Training: Epoch 127, Batch 84, Loss: 0.131\n",
      "Training: Epoch 127, Batch 85, Loss: 0.134\n",
      "Training: Epoch 127, Batch 86, Loss: 0.135\n",
      "Training: Epoch 127, Batch 87, Loss: 0.134\n",
      "Training: Epoch 127, Batch 88, Loss: 0.106\n",
      "Training: Epoch 127, Batch 89, Loss: 0.105\n",
      "Val: Epoch 127, Loss: 0.281\n",
      "Training: Epoch 128, Batch 0, Loss: 0.076\n",
      "Training: Epoch 128, Batch 1, Loss: 0.146\n",
      "Training: Epoch 128, Batch 2, Loss: 0.133\n",
      "Training: Epoch 128, Batch 3, Loss: 0.141\n",
      "Training: Epoch 128, Batch 4, Loss: 0.105\n",
      "Training: Epoch 128, Batch 5, Loss: 0.096\n",
      "Training: Epoch 128, Batch 6, Loss: 0.109\n",
      "Training: Epoch 128, Batch 7, Loss: 0.093\n",
      "Training: Epoch 128, Batch 8, Loss: 0.128\n",
      "Training: Epoch 128, Batch 9, Loss: 0.109\n",
      "Training: Epoch 128, Batch 10, Loss: 0.109\n",
      "Training: Epoch 128, Batch 11, Loss: 0.114\n",
      "Training: Epoch 128, Batch 12, Loss: 0.163\n",
      "Training: Epoch 128, Batch 13, Loss: 0.091\n",
      "Training: Epoch 128, Batch 14, Loss: 0.111\n",
      "Training: Epoch 128, Batch 15, Loss: 0.09\n",
      "Training: Epoch 128, Batch 16, Loss: 0.112\n",
      "Training: Epoch 128, Batch 17, Loss: 0.105\n",
      "Training: Epoch 128, Batch 18, Loss: 0.129\n",
      "Training: Epoch 128, Batch 19, Loss: 0.119\n",
      "Training: Epoch 128, Batch 20, Loss: 0.103\n",
      "Training: Epoch 128, Batch 21, Loss: 0.113\n",
      "Training: Epoch 128, Batch 22, Loss: 0.106\n",
      "Training: Epoch 128, Batch 23, Loss: 0.101\n",
      "Training: Epoch 128, Batch 24, Loss: 0.154\n",
      "Training: Epoch 128, Batch 25, Loss: 0.105\n",
      "Training: Epoch 128, Batch 26, Loss: 0.106\n",
      "Training: Epoch 128, Batch 27, Loss: 0.098\n",
      "Training: Epoch 128, Batch 28, Loss: 0.13\n",
      "Training: Epoch 128, Batch 29, Loss: 0.107\n",
      "Training: Epoch 128, Batch 30, Loss: 0.09\n",
      "Training: Epoch 128, Batch 31, Loss: 0.127\n",
      "Training: Epoch 128, Batch 32, Loss: 0.128\n",
      "Training: Epoch 128, Batch 33, Loss: 0.089\n",
      "Training: Epoch 128, Batch 34, Loss: 0.079\n",
      "Training: Epoch 128, Batch 35, Loss: 0.123\n",
      "Training: Epoch 128, Batch 36, Loss: 0.11\n",
      "Training: Epoch 128, Batch 37, Loss: 0.102\n",
      "Training: Epoch 128, Batch 38, Loss: 0.112\n",
      "Training: Epoch 128, Batch 39, Loss: 0.125\n",
      "Training: Epoch 128, Batch 40, Loss: 0.123\n",
      "Training: Epoch 128, Batch 41, Loss: 0.123\n",
      "Training: Epoch 128, Batch 42, Loss: 0.117\n",
      "Training: Epoch 128, Batch 43, Loss: 0.104\n",
      "Training: Epoch 128, Batch 44, Loss: 0.097\n",
      "Training: Epoch 128, Batch 45, Loss: 0.113\n",
      "Training: Epoch 128, Batch 46, Loss: 0.132\n",
      "Training: Epoch 128, Batch 47, Loss: 0.083\n",
      "Training: Epoch 128, Batch 48, Loss: 0.127\n",
      "Training: Epoch 128, Batch 49, Loss: 0.106\n",
      "Training: Epoch 128, Batch 50, Loss: 0.086\n",
      "Training: Epoch 128, Batch 51, Loss: 0.128\n",
      "Training: Epoch 128, Batch 52, Loss: 0.128\n",
      "Training: Epoch 128, Batch 53, Loss: 0.123\n",
      "Training: Epoch 128, Batch 54, Loss: 0.093\n",
      "Training: Epoch 128, Batch 55, Loss: 0.124\n",
      "Training: Epoch 128, Batch 56, Loss: 0.204\n",
      "Training: Epoch 128, Batch 57, Loss: 0.095\n",
      "Training: Epoch 128, Batch 58, Loss: 0.137\n",
      "Training: Epoch 128, Batch 59, Loss: 0.118\n",
      "Training: Epoch 128, Batch 60, Loss: 0.122\n",
      "Training: Epoch 128, Batch 61, Loss: 0.091\n",
      "Training: Epoch 128, Batch 62, Loss: 0.08\n",
      "Training: Epoch 128, Batch 63, Loss: 0.119\n",
      "Training: Epoch 128, Batch 64, Loss: 0.112\n",
      "Training: Epoch 128, Batch 65, Loss: 0.13\n",
      "Training: Epoch 128, Batch 66, Loss: 0.14\n",
      "Training: Epoch 128, Batch 67, Loss: 0.14\n",
      "Training: Epoch 128, Batch 68, Loss: 0.094\n",
      "Training: Epoch 128, Batch 69, Loss: 0.113\n",
      "Training: Epoch 128, Batch 70, Loss: 0.107\n",
      "Training: Epoch 128, Batch 71, Loss: 0.112\n",
      "Training: Epoch 128, Batch 72, Loss: 0.112\n",
      "Training: Epoch 128, Batch 73, Loss: 0.087\n",
      "Training: Epoch 128, Batch 74, Loss: 0.123\n",
      "Training: Epoch 128, Batch 75, Loss: 0.107\n",
      "Training: Epoch 128, Batch 76, Loss: 0.123\n",
      "Training: Epoch 128, Batch 77, Loss: 0.123\n",
      "Training: Epoch 128, Batch 78, Loss: 0.124\n",
      "Training: Epoch 128, Batch 79, Loss: 0.118\n",
      "Training: Epoch 128, Batch 80, Loss: 0.11\n",
      "Training: Epoch 128, Batch 81, Loss: 0.125\n",
      "Training: Epoch 128, Batch 82, Loss: 0.092\n",
      "Training: Epoch 128, Batch 83, Loss: 0.104\n",
      "Training: Epoch 128, Batch 84, Loss: 0.102\n",
      "Training: Epoch 128, Batch 85, Loss: 0.12\n",
      "Training: Epoch 128, Batch 86, Loss: 0.161\n",
      "Training: Epoch 128, Batch 87, Loss: 0.111\n",
      "Training: Epoch 128, Batch 88, Loss: 0.128\n",
      "Training: Epoch 128, Batch 89, Loss: 0.14\n",
      "Val: Epoch 128, Loss: 0.291\n",
      "Training: Epoch 129, Batch 0, Loss: 0.086\n",
      "Training: Epoch 129, Batch 1, Loss: 0.107\n",
      "Training: Epoch 129, Batch 2, Loss: 0.118\n",
      "Training: Epoch 129, Batch 3, Loss: 0.16\n",
      "Training: Epoch 129, Batch 4, Loss: 0.098\n",
      "Training: Epoch 129, Batch 5, Loss: 0.077\n",
      "Training: Epoch 129, Batch 6, Loss: 0.102\n",
      "Training: Epoch 129, Batch 7, Loss: 0.124\n",
      "Training: Epoch 129, Batch 8, Loss: 0.121\n",
      "Training: Epoch 129, Batch 9, Loss: 0.09\n",
      "Training: Epoch 129, Batch 10, Loss: 0.128\n",
      "Training: Epoch 129, Batch 11, Loss: 0.12\n",
      "Training: Epoch 129, Batch 12, Loss: 0.084\n",
      "Training: Epoch 129, Batch 13, Loss: 0.13\n",
      "Training: Epoch 129, Batch 14, Loss: 0.1\n",
      "Training: Epoch 129, Batch 15, Loss: 0.113\n",
      "Training: Epoch 129, Batch 16, Loss: 0.134\n",
      "Training: Epoch 129, Batch 17, Loss: 0.158\n",
      "Training: Epoch 129, Batch 18, Loss: 0.133\n",
      "Training: Epoch 129, Batch 19, Loss: 0.098\n",
      "Training: Epoch 129, Batch 20, Loss: 0.093\n",
      "Training: Epoch 129, Batch 21, Loss: 0.113\n",
      "Training: Epoch 129, Batch 22, Loss: 0.107\n",
      "Training: Epoch 129, Batch 23, Loss: 0.111\n",
      "Training: Epoch 129, Batch 24, Loss: 0.098\n",
      "Training: Epoch 129, Batch 25, Loss: 0.113\n",
      "Training: Epoch 129, Batch 26, Loss: 0.129\n",
      "Training: Epoch 129, Batch 27, Loss: 0.117\n",
      "Training: Epoch 129, Batch 28, Loss: 0.114\n",
      "Training: Epoch 129, Batch 29, Loss: 0.17\n",
      "Training: Epoch 129, Batch 30, Loss: 0.109\n",
      "Training: Epoch 129, Batch 31, Loss: 0.109\n",
      "Training: Epoch 129, Batch 32, Loss: 0.137\n",
      "Training: Epoch 129, Batch 33, Loss: 0.138\n",
      "Training: Epoch 129, Batch 34, Loss: 0.119\n",
      "Training: Epoch 129, Batch 35, Loss: 0.132\n",
      "Training: Epoch 129, Batch 36, Loss: 0.11\n",
      "Training: Epoch 129, Batch 37, Loss: 0.095\n",
      "Training: Epoch 129, Batch 38, Loss: 0.097\n",
      "Training: Epoch 129, Batch 39, Loss: 0.11\n",
      "Training: Epoch 129, Batch 40, Loss: 0.104\n",
      "Training: Epoch 129, Batch 41, Loss: 0.12\n",
      "Training: Epoch 129, Batch 42, Loss: 0.125\n",
      "Training: Epoch 129, Batch 43, Loss: 0.107\n",
      "Training: Epoch 129, Batch 44, Loss: 0.134\n",
      "Training: Epoch 129, Batch 45, Loss: 0.107\n",
      "Training: Epoch 129, Batch 46, Loss: 0.11\n",
      "Training: Epoch 129, Batch 47, Loss: 0.124\n",
      "Training: Epoch 129, Batch 48, Loss: 0.107\n",
      "Training: Epoch 129, Batch 49, Loss: 0.137\n",
      "Training: Epoch 129, Batch 50, Loss: 0.13\n",
      "Training: Epoch 129, Batch 51, Loss: 0.123\n",
      "Training: Epoch 129, Batch 52, Loss: 0.101\n",
      "Training: Epoch 129, Batch 53, Loss: 0.109\n",
      "Training: Epoch 129, Batch 54, Loss: 0.137\n",
      "Training: Epoch 129, Batch 55, Loss: 0.088\n",
      "Training: Epoch 129, Batch 56, Loss: 0.097\n",
      "Training: Epoch 129, Batch 57, Loss: 0.087\n",
      "Training: Epoch 129, Batch 58, Loss: 0.145\n",
      "Training: Epoch 129, Batch 59, Loss: 0.159\n",
      "Training: Epoch 129, Batch 60, Loss: 0.117\n",
      "Training: Epoch 129, Batch 61, Loss: 0.183\n",
      "Training: Epoch 129, Batch 62, Loss: 0.141\n",
      "Training: Epoch 129, Batch 63, Loss: 0.079\n",
      "Training: Epoch 129, Batch 64, Loss: 0.127\n",
      "Training: Epoch 129, Batch 65, Loss: 0.069\n",
      "Training: Epoch 129, Batch 66, Loss: 0.183\n",
      "Training: Epoch 129, Batch 67, Loss: 0.117\n",
      "Training: Epoch 129, Batch 68, Loss: 0.101\n",
      "Training: Epoch 129, Batch 69, Loss: 0.124\n",
      "Training: Epoch 129, Batch 70, Loss: 0.102\n",
      "Training: Epoch 129, Batch 71, Loss: 0.142\n",
      "Training: Epoch 129, Batch 72, Loss: 0.09\n",
      "Training: Epoch 129, Batch 73, Loss: 0.164\n",
      "Training: Epoch 129, Batch 74, Loss: 0.112\n",
      "Training: Epoch 129, Batch 75, Loss: 0.094\n",
      "Training: Epoch 129, Batch 76, Loss: 0.118\n",
      "Training: Epoch 129, Batch 77, Loss: 0.123\n",
      "Training: Epoch 129, Batch 78, Loss: 0.102\n",
      "Training: Epoch 129, Batch 79, Loss: 0.117\n",
      "Training: Epoch 129, Batch 80, Loss: 0.133\n",
      "Training: Epoch 129, Batch 81, Loss: 0.074\n",
      "Training: Epoch 129, Batch 82, Loss: 0.094\n",
      "Training: Epoch 129, Batch 83, Loss: 0.129\n",
      "Training: Epoch 129, Batch 84, Loss: 0.138\n",
      "Training: Epoch 129, Batch 85, Loss: 0.082\n",
      "Training: Epoch 129, Batch 86, Loss: 0.124\n",
      "Training: Epoch 129, Batch 87, Loss: 0.107\n",
      "Training: Epoch 129, Batch 88, Loss: 0.106\n",
      "Training: Epoch 129, Batch 89, Loss: 0.113\n",
      "Val: Epoch 129, Loss: 0.325\n",
      "Training: Epoch 130, Batch 0, Loss: 0.087\n",
      "Training: Epoch 130, Batch 1, Loss: 0.086\n",
      "Training: Epoch 130, Batch 2, Loss: 0.094\n",
      "Training: Epoch 130, Batch 3, Loss: 0.098\n",
      "Training: Epoch 130, Batch 4, Loss: 0.104\n",
      "Training: Epoch 130, Batch 5, Loss: 0.151\n",
      "Training: Epoch 130, Batch 6, Loss: 0.129\n",
      "Training: Epoch 130, Batch 7, Loss: 0.119\n",
      "Training: Epoch 130, Batch 8, Loss: 0.079\n",
      "Training: Epoch 130, Batch 9, Loss: 0.109\n",
      "Training: Epoch 130, Batch 10, Loss: 0.111\n",
      "Training: Epoch 130, Batch 11, Loss: 0.122\n",
      "Training: Epoch 130, Batch 12, Loss: 0.097\n",
      "Training: Epoch 130, Batch 13, Loss: 0.097\n",
      "Training: Epoch 130, Batch 14, Loss: 0.113\n",
      "Training: Epoch 130, Batch 15, Loss: 0.149\n",
      "Training: Epoch 130, Batch 16, Loss: 0.114\n",
      "Training: Epoch 130, Batch 17, Loss: 0.12\n",
      "Training: Epoch 130, Batch 18, Loss: 0.093\n",
      "Training: Epoch 130, Batch 19, Loss: 0.132\n",
      "Training: Epoch 130, Batch 20, Loss: 0.123\n",
      "Training: Epoch 130, Batch 21, Loss: 0.104\n",
      "Training: Epoch 130, Batch 22, Loss: 0.111\n",
      "Training: Epoch 130, Batch 23, Loss: 0.088\n",
      "Training: Epoch 130, Batch 24, Loss: 0.088\n",
      "Training: Epoch 130, Batch 25, Loss: 0.114\n",
      "Training: Epoch 130, Batch 26, Loss: 0.111\n",
      "Training: Epoch 130, Batch 27, Loss: 0.107\n",
      "Training: Epoch 130, Batch 28, Loss: 0.108\n",
      "Training: Epoch 130, Batch 29, Loss: 0.095\n",
      "Training: Epoch 130, Batch 30, Loss: 0.114\n",
      "Training: Epoch 130, Batch 31, Loss: 0.137\n",
      "Training: Epoch 130, Batch 32, Loss: 0.146\n",
      "Training: Epoch 130, Batch 33, Loss: 0.108\n",
      "Training: Epoch 130, Batch 34, Loss: 0.122\n",
      "Training: Epoch 130, Batch 35, Loss: 0.145\n",
      "Training: Epoch 130, Batch 36, Loss: 0.106\n",
      "Training: Epoch 130, Batch 37, Loss: 0.119\n",
      "Training: Epoch 130, Batch 38, Loss: 0.101\n",
      "Training: Epoch 130, Batch 39, Loss: 0.122\n",
      "Training: Epoch 130, Batch 40, Loss: 0.156\n",
      "Training: Epoch 130, Batch 41, Loss: 0.105\n",
      "Training: Epoch 130, Batch 42, Loss: 0.113\n",
      "Training: Epoch 130, Batch 43, Loss: 0.131\n",
      "Training: Epoch 130, Batch 44, Loss: 0.138\n",
      "Training: Epoch 130, Batch 45, Loss: 0.108\n",
      "Training: Epoch 130, Batch 46, Loss: 0.09\n",
      "Training: Epoch 130, Batch 47, Loss: 0.096\n",
      "Training: Epoch 130, Batch 48, Loss: 0.101\n",
      "Training: Epoch 130, Batch 49, Loss: 0.122\n",
      "Training: Epoch 130, Batch 50, Loss: 0.115\n",
      "Training: Epoch 130, Batch 51, Loss: 0.1\n",
      "Training: Epoch 130, Batch 52, Loss: 0.133\n",
      "Training: Epoch 130, Batch 53, Loss: 0.101\n",
      "Training: Epoch 130, Batch 54, Loss: 0.159\n",
      "Training: Epoch 130, Batch 55, Loss: 0.094\n",
      "Training: Epoch 130, Batch 56, Loss: 0.1\n",
      "Training: Epoch 130, Batch 57, Loss: 0.083\n",
      "Training: Epoch 130, Batch 58, Loss: 0.094\n",
      "Training: Epoch 130, Batch 59, Loss: 0.175\n",
      "Training: Epoch 130, Batch 60, Loss: 0.112\n",
      "Training: Epoch 130, Batch 61, Loss: 0.154\n",
      "Training: Epoch 130, Batch 62, Loss: 0.12\n",
      "Training: Epoch 130, Batch 63, Loss: 0.111\n",
      "Training: Epoch 130, Batch 64, Loss: 0.142\n",
      "Training: Epoch 130, Batch 65, Loss: 0.117\n",
      "Training: Epoch 130, Batch 66, Loss: 0.109\n",
      "Training: Epoch 130, Batch 67, Loss: 0.102\n",
      "Training: Epoch 130, Batch 68, Loss: 0.12\n",
      "Training: Epoch 130, Batch 69, Loss: 0.121\n",
      "Training: Epoch 130, Batch 70, Loss: 0.141\n",
      "Training: Epoch 130, Batch 71, Loss: 0.116\n",
      "Training: Epoch 130, Batch 72, Loss: 0.078\n",
      "Training: Epoch 130, Batch 73, Loss: 0.122\n",
      "Training: Epoch 130, Batch 74, Loss: 0.107\n",
      "Training: Epoch 130, Batch 75, Loss: 0.129\n",
      "Training: Epoch 130, Batch 76, Loss: 0.095\n",
      "Training: Epoch 130, Batch 77, Loss: 0.119\n",
      "Training: Epoch 130, Batch 78, Loss: 0.109\n",
      "Training: Epoch 130, Batch 79, Loss: 0.125\n",
      "Training: Epoch 130, Batch 80, Loss: 0.094\n",
      "Training: Epoch 130, Batch 81, Loss: 0.145\n",
      "Training: Epoch 130, Batch 82, Loss: 0.118\n",
      "Training: Epoch 130, Batch 83, Loss: 0.136\n",
      "Training: Epoch 130, Batch 84, Loss: 0.122\n",
      "Training: Epoch 130, Batch 85, Loss: 0.109\n",
      "Training: Epoch 130, Batch 86, Loss: 0.145\n",
      "Training: Epoch 130, Batch 87, Loss: 0.103\n",
      "Training: Epoch 130, Batch 88, Loss: 0.109\n",
      "Training: Epoch 130, Batch 89, Loss: 0.107\n",
      "Val: Epoch 130, Loss: 0.295\n",
      "Training: Epoch 131, Batch 0, Loss: 0.103\n",
      "Training: Epoch 131, Batch 1, Loss: 0.124\n",
      "Training: Epoch 131, Batch 2, Loss: 0.178\n",
      "Training: Epoch 131, Batch 3, Loss: 0.117\n",
      "Training: Epoch 131, Batch 4, Loss: 0.12\n",
      "Training: Epoch 131, Batch 5, Loss: 0.102\n",
      "Training: Epoch 131, Batch 6, Loss: 0.134\n",
      "Training: Epoch 131, Batch 7, Loss: 0.123\n",
      "Training: Epoch 131, Batch 8, Loss: 0.121\n",
      "Training: Epoch 131, Batch 9, Loss: 0.092\n",
      "Training: Epoch 131, Batch 10, Loss: 0.163\n",
      "Training: Epoch 131, Batch 11, Loss: 0.084\n",
      "Training: Epoch 131, Batch 12, Loss: 0.127\n",
      "Training: Epoch 131, Batch 13, Loss: 0.117\n",
      "Training: Epoch 131, Batch 14, Loss: 0.127\n",
      "Training: Epoch 131, Batch 15, Loss: 0.129\n",
      "Training: Epoch 131, Batch 16, Loss: 0.118\n",
      "Training: Epoch 131, Batch 17, Loss: 0.095\n",
      "Training: Epoch 131, Batch 18, Loss: 0.104\n",
      "Training: Epoch 131, Batch 19, Loss: 0.095\n",
      "Training: Epoch 131, Batch 20, Loss: 0.143\n",
      "Training: Epoch 131, Batch 21, Loss: 0.182\n",
      "Training: Epoch 131, Batch 22, Loss: 0.086\n",
      "Training: Epoch 131, Batch 23, Loss: 0.086\n",
      "Training: Epoch 131, Batch 24, Loss: 0.128\n",
      "Training: Epoch 131, Batch 25, Loss: 0.118\n",
      "Training: Epoch 131, Batch 26, Loss: 0.153\n",
      "Training: Epoch 131, Batch 27, Loss: 0.11\n",
      "Training: Epoch 131, Batch 28, Loss: 0.113\n",
      "Training: Epoch 131, Batch 29, Loss: 0.114\n",
      "Training: Epoch 131, Batch 30, Loss: 0.109\n",
      "Training: Epoch 131, Batch 31, Loss: 0.093\n",
      "Training: Epoch 131, Batch 32, Loss: 0.123\n",
      "Training: Epoch 131, Batch 33, Loss: 0.105\n",
      "Training: Epoch 131, Batch 34, Loss: 0.121\n",
      "Training: Epoch 131, Batch 35, Loss: 0.101\n",
      "Training: Epoch 131, Batch 36, Loss: 0.119\n",
      "Training: Epoch 131, Batch 37, Loss: 0.119\n",
      "Training: Epoch 131, Batch 38, Loss: 0.099\n",
      "Training: Epoch 131, Batch 39, Loss: 0.083\n",
      "Training: Epoch 131, Batch 40, Loss: 0.122\n",
      "Training: Epoch 131, Batch 41, Loss: 0.133\n",
      "Training: Epoch 131, Batch 42, Loss: 0.104\n",
      "Training: Epoch 131, Batch 43, Loss: 0.133\n",
      "Training: Epoch 131, Batch 44, Loss: 0.08\n",
      "Training: Epoch 131, Batch 45, Loss: 0.129\n",
      "Training: Epoch 131, Batch 46, Loss: 0.103\n",
      "Training: Epoch 131, Batch 47, Loss: 0.123\n",
      "Training: Epoch 131, Batch 48, Loss: 0.096\n",
      "Training: Epoch 131, Batch 49, Loss: 0.116\n",
      "Training: Epoch 131, Batch 50, Loss: 0.104\n",
      "Training: Epoch 131, Batch 51, Loss: 0.088\n",
      "Training: Epoch 131, Batch 52, Loss: 0.072\n",
      "Training: Epoch 131, Batch 53, Loss: 0.108\n",
      "Training: Epoch 131, Batch 54, Loss: 0.095\n",
      "Training: Epoch 131, Batch 55, Loss: 0.122\n",
      "Training: Epoch 131, Batch 56, Loss: 0.111\n",
      "Training: Epoch 131, Batch 57, Loss: 0.101\n",
      "Training: Epoch 131, Batch 58, Loss: 0.159\n",
      "Training: Epoch 131, Batch 59, Loss: 0.103\n",
      "Training: Epoch 131, Batch 60, Loss: 0.099\n",
      "Training: Epoch 131, Batch 61, Loss: 0.129\n",
      "Training: Epoch 131, Batch 62, Loss: 0.095\n",
      "Training: Epoch 131, Batch 63, Loss: 0.073\n",
      "Training: Epoch 131, Batch 64, Loss: 0.101\n",
      "Training: Epoch 131, Batch 65, Loss: 0.116\n",
      "Training: Epoch 131, Batch 66, Loss: 0.112\n",
      "Training: Epoch 131, Batch 67, Loss: 0.11\n",
      "Training: Epoch 131, Batch 68, Loss: 0.1\n",
      "Training: Epoch 131, Batch 69, Loss: 0.091\n",
      "Training: Epoch 131, Batch 70, Loss: 0.107\n",
      "Training: Epoch 131, Batch 71, Loss: 0.117\n",
      "Training: Epoch 131, Batch 72, Loss: 0.096\n",
      "Training: Epoch 131, Batch 73, Loss: 0.106\n",
      "Training: Epoch 131, Batch 74, Loss: 0.114\n",
      "Training: Epoch 131, Batch 75, Loss: 0.07\n",
      "Training: Epoch 131, Batch 76, Loss: 0.14\n",
      "Training: Epoch 131, Batch 77, Loss: 0.111\n",
      "Training: Epoch 131, Batch 78, Loss: 0.143\n",
      "Training: Epoch 131, Batch 79, Loss: 0.097\n",
      "Training: Epoch 131, Batch 80, Loss: 0.117\n",
      "Training: Epoch 131, Batch 81, Loss: 0.127\n",
      "Training: Epoch 131, Batch 82, Loss: 0.104\n",
      "Training: Epoch 131, Batch 83, Loss: 0.096\n",
      "Training: Epoch 131, Batch 84, Loss: 0.127\n",
      "Training: Epoch 131, Batch 85, Loss: 0.136\n",
      "Training: Epoch 131, Batch 86, Loss: 0.117\n",
      "Training: Epoch 131, Batch 87, Loss: 0.089\n",
      "Training: Epoch 131, Batch 88, Loss: 0.116\n",
      "Training: Epoch 131, Batch 89, Loss: 0.114\n",
      "Val: Epoch 131, Loss: 0.274\n",
      "Training: Epoch 132, Batch 0, Loss: 0.089\n",
      "Training: Epoch 132, Batch 1, Loss: 0.109\n",
      "Training: Epoch 132, Batch 2, Loss: 0.115\n",
      "Training: Epoch 132, Batch 3, Loss: 0.084\n",
      "Training: Epoch 132, Batch 4, Loss: 0.126\n",
      "Training: Epoch 132, Batch 5, Loss: 0.09\n",
      "Training: Epoch 132, Batch 6, Loss: 0.081\n",
      "Training: Epoch 132, Batch 7, Loss: 0.136\n",
      "Training: Epoch 132, Batch 8, Loss: 0.103\n",
      "Training: Epoch 132, Batch 9, Loss: 0.08\n",
      "Training: Epoch 132, Batch 10, Loss: 0.127\n",
      "Training: Epoch 132, Batch 11, Loss: 0.11\n",
      "Training: Epoch 132, Batch 12, Loss: 0.132\n",
      "Training: Epoch 132, Batch 13, Loss: 0.132\n",
      "Training: Epoch 132, Batch 14, Loss: 0.079\n",
      "Training: Epoch 132, Batch 15, Loss: 0.091\n",
      "Training: Epoch 132, Batch 16, Loss: 0.083\n",
      "Training: Epoch 132, Batch 17, Loss: 0.14\n",
      "Training: Epoch 132, Batch 18, Loss: 0.118\n",
      "Training: Epoch 132, Batch 19, Loss: 0.116\n",
      "Training: Epoch 132, Batch 20, Loss: 0.1\n",
      "Training: Epoch 132, Batch 21, Loss: 0.12\n",
      "Training: Epoch 132, Batch 22, Loss: 0.098\n",
      "Training: Epoch 132, Batch 23, Loss: 0.126\n",
      "Training: Epoch 132, Batch 24, Loss: 0.142\n",
      "Training: Epoch 132, Batch 25, Loss: 0.092\n",
      "Training: Epoch 132, Batch 26, Loss: 0.081\n",
      "Training: Epoch 132, Batch 27, Loss: 0.078\n",
      "Training: Epoch 132, Batch 28, Loss: 0.122\n",
      "Training: Epoch 132, Batch 29, Loss: 0.122\n",
      "Training: Epoch 132, Batch 30, Loss: 0.086\n",
      "Training: Epoch 132, Batch 31, Loss: 0.106\n",
      "Training: Epoch 132, Batch 32, Loss: 0.121\n",
      "Training: Epoch 132, Batch 33, Loss: 0.112\n",
      "Training: Epoch 132, Batch 34, Loss: 0.12\n",
      "Training: Epoch 132, Batch 35, Loss: 0.112\n",
      "Training: Epoch 132, Batch 36, Loss: 0.091\n",
      "Training: Epoch 132, Batch 37, Loss: 0.084\n",
      "Training: Epoch 132, Batch 38, Loss: 0.136\n",
      "Training: Epoch 132, Batch 39, Loss: 0.135\n",
      "Training: Epoch 132, Batch 40, Loss: 0.123\n",
      "Training: Epoch 132, Batch 41, Loss: 0.132\n",
      "Training: Epoch 132, Batch 42, Loss: 0.139\n",
      "Training: Epoch 132, Batch 43, Loss: 0.092\n",
      "Training: Epoch 132, Batch 44, Loss: 0.136\n",
      "Training: Epoch 132, Batch 45, Loss: 0.098\n",
      "Training: Epoch 132, Batch 46, Loss: 0.112\n",
      "Training: Epoch 132, Batch 47, Loss: 0.122\n",
      "Training: Epoch 132, Batch 48, Loss: 0.102\n",
      "Training: Epoch 132, Batch 49, Loss: 0.097\n",
      "Training: Epoch 132, Batch 50, Loss: 0.123\n",
      "Training: Epoch 132, Batch 51, Loss: 0.091\n",
      "Training: Epoch 132, Batch 52, Loss: 0.094\n",
      "Training: Epoch 132, Batch 53, Loss: 0.155\n",
      "Training: Epoch 132, Batch 54, Loss: 0.136\n",
      "Training: Epoch 132, Batch 55, Loss: 0.125\n",
      "Training: Epoch 132, Batch 56, Loss: 0.092\n",
      "Training: Epoch 132, Batch 57, Loss: 0.139\n",
      "Training: Epoch 132, Batch 58, Loss: 0.122\n",
      "Training: Epoch 132, Batch 59, Loss: 0.139\n",
      "Training: Epoch 132, Batch 60, Loss: 0.153\n",
      "Training: Epoch 132, Batch 61, Loss: 0.1\n",
      "Training: Epoch 132, Batch 62, Loss: 0.117\n",
      "Training: Epoch 132, Batch 63, Loss: 0.084\n",
      "Training: Epoch 132, Batch 64, Loss: 0.12\n",
      "Training: Epoch 132, Batch 65, Loss: 0.113\n",
      "Training: Epoch 132, Batch 66, Loss: 0.103\n",
      "Training: Epoch 132, Batch 67, Loss: 0.118\n",
      "Training: Epoch 132, Batch 68, Loss: 0.141\n",
      "Training: Epoch 132, Batch 69, Loss: 0.096\n",
      "Training: Epoch 132, Batch 70, Loss: 0.062\n",
      "Training: Epoch 132, Batch 71, Loss: 0.085\n",
      "Training: Epoch 132, Batch 72, Loss: 0.138\n",
      "Training: Epoch 132, Batch 73, Loss: 0.081\n",
      "Training: Epoch 132, Batch 74, Loss: 0.154\n",
      "Training: Epoch 132, Batch 75, Loss: 0.094\n",
      "Training: Epoch 132, Batch 76, Loss: 0.155\n",
      "Training: Epoch 132, Batch 77, Loss: 0.133\n",
      "Training: Epoch 132, Batch 78, Loss: 0.102\n",
      "Training: Epoch 132, Batch 79, Loss: 0.115\n",
      "Training: Epoch 132, Batch 80, Loss: 0.101\n",
      "Training: Epoch 132, Batch 81, Loss: 0.072\n",
      "Training: Epoch 132, Batch 82, Loss: 0.105\n",
      "Training: Epoch 132, Batch 83, Loss: 0.118\n",
      "Training: Epoch 132, Batch 84, Loss: 0.079\n",
      "Training: Epoch 132, Batch 85, Loss: 0.088\n",
      "Training: Epoch 132, Batch 86, Loss: 0.099\n",
      "Training: Epoch 132, Batch 87, Loss: 0.106\n",
      "Training: Epoch 132, Batch 88, Loss: 0.107\n",
      "Training: Epoch 132, Batch 89, Loss: 0.13\n",
      "Val: Epoch 132, Loss: 0.309\n",
      "Training: Epoch 133, Batch 0, Loss: 0.094\n",
      "Training: Epoch 133, Batch 1, Loss: 0.091\n",
      "Training: Epoch 133, Batch 2, Loss: 0.103\n",
      "Training: Epoch 133, Batch 3, Loss: 0.117\n",
      "Training: Epoch 133, Batch 4, Loss: 0.098\n",
      "Training: Epoch 133, Batch 5, Loss: 0.115\n",
      "Training: Epoch 133, Batch 6, Loss: 0.131\n",
      "Training: Epoch 133, Batch 7, Loss: 0.084\n",
      "Training: Epoch 133, Batch 8, Loss: 0.113\n",
      "Training: Epoch 133, Batch 9, Loss: 0.08\n",
      "Training: Epoch 133, Batch 10, Loss: 0.1\n",
      "Training: Epoch 133, Batch 11, Loss: 0.121\n",
      "Training: Epoch 133, Batch 12, Loss: 0.076\n",
      "Training: Epoch 133, Batch 13, Loss: 0.13\n",
      "Training: Epoch 133, Batch 14, Loss: 0.126\n",
      "Training: Epoch 133, Batch 15, Loss: 0.113\n",
      "Training: Epoch 133, Batch 16, Loss: 0.108\n",
      "Training: Epoch 133, Batch 17, Loss: 0.125\n",
      "Training: Epoch 133, Batch 18, Loss: 0.091\n",
      "Training: Epoch 133, Batch 19, Loss: 0.132\n",
      "Training: Epoch 133, Batch 20, Loss: 0.078\n",
      "Training: Epoch 133, Batch 21, Loss: 0.101\n",
      "Training: Epoch 133, Batch 22, Loss: 0.088\n",
      "Training: Epoch 133, Batch 23, Loss: 0.122\n",
      "Training: Epoch 133, Batch 24, Loss: 0.131\n",
      "Training: Epoch 133, Batch 25, Loss: 0.126\n",
      "Training: Epoch 133, Batch 26, Loss: 0.093\n",
      "Training: Epoch 133, Batch 27, Loss: 0.119\n",
      "Training: Epoch 133, Batch 28, Loss: 0.132\n",
      "Training: Epoch 133, Batch 29, Loss: 0.1\n",
      "Training: Epoch 133, Batch 30, Loss: 0.104\n",
      "Training: Epoch 133, Batch 31, Loss: 0.142\n",
      "Training: Epoch 133, Batch 32, Loss: 0.125\n",
      "Training: Epoch 133, Batch 33, Loss: 0.168\n",
      "Training: Epoch 133, Batch 34, Loss: 0.098\n",
      "Training: Epoch 133, Batch 35, Loss: 0.082\n",
      "Training: Epoch 133, Batch 36, Loss: 0.09\n",
      "Training: Epoch 133, Batch 37, Loss: 0.186\n",
      "Training: Epoch 133, Batch 38, Loss: 0.095\n",
      "Training: Epoch 133, Batch 39, Loss: 0.127\n",
      "Training: Epoch 133, Batch 40, Loss: 0.095\n",
      "Training: Epoch 133, Batch 41, Loss: 0.123\n",
      "Training: Epoch 133, Batch 42, Loss: 0.099\n",
      "Training: Epoch 133, Batch 43, Loss: 0.105\n",
      "Training: Epoch 133, Batch 44, Loss: 0.101\n",
      "Training: Epoch 133, Batch 45, Loss: 0.132\n",
      "Training: Epoch 133, Batch 46, Loss: 0.135\n",
      "Training: Epoch 133, Batch 47, Loss: 0.133\n",
      "Training: Epoch 133, Batch 48, Loss: 0.099\n",
      "Training: Epoch 133, Batch 49, Loss: 0.118\n",
      "Training: Epoch 133, Batch 50, Loss: 0.079\n",
      "Training: Epoch 133, Batch 51, Loss: 0.1\n",
      "Training: Epoch 133, Batch 52, Loss: 0.085\n",
      "Training: Epoch 133, Batch 53, Loss: 0.137\n",
      "Training: Epoch 133, Batch 54, Loss: 0.069\n",
      "Training: Epoch 133, Batch 55, Loss: 0.1\n",
      "Training: Epoch 133, Batch 56, Loss: 0.124\n",
      "Training: Epoch 133, Batch 57, Loss: 0.143\n",
      "Training: Epoch 133, Batch 58, Loss: 0.11\n",
      "Training: Epoch 133, Batch 59, Loss: 0.073\n",
      "Training: Epoch 133, Batch 60, Loss: 0.118\n",
      "Training: Epoch 133, Batch 61, Loss: 0.095\n",
      "Training: Epoch 133, Batch 62, Loss: 0.12\n",
      "Training: Epoch 133, Batch 63, Loss: 0.142\n",
      "Training: Epoch 133, Batch 64, Loss: 0.115\n",
      "Training: Epoch 133, Batch 65, Loss: 0.109\n",
      "Training: Epoch 133, Batch 66, Loss: 0.093\n",
      "Training: Epoch 133, Batch 67, Loss: 0.12\n",
      "Training: Epoch 133, Batch 68, Loss: 0.149\n",
      "Training: Epoch 133, Batch 69, Loss: 0.12\n",
      "Training: Epoch 133, Batch 70, Loss: 0.084\n",
      "Training: Epoch 133, Batch 71, Loss: 0.127\n",
      "Training: Epoch 133, Batch 72, Loss: 0.172\n",
      "Training: Epoch 133, Batch 73, Loss: 0.141\n",
      "Training: Epoch 133, Batch 74, Loss: 0.144\n",
      "Training: Epoch 133, Batch 75, Loss: 0.153\n",
      "Training: Epoch 133, Batch 76, Loss: 0.109\n",
      "Training: Epoch 133, Batch 77, Loss: 0.108\n",
      "Training: Epoch 133, Batch 78, Loss: 0.086\n",
      "Training: Epoch 133, Batch 79, Loss: 0.11\n",
      "Training: Epoch 133, Batch 80, Loss: 0.11\n",
      "Training: Epoch 133, Batch 81, Loss: 0.114\n",
      "Training: Epoch 133, Batch 82, Loss: 0.105\n",
      "Training: Epoch 133, Batch 83, Loss: 0.12\n",
      "Training: Epoch 133, Batch 84, Loss: 0.1\n",
      "Training: Epoch 133, Batch 85, Loss: 0.096\n",
      "Training: Epoch 133, Batch 86, Loss: 0.088\n",
      "Training: Epoch 133, Batch 87, Loss: 0.114\n",
      "Training: Epoch 133, Batch 88, Loss: 0.125\n",
      "Training: Epoch 133, Batch 89, Loss: 0.158\n",
      "Val: Epoch 133, Loss: 0.293\n",
      "Training: Epoch 134, Batch 0, Loss: 0.123\n",
      "Training: Epoch 134, Batch 1, Loss: 0.114\n",
      "Training: Epoch 134, Batch 2, Loss: 0.102\n",
      "Training: Epoch 134, Batch 3, Loss: 0.141\n",
      "Training: Epoch 134, Batch 4, Loss: 0.105\n",
      "Training: Epoch 134, Batch 5, Loss: 0.127\n",
      "Training: Epoch 134, Batch 6, Loss: 0.127\n",
      "Training: Epoch 134, Batch 7, Loss: 0.156\n",
      "Training: Epoch 134, Batch 8, Loss: 0.113\n",
      "Training: Epoch 134, Batch 9, Loss: 0.126\n",
      "Training: Epoch 134, Batch 10, Loss: 0.097\n",
      "Training: Epoch 134, Batch 11, Loss: 0.089\n",
      "Training: Epoch 134, Batch 12, Loss: 0.139\n",
      "Training: Epoch 134, Batch 13, Loss: 0.121\n",
      "Training: Epoch 134, Batch 14, Loss: 0.137\n",
      "Training: Epoch 134, Batch 15, Loss: 0.099\n",
      "Training: Epoch 134, Batch 16, Loss: 0.103\n",
      "Training: Epoch 134, Batch 17, Loss: 0.142\n",
      "Training: Epoch 134, Batch 18, Loss: 0.123\n",
      "Training: Epoch 134, Batch 19, Loss: 0.117\n",
      "Training: Epoch 134, Batch 20, Loss: 0.136\n",
      "Training: Epoch 134, Batch 21, Loss: 0.102\n",
      "Training: Epoch 134, Batch 22, Loss: 0.127\n",
      "Training: Epoch 134, Batch 23, Loss: 0.105\n",
      "Training: Epoch 134, Batch 24, Loss: 0.09\n",
      "Training: Epoch 134, Batch 25, Loss: 0.13\n",
      "Training: Epoch 134, Batch 26, Loss: 0.111\n",
      "Training: Epoch 134, Batch 27, Loss: 0.1\n",
      "Training: Epoch 134, Batch 28, Loss: 0.085\n",
      "Training: Epoch 134, Batch 29, Loss: 0.095\n",
      "Training: Epoch 134, Batch 30, Loss: 0.142\n",
      "Training: Epoch 134, Batch 31, Loss: 0.108\n",
      "Training: Epoch 134, Batch 32, Loss: 0.111\n",
      "Training: Epoch 134, Batch 33, Loss: 0.13\n",
      "Training: Epoch 134, Batch 34, Loss: 0.146\n",
      "Training: Epoch 134, Batch 35, Loss: 0.075\n",
      "Training: Epoch 134, Batch 36, Loss: 0.14\n",
      "Training: Epoch 134, Batch 37, Loss: 0.086\n",
      "Training: Epoch 134, Batch 38, Loss: 0.119\n",
      "Training: Epoch 134, Batch 39, Loss: 0.118\n",
      "Training: Epoch 134, Batch 40, Loss: 0.096\n",
      "Training: Epoch 134, Batch 41, Loss: 0.107\n",
      "Training: Epoch 134, Batch 42, Loss: 0.091\n",
      "Training: Epoch 134, Batch 43, Loss: 0.123\n",
      "Training: Epoch 134, Batch 44, Loss: 0.099\n",
      "Training: Epoch 134, Batch 45, Loss: 0.089\n",
      "Training: Epoch 134, Batch 46, Loss: 0.122\n",
      "Training: Epoch 134, Batch 47, Loss: 0.135\n",
      "Training: Epoch 134, Batch 48, Loss: 0.13\n",
      "Training: Epoch 134, Batch 49, Loss: 0.085\n",
      "Training: Epoch 134, Batch 50, Loss: 0.101\n",
      "Training: Epoch 134, Batch 51, Loss: 0.094\n",
      "Training: Epoch 134, Batch 52, Loss: 0.105\n",
      "Training: Epoch 134, Batch 53, Loss: 0.135\n",
      "Training: Epoch 134, Batch 54, Loss: 0.107\n",
      "Training: Epoch 134, Batch 55, Loss: 0.104\n",
      "Training: Epoch 134, Batch 56, Loss: 0.101\n",
      "Training: Epoch 134, Batch 57, Loss: 0.095\n",
      "Training: Epoch 134, Batch 58, Loss: 0.103\n",
      "Training: Epoch 134, Batch 59, Loss: 0.091\n",
      "Training: Epoch 134, Batch 60, Loss: 0.1\n",
      "Training: Epoch 134, Batch 61, Loss: 0.117\n",
      "Training: Epoch 134, Batch 62, Loss: 0.127\n",
      "Training: Epoch 134, Batch 63, Loss: 0.105\n",
      "Training: Epoch 134, Batch 64, Loss: 0.104\n",
      "Training: Epoch 134, Batch 65, Loss: 0.093\n",
      "Training: Epoch 134, Batch 66, Loss: 0.106\n",
      "Training: Epoch 134, Batch 67, Loss: 0.101\n",
      "Training: Epoch 134, Batch 68, Loss: 0.117\n",
      "Training: Epoch 134, Batch 69, Loss: 0.109\n",
      "Training: Epoch 134, Batch 70, Loss: 0.147\n",
      "Training: Epoch 134, Batch 71, Loss: 0.107\n",
      "Training: Epoch 134, Batch 72, Loss: 0.109\n",
      "Training: Epoch 134, Batch 73, Loss: 0.1\n",
      "Training: Epoch 134, Batch 74, Loss: 0.141\n",
      "Training: Epoch 134, Batch 75, Loss: 0.147\n",
      "Training: Epoch 134, Batch 76, Loss: 0.107\n",
      "Training: Epoch 134, Batch 77, Loss: 0.122\n",
      "Training: Epoch 134, Batch 78, Loss: 0.133\n",
      "Training: Epoch 134, Batch 79, Loss: 0.099\n",
      "Training: Epoch 134, Batch 80, Loss: 0.092\n",
      "Training: Epoch 134, Batch 81, Loss: 0.102\n",
      "Training: Epoch 134, Batch 82, Loss: 0.095\n",
      "Training: Epoch 134, Batch 83, Loss: 0.077\n",
      "Training: Epoch 134, Batch 84, Loss: 0.097\n",
      "Training: Epoch 134, Batch 85, Loss: 0.161\n",
      "Training: Epoch 134, Batch 86, Loss: 0.095\n",
      "Training: Epoch 134, Batch 87, Loss: 0.109\n",
      "Training: Epoch 134, Batch 88, Loss: 0.126\n",
      "Training: Epoch 134, Batch 89, Loss: 0.11\n",
      "Val: Epoch 134, Loss: 0.264\n",
      "Training: Epoch 135, Batch 0, Loss: 0.115\n",
      "Training: Epoch 135, Batch 1, Loss: 0.093\n",
      "Training: Epoch 135, Batch 2, Loss: 0.108\n",
      "Training: Epoch 135, Batch 3, Loss: 0.081\n",
      "Training: Epoch 135, Batch 4, Loss: 0.134\n",
      "Training: Epoch 135, Batch 5, Loss: 0.114\n",
      "Training: Epoch 135, Batch 6, Loss: 0.117\n",
      "Training: Epoch 135, Batch 7, Loss: 0.156\n",
      "Training: Epoch 135, Batch 8, Loss: 0.103\n",
      "Training: Epoch 135, Batch 9, Loss: 0.078\n",
      "Training: Epoch 135, Batch 10, Loss: 0.168\n",
      "Training: Epoch 135, Batch 11, Loss: 0.096\n",
      "Training: Epoch 135, Batch 12, Loss: 0.086\n",
      "Training: Epoch 135, Batch 13, Loss: 0.094\n",
      "Training: Epoch 135, Batch 14, Loss: 0.118\n",
      "Training: Epoch 135, Batch 15, Loss: 0.115\n",
      "Training: Epoch 135, Batch 16, Loss: 0.086\n",
      "Training: Epoch 135, Batch 17, Loss: 0.108\n",
      "Training: Epoch 135, Batch 18, Loss: 0.114\n",
      "Training: Epoch 135, Batch 19, Loss: 0.104\n",
      "Training: Epoch 135, Batch 20, Loss: 0.11\n",
      "Training: Epoch 135, Batch 21, Loss: 0.081\n",
      "Training: Epoch 135, Batch 22, Loss: 0.103\n",
      "Training: Epoch 135, Batch 23, Loss: 0.092\n",
      "Training: Epoch 135, Batch 24, Loss: 0.12\n",
      "Training: Epoch 135, Batch 25, Loss: 0.116\n",
      "Training: Epoch 135, Batch 26, Loss: 0.133\n",
      "Training: Epoch 135, Batch 27, Loss: 0.118\n",
      "Training: Epoch 135, Batch 28, Loss: 0.13\n",
      "Training: Epoch 135, Batch 29, Loss: 0.107\n",
      "Training: Epoch 135, Batch 30, Loss: 0.136\n",
      "Training: Epoch 135, Batch 31, Loss: 0.099\n",
      "Training: Epoch 135, Batch 32, Loss: 0.105\n",
      "Training: Epoch 135, Batch 33, Loss: 0.117\n",
      "Training: Epoch 135, Batch 34, Loss: 0.159\n",
      "Training: Epoch 135, Batch 35, Loss: 0.105\n",
      "Training: Epoch 135, Batch 36, Loss: 0.121\n",
      "Training: Epoch 135, Batch 37, Loss: 0.12\n",
      "Training: Epoch 135, Batch 38, Loss: 0.128\n",
      "Training: Epoch 135, Batch 39, Loss: 0.124\n",
      "Training: Epoch 135, Batch 40, Loss: 0.086\n",
      "Training: Epoch 135, Batch 41, Loss: 0.118\n",
      "Training: Epoch 135, Batch 42, Loss: 0.118\n",
      "Training: Epoch 135, Batch 43, Loss: 0.086\n",
      "Training: Epoch 135, Batch 44, Loss: 0.1\n",
      "Training: Epoch 135, Batch 45, Loss: 0.107\n",
      "Training: Epoch 135, Batch 46, Loss: 0.117\n",
      "Training: Epoch 135, Batch 47, Loss: 0.109\n",
      "Training: Epoch 135, Batch 48, Loss: 0.13\n",
      "Training: Epoch 135, Batch 49, Loss: 0.086\n",
      "Training: Epoch 135, Batch 50, Loss: 0.123\n",
      "Training: Epoch 135, Batch 51, Loss: 0.152\n",
      "Training: Epoch 135, Batch 52, Loss: 0.098\n",
      "Training: Epoch 135, Batch 53, Loss: 0.098\n",
      "Training: Epoch 135, Batch 54, Loss: 0.1\n",
      "Training: Epoch 135, Batch 55, Loss: 0.091\n",
      "Training: Epoch 135, Batch 56, Loss: 0.081\n",
      "Training: Epoch 135, Batch 57, Loss: 0.155\n",
      "Training: Epoch 135, Batch 58, Loss: 0.102\n",
      "Training: Epoch 135, Batch 59, Loss: 0.085\n",
      "Training: Epoch 135, Batch 60, Loss: 0.117\n",
      "Training: Epoch 135, Batch 61, Loss: 0.113\n",
      "Training: Epoch 135, Batch 62, Loss: 0.09\n",
      "Training: Epoch 135, Batch 63, Loss: 0.121\n",
      "Training: Epoch 135, Batch 64, Loss: 0.127\n",
      "Training: Epoch 135, Batch 65, Loss: 0.167\n",
      "Training: Epoch 135, Batch 66, Loss: 0.149\n",
      "Training: Epoch 135, Batch 67, Loss: 0.119\n",
      "Training: Epoch 135, Batch 68, Loss: 0.099\n",
      "Training: Epoch 135, Batch 69, Loss: 0.103\n",
      "Training: Epoch 135, Batch 70, Loss: 0.089\n",
      "Training: Epoch 135, Batch 71, Loss: 0.086\n",
      "Training: Epoch 135, Batch 72, Loss: 0.121\n",
      "Training: Epoch 135, Batch 73, Loss: 0.118\n",
      "Training: Epoch 135, Batch 74, Loss: 0.128\n",
      "Training: Epoch 135, Batch 75, Loss: 0.121\n",
      "Training: Epoch 135, Batch 76, Loss: 0.128\n",
      "Training: Epoch 135, Batch 77, Loss: 0.076\n",
      "Training: Epoch 135, Batch 78, Loss: 0.101\n",
      "Training: Epoch 135, Batch 79, Loss: 0.101\n",
      "Training: Epoch 135, Batch 80, Loss: 0.088\n",
      "Training: Epoch 135, Batch 81, Loss: 0.091\n",
      "Training: Epoch 135, Batch 82, Loss: 0.137\n",
      "Training: Epoch 135, Batch 83, Loss: 0.12\n",
      "Training: Epoch 135, Batch 84, Loss: 0.122\n",
      "Training: Epoch 135, Batch 85, Loss: 0.096\n",
      "Training: Epoch 135, Batch 86, Loss: 0.11\n",
      "Training: Epoch 135, Batch 87, Loss: 0.162\n",
      "Training: Epoch 135, Batch 88, Loss: 0.153\n",
      "Training: Epoch 135, Batch 89, Loss: 0.123\n",
      "Val: Epoch 135, Loss: 0.331\n",
      "Training: Epoch 136, Batch 0, Loss: 0.099\n",
      "Training: Epoch 136, Batch 1, Loss: 0.136\n",
      "Training: Epoch 136, Batch 2, Loss: 0.108\n",
      "Training: Epoch 136, Batch 3, Loss: 0.093\n",
      "Training: Epoch 136, Batch 4, Loss: 0.133\n",
      "Training: Epoch 136, Batch 5, Loss: 0.097\n",
      "Training: Epoch 136, Batch 6, Loss: 0.11\n",
      "Training: Epoch 136, Batch 7, Loss: 0.09\n",
      "Training: Epoch 136, Batch 8, Loss: 0.081\n",
      "Training: Epoch 136, Batch 9, Loss: 0.119\n",
      "Training: Epoch 136, Batch 10, Loss: 0.108\n",
      "Training: Epoch 136, Batch 11, Loss: 0.111\n",
      "Training: Epoch 136, Batch 12, Loss: 0.144\n",
      "Training: Epoch 136, Batch 13, Loss: 0.115\n",
      "Training: Epoch 136, Batch 14, Loss: 0.094\n",
      "Training: Epoch 136, Batch 15, Loss: 0.15\n",
      "Training: Epoch 136, Batch 16, Loss: 0.113\n",
      "Training: Epoch 136, Batch 17, Loss: 0.117\n",
      "Training: Epoch 136, Batch 18, Loss: 0.088\n",
      "Training: Epoch 136, Batch 19, Loss: 0.082\n",
      "Training: Epoch 136, Batch 20, Loss: 0.142\n",
      "Training: Epoch 136, Batch 21, Loss: 0.115\n",
      "Training: Epoch 136, Batch 22, Loss: 0.116\n",
      "Training: Epoch 136, Batch 23, Loss: 0.133\n",
      "Training: Epoch 136, Batch 24, Loss: 0.159\n",
      "Training: Epoch 136, Batch 25, Loss: 0.136\n",
      "Training: Epoch 136, Batch 26, Loss: 0.119\n",
      "Training: Epoch 136, Batch 27, Loss: 0.126\n",
      "Training: Epoch 136, Batch 28, Loss: 0.096\n",
      "Training: Epoch 136, Batch 29, Loss: 0.113\n",
      "Training: Epoch 136, Batch 30, Loss: 0.084\n",
      "Training: Epoch 136, Batch 31, Loss: 0.153\n",
      "Training: Epoch 136, Batch 32, Loss: 0.121\n",
      "Training: Epoch 136, Batch 33, Loss: 0.099\n",
      "Training: Epoch 136, Batch 34, Loss: 0.147\n",
      "Training: Epoch 136, Batch 35, Loss: 0.098\n",
      "Training: Epoch 136, Batch 36, Loss: 0.105\n",
      "Training: Epoch 136, Batch 37, Loss: 0.123\n",
      "Training: Epoch 136, Batch 38, Loss: 0.123\n",
      "Training: Epoch 136, Batch 39, Loss: 0.081\n",
      "Training: Epoch 136, Batch 40, Loss: 0.077\n",
      "Training: Epoch 136, Batch 41, Loss: 0.108\n",
      "Training: Epoch 136, Batch 42, Loss: 0.102\n",
      "Training: Epoch 136, Batch 43, Loss: 0.084\n",
      "Training: Epoch 136, Batch 44, Loss: 0.102\n",
      "Training: Epoch 136, Batch 45, Loss: 0.143\n",
      "Training: Epoch 136, Batch 46, Loss: 0.106\n",
      "Training: Epoch 136, Batch 47, Loss: 0.118\n",
      "Training: Epoch 136, Batch 48, Loss: 0.12\n",
      "Training: Epoch 136, Batch 49, Loss: 0.08\n",
      "Training: Epoch 136, Batch 50, Loss: 0.148\n",
      "Training: Epoch 136, Batch 51, Loss: 0.115\n",
      "Training: Epoch 136, Batch 52, Loss: 0.098\n",
      "Training: Epoch 136, Batch 53, Loss: 0.129\n",
      "Training: Epoch 136, Batch 54, Loss: 0.084\n",
      "Training: Epoch 136, Batch 55, Loss: 0.117\n",
      "Training: Epoch 136, Batch 56, Loss: 0.091\n",
      "Training: Epoch 136, Batch 57, Loss: 0.105\n",
      "Training: Epoch 136, Batch 58, Loss: 0.097\n",
      "Training: Epoch 136, Batch 59, Loss: 0.124\n",
      "Training: Epoch 136, Batch 60, Loss: 0.111\n",
      "Training: Epoch 136, Batch 61, Loss: 0.111\n",
      "Training: Epoch 136, Batch 62, Loss: 0.127\n",
      "Training: Epoch 136, Batch 63, Loss: 0.139\n",
      "Training: Epoch 136, Batch 64, Loss: 0.099\n",
      "Training: Epoch 136, Batch 65, Loss: 0.13\n",
      "Training: Epoch 136, Batch 66, Loss: 0.089\n",
      "Training: Epoch 136, Batch 67, Loss: 0.108\n",
      "Training: Epoch 136, Batch 68, Loss: 0.139\n",
      "Training: Epoch 136, Batch 69, Loss: 0.121\n",
      "Training: Epoch 136, Batch 70, Loss: 0.114\n",
      "Training: Epoch 136, Batch 71, Loss: 0.092\n",
      "Training: Epoch 136, Batch 72, Loss: 0.1\n",
      "Training: Epoch 136, Batch 73, Loss: 0.078\n",
      "Training: Epoch 136, Batch 74, Loss: 0.148\n",
      "Training: Epoch 136, Batch 75, Loss: 0.13\n",
      "Training: Epoch 136, Batch 76, Loss: 0.124\n",
      "Training: Epoch 136, Batch 77, Loss: 0.123\n",
      "Training: Epoch 136, Batch 78, Loss: 0.123\n",
      "Training: Epoch 136, Batch 79, Loss: 0.094\n",
      "Training: Epoch 136, Batch 80, Loss: 0.109\n",
      "Training: Epoch 136, Batch 81, Loss: 0.114\n",
      "Training: Epoch 136, Batch 82, Loss: 0.141\n",
      "Training: Epoch 136, Batch 83, Loss: 0.103\n",
      "Training: Epoch 136, Batch 84, Loss: 0.083\n",
      "Training: Epoch 136, Batch 85, Loss: 0.096\n",
      "Training: Epoch 136, Batch 86, Loss: 0.089\n",
      "Training: Epoch 136, Batch 87, Loss: 0.123\n",
      "Training: Epoch 136, Batch 88, Loss: 0.099\n",
      "Training: Epoch 136, Batch 89, Loss: 0.107\n",
      "Val: Epoch 136, Loss: 0.29\n",
      "Training: Epoch 137, Batch 0, Loss: 0.085\n",
      "Training: Epoch 137, Batch 1, Loss: 0.113\n",
      "Training: Epoch 137, Batch 2, Loss: 0.116\n",
      "Training: Epoch 137, Batch 3, Loss: 0.1\n",
      "Training: Epoch 137, Batch 4, Loss: 0.078\n",
      "Training: Epoch 137, Batch 5, Loss: 0.11\n",
      "Training: Epoch 137, Batch 6, Loss: 0.093\n",
      "Training: Epoch 137, Batch 7, Loss: 0.13\n",
      "Training: Epoch 137, Batch 8, Loss: 0.1\n",
      "Training: Epoch 137, Batch 9, Loss: 0.084\n",
      "Training: Epoch 137, Batch 10, Loss: 0.131\n",
      "Training: Epoch 137, Batch 11, Loss: 0.11\n",
      "Training: Epoch 137, Batch 12, Loss: 0.106\n",
      "Training: Epoch 137, Batch 13, Loss: 0.111\n",
      "Training: Epoch 137, Batch 14, Loss: 0.094\n",
      "Training: Epoch 137, Batch 15, Loss: 0.119\n",
      "Training: Epoch 137, Batch 16, Loss: 0.103\n",
      "Training: Epoch 137, Batch 17, Loss: 0.104\n",
      "Training: Epoch 137, Batch 18, Loss: 0.129\n",
      "Training: Epoch 137, Batch 19, Loss: 0.087\n",
      "Training: Epoch 137, Batch 20, Loss: 0.143\n",
      "Training: Epoch 137, Batch 21, Loss: 0.113\n",
      "Training: Epoch 137, Batch 22, Loss: 0.12\n",
      "Training: Epoch 137, Batch 23, Loss: 0.088\n",
      "Training: Epoch 137, Batch 24, Loss: 0.117\n",
      "Training: Epoch 137, Batch 25, Loss: 0.131\n",
      "Training: Epoch 137, Batch 26, Loss: 0.073\n",
      "Training: Epoch 137, Batch 27, Loss: 0.099\n",
      "Training: Epoch 137, Batch 28, Loss: 0.13\n",
      "Training: Epoch 137, Batch 29, Loss: 0.105\n",
      "Training: Epoch 137, Batch 30, Loss: 0.14\n",
      "Training: Epoch 137, Batch 31, Loss: 0.078\n",
      "Training: Epoch 137, Batch 32, Loss: 0.117\n",
      "Training: Epoch 137, Batch 33, Loss: 0.122\n",
      "Training: Epoch 137, Batch 34, Loss: 0.119\n",
      "Training: Epoch 137, Batch 35, Loss: 0.105\n",
      "Training: Epoch 137, Batch 36, Loss: 0.11\n",
      "Training: Epoch 137, Batch 37, Loss: 0.08\n",
      "Training: Epoch 137, Batch 38, Loss: 0.101\n",
      "Training: Epoch 137, Batch 39, Loss: 0.106\n",
      "Training: Epoch 137, Batch 40, Loss: 0.098\n",
      "Training: Epoch 137, Batch 41, Loss: 0.129\n",
      "Training: Epoch 137, Batch 42, Loss: 0.092\n",
      "Training: Epoch 137, Batch 43, Loss: 0.126\n",
      "Training: Epoch 137, Batch 44, Loss: 0.112\n",
      "Training: Epoch 137, Batch 45, Loss: 0.124\n",
      "Training: Epoch 137, Batch 46, Loss: 0.113\n",
      "Training: Epoch 137, Batch 47, Loss: 0.105\n",
      "Training: Epoch 137, Batch 48, Loss: 0.103\n",
      "Training: Epoch 137, Batch 49, Loss: 0.124\n",
      "Training: Epoch 137, Batch 50, Loss: 0.086\n",
      "Training: Epoch 137, Batch 51, Loss: 0.088\n",
      "Training: Epoch 137, Batch 52, Loss: 0.105\n",
      "Training: Epoch 137, Batch 53, Loss: 0.121\n",
      "Training: Epoch 137, Batch 54, Loss: 0.118\n",
      "Training: Epoch 137, Batch 55, Loss: 0.075\n",
      "Training: Epoch 137, Batch 56, Loss: 0.107\n",
      "Training: Epoch 137, Batch 57, Loss: 0.178\n",
      "Training: Epoch 137, Batch 58, Loss: 0.16\n",
      "Training: Epoch 137, Batch 59, Loss: 0.126\n",
      "Training: Epoch 137, Batch 60, Loss: 0.094\n",
      "Training: Epoch 137, Batch 61, Loss: 0.095\n",
      "Training: Epoch 137, Batch 62, Loss: 0.124\n",
      "Training: Epoch 137, Batch 63, Loss: 0.092\n",
      "Training: Epoch 137, Batch 64, Loss: 0.136\n",
      "Training: Epoch 137, Batch 65, Loss: 0.118\n",
      "Training: Epoch 137, Batch 66, Loss: 0.068\n",
      "Training: Epoch 137, Batch 67, Loss: 0.119\n",
      "Training: Epoch 137, Batch 68, Loss: 0.132\n",
      "Training: Epoch 137, Batch 69, Loss: 0.101\n",
      "Training: Epoch 137, Batch 70, Loss: 0.116\n",
      "Training: Epoch 137, Batch 71, Loss: 0.073\n",
      "Training: Epoch 137, Batch 72, Loss: 0.092\n",
      "Training: Epoch 137, Batch 73, Loss: 0.083\n",
      "Training: Epoch 137, Batch 74, Loss: 0.105\n",
      "Training: Epoch 137, Batch 75, Loss: 0.086\n",
      "Training: Epoch 137, Batch 76, Loss: 0.097\n",
      "Training: Epoch 137, Batch 77, Loss: 0.119\n",
      "Training: Epoch 137, Batch 78, Loss: 0.093\n",
      "Training: Epoch 137, Batch 79, Loss: 0.078\n",
      "Training: Epoch 137, Batch 80, Loss: 0.118\n",
      "Training: Epoch 137, Batch 81, Loss: 0.125\n",
      "Training: Epoch 137, Batch 82, Loss: 0.098\n",
      "Training: Epoch 137, Batch 83, Loss: 0.115\n",
      "Training: Epoch 137, Batch 84, Loss: 0.073\n",
      "Training: Epoch 137, Batch 85, Loss: 0.093\n",
      "Training: Epoch 137, Batch 86, Loss: 0.133\n",
      "Training: Epoch 137, Batch 87, Loss: 0.103\n",
      "Training: Epoch 137, Batch 88, Loss: 0.089\n",
      "Training: Epoch 137, Batch 89, Loss: 0.108\n",
      "Val: Epoch 137, Loss: 0.296\n",
      "Training: Epoch 138, Batch 0, Loss: 0.117\n",
      "Training: Epoch 138, Batch 1, Loss: 0.119\n",
      "Training: Epoch 138, Batch 2, Loss: 0.084\n",
      "Training: Epoch 138, Batch 3, Loss: 0.078\n",
      "Training: Epoch 138, Batch 4, Loss: 0.136\n",
      "Training: Epoch 138, Batch 5, Loss: 0.102\n",
      "Training: Epoch 138, Batch 6, Loss: 0.082\n",
      "Training: Epoch 138, Batch 7, Loss: 0.108\n",
      "Training: Epoch 138, Batch 8, Loss: 0.116\n",
      "Training: Epoch 138, Batch 9, Loss: 0.097\n",
      "Training: Epoch 138, Batch 10, Loss: 0.106\n",
      "Training: Epoch 138, Batch 11, Loss: 0.106\n",
      "Training: Epoch 138, Batch 12, Loss: 0.074\n",
      "Training: Epoch 138, Batch 13, Loss: 0.092\n",
      "Training: Epoch 138, Batch 14, Loss: 0.072\n",
      "Training: Epoch 138, Batch 15, Loss: 0.107\n",
      "Training: Epoch 138, Batch 16, Loss: 0.118\n",
      "Training: Epoch 138, Batch 17, Loss: 0.157\n",
      "Training: Epoch 138, Batch 18, Loss: 0.12\n",
      "Training: Epoch 138, Batch 19, Loss: 0.076\n",
      "Training: Epoch 138, Batch 20, Loss: 0.132\n",
      "Training: Epoch 138, Batch 21, Loss: 0.119\n",
      "Training: Epoch 138, Batch 22, Loss: 0.131\n",
      "Training: Epoch 138, Batch 23, Loss: 0.114\n",
      "Training: Epoch 138, Batch 24, Loss: 0.16\n",
      "Training: Epoch 138, Batch 25, Loss: 0.119\n",
      "Training: Epoch 138, Batch 26, Loss: 0.128\n",
      "Training: Epoch 138, Batch 27, Loss: 0.128\n",
      "Training: Epoch 138, Batch 28, Loss: 0.112\n",
      "Training: Epoch 138, Batch 29, Loss: 0.135\n",
      "Training: Epoch 138, Batch 30, Loss: 0.096\n",
      "Training: Epoch 138, Batch 31, Loss: 0.104\n",
      "Training: Epoch 138, Batch 32, Loss: 0.086\n",
      "Training: Epoch 138, Batch 33, Loss: 0.124\n",
      "Training: Epoch 138, Batch 34, Loss: 0.074\n",
      "Training: Epoch 138, Batch 35, Loss: 0.114\n",
      "Training: Epoch 138, Batch 36, Loss: 0.113\n",
      "Training: Epoch 138, Batch 37, Loss: 0.129\n",
      "Training: Epoch 138, Batch 38, Loss: 0.122\n",
      "Training: Epoch 138, Batch 39, Loss: 0.095\n",
      "Training: Epoch 138, Batch 40, Loss: 0.127\n",
      "Training: Epoch 138, Batch 41, Loss: 0.108\n",
      "Training: Epoch 138, Batch 42, Loss: 0.104\n",
      "Training: Epoch 138, Batch 43, Loss: 0.098\n",
      "Training: Epoch 138, Batch 44, Loss: 0.098\n",
      "Training: Epoch 138, Batch 45, Loss: 0.091\n",
      "Training: Epoch 138, Batch 46, Loss: 0.1\n",
      "Training: Epoch 138, Batch 47, Loss: 0.125\n",
      "Training: Epoch 138, Batch 48, Loss: 0.089\n",
      "Training: Epoch 138, Batch 49, Loss: 0.131\n",
      "Training: Epoch 138, Batch 50, Loss: 0.107\n",
      "Training: Epoch 138, Batch 51, Loss: 0.102\n",
      "Training: Epoch 138, Batch 52, Loss: 0.11\n",
      "Training: Epoch 138, Batch 53, Loss: 0.099\n",
      "Training: Epoch 138, Batch 54, Loss: 0.104\n",
      "Training: Epoch 138, Batch 55, Loss: 0.153\n",
      "Training: Epoch 138, Batch 56, Loss: 0.114\n",
      "Training: Epoch 138, Batch 57, Loss: 0.081\n",
      "Training: Epoch 138, Batch 58, Loss: 0.112\n",
      "Training: Epoch 138, Batch 59, Loss: 0.128\n",
      "Training: Epoch 138, Batch 60, Loss: 0.083\n",
      "Training: Epoch 138, Batch 61, Loss: 0.111\n",
      "Training: Epoch 138, Batch 62, Loss: 0.101\n",
      "Training: Epoch 138, Batch 63, Loss: 0.103\n",
      "Training: Epoch 138, Batch 64, Loss: 0.088\n",
      "Training: Epoch 138, Batch 65, Loss: 0.101\n",
      "Training: Epoch 138, Batch 66, Loss: 0.11\n",
      "Training: Epoch 138, Batch 67, Loss: 0.105\n",
      "Training: Epoch 138, Batch 68, Loss: 0.102\n",
      "Training: Epoch 138, Batch 69, Loss: 0.135\n",
      "Training: Epoch 138, Batch 70, Loss: 0.119\n",
      "Training: Epoch 138, Batch 71, Loss: 0.095\n",
      "Training: Epoch 138, Batch 72, Loss: 0.096\n",
      "Training: Epoch 138, Batch 73, Loss: 0.119\n",
      "Training: Epoch 138, Batch 74, Loss: 0.096\n",
      "Training: Epoch 138, Batch 75, Loss: 0.102\n",
      "Training: Epoch 138, Batch 76, Loss: 0.116\n",
      "Training: Epoch 138, Batch 77, Loss: 0.112\n",
      "Training: Epoch 138, Batch 78, Loss: 0.082\n",
      "Training: Epoch 138, Batch 79, Loss: 0.074\n",
      "Training: Epoch 138, Batch 80, Loss: 0.125\n",
      "Training: Epoch 138, Batch 81, Loss: 0.121\n",
      "Training: Epoch 138, Batch 82, Loss: 0.098\n",
      "Training: Epoch 138, Batch 83, Loss: 0.129\n",
      "Training: Epoch 138, Batch 84, Loss: 0.11\n",
      "Training: Epoch 138, Batch 85, Loss: 0.126\n",
      "Training: Epoch 138, Batch 86, Loss: 0.145\n",
      "Training: Epoch 138, Batch 87, Loss: 0.111\n",
      "Training: Epoch 138, Batch 88, Loss: 0.104\n",
      "Training: Epoch 138, Batch 89, Loss: 0.081\n",
      "Val: Epoch 138, Loss: 0.295\n",
      "Training: Epoch 139, Batch 0, Loss: 0.105\n",
      "Training: Epoch 139, Batch 1, Loss: 0.126\n",
      "Training: Epoch 139, Batch 2, Loss: 0.103\n",
      "Training: Epoch 139, Batch 3, Loss: 0.123\n",
      "Training: Epoch 139, Batch 4, Loss: 0.096\n",
      "Training: Epoch 139, Batch 5, Loss: 0.094\n",
      "Training: Epoch 139, Batch 6, Loss: 0.09\n",
      "Training: Epoch 139, Batch 7, Loss: 0.131\n",
      "Training: Epoch 139, Batch 8, Loss: 0.117\n",
      "Training: Epoch 139, Batch 9, Loss: 0.105\n",
      "Training: Epoch 139, Batch 10, Loss: 0.107\n",
      "Training: Epoch 139, Batch 11, Loss: 0.1\n",
      "Training: Epoch 139, Batch 12, Loss: 0.099\n",
      "Training: Epoch 139, Batch 13, Loss: 0.095\n",
      "Training: Epoch 139, Batch 14, Loss: 0.1\n",
      "Training: Epoch 139, Batch 15, Loss: 0.104\n",
      "Training: Epoch 139, Batch 16, Loss: 0.125\n",
      "Training: Epoch 139, Batch 17, Loss: 0.113\n",
      "Training: Epoch 139, Batch 18, Loss: 0.107\n",
      "Training: Epoch 139, Batch 19, Loss: 0.139\n",
      "Training: Epoch 139, Batch 20, Loss: 0.139\n",
      "Training: Epoch 139, Batch 21, Loss: 0.115\n",
      "Training: Epoch 139, Batch 22, Loss: 0.114\n",
      "Training: Epoch 139, Batch 23, Loss: 0.14\n",
      "Training: Epoch 139, Batch 24, Loss: 0.139\n",
      "Training: Epoch 139, Batch 25, Loss: 0.176\n",
      "Training: Epoch 139, Batch 26, Loss: 0.084\n",
      "Training: Epoch 139, Batch 27, Loss: 0.101\n",
      "Training: Epoch 139, Batch 28, Loss: 0.092\n",
      "Training: Epoch 139, Batch 29, Loss: 0.098\n",
      "Training: Epoch 139, Batch 30, Loss: 0.093\n",
      "Training: Epoch 139, Batch 31, Loss: 0.117\n",
      "Training: Epoch 139, Batch 32, Loss: 0.084\n",
      "Training: Epoch 139, Batch 33, Loss: 0.119\n",
      "Training: Epoch 139, Batch 34, Loss: 0.112\n",
      "Training: Epoch 139, Batch 35, Loss: 0.09\n",
      "Training: Epoch 139, Batch 36, Loss: 0.138\n",
      "Training: Epoch 139, Batch 37, Loss: 0.105\n",
      "Training: Epoch 139, Batch 38, Loss: 0.126\n",
      "Training: Epoch 139, Batch 39, Loss: 0.065\n",
      "Training: Epoch 139, Batch 40, Loss: 0.113\n",
      "Training: Epoch 139, Batch 41, Loss: 0.105\n",
      "Training: Epoch 139, Batch 42, Loss: 0.098\n",
      "Training: Epoch 139, Batch 43, Loss: 0.127\n",
      "Training: Epoch 139, Batch 44, Loss: 0.12\n",
      "Training: Epoch 139, Batch 45, Loss: 0.093\n",
      "Training: Epoch 139, Batch 46, Loss: 0.142\n",
      "Training: Epoch 139, Batch 47, Loss: 0.097\n",
      "Training: Epoch 139, Batch 48, Loss: 0.138\n",
      "Training: Epoch 139, Batch 49, Loss: 0.125\n",
      "Training: Epoch 139, Batch 50, Loss: 0.12\n",
      "Training: Epoch 139, Batch 51, Loss: 0.09\n",
      "Training: Epoch 139, Batch 52, Loss: 0.133\n",
      "Training: Epoch 139, Batch 53, Loss: 0.114\n",
      "Training: Epoch 139, Batch 54, Loss: 0.102\n",
      "Training: Epoch 139, Batch 55, Loss: 0.112\n",
      "Training: Epoch 139, Batch 56, Loss: 0.071\n",
      "Training: Epoch 139, Batch 57, Loss: 0.105\n",
      "Training: Epoch 139, Batch 58, Loss: 0.112\n",
      "Training: Epoch 139, Batch 59, Loss: 0.087\n",
      "Training: Epoch 139, Batch 60, Loss: 0.088\n",
      "Training: Epoch 139, Batch 61, Loss: 0.103\n",
      "Training: Epoch 139, Batch 62, Loss: 0.137\n",
      "Training: Epoch 139, Batch 63, Loss: 0.119\n",
      "Training: Epoch 139, Batch 64, Loss: 0.1\n",
      "Training: Epoch 139, Batch 65, Loss: 0.08\n",
      "Training: Epoch 139, Batch 66, Loss: 0.092\n",
      "Training: Epoch 139, Batch 67, Loss: 0.112\n",
      "Training: Epoch 139, Batch 68, Loss: 0.094\n",
      "Training: Epoch 139, Batch 69, Loss: 0.116\n",
      "Training: Epoch 139, Batch 70, Loss: 0.103\n",
      "Training: Epoch 139, Batch 71, Loss: 0.095\n",
      "Training: Epoch 139, Batch 72, Loss: 0.113\n",
      "Training: Epoch 139, Batch 73, Loss: 0.095\n",
      "Training: Epoch 139, Batch 74, Loss: 0.141\n",
      "Training: Epoch 139, Batch 75, Loss: 0.08\n",
      "Training: Epoch 139, Batch 76, Loss: 0.074\n",
      "Training: Epoch 139, Batch 77, Loss: 0.075\n",
      "Training: Epoch 139, Batch 78, Loss: 0.131\n",
      "Training: Epoch 139, Batch 79, Loss: 0.082\n",
      "Training: Epoch 139, Batch 80, Loss: 0.077\n",
      "Training: Epoch 139, Batch 81, Loss: 0.119\n",
      "Training: Epoch 139, Batch 82, Loss: 0.1\n",
      "Training: Epoch 139, Batch 83, Loss: 0.114\n",
      "Training: Epoch 139, Batch 84, Loss: 0.101\n",
      "Training: Epoch 139, Batch 85, Loss: 0.112\n",
      "Training: Epoch 139, Batch 86, Loss: 0.102\n",
      "Training: Epoch 139, Batch 87, Loss: 0.123\n",
      "Training: Epoch 139, Batch 88, Loss: 0.123\n",
      "Training: Epoch 139, Batch 89, Loss: 0.109\n",
      "Val: Epoch 139, Loss: 0.299\n",
      "Training: Epoch 140, Batch 0, Loss: 0.115\n",
      "Training: Epoch 140, Batch 1, Loss: 0.084\n",
      "Training: Epoch 140, Batch 2, Loss: 0.143\n",
      "Training: Epoch 140, Batch 3, Loss: 0.125\n",
      "Training: Epoch 140, Batch 4, Loss: 0.109\n",
      "Training: Epoch 140, Batch 5, Loss: 0.105\n",
      "Training: Epoch 140, Batch 6, Loss: 0.153\n",
      "Training: Epoch 140, Batch 7, Loss: 0.074\n",
      "Training: Epoch 140, Batch 8, Loss: 0.089\n",
      "Training: Epoch 140, Batch 9, Loss: 0.08\n",
      "Training: Epoch 140, Batch 10, Loss: 0.105\n",
      "Training: Epoch 140, Batch 11, Loss: 0.094\n",
      "Training: Epoch 140, Batch 12, Loss: 0.087\n",
      "Training: Epoch 140, Batch 13, Loss: 0.086\n",
      "Training: Epoch 140, Batch 14, Loss: 0.105\n",
      "Training: Epoch 140, Batch 15, Loss: 0.098\n",
      "Training: Epoch 140, Batch 16, Loss: 0.11\n",
      "Training: Epoch 140, Batch 17, Loss: 0.104\n",
      "Training: Epoch 140, Batch 18, Loss: 0.11\n",
      "Training: Epoch 140, Batch 19, Loss: 0.119\n",
      "Training: Epoch 140, Batch 20, Loss: 0.088\n",
      "Training: Epoch 140, Batch 21, Loss: 0.129\n",
      "Training: Epoch 140, Batch 22, Loss: 0.086\n",
      "Training: Epoch 140, Batch 23, Loss: 0.077\n",
      "Training: Epoch 140, Batch 24, Loss: 0.123\n",
      "Training: Epoch 140, Batch 25, Loss: 0.091\n",
      "Training: Epoch 140, Batch 26, Loss: 0.08\n",
      "Training: Epoch 140, Batch 27, Loss: 0.122\n",
      "Training: Epoch 140, Batch 28, Loss: 0.08\n",
      "Training: Epoch 140, Batch 29, Loss: 0.09\n",
      "Training: Epoch 140, Batch 30, Loss: 0.138\n",
      "Training: Epoch 140, Batch 31, Loss: 0.122\n",
      "Training: Epoch 140, Batch 32, Loss: 0.115\n",
      "Training: Epoch 140, Batch 33, Loss: 0.084\n",
      "Training: Epoch 140, Batch 34, Loss: 0.122\n",
      "Training: Epoch 140, Batch 35, Loss: 0.109\n",
      "Training: Epoch 140, Batch 36, Loss: 0.098\n",
      "Training: Epoch 140, Batch 37, Loss: 0.116\n",
      "Training: Epoch 140, Batch 38, Loss: 0.089\n",
      "Training: Epoch 140, Batch 39, Loss: 0.095\n",
      "Training: Epoch 140, Batch 40, Loss: 0.074\n",
      "Training: Epoch 140, Batch 41, Loss: 0.064\n",
      "Training: Epoch 140, Batch 42, Loss: 0.152\n",
      "Training: Epoch 140, Batch 43, Loss: 0.105\n",
      "Training: Epoch 140, Batch 44, Loss: 0.1\n",
      "Training: Epoch 140, Batch 45, Loss: 0.123\n",
      "Training: Epoch 140, Batch 46, Loss: 0.112\n",
      "Training: Epoch 140, Batch 47, Loss: 0.069\n",
      "Training: Epoch 140, Batch 48, Loss: 0.088\n",
      "Training: Epoch 140, Batch 49, Loss: 0.143\n",
      "Training: Epoch 140, Batch 50, Loss: 0.139\n",
      "Training: Epoch 140, Batch 51, Loss: 0.104\n",
      "Training: Epoch 140, Batch 52, Loss: 0.114\n",
      "Training: Epoch 140, Batch 53, Loss: 0.088\n",
      "Training: Epoch 140, Batch 54, Loss: 0.089\n",
      "Training: Epoch 140, Batch 55, Loss: 0.092\n",
      "Training: Epoch 140, Batch 56, Loss: 0.089\n",
      "Training: Epoch 140, Batch 57, Loss: 0.114\n",
      "Training: Epoch 140, Batch 58, Loss: 0.114\n",
      "Training: Epoch 140, Batch 59, Loss: 0.097\n",
      "Training: Epoch 140, Batch 60, Loss: 0.118\n",
      "Training: Epoch 140, Batch 61, Loss: 0.128\n",
      "Training: Epoch 140, Batch 62, Loss: 0.16\n",
      "Training: Epoch 140, Batch 63, Loss: 0.082\n",
      "Training: Epoch 140, Batch 64, Loss: 0.114\n",
      "Training: Epoch 140, Batch 65, Loss: 0.105\n",
      "Training: Epoch 140, Batch 66, Loss: 0.084\n",
      "Training: Epoch 140, Batch 67, Loss: 0.117\n",
      "Training: Epoch 140, Batch 68, Loss: 0.081\n",
      "Training: Epoch 140, Batch 69, Loss: 0.078\n",
      "Training: Epoch 140, Batch 70, Loss: 0.086\n",
      "Training: Epoch 140, Batch 71, Loss: 0.13\n",
      "Training: Epoch 140, Batch 72, Loss: 0.07\n",
      "Training: Epoch 140, Batch 73, Loss: 0.126\n",
      "Training: Epoch 140, Batch 74, Loss: 0.11\n",
      "Training: Epoch 140, Batch 75, Loss: 0.123\n",
      "Training: Epoch 140, Batch 76, Loss: 0.082\n",
      "Training: Epoch 140, Batch 77, Loss: 0.125\n",
      "Training: Epoch 140, Batch 78, Loss: 0.102\n",
      "Training: Epoch 140, Batch 79, Loss: 0.08\n",
      "Training: Epoch 140, Batch 80, Loss: 0.125\n",
      "Training: Epoch 140, Batch 81, Loss: 0.144\n",
      "Training: Epoch 140, Batch 82, Loss: 0.122\n",
      "Training: Epoch 140, Batch 83, Loss: 0.101\n",
      "Training: Epoch 140, Batch 84, Loss: 0.128\n",
      "Training: Epoch 140, Batch 85, Loss: 0.075\n",
      "Training: Epoch 140, Batch 86, Loss: 0.132\n",
      "Training: Epoch 140, Batch 87, Loss: 0.127\n",
      "Training: Epoch 140, Batch 88, Loss: 0.097\n",
      "Training: Epoch 140, Batch 89, Loss: 0.119\n",
      "Val: Epoch 140, Loss: 0.309\n",
      "Training: Epoch 141, Batch 0, Loss: 0.083\n",
      "Training: Epoch 141, Batch 1, Loss: 0.086\n",
      "Training: Epoch 141, Batch 2, Loss: 0.119\n",
      "Training: Epoch 141, Batch 3, Loss: 0.144\n",
      "Training: Epoch 141, Batch 4, Loss: 0.077\n",
      "Training: Epoch 141, Batch 5, Loss: 0.112\n",
      "Training: Epoch 141, Batch 6, Loss: 0.079\n",
      "Training: Epoch 141, Batch 7, Loss: 0.135\n",
      "Training: Epoch 141, Batch 8, Loss: 0.112\n",
      "Training: Epoch 141, Batch 9, Loss: 0.118\n",
      "Training: Epoch 141, Batch 10, Loss: 0.083\n",
      "Training: Epoch 141, Batch 11, Loss: 0.096\n",
      "Training: Epoch 141, Batch 12, Loss: 0.091\n",
      "Training: Epoch 141, Batch 13, Loss: 0.101\n",
      "Training: Epoch 141, Batch 14, Loss: 0.077\n",
      "Training: Epoch 141, Batch 15, Loss: 0.105\n",
      "Training: Epoch 141, Batch 16, Loss: 0.112\n",
      "Training: Epoch 141, Batch 17, Loss: 0.114\n",
      "Training: Epoch 141, Batch 18, Loss: 0.12\n",
      "Training: Epoch 141, Batch 19, Loss: 0.101\n",
      "Training: Epoch 141, Batch 20, Loss: 0.126\n",
      "Training: Epoch 141, Batch 21, Loss: 0.077\n",
      "Training: Epoch 141, Batch 22, Loss: 0.13\n",
      "Training: Epoch 141, Batch 23, Loss: 0.104\n",
      "Training: Epoch 141, Batch 24, Loss: 0.078\n",
      "Training: Epoch 141, Batch 25, Loss: 0.099\n",
      "Training: Epoch 141, Batch 26, Loss: 0.11\n",
      "Training: Epoch 141, Batch 27, Loss: 0.075\n",
      "Training: Epoch 141, Batch 28, Loss: 0.13\n",
      "Training: Epoch 141, Batch 29, Loss: 0.095\n",
      "Training: Epoch 141, Batch 30, Loss: 0.112\n",
      "Training: Epoch 141, Batch 31, Loss: 0.075\n",
      "Training: Epoch 141, Batch 32, Loss: 0.134\n",
      "Training: Epoch 141, Batch 33, Loss: 0.082\n",
      "Training: Epoch 141, Batch 34, Loss: 0.081\n",
      "Training: Epoch 141, Batch 35, Loss: 0.12\n",
      "Training: Epoch 141, Batch 36, Loss: 0.074\n",
      "Training: Epoch 141, Batch 37, Loss: 0.099\n",
      "Training: Epoch 141, Batch 38, Loss: 0.108\n",
      "Training: Epoch 141, Batch 39, Loss: 0.084\n",
      "Training: Epoch 141, Batch 40, Loss: 0.084\n",
      "Training: Epoch 141, Batch 41, Loss: 0.125\n",
      "Training: Epoch 141, Batch 42, Loss: 0.101\n",
      "Training: Epoch 141, Batch 43, Loss: 0.083\n",
      "Training: Epoch 141, Batch 44, Loss: 0.15\n",
      "Training: Epoch 141, Batch 45, Loss: 0.124\n",
      "Training: Epoch 141, Batch 46, Loss: 0.107\n",
      "Training: Epoch 141, Batch 47, Loss: 0.103\n",
      "Training: Epoch 141, Batch 48, Loss: 0.091\n",
      "Training: Epoch 141, Batch 49, Loss: 0.121\n",
      "Training: Epoch 141, Batch 50, Loss: 0.081\n",
      "Training: Epoch 141, Batch 51, Loss: 0.09\n",
      "Training: Epoch 141, Batch 52, Loss: 0.087\n",
      "Training: Epoch 141, Batch 53, Loss: 0.097\n",
      "Training: Epoch 141, Batch 54, Loss: 0.077\n",
      "Training: Epoch 141, Batch 55, Loss: 0.111\n",
      "Training: Epoch 141, Batch 56, Loss: 0.103\n",
      "Training: Epoch 141, Batch 57, Loss: 0.13\n",
      "Training: Epoch 141, Batch 58, Loss: 0.093\n",
      "Training: Epoch 141, Batch 59, Loss: 0.124\n",
      "Training: Epoch 141, Batch 60, Loss: 0.088\n",
      "Training: Epoch 141, Batch 61, Loss: 0.112\n",
      "Training: Epoch 141, Batch 62, Loss: 0.094\n",
      "Training: Epoch 141, Batch 63, Loss: 0.091\n",
      "Training: Epoch 141, Batch 64, Loss: 0.12\n",
      "Training: Epoch 141, Batch 65, Loss: 0.135\n",
      "Training: Epoch 141, Batch 66, Loss: 0.085\n",
      "Training: Epoch 141, Batch 67, Loss: 0.126\n",
      "Training: Epoch 141, Batch 68, Loss: 0.105\n",
      "Training: Epoch 141, Batch 69, Loss: 0.094\n",
      "Training: Epoch 141, Batch 70, Loss: 0.13\n",
      "Training: Epoch 141, Batch 71, Loss: 0.085\n",
      "Training: Epoch 141, Batch 72, Loss: 0.122\n",
      "Training: Epoch 141, Batch 73, Loss: 0.136\n",
      "Training: Epoch 141, Batch 74, Loss: 0.097\n",
      "Training: Epoch 141, Batch 75, Loss: 0.135\n",
      "Training: Epoch 141, Batch 76, Loss: 0.091\n",
      "Training: Epoch 141, Batch 77, Loss: 0.138\n",
      "Training: Epoch 141, Batch 78, Loss: 0.12\n",
      "Training: Epoch 141, Batch 79, Loss: 0.082\n",
      "Training: Epoch 141, Batch 80, Loss: 0.115\n",
      "Training: Epoch 141, Batch 81, Loss: 0.108\n",
      "Training: Epoch 141, Batch 82, Loss: 0.146\n",
      "Training: Epoch 141, Batch 83, Loss: 0.081\n",
      "Training: Epoch 141, Batch 84, Loss: 0.129\n",
      "Training: Epoch 141, Batch 85, Loss: 0.102\n",
      "Training: Epoch 141, Batch 86, Loss: 0.127\n",
      "Training: Epoch 141, Batch 87, Loss: 0.118\n",
      "Training: Epoch 141, Batch 88, Loss: 0.091\n",
      "Training: Epoch 141, Batch 89, Loss: 0.082\n",
      "Val: Epoch 141, Loss: 0.3\n",
      "Training: Epoch 142, Batch 0, Loss: 0.119\n",
      "Training: Epoch 142, Batch 1, Loss: 0.073\n",
      "Training: Epoch 142, Batch 2, Loss: 0.097\n",
      "Training: Epoch 142, Batch 3, Loss: 0.084\n",
      "Training: Epoch 142, Batch 4, Loss: 0.108\n",
      "Training: Epoch 142, Batch 5, Loss: 0.08\n",
      "Training: Epoch 142, Batch 6, Loss: 0.095\n",
      "Training: Epoch 142, Batch 7, Loss: 0.113\n",
      "Training: Epoch 142, Batch 8, Loss: 0.099\n",
      "Training: Epoch 142, Batch 9, Loss: 0.078\n",
      "Training: Epoch 142, Batch 10, Loss: 0.104\n",
      "Training: Epoch 142, Batch 11, Loss: 0.105\n",
      "Training: Epoch 142, Batch 12, Loss: 0.092\n",
      "Training: Epoch 142, Batch 13, Loss: 0.113\n",
      "Training: Epoch 142, Batch 14, Loss: 0.113\n",
      "Training: Epoch 142, Batch 15, Loss: 0.12\n",
      "Training: Epoch 142, Batch 16, Loss: 0.113\n",
      "Training: Epoch 142, Batch 17, Loss: 0.113\n",
      "Training: Epoch 142, Batch 18, Loss: 0.118\n",
      "Training: Epoch 142, Batch 19, Loss: 0.15\n",
      "Training: Epoch 142, Batch 20, Loss: 0.096\n",
      "Training: Epoch 142, Batch 21, Loss: 0.092\n",
      "Training: Epoch 142, Batch 22, Loss: 0.093\n",
      "Training: Epoch 142, Batch 23, Loss: 0.1\n",
      "Training: Epoch 142, Batch 24, Loss: 0.075\n",
      "Training: Epoch 142, Batch 25, Loss: 0.096\n",
      "Training: Epoch 142, Batch 26, Loss: 0.1\n",
      "Training: Epoch 142, Batch 27, Loss: 0.129\n",
      "Training: Epoch 142, Batch 28, Loss: 0.123\n",
      "Training: Epoch 142, Batch 29, Loss: 0.116\n",
      "Training: Epoch 142, Batch 30, Loss: 0.092\n",
      "Training: Epoch 142, Batch 31, Loss: 0.11\n",
      "Training: Epoch 142, Batch 32, Loss: 0.091\n",
      "Training: Epoch 142, Batch 33, Loss: 0.079\n",
      "Training: Epoch 142, Batch 34, Loss: 0.11\n",
      "Training: Epoch 142, Batch 35, Loss: 0.09\n",
      "Training: Epoch 142, Batch 36, Loss: 0.114\n",
      "Training: Epoch 142, Batch 37, Loss: 0.099\n",
      "Training: Epoch 142, Batch 38, Loss: 0.079\n",
      "Training: Epoch 142, Batch 39, Loss: 0.081\n",
      "Training: Epoch 142, Batch 40, Loss: 0.099\n",
      "Training: Epoch 142, Batch 41, Loss: 0.088\n",
      "Training: Epoch 142, Batch 42, Loss: 0.142\n",
      "Training: Epoch 142, Batch 43, Loss: 0.071\n",
      "Training: Epoch 142, Batch 44, Loss: 0.085\n",
      "Training: Epoch 142, Batch 45, Loss: 0.08\n",
      "Training: Epoch 142, Batch 46, Loss: 0.116\n",
      "Training: Epoch 142, Batch 47, Loss: 0.115\n",
      "Training: Epoch 142, Batch 48, Loss: 0.094\n",
      "Training: Epoch 142, Batch 49, Loss: 0.084\n",
      "Training: Epoch 142, Batch 50, Loss: 0.116\n",
      "Training: Epoch 142, Batch 51, Loss: 0.112\n",
      "Training: Epoch 142, Batch 52, Loss: 0.104\n",
      "Training: Epoch 142, Batch 53, Loss: 0.091\n",
      "Training: Epoch 142, Batch 54, Loss: 0.116\n",
      "Training: Epoch 142, Batch 55, Loss: 0.103\n",
      "Training: Epoch 142, Batch 56, Loss: 0.1\n",
      "Training: Epoch 142, Batch 57, Loss: 0.118\n",
      "Training: Epoch 142, Batch 58, Loss: 0.097\n",
      "Training: Epoch 142, Batch 59, Loss: 0.088\n",
      "Training: Epoch 142, Batch 60, Loss: 0.143\n",
      "Training: Epoch 142, Batch 61, Loss: 0.136\n",
      "Training: Epoch 142, Batch 62, Loss: 0.087\n",
      "Training: Epoch 142, Batch 63, Loss: 0.127\n",
      "Training: Epoch 142, Batch 64, Loss: 0.075\n",
      "Training: Epoch 142, Batch 65, Loss: 0.074\n",
      "Training: Epoch 142, Batch 66, Loss: 0.136\n",
      "Training: Epoch 142, Batch 67, Loss: 0.124\n",
      "Training: Epoch 142, Batch 68, Loss: 0.102\n",
      "Training: Epoch 142, Batch 69, Loss: 0.089\n",
      "Training: Epoch 142, Batch 70, Loss: 0.097\n",
      "Training: Epoch 142, Batch 71, Loss: 0.141\n",
      "Training: Epoch 142, Batch 72, Loss: 0.089\n",
      "Training: Epoch 142, Batch 73, Loss: 0.095\n",
      "Training: Epoch 142, Batch 74, Loss: 0.074\n",
      "Training: Epoch 142, Batch 75, Loss: 0.128\n",
      "Training: Epoch 142, Batch 76, Loss: 0.132\n",
      "Training: Epoch 142, Batch 77, Loss: 0.11\n",
      "Training: Epoch 142, Batch 78, Loss: 0.079\n",
      "Training: Epoch 142, Batch 79, Loss: 0.123\n",
      "Training: Epoch 142, Batch 80, Loss: 0.109\n",
      "Training: Epoch 142, Batch 81, Loss: 0.137\n",
      "Training: Epoch 142, Batch 82, Loss: 0.104\n",
      "Training: Epoch 142, Batch 83, Loss: 0.126\n",
      "Training: Epoch 142, Batch 84, Loss: 0.098\n",
      "Training: Epoch 142, Batch 85, Loss: 0.14\n",
      "Training: Epoch 142, Batch 86, Loss: 0.083\n",
      "Training: Epoch 142, Batch 87, Loss: 0.116\n",
      "Training: Epoch 142, Batch 88, Loss: 0.138\n",
      "Training: Epoch 142, Batch 89, Loss: 0.118\n",
      "Val: Epoch 142, Loss: 0.309\n",
      "Training: Epoch 143, Batch 0, Loss: 0.128\n",
      "Training: Epoch 143, Batch 1, Loss: 0.104\n",
      "Training: Epoch 143, Batch 2, Loss: 0.135\n",
      "Training: Epoch 143, Batch 3, Loss: 0.094\n",
      "Training: Epoch 143, Batch 4, Loss: 0.123\n",
      "Training: Epoch 143, Batch 5, Loss: 0.121\n",
      "Training: Epoch 143, Batch 6, Loss: 0.081\n",
      "Training: Epoch 143, Batch 7, Loss: 0.112\n",
      "Training: Epoch 143, Batch 8, Loss: 0.07\n",
      "Training: Epoch 143, Batch 9, Loss: 0.158\n",
      "Training: Epoch 143, Batch 10, Loss: 0.119\n",
      "Training: Epoch 143, Batch 11, Loss: 0.118\n",
      "Training: Epoch 143, Batch 12, Loss: 0.088\n",
      "Training: Epoch 143, Batch 13, Loss: 0.136\n",
      "Training: Epoch 143, Batch 14, Loss: 0.092\n",
      "Training: Epoch 143, Batch 15, Loss: 0.091\n",
      "Training: Epoch 143, Batch 16, Loss: 0.131\n",
      "Training: Epoch 143, Batch 17, Loss: 0.109\n",
      "Training: Epoch 143, Batch 18, Loss: 0.085\n",
      "Training: Epoch 143, Batch 19, Loss: 0.105\n",
      "Training: Epoch 143, Batch 20, Loss: 0.073\n",
      "Training: Epoch 143, Batch 21, Loss: 0.1\n",
      "Training: Epoch 143, Batch 22, Loss: 0.114\n",
      "Training: Epoch 143, Batch 23, Loss: 0.098\n",
      "Training: Epoch 143, Batch 24, Loss: 0.109\n",
      "Training: Epoch 143, Batch 25, Loss: 0.078\n",
      "Training: Epoch 143, Batch 26, Loss: 0.092\n",
      "Training: Epoch 143, Batch 27, Loss: 0.071\n",
      "Training: Epoch 143, Batch 28, Loss: 0.1\n",
      "Training: Epoch 143, Batch 29, Loss: 0.124\n",
      "Training: Epoch 143, Batch 30, Loss: 0.075\n",
      "Training: Epoch 143, Batch 31, Loss: 0.1\n",
      "Training: Epoch 143, Batch 32, Loss: 0.087\n",
      "Training: Epoch 143, Batch 33, Loss: 0.091\n",
      "Training: Epoch 143, Batch 34, Loss: 0.145\n",
      "Training: Epoch 143, Batch 35, Loss: 0.12\n",
      "Training: Epoch 143, Batch 36, Loss: 0.1\n",
      "Training: Epoch 143, Batch 37, Loss: 0.096\n",
      "Training: Epoch 143, Batch 38, Loss: 0.099\n",
      "Training: Epoch 143, Batch 39, Loss: 0.135\n",
      "Training: Epoch 143, Batch 40, Loss: 0.125\n",
      "Training: Epoch 143, Batch 41, Loss: 0.12\n",
      "Training: Epoch 143, Batch 42, Loss: 0.118\n",
      "Training: Epoch 143, Batch 43, Loss: 0.068\n",
      "Training: Epoch 143, Batch 44, Loss: 0.098\n",
      "Training: Epoch 143, Batch 45, Loss: 0.097\n",
      "Training: Epoch 143, Batch 46, Loss: 0.097\n",
      "Training: Epoch 143, Batch 47, Loss: 0.125\n",
      "Training: Epoch 143, Batch 48, Loss: 0.085\n",
      "Training: Epoch 143, Batch 49, Loss: 0.105\n",
      "Training: Epoch 143, Batch 50, Loss: 0.091\n",
      "Training: Epoch 143, Batch 51, Loss: 0.102\n",
      "Training: Epoch 143, Batch 52, Loss: 0.113\n",
      "Training: Epoch 143, Batch 53, Loss: 0.119\n",
      "Training: Epoch 143, Batch 54, Loss: 0.105\n",
      "Training: Epoch 143, Batch 55, Loss: 0.129\n",
      "Training: Epoch 143, Batch 56, Loss: 0.109\n",
      "Training: Epoch 143, Batch 57, Loss: 0.091\n",
      "Training: Epoch 143, Batch 58, Loss: 0.105\n",
      "Training: Epoch 143, Batch 59, Loss: 0.1\n",
      "Training: Epoch 143, Batch 60, Loss: 0.133\n",
      "Training: Epoch 143, Batch 61, Loss: 0.156\n",
      "Training: Epoch 143, Batch 62, Loss: 0.089\n",
      "Training: Epoch 143, Batch 63, Loss: 0.074\n",
      "Training: Epoch 143, Batch 64, Loss: 0.097\n",
      "Training: Epoch 143, Batch 65, Loss: 0.087\n",
      "Training: Epoch 143, Batch 66, Loss: 0.108\n",
      "Training: Epoch 143, Batch 67, Loss: 0.103\n",
      "Training: Epoch 143, Batch 68, Loss: 0.082\n",
      "Training: Epoch 143, Batch 69, Loss: 0.104\n",
      "Training: Epoch 143, Batch 70, Loss: 0.097\n",
      "Training: Epoch 143, Batch 71, Loss: 0.098\n",
      "Training: Epoch 143, Batch 72, Loss: 0.104\n",
      "Training: Epoch 143, Batch 73, Loss: 0.116\n",
      "Training: Epoch 143, Batch 74, Loss: 0.137\n",
      "Training: Epoch 143, Batch 75, Loss: 0.139\n",
      "Training: Epoch 143, Batch 76, Loss: 0.107\n",
      "Training: Epoch 143, Batch 77, Loss: 0.089\n",
      "Training: Epoch 143, Batch 78, Loss: 0.101\n",
      "Training: Epoch 143, Batch 79, Loss: 0.115\n",
      "Training: Epoch 143, Batch 80, Loss: 0.107\n",
      "Training: Epoch 143, Batch 81, Loss: 0.096\n",
      "Training: Epoch 143, Batch 82, Loss: 0.089\n",
      "Training: Epoch 143, Batch 83, Loss: 0.078\n",
      "Training: Epoch 143, Batch 84, Loss: 0.146\n",
      "Training: Epoch 143, Batch 85, Loss: 0.091\n",
      "Training: Epoch 143, Batch 86, Loss: 0.138\n",
      "Training: Epoch 143, Batch 87, Loss: 0.105\n",
      "Training: Epoch 143, Batch 88, Loss: 0.11\n",
      "Training: Epoch 143, Batch 89, Loss: 0.101\n",
      "Val: Epoch 143, Loss: 0.291\n",
      "Training: Epoch 144, Batch 0, Loss: 0.09\n",
      "Training: Epoch 144, Batch 1, Loss: 0.082\n",
      "Training: Epoch 144, Batch 2, Loss: 0.1\n",
      "Training: Epoch 144, Batch 3, Loss: 0.085\n",
      "Training: Epoch 144, Batch 4, Loss: 0.106\n",
      "Training: Epoch 144, Batch 5, Loss: 0.132\n",
      "Training: Epoch 144, Batch 6, Loss: 0.114\n",
      "Training: Epoch 144, Batch 7, Loss: 0.132\n",
      "Training: Epoch 144, Batch 8, Loss: 0.083\n",
      "Training: Epoch 144, Batch 9, Loss: 0.107\n",
      "Training: Epoch 144, Batch 10, Loss: 0.121\n",
      "Training: Epoch 144, Batch 11, Loss: 0.096\n",
      "Training: Epoch 144, Batch 12, Loss: 0.122\n",
      "Training: Epoch 144, Batch 13, Loss: 0.111\n",
      "Training: Epoch 144, Batch 14, Loss: 0.098\n",
      "Training: Epoch 144, Batch 15, Loss: 0.109\n",
      "Training: Epoch 144, Batch 16, Loss: 0.108\n",
      "Training: Epoch 144, Batch 17, Loss: 0.112\n",
      "Training: Epoch 144, Batch 18, Loss: 0.109\n",
      "Training: Epoch 144, Batch 19, Loss: 0.108\n",
      "Training: Epoch 144, Batch 20, Loss: 0.121\n",
      "Training: Epoch 144, Batch 21, Loss: 0.097\n",
      "Training: Epoch 144, Batch 22, Loss: 0.063\n",
      "Training: Epoch 144, Batch 23, Loss: 0.114\n",
      "Training: Epoch 144, Batch 24, Loss: 0.096\n",
      "Training: Epoch 144, Batch 25, Loss: 0.102\n",
      "Training: Epoch 144, Batch 26, Loss: 0.096\n",
      "Training: Epoch 144, Batch 27, Loss: 0.125\n",
      "Training: Epoch 144, Batch 28, Loss: 0.108\n",
      "Training: Epoch 144, Batch 29, Loss: 0.128\n",
      "Training: Epoch 144, Batch 30, Loss: 0.064\n",
      "Training: Epoch 144, Batch 31, Loss: 0.119\n",
      "Training: Epoch 144, Batch 32, Loss: 0.147\n",
      "Training: Epoch 144, Batch 33, Loss: 0.115\n",
      "Training: Epoch 144, Batch 34, Loss: 0.064\n",
      "Training: Epoch 144, Batch 35, Loss: 0.12\n",
      "Training: Epoch 144, Batch 36, Loss: 0.077\n",
      "Training: Epoch 144, Batch 37, Loss: 0.093\n",
      "Training: Epoch 144, Batch 38, Loss: 0.094\n",
      "Training: Epoch 144, Batch 39, Loss: 0.088\n",
      "Training: Epoch 144, Batch 40, Loss: 0.106\n",
      "Training: Epoch 144, Batch 41, Loss: 0.105\n",
      "Training: Epoch 144, Batch 42, Loss: 0.097\n",
      "Training: Epoch 144, Batch 43, Loss: 0.117\n",
      "Training: Epoch 144, Batch 44, Loss: 0.1\n",
      "Training: Epoch 144, Batch 45, Loss: 0.07\n",
      "Training: Epoch 144, Batch 46, Loss: 0.091\n",
      "Training: Epoch 144, Batch 47, Loss: 0.091\n",
      "Training: Epoch 144, Batch 48, Loss: 0.1\n",
      "Training: Epoch 144, Batch 49, Loss: 0.079\n",
      "Training: Epoch 144, Batch 50, Loss: 0.145\n",
      "Training: Epoch 144, Batch 51, Loss: 0.09\n",
      "Training: Epoch 144, Batch 52, Loss: 0.107\n",
      "Training: Epoch 144, Batch 53, Loss: 0.109\n",
      "Training: Epoch 144, Batch 54, Loss: 0.13\n",
      "Training: Epoch 144, Batch 55, Loss: 0.133\n",
      "Training: Epoch 144, Batch 56, Loss: 0.087\n",
      "Training: Epoch 144, Batch 57, Loss: 0.078\n",
      "Training: Epoch 144, Batch 58, Loss: 0.125\n",
      "Training: Epoch 144, Batch 59, Loss: 0.091\n",
      "Training: Epoch 144, Batch 60, Loss: 0.111\n",
      "Training: Epoch 144, Batch 61, Loss: 0.085\n",
      "Training: Epoch 144, Batch 62, Loss: 0.11\n",
      "Training: Epoch 144, Batch 63, Loss: 0.126\n",
      "Training: Epoch 144, Batch 64, Loss: 0.105\n",
      "Training: Epoch 144, Batch 65, Loss: 0.09\n",
      "Training: Epoch 144, Batch 66, Loss: 0.076\n",
      "Training: Epoch 144, Batch 67, Loss: 0.126\n",
      "Training: Epoch 144, Batch 68, Loss: 0.106\n",
      "Training: Epoch 144, Batch 69, Loss: 0.138\n",
      "Training: Epoch 144, Batch 70, Loss: 0.106\n",
      "Training: Epoch 144, Batch 71, Loss: 0.071\n",
      "Training: Epoch 144, Batch 72, Loss: 0.147\n",
      "Training: Epoch 144, Batch 73, Loss: 0.101\n",
      "Training: Epoch 144, Batch 74, Loss: 0.063\n",
      "Training: Epoch 144, Batch 75, Loss: 0.103\n",
      "Training: Epoch 144, Batch 76, Loss: 0.071\n",
      "Training: Epoch 144, Batch 77, Loss: 0.106\n",
      "Training: Epoch 144, Batch 78, Loss: 0.131\n",
      "Training: Epoch 144, Batch 79, Loss: 0.127\n",
      "Training: Epoch 144, Batch 80, Loss: 0.125\n",
      "Training: Epoch 144, Batch 81, Loss: 0.121\n",
      "Training: Epoch 144, Batch 82, Loss: 0.141\n",
      "Training: Epoch 144, Batch 83, Loss: 0.117\n",
      "Training: Epoch 144, Batch 84, Loss: 0.123\n",
      "Training: Epoch 144, Batch 85, Loss: 0.121\n",
      "Training: Epoch 144, Batch 86, Loss: 0.094\n",
      "Training: Epoch 144, Batch 87, Loss: 0.102\n",
      "Training: Epoch 144, Batch 88, Loss: 0.094\n",
      "Training: Epoch 144, Batch 89, Loss: 0.086\n",
      "Val: Epoch 144, Loss: 0.305\n",
      "Training: Epoch 145, Batch 0, Loss: 0.106\n",
      "Training: Epoch 145, Batch 1, Loss: 0.121\n",
      "Training: Epoch 145, Batch 2, Loss: 0.094\n",
      "Training: Epoch 145, Batch 3, Loss: 0.118\n",
      "Training: Epoch 145, Batch 4, Loss: 0.104\n",
      "Training: Epoch 145, Batch 5, Loss: 0.113\n",
      "Training: Epoch 145, Batch 6, Loss: 0.079\n",
      "Training: Epoch 145, Batch 7, Loss: 0.092\n",
      "Training: Epoch 145, Batch 8, Loss: 0.102\n",
      "Training: Epoch 145, Batch 9, Loss: 0.08\n",
      "Training: Epoch 145, Batch 10, Loss: 0.08\n",
      "Training: Epoch 145, Batch 11, Loss: 0.085\n",
      "Training: Epoch 145, Batch 12, Loss: 0.102\n",
      "Training: Epoch 145, Batch 13, Loss: 0.082\n",
      "Training: Epoch 145, Batch 14, Loss: 0.08\n",
      "Training: Epoch 145, Batch 15, Loss: 0.126\n",
      "Training: Epoch 145, Batch 16, Loss: 0.139\n",
      "Training: Epoch 145, Batch 17, Loss: 0.091\n",
      "Training: Epoch 145, Batch 18, Loss: 0.095\n",
      "Training: Epoch 145, Batch 19, Loss: 0.104\n",
      "Training: Epoch 145, Batch 20, Loss: 0.13\n",
      "Training: Epoch 145, Batch 21, Loss: 0.119\n",
      "Training: Epoch 145, Batch 22, Loss: 0.091\n",
      "Training: Epoch 145, Batch 23, Loss: 0.097\n",
      "Training: Epoch 145, Batch 24, Loss: 0.11\n",
      "Training: Epoch 145, Batch 25, Loss: 0.087\n",
      "Training: Epoch 145, Batch 26, Loss: 0.11\n",
      "Training: Epoch 145, Batch 27, Loss: 0.112\n",
      "Training: Epoch 145, Batch 28, Loss: 0.105\n",
      "Training: Epoch 145, Batch 29, Loss: 0.089\n",
      "Training: Epoch 145, Batch 30, Loss: 0.086\n",
      "Training: Epoch 145, Batch 31, Loss: 0.086\n",
      "Training: Epoch 145, Batch 32, Loss: 0.112\n",
      "Training: Epoch 145, Batch 33, Loss: 0.122\n",
      "Training: Epoch 145, Batch 34, Loss: 0.091\n",
      "Training: Epoch 145, Batch 35, Loss: 0.129\n",
      "Training: Epoch 145, Batch 36, Loss: 0.12\n",
      "Training: Epoch 145, Batch 37, Loss: 0.104\n",
      "Training: Epoch 145, Batch 38, Loss: 0.127\n",
      "Training: Epoch 145, Batch 39, Loss: 0.13\n",
      "Training: Epoch 145, Batch 40, Loss: 0.092\n",
      "Training: Epoch 145, Batch 41, Loss: 0.095\n",
      "Training: Epoch 145, Batch 42, Loss: 0.095\n",
      "Training: Epoch 145, Batch 43, Loss: 0.111\n",
      "Training: Epoch 145, Batch 44, Loss: 0.117\n",
      "Training: Epoch 145, Batch 45, Loss: 0.093\n",
      "Training: Epoch 145, Batch 46, Loss: 0.092\n",
      "Training: Epoch 145, Batch 47, Loss: 0.098\n",
      "Training: Epoch 145, Batch 48, Loss: 0.152\n",
      "Training: Epoch 145, Batch 49, Loss: 0.087\n",
      "Training: Epoch 145, Batch 50, Loss: 0.105\n",
      "Training: Epoch 145, Batch 51, Loss: 0.063\n",
      "Training: Epoch 145, Batch 52, Loss: 0.099\n",
      "Training: Epoch 145, Batch 53, Loss: 0.089\n",
      "Training: Epoch 145, Batch 54, Loss: 0.12\n",
      "Training: Epoch 145, Batch 55, Loss: 0.136\n",
      "Training: Epoch 145, Batch 56, Loss: 0.11\n",
      "Training: Epoch 145, Batch 57, Loss: 0.106\n",
      "Training: Epoch 145, Batch 58, Loss: 0.087\n",
      "Training: Epoch 145, Batch 59, Loss: 0.07\n",
      "Training: Epoch 145, Batch 60, Loss: 0.127\n",
      "Training: Epoch 145, Batch 61, Loss: 0.119\n",
      "Training: Epoch 145, Batch 62, Loss: 0.117\n",
      "Training: Epoch 145, Batch 63, Loss: 0.085\n",
      "Training: Epoch 145, Batch 64, Loss: 0.167\n",
      "Training: Epoch 145, Batch 65, Loss: 0.128\n",
      "Training: Epoch 145, Batch 66, Loss: 0.089\n",
      "Training: Epoch 145, Batch 67, Loss: 0.091\n",
      "Training: Epoch 145, Batch 68, Loss: 0.107\n",
      "Training: Epoch 145, Batch 69, Loss: 0.123\n",
      "Training: Epoch 145, Batch 70, Loss: 0.096\n",
      "Training: Epoch 145, Batch 71, Loss: 0.119\n",
      "Training: Epoch 145, Batch 72, Loss: 0.109\n",
      "Training: Epoch 145, Batch 73, Loss: 0.085\n",
      "Training: Epoch 145, Batch 74, Loss: 0.1\n",
      "Training: Epoch 145, Batch 75, Loss: 0.095\n",
      "Training: Epoch 145, Batch 76, Loss: 0.087\n",
      "Training: Epoch 145, Batch 77, Loss: 0.125\n",
      "Training: Epoch 145, Batch 78, Loss: 0.119\n",
      "Training: Epoch 145, Batch 79, Loss: 0.109\n",
      "Training: Epoch 145, Batch 80, Loss: 0.091\n",
      "Training: Epoch 145, Batch 81, Loss: 0.097\n",
      "Training: Epoch 145, Batch 82, Loss: 0.106\n",
      "Training: Epoch 145, Batch 83, Loss: 0.127\n",
      "Training: Epoch 145, Batch 84, Loss: 0.098\n",
      "Training: Epoch 145, Batch 85, Loss: 0.072\n",
      "Training: Epoch 145, Batch 86, Loss: 0.106\n",
      "Training: Epoch 145, Batch 87, Loss: 0.098\n",
      "Training: Epoch 145, Batch 88, Loss: 0.139\n",
      "Training: Epoch 145, Batch 89, Loss: 0.113\n",
      "Val: Epoch 145, Loss: 0.427\n",
      "Training: Epoch 146, Batch 0, Loss: 0.113\n",
      "Training: Epoch 146, Batch 1, Loss: 0.095\n",
      "Training: Epoch 146, Batch 2, Loss: 0.154\n",
      "Training: Epoch 146, Batch 3, Loss: 0.088\n",
      "Training: Epoch 146, Batch 4, Loss: 0.077\n",
      "Training: Epoch 146, Batch 5, Loss: 0.119\n",
      "Training: Epoch 146, Batch 6, Loss: 0.096\n",
      "Training: Epoch 146, Batch 7, Loss: 0.101\n",
      "Training: Epoch 146, Batch 8, Loss: 0.089\n",
      "Training: Epoch 146, Batch 9, Loss: 0.107\n",
      "Training: Epoch 146, Batch 10, Loss: 0.148\n",
      "Training: Epoch 146, Batch 11, Loss: 0.112\n",
      "Training: Epoch 146, Batch 12, Loss: 0.105\n",
      "Training: Epoch 146, Batch 13, Loss: 0.104\n",
      "Training: Epoch 146, Batch 14, Loss: 0.099\n",
      "Training: Epoch 146, Batch 15, Loss: 0.075\n",
      "Training: Epoch 146, Batch 16, Loss: 0.114\n",
      "Training: Epoch 146, Batch 17, Loss: 0.119\n",
      "Training: Epoch 146, Batch 18, Loss: 0.118\n",
      "Training: Epoch 146, Batch 19, Loss: 0.132\n",
      "Training: Epoch 146, Batch 20, Loss: 0.107\n",
      "Training: Epoch 146, Batch 21, Loss: 0.1\n",
      "Training: Epoch 146, Batch 22, Loss: 0.079\n",
      "Training: Epoch 146, Batch 23, Loss: 0.131\n",
      "Training: Epoch 146, Batch 24, Loss: 0.157\n",
      "Training: Epoch 146, Batch 25, Loss: 0.098\n",
      "Training: Epoch 146, Batch 26, Loss: 0.113\n",
      "Training: Epoch 146, Batch 27, Loss: 0.079\n",
      "Training: Epoch 146, Batch 28, Loss: 0.104\n",
      "Training: Epoch 146, Batch 29, Loss: 0.11\n",
      "Training: Epoch 146, Batch 30, Loss: 0.092\n",
      "Training: Epoch 146, Batch 31, Loss: 0.107\n",
      "Training: Epoch 146, Batch 32, Loss: 0.134\n",
      "Training: Epoch 146, Batch 33, Loss: 0.092\n",
      "Training: Epoch 146, Batch 34, Loss: 0.124\n",
      "Training: Epoch 146, Batch 35, Loss: 0.104\n",
      "Training: Epoch 146, Batch 36, Loss: 0.103\n",
      "Training: Epoch 146, Batch 37, Loss: 0.089\n",
      "Training: Epoch 146, Batch 38, Loss: 0.119\n",
      "Training: Epoch 146, Batch 39, Loss: 0.095\n",
      "Training: Epoch 146, Batch 40, Loss: 0.119\n",
      "Training: Epoch 146, Batch 41, Loss: 0.113\n",
      "Training: Epoch 146, Batch 42, Loss: 0.086\n",
      "Training: Epoch 146, Batch 43, Loss: 0.116\n",
      "Training: Epoch 146, Batch 44, Loss: 0.101\n",
      "Training: Epoch 146, Batch 45, Loss: 0.093\n",
      "Training: Epoch 146, Batch 46, Loss: 0.11\n",
      "Training: Epoch 146, Batch 47, Loss: 0.082\n",
      "Training: Epoch 146, Batch 48, Loss: 0.111\n",
      "Training: Epoch 146, Batch 49, Loss: 0.141\n",
      "Training: Epoch 146, Batch 50, Loss: 0.095\n",
      "Training: Epoch 146, Batch 51, Loss: 0.096\n",
      "Training: Epoch 146, Batch 52, Loss: 0.097\n",
      "Training: Epoch 146, Batch 53, Loss: 0.098\n",
      "Training: Epoch 146, Batch 54, Loss: 0.097\n",
      "Training: Epoch 146, Batch 55, Loss: 0.08\n",
      "Training: Epoch 146, Batch 56, Loss: 0.079\n",
      "Training: Epoch 146, Batch 57, Loss: 0.1\n",
      "Training: Epoch 146, Batch 58, Loss: 0.077\n",
      "Training: Epoch 146, Batch 59, Loss: 0.086\n",
      "Training: Epoch 146, Batch 60, Loss: 0.072\n",
      "Training: Epoch 146, Batch 61, Loss: 0.12\n",
      "Training: Epoch 146, Batch 62, Loss: 0.091\n",
      "Training: Epoch 146, Batch 63, Loss: 0.092\n",
      "Training: Epoch 146, Batch 64, Loss: 0.099\n",
      "Training: Epoch 146, Batch 65, Loss: 0.107\n",
      "Training: Epoch 146, Batch 66, Loss: 0.131\n",
      "Training: Epoch 146, Batch 67, Loss: 0.097\n",
      "Training: Epoch 146, Batch 68, Loss: 0.069\n",
      "Training: Epoch 146, Batch 69, Loss: 0.105\n",
      "Training: Epoch 146, Batch 70, Loss: 0.099\n",
      "Training: Epoch 146, Batch 71, Loss: 0.134\n",
      "Training: Epoch 146, Batch 72, Loss: 0.085\n",
      "Training: Epoch 146, Batch 73, Loss: 0.092\n",
      "Training: Epoch 146, Batch 74, Loss: 0.068\n",
      "Training: Epoch 146, Batch 75, Loss: 0.137\n",
      "Training: Epoch 146, Batch 76, Loss: 0.095\n",
      "Training: Epoch 146, Batch 77, Loss: 0.091\n",
      "Training: Epoch 146, Batch 78, Loss: 0.07\n",
      "Training: Epoch 146, Batch 79, Loss: 0.134\n",
      "Training: Epoch 146, Batch 80, Loss: 0.099\n",
      "Training: Epoch 146, Batch 81, Loss: 0.089\n",
      "Training: Epoch 146, Batch 82, Loss: 0.105\n",
      "Training: Epoch 146, Batch 83, Loss: 0.07\n",
      "Training: Epoch 146, Batch 84, Loss: 0.09\n",
      "Training: Epoch 146, Batch 85, Loss: 0.124\n",
      "Training: Epoch 146, Batch 86, Loss: 0.119\n",
      "Training: Epoch 146, Batch 87, Loss: 0.077\n",
      "Training: Epoch 146, Batch 88, Loss: 0.077\n",
      "Training: Epoch 146, Batch 89, Loss: 0.093\n",
      "Val: Epoch 146, Loss: 0.298\n",
      "Training: Epoch 147, Batch 0, Loss: 0.122\n",
      "Training: Epoch 147, Batch 1, Loss: 0.074\n",
      "Training: Epoch 147, Batch 2, Loss: 0.11\n",
      "Training: Epoch 147, Batch 3, Loss: 0.109\n",
      "Training: Epoch 147, Batch 4, Loss: 0.095\n",
      "Training: Epoch 147, Batch 5, Loss: 0.097\n",
      "Training: Epoch 147, Batch 6, Loss: 0.107\n",
      "Training: Epoch 147, Batch 7, Loss: 0.113\n",
      "Training: Epoch 147, Batch 8, Loss: 0.12\n",
      "Training: Epoch 147, Batch 9, Loss: 0.103\n",
      "Training: Epoch 147, Batch 10, Loss: 0.068\n",
      "Training: Epoch 147, Batch 11, Loss: 0.107\n",
      "Training: Epoch 147, Batch 12, Loss: 0.109\n",
      "Training: Epoch 147, Batch 13, Loss: 0.104\n",
      "Training: Epoch 147, Batch 14, Loss: 0.092\n",
      "Training: Epoch 147, Batch 15, Loss: 0.099\n",
      "Training: Epoch 147, Batch 16, Loss: 0.078\n",
      "Training: Epoch 147, Batch 17, Loss: 0.11\n",
      "Training: Epoch 147, Batch 18, Loss: 0.116\n",
      "Training: Epoch 147, Batch 19, Loss: 0.081\n",
      "Training: Epoch 147, Batch 20, Loss: 0.081\n",
      "Training: Epoch 147, Batch 21, Loss: 0.132\n",
      "Training: Epoch 147, Batch 22, Loss: 0.09\n",
      "Training: Epoch 147, Batch 23, Loss: 0.122\n",
      "Training: Epoch 147, Batch 24, Loss: 0.103\n",
      "Training: Epoch 147, Batch 25, Loss: 0.133\n",
      "Training: Epoch 147, Batch 26, Loss: 0.114\n",
      "Training: Epoch 147, Batch 27, Loss: 0.105\n",
      "Training: Epoch 147, Batch 28, Loss: 0.116\n",
      "Training: Epoch 147, Batch 29, Loss: 0.129\n",
      "Training: Epoch 147, Batch 30, Loss: 0.09\n",
      "Training: Epoch 147, Batch 31, Loss: 0.076\n",
      "Training: Epoch 147, Batch 32, Loss: 0.095\n",
      "Training: Epoch 147, Batch 33, Loss: 0.085\n",
      "Training: Epoch 147, Batch 34, Loss: 0.089\n",
      "Training: Epoch 147, Batch 35, Loss: 0.088\n",
      "Training: Epoch 147, Batch 36, Loss: 0.088\n",
      "Training: Epoch 147, Batch 37, Loss: 0.121\n",
      "Training: Epoch 147, Batch 38, Loss: 0.094\n",
      "Training: Epoch 147, Batch 39, Loss: 0.095\n",
      "Training: Epoch 147, Batch 40, Loss: 0.102\n",
      "Training: Epoch 147, Batch 41, Loss: 0.093\n",
      "Training: Epoch 147, Batch 42, Loss: 0.093\n",
      "Training: Epoch 147, Batch 43, Loss: 0.073\n",
      "Training: Epoch 147, Batch 44, Loss: 0.131\n",
      "Training: Epoch 147, Batch 45, Loss: 0.075\n",
      "Training: Epoch 147, Batch 46, Loss: 0.098\n",
      "Training: Epoch 147, Batch 47, Loss: 0.091\n",
      "Training: Epoch 147, Batch 48, Loss: 0.099\n",
      "Training: Epoch 147, Batch 49, Loss: 0.076\n",
      "Training: Epoch 147, Batch 50, Loss: 0.132\n",
      "Training: Epoch 147, Batch 51, Loss: 0.143\n",
      "Training: Epoch 147, Batch 52, Loss: 0.099\n",
      "Training: Epoch 147, Batch 53, Loss: 0.141\n",
      "Training: Epoch 147, Batch 54, Loss: 0.103\n",
      "Training: Epoch 147, Batch 55, Loss: 0.067\n",
      "Training: Epoch 147, Batch 56, Loss: 0.09\n",
      "Training: Epoch 147, Batch 57, Loss: 0.1\n",
      "Training: Epoch 147, Batch 58, Loss: 0.091\n",
      "Training: Epoch 147, Batch 59, Loss: 0.133\n",
      "Training: Epoch 147, Batch 60, Loss: 0.085\n",
      "Training: Epoch 147, Batch 61, Loss: 0.084\n",
      "Training: Epoch 147, Batch 62, Loss: 0.078\n",
      "Training: Epoch 147, Batch 63, Loss: 0.081\n",
      "Training: Epoch 147, Batch 64, Loss: 0.086\n",
      "Training: Epoch 147, Batch 65, Loss: 0.089\n",
      "Training: Epoch 147, Batch 66, Loss: 0.112\n",
      "Training: Epoch 147, Batch 67, Loss: 0.086\n",
      "Training: Epoch 147, Batch 68, Loss: 0.13\n",
      "Training: Epoch 147, Batch 69, Loss: 0.102\n",
      "Training: Epoch 147, Batch 70, Loss: 0.129\n",
      "Training: Epoch 147, Batch 71, Loss: 0.109\n",
      "Training: Epoch 147, Batch 72, Loss: 0.089\n",
      "Training: Epoch 147, Batch 73, Loss: 0.072\n",
      "Training: Epoch 147, Batch 74, Loss: 0.151\n",
      "Training: Epoch 147, Batch 75, Loss: 0.068\n",
      "Training: Epoch 147, Batch 76, Loss: 0.088\n",
      "Training: Epoch 147, Batch 77, Loss: 0.09\n",
      "Training: Epoch 147, Batch 78, Loss: 0.087\n",
      "Training: Epoch 147, Batch 79, Loss: 0.088\n",
      "Training: Epoch 147, Batch 80, Loss: 0.098\n",
      "Training: Epoch 147, Batch 81, Loss: 0.111\n",
      "Training: Epoch 147, Batch 82, Loss: 0.094\n",
      "Training: Epoch 147, Batch 83, Loss: 0.125\n",
      "Training: Epoch 147, Batch 84, Loss: 0.117\n",
      "Training: Epoch 147, Batch 85, Loss: 0.085\n",
      "Training: Epoch 147, Batch 86, Loss: 0.071\n",
      "Training: Epoch 147, Batch 87, Loss: 0.089\n",
      "Training: Epoch 147, Batch 88, Loss: 0.104\n",
      "Training: Epoch 147, Batch 89, Loss: 0.111\n",
      "Val: Epoch 147, Loss: 0.298\n",
      "Training: Epoch 148, Batch 0, Loss: 0.076\n",
      "Training: Epoch 148, Batch 1, Loss: 0.167\n",
      "Training: Epoch 148, Batch 2, Loss: 0.092\n",
      "Training: Epoch 148, Batch 3, Loss: 0.114\n",
      "Training: Epoch 148, Batch 4, Loss: 0.099\n",
      "Training: Epoch 148, Batch 5, Loss: 0.111\n",
      "Training: Epoch 148, Batch 6, Loss: 0.078\n",
      "Training: Epoch 148, Batch 7, Loss: 0.124\n",
      "Training: Epoch 148, Batch 8, Loss: 0.113\n",
      "Training: Epoch 148, Batch 9, Loss: 0.118\n",
      "Training: Epoch 148, Batch 10, Loss: 0.11\n",
      "Training: Epoch 148, Batch 11, Loss: 0.09\n",
      "Training: Epoch 148, Batch 12, Loss: 0.099\n",
      "Training: Epoch 148, Batch 13, Loss: 0.094\n",
      "Training: Epoch 148, Batch 14, Loss: 0.115\n",
      "Training: Epoch 148, Batch 15, Loss: 0.096\n",
      "Training: Epoch 148, Batch 16, Loss: 0.12\n",
      "Training: Epoch 148, Batch 17, Loss: 0.096\n",
      "Training: Epoch 148, Batch 18, Loss: 0.118\n",
      "Training: Epoch 148, Batch 19, Loss: 0.133\n",
      "Training: Epoch 148, Batch 20, Loss: 0.092\n",
      "Training: Epoch 148, Batch 21, Loss: 0.089\n",
      "Training: Epoch 148, Batch 22, Loss: 0.086\n",
      "Training: Epoch 148, Batch 23, Loss: 0.092\n",
      "Training: Epoch 148, Batch 24, Loss: 0.122\n",
      "Training: Epoch 148, Batch 25, Loss: 0.092\n",
      "Training: Epoch 148, Batch 26, Loss: 0.072\n",
      "Training: Epoch 148, Batch 27, Loss: 0.118\n",
      "Training: Epoch 148, Batch 28, Loss: 0.088\n",
      "Training: Epoch 148, Batch 29, Loss: 0.078\n",
      "Training: Epoch 148, Batch 30, Loss: 0.068\n",
      "Training: Epoch 148, Batch 31, Loss: 0.121\n",
      "Training: Epoch 148, Batch 32, Loss: 0.085\n",
      "Training: Epoch 148, Batch 33, Loss: 0.091\n",
      "Training: Epoch 148, Batch 34, Loss: 0.122\n",
      "Training: Epoch 148, Batch 35, Loss: 0.085\n",
      "Training: Epoch 148, Batch 36, Loss: 0.131\n",
      "Training: Epoch 148, Batch 37, Loss: 0.104\n",
      "Training: Epoch 148, Batch 38, Loss: 0.094\n",
      "Training: Epoch 148, Batch 39, Loss: 0.106\n",
      "Training: Epoch 148, Batch 40, Loss: 0.089\n",
      "Training: Epoch 148, Batch 41, Loss: 0.115\n",
      "Training: Epoch 148, Batch 42, Loss: 0.084\n",
      "Training: Epoch 148, Batch 43, Loss: 0.134\n",
      "Training: Epoch 148, Batch 44, Loss: 0.093\n",
      "Training: Epoch 148, Batch 45, Loss: 0.098\n",
      "Training: Epoch 148, Batch 46, Loss: 0.094\n",
      "Training: Epoch 148, Batch 47, Loss: 0.08\n",
      "Training: Epoch 148, Batch 48, Loss: 0.108\n",
      "Training: Epoch 148, Batch 49, Loss: 0.115\n",
      "Training: Epoch 148, Batch 50, Loss: 0.097\n",
      "Training: Epoch 148, Batch 51, Loss: 0.089\n",
      "Training: Epoch 148, Batch 52, Loss: 0.112\n",
      "Training: Epoch 148, Batch 53, Loss: 0.127\n",
      "Training: Epoch 148, Batch 54, Loss: 0.095\n",
      "Training: Epoch 148, Batch 55, Loss: 0.141\n",
      "Training: Epoch 148, Batch 56, Loss: 0.101\n",
      "Training: Epoch 148, Batch 57, Loss: 0.104\n",
      "Training: Epoch 148, Batch 58, Loss: 0.095\n",
      "Training: Epoch 148, Batch 59, Loss: 0.099\n",
      "Training: Epoch 148, Batch 60, Loss: 0.096\n",
      "Training: Epoch 148, Batch 61, Loss: 0.1\n",
      "Training: Epoch 148, Batch 62, Loss: 0.103\n",
      "Training: Epoch 148, Batch 63, Loss: 0.083\n",
      "Training: Epoch 148, Batch 64, Loss: 0.088\n",
      "Training: Epoch 148, Batch 65, Loss: 0.093\n",
      "Training: Epoch 148, Batch 66, Loss: 0.083\n",
      "Training: Epoch 148, Batch 67, Loss: 0.12\n",
      "Training: Epoch 148, Batch 68, Loss: 0.136\n",
      "Training: Epoch 148, Batch 69, Loss: 0.095\n",
      "Training: Epoch 148, Batch 70, Loss: 0.076\n",
      "Training: Epoch 148, Batch 71, Loss: 0.107\n",
      "Training: Epoch 148, Batch 72, Loss: 0.091\n",
      "Training: Epoch 148, Batch 73, Loss: 0.111\n",
      "Training: Epoch 148, Batch 74, Loss: 0.081\n",
      "Training: Epoch 148, Batch 75, Loss: 0.11\n",
      "Training: Epoch 148, Batch 76, Loss: 0.111\n",
      "Training: Epoch 148, Batch 77, Loss: 0.092\n",
      "Training: Epoch 148, Batch 78, Loss: 0.11\n",
      "Training: Epoch 148, Batch 79, Loss: 0.116\n",
      "Training: Epoch 148, Batch 80, Loss: 0.089\n",
      "Training: Epoch 148, Batch 81, Loss: 0.094\n",
      "Training: Epoch 148, Batch 82, Loss: 0.086\n",
      "Training: Epoch 148, Batch 83, Loss: 0.121\n",
      "Training: Epoch 148, Batch 84, Loss: 0.077\n",
      "Training: Epoch 148, Batch 85, Loss: 0.086\n",
      "Training: Epoch 148, Batch 86, Loss: 0.111\n",
      "Training: Epoch 148, Batch 87, Loss: 0.074\n",
      "Training: Epoch 148, Batch 88, Loss: 0.067\n",
      "Training: Epoch 148, Batch 89, Loss: 0.082\n",
      "Val: Epoch 148, Loss: 0.304\n",
      "Training: Epoch 149, Batch 0, Loss: 0.136\n",
      "Training: Epoch 149, Batch 1, Loss: 0.122\n",
      "Training: Epoch 149, Batch 2, Loss: 0.09\n",
      "Training: Epoch 149, Batch 3, Loss: 0.079\n",
      "Training: Epoch 149, Batch 4, Loss: 0.066\n",
      "Training: Epoch 149, Batch 5, Loss: 0.105\n",
      "Training: Epoch 149, Batch 6, Loss: 0.098\n",
      "Training: Epoch 149, Batch 7, Loss: 0.089\n",
      "Training: Epoch 149, Batch 8, Loss: 0.114\n",
      "Training: Epoch 149, Batch 9, Loss: 0.099\n",
      "Training: Epoch 149, Batch 10, Loss: 0.116\n",
      "Training: Epoch 149, Batch 11, Loss: 0.113\n",
      "Training: Epoch 149, Batch 12, Loss: 0.093\n",
      "Training: Epoch 149, Batch 13, Loss: 0.13\n",
      "Training: Epoch 149, Batch 14, Loss: 0.083\n",
      "Training: Epoch 149, Batch 15, Loss: 0.098\n",
      "Training: Epoch 149, Batch 16, Loss: 0.07\n",
      "Training: Epoch 149, Batch 17, Loss: 0.101\n",
      "Training: Epoch 149, Batch 18, Loss: 0.084\n",
      "Training: Epoch 149, Batch 19, Loss: 0.094\n",
      "Training: Epoch 149, Batch 20, Loss: 0.086\n",
      "Training: Epoch 149, Batch 21, Loss: 0.113\n",
      "Training: Epoch 149, Batch 22, Loss: 0.107\n",
      "Training: Epoch 149, Batch 23, Loss: 0.151\n",
      "Training: Epoch 149, Batch 24, Loss: 0.077\n",
      "Training: Epoch 149, Batch 25, Loss: 0.076\n",
      "Training: Epoch 149, Batch 26, Loss: 0.115\n",
      "Training: Epoch 149, Batch 27, Loss: 0.081\n",
      "Training: Epoch 149, Batch 28, Loss: 0.104\n",
      "Training: Epoch 149, Batch 29, Loss: 0.099\n",
      "Training: Epoch 149, Batch 30, Loss: 0.064\n",
      "Training: Epoch 149, Batch 31, Loss: 0.095\n",
      "Training: Epoch 149, Batch 32, Loss: 0.161\n",
      "Training: Epoch 149, Batch 33, Loss: 0.119\n",
      "Training: Epoch 149, Batch 34, Loss: 0.075\n",
      "Training: Epoch 149, Batch 35, Loss: 0.078\n",
      "Training: Epoch 149, Batch 36, Loss: 0.086\n",
      "Training: Epoch 149, Batch 37, Loss: 0.127\n",
      "Training: Epoch 149, Batch 38, Loss: 0.099\n",
      "Training: Epoch 149, Batch 39, Loss: 0.105\n",
      "Training: Epoch 149, Batch 40, Loss: 0.071\n",
      "Training: Epoch 149, Batch 41, Loss: 0.079\n",
      "Training: Epoch 149, Batch 42, Loss: 0.115\n",
      "Training: Epoch 149, Batch 43, Loss: 0.096\n",
      "Training: Epoch 149, Batch 44, Loss: 0.094\n",
      "Training: Epoch 149, Batch 45, Loss: 0.121\n",
      "Training: Epoch 149, Batch 46, Loss: 0.138\n",
      "Training: Epoch 149, Batch 47, Loss: 0.084\n",
      "Training: Epoch 149, Batch 48, Loss: 0.13\n",
      "Training: Epoch 149, Batch 49, Loss: 0.108\n",
      "Training: Epoch 149, Batch 50, Loss: 0.105\n",
      "Training: Epoch 149, Batch 51, Loss: 0.097\n",
      "Training: Epoch 149, Batch 52, Loss: 0.13\n",
      "Training: Epoch 149, Batch 53, Loss: 0.105\n",
      "Training: Epoch 149, Batch 54, Loss: 0.098\n",
      "Training: Epoch 149, Batch 55, Loss: 0.083\n",
      "Training: Epoch 149, Batch 56, Loss: 0.11\n",
      "Training: Epoch 149, Batch 57, Loss: 0.149\n",
      "Training: Epoch 149, Batch 58, Loss: 0.122\n",
      "Training: Epoch 149, Batch 59, Loss: 0.16\n",
      "Training: Epoch 149, Batch 60, Loss: 0.106\n",
      "Training: Epoch 149, Batch 61, Loss: 0.084\n",
      "Training: Epoch 149, Batch 62, Loss: 0.116\n",
      "Training: Epoch 149, Batch 63, Loss: 0.098\n",
      "Training: Epoch 149, Batch 64, Loss: 0.088\n",
      "Training: Epoch 149, Batch 65, Loss: 0.089\n",
      "Training: Epoch 149, Batch 66, Loss: 0.102\n",
      "Training: Epoch 149, Batch 67, Loss: 0.088\n",
      "Training: Epoch 149, Batch 68, Loss: 0.106\n",
      "Training: Epoch 149, Batch 69, Loss: 0.085\n",
      "Training: Epoch 149, Batch 70, Loss: 0.09\n",
      "Training: Epoch 149, Batch 71, Loss: 0.103\n",
      "Training: Epoch 149, Batch 72, Loss: 0.087\n",
      "Training: Epoch 149, Batch 73, Loss: 0.109\n",
      "Training: Epoch 149, Batch 74, Loss: 0.089\n",
      "Training: Epoch 149, Batch 75, Loss: 0.085\n",
      "Training: Epoch 149, Batch 76, Loss: 0.091\n",
      "Training: Epoch 149, Batch 77, Loss: 0.106\n",
      "Training: Epoch 149, Batch 78, Loss: 0.093\n",
      "Training: Epoch 149, Batch 79, Loss: 0.105\n",
      "Training: Epoch 149, Batch 80, Loss: 0.098\n",
      "Training: Epoch 149, Batch 81, Loss: 0.077\n",
      "Training: Epoch 149, Batch 82, Loss: 0.105\n",
      "Training: Epoch 149, Batch 83, Loss: 0.113\n",
      "Training: Epoch 149, Batch 84, Loss: 0.104\n",
      "Training: Epoch 149, Batch 85, Loss: 0.106\n",
      "Training: Epoch 149, Batch 86, Loss: 0.071\n",
      "Training: Epoch 149, Batch 87, Loss: 0.096\n",
      "Training: Epoch 149, Batch 88, Loss: 0.073\n",
      "Training: Epoch 149, Batch 89, Loss: 0.127\n",
      "Val: Epoch 149, Loss: 0.324\n",
      "Training: Epoch 150, Batch 0, Loss: 0.131\n",
      "Training: Epoch 150, Batch 1, Loss: 0.081\n",
      "Training: Epoch 150, Batch 2, Loss: 0.101\n",
      "Training: Epoch 150, Batch 3, Loss: 0.08\n",
      "Training: Epoch 150, Batch 4, Loss: 0.112\n",
      "Training: Epoch 150, Batch 5, Loss: 0.104\n",
      "Training: Epoch 150, Batch 6, Loss: 0.127\n",
      "Training: Epoch 150, Batch 7, Loss: 0.1\n",
      "Training: Epoch 150, Batch 8, Loss: 0.116\n",
      "Training: Epoch 150, Batch 9, Loss: 0.086\n",
      "Training: Epoch 150, Batch 10, Loss: 0.069\n",
      "Training: Epoch 150, Batch 11, Loss: 0.116\n",
      "Training: Epoch 150, Batch 12, Loss: 0.09\n",
      "Training: Epoch 150, Batch 13, Loss: 0.093\n",
      "Training: Epoch 150, Batch 14, Loss: 0.09\n",
      "Training: Epoch 150, Batch 15, Loss: 0.108\n",
      "Training: Epoch 150, Batch 16, Loss: 0.094\n",
      "Training: Epoch 150, Batch 17, Loss: 0.074\n",
      "Training: Epoch 150, Batch 18, Loss: 0.101\n",
      "Training: Epoch 150, Batch 19, Loss: 0.103\n",
      "Training: Epoch 150, Batch 20, Loss: 0.108\n",
      "Training: Epoch 150, Batch 21, Loss: 0.092\n",
      "Training: Epoch 150, Batch 22, Loss: 0.09\n",
      "Training: Epoch 150, Batch 23, Loss: 0.099\n",
      "Training: Epoch 150, Batch 24, Loss: 0.097\n",
      "Training: Epoch 150, Batch 25, Loss: 0.102\n",
      "Training: Epoch 150, Batch 26, Loss: 0.094\n",
      "Training: Epoch 150, Batch 27, Loss: 0.09\n",
      "Training: Epoch 150, Batch 28, Loss: 0.096\n",
      "Training: Epoch 150, Batch 29, Loss: 0.107\n",
      "Training: Epoch 150, Batch 30, Loss: 0.087\n",
      "Training: Epoch 150, Batch 31, Loss: 0.11\n",
      "Training: Epoch 150, Batch 32, Loss: 0.077\n",
      "Training: Epoch 150, Batch 33, Loss: 0.086\n",
      "Training: Epoch 150, Batch 34, Loss: 0.089\n",
      "Training: Epoch 150, Batch 35, Loss: 0.088\n",
      "Training: Epoch 150, Batch 36, Loss: 0.081\n",
      "Training: Epoch 150, Batch 37, Loss: 0.073\n",
      "Training: Epoch 150, Batch 38, Loss: 0.078\n",
      "Training: Epoch 150, Batch 39, Loss: 0.077\n",
      "Training: Epoch 150, Batch 40, Loss: 0.128\n",
      "Training: Epoch 150, Batch 41, Loss: 0.12\n",
      "Training: Epoch 150, Batch 42, Loss: 0.125\n",
      "Training: Epoch 150, Batch 43, Loss: 0.187\n",
      "Training: Epoch 150, Batch 44, Loss: 0.06\n",
      "Training: Epoch 150, Batch 45, Loss: 0.116\n",
      "Training: Epoch 150, Batch 46, Loss: 0.086\n",
      "Training: Epoch 150, Batch 47, Loss: 0.081\n",
      "Training: Epoch 150, Batch 48, Loss: 0.079\n",
      "Training: Epoch 150, Batch 49, Loss: 0.108\n",
      "Training: Epoch 150, Batch 50, Loss: 0.088\n",
      "Training: Epoch 150, Batch 51, Loss: 0.139\n",
      "Training: Epoch 150, Batch 52, Loss: 0.1\n",
      "Training: Epoch 150, Batch 53, Loss: 0.119\n",
      "Training: Epoch 150, Batch 54, Loss: 0.141\n",
      "Training: Epoch 150, Batch 55, Loss: 0.092\n",
      "Training: Epoch 150, Batch 56, Loss: 0.066\n",
      "Training: Epoch 150, Batch 57, Loss: 0.077\n",
      "Training: Epoch 150, Batch 58, Loss: 0.079\n",
      "Training: Epoch 150, Batch 59, Loss: 0.102\n",
      "Training: Epoch 150, Batch 60, Loss: 0.116\n",
      "Training: Epoch 150, Batch 61, Loss: 0.142\n",
      "Training: Epoch 150, Batch 62, Loss: 0.084\n",
      "Training: Epoch 150, Batch 63, Loss: 0.075\n",
      "Training: Epoch 150, Batch 64, Loss: 0.079\n",
      "Training: Epoch 150, Batch 65, Loss: 0.1\n",
      "Training: Epoch 150, Batch 66, Loss: 0.078\n",
      "Training: Epoch 150, Batch 67, Loss: 0.122\n",
      "Training: Epoch 150, Batch 68, Loss: 0.086\n",
      "Training: Epoch 150, Batch 69, Loss: 0.134\n",
      "Training: Epoch 150, Batch 70, Loss: 0.081\n",
      "Training: Epoch 150, Batch 71, Loss: 0.118\n",
      "Training: Epoch 150, Batch 72, Loss: 0.076\n",
      "Training: Epoch 150, Batch 73, Loss: 0.129\n",
      "Training: Epoch 150, Batch 74, Loss: 0.108\n",
      "Training: Epoch 150, Batch 75, Loss: 0.105\n",
      "Training: Epoch 150, Batch 76, Loss: 0.095\n",
      "Training: Epoch 150, Batch 77, Loss: 0.097\n",
      "Training: Epoch 150, Batch 78, Loss: 0.104\n",
      "Training: Epoch 150, Batch 79, Loss: 0.102\n",
      "Training: Epoch 150, Batch 80, Loss: 0.089\n",
      "Training: Epoch 150, Batch 81, Loss: 0.111\n",
      "Training: Epoch 150, Batch 82, Loss: 0.165\n",
      "Training: Epoch 150, Batch 83, Loss: 0.102\n",
      "Training: Epoch 150, Batch 84, Loss: 0.108\n",
      "Training: Epoch 150, Batch 85, Loss: 0.072\n",
      "Training: Epoch 150, Batch 86, Loss: 0.081\n",
      "Training: Epoch 150, Batch 87, Loss: 0.074\n",
      "Training: Epoch 150, Batch 88, Loss: 0.091\n",
      "Training: Epoch 150, Batch 89, Loss: 0.109\n",
      "Val: Epoch 150, Loss: 0.304\n",
      "Training: Epoch 151, Batch 0, Loss: 0.118\n",
      "Training: Epoch 151, Batch 1, Loss: 0.099\n",
      "Training: Epoch 151, Batch 2, Loss: 0.106\n",
      "Training: Epoch 151, Batch 3, Loss: 0.091\n",
      "Training: Epoch 151, Batch 4, Loss: 0.124\n",
      "Training: Epoch 151, Batch 5, Loss: 0.069\n",
      "Training: Epoch 151, Batch 6, Loss: 0.114\n",
      "Training: Epoch 151, Batch 7, Loss: 0.12\n",
      "Training: Epoch 151, Batch 8, Loss: 0.079\n",
      "Training: Epoch 151, Batch 9, Loss: 0.108\n",
      "Training: Epoch 151, Batch 10, Loss: 0.095\n",
      "Training: Epoch 151, Batch 11, Loss: 0.09\n",
      "Training: Epoch 151, Batch 12, Loss: 0.107\n",
      "Training: Epoch 151, Batch 13, Loss: 0.097\n",
      "Training: Epoch 151, Batch 14, Loss: 0.092\n",
      "Training: Epoch 151, Batch 15, Loss: 0.081\n",
      "Training: Epoch 151, Batch 16, Loss: 0.127\n",
      "Training: Epoch 151, Batch 17, Loss: 0.108\n",
      "Training: Epoch 151, Batch 18, Loss: 0.08\n",
      "Training: Epoch 151, Batch 19, Loss: 0.114\n",
      "Training: Epoch 151, Batch 20, Loss: 0.081\n",
      "Training: Epoch 151, Batch 21, Loss: 0.111\n",
      "Training: Epoch 151, Batch 22, Loss: 0.097\n",
      "Training: Epoch 151, Batch 23, Loss: 0.09\n",
      "Training: Epoch 151, Batch 24, Loss: 0.153\n",
      "Training: Epoch 151, Batch 25, Loss: 0.069\n",
      "Training: Epoch 151, Batch 26, Loss: 0.086\n",
      "Training: Epoch 151, Batch 27, Loss: 0.114\n",
      "Training: Epoch 151, Batch 28, Loss: 0.109\n",
      "Training: Epoch 151, Batch 29, Loss: 0.074\n",
      "Training: Epoch 151, Batch 30, Loss: 0.079\n",
      "Training: Epoch 151, Batch 31, Loss: 0.1\n",
      "Training: Epoch 151, Batch 32, Loss: 0.124\n",
      "Training: Epoch 151, Batch 33, Loss: 0.089\n",
      "Training: Epoch 151, Batch 34, Loss: 0.102\n",
      "Training: Epoch 151, Batch 35, Loss: 0.114\n",
      "Training: Epoch 151, Batch 36, Loss: 0.095\n",
      "Training: Epoch 151, Batch 37, Loss: 0.081\n",
      "Training: Epoch 151, Batch 38, Loss: 0.097\n",
      "Training: Epoch 151, Batch 39, Loss: 0.12\n",
      "Training: Epoch 151, Batch 40, Loss: 0.105\n",
      "Training: Epoch 151, Batch 41, Loss: 0.112\n",
      "Training: Epoch 151, Batch 42, Loss: 0.101\n",
      "Training: Epoch 151, Batch 43, Loss: 0.069\n",
      "Training: Epoch 151, Batch 44, Loss: 0.085\n",
      "Training: Epoch 151, Batch 45, Loss: 0.125\n",
      "Training: Epoch 151, Batch 46, Loss: 0.081\n",
      "Training: Epoch 151, Batch 47, Loss: 0.084\n",
      "Training: Epoch 151, Batch 48, Loss: 0.094\n",
      "Training: Epoch 151, Batch 49, Loss: 0.142\n",
      "Training: Epoch 151, Batch 50, Loss: 0.101\n",
      "Training: Epoch 151, Batch 51, Loss: 0.11\n",
      "Training: Epoch 151, Batch 52, Loss: 0.099\n",
      "Training: Epoch 151, Batch 53, Loss: 0.084\n",
      "Training: Epoch 151, Batch 54, Loss: 0.108\n",
      "Training: Epoch 151, Batch 55, Loss: 0.08\n",
      "Training: Epoch 151, Batch 56, Loss: 0.093\n",
      "Training: Epoch 151, Batch 57, Loss: 0.084\n",
      "Training: Epoch 151, Batch 58, Loss: 0.074\n",
      "Training: Epoch 151, Batch 59, Loss: 0.093\n",
      "Training: Epoch 151, Batch 60, Loss: 0.096\n",
      "Training: Epoch 151, Batch 61, Loss: 0.095\n",
      "Training: Epoch 151, Batch 62, Loss: 0.101\n",
      "Training: Epoch 151, Batch 63, Loss: 0.075\n",
      "Training: Epoch 151, Batch 64, Loss: 0.117\n",
      "Training: Epoch 151, Batch 65, Loss: 0.076\n",
      "Training: Epoch 151, Batch 66, Loss: 0.092\n",
      "Training: Epoch 151, Batch 67, Loss: 0.126\n",
      "Training: Epoch 151, Batch 68, Loss: 0.118\n",
      "Training: Epoch 151, Batch 69, Loss: 0.123\n",
      "Training: Epoch 151, Batch 70, Loss: 0.085\n",
      "Training: Epoch 151, Batch 71, Loss: 0.087\n",
      "Training: Epoch 151, Batch 72, Loss: 0.094\n",
      "Training: Epoch 151, Batch 73, Loss: 0.073\n",
      "Training: Epoch 151, Batch 74, Loss: 0.093\n",
      "Training: Epoch 151, Batch 75, Loss: 0.09\n",
      "Training: Epoch 151, Batch 76, Loss: 0.118\n",
      "Training: Epoch 151, Batch 77, Loss: 0.074\n",
      "Training: Epoch 151, Batch 78, Loss: 0.121\n",
      "Training: Epoch 151, Batch 79, Loss: 0.087\n",
      "Training: Epoch 151, Batch 80, Loss: 0.063\n",
      "Training: Epoch 151, Batch 81, Loss: 0.105\n",
      "Training: Epoch 151, Batch 82, Loss: 0.098\n",
      "Training: Epoch 151, Batch 83, Loss: 0.107\n",
      "Training: Epoch 151, Batch 84, Loss: 0.072\n",
      "Training: Epoch 151, Batch 85, Loss: 0.11\n",
      "Training: Epoch 151, Batch 86, Loss: 0.106\n",
      "Training: Epoch 151, Batch 87, Loss: 0.109\n",
      "Training: Epoch 151, Batch 88, Loss: 0.063\n",
      "Training: Epoch 151, Batch 89, Loss: 0.092\n",
      "Val: Epoch 151, Loss: 0.299\n",
      "Training: Epoch 152, Batch 0, Loss: 0.106\n",
      "Training: Epoch 152, Batch 1, Loss: 0.098\n",
      "Training: Epoch 152, Batch 2, Loss: 0.072\n",
      "Training: Epoch 152, Batch 3, Loss: 0.093\n",
      "Training: Epoch 152, Batch 4, Loss: 0.083\n",
      "Training: Epoch 152, Batch 5, Loss: 0.103\n",
      "Training: Epoch 152, Batch 6, Loss: 0.127\n",
      "Training: Epoch 152, Batch 7, Loss: 0.085\n",
      "Training: Epoch 152, Batch 8, Loss: 0.084\n",
      "Training: Epoch 152, Batch 9, Loss: 0.141\n",
      "Training: Epoch 152, Batch 10, Loss: 0.07\n",
      "Training: Epoch 152, Batch 11, Loss: 0.074\n",
      "Training: Epoch 152, Batch 12, Loss: 0.083\n",
      "Training: Epoch 152, Batch 13, Loss: 0.134\n",
      "Training: Epoch 152, Batch 14, Loss: 0.097\n",
      "Training: Epoch 152, Batch 15, Loss: 0.074\n",
      "Training: Epoch 152, Batch 16, Loss: 0.114\n",
      "Training: Epoch 152, Batch 17, Loss: 0.095\n",
      "Training: Epoch 152, Batch 18, Loss: 0.072\n",
      "Training: Epoch 152, Batch 19, Loss: 0.095\n",
      "Training: Epoch 152, Batch 20, Loss: 0.093\n",
      "Training: Epoch 152, Batch 21, Loss: 0.123\n",
      "Training: Epoch 152, Batch 22, Loss: 0.112\n",
      "Training: Epoch 152, Batch 23, Loss: 0.111\n",
      "Training: Epoch 152, Batch 24, Loss: 0.101\n",
      "Training: Epoch 152, Batch 25, Loss: 0.118\n",
      "Training: Epoch 152, Batch 26, Loss: 0.082\n",
      "Training: Epoch 152, Batch 27, Loss: 0.082\n",
      "Training: Epoch 152, Batch 28, Loss: 0.08\n",
      "Training: Epoch 152, Batch 29, Loss: 0.115\n",
      "Training: Epoch 152, Batch 30, Loss: 0.09\n",
      "Training: Epoch 152, Batch 31, Loss: 0.074\n",
      "Training: Epoch 152, Batch 32, Loss: 0.081\n",
      "Training: Epoch 152, Batch 33, Loss: 0.107\n",
      "Training: Epoch 152, Batch 34, Loss: 0.104\n",
      "Training: Epoch 152, Batch 35, Loss: 0.09\n",
      "Training: Epoch 152, Batch 36, Loss: 0.073\n",
      "Training: Epoch 152, Batch 37, Loss: 0.084\n",
      "Training: Epoch 152, Batch 38, Loss: 0.084\n",
      "Training: Epoch 152, Batch 39, Loss: 0.077\n",
      "Training: Epoch 152, Batch 40, Loss: 0.114\n",
      "Training: Epoch 152, Batch 41, Loss: 0.077\n",
      "Training: Epoch 152, Batch 42, Loss: 0.092\n",
      "Training: Epoch 152, Batch 43, Loss: 0.12\n",
      "Training: Epoch 152, Batch 44, Loss: 0.093\n",
      "Training: Epoch 152, Batch 45, Loss: 0.09\n",
      "Training: Epoch 152, Batch 46, Loss: 0.097\n",
      "Training: Epoch 152, Batch 47, Loss: 0.081\n",
      "Training: Epoch 152, Batch 48, Loss: 0.086\n",
      "Training: Epoch 152, Batch 49, Loss: 0.102\n",
      "Training: Epoch 152, Batch 50, Loss: 0.072\n",
      "Training: Epoch 152, Batch 51, Loss: 0.077\n",
      "Training: Epoch 152, Batch 52, Loss: 0.075\n",
      "Training: Epoch 152, Batch 53, Loss: 0.095\n",
      "Training: Epoch 152, Batch 54, Loss: 0.114\n",
      "Training: Epoch 152, Batch 55, Loss: 0.127\n",
      "Training: Epoch 152, Batch 56, Loss: 0.136\n",
      "Training: Epoch 152, Batch 57, Loss: 0.113\n",
      "Training: Epoch 152, Batch 58, Loss: 0.094\n",
      "Training: Epoch 152, Batch 59, Loss: 0.104\n",
      "Training: Epoch 152, Batch 60, Loss: 0.119\n",
      "Training: Epoch 152, Batch 61, Loss: 0.106\n",
      "Training: Epoch 152, Batch 62, Loss: 0.083\n",
      "Training: Epoch 152, Batch 63, Loss: 0.109\n",
      "Training: Epoch 152, Batch 64, Loss: 0.093\n",
      "Training: Epoch 152, Batch 65, Loss: 0.091\n",
      "Training: Epoch 152, Batch 66, Loss: 0.104\n",
      "Training: Epoch 152, Batch 67, Loss: 0.091\n",
      "Training: Epoch 152, Batch 68, Loss: 0.078\n",
      "Training: Epoch 152, Batch 69, Loss: 0.11\n",
      "Training: Epoch 152, Batch 70, Loss: 0.08\n",
      "Training: Epoch 152, Batch 71, Loss: 0.083\n",
      "Training: Epoch 152, Batch 72, Loss: 0.086\n",
      "Training: Epoch 152, Batch 73, Loss: 0.118\n",
      "Training: Epoch 152, Batch 74, Loss: 0.09\n",
      "Training: Epoch 152, Batch 75, Loss: 0.092\n",
      "Training: Epoch 152, Batch 76, Loss: 0.065\n",
      "Training: Epoch 152, Batch 77, Loss: 0.085\n",
      "Training: Epoch 152, Batch 78, Loss: 0.094\n",
      "Training: Epoch 152, Batch 79, Loss: 0.138\n",
      "Training: Epoch 152, Batch 80, Loss: 0.095\n",
      "Training: Epoch 152, Batch 81, Loss: 0.128\n",
      "Training: Epoch 152, Batch 82, Loss: 0.088\n",
      "Training: Epoch 152, Batch 83, Loss: 0.104\n",
      "Training: Epoch 152, Batch 84, Loss: 0.094\n",
      "Training: Epoch 152, Batch 85, Loss: 0.098\n",
      "Training: Epoch 152, Batch 86, Loss: 0.099\n",
      "Training: Epoch 152, Batch 87, Loss: 0.101\n",
      "Training: Epoch 152, Batch 88, Loss: 0.075\n",
      "Training: Epoch 152, Batch 89, Loss: 0.114\n",
      "Val: Epoch 152, Loss: 0.331\n",
      "Training: Epoch 153, Batch 0, Loss: 0.124\n",
      "Training: Epoch 153, Batch 1, Loss: 0.085\n",
      "Training: Epoch 153, Batch 2, Loss: 0.078\n",
      "Training: Epoch 153, Batch 3, Loss: 0.097\n",
      "Training: Epoch 153, Batch 4, Loss: 0.093\n",
      "Training: Epoch 153, Batch 5, Loss: 0.085\n",
      "Training: Epoch 153, Batch 6, Loss: 0.109\n",
      "Training: Epoch 153, Batch 7, Loss: 0.116\n",
      "Training: Epoch 153, Batch 8, Loss: 0.083\n",
      "Training: Epoch 153, Batch 9, Loss: 0.09\n",
      "Training: Epoch 153, Batch 10, Loss: 0.082\n",
      "Training: Epoch 153, Batch 11, Loss: 0.091\n",
      "Training: Epoch 153, Batch 12, Loss: 0.105\n",
      "Training: Epoch 153, Batch 13, Loss: 0.092\n",
      "Training: Epoch 153, Batch 14, Loss: 0.068\n",
      "Training: Epoch 153, Batch 15, Loss: 0.118\n",
      "Training: Epoch 153, Batch 16, Loss: 0.081\n",
      "Training: Epoch 153, Batch 17, Loss: 0.112\n",
      "Training: Epoch 153, Batch 18, Loss: 0.089\n",
      "Training: Epoch 153, Batch 19, Loss: 0.137\n",
      "Training: Epoch 153, Batch 20, Loss: 0.065\n",
      "Training: Epoch 153, Batch 21, Loss: 0.104\n",
      "Training: Epoch 153, Batch 22, Loss: 0.093\n",
      "Training: Epoch 153, Batch 23, Loss: 0.077\n",
      "Training: Epoch 153, Batch 24, Loss: 0.085\n",
      "Training: Epoch 153, Batch 25, Loss: 0.116\n",
      "Training: Epoch 153, Batch 26, Loss: 0.107\n",
      "Training: Epoch 153, Batch 27, Loss: 0.115\n",
      "Training: Epoch 153, Batch 28, Loss: 0.073\n",
      "Training: Epoch 153, Batch 29, Loss: 0.13\n",
      "Training: Epoch 153, Batch 30, Loss: 0.109\n",
      "Training: Epoch 153, Batch 31, Loss: 0.065\n",
      "Training: Epoch 153, Batch 32, Loss: 0.083\n",
      "Training: Epoch 153, Batch 33, Loss: 0.112\n",
      "Training: Epoch 153, Batch 34, Loss: 0.093\n",
      "Training: Epoch 153, Batch 35, Loss: 0.086\n",
      "Training: Epoch 153, Batch 36, Loss: 0.088\n",
      "Training: Epoch 153, Batch 37, Loss: 0.112\n",
      "Training: Epoch 153, Batch 38, Loss: 0.105\n",
      "Training: Epoch 153, Batch 39, Loss: 0.091\n",
      "Training: Epoch 153, Batch 40, Loss: 0.131\n",
      "Training: Epoch 153, Batch 41, Loss: 0.092\n",
      "Training: Epoch 153, Batch 42, Loss: 0.103\n",
      "Training: Epoch 153, Batch 43, Loss: 0.074\n",
      "Training: Epoch 153, Batch 44, Loss: 0.094\n",
      "Training: Epoch 153, Batch 45, Loss: 0.125\n",
      "Training: Epoch 153, Batch 46, Loss: 0.086\n",
      "Training: Epoch 153, Batch 47, Loss: 0.1\n",
      "Training: Epoch 153, Batch 48, Loss: 0.117\n",
      "Training: Epoch 153, Batch 49, Loss: 0.108\n",
      "Training: Epoch 153, Batch 50, Loss: 0.076\n",
      "Training: Epoch 153, Batch 51, Loss: 0.106\n",
      "Training: Epoch 153, Batch 52, Loss: 0.072\n",
      "Training: Epoch 153, Batch 53, Loss: 0.097\n",
      "Training: Epoch 153, Batch 54, Loss: 0.085\n",
      "Training: Epoch 153, Batch 55, Loss: 0.077\n",
      "Training: Epoch 153, Batch 56, Loss: 0.108\n",
      "Training: Epoch 153, Batch 57, Loss: 0.105\n",
      "Training: Epoch 153, Batch 58, Loss: 0.119\n",
      "Training: Epoch 153, Batch 59, Loss: 0.09\n",
      "Training: Epoch 153, Batch 60, Loss: 0.071\n",
      "Training: Epoch 153, Batch 61, Loss: 0.083\n",
      "Training: Epoch 153, Batch 62, Loss: 0.099\n",
      "Training: Epoch 153, Batch 63, Loss: 0.111\n",
      "Training: Epoch 153, Batch 64, Loss: 0.086\n",
      "Training: Epoch 153, Batch 65, Loss: 0.098\n",
      "Training: Epoch 153, Batch 66, Loss: 0.091\n",
      "Training: Epoch 153, Batch 67, Loss: 0.096\n",
      "Training: Epoch 153, Batch 68, Loss: 0.102\n",
      "Training: Epoch 153, Batch 69, Loss: 0.106\n",
      "Training: Epoch 153, Batch 70, Loss: 0.077\n",
      "Training: Epoch 153, Batch 71, Loss: 0.116\n",
      "Training: Epoch 153, Batch 72, Loss: 0.11\n",
      "Training: Epoch 153, Batch 73, Loss: 0.132\n",
      "Training: Epoch 153, Batch 74, Loss: 0.079\n",
      "Training: Epoch 153, Batch 75, Loss: 0.081\n",
      "Training: Epoch 153, Batch 76, Loss: 0.095\n",
      "Training: Epoch 153, Batch 77, Loss: 0.096\n",
      "Training: Epoch 153, Batch 78, Loss: 0.121\n",
      "Training: Epoch 153, Batch 79, Loss: 0.088\n",
      "Training: Epoch 153, Batch 80, Loss: 0.13\n",
      "Training: Epoch 153, Batch 81, Loss: 0.082\n",
      "Training: Epoch 153, Batch 82, Loss: 0.093\n",
      "Training: Epoch 153, Batch 83, Loss: 0.097\n",
      "Training: Epoch 153, Batch 84, Loss: 0.092\n",
      "Training: Epoch 153, Batch 85, Loss: 0.09\n",
      "Training: Epoch 153, Batch 86, Loss: 0.062\n",
      "Training: Epoch 153, Batch 87, Loss: 0.086\n",
      "Training: Epoch 153, Batch 88, Loss: 0.144\n",
      "Training: Epoch 153, Batch 89, Loss: 0.088\n",
      "Val: Epoch 153, Loss: 0.298\n",
      "Training: Epoch 154, Batch 0, Loss: 0.101\n",
      "Training: Epoch 154, Batch 1, Loss: 0.105\n",
      "Training: Epoch 154, Batch 2, Loss: 0.101\n",
      "Training: Epoch 154, Batch 3, Loss: 0.104\n",
      "Training: Epoch 154, Batch 4, Loss: 0.106\n",
      "Training: Epoch 154, Batch 5, Loss: 0.063\n",
      "Training: Epoch 154, Batch 6, Loss: 0.075\n",
      "Training: Epoch 154, Batch 7, Loss: 0.106\n",
      "Training: Epoch 154, Batch 8, Loss: 0.101\n",
      "Training: Epoch 154, Batch 9, Loss: 0.152\n",
      "Training: Epoch 154, Batch 10, Loss: 0.128\n",
      "Training: Epoch 154, Batch 11, Loss: 0.093\n",
      "Training: Epoch 154, Batch 12, Loss: 0.096\n",
      "Training: Epoch 154, Batch 13, Loss: 0.111\n",
      "Training: Epoch 154, Batch 14, Loss: 0.084\n",
      "Training: Epoch 154, Batch 15, Loss: 0.076\n",
      "Training: Epoch 154, Batch 16, Loss: 0.121\n",
      "Training: Epoch 154, Batch 17, Loss: 0.1\n",
      "Training: Epoch 154, Batch 18, Loss: 0.096\n",
      "Training: Epoch 154, Batch 19, Loss: 0.103\n",
      "Training: Epoch 154, Batch 20, Loss: 0.091\n",
      "Training: Epoch 154, Batch 21, Loss: 0.08\n",
      "Training: Epoch 154, Batch 22, Loss: 0.102\n",
      "Training: Epoch 154, Batch 23, Loss: 0.093\n",
      "Training: Epoch 154, Batch 24, Loss: 0.1\n",
      "Training: Epoch 154, Batch 25, Loss: 0.129\n",
      "Training: Epoch 154, Batch 26, Loss: 0.111\n",
      "Training: Epoch 154, Batch 27, Loss: 0.095\n",
      "Training: Epoch 154, Batch 28, Loss: 0.1\n",
      "Training: Epoch 154, Batch 29, Loss: 0.078\n",
      "Training: Epoch 154, Batch 30, Loss: 0.078\n",
      "Training: Epoch 154, Batch 31, Loss: 0.108\n",
      "Training: Epoch 154, Batch 32, Loss: 0.095\n",
      "Training: Epoch 154, Batch 33, Loss: 0.089\n",
      "Training: Epoch 154, Batch 34, Loss: 0.099\n",
      "Training: Epoch 154, Batch 35, Loss: 0.124\n",
      "Training: Epoch 154, Batch 36, Loss: 0.108\n",
      "Training: Epoch 154, Batch 37, Loss: 0.077\n",
      "Training: Epoch 154, Batch 38, Loss: 0.093\n",
      "Training: Epoch 154, Batch 39, Loss: 0.082\n",
      "Training: Epoch 154, Batch 40, Loss: 0.092\n",
      "Training: Epoch 154, Batch 41, Loss: 0.141\n",
      "Training: Epoch 154, Batch 42, Loss: 0.088\n",
      "Training: Epoch 154, Batch 43, Loss: 0.103\n",
      "Training: Epoch 154, Batch 44, Loss: 0.081\n",
      "Training: Epoch 154, Batch 45, Loss: 0.076\n",
      "Training: Epoch 154, Batch 46, Loss: 0.098\n",
      "Training: Epoch 154, Batch 47, Loss: 0.107\n",
      "Training: Epoch 154, Batch 48, Loss: 0.085\n",
      "Training: Epoch 154, Batch 49, Loss: 0.084\n",
      "Training: Epoch 154, Batch 50, Loss: 0.105\n",
      "Training: Epoch 154, Batch 51, Loss: 0.119\n",
      "Training: Epoch 154, Batch 52, Loss: 0.071\n",
      "Training: Epoch 154, Batch 53, Loss: 0.093\n",
      "Training: Epoch 154, Batch 54, Loss: 0.104\n",
      "Training: Epoch 154, Batch 55, Loss: 0.091\n",
      "Training: Epoch 154, Batch 56, Loss: 0.089\n",
      "Training: Epoch 154, Batch 57, Loss: 0.089\n",
      "Training: Epoch 154, Batch 58, Loss: 0.093\n",
      "Training: Epoch 154, Batch 59, Loss: 0.159\n",
      "Training: Epoch 154, Batch 60, Loss: 0.098\n",
      "Training: Epoch 154, Batch 61, Loss: 0.099\n",
      "Training: Epoch 154, Batch 62, Loss: 0.114\n",
      "Training: Epoch 154, Batch 63, Loss: 0.08\n",
      "Training: Epoch 154, Batch 64, Loss: 0.099\n",
      "Training: Epoch 154, Batch 65, Loss: 0.109\n",
      "Training: Epoch 154, Batch 66, Loss: 0.119\n",
      "Training: Epoch 154, Batch 67, Loss: 0.094\n",
      "Training: Epoch 154, Batch 68, Loss: 0.115\n",
      "Training: Epoch 154, Batch 69, Loss: 0.083\n",
      "Training: Epoch 154, Batch 70, Loss: 0.083\n",
      "Training: Epoch 154, Batch 71, Loss: 0.108\n",
      "Training: Epoch 154, Batch 72, Loss: 0.081\n",
      "Training: Epoch 154, Batch 73, Loss: 0.118\n",
      "Training: Epoch 154, Batch 74, Loss: 0.094\n",
      "Training: Epoch 154, Batch 75, Loss: 0.081\n",
      "Training: Epoch 154, Batch 76, Loss: 0.097\n",
      "Training: Epoch 154, Batch 77, Loss: 0.099\n",
      "Training: Epoch 154, Batch 78, Loss: 0.104\n",
      "Training: Epoch 154, Batch 79, Loss: 0.12\n",
      "Training: Epoch 154, Batch 80, Loss: 0.101\n",
      "Training: Epoch 154, Batch 81, Loss: 0.075\n",
      "Training: Epoch 154, Batch 82, Loss: 0.113\n",
      "Training: Epoch 154, Batch 83, Loss: 0.099\n",
      "Training: Epoch 154, Batch 84, Loss: 0.119\n",
      "Training: Epoch 154, Batch 85, Loss: 0.076\n",
      "Training: Epoch 154, Batch 86, Loss: 0.085\n",
      "Training: Epoch 154, Batch 87, Loss: 0.089\n",
      "Training: Epoch 154, Batch 88, Loss: 0.087\n",
      "Training: Epoch 154, Batch 89, Loss: 0.068\n",
      "Val: Epoch 154, Loss: 0.298\n",
      "Training: Epoch 155, Batch 0, Loss: 0.083\n",
      "Training: Epoch 155, Batch 1, Loss: 0.079\n",
      "Training: Epoch 155, Batch 2, Loss: 0.066\n",
      "Training: Epoch 155, Batch 3, Loss: 0.083\n",
      "Training: Epoch 155, Batch 4, Loss: 0.11\n",
      "Training: Epoch 155, Batch 5, Loss: 0.175\n",
      "Training: Epoch 155, Batch 6, Loss: 0.104\n",
      "Training: Epoch 155, Batch 7, Loss: 0.066\n",
      "Training: Epoch 155, Batch 8, Loss: 0.143\n",
      "Training: Epoch 155, Batch 9, Loss: 0.092\n",
      "Training: Epoch 155, Batch 10, Loss: 0.118\n",
      "Training: Epoch 155, Batch 11, Loss: 0.117\n",
      "Training: Epoch 155, Batch 12, Loss: 0.093\n",
      "Training: Epoch 155, Batch 13, Loss: 0.097\n",
      "Training: Epoch 155, Batch 14, Loss: 0.088\n",
      "Training: Epoch 155, Batch 15, Loss: 0.084\n",
      "Training: Epoch 155, Batch 16, Loss: 0.103\n",
      "Training: Epoch 155, Batch 17, Loss: 0.087\n",
      "Training: Epoch 155, Batch 18, Loss: 0.079\n",
      "Training: Epoch 155, Batch 19, Loss: 0.106\n",
      "Training: Epoch 155, Batch 20, Loss: 0.086\n",
      "Training: Epoch 155, Batch 21, Loss: 0.11\n",
      "Training: Epoch 155, Batch 22, Loss: 0.107\n",
      "Training: Epoch 155, Batch 23, Loss: 0.074\n",
      "Training: Epoch 155, Batch 24, Loss: 0.099\n",
      "Training: Epoch 155, Batch 25, Loss: 0.083\n",
      "Training: Epoch 155, Batch 26, Loss: 0.072\n",
      "Training: Epoch 155, Batch 27, Loss: 0.102\n",
      "Training: Epoch 155, Batch 28, Loss: 0.094\n",
      "Training: Epoch 155, Batch 29, Loss: 0.097\n",
      "Training: Epoch 155, Batch 30, Loss: 0.117\n",
      "Training: Epoch 155, Batch 31, Loss: 0.117\n",
      "Training: Epoch 155, Batch 32, Loss: 0.098\n",
      "Training: Epoch 155, Batch 33, Loss: 0.122\n",
      "Training: Epoch 155, Batch 34, Loss: 0.109\n",
      "Training: Epoch 155, Batch 35, Loss: 0.122\n",
      "Training: Epoch 155, Batch 36, Loss: 0.095\n",
      "Training: Epoch 155, Batch 37, Loss: 0.081\n",
      "Training: Epoch 155, Batch 38, Loss: 0.095\n",
      "Training: Epoch 155, Batch 39, Loss: 0.094\n",
      "Training: Epoch 155, Batch 40, Loss: 0.117\n",
      "Training: Epoch 155, Batch 41, Loss: 0.083\n",
      "Training: Epoch 155, Batch 42, Loss: 0.072\n",
      "Training: Epoch 155, Batch 43, Loss: 0.08\n",
      "Training: Epoch 155, Batch 44, Loss: 0.082\n",
      "Training: Epoch 155, Batch 45, Loss: 0.101\n",
      "Training: Epoch 155, Batch 46, Loss: 0.115\n",
      "Training: Epoch 155, Batch 47, Loss: 0.094\n",
      "Training: Epoch 155, Batch 48, Loss: 0.077\n",
      "Training: Epoch 155, Batch 49, Loss: 0.103\n",
      "Training: Epoch 155, Batch 50, Loss: 0.109\n",
      "Training: Epoch 155, Batch 51, Loss: 0.122\n",
      "Training: Epoch 155, Batch 52, Loss: 0.104\n",
      "Training: Epoch 155, Batch 53, Loss: 0.109\n",
      "Training: Epoch 155, Batch 54, Loss: 0.099\n",
      "Training: Epoch 155, Batch 55, Loss: 0.086\n",
      "Training: Epoch 155, Batch 56, Loss: 0.117\n",
      "Training: Epoch 155, Batch 57, Loss: 0.115\n",
      "Training: Epoch 155, Batch 58, Loss: 0.097\n",
      "Training: Epoch 155, Batch 59, Loss: 0.113\n",
      "Training: Epoch 155, Batch 60, Loss: 0.104\n",
      "Training: Epoch 155, Batch 61, Loss: 0.085\n",
      "Training: Epoch 155, Batch 62, Loss: 0.129\n",
      "Training: Epoch 155, Batch 63, Loss: 0.073\n",
      "Training: Epoch 155, Batch 64, Loss: 0.101\n",
      "Training: Epoch 155, Batch 65, Loss: 0.13\n",
      "Training: Epoch 155, Batch 66, Loss: 0.086\n",
      "Training: Epoch 155, Batch 67, Loss: 0.096\n",
      "Training: Epoch 155, Batch 68, Loss: 0.105\n",
      "Training: Epoch 155, Batch 69, Loss: 0.103\n",
      "Training: Epoch 155, Batch 70, Loss: 0.144\n",
      "Training: Epoch 155, Batch 71, Loss: 0.117\n",
      "Training: Epoch 155, Batch 72, Loss: 0.104\n",
      "Training: Epoch 155, Batch 73, Loss: 0.07\n",
      "Training: Epoch 155, Batch 74, Loss: 0.083\n",
      "Training: Epoch 155, Batch 75, Loss: 0.106\n",
      "Training: Epoch 155, Batch 76, Loss: 0.083\n",
      "Training: Epoch 155, Batch 77, Loss: 0.07\n",
      "Training: Epoch 155, Batch 78, Loss: 0.089\n",
      "Training: Epoch 155, Batch 79, Loss: 0.116\n",
      "Training: Epoch 155, Batch 80, Loss: 0.091\n",
      "Training: Epoch 155, Batch 81, Loss: 0.112\n",
      "Training: Epoch 155, Batch 82, Loss: 0.095\n",
      "Training: Epoch 155, Batch 83, Loss: 0.103\n",
      "Training: Epoch 155, Batch 84, Loss: 0.135\n",
      "Training: Epoch 155, Batch 85, Loss: 0.087\n",
      "Training: Epoch 155, Batch 86, Loss: 0.132\n",
      "Training: Epoch 155, Batch 87, Loss: 0.093\n",
      "Training: Epoch 155, Batch 88, Loss: 0.124\n",
      "Training: Epoch 155, Batch 89, Loss: 0.136\n",
      "Val: Epoch 155, Loss: 0.325\n",
      "Training: Epoch 156, Batch 0, Loss: 0.091\n",
      "Training: Epoch 156, Batch 1, Loss: 0.095\n",
      "Training: Epoch 156, Batch 2, Loss: 0.095\n",
      "Training: Epoch 156, Batch 3, Loss: 0.082\n",
      "Training: Epoch 156, Batch 4, Loss: 0.087\n",
      "Training: Epoch 156, Batch 5, Loss: 0.08\n",
      "Training: Epoch 156, Batch 6, Loss: 0.108\n",
      "Training: Epoch 156, Batch 7, Loss: 0.113\n",
      "Training: Epoch 156, Batch 8, Loss: 0.11\n",
      "Training: Epoch 156, Batch 9, Loss: 0.082\n",
      "Training: Epoch 156, Batch 10, Loss: 0.081\n",
      "Training: Epoch 156, Batch 11, Loss: 0.091\n",
      "Training: Epoch 156, Batch 12, Loss: 0.076\n",
      "Training: Epoch 156, Batch 13, Loss: 0.127\n",
      "Training: Epoch 156, Batch 14, Loss: 0.08\n",
      "Training: Epoch 156, Batch 15, Loss: 0.108\n",
      "Training: Epoch 156, Batch 16, Loss: 0.097\n",
      "Training: Epoch 156, Batch 17, Loss: 0.096\n",
      "Training: Epoch 156, Batch 18, Loss: 0.128\n",
      "Training: Epoch 156, Batch 19, Loss: 0.073\n",
      "Training: Epoch 156, Batch 20, Loss: 0.105\n",
      "Training: Epoch 156, Batch 21, Loss: 0.071\n",
      "Training: Epoch 156, Batch 22, Loss: 0.108\n",
      "Training: Epoch 156, Batch 23, Loss: 0.059\n",
      "Training: Epoch 156, Batch 24, Loss: 0.106\n",
      "Training: Epoch 156, Batch 25, Loss: 0.078\n",
      "Training: Epoch 156, Batch 26, Loss: 0.119\n",
      "Training: Epoch 156, Batch 27, Loss: 0.116\n",
      "Training: Epoch 156, Batch 28, Loss: 0.101\n",
      "Training: Epoch 156, Batch 29, Loss: 0.082\n",
      "Training: Epoch 156, Batch 30, Loss: 0.092\n",
      "Training: Epoch 156, Batch 31, Loss: 0.145\n",
      "Training: Epoch 156, Batch 32, Loss: 0.084\n",
      "Training: Epoch 156, Batch 33, Loss: 0.076\n",
      "Training: Epoch 156, Batch 34, Loss: 0.103\n",
      "Training: Epoch 156, Batch 35, Loss: 0.071\n",
      "Training: Epoch 156, Batch 36, Loss: 0.126\n",
      "Training: Epoch 156, Batch 37, Loss: 0.09\n",
      "Training: Epoch 156, Batch 38, Loss: 0.088\n",
      "Training: Epoch 156, Batch 39, Loss: 0.09\n",
      "Training: Epoch 156, Batch 40, Loss: 0.078\n",
      "Training: Epoch 156, Batch 41, Loss: 0.076\n",
      "Training: Epoch 156, Batch 42, Loss: 0.078\n",
      "Training: Epoch 156, Batch 43, Loss: 0.094\n",
      "Training: Epoch 156, Batch 44, Loss: 0.072\n",
      "Training: Epoch 156, Batch 45, Loss: 0.111\n",
      "Training: Epoch 156, Batch 46, Loss: 0.106\n",
      "Training: Epoch 156, Batch 47, Loss: 0.101\n",
      "Training: Epoch 156, Batch 48, Loss: 0.121\n",
      "Training: Epoch 156, Batch 49, Loss: 0.121\n",
      "Training: Epoch 156, Batch 50, Loss: 0.108\n",
      "Training: Epoch 156, Batch 51, Loss: 0.14\n",
      "Training: Epoch 156, Batch 52, Loss: 0.095\n",
      "Training: Epoch 156, Batch 53, Loss: 0.098\n",
      "Training: Epoch 156, Batch 54, Loss: 0.077\n",
      "Training: Epoch 156, Batch 55, Loss: 0.155\n",
      "Training: Epoch 156, Batch 56, Loss: 0.094\n",
      "Training: Epoch 156, Batch 57, Loss: 0.096\n",
      "Training: Epoch 156, Batch 58, Loss: 0.089\n",
      "Training: Epoch 156, Batch 59, Loss: 0.097\n",
      "Training: Epoch 156, Batch 60, Loss: 0.112\n",
      "Training: Epoch 156, Batch 61, Loss: 0.098\n",
      "Training: Epoch 156, Batch 62, Loss: 0.104\n",
      "Training: Epoch 156, Batch 63, Loss: 0.098\n",
      "Training: Epoch 156, Batch 64, Loss: 0.093\n",
      "Training: Epoch 156, Batch 65, Loss: 0.084\n",
      "Training: Epoch 156, Batch 66, Loss: 0.094\n",
      "Training: Epoch 156, Batch 67, Loss: 0.076\n",
      "Training: Epoch 156, Batch 68, Loss: 0.063\n",
      "Training: Epoch 156, Batch 69, Loss: 0.105\n",
      "Training: Epoch 156, Batch 70, Loss: 0.077\n",
      "Training: Epoch 156, Batch 71, Loss: 0.173\n",
      "Training: Epoch 156, Batch 72, Loss: 0.104\n",
      "Training: Epoch 156, Batch 73, Loss: 0.076\n",
      "Training: Epoch 156, Batch 74, Loss: 0.11\n",
      "Training: Epoch 156, Batch 75, Loss: 0.107\n",
      "Training: Epoch 156, Batch 76, Loss: 0.108\n",
      "Training: Epoch 156, Batch 77, Loss: 0.124\n",
      "Training: Epoch 156, Batch 78, Loss: 0.112\n",
      "Training: Epoch 156, Batch 79, Loss: 0.068\n",
      "Training: Epoch 156, Batch 80, Loss: 0.106\n",
      "Training: Epoch 156, Batch 81, Loss: 0.103\n",
      "Training: Epoch 156, Batch 82, Loss: 0.114\n",
      "Training: Epoch 156, Batch 83, Loss: 0.072\n",
      "Training: Epoch 156, Batch 84, Loss: 0.088\n",
      "Training: Epoch 156, Batch 85, Loss: 0.108\n",
      "Training: Epoch 156, Batch 86, Loss: 0.116\n",
      "Training: Epoch 156, Batch 87, Loss: 0.143\n",
      "Training: Epoch 156, Batch 88, Loss: 0.085\n",
      "Training: Epoch 156, Batch 89, Loss: 0.11\n",
      "Val: Epoch 156, Loss: 0.319\n",
      "Training: Epoch 157, Batch 0, Loss: 0.121\n",
      "Training: Epoch 157, Batch 1, Loss: 0.093\n",
      "Training: Epoch 157, Batch 2, Loss: 0.11\n",
      "Training: Epoch 157, Batch 3, Loss: 0.088\n",
      "Training: Epoch 157, Batch 4, Loss: 0.096\n",
      "Training: Epoch 157, Batch 5, Loss: 0.142\n",
      "Training: Epoch 157, Batch 6, Loss: 0.109\n",
      "Training: Epoch 157, Batch 7, Loss: 0.105\n",
      "Training: Epoch 157, Batch 8, Loss: 0.131\n",
      "Training: Epoch 157, Batch 9, Loss: 0.147\n",
      "Training: Epoch 157, Batch 10, Loss: 0.103\n",
      "Training: Epoch 157, Batch 11, Loss: 0.101\n",
      "Training: Epoch 157, Batch 12, Loss: 0.092\n",
      "Training: Epoch 157, Batch 13, Loss: 0.093\n",
      "Training: Epoch 157, Batch 14, Loss: 0.109\n",
      "Training: Epoch 157, Batch 15, Loss: 0.111\n",
      "Training: Epoch 157, Batch 16, Loss: 0.09\n",
      "Training: Epoch 157, Batch 17, Loss: 0.103\n",
      "Training: Epoch 157, Batch 18, Loss: 0.115\n",
      "Training: Epoch 157, Batch 19, Loss: 0.089\n",
      "Training: Epoch 157, Batch 20, Loss: 0.091\n",
      "Training: Epoch 157, Batch 21, Loss: 0.09\n",
      "Training: Epoch 157, Batch 22, Loss: 0.082\n",
      "Training: Epoch 157, Batch 23, Loss: 0.081\n",
      "Training: Epoch 157, Batch 24, Loss: 0.076\n",
      "Training: Epoch 157, Batch 25, Loss: 0.071\n",
      "Training: Epoch 157, Batch 26, Loss: 0.088\n",
      "Training: Epoch 157, Batch 27, Loss: 0.117\n",
      "Training: Epoch 157, Batch 28, Loss: 0.071\n",
      "Training: Epoch 157, Batch 29, Loss: 0.1\n",
      "Training: Epoch 157, Batch 30, Loss: 0.119\n",
      "Training: Epoch 157, Batch 31, Loss: 0.084\n",
      "Training: Epoch 157, Batch 32, Loss: 0.105\n",
      "Training: Epoch 157, Batch 33, Loss: 0.095\n",
      "Training: Epoch 157, Batch 34, Loss: 0.093\n",
      "Training: Epoch 157, Batch 35, Loss: 0.068\n",
      "Training: Epoch 157, Batch 36, Loss: 0.111\n",
      "Training: Epoch 157, Batch 37, Loss: 0.097\n",
      "Training: Epoch 157, Batch 38, Loss: 0.099\n",
      "Training: Epoch 157, Batch 39, Loss: 0.089\n",
      "Training: Epoch 157, Batch 40, Loss: 0.09\n",
      "Training: Epoch 157, Batch 41, Loss: 0.128\n",
      "Training: Epoch 157, Batch 42, Loss: 0.091\n",
      "Training: Epoch 157, Batch 43, Loss: 0.104\n",
      "Training: Epoch 157, Batch 44, Loss: 0.078\n",
      "Training: Epoch 157, Batch 45, Loss: 0.117\n",
      "Training: Epoch 157, Batch 46, Loss: 0.088\n",
      "Training: Epoch 157, Batch 47, Loss: 0.094\n",
      "Training: Epoch 157, Batch 48, Loss: 0.1\n",
      "Training: Epoch 157, Batch 49, Loss: 0.095\n",
      "Training: Epoch 157, Batch 50, Loss: 0.115\n",
      "Training: Epoch 157, Batch 51, Loss: 0.079\n",
      "Training: Epoch 157, Batch 52, Loss: 0.077\n",
      "Training: Epoch 157, Batch 53, Loss: 0.08\n",
      "Training: Epoch 157, Batch 54, Loss: 0.114\n",
      "Training: Epoch 157, Batch 55, Loss: 0.106\n",
      "Training: Epoch 157, Batch 56, Loss: 0.08\n",
      "Training: Epoch 157, Batch 57, Loss: 0.092\n",
      "Training: Epoch 157, Batch 58, Loss: 0.097\n",
      "Training: Epoch 157, Batch 59, Loss: 0.095\n",
      "Training: Epoch 157, Batch 60, Loss: 0.073\n",
      "Training: Epoch 157, Batch 61, Loss: 0.086\n",
      "Training: Epoch 157, Batch 62, Loss: 0.085\n",
      "Training: Epoch 157, Batch 63, Loss: 0.105\n",
      "Training: Epoch 157, Batch 64, Loss: 0.076\n",
      "Training: Epoch 157, Batch 65, Loss: 0.073\n",
      "Training: Epoch 157, Batch 66, Loss: 0.093\n",
      "Training: Epoch 157, Batch 67, Loss: 0.117\n",
      "Training: Epoch 157, Batch 68, Loss: 0.094\n",
      "Training: Epoch 157, Batch 69, Loss: 0.085\n",
      "Training: Epoch 157, Batch 70, Loss: 0.113\n",
      "Training: Epoch 157, Batch 71, Loss: 0.066\n",
      "Training: Epoch 157, Batch 72, Loss: 0.126\n",
      "Training: Epoch 157, Batch 73, Loss: 0.06\n",
      "Training: Epoch 157, Batch 74, Loss: 0.126\n",
      "Training: Epoch 157, Batch 75, Loss: 0.127\n",
      "Training: Epoch 157, Batch 76, Loss: 0.099\n",
      "Training: Epoch 157, Batch 77, Loss: 0.081\n",
      "Training: Epoch 157, Batch 78, Loss: 0.089\n",
      "Training: Epoch 157, Batch 79, Loss: 0.082\n",
      "Training: Epoch 157, Batch 80, Loss: 0.093\n",
      "Training: Epoch 157, Batch 81, Loss: 0.073\n",
      "Training: Epoch 157, Batch 82, Loss: 0.111\n",
      "Training: Epoch 157, Batch 83, Loss: 0.104\n",
      "Training: Epoch 157, Batch 84, Loss: 0.099\n",
      "Training: Epoch 157, Batch 85, Loss: 0.101\n",
      "Training: Epoch 157, Batch 86, Loss: 0.108\n",
      "Training: Epoch 157, Batch 87, Loss: 0.119\n",
      "Training: Epoch 157, Batch 88, Loss: 0.117\n",
      "Training: Epoch 157, Batch 89, Loss: 0.132\n",
      "Val: Epoch 157, Loss: 0.309\n",
      "Training: Epoch 158, Batch 0, Loss: 0.104\n",
      "Training: Epoch 158, Batch 1, Loss: 0.106\n",
      "Training: Epoch 158, Batch 2, Loss: 0.099\n",
      "Training: Epoch 158, Batch 3, Loss: 0.119\n",
      "Training: Epoch 158, Batch 4, Loss: 0.094\n",
      "Training: Epoch 158, Batch 5, Loss: 0.079\n",
      "Training: Epoch 158, Batch 6, Loss: 0.097\n",
      "Training: Epoch 158, Batch 7, Loss: 0.12\n",
      "Training: Epoch 158, Batch 8, Loss: 0.125\n",
      "Training: Epoch 158, Batch 9, Loss: 0.083\n",
      "Training: Epoch 158, Batch 10, Loss: 0.116\n",
      "Training: Epoch 158, Batch 11, Loss: 0.118\n",
      "Training: Epoch 158, Batch 12, Loss: 0.104\n",
      "Training: Epoch 158, Batch 13, Loss: 0.08\n",
      "Training: Epoch 158, Batch 14, Loss: 0.091\n",
      "Training: Epoch 158, Batch 15, Loss: 0.07\n",
      "Training: Epoch 158, Batch 16, Loss: 0.09\n",
      "Training: Epoch 158, Batch 17, Loss: 0.107\n",
      "Training: Epoch 158, Batch 18, Loss: 0.113\n",
      "Training: Epoch 158, Batch 19, Loss: 0.07\n",
      "Training: Epoch 158, Batch 20, Loss: 0.077\n",
      "Training: Epoch 158, Batch 21, Loss: 0.099\n",
      "Training: Epoch 158, Batch 22, Loss: 0.13\n",
      "Training: Epoch 158, Batch 23, Loss: 0.091\n",
      "Training: Epoch 158, Batch 24, Loss: 0.109\n",
      "Training: Epoch 158, Batch 25, Loss: 0.089\n",
      "Training: Epoch 158, Batch 26, Loss: 0.085\n",
      "Training: Epoch 158, Batch 27, Loss: 0.089\n",
      "Training: Epoch 158, Batch 28, Loss: 0.126\n",
      "Training: Epoch 158, Batch 29, Loss: 0.114\n",
      "Training: Epoch 158, Batch 30, Loss: 0.096\n",
      "Training: Epoch 158, Batch 31, Loss: 0.086\n",
      "Training: Epoch 158, Batch 32, Loss: 0.091\n",
      "Training: Epoch 158, Batch 33, Loss: 0.092\n",
      "Training: Epoch 158, Batch 34, Loss: 0.134\n",
      "Training: Epoch 158, Batch 35, Loss: 0.093\n",
      "Training: Epoch 158, Batch 36, Loss: 0.079\n",
      "Training: Epoch 158, Batch 37, Loss: 0.086\n",
      "Training: Epoch 158, Batch 38, Loss: 0.079\n",
      "Training: Epoch 158, Batch 39, Loss: 0.069\n",
      "Training: Epoch 158, Batch 40, Loss: 0.055\n",
      "Training: Epoch 158, Batch 41, Loss: 0.09\n",
      "Training: Epoch 158, Batch 42, Loss: 0.089\n",
      "Training: Epoch 158, Batch 43, Loss: 0.12\n",
      "Training: Epoch 158, Batch 44, Loss: 0.074\n",
      "Training: Epoch 158, Batch 45, Loss: 0.088\n",
      "Training: Epoch 158, Batch 46, Loss: 0.111\n",
      "Training: Epoch 158, Batch 47, Loss: 0.119\n",
      "Training: Epoch 158, Batch 48, Loss: 0.077\n",
      "Training: Epoch 158, Batch 49, Loss: 0.098\n",
      "Training: Epoch 158, Batch 50, Loss: 0.087\n",
      "Training: Epoch 158, Batch 51, Loss: 0.103\n",
      "Training: Epoch 158, Batch 52, Loss: 0.097\n",
      "Training: Epoch 158, Batch 53, Loss: 0.099\n",
      "Training: Epoch 158, Batch 54, Loss: 0.086\n",
      "Training: Epoch 158, Batch 55, Loss: 0.084\n",
      "Training: Epoch 158, Batch 56, Loss: 0.087\n",
      "Training: Epoch 158, Batch 57, Loss: 0.086\n",
      "Training: Epoch 158, Batch 58, Loss: 0.09\n",
      "Training: Epoch 158, Batch 59, Loss: 0.093\n",
      "Training: Epoch 158, Batch 60, Loss: 0.088\n",
      "Training: Epoch 158, Batch 61, Loss: 0.098\n",
      "Training: Epoch 158, Batch 62, Loss: 0.07\n",
      "Training: Epoch 158, Batch 63, Loss: 0.077\n",
      "Training: Epoch 158, Batch 64, Loss: 0.087\n",
      "Training: Epoch 158, Batch 65, Loss: 0.115\n",
      "Training: Epoch 158, Batch 66, Loss: 0.103\n",
      "Training: Epoch 158, Batch 67, Loss: 0.106\n",
      "Training: Epoch 158, Batch 68, Loss: 0.087\n",
      "Training: Epoch 158, Batch 69, Loss: 0.108\n",
      "Training: Epoch 158, Batch 70, Loss: 0.095\n",
      "Training: Epoch 158, Batch 71, Loss: 0.11\n",
      "Training: Epoch 158, Batch 72, Loss: 0.103\n",
      "Training: Epoch 158, Batch 73, Loss: 0.085\n",
      "Training: Epoch 158, Batch 74, Loss: 0.103\n",
      "Training: Epoch 158, Batch 75, Loss: 0.094\n",
      "Training: Epoch 158, Batch 76, Loss: 0.086\n",
      "Training: Epoch 158, Batch 77, Loss: 0.08\n",
      "Training: Epoch 158, Batch 78, Loss: 0.104\n",
      "Training: Epoch 158, Batch 79, Loss: 0.072\n",
      "Training: Epoch 158, Batch 80, Loss: 0.094\n",
      "Training: Epoch 158, Batch 81, Loss: 0.091\n",
      "Training: Epoch 158, Batch 82, Loss: 0.084\n",
      "Training: Epoch 158, Batch 83, Loss: 0.095\n",
      "Training: Epoch 158, Batch 84, Loss: 0.128\n",
      "Training: Epoch 158, Batch 85, Loss: 0.095\n",
      "Training: Epoch 158, Batch 86, Loss: 0.088\n",
      "Training: Epoch 158, Batch 87, Loss: 0.088\n",
      "Training: Epoch 158, Batch 88, Loss: 0.087\n",
      "Training: Epoch 158, Batch 89, Loss: 0.079\n",
      "Val: Epoch 158, Loss: 0.322\n",
      "Training: Epoch 159, Batch 0, Loss: 0.088\n",
      "Training: Epoch 159, Batch 1, Loss: 0.11\n",
      "Training: Epoch 159, Batch 2, Loss: 0.06\n",
      "Training: Epoch 159, Batch 3, Loss: 0.08\n",
      "Training: Epoch 159, Batch 4, Loss: 0.102\n",
      "Training: Epoch 159, Batch 5, Loss: 0.101\n",
      "Training: Epoch 159, Batch 6, Loss: 0.102\n",
      "Training: Epoch 159, Batch 7, Loss: 0.093\n",
      "Training: Epoch 159, Batch 8, Loss: 0.097\n",
      "Training: Epoch 159, Batch 9, Loss: 0.088\n",
      "Training: Epoch 159, Batch 10, Loss: 0.088\n",
      "Training: Epoch 159, Batch 11, Loss: 0.101\n",
      "Training: Epoch 159, Batch 12, Loss: 0.118\n",
      "Training: Epoch 159, Batch 13, Loss: 0.097\n",
      "Training: Epoch 159, Batch 14, Loss: 0.083\n",
      "Training: Epoch 159, Batch 15, Loss: 0.102\n",
      "Training: Epoch 159, Batch 16, Loss: 0.093\n",
      "Training: Epoch 159, Batch 17, Loss: 0.085\n",
      "Training: Epoch 159, Batch 18, Loss: 0.089\n",
      "Training: Epoch 159, Batch 19, Loss: 0.11\n",
      "Training: Epoch 159, Batch 20, Loss: 0.068\n",
      "Training: Epoch 159, Batch 21, Loss: 0.085\n",
      "Training: Epoch 159, Batch 22, Loss: 0.088\n",
      "Training: Epoch 159, Batch 23, Loss: 0.096\n",
      "Training: Epoch 159, Batch 24, Loss: 0.071\n",
      "Training: Epoch 159, Batch 25, Loss: 0.091\n",
      "Training: Epoch 159, Batch 26, Loss: 0.119\n",
      "Training: Epoch 159, Batch 27, Loss: 0.102\n",
      "Training: Epoch 159, Batch 28, Loss: 0.079\n",
      "Training: Epoch 159, Batch 29, Loss: 0.081\n",
      "Training: Epoch 159, Batch 30, Loss: 0.088\n",
      "Training: Epoch 159, Batch 31, Loss: 0.077\n",
      "Training: Epoch 159, Batch 32, Loss: 0.093\n",
      "Training: Epoch 159, Batch 33, Loss: 0.074\n",
      "Training: Epoch 159, Batch 34, Loss: 0.073\n",
      "Training: Epoch 159, Batch 35, Loss: 0.095\n",
      "Training: Epoch 159, Batch 36, Loss: 0.066\n",
      "Training: Epoch 159, Batch 37, Loss: 0.083\n",
      "Training: Epoch 159, Batch 38, Loss: 0.103\n",
      "Training: Epoch 159, Batch 39, Loss: 0.097\n",
      "Training: Epoch 159, Batch 40, Loss: 0.099\n",
      "Training: Epoch 159, Batch 41, Loss: 0.105\n",
      "Training: Epoch 159, Batch 42, Loss: 0.115\n",
      "Training: Epoch 159, Batch 43, Loss: 0.095\n",
      "Training: Epoch 159, Batch 44, Loss: 0.084\n",
      "Training: Epoch 159, Batch 45, Loss: 0.09\n",
      "Training: Epoch 159, Batch 46, Loss: 0.117\n",
      "Training: Epoch 159, Batch 47, Loss: 0.078\n",
      "Training: Epoch 159, Batch 48, Loss: 0.082\n",
      "Training: Epoch 159, Batch 49, Loss: 0.109\n",
      "Training: Epoch 159, Batch 50, Loss: 0.076\n",
      "Training: Epoch 159, Batch 51, Loss: 0.116\n",
      "Training: Epoch 159, Batch 52, Loss: 0.129\n",
      "Training: Epoch 159, Batch 53, Loss: 0.14\n",
      "Training: Epoch 159, Batch 54, Loss: 0.077\n",
      "Training: Epoch 159, Batch 55, Loss: 0.079\n",
      "Training: Epoch 159, Batch 56, Loss: 0.16\n",
      "Training: Epoch 159, Batch 57, Loss: 0.108\n",
      "Training: Epoch 159, Batch 58, Loss: 0.092\n",
      "Training: Epoch 159, Batch 59, Loss: 0.123\n",
      "Training: Epoch 159, Batch 60, Loss: 0.076\n",
      "Training: Epoch 159, Batch 61, Loss: 0.07\n",
      "Training: Epoch 159, Batch 62, Loss: 0.117\n",
      "Training: Epoch 159, Batch 63, Loss: 0.093\n",
      "Training: Epoch 159, Batch 64, Loss: 0.067\n",
      "Training: Epoch 159, Batch 65, Loss: 0.096\n",
      "Training: Epoch 159, Batch 66, Loss: 0.105\n",
      "Training: Epoch 159, Batch 67, Loss: 0.084\n",
      "Training: Epoch 159, Batch 68, Loss: 0.116\n",
      "Training: Epoch 159, Batch 69, Loss: 0.068\n",
      "Training: Epoch 159, Batch 70, Loss: 0.081\n",
      "Training: Epoch 159, Batch 71, Loss: 0.084\n",
      "Training: Epoch 159, Batch 72, Loss: 0.09\n",
      "Training: Epoch 159, Batch 73, Loss: 0.082\n",
      "Training: Epoch 159, Batch 74, Loss: 0.091\n",
      "Training: Epoch 159, Batch 75, Loss: 0.092\n",
      "Training: Epoch 159, Batch 76, Loss: 0.102\n",
      "Training: Epoch 159, Batch 77, Loss: 0.112\n",
      "Training: Epoch 159, Batch 78, Loss: 0.078\n",
      "Training: Epoch 159, Batch 79, Loss: 0.064\n",
      "Training: Epoch 159, Batch 80, Loss: 0.077\n",
      "Training: Epoch 159, Batch 81, Loss: 0.105\n",
      "Training: Epoch 159, Batch 82, Loss: 0.105\n",
      "Training: Epoch 159, Batch 83, Loss: 0.089\n",
      "Training: Epoch 159, Batch 84, Loss: 0.085\n",
      "Training: Epoch 159, Batch 85, Loss: 0.109\n",
      "Training: Epoch 159, Batch 86, Loss: 0.078\n",
      "Training: Epoch 159, Batch 87, Loss: 0.084\n",
      "Training: Epoch 159, Batch 88, Loss: 0.11\n",
      "Training: Epoch 159, Batch 89, Loss: 0.089\n",
      "Val: Epoch 159, Loss: 0.307\n",
      "Training: Epoch 160, Batch 0, Loss: 0.077\n",
      "Training: Epoch 160, Batch 1, Loss: 0.072\n",
      "Training: Epoch 160, Batch 2, Loss: 0.076\n",
      "Training: Epoch 160, Batch 3, Loss: 0.089\n",
      "Training: Epoch 160, Batch 4, Loss: 0.095\n",
      "Training: Epoch 160, Batch 5, Loss: 0.103\n",
      "Training: Epoch 160, Batch 6, Loss: 0.076\n",
      "Training: Epoch 160, Batch 7, Loss: 0.087\n",
      "Training: Epoch 160, Batch 8, Loss: 0.086\n",
      "Training: Epoch 160, Batch 9, Loss: 0.083\n",
      "Training: Epoch 160, Batch 10, Loss: 0.074\n",
      "Training: Epoch 160, Batch 11, Loss: 0.081\n",
      "Training: Epoch 160, Batch 12, Loss: 0.077\n",
      "Training: Epoch 160, Batch 13, Loss: 0.07\n",
      "Training: Epoch 160, Batch 14, Loss: 0.097\n",
      "Training: Epoch 160, Batch 15, Loss: 0.097\n",
      "Training: Epoch 160, Batch 16, Loss: 0.074\n",
      "Training: Epoch 160, Batch 17, Loss: 0.081\n",
      "Training: Epoch 160, Batch 18, Loss: 0.106\n",
      "Training: Epoch 160, Batch 19, Loss: 0.097\n",
      "Training: Epoch 160, Batch 20, Loss: 0.104\n",
      "Training: Epoch 160, Batch 21, Loss: 0.078\n",
      "Training: Epoch 160, Batch 22, Loss: 0.098\n",
      "Training: Epoch 160, Batch 23, Loss: 0.109\n",
      "Training: Epoch 160, Batch 24, Loss: 0.099\n",
      "Training: Epoch 160, Batch 25, Loss: 0.089\n",
      "Training: Epoch 160, Batch 26, Loss: 0.09\n",
      "Training: Epoch 160, Batch 27, Loss: 0.093\n",
      "Training: Epoch 160, Batch 28, Loss: 0.164\n",
      "Training: Epoch 160, Batch 29, Loss: 0.107\n",
      "Training: Epoch 160, Batch 30, Loss: 0.083\n",
      "Training: Epoch 160, Batch 31, Loss: 0.147\n",
      "Training: Epoch 160, Batch 32, Loss: 0.114\n",
      "Training: Epoch 160, Batch 33, Loss: 0.089\n",
      "Training: Epoch 160, Batch 34, Loss: 0.081\n",
      "Training: Epoch 160, Batch 35, Loss: 0.075\n",
      "Training: Epoch 160, Batch 36, Loss: 0.075\n",
      "Training: Epoch 160, Batch 37, Loss: 0.125\n",
      "Training: Epoch 160, Batch 38, Loss: 0.106\n",
      "Training: Epoch 160, Batch 39, Loss: 0.11\n",
      "Training: Epoch 160, Batch 40, Loss: 0.114\n",
      "Training: Epoch 160, Batch 41, Loss: 0.072\n",
      "Training: Epoch 160, Batch 42, Loss: 0.076\n",
      "Training: Epoch 160, Batch 43, Loss: 0.085\n",
      "Training: Epoch 160, Batch 44, Loss: 0.109\n",
      "Training: Epoch 160, Batch 45, Loss: 0.091\n",
      "Training: Epoch 160, Batch 46, Loss: 0.088\n",
      "Training: Epoch 160, Batch 47, Loss: 0.109\n",
      "Training: Epoch 160, Batch 48, Loss: 0.074\n",
      "Training: Epoch 160, Batch 49, Loss: 0.089\n",
      "Training: Epoch 160, Batch 50, Loss: 0.083\n",
      "Training: Epoch 160, Batch 51, Loss: 0.136\n",
      "Training: Epoch 160, Batch 52, Loss: 0.115\n",
      "Training: Epoch 160, Batch 53, Loss: 0.071\n",
      "Training: Epoch 160, Batch 54, Loss: 0.113\n",
      "Training: Epoch 160, Batch 55, Loss: 0.104\n",
      "Training: Epoch 160, Batch 56, Loss: 0.125\n",
      "Training: Epoch 160, Batch 57, Loss: 0.109\n",
      "Training: Epoch 160, Batch 58, Loss: 0.078\n",
      "Training: Epoch 160, Batch 59, Loss: 0.105\n",
      "Training: Epoch 160, Batch 60, Loss: 0.11\n",
      "Training: Epoch 160, Batch 61, Loss: 0.1\n",
      "Training: Epoch 160, Batch 62, Loss: 0.069\n",
      "Training: Epoch 160, Batch 63, Loss: 0.081\n",
      "Training: Epoch 160, Batch 64, Loss: 0.11\n",
      "Training: Epoch 160, Batch 65, Loss: 0.095\n",
      "Training: Epoch 160, Batch 66, Loss: 0.099\n",
      "Training: Epoch 160, Batch 67, Loss: 0.064\n",
      "Training: Epoch 160, Batch 68, Loss: 0.106\n",
      "Training: Epoch 160, Batch 69, Loss: 0.086\n",
      "Training: Epoch 160, Batch 70, Loss: 0.117\n",
      "Training: Epoch 160, Batch 71, Loss: 0.083\n",
      "Training: Epoch 160, Batch 72, Loss: 0.126\n",
      "Training: Epoch 160, Batch 73, Loss: 0.096\n",
      "Training: Epoch 160, Batch 74, Loss: 0.078\n",
      "Training: Epoch 160, Batch 75, Loss: 0.086\n",
      "Training: Epoch 160, Batch 76, Loss: 0.09\n",
      "Training: Epoch 160, Batch 77, Loss: 0.088\n",
      "Training: Epoch 160, Batch 78, Loss: 0.108\n",
      "Training: Epoch 160, Batch 79, Loss: 0.081\n",
      "Training: Epoch 160, Batch 80, Loss: 0.081\n",
      "Training: Epoch 160, Batch 81, Loss: 0.08\n",
      "Training: Epoch 160, Batch 82, Loss: 0.095\n",
      "Training: Epoch 160, Batch 83, Loss: 0.085\n",
      "Training: Epoch 160, Batch 84, Loss: 0.134\n",
      "Training: Epoch 160, Batch 85, Loss: 0.084\n",
      "Training: Epoch 160, Batch 86, Loss: 0.07\n",
      "Training: Epoch 160, Batch 87, Loss: 0.073\n",
      "Training: Epoch 160, Batch 88, Loss: 0.1\n",
      "Training: Epoch 160, Batch 89, Loss: 0.083\n",
      "Val: Epoch 160, Loss: 0.329\n",
      "Training: Epoch 161, Batch 0, Loss: 0.075\n",
      "Training: Epoch 161, Batch 1, Loss: 0.099\n",
      "Training: Epoch 161, Batch 2, Loss: 0.089\n",
      "Training: Epoch 161, Batch 3, Loss: 0.124\n",
      "Training: Epoch 161, Batch 4, Loss: 0.078\n",
      "Training: Epoch 161, Batch 5, Loss: 0.113\n",
      "Training: Epoch 161, Batch 6, Loss: 0.069\n",
      "Training: Epoch 161, Batch 7, Loss: 0.079\n",
      "Training: Epoch 161, Batch 8, Loss: 0.07\n",
      "Training: Epoch 161, Batch 9, Loss: 0.066\n",
      "Training: Epoch 161, Batch 10, Loss: 0.102\n",
      "Training: Epoch 161, Batch 11, Loss: 0.08\n",
      "Training: Epoch 161, Batch 12, Loss: 0.067\n",
      "Training: Epoch 161, Batch 13, Loss: 0.074\n",
      "Training: Epoch 161, Batch 14, Loss: 0.065\n",
      "Training: Epoch 161, Batch 15, Loss: 0.082\n",
      "Training: Epoch 161, Batch 16, Loss: 0.14\n",
      "Training: Epoch 161, Batch 17, Loss: 0.112\n",
      "Training: Epoch 161, Batch 18, Loss: 0.085\n",
      "Training: Epoch 161, Batch 19, Loss: 0.072\n",
      "Training: Epoch 161, Batch 20, Loss: 0.093\n",
      "Training: Epoch 161, Batch 21, Loss: 0.103\n",
      "Training: Epoch 161, Batch 22, Loss: 0.079\n",
      "Training: Epoch 161, Batch 23, Loss: 0.1\n",
      "Training: Epoch 161, Batch 24, Loss: 0.095\n",
      "Training: Epoch 161, Batch 25, Loss: 0.096\n",
      "Training: Epoch 161, Batch 26, Loss: 0.059\n",
      "Training: Epoch 161, Batch 27, Loss: 0.098\n",
      "Training: Epoch 161, Batch 28, Loss: 0.082\n",
      "Training: Epoch 161, Batch 29, Loss: 0.117\n",
      "Training: Epoch 161, Batch 30, Loss: 0.092\n",
      "Training: Epoch 161, Batch 31, Loss: 0.1\n",
      "Training: Epoch 161, Batch 32, Loss: 0.106\n",
      "Training: Epoch 161, Batch 33, Loss: 0.093\n",
      "Training: Epoch 161, Batch 34, Loss: 0.096\n",
      "Training: Epoch 161, Batch 35, Loss: 0.097\n",
      "Training: Epoch 161, Batch 36, Loss: 0.095\n",
      "Training: Epoch 161, Batch 37, Loss: 0.094\n",
      "Training: Epoch 161, Batch 38, Loss: 0.094\n",
      "Training: Epoch 161, Batch 39, Loss: 0.096\n",
      "Training: Epoch 161, Batch 40, Loss: 0.086\n",
      "Training: Epoch 161, Batch 41, Loss: 0.103\n",
      "Training: Epoch 161, Batch 42, Loss: 0.099\n",
      "Training: Epoch 161, Batch 43, Loss: 0.081\n",
      "Training: Epoch 161, Batch 44, Loss: 0.117\n",
      "Training: Epoch 161, Batch 45, Loss: 0.084\n",
      "Training: Epoch 161, Batch 46, Loss: 0.113\n",
      "Training: Epoch 161, Batch 47, Loss: 0.091\n",
      "Training: Epoch 161, Batch 48, Loss: 0.096\n",
      "Training: Epoch 161, Batch 49, Loss: 0.063\n",
      "Training: Epoch 161, Batch 50, Loss: 0.109\n",
      "Training: Epoch 161, Batch 51, Loss: 0.086\n",
      "Training: Epoch 161, Batch 52, Loss: 0.088\n",
      "Training: Epoch 161, Batch 53, Loss: 0.099\n",
      "Training: Epoch 161, Batch 54, Loss: 0.089\n",
      "Training: Epoch 161, Batch 55, Loss: 0.075\n",
      "Training: Epoch 161, Batch 56, Loss: 0.109\n",
      "Training: Epoch 161, Batch 57, Loss: 0.104\n",
      "Training: Epoch 161, Batch 58, Loss: 0.105\n",
      "Training: Epoch 161, Batch 59, Loss: 0.094\n",
      "Training: Epoch 161, Batch 60, Loss: 0.111\n",
      "Training: Epoch 161, Batch 61, Loss: 0.119\n",
      "Training: Epoch 161, Batch 62, Loss: 0.076\n",
      "Training: Epoch 161, Batch 63, Loss: 0.091\n",
      "Training: Epoch 161, Batch 64, Loss: 0.086\n",
      "Training: Epoch 161, Batch 65, Loss: 0.078\n",
      "Training: Epoch 161, Batch 66, Loss: 0.108\n",
      "Training: Epoch 161, Batch 67, Loss: 0.118\n",
      "Training: Epoch 161, Batch 68, Loss: 0.087\n",
      "Training: Epoch 161, Batch 69, Loss: 0.075\n",
      "Training: Epoch 161, Batch 70, Loss: 0.078\n",
      "Training: Epoch 161, Batch 71, Loss: 0.087\n",
      "Training: Epoch 161, Batch 72, Loss: 0.076\n",
      "Training: Epoch 161, Batch 73, Loss: 0.081\n",
      "Training: Epoch 161, Batch 74, Loss: 0.119\n",
      "Training: Epoch 161, Batch 75, Loss: 0.086\n",
      "Training: Epoch 161, Batch 76, Loss: 0.09\n",
      "Training: Epoch 161, Batch 77, Loss: 0.079\n",
      "Training: Epoch 161, Batch 78, Loss: 0.091\n",
      "Training: Epoch 161, Batch 79, Loss: 0.087\n",
      "Training: Epoch 161, Batch 80, Loss: 0.113\n",
      "Training: Epoch 161, Batch 81, Loss: 0.08\n",
      "Training: Epoch 161, Batch 82, Loss: 0.097\n",
      "Training: Epoch 161, Batch 83, Loss: 0.091\n",
      "Training: Epoch 161, Batch 84, Loss: 0.105\n",
      "Training: Epoch 161, Batch 85, Loss: 0.111\n",
      "Training: Epoch 161, Batch 86, Loss: 0.092\n",
      "Training: Epoch 161, Batch 87, Loss: 0.086\n",
      "Training: Epoch 161, Batch 88, Loss: 0.09\n",
      "Training: Epoch 161, Batch 89, Loss: 0.104\n",
      "Val: Epoch 161, Loss: 0.314\n",
      "Training: Epoch 162, Batch 0, Loss: 0.083\n",
      "Training: Epoch 162, Batch 1, Loss: 0.114\n",
      "Training: Epoch 162, Batch 2, Loss: 0.074\n",
      "Training: Epoch 162, Batch 3, Loss: 0.088\n",
      "Training: Epoch 162, Batch 4, Loss: 0.093\n",
      "Training: Epoch 162, Batch 5, Loss: 0.077\n",
      "Training: Epoch 162, Batch 6, Loss: 0.081\n",
      "Training: Epoch 162, Batch 7, Loss: 0.12\n",
      "Training: Epoch 162, Batch 8, Loss: 0.078\n",
      "Training: Epoch 162, Batch 9, Loss: 0.072\n",
      "Training: Epoch 162, Batch 10, Loss: 0.12\n",
      "Training: Epoch 162, Batch 11, Loss: 0.089\n",
      "Training: Epoch 162, Batch 12, Loss: 0.085\n",
      "Training: Epoch 162, Batch 13, Loss: 0.072\n",
      "Training: Epoch 162, Batch 14, Loss: 0.073\n",
      "Training: Epoch 162, Batch 15, Loss: 0.091\n",
      "Training: Epoch 162, Batch 16, Loss: 0.075\n",
      "Training: Epoch 162, Batch 17, Loss: 0.098\n",
      "Training: Epoch 162, Batch 18, Loss: 0.113\n",
      "Training: Epoch 162, Batch 19, Loss: 0.093\n",
      "Training: Epoch 162, Batch 20, Loss: 0.112\n",
      "Training: Epoch 162, Batch 21, Loss: 0.091\n",
      "Training: Epoch 162, Batch 22, Loss: 0.114\n",
      "Training: Epoch 162, Batch 23, Loss: 0.078\n",
      "Training: Epoch 162, Batch 24, Loss: 0.103\n",
      "Training: Epoch 162, Batch 25, Loss: 0.083\n",
      "Training: Epoch 162, Batch 26, Loss: 0.121\n",
      "Training: Epoch 162, Batch 27, Loss: 0.097\n",
      "Training: Epoch 162, Batch 28, Loss: 0.128\n",
      "Training: Epoch 162, Batch 29, Loss: 0.061\n",
      "Training: Epoch 162, Batch 30, Loss: 0.126\n",
      "Training: Epoch 162, Batch 31, Loss: 0.092\n",
      "Training: Epoch 162, Batch 32, Loss: 0.101\n",
      "Training: Epoch 162, Batch 33, Loss: 0.085\n",
      "Training: Epoch 162, Batch 34, Loss: 0.109\n",
      "Training: Epoch 162, Batch 35, Loss: 0.095\n",
      "Training: Epoch 162, Batch 36, Loss: 0.146\n",
      "Training: Epoch 162, Batch 37, Loss: 0.093\n",
      "Training: Epoch 162, Batch 38, Loss: 0.09\n",
      "Training: Epoch 162, Batch 39, Loss: 0.104\n",
      "Training: Epoch 162, Batch 40, Loss: 0.087\n",
      "Training: Epoch 162, Batch 41, Loss: 0.072\n",
      "Training: Epoch 162, Batch 42, Loss: 0.094\n",
      "Training: Epoch 162, Batch 43, Loss: 0.074\n",
      "Training: Epoch 162, Batch 44, Loss: 0.122\n",
      "Training: Epoch 162, Batch 45, Loss: 0.09\n",
      "Training: Epoch 162, Batch 46, Loss: 0.103\n",
      "Training: Epoch 162, Batch 47, Loss: 0.113\n",
      "Training: Epoch 162, Batch 48, Loss: 0.099\n",
      "Training: Epoch 162, Batch 49, Loss: 0.098\n",
      "Training: Epoch 162, Batch 50, Loss: 0.086\n",
      "Training: Epoch 162, Batch 51, Loss: 0.095\n",
      "Training: Epoch 162, Batch 52, Loss: 0.114\n",
      "Training: Epoch 162, Batch 53, Loss: 0.107\n",
      "Training: Epoch 162, Batch 54, Loss: 0.079\n",
      "Training: Epoch 162, Batch 55, Loss: 0.075\n",
      "Training: Epoch 162, Batch 56, Loss: 0.097\n",
      "Training: Epoch 162, Batch 57, Loss: 0.076\n",
      "Training: Epoch 162, Batch 58, Loss: 0.111\n",
      "Training: Epoch 162, Batch 59, Loss: 0.117\n",
      "Training: Epoch 162, Batch 60, Loss: 0.103\n",
      "Training: Epoch 162, Batch 61, Loss: 0.104\n",
      "Training: Epoch 162, Batch 62, Loss: 0.081\n",
      "Training: Epoch 162, Batch 63, Loss: 0.09\n",
      "Training: Epoch 162, Batch 64, Loss: 0.11\n",
      "Training: Epoch 162, Batch 65, Loss: 0.095\n",
      "Training: Epoch 162, Batch 66, Loss: 0.082\n",
      "Training: Epoch 162, Batch 67, Loss: 0.097\n",
      "Training: Epoch 162, Batch 68, Loss: 0.079\n",
      "Training: Epoch 162, Batch 69, Loss: 0.118\n",
      "Training: Epoch 162, Batch 70, Loss: 0.077\n",
      "Training: Epoch 162, Batch 71, Loss: 0.077\n",
      "Training: Epoch 162, Batch 72, Loss: 0.087\n",
      "Training: Epoch 162, Batch 73, Loss: 0.083\n",
      "Training: Epoch 162, Batch 74, Loss: 0.121\n",
      "Training: Epoch 162, Batch 75, Loss: 0.084\n",
      "Training: Epoch 162, Batch 76, Loss: 0.11\n",
      "Training: Epoch 162, Batch 77, Loss: 0.097\n",
      "Training: Epoch 162, Batch 78, Loss: 0.079\n",
      "Training: Epoch 162, Batch 79, Loss: 0.089\n",
      "Training: Epoch 162, Batch 80, Loss: 0.088\n",
      "Training: Epoch 162, Batch 81, Loss: 0.064\n",
      "Training: Epoch 162, Batch 82, Loss: 0.074\n",
      "Training: Epoch 162, Batch 83, Loss: 0.071\n",
      "Training: Epoch 162, Batch 84, Loss: 0.108\n",
      "Training: Epoch 162, Batch 85, Loss: 0.105\n",
      "Training: Epoch 162, Batch 86, Loss: 0.076\n",
      "Training: Epoch 162, Batch 87, Loss: 0.103\n",
      "Training: Epoch 162, Batch 88, Loss: 0.084\n",
      "Training: Epoch 162, Batch 89, Loss: 0.065\n",
      "Val: Epoch 162, Loss: 0.334\n",
      "Training: Epoch 163, Batch 0, Loss: 0.108\n",
      "Training: Epoch 163, Batch 1, Loss: 0.088\n",
      "Training: Epoch 163, Batch 2, Loss: 0.113\n",
      "Training: Epoch 163, Batch 3, Loss: 0.083\n",
      "Training: Epoch 163, Batch 4, Loss: 0.07\n",
      "Training: Epoch 163, Batch 5, Loss: 0.068\n",
      "Training: Epoch 163, Batch 6, Loss: 0.081\n",
      "Training: Epoch 163, Batch 7, Loss: 0.074\n",
      "Training: Epoch 163, Batch 8, Loss: 0.087\n",
      "Training: Epoch 163, Batch 9, Loss: 0.08\n",
      "Training: Epoch 163, Batch 10, Loss: 0.089\n",
      "Training: Epoch 163, Batch 11, Loss: 0.121\n",
      "Training: Epoch 163, Batch 12, Loss: 0.098\n",
      "Training: Epoch 163, Batch 13, Loss: 0.088\n",
      "Training: Epoch 163, Batch 14, Loss: 0.067\n",
      "Training: Epoch 163, Batch 15, Loss: 0.117\n",
      "Training: Epoch 163, Batch 16, Loss: 0.108\n",
      "Training: Epoch 163, Batch 17, Loss: 0.081\n",
      "Training: Epoch 163, Batch 18, Loss: 0.076\n",
      "Training: Epoch 163, Batch 19, Loss: 0.092\n",
      "Training: Epoch 163, Batch 20, Loss: 0.115\n",
      "Training: Epoch 163, Batch 21, Loss: 0.065\n",
      "Training: Epoch 163, Batch 22, Loss: 0.102\n",
      "Training: Epoch 163, Batch 23, Loss: 0.084\n",
      "Training: Epoch 163, Batch 24, Loss: 0.069\n",
      "Training: Epoch 163, Batch 25, Loss: 0.104\n",
      "Training: Epoch 163, Batch 26, Loss: 0.087\n",
      "Training: Epoch 163, Batch 27, Loss: 0.095\n",
      "Training: Epoch 163, Batch 28, Loss: 0.101\n",
      "Training: Epoch 163, Batch 29, Loss: 0.095\n",
      "Training: Epoch 163, Batch 30, Loss: 0.091\n",
      "Training: Epoch 163, Batch 31, Loss: 0.077\n",
      "Training: Epoch 163, Batch 32, Loss: 0.124\n",
      "Training: Epoch 163, Batch 33, Loss: 0.121\n",
      "Training: Epoch 163, Batch 34, Loss: 0.132\n",
      "Training: Epoch 163, Batch 35, Loss: 0.075\n",
      "Training: Epoch 163, Batch 36, Loss: 0.092\n",
      "Training: Epoch 163, Batch 37, Loss: 0.099\n",
      "Training: Epoch 163, Batch 38, Loss: 0.075\n",
      "Training: Epoch 163, Batch 39, Loss: 0.11\n",
      "Training: Epoch 163, Batch 40, Loss: 0.118\n",
      "Training: Epoch 163, Batch 41, Loss: 0.089\n",
      "Training: Epoch 163, Batch 42, Loss: 0.075\n",
      "Training: Epoch 163, Batch 43, Loss: 0.098\n",
      "Training: Epoch 163, Batch 44, Loss: 0.081\n",
      "Training: Epoch 163, Batch 45, Loss: 0.067\n",
      "Training: Epoch 163, Batch 46, Loss: 0.09\n",
      "Training: Epoch 163, Batch 47, Loss: 0.114\n",
      "Training: Epoch 163, Batch 48, Loss: 0.072\n",
      "Training: Epoch 163, Batch 49, Loss: 0.102\n",
      "Training: Epoch 163, Batch 50, Loss: 0.105\n",
      "Training: Epoch 163, Batch 51, Loss: 0.067\n",
      "Training: Epoch 163, Batch 52, Loss: 0.087\n",
      "Training: Epoch 163, Batch 53, Loss: 0.084\n",
      "Training: Epoch 163, Batch 54, Loss: 0.071\n",
      "Training: Epoch 163, Batch 55, Loss: 0.091\n",
      "Training: Epoch 163, Batch 56, Loss: 0.096\n",
      "Training: Epoch 163, Batch 57, Loss: 0.126\n",
      "Training: Epoch 163, Batch 58, Loss: 0.095\n",
      "Training: Epoch 163, Batch 59, Loss: 0.089\n",
      "Training: Epoch 163, Batch 60, Loss: 0.093\n",
      "Training: Epoch 163, Batch 61, Loss: 0.096\n",
      "Training: Epoch 163, Batch 62, Loss: 0.061\n",
      "Training: Epoch 163, Batch 63, Loss: 0.076\n",
      "Training: Epoch 163, Batch 64, Loss: 0.096\n",
      "Training: Epoch 163, Batch 65, Loss: 0.097\n",
      "Training: Epoch 163, Batch 66, Loss: 0.073\n",
      "Training: Epoch 163, Batch 67, Loss: 0.128\n",
      "Training: Epoch 163, Batch 68, Loss: 0.095\n",
      "Training: Epoch 163, Batch 69, Loss: 0.079\n",
      "Training: Epoch 163, Batch 70, Loss: 0.071\n",
      "Training: Epoch 163, Batch 71, Loss: 0.09\n",
      "Training: Epoch 163, Batch 72, Loss: 0.086\n",
      "Training: Epoch 163, Batch 73, Loss: 0.101\n",
      "Training: Epoch 163, Batch 74, Loss: 0.122\n",
      "Training: Epoch 163, Batch 75, Loss: 0.079\n",
      "Training: Epoch 163, Batch 76, Loss: 0.099\n",
      "Training: Epoch 163, Batch 77, Loss: 0.126\n",
      "Training: Epoch 163, Batch 78, Loss: 0.101\n",
      "Training: Epoch 163, Batch 79, Loss: 0.085\n",
      "Training: Epoch 163, Batch 80, Loss: 0.082\n",
      "Training: Epoch 163, Batch 81, Loss: 0.111\n",
      "Training: Epoch 163, Batch 82, Loss: 0.094\n",
      "Training: Epoch 163, Batch 83, Loss: 0.083\n",
      "Training: Epoch 163, Batch 84, Loss: 0.099\n",
      "Training: Epoch 163, Batch 85, Loss: 0.11\n",
      "Training: Epoch 163, Batch 86, Loss: 0.105\n",
      "Training: Epoch 163, Batch 87, Loss: 0.109\n",
      "Training: Epoch 163, Batch 88, Loss: 0.088\n",
      "Training: Epoch 163, Batch 89, Loss: 0.067\n",
      "Val: Epoch 163, Loss: 0.319\n",
      "Training: Epoch 164, Batch 0, Loss: 0.094\n",
      "Training: Epoch 164, Batch 1, Loss: 0.087\n",
      "Training: Epoch 164, Batch 2, Loss: 0.07\n",
      "Training: Epoch 164, Batch 3, Loss: 0.105\n",
      "Training: Epoch 164, Batch 4, Loss: 0.102\n",
      "Training: Epoch 164, Batch 5, Loss: 0.089\n",
      "Training: Epoch 164, Batch 6, Loss: 0.075\n",
      "Training: Epoch 164, Batch 7, Loss: 0.096\n",
      "Training: Epoch 164, Batch 8, Loss: 0.11\n",
      "Training: Epoch 164, Batch 9, Loss: 0.131\n",
      "Training: Epoch 164, Batch 10, Loss: 0.078\n",
      "Training: Epoch 164, Batch 11, Loss: 0.089\n",
      "Training: Epoch 164, Batch 12, Loss: 0.094\n",
      "Training: Epoch 164, Batch 13, Loss: 0.075\n",
      "Training: Epoch 164, Batch 14, Loss: 0.082\n",
      "Training: Epoch 164, Batch 15, Loss: 0.103\n",
      "Training: Epoch 164, Batch 16, Loss: 0.11\n",
      "Training: Epoch 164, Batch 17, Loss: 0.089\n",
      "Training: Epoch 164, Batch 18, Loss: 0.094\n",
      "Training: Epoch 164, Batch 19, Loss: 0.093\n",
      "Training: Epoch 164, Batch 20, Loss: 0.102\n",
      "Training: Epoch 164, Batch 21, Loss: 0.101\n",
      "Training: Epoch 164, Batch 22, Loss: 0.088\n",
      "Training: Epoch 164, Batch 23, Loss: 0.089\n",
      "Training: Epoch 164, Batch 24, Loss: 0.098\n",
      "Training: Epoch 164, Batch 25, Loss: 0.093\n",
      "Training: Epoch 164, Batch 26, Loss: 0.08\n",
      "Training: Epoch 164, Batch 27, Loss: 0.101\n",
      "Training: Epoch 164, Batch 28, Loss: 0.088\n",
      "Training: Epoch 164, Batch 29, Loss: 0.075\n",
      "Training: Epoch 164, Batch 30, Loss: 0.101\n",
      "Training: Epoch 164, Batch 31, Loss: 0.08\n",
      "Training: Epoch 164, Batch 32, Loss: 0.099\n",
      "Training: Epoch 164, Batch 33, Loss: 0.068\n",
      "Training: Epoch 164, Batch 34, Loss: 0.088\n",
      "Training: Epoch 164, Batch 35, Loss: 0.107\n",
      "Training: Epoch 164, Batch 36, Loss: 0.091\n",
      "Training: Epoch 164, Batch 37, Loss: 0.111\n",
      "Training: Epoch 164, Batch 38, Loss: 0.108\n",
      "Training: Epoch 164, Batch 39, Loss: 0.1\n",
      "Training: Epoch 164, Batch 40, Loss: 0.082\n",
      "Training: Epoch 164, Batch 41, Loss: 0.094\n",
      "Training: Epoch 164, Batch 42, Loss: 0.105\n",
      "Training: Epoch 164, Batch 43, Loss: 0.099\n",
      "Training: Epoch 164, Batch 44, Loss: 0.095\n",
      "Training: Epoch 164, Batch 45, Loss: 0.094\n",
      "Training: Epoch 164, Batch 46, Loss: 0.069\n",
      "Training: Epoch 164, Batch 47, Loss: 0.103\n",
      "Training: Epoch 164, Batch 48, Loss: 0.083\n",
      "Training: Epoch 164, Batch 49, Loss: 0.098\n",
      "Training: Epoch 164, Batch 50, Loss: 0.073\n",
      "Training: Epoch 164, Batch 51, Loss: 0.124\n",
      "Training: Epoch 164, Batch 52, Loss: 0.095\n",
      "Training: Epoch 164, Batch 53, Loss: 0.078\n",
      "Training: Epoch 164, Batch 54, Loss: 0.114\n",
      "Training: Epoch 164, Batch 55, Loss: 0.083\n",
      "Training: Epoch 164, Batch 56, Loss: 0.092\n",
      "Training: Epoch 164, Batch 57, Loss: 0.099\n",
      "Training: Epoch 164, Batch 58, Loss: 0.077\n",
      "Training: Epoch 164, Batch 59, Loss: 0.134\n",
      "Training: Epoch 164, Batch 60, Loss: 0.124\n",
      "Training: Epoch 164, Batch 61, Loss: 0.082\n",
      "Training: Epoch 164, Batch 62, Loss: 0.076\n",
      "Training: Epoch 164, Batch 63, Loss: 0.087\n",
      "Training: Epoch 164, Batch 64, Loss: 0.118\n",
      "Training: Epoch 164, Batch 65, Loss: 0.076\n",
      "Training: Epoch 164, Batch 66, Loss: 0.095\n",
      "Training: Epoch 164, Batch 67, Loss: 0.108\n",
      "Training: Epoch 164, Batch 68, Loss: 0.071\n",
      "Training: Epoch 164, Batch 69, Loss: 0.058\n",
      "Training: Epoch 164, Batch 70, Loss: 0.074\n",
      "Training: Epoch 164, Batch 71, Loss: 0.071\n",
      "Training: Epoch 164, Batch 72, Loss: 0.089\n",
      "Training: Epoch 164, Batch 73, Loss: 0.073\n",
      "Training: Epoch 164, Batch 74, Loss: 0.078\n",
      "Training: Epoch 164, Batch 75, Loss: 0.107\n",
      "Training: Epoch 164, Batch 76, Loss: 0.089\n",
      "Training: Epoch 164, Batch 77, Loss: 0.092\n",
      "Training: Epoch 164, Batch 78, Loss: 0.086\n",
      "Training: Epoch 164, Batch 79, Loss: 0.106\n",
      "Training: Epoch 164, Batch 80, Loss: 0.105\n",
      "Training: Epoch 164, Batch 81, Loss: 0.111\n",
      "Training: Epoch 164, Batch 82, Loss: 0.122\n",
      "Training: Epoch 164, Batch 83, Loss: 0.091\n",
      "Training: Epoch 164, Batch 84, Loss: 0.073\n",
      "Training: Epoch 164, Batch 85, Loss: 0.09\n",
      "Training: Epoch 164, Batch 86, Loss: 0.101\n",
      "Training: Epoch 164, Batch 87, Loss: 0.112\n",
      "Training: Epoch 164, Batch 88, Loss: 0.08\n",
      "Training: Epoch 164, Batch 89, Loss: 0.1\n",
      "Val: Epoch 164, Loss: 0.346\n",
      "Training: Epoch 165, Batch 0, Loss: 0.069\n",
      "Training: Epoch 165, Batch 1, Loss: 0.121\n",
      "Training: Epoch 165, Batch 2, Loss: 0.097\n",
      "Training: Epoch 165, Batch 3, Loss: 0.093\n",
      "Training: Epoch 165, Batch 4, Loss: 0.108\n",
      "Training: Epoch 165, Batch 5, Loss: 0.058\n",
      "Training: Epoch 165, Batch 6, Loss: 0.107\n",
      "Training: Epoch 165, Batch 7, Loss: 0.081\n",
      "Training: Epoch 165, Batch 8, Loss: 0.104\n",
      "Training: Epoch 165, Batch 9, Loss: 0.1\n",
      "Training: Epoch 165, Batch 10, Loss: 0.098\n",
      "Training: Epoch 165, Batch 11, Loss: 0.095\n",
      "Training: Epoch 165, Batch 12, Loss: 0.064\n",
      "Training: Epoch 165, Batch 13, Loss: 0.073\n",
      "Training: Epoch 165, Batch 14, Loss: 0.103\n",
      "Training: Epoch 165, Batch 15, Loss: 0.084\n",
      "Training: Epoch 165, Batch 16, Loss: 0.061\n",
      "Training: Epoch 165, Batch 17, Loss: 0.097\n",
      "Training: Epoch 165, Batch 18, Loss: 0.083\n",
      "Training: Epoch 165, Batch 19, Loss: 0.071\n",
      "Training: Epoch 165, Batch 20, Loss: 0.095\n",
      "Training: Epoch 165, Batch 21, Loss: 0.097\n",
      "Training: Epoch 165, Batch 22, Loss: 0.079\n",
      "Training: Epoch 165, Batch 23, Loss: 0.083\n",
      "Training: Epoch 165, Batch 24, Loss: 0.092\n",
      "Training: Epoch 165, Batch 25, Loss: 0.077\n",
      "Training: Epoch 165, Batch 26, Loss: 0.083\n",
      "Training: Epoch 165, Batch 27, Loss: 0.066\n",
      "Training: Epoch 165, Batch 28, Loss: 0.123\n",
      "Training: Epoch 165, Batch 29, Loss: 0.088\n",
      "Training: Epoch 165, Batch 30, Loss: 0.11\n",
      "Training: Epoch 165, Batch 31, Loss: 0.106\n",
      "Training: Epoch 165, Batch 32, Loss: 0.117\n",
      "Training: Epoch 165, Batch 33, Loss: 0.11\n",
      "Training: Epoch 165, Batch 34, Loss: 0.096\n",
      "Training: Epoch 165, Batch 35, Loss: 0.074\n",
      "Training: Epoch 165, Batch 36, Loss: 0.076\n",
      "Training: Epoch 165, Batch 37, Loss: 0.087\n",
      "Training: Epoch 165, Batch 38, Loss: 0.088\n",
      "Training: Epoch 165, Batch 39, Loss: 0.114\n",
      "Training: Epoch 165, Batch 40, Loss: 0.113\n",
      "Training: Epoch 165, Batch 41, Loss: 0.095\n",
      "Training: Epoch 165, Batch 42, Loss: 0.105\n",
      "Training: Epoch 165, Batch 43, Loss: 0.082\n",
      "Training: Epoch 165, Batch 44, Loss: 0.084\n",
      "Training: Epoch 165, Batch 45, Loss: 0.124\n",
      "Training: Epoch 165, Batch 46, Loss: 0.099\n",
      "Training: Epoch 165, Batch 47, Loss: 0.115\n",
      "Training: Epoch 165, Batch 48, Loss: 0.078\n",
      "Training: Epoch 165, Batch 49, Loss: 0.08\n",
      "Training: Epoch 165, Batch 50, Loss: 0.102\n",
      "Training: Epoch 165, Batch 51, Loss: 0.082\n",
      "Training: Epoch 165, Batch 52, Loss: 0.097\n",
      "Training: Epoch 165, Batch 53, Loss: 0.082\n",
      "Training: Epoch 165, Batch 54, Loss: 0.075\n",
      "Training: Epoch 165, Batch 55, Loss: 0.086\n",
      "Training: Epoch 165, Batch 56, Loss: 0.062\n",
      "Training: Epoch 165, Batch 57, Loss: 0.103\n",
      "Training: Epoch 165, Batch 58, Loss: 0.115\n",
      "Training: Epoch 165, Batch 59, Loss: 0.092\n",
      "Training: Epoch 165, Batch 60, Loss: 0.087\n",
      "Training: Epoch 165, Batch 61, Loss: 0.091\n",
      "Training: Epoch 165, Batch 62, Loss: 0.111\n",
      "Training: Epoch 165, Batch 63, Loss: 0.081\n",
      "Training: Epoch 165, Batch 64, Loss: 0.087\n",
      "Training: Epoch 165, Batch 65, Loss: 0.103\n",
      "Training: Epoch 165, Batch 66, Loss: 0.105\n",
      "Training: Epoch 165, Batch 67, Loss: 0.089\n",
      "Training: Epoch 165, Batch 68, Loss: 0.097\n",
      "Training: Epoch 165, Batch 69, Loss: 0.098\n",
      "Training: Epoch 165, Batch 70, Loss: 0.076\n",
      "Training: Epoch 165, Batch 71, Loss: 0.141\n",
      "Training: Epoch 165, Batch 72, Loss: 0.1\n",
      "Training: Epoch 165, Batch 73, Loss: 0.085\n",
      "Training: Epoch 165, Batch 74, Loss: 0.107\n",
      "Training: Epoch 165, Batch 75, Loss: 0.093\n",
      "Training: Epoch 165, Batch 76, Loss: 0.076\n",
      "Training: Epoch 165, Batch 77, Loss: 0.106\n",
      "Training: Epoch 165, Batch 78, Loss: 0.089\n",
      "Training: Epoch 165, Batch 79, Loss: 0.106\n",
      "Training: Epoch 165, Batch 80, Loss: 0.094\n",
      "Training: Epoch 165, Batch 81, Loss: 0.11\n",
      "Training: Epoch 165, Batch 82, Loss: 0.084\n",
      "Training: Epoch 165, Batch 83, Loss: 0.118\n",
      "Training: Epoch 165, Batch 84, Loss: 0.107\n",
      "Training: Epoch 165, Batch 85, Loss: 0.074\n",
      "Training: Epoch 165, Batch 86, Loss: 0.082\n",
      "Training: Epoch 165, Batch 87, Loss: 0.073\n",
      "Training: Epoch 165, Batch 88, Loss: 0.071\n",
      "Training: Epoch 165, Batch 89, Loss: 0.078\n",
      "Val: Epoch 165, Loss: 0.326\n",
      "Training: Epoch 166, Batch 0, Loss: 0.118\n",
      "Training: Epoch 166, Batch 1, Loss: 0.127\n",
      "Training: Epoch 166, Batch 2, Loss: 0.109\n",
      "Training: Epoch 166, Batch 3, Loss: 0.092\n",
      "Training: Epoch 166, Batch 4, Loss: 0.077\n",
      "Training: Epoch 166, Batch 5, Loss: 0.079\n",
      "Training: Epoch 166, Batch 6, Loss: 0.076\n",
      "Training: Epoch 166, Batch 7, Loss: 0.082\n",
      "Training: Epoch 166, Batch 8, Loss: 0.071\n",
      "Training: Epoch 166, Batch 9, Loss: 0.062\n",
      "Training: Epoch 166, Batch 10, Loss: 0.076\n",
      "Training: Epoch 166, Batch 11, Loss: 0.095\n",
      "Training: Epoch 166, Batch 12, Loss: 0.108\n",
      "Training: Epoch 166, Batch 13, Loss: 0.092\n",
      "Training: Epoch 166, Batch 14, Loss: 0.099\n",
      "Training: Epoch 166, Batch 15, Loss: 0.073\n",
      "Training: Epoch 166, Batch 16, Loss: 0.093\n",
      "Training: Epoch 166, Batch 17, Loss: 0.103\n",
      "Training: Epoch 166, Batch 18, Loss: 0.09\n",
      "Training: Epoch 166, Batch 19, Loss: 0.093\n",
      "Training: Epoch 166, Batch 20, Loss: 0.096\n",
      "Training: Epoch 166, Batch 21, Loss: 0.08\n",
      "Training: Epoch 166, Batch 22, Loss: 0.102\n",
      "Training: Epoch 166, Batch 23, Loss: 0.07\n",
      "Training: Epoch 166, Batch 24, Loss: 0.116\n",
      "Training: Epoch 166, Batch 25, Loss: 0.1\n",
      "Training: Epoch 166, Batch 26, Loss: 0.119\n",
      "Training: Epoch 166, Batch 27, Loss: 0.097\n",
      "Training: Epoch 166, Batch 28, Loss: 0.092\n",
      "Training: Epoch 166, Batch 29, Loss: 0.092\n",
      "Training: Epoch 166, Batch 30, Loss: 0.112\n",
      "Training: Epoch 166, Batch 31, Loss: 0.096\n",
      "Training: Epoch 166, Batch 32, Loss: 0.098\n",
      "Training: Epoch 166, Batch 33, Loss: 0.09\n",
      "Training: Epoch 166, Batch 34, Loss: 0.084\n",
      "Training: Epoch 166, Batch 35, Loss: 0.087\n",
      "Training: Epoch 166, Batch 36, Loss: 0.13\n",
      "Training: Epoch 166, Batch 37, Loss: 0.096\n",
      "Training: Epoch 166, Batch 38, Loss: 0.075\n",
      "Training: Epoch 166, Batch 39, Loss: 0.078\n",
      "Training: Epoch 166, Batch 40, Loss: 0.067\n",
      "Training: Epoch 166, Batch 41, Loss: 0.095\n",
      "Training: Epoch 166, Batch 42, Loss: 0.116\n",
      "Training: Epoch 166, Batch 43, Loss: 0.066\n",
      "Training: Epoch 166, Batch 44, Loss: 0.093\n",
      "Training: Epoch 166, Batch 45, Loss: 0.12\n",
      "Training: Epoch 166, Batch 46, Loss: 0.108\n",
      "Training: Epoch 166, Batch 47, Loss: 0.084\n",
      "Training: Epoch 166, Batch 48, Loss: 0.09\n",
      "Training: Epoch 166, Batch 49, Loss: 0.102\n",
      "Training: Epoch 166, Batch 50, Loss: 0.075\n",
      "Training: Epoch 166, Batch 51, Loss: 0.088\n",
      "Training: Epoch 166, Batch 52, Loss: 0.107\n",
      "Training: Epoch 166, Batch 53, Loss: 0.112\n",
      "Training: Epoch 166, Batch 54, Loss: 0.121\n",
      "Training: Epoch 166, Batch 55, Loss: 0.076\n",
      "Training: Epoch 166, Batch 56, Loss: 0.094\n",
      "Training: Epoch 166, Batch 57, Loss: 0.083\n",
      "Training: Epoch 166, Batch 58, Loss: 0.096\n",
      "Training: Epoch 166, Batch 59, Loss: 0.078\n",
      "Training: Epoch 166, Batch 60, Loss: 0.063\n",
      "Training: Epoch 166, Batch 61, Loss: 0.105\n",
      "Training: Epoch 166, Batch 62, Loss: 0.094\n",
      "Training: Epoch 166, Batch 63, Loss: 0.098\n",
      "Training: Epoch 166, Batch 64, Loss: 0.107\n",
      "Training: Epoch 166, Batch 65, Loss: 0.093\n",
      "Training: Epoch 166, Batch 66, Loss: 0.092\n",
      "Training: Epoch 166, Batch 67, Loss: 0.097\n",
      "Training: Epoch 166, Batch 68, Loss: 0.079\n",
      "Training: Epoch 166, Batch 69, Loss: 0.089\n",
      "Training: Epoch 166, Batch 70, Loss: 0.085\n",
      "Training: Epoch 166, Batch 71, Loss: 0.09\n",
      "Training: Epoch 166, Batch 72, Loss: 0.082\n",
      "Training: Epoch 166, Batch 73, Loss: 0.089\n",
      "Training: Epoch 166, Batch 74, Loss: 0.085\n",
      "Training: Epoch 166, Batch 75, Loss: 0.067\n",
      "Training: Epoch 166, Batch 76, Loss: 0.137\n",
      "Training: Epoch 166, Batch 77, Loss: 0.081\n",
      "Training: Epoch 166, Batch 78, Loss: 0.075\n",
      "Training: Epoch 166, Batch 79, Loss: 0.118\n",
      "Training: Epoch 166, Batch 80, Loss: 0.09\n",
      "Training: Epoch 166, Batch 81, Loss: 0.092\n",
      "Training: Epoch 166, Batch 82, Loss: 0.081\n",
      "Training: Epoch 166, Batch 83, Loss: 0.085\n",
      "Training: Epoch 166, Batch 84, Loss: 0.133\n",
      "Training: Epoch 166, Batch 85, Loss: 0.092\n",
      "Training: Epoch 166, Batch 86, Loss: 0.102\n",
      "Training: Epoch 166, Batch 87, Loss: 0.097\n",
      "Training: Epoch 166, Batch 88, Loss: 0.074\n",
      "Training: Epoch 166, Batch 89, Loss: 0.086\n",
      "Val: Epoch 166, Loss: 0.326\n",
      "Training: Epoch 167, Batch 0, Loss: 0.077\n",
      "Training: Epoch 167, Batch 1, Loss: 0.081\n",
      "Training: Epoch 167, Batch 2, Loss: 0.128\n",
      "Training: Epoch 167, Batch 3, Loss: 0.08\n",
      "Training: Epoch 167, Batch 4, Loss: 0.088\n",
      "Training: Epoch 167, Batch 5, Loss: 0.09\n",
      "Training: Epoch 167, Batch 6, Loss: 0.092\n",
      "Training: Epoch 167, Batch 7, Loss: 0.13\n",
      "Training: Epoch 167, Batch 8, Loss: 0.081\n",
      "Training: Epoch 167, Batch 9, Loss: 0.084\n",
      "Training: Epoch 167, Batch 10, Loss: 0.084\n",
      "Training: Epoch 167, Batch 11, Loss: 0.094\n",
      "Training: Epoch 167, Batch 12, Loss: 0.085\n",
      "Training: Epoch 167, Batch 13, Loss: 0.091\n",
      "Training: Epoch 167, Batch 14, Loss: 0.104\n",
      "Training: Epoch 167, Batch 15, Loss: 0.1\n",
      "Training: Epoch 167, Batch 16, Loss: 0.098\n",
      "Training: Epoch 167, Batch 17, Loss: 0.117\n",
      "Training: Epoch 167, Batch 18, Loss: 0.104\n",
      "Training: Epoch 167, Batch 19, Loss: 0.098\n",
      "Training: Epoch 167, Batch 20, Loss: 0.102\n",
      "Training: Epoch 167, Batch 21, Loss: 0.073\n",
      "Training: Epoch 167, Batch 22, Loss: 0.069\n",
      "Training: Epoch 167, Batch 23, Loss: 0.084\n",
      "Training: Epoch 167, Batch 24, Loss: 0.104\n",
      "Training: Epoch 167, Batch 25, Loss: 0.09\n",
      "Training: Epoch 167, Batch 26, Loss: 0.11\n",
      "Training: Epoch 167, Batch 27, Loss: 0.103\n",
      "Training: Epoch 167, Batch 28, Loss: 0.073\n",
      "Training: Epoch 167, Batch 29, Loss: 0.091\n",
      "Training: Epoch 167, Batch 30, Loss: 0.098\n",
      "Training: Epoch 167, Batch 31, Loss: 0.088\n",
      "Training: Epoch 167, Batch 32, Loss: 0.097\n",
      "Training: Epoch 167, Batch 33, Loss: 0.064\n",
      "Training: Epoch 167, Batch 34, Loss: 0.095\n",
      "Training: Epoch 167, Batch 35, Loss: 0.083\n",
      "Training: Epoch 167, Batch 36, Loss: 0.078\n",
      "Training: Epoch 167, Batch 37, Loss: 0.075\n",
      "Training: Epoch 167, Batch 38, Loss: 0.09\n",
      "Training: Epoch 167, Batch 39, Loss: 0.078\n",
      "Training: Epoch 167, Batch 40, Loss: 0.1\n",
      "Training: Epoch 167, Batch 41, Loss: 0.07\n",
      "Training: Epoch 167, Batch 42, Loss: 0.082\n",
      "Training: Epoch 167, Batch 43, Loss: 0.096\n",
      "Training: Epoch 167, Batch 44, Loss: 0.083\n",
      "Training: Epoch 167, Batch 45, Loss: 0.092\n",
      "Training: Epoch 167, Batch 46, Loss: 0.081\n",
      "Training: Epoch 167, Batch 47, Loss: 0.114\n",
      "Training: Epoch 167, Batch 48, Loss: 0.097\n",
      "Training: Epoch 167, Batch 49, Loss: 0.102\n",
      "Training: Epoch 167, Batch 50, Loss: 0.096\n",
      "Training: Epoch 167, Batch 51, Loss: 0.088\n",
      "Training: Epoch 167, Batch 52, Loss: 0.083\n",
      "Training: Epoch 167, Batch 53, Loss: 0.1\n",
      "Training: Epoch 167, Batch 54, Loss: 0.068\n",
      "Training: Epoch 167, Batch 55, Loss: 0.081\n",
      "Training: Epoch 167, Batch 56, Loss: 0.102\n",
      "Training: Epoch 167, Batch 57, Loss: 0.076\n",
      "Training: Epoch 167, Batch 58, Loss: 0.084\n",
      "Training: Epoch 167, Batch 59, Loss: 0.079\n",
      "Training: Epoch 167, Batch 60, Loss: 0.062\n",
      "Training: Epoch 167, Batch 61, Loss: 0.106\n",
      "Training: Epoch 167, Batch 62, Loss: 0.077\n",
      "Training: Epoch 167, Batch 63, Loss: 0.116\n",
      "Training: Epoch 167, Batch 64, Loss: 0.092\n",
      "Training: Epoch 167, Batch 65, Loss: 0.076\n",
      "Training: Epoch 167, Batch 66, Loss: 0.117\n",
      "Training: Epoch 167, Batch 67, Loss: 0.106\n",
      "Training: Epoch 167, Batch 68, Loss: 0.073\n",
      "Training: Epoch 167, Batch 69, Loss: 0.073\n",
      "Training: Epoch 167, Batch 70, Loss: 0.111\n",
      "Training: Epoch 167, Batch 71, Loss: 0.075\n",
      "Training: Epoch 167, Batch 72, Loss: 0.086\n",
      "Training: Epoch 167, Batch 73, Loss: 0.083\n",
      "Training: Epoch 167, Batch 74, Loss: 0.082\n",
      "Training: Epoch 167, Batch 75, Loss: 0.07\n",
      "Training: Epoch 167, Batch 76, Loss: 0.111\n",
      "Training: Epoch 167, Batch 77, Loss: 0.094\n",
      "Training: Epoch 167, Batch 78, Loss: 0.085\n",
      "Training: Epoch 167, Batch 79, Loss: 0.126\n",
      "Training: Epoch 167, Batch 80, Loss: 0.088\n",
      "Training: Epoch 167, Batch 81, Loss: 0.059\n",
      "Training: Epoch 167, Batch 82, Loss: 0.083\n",
      "Training: Epoch 167, Batch 83, Loss: 0.088\n",
      "Training: Epoch 167, Batch 84, Loss: 0.143\n",
      "Training: Epoch 167, Batch 85, Loss: 0.119\n",
      "Training: Epoch 167, Batch 86, Loss: 0.068\n",
      "Training: Epoch 167, Batch 87, Loss: 0.081\n",
      "Training: Epoch 167, Batch 88, Loss: 0.095\n",
      "Training: Epoch 167, Batch 89, Loss: 0.086\n",
      "Val: Epoch 167, Loss: 0.331\n",
      "Training: Epoch 168, Batch 0, Loss: 0.098\n",
      "Training: Epoch 168, Batch 1, Loss: 0.1\n",
      "Training: Epoch 168, Batch 2, Loss: 0.092\n",
      "Training: Epoch 168, Batch 3, Loss: 0.077\n",
      "Training: Epoch 168, Batch 4, Loss: 0.062\n",
      "Training: Epoch 168, Batch 5, Loss: 0.069\n",
      "Training: Epoch 168, Batch 6, Loss: 0.066\n",
      "Training: Epoch 168, Batch 7, Loss: 0.095\n",
      "Training: Epoch 168, Batch 8, Loss: 0.068\n",
      "Training: Epoch 168, Batch 9, Loss: 0.092\n",
      "Training: Epoch 168, Batch 10, Loss: 0.069\n",
      "Training: Epoch 168, Batch 11, Loss: 0.082\n",
      "Training: Epoch 168, Batch 12, Loss: 0.089\n",
      "Training: Epoch 168, Batch 13, Loss: 0.11\n",
      "Training: Epoch 168, Batch 14, Loss: 0.121\n",
      "Training: Epoch 168, Batch 15, Loss: 0.083\n",
      "Training: Epoch 168, Batch 16, Loss: 0.099\n",
      "Training: Epoch 168, Batch 17, Loss: 0.083\n",
      "Training: Epoch 168, Batch 18, Loss: 0.074\n",
      "Training: Epoch 168, Batch 19, Loss: 0.097\n",
      "Training: Epoch 168, Batch 20, Loss: 0.096\n",
      "Training: Epoch 168, Batch 21, Loss: 0.095\n",
      "Training: Epoch 168, Batch 22, Loss: 0.075\n",
      "Training: Epoch 168, Batch 23, Loss: 0.085\n",
      "Training: Epoch 168, Batch 24, Loss: 0.08\n",
      "Training: Epoch 168, Batch 25, Loss: 0.09\n",
      "Training: Epoch 168, Batch 26, Loss: 0.081\n",
      "Training: Epoch 168, Batch 27, Loss: 0.094\n",
      "Training: Epoch 168, Batch 28, Loss: 0.069\n",
      "Training: Epoch 168, Batch 29, Loss: 0.078\n",
      "Training: Epoch 168, Batch 30, Loss: 0.107\n",
      "Training: Epoch 168, Batch 31, Loss: 0.128\n",
      "Training: Epoch 168, Batch 32, Loss: 0.097\n",
      "Training: Epoch 168, Batch 33, Loss: 0.133\n",
      "Training: Epoch 168, Batch 34, Loss: 0.09\n",
      "Training: Epoch 168, Batch 35, Loss: 0.087\n",
      "Training: Epoch 168, Batch 36, Loss: 0.109\n",
      "Training: Epoch 168, Batch 37, Loss: 0.092\n",
      "Training: Epoch 168, Batch 38, Loss: 0.14\n",
      "Training: Epoch 168, Batch 39, Loss: 0.069\n",
      "Training: Epoch 168, Batch 40, Loss: 0.09\n",
      "Training: Epoch 168, Batch 41, Loss: 0.113\n",
      "Training: Epoch 168, Batch 42, Loss: 0.078\n",
      "Training: Epoch 168, Batch 43, Loss: 0.102\n",
      "Training: Epoch 168, Batch 44, Loss: 0.079\n",
      "Training: Epoch 168, Batch 45, Loss: 0.08\n",
      "Training: Epoch 168, Batch 46, Loss: 0.086\n",
      "Training: Epoch 168, Batch 47, Loss: 0.089\n",
      "Training: Epoch 168, Batch 48, Loss: 0.06\n",
      "Training: Epoch 168, Batch 49, Loss: 0.07\n",
      "Training: Epoch 168, Batch 50, Loss: 0.078\n",
      "Training: Epoch 168, Batch 51, Loss: 0.089\n",
      "Training: Epoch 168, Batch 52, Loss: 0.101\n",
      "Training: Epoch 168, Batch 53, Loss: 0.065\n",
      "Training: Epoch 168, Batch 54, Loss: 0.12\n",
      "Training: Epoch 168, Batch 55, Loss: 0.105\n",
      "Training: Epoch 168, Batch 56, Loss: 0.076\n",
      "Training: Epoch 168, Batch 57, Loss: 0.08\n",
      "Training: Epoch 168, Batch 58, Loss: 0.089\n",
      "Training: Epoch 168, Batch 59, Loss: 0.068\n",
      "Training: Epoch 168, Batch 60, Loss: 0.12\n",
      "Training: Epoch 168, Batch 61, Loss: 0.086\n",
      "Training: Epoch 168, Batch 62, Loss: 0.072\n",
      "Training: Epoch 168, Batch 63, Loss: 0.1\n",
      "Training: Epoch 168, Batch 64, Loss: 0.098\n",
      "Training: Epoch 168, Batch 65, Loss: 0.112\n",
      "Training: Epoch 168, Batch 66, Loss: 0.085\n",
      "Training: Epoch 168, Batch 67, Loss: 0.071\n",
      "Training: Epoch 168, Batch 68, Loss: 0.082\n",
      "Training: Epoch 168, Batch 69, Loss: 0.08\n",
      "Training: Epoch 168, Batch 70, Loss: 0.082\n",
      "Training: Epoch 168, Batch 71, Loss: 0.111\n",
      "Training: Epoch 168, Batch 72, Loss: 0.086\n",
      "Training: Epoch 168, Batch 73, Loss: 0.086\n",
      "Training: Epoch 168, Batch 74, Loss: 0.076\n",
      "Training: Epoch 168, Batch 75, Loss: 0.113\n",
      "Training: Epoch 168, Batch 76, Loss: 0.081\n",
      "Training: Epoch 168, Batch 77, Loss: 0.072\n",
      "Training: Epoch 168, Batch 78, Loss: 0.111\n",
      "Training: Epoch 168, Batch 79, Loss: 0.081\n",
      "Training: Epoch 168, Batch 80, Loss: 0.095\n",
      "Training: Epoch 168, Batch 81, Loss: 0.093\n",
      "Training: Epoch 168, Batch 82, Loss: 0.127\n",
      "Training: Epoch 168, Batch 83, Loss: 0.096\n",
      "Training: Epoch 168, Batch 84, Loss: 0.083\n",
      "Training: Epoch 168, Batch 85, Loss: 0.12\n",
      "Training: Epoch 168, Batch 86, Loss: 0.079\n",
      "Training: Epoch 168, Batch 87, Loss: 0.103\n",
      "Training: Epoch 168, Batch 88, Loss: 0.078\n",
      "Training: Epoch 168, Batch 89, Loss: 0.08\n",
      "Val: Epoch 168, Loss: 0.333\n",
      "Training: Epoch 169, Batch 0, Loss: 0.088\n",
      "Training: Epoch 169, Batch 1, Loss: 0.114\n",
      "Training: Epoch 169, Batch 2, Loss: 0.075\n",
      "Training: Epoch 169, Batch 3, Loss: 0.072\n",
      "Training: Epoch 169, Batch 4, Loss: 0.088\n",
      "Training: Epoch 169, Batch 5, Loss: 0.094\n",
      "Training: Epoch 169, Batch 6, Loss: 0.085\n",
      "Training: Epoch 169, Batch 7, Loss: 0.078\n",
      "Training: Epoch 169, Batch 8, Loss: 0.13\n",
      "Training: Epoch 169, Batch 9, Loss: 0.079\n",
      "Training: Epoch 169, Batch 10, Loss: 0.09\n",
      "Training: Epoch 169, Batch 11, Loss: 0.077\n",
      "Training: Epoch 169, Batch 12, Loss: 0.104\n",
      "Training: Epoch 169, Batch 13, Loss: 0.094\n",
      "Training: Epoch 169, Batch 14, Loss: 0.097\n",
      "Training: Epoch 169, Batch 15, Loss: 0.097\n",
      "Training: Epoch 169, Batch 16, Loss: 0.069\n",
      "Training: Epoch 169, Batch 17, Loss: 0.107\n",
      "Training: Epoch 169, Batch 18, Loss: 0.088\n",
      "Training: Epoch 169, Batch 19, Loss: 0.121\n",
      "Training: Epoch 169, Batch 20, Loss: 0.08\n",
      "Training: Epoch 169, Batch 21, Loss: 0.103\n",
      "Training: Epoch 169, Batch 22, Loss: 0.084\n",
      "Training: Epoch 169, Batch 23, Loss: 0.084\n",
      "Training: Epoch 169, Batch 24, Loss: 0.08\n",
      "Training: Epoch 169, Batch 25, Loss: 0.074\n",
      "Training: Epoch 169, Batch 26, Loss: 0.099\n",
      "Training: Epoch 169, Batch 27, Loss: 0.074\n",
      "Training: Epoch 169, Batch 28, Loss: 0.091\n",
      "Training: Epoch 169, Batch 29, Loss: 0.085\n",
      "Training: Epoch 169, Batch 30, Loss: 0.111\n",
      "Training: Epoch 169, Batch 31, Loss: 0.104\n",
      "Training: Epoch 169, Batch 32, Loss: 0.108\n",
      "Training: Epoch 169, Batch 33, Loss: 0.09\n",
      "Training: Epoch 169, Batch 34, Loss: 0.115\n",
      "Training: Epoch 169, Batch 35, Loss: 0.085\n",
      "Training: Epoch 169, Batch 36, Loss: 0.082\n",
      "Training: Epoch 169, Batch 37, Loss: 0.087\n",
      "Training: Epoch 169, Batch 38, Loss: 0.081\n",
      "Training: Epoch 169, Batch 39, Loss: 0.113\n",
      "Training: Epoch 169, Batch 40, Loss: 0.087\n",
      "Training: Epoch 169, Batch 41, Loss: 0.107\n",
      "Training: Epoch 169, Batch 42, Loss: 0.102\n",
      "Training: Epoch 169, Batch 43, Loss: 0.075\n",
      "Training: Epoch 169, Batch 44, Loss: 0.077\n",
      "Training: Epoch 169, Batch 45, Loss: 0.11\n",
      "Training: Epoch 169, Batch 46, Loss: 0.102\n",
      "Training: Epoch 169, Batch 47, Loss: 0.097\n",
      "Training: Epoch 169, Batch 48, Loss: 0.079\n",
      "Training: Epoch 169, Batch 49, Loss: 0.083\n",
      "Training: Epoch 169, Batch 50, Loss: 0.11\n",
      "Training: Epoch 169, Batch 51, Loss: 0.086\n",
      "Training: Epoch 169, Batch 52, Loss: 0.1\n",
      "Training: Epoch 169, Batch 53, Loss: 0.092\n",
      "Training: Epoch 169, Batch 54, Loss: 0.108\n",
      "Training: Epoch 169, Batch 55, Loss: 0.072\n",
      "Training: Epoch 169, Batch 56, Loss: 0.076\n",
      "Training: Epoch 169, Batch 57, Loss: 0.062\n",
      "Training: Epoch 169, Batch 58, Loss: 0.093\n",
      "Training: Epoch 169, Batch 59, Loss: 0.088\n",
      "Training: Epoch 169, Batch 60, Loss: 0.085\n",
      "Training: Epoch 169, Batch 61, Loss: 0.08\n",
      "Training: Epoch 169, Batch 62, Loss: 0.124\n",
      "Training: Epoch 169, Batch 63, Loss: 0.055\n",
      "Training: Epoch 169, Batch 64, Loss: 0.121\n",
      "Training: Epoch 169, Batch 65, Loss: 0.097\n",
      "Training: Epoch 169, Batch 66, Loss: 0.078\n",
      "Training: Epoch 169, Batch 67, Loss: 0.111\n",
      "Training: Epoch 169, Batch 68, Loss: 0.097\n",
      "Training: Epoch 169, Batch 69, Loss: 0.105\n",
      "Training: Epoch 169, Batch 70, Loss: 0.086\n",
      "Training: Epoch 169, Batch 71, Loss: 0.08\n",
      "Training: Epoch 169, Batch 72, Loss: 0.095\n",
      "Training: Epoch 169, Batch 73, Loss: 0.081\n",
      "Training: Epoch 169, Batch 74, Loss: 0.093\n",
      "Training: Epoch 169, Batch 75, Loss: 0.104\n",
      "Training: Epoch 169, Batch 76, Loss: 0.075\n",
      "Training: Epoch 169, Batch 77, Loss: 0.092\n",
      "Training: Epoch 169, Batch 78, Loss: 0.068\n",
      "Training: Epoch 169, Batch 79, Loss: 0.105\n",
      "Training: Epoch 169, Batch 80, Loss: 0.067\n",
      "Training: Epoch 169, Batch 81, Loss: 0.066\n",
      "Training: Epoch 169, Batch 82, Loss: 0.074\n",
      "Training: Epoch 169, Batch 83, Loss: 0.088\n",
      "Training: Epoch 169, Batch 84, Loss: 0.08\n",
      "Training: Epoch 169, Batch 85, Loss: 0.092\n",
      "Training: Epoch 169, Batch 86, Loss: 0.06\n",
      "Training: Epoch 169, Batch 87, Loss: 0.088\n",
      "Training: Epoch 169, Batch 88, Loss: 0.095\n",
      "Training: Epoch 169, Batch 89, Loss: 0.096\n",
      "Val: Epoch 169, Loss: 0.322\n",
      "Training: Epoch 170, Batch 0, Loss: 0.074\n",
      "Training: Epoch 170, Batch 1, Loss: 0.083\n",
      "Training: Epoch 170, Batch 2, Loss: 0.102\n",
      "Training: Epoch 170, Batch 3, Loss: 0.069\n",
      "Training: Epoch 170, Batch 4, Loss: 0.071\n",
      "Training: Epoch 170, Batch 5, Loss: 0.072\n",
      "Training: Epoch 170, Batch 6, Loss: 0.091\n",
      "Training: Epoch 170, Batch 7, Loss: 0.103\n",
      "Training: Epoch 170, Batch 8, Loss: 0.09\n",
      "Training: Epoch 170, Batch 9, Loss: 0.073\n",
      "Training: Epoch 170, Batch 10, Loss: 0.102\n",
      "Training: Epoch 170, Batch 11, Loss: 0.083\n",
      "Training: Epoch 170, Batch 12, Loss: 0.086\n",
      "Training: Epoch 170, Batch 13, Loss: 0.106\n",
      "Training: Epoch 170, Batch 14, Loss: 0.086\n",
      "Training: Epoch 170, Batch 15, Loss: 0.11\n",
      "Training: Epoch 170, Batch 16, Loss: 0.068\n",
      "Training: Epoch 170, Batch 17, Loss: 0.068\n",
      "Training: Epoch 170, Batch 18, Loss: 0.09\n",
      "Training: Epoch 170, Batch 19, Loss: 0.091\n",
      "Training: Epoch 170, Batch 20, Loss: 0.069\n",
      "Training: Epoch 170, Batch 21, Loss: 0.069\n",
      "Training: Epoch 170, Batch 22, Loss: 0.072\n",
      "Training: Epoch 170, Batch 23, Loss: 0.089\n",
      "Training: Epoch 170, Batch 24, Loss: 0.105\n",
      "Training: Epoch 170, Batch 25, Loss: 0.089\n",
      "Training: Epoch 170, Batch 26, Loss: 0.093\n",
      "Training: Epoch 170, Batch 27, Loss: 0.106\n",
      "Training: Epoch 170, Batch 28, Loss: 0.058\n",
      "Training: Epoch 170, Batch 29, Loss: 0.108\n",
      "Training: Epoch 170, Batch 30, Loss: 0.087\n",
      "Training: Epoch 170, Batch 31, Loss: 0.083\n",
      "Training: Epoch 170, Batch 32, Loss: 0.087\n",
      "Training: Epoch 170, Batch 33, Loss: 0.118\n",
      "Training: Epoch 170, Batch 34, Loss: 0.1\n",
      "Training: Epoch 170, Batch 35, Loss: 0.075\n",
      "Training: Epoch 170, Batch 36, Loss: 0.098\n",
      "Training: Epoch 170, Batch 37, Loss: 0.119\n",
      "Training: Epoch 170, Batch 38, Loss: 0.096\n",
      "Training: Epoch 170, Batch 39, Loss: 0.075\n",
      "Training: Epoch 170, Batch 40, Loss: 0.075\n",
      "Training: Epoch 170, Batch 41, Loss: 0.069\n",
      "Training: Epoch 170, Batch 42, Loss: 0.095\n",
      "Training: Epoch 170, Batch 43, Loss: 0.091\n",
      "Training: Epoch 170, Batch 44, Loss: 0.08\n",
      "Training: Epoch 170, Batch 45, Loss: 0.1\n",
      "Training: Epoch 170, Batch 46, Loss: 0.095\n",
      "Training: Epoch 170, Batch 47, Loss: 0.068\n",
      "Training: Epoch 170, Batch 48, Loss: 0.089\n",
      "Training: Epoch 170, Batch 49, Loss: 0.095\n",
      "Training: Epoch 170, Batch 50, Loss: 0.097\n",
      "Training: Epoch 170, Batch 51, Loss: 0.064\n",
      "Training: Epoch 170, Batch 52, Loss: 0.095\n",
      "Training: Epoch 170, Batch 53, Loss: 0.102\n",
      "Training: Epoch 170, Batch 54, Loss: 0.097\n",
      "Training: Epoch 170, Batch 55, Loss: 0.092\n",
      "Training: Epoch 170, Batch 56, Loss: 0.079\n",
      "Training: Epoch 170, Batch 57, Loss: 0.105\n",
      "Training: Epoch 170, Batch 58, Loss: 0.092\n",
      "Training: Epoch 170, Batch 59, Loss: 0.096\n",
      "Training: Epoch 170, Batch 60, Loss: 0.077\n",
      "Training: Epoch 170, Batch 61, Loss: 0.09\n",
      "Training: Epoch 170, Batch 62, Loss: 0.078\n",
      "Training: Epoch 170, Batch 63, Loss: 0.08\n",
      "Training: Epoch 170, Batch 64, Loss: 0.081\n",
      "Training: Epoch 170, Batch 65, Loss: 0.079\n",
      "Training: Epoch 170, Batch 66, Loss: 0.108\n",
      "Training: Epoch 170, Batch 67, Loss: 0.139\n",
      "Training: Epoch 170, Batch 68, Loss: 0.106\n",
      "Training: Epoch 170, Batch 69, Loss: 0.115\n",
      "Training: Epoch 170, Batch 70, Loss: 0.094\n",
      "Training: Epoch 170, Batch 71, Loss: 0.08\n",
      "Training: Epoch 170, Batch 72, Loss: 0.085\n",
      "Training: Epoch 170, Batch 73, Loss: 0.108\n",
      "Training: Epoch 170, Batch 74, Loss: 0.101\n",
      "Training: Epoch 170, Batch 75, Loss: 0.076\n",
      "Training: Epoch 170, Batch 76, Loss: 0.079\n",
      "Training: Epoch 170, Batch 77, Loss: 0.108\n",
      "Training: Epoch 170, Batch 78, Loss: 0.099\n",
      "Training: Epoch 170, Batch 79, Loss: 0.075\n",
      "Training: Epoch 170, Batch 80, Loss: 0.073\n",
      "Training: Epoch 170, Batch 81, Loss: 0.085\n",
      "Training: Epoch 170, Batch 82, Loss: 0.093\n",
      "Training: Epoch 170, Batch 83, Loss: 0.091\n",
      "Training: Epoch 170, Batch 84, Loss: 0.082\n",
      "Training: Epoch 170, Batch 85, Loss: 0.075\n",
      "Training: Epoch 170, Batch 86, Loss: 0.077\n",
      "Training: Epoch 170, Batch 87, Loss: 0.076\n",
      "Training: Epoch 170, Batch 88, Loss: 0.067\n",
      "Training: Epoch 170, Batch 89, Loss: 0.121\n",
      "Val: Epoch 170, Loss: 0.334\n",
      "Training: Epoch 171, Batch 0, Loss: 0.077\n",
      "Training: Epoch 171, Batch 1, Loss: 0.075\n",
      "Training: Epoch 171, Batch 2, Loss: 0.092\n",
      "Training: Epoch 171, Batch 3, Loss: 0.11\n",
      "Training: Epoch 171, Batch 4, Loss: 0.075\n",
      "Training: Epoch 171, Batch 5, Loss: 0.071\n",
      "Training: Epoch 171, Batch 6, Loss: 0.086\n",
      "Training: Epoch 171, Batch 7, Loss: 0.106\n",
      "Training: Epoch 171, Batch 8, Loss: 0.084\n",
      "Training: Epoch 171, Batch 9, Loss: 0.111\n",
      "Training: Epoch 171, Batch 10, Loss: 0.093\n",
      "Training: Epoch 171, Batch 11, Loss: 0.064\n",
      "Training: Epoch 171, Batch 12, Loss: 0.11\n",
      "Training: Epoch 171, Batch 13, Loss: 0.072\n",
      "Training: Epoch 171, Batch 14, Loss: 0.098\n",
      "Training: Epoch 171, Batch 15, Loss: 0.075\n",
      "Training: Epoch 171, Batch 16, Loss: 0.096\n",
      "Training: Epoch 171, Batch 17, Loss: 0.1\n",
      "Training: Epoch 171, Batch 18, Loss: 0.089\n",
      "Training: Epoch 171, Batch 19, Loss: 0.097\n",
      "Training: Epoch 171, Batch 20, Loss: 0.088\n",
      "Training: Epoch 171, Batch 21, Loss: 0.094\n",
      "Training: Epoch 171, Batch 22, Loss: 0.075\n",
      "Training: Epoch 171, Batch 23, Loss: 0.088\n",
      "Training: Epoch 171, Batch 24, Loss: 0.077\n",
      "Training: Epoch 171, Batch 25, Loss: 0.09\n",
      "Training: Epoch 171, Batch 26, Loss: 0.094\n",
      "Training: Epoch 171, Batch 27, Loss: 0.086\n",
      "Training: Epoch 171, Batch 28, Loss: 0.089\n",
      "Training: Epoch 171, Batch 29, Loss: 0.078\n",
      "Training: Epoch 171, Batch 30, Loss: 0.08\n",
      "Training: Epoch 171, Batch 31, Loss: 0.08\n",
      "Training: Epoch 171, Batch 32, Loss: 0.12\n",
      "Training: Epoch 171, Batch 33, Loss: 0.08\n",
      "Training: Epoch 171, Batch 34, Loss: 0.083\n",
      "Training: Epoch 171, Batch 35, Loss: 0.072\n",
      "Training: Epoch 171, Batch 36, Loss: 0.079\n",
      "Training: Epoch 171, Batch 37, Loss: 0.101\n",
      "Training: Epoch 171, Batch 38, Loss: 0.082\n",
      "Training: Epoch 171, Batch 39, Loss: 0.073\n",
      "Training: Epoch 171, Batch 40, Loss: 0.103\n",
      "Training: Epoch 171, Batch 41, Loss: 0.102\n",
      "Training: Epoch 171, Batch 42, Loss: 0.073\n",
      "Training: Epoch 171, Batch 43, Loss: 0.107\n",
      "Training: Epoch 171, Batch 44, Loss: 0.09\n",
      "Training: Epoch 171, Batch 45, Loss: 0.104\n",
      "Training: Epoch 171, Batch 46, Loss: 0.107\n",
      "Training: Epoch 171, Batch 47, Loss: 0.142\n",
      "Training: Epoch 171, Batch 48, Loss: 0.08\n",
      "Training: Epoch 171, Batch 49, Loss: 0.104\n",
      "Training: Epoch 171, Batch 50, Loss: 0.066\n",
      "Training: Epoch 171, Batch 51, Loss: 0.083\n",
      "Training: Epoch 171, Batch 52, Loss: 0.067\n",
      "Training: Epoch 171, Batch 53, Loss: 0.076\n",
      "Training: Epoch 171, Batch 54, Loss: 0.062\n",
      "Training: Epoch 171, Batch 55, Loss: 0.073\n",
      "Training: Epoch 171, Batch 56, Loss: 0.116\n",
      "Training: Epoch 171, Batch 57, Loss: 0.086\n",
      "Training: Epoch 171, Batch 58, Loss: 0.099\n",
      "Training: Epoch 171, Batch 59, Loss: 0.083\n",
      "Training: Epoch 171, Batch 60, Loss: 0.072\n",
      "Training: Epoch 171, Batch 61, Loss: 0.083\n",
      "Training: Epoch 171, Batch 62, Loss: 0.072\n",
      "Training: Epoch 171, Batch 63, Loss: 0.095\n",
      "Training: Epoch 171, Batch 64, Loss: 0.1\n",
      "Training: Epoch 171, Batch 65, Loss: 0.113\n",
      "Training: Epoch 171, Batch 66, Loss: 0.088\n",
      "Training: Epoch 171, Batch 67, Loss: 0.065\n",
      "Training: Epoch 171, Batch 68, Loss: 0.099\n",
      "Training: Epoch 171, Batch 69, Loss: 0.068\n",
      "Training: Epoch 171, Batch 70, Loss: 0.089\n",
      "Training: Epoch 171, Batch 71, Loss: 0.089\n",
      "Training: Epoch 171, Batch 72, Loss: 0.09\n",
      "Training: Epoch 171, Batch 73, Loss: 0.09\n",
      "Training: Epoch 171, Batch 74, Loss: 0.079\n",
      "Training: Epoch 171, Batch 75, Loss: 0.095\n",
      "Training: Epoch 171, Batch 76, Loss: 0.077\n",
      "Training: Epoch 171, Batch 77, Loss: 0.11\n",
      "Training: Epoch 171, Batch 78, Loss: 0.097\n",
      "Training: Epoch 171, Batch 79, Loss: 0.083\n",
      "Training: Epoch 171, Batch 80, Loss: 0.087\n",
      "Training: Epoch 171, Batch 81, Loss: 0.071\n",
      "Training: Epoch 171, Batch 82, Loss: 0.058\n",
      "Training: Epoch 171, Batch 83, Loss: 0.088\n",
      "Training: Epoch 171, Batch 84, Loss: 0.107\n",
      "Training: Epoch 171, Batch 85, Loss: 0.088\n",
      "Training: Epoch 171, Batch 86, Loss: 0.103\n",
      "Training: Epoch 171, Batch 87, Loss: 0.095\n",
      "Training: Epoch 171, Batch 88, Loss: 0.079\n",
      "Training: Epoch 171, Batch 89, Loss: 0.089\n",
      "Val: Epoch 171, Loss: 0.31\n",
      "Training: Epoch 172, Batch 0, Loss: 0.112\n",
      "Training: Epoch 172, Batch 1, Loss: 0.075\n",
      "Training: Epoch 172, Batch 2, Loss: 0.067\n",
      "Training: Epoch 172, Batch 3, Loss: 0.079\n",
      "Training: Epoch 172, Batch 4, Loss: 0.093\n",
      "Training: Epoch 172, Batch 5, Loss: 0.082\n",
      "Training: Epoch 172, Batch 6, Loss: 0.061\n",
      "Training: Epoch 172, Batch 7, Loss: 0.095\n",
      "Training: Epoch 172, Batch 8, Loss: 0.067\n",
      "Training: Epoch 172, Batch 9, Loss: 0.079\n",
      "Training: Epoch 172, Batch 10, Loss: 0.081\n",
      "Training: Epoch 172, Batch 11, Loss: 0.08\n",
      "Training: Epoch 172, Batch 12, Loss: 0.087\n",
      "Training: Epoch 172, Batch 13, Loss: 0.073\n",
      "Training: Epoch 172, Batch 14, Loss: 0.098\n",
      "Training: Epoch 172, Batch 15, Loss: 0.101\n",
      "Training: Epoch 172, Batch 16, Loss: 0.094\n",
      "Training: Epoch 172, Batch 17, Loss: 0.084\n",
      "Training: Epoch 172, Batch 18, Loss: 0.104\n",
      "Training: Epoch 172, Batch 19, Loss: 0.084\n",
      "Training: Epoch 172, Batch 20, Loss: 0.081\n",
      "Training: Epoch 172, Batch 21, Loss: 0.101\n",
      "Training: Epoch 172, Batch 22, Loss: 0.085\n",
      "Training: Epoch 172, Batch 23, Loss: 0.085\n",
      "Training: Epoch 172, Batch 24, Loss: 0.079\n",
      "Training: Epoch 172, Batch 25, Loss: 0.119\n",
      "Training: Epoch 172, Batch 26, Loss: 0.073\n",
      "Training: Epoch 172, Batch 27, Loss: 0.088\n",
      "Training: Epoch 172, Batch 28, Loss: 0.116\n",
      "Training: Epoch 172, Batch 29, Loss: 0.096\n",
      "Training: Epoch 172, Batch 30, Loss: 0.091\n",
      "Training: Epoch 172, Batch 31, Loss: 0.095\n",
      "Training: Epoch 172, Batch 32, Loss: 0.114\n",
      "Training: Epoch 172, Batch 33, Loss: 0.083\n",
      "Training: Epoch 172, Batch 34, Loss: 0.095\n",
      "Training: Epoch 172, Batch 35, Loss: 0.097\n",
      "Training: Epoch 172, Batch 36, Loss: 0.081\n",
      "Training: Epoch 172, Batch 37, Loss: 0.079\n",
      "Training: Epoch 172, Batch 38, Loss: 0.093\n",
      "Training: Epoch 172, Batch 39, Loss: 0.069\n",
      "Training: Epoch 172, Batch 40, Loss: 0.104\n",
      "Training: Epoch 172, Batch 41, Loss: 0.099\n",
      "Training: Epoch 172, Batch 42, Loss: 0.072\n",
      "Training: Epoch 172, Batch 43, Loss: 0.085\n",
      "Training: Epoch 172, Batch 44, Loss: 0.074\n",
      "Training: Epoch 172, Batch 45, Loss: 0.113\n",
      "Training: Epoch 172, Batch 46, Loss: 0.08\n",
      "Training: Epoch 172, Batch 47, Loss: 0.069\n",
      "Training: Epoch 172, Batch 48, Loss: 0.109\n",
      "Training: Epoch 172, Batch 49, Loss: 0.094\n",
      "Training: Epoch 172, Batch 50, Loss: 0.095\n",
      "Training: Epoch 172, Batch 51, Loss: 0.075\n",
      "Training: Epoch 172, Batch 52, Loss: 0.088\n",
      "Training: Epoch 172, Batch 53, Loss: 0.109\n",
      "Training: Epoch 172, Batch 54, Loss: 0.081\n",
      "Training: Epoch 172, Batch 55, Loss: 0.1\n",
      "Training: Epoch 172, Batch 56, Loss: 0.081\n",
      "Training: Epoch 172, Batch 57, Loss: 0.094\n",
      "Training: Epoch 172, Batch 58, Loss: 0.092\n",
      "Training: Epoch 172, Batch 59, Loss: 0.083\n",
      "Training: Epoch 172, Batch 60, Loss: 0.082\n",
      "Training: Epoch 172, Batch 61, Loss: 0.116\n",
      "Training: Epoch 172, Batch 62, Loss: 0.073\n",
      "Training: Epoch 172, Batch 63, Loss: 0.084\n",
      "Training: Epoch 172, Batch 64, Loss: 0.077\n",
      "Training: Epoch 172, Batch 65, Loss: 0.113\n",
      "Training: Epoch 172, Batch 66, Loss: 0.097\n",
      "Training: Epoch 172, Batch 67, Loss: 0.097\n",
      "Training: Epoch 172, Batch 68, Loss: 0.101\n",
      "Training: Epoch 172, Batch 69, Loss: 0.079\n",
      "Training: Epoch 172, Batch 70, Loss: 0.103\n",
      "Training: Epoch 172, Batch 71, Loss: 0.08\n",
      "Training: Epoch 172, Batch 72, Loss: 0.07\n",
      "Training: Epoch 172, Batch 73, Loss: 0.104\n",
      "Training: Epoch 172, Batch 74, Loss: 0.081\n",
      "Training: Epoch 172, Batch 75, Loss: 0.072\n",
      "Training: Epoch 172, Batch 76, Loss: 0.068\n",
      "Training: Epoch 172, Batch 77, Loss: 0.117\n",
      "Training: Epoch 172, Batch 78, Loss: 0.114\n",
      "Training: Epoch 172, Batch 79, Loss: 0.079\n",
      "Training: Epoch 172, Batch 80, Loss: 0.069\n",
      "Training: Epoch 172, Batch 81, Loss: 0.078\n",
      "Training: Epoch 172, Batch 82, Loss: 0.077\n",
      "Training: Epoch 172, Batch 83, Loss: 0.107\n",
      "Training: Epoch 172, Batch 84, Loss: 0.092\n",
      "Training: Epoch 172, Batch 85, Loss: 0.081\n",
      "Training: Epoch 172, Batch 86, Loss: 0.065\n",
      "Training: Epoch 172, Batch 87, Loss: 0.078\n",
      "Training: Epoch 172, Batch 88, Loss: 0.097\n",
      "Training: Epoch 172, Batch 89, Loss: 0.089\n",
      "Val: Epoch 172, Loss: 0.334\n",
      "Training: Epoch 173, Batch 0, Loss: 0.104\n",
      "Training: Epoch 173, Batch 1, Loss: 0.073\n",
      "Training: Epoch 173, Batch 2, Loss: 0.078\n",
      "Training: Epoch 173, Batch 3, Loss: 0.063\n",
      "Training: Epoch 173, Batch 4, Loss: 0.086\n",
      "Training: Epoch 173, Batch 5, Loss: 0.091\n",
      "Training: Epoch 173, Batch 6, Loss: 0.069\n",
      "Training: Epoch 173, Batch 7, Loss: 0.099\n",
      "Training: Epoch 173, Batch 8, Loss: 0.102\n",
      "Training: Epoch 173, Batch 9, Loss: 0.087\n",
      "Training: Epoch 173, Batch 10, Loss: 0.11\n",
      "Training: Epoch 173, Batch 11, Loss: 0.082\n",
      "Training: Epoch 173, Batch 12, Loss: 0.08\n",
      "Training: Epoch 173, Batch 13, Loss: 0.058\n",
      "Training: Epoch 173, Batch 14, Loss: 0.076\n",
      "Training: Epoch 173, Batch 15, Loss: 0.094\n",
      "Training: Epoch 173, Batch 16, Loss: 0.094\n",
      "Training: Epoch 173, Batch 17, Loss: 0.094\n",
      "Training: Epoch 173, Batch 18, Loss: 0.099\n",
      "Training: Epoch 173, Batch 19, Loss: 0.072\n",
      "Training: Epoch 173, Batch 20, Loss: 0.073\n",
      "Training: Epoch 173, Batch 21, Loss: 0.088\n",
      "Training: Epoch 173, Batch 22, Loss: 0.082\n",
      "Training: Epoch 173, Batch 23, Loss: 0.101\n",
      "Training: Epoch 173, Batch 24, Loss: 0.123\n",
      "Training: Epoch 173, Batch 25, Loss: 0.075\n",
      "Training: Epoch 173, Batch 26, Loss: 0.08\n",
      "Training: Epoch 173, Batch 27, Loss: 0.076\n",
      "Training: Epoch 173, Batch 28, Loss: 0.117\n",
      "Training: Epoch 173, Batch 29, Loss: 0.099\n",
      "Training: Epoch 173, Batch 30, Loss: 0.083\n",
      "Training: Epoch 173, Batch 31, Loss: 0.107\n",
      "Training: Epoch 173, Batch 32, Loss: 0.129\n",
      "Training: Epoch 173, Batch 33, Loss: 0.099\n",
      "Training: Epoch 173, Batch 34, Loss: 0.077\n",
      "Training: Epoch 173, Batch 35, Loss: 0.094\n",
      "Training: Epoch 173, Batch 36, Loss: 0.07\n",
      "Training: Epoch 173, Batch 37, Loss: 0.076\n",
      "Training: Epoch 173, Batch 38, Loss: 0.094\n",
      "Training: Epoch 173, Batch 39, Loss: 0.057\n",
      "Training: Epoch 173, Batch 40, Loss: 0.121\n",
      "Training: Epoch 173, Batch 41, Loss: 0.099\n",
      "Training: Epoch 173, Batch 42, Loss: 0.079\n",
      "Training: Epoch 173, Batch 43, Loss: 0.109\n",
      "Training: Epoch 173, Batch 44, Loss: 0.08\n",
      "Training: Epoch 173, Batch 45, Loss: 0.072\n",
      "Training: Epoch 173, Batch 46, Loss: 0.08\n",
      "Training: Epoch 173, Batch 47, Loss: 0.076\n",
      "Training: Epoch 173, Batch 48, Loss: 0.091\n",
      "Training: Epoch 173, Batch 49, Loss: 0.065\n",
      "Training: Epoch 173, Batch 50, Loss: 0.09\n",
      "Training: Epoch 173, Batch 51, Loss: 0.091\n",
      "Training: Epoch 173, Batch 52, Loss: 0.068\n",
      "Training: Epoch 173, Batch 53, Loss: 0.081\n",
      "Training: Epoch 173, Batch 54, Loss: 0.073\n",
      "Training: Epoch 173, Batch 55, Loss: 0.086\n",
      "Training: Epoch 173, Batch 56, Loss: 0.083\n",
      "Training: Epoch 173, Batch 57, Loss: 0.091\n",
      "Training: Epoch 173, Batch 58, Loss: 0.077\n",
      "Training: Epoch 173, Batch 59, Loss: 0.067\n",
      "Training: Epoch 173, Batch 60, Loss: 0.064\n",
      "Training: Epoch 173, Batch 61, Loss: 0.087\n",
      "Training: Epoch 173, Batch 62, Loss: 0.084\n",
      "Training: Epoch 173, Batch 63, Loss: 0.07\n",
      "Training: Epoch 173, Batch 64, Loss: 0.071\n",
      "Training: Epoch 173, Batch 65, Loss: 0.075\n",
      "Training: Epoch 173, Batch 66, Loss: 0.103\n",
      "Training: Epoch 173, Batch 67, Loss: 0.084\n",
      "Training: Epoch 173, Batch 68, Loss: 0.085\n",
      "Training: Epoch 173, Batch 69, Loss: 0.107\n",
      "Training: Epoch 173, Batch 70, Loss: 0.072\n",
      "Training: Epoch 173, Batch 71, Loss: 0.096\n",
      "Training: Epoch 173, Batch 72, Loss: 0.079\n",
      "Training: Epoch 173, Batch 73, Loss: 0.108\n",
      "Training: Epoch 173, Batch 74, Loss: 0.094\n",
      "Training: Epoch 173, Batch 75, Loss: 0.076\n",
      "Training: Epoch 173, Batch 76, Loss: 0.117\n",
      "Training: Epoch 173, Batch 77, Loss: 0.11\n",
      "Training: Epoch 173, Batch 78, Loss: 0.128\n",
      "Training: Epoch 173, Batch 79, Loss: 0.083\n",
      "Training: Epoch 173, Batch 80, Loss: 0.075\n",
      "Training: Epoch 173, Batch 81, Loss: 0.096\n",
      "Training: Epoch 173, Batch 82, Loss: 0.092\n",
      "Training: Epoch 173, Batch 83, Loss: 0.091\n",
      "Training: Epoch 173, Batch 84, Loss: 0.088\n",
      "Training: Epoch 173, Batch 85, Loss: 0.104\n",
      "Training: Epoch 173, Batch 86, Loss: 0.077\n",
      "Training: Epoch 173, Batch 87, Loss: 0.058\n",
      "Training: Epoch 173, Batch 88, Loss: 0.1\n",
      "Training: Epoch 173, Batch 89, Loss: 0.083\n",
      "Val: Epoch 173, Loss: 0.366\n",
      "Training: Epoch 174, Batch 0, Loss: 0.09\n",
      "Training: Epoch 174, Batch 1, Loss: 0.067\n",
      "Training: Epoch 174, Batch 2, Loss: 0.086\n",
      "Training: Epoch 174, Batch 3, Loss: 0.085\n",
      "Training: Epoch 174, Batch 4, Loss: 0.085\n",
      "Training: Epoch 174, Batch 5, Loss: 0.087\n",
      "Training: Epoch 174, Batch 6, Loss: 0.09\n",
      "Training: Epoch 174, Batch 7, Loss: 0.068\n",
      "Training: Epoch 174, Batch 8, Loss: 0.083\n",
      "Training: Epoch 174, Batch 9, Loss: 0.084\n",
      "Training: Epoch 174, Batch 10, Loss: 0.083\n",
      "Training: Epoch 174, Batch 11, Loss: 0.112\n",
      "Training: Epoch 174, Batch 12, Loss: 0.08\n",
      "Training: Epoch 174, Batch 13, Loss: 0.073\n",
      "Training: Epoch 174, Batch 14, Loss: 0.077\n",
      "Training: Epoch 174, Batch 15, Loss: 0.09\n",
      "Training: Epoch 174, Batch 16, Loss: 0.081\n",
      "Training: Epoch 174, Batch 17, Loss: 0.107\n",
      "Training: Epoch 174, Batch 18, Loss: 0.097\n",
      "Training: Epoch 174, Batch 19, Loss: 0.079\n",
      "Training: Epoch 174, Batch 20, Loss: 0.081\n",
      "Training: Epoch 174, Batch 21, Loss: 0.105\n",
      "Training: Epoch 174, Batch 22, Loss: 0.103\n",
      "Training: Epoch 174, Batch 23, Loss: 0.109\n",
      "Training: Epoch 174, Batch 24, Loss: 0.097\n",
      "Training: Epoch 174, Batch 25, Loss: 0.094\n",
      "Training: Epoch 174, Batch 26, Loss: 0.077\n",
      "Training: Epoch 174, Batch 27, Loss: 0.086\n",
      "Training: Epoch 174, Batch 28, Loss: 0.11\n",
      "Training: Epoch 174, Batch 29, Loss: 0.058\n",
      "Training: Epoch 174, Batch 30, Loss: 0.084\n",
      "Training: Epoch 174, Batch 31, Loss: 0.089\n",
      "Training: Epoch 174, Batch 32, Loss: 0.076\n",
      "Training: Epoch 174, Batch 33, Loss: 0.084\n",
      "Training: Epoch 174, Batch 34, Loss: 0.061\n",
      "Training: Epoch 174, Batch 35, Loss: 0.099\n",
      "Training: Epoch 174, Batch 36, Loss: 0.062\n",
      "Training: Epoch 174, Batch 37, Loss: 0.093\n",
      "Training: Epoch 174, Batch 38, Loss: 0.071\n",
      "Training: Epoch 174, Batch 39, Loss: 0.089\n",
      "Training: Epoch 174, Batch 40, Loss: 0.065\n",
      "Training: Epoch 174, Batch 41, Loss: 0.083\n",
      "Training: Epoch 174, Batch 42, Loss: 0.063\n",
      "Training: Epoch 174, Batch 43, Loss: 0.082\n",
      "Training: Epoch 174, Batch 44, Loss: 0.08\n",
      "Training: Epoch 174, Batch 45, Loss: 0.08\n",
      "Training: Epoch 174, Batch 46, Loss: 0.086\n",
      "Training: Epoch 174, Batch 47, Loss: 0.082\n",
      "Training: Epoch 174, Batch 48, Loss: 0.089\n",
      "Training: Epoch 174, Batch 49, Loss: 0.094\n",
      "Training: Epoch 174, Batch 50, Loss: 0.076\n",
      "Training: Epoch 174, Batch 51, Loss: 0.106\n",
      "Training: Epoch 174, Batch 52, Loss: 0.068\n",
      "Training: Epoch 174, Batch 53, Loss: 0.09\n",
      "Training: Epoch 174, Batch 54, Loss: 0.11\n",
      "Training: Epoch 174, Batch 55, Loss: 0.122\n",
      "Training: Epoch 174, Batch 56, Loss: 0.057\n",
      "Training: Epoch 174, Batch 57, Loss: 0.118\n",
      "Training: Epoch 174, Batch 58, Loss: 0.085\n",
      "Training: Epoch 174, Batch 59, Loss: 0.1\n",
      "Training: Epoch 174, Batch 60, Loss: 0.084\n",
      "Training: Epoch 174, Batch 61, Loss: 0.102\n",
      "Training: Epoch 174, Batch 62, Loss: 0.076\n",
      "Training: Epoch 174, Batch 63, Loss: 0.072\n",
      "Training: Epoch 174, Batch 64, Loss: 0.087\n",
      "Training: Epoch 174, Batch 65, Loss: 0.06\n",
      "Training: Epoch 174, Batch 66, Loss: 0.074\n",
      "Training: Epoch 174, Batch 67, Loss: 0.13\n",
      "Training: Epoch 174, Batch 68, Loss: 0.085\n",
      "Training: Epoch 174, Batch 69, Loss: 0.13\n",
      "Training: Epoch 174, Batch 70, Loss: 0.094\n",
      "Training: Epoch 174, Batch 71, Loss: 0.069\n",
      "Training: Epoch 174, Batch 72, Loss: 0.073\n",
      "Training: Epoch 174, Batch 73, Loss: 0.097\n",
      "Training: Epoch 174, Batch 74, Loss: 0.079\n",
      "Training: Epoch 174, Batch 75, Loss: 0.089\n",
      "Training: Epoch 174, Batch 76, Loss: 0.085\n",
      "Training: Epoch 174, Batch 77, Loss: 0.121\n",
      "Training: Epoch 174, Batch 78, Loss: 0.087\n",
      "Training: Epoch 174, Batch 79, Loss: 0.071\n",
      "Training: Epoch 174, Batch 80, Loss: 0.078\n",
      "Training: Epoch 174, Batch 81, Loss: 0.078\n",
      "Training: Epoch 174, Batch 82, Loss: 0.081\n",
      "Training: Epoch 174, Batch 83, Loss: 0.109\n",
      "Training: Epoch 174, Batch 84, Loss: 0.086\n",
      "Training: Epoch 174, Batch 85, Loss: 0.067\n",
      "Training: Epoch 174, Batch 86, Loss: 0.104\n",
      "Training: Epoch 174, Batch 87, Loss: 0.099\n",
      "Training: Epoch 174, Batch 88, Loss: 0.093\n",
      "Training: Epoch 174, Batch 89, Loss: 0.067\n",
      "Val: Epoch 174, Loss: 0.341\n",
      "Training: Epoch 175, Batch 0, Loss: 0.083\n",
      "Training: Epoch 175, Batch 1, Loss: 0.099\n",
      "Training: Epoch 175, Batch 2, Loss: 0.097\n",
      "Training: Epoch 175, Batch 3, Loss: 0.079\n",
      "Training: Epoch 175, Batch 4, Loss: 0.081\n",
      "Training: Epoch 175, Batch 5, Loss: 0.073\n",
      "Training: Epoch 175, Batch 6, Loss: 0.095\n",
      "Training: Epoch 175, Batch 7, Loss: 0.093\n",
      "Training: Epoch 175, Batch 8, Loss: 0.072\n",
      "Training: Epoch 175, Batch 9, Loss: 0.129\n",
      "Training: Epoch 175, Batch 10, Loss: 0.09\n",
      "Training: Epoch 175, Batch 11, Loss: 0.092\n",
      "Training: Epoch 175, Batch 12, Loss: 0.068\n",
      "Training: Epoch 175, Batch 13, Loss: 0.102\n",
      "Training: Epoch 175, Batch 14, Loss: 0.091\n",
      "Training: Epoch 175, Batch 15, Loss: 0.065\n",
      "Training: Epoch 175, Batch 16, Loss: 0.078\n",
      "Training: Epoch 175, Batch 17, Loss: 0.064\n",
      "Training: Epoch 175, Batch 18, Loss: 0.065\n",
      "Training: Epoch 175, Batch 19, Loss: 0.09\n",
      "Training: Epoch 175, Batch 20, Loss: 0.08\n",
      "Training: Epoch 175, Batch 21, Loss: 0.103\n",
      "Training: Epoch 175, Batch 22, Loss: 0.084\n",
      "Training: Epoch 175, Batch 23, Loss: 0.073\n",
      "Training: Epoch 175, Batch 24, Loss: 0.096\n",
      "Training: Epoch 175, Batch 25, Loss: 0.081\n",
      "Training: Epoch 175, Batch 26, Loss: 0.095\n",
      "Training: Epoch 175, Batch 27, Loss: 0.085\n",
      "Training: Epoch 175, Batch 28, Loss: 0.096\n",
      "Training: Epoch 175, Batch 29, Loss: 0.088\n",
      "Training: Epoch 175, Batch 30, Loss: 0.083\n",
      "Training: Epoch 175, Batch 31, Loss: 0.096\n",
      "Training: Epoch 175, Batch 32, Loss: 0.089\n",
      "Training: Epoch 175, Batch 33, Loss: 0.102\n",
      "Training: Epoch 175, Batch 34, Loss: 0.122\n",
      "Training: Epoch 175, Batch 35, Loss: 0.098\n",
      "Training: Epoch 175, Batch 36, Loss: 0.066\n",
      "Training: Epoch 175, Batch 37, Loss: 0.076\n",
      "Training: Epoch 175, Batch 38, Loss: 0.089\n",
      "Training: Epoch 175, Batch 39, Loss: 0.082\n",
      "Training: Epoch 175, Batch 40, Loss: 0.087\n",
      "Training: Epoch 175, Batch 41, Loss: 0.093\n",
      "Training: Epoch 175, Batch 42, Loss: 0.087\n",
      "Training: Epoch 175, Batch 43, Loss: 0.097\n",
      "Training: Epoch 175, Batch 44, Loss: 0.081\n",
      "Training: Epoch 175, Batch 45, Loss: 0.124\n",
      "Training: Epoch 175, Batch 46, Loss: 0.103\n",
      "Training: Epoch 175, Batch 47, Loss: 0.061\n",
      "Training: Epoch 175, Batch 48, Loss: 0.101\n",
      "Training: Epoch 175, Batch 49, Loss: 0.101\n",
      "Training: Epoch 175, Batch 50, Loss: 0.081\n",
      "Training: Epoch 175, Batch 51, Loss: 0.067\n",
      "Training: Epoch 175, Batch 52, Loss: 0.084\n",
      "Training: Epoch 175, Batch 53, Loss: 0.084\n",
      "Training: Epoch 175, Batch 54, Loss: 0.08\n",
      "Training: Epoch 175, Batch 55, Loss: 0.076\n",
      "Training: Epoch 175, Batch 56, Loss: 0.078\n",
      "Training: Epoch 175, Batch 57, Loss: 0.088\n",
      "Training: Epoch 175, Batch 58, Loss: 0.077\n",
      "Training: Epoch 175, Batch 59, Loss: 0.111\n",
      "Training: Epoch 175, Batch 60, Loss: 0.081\n",
      "Training: Epoch 175, Batch 61, Loss: 0.092\n",
      "Training: Epoch 175, Batch 62, Loss: 0.062\n",
      "Training: Epoch 175, Batch 63, Loss: 0.062\n",
      "Training: Epoch 175, Batch 64, Loss: 0.071\n",
      "Training: Epoch 175, Batch 65, Loss: 0.091\n",
      "Training: Epoch 175, Batch 66, Loss: 0.132\n",
      "Training: Epoch 175, Batch 67, Loss: 0.086\n",
      "Training: Epoch 175, Batch 68, Loss: 0.074\n",
      "Training: Epoch 175, Batch 69, Loss: 0.082\n",
      "Training: Epoch 175, Batch 70, Loss: 0.104\n",
      "Training: Epoch 175, Batch 71, Loss: 0.062\n",
      "Training: Epoch 175, Batch 72, Loss: 0.081\n",
      "Training: Epoch 175, Batch 73, Loss: 0.068\n",
      "Training: Epoch 175, Batch 74, Loss: 0.085\n",
      "Training: Epoch 175, Batch 75, Loss: 0.066\n",
      "Training: Epoch 175, Batch 76, Loss: 0.074\n",
      "Training: Epoch 175, Batch 77, Loss: 0.081\n",
      "Training: Epoch 175, Batch 78, Loss: 0.093\n",
      "Training: Epoch 175, Batch 79, Loss: 0.076\n",
      "Training: Epoch 175, Batch 80, Loss: 0.099\n",
      "Training: Epoch 175, Batch 81, Loss: 0.083\n",
      "Training: Epoch 175, Batch 82, Loss: 0.081\n",
      "Training: Epoch 175, Batch 83, Loss: 0.082\n",
      "Training: Epoch 175, Batch 84, Loss: 0.078\n",
      "Training: Epoch 175, Batch 85, Loss: 0.078\n",
      "Training: Epoch 175, Batch 86, Loss: 0.068\n",
      "Training: Epoch 175, Batch 87, Loss: 0.094\n",
      "Training: Epoch 175, Batch 88, Loss: 0.064\n",
      "Training: Epoch 175, Batch 89, Loss: 0.093\n",
      "Val: Epoch 175, Loss: 0.339\n",
      "Training: Epoch 176, Batch 0, Loss: 0.075\n",
      "Training: Epoch 176, Batch 1, Loss: 0.092\n",
      "Training: Epoch 176, Batch 2, Loss: 0.076\n",
      "Training: Epoch 176, Batch 3, Loss: 0.092\n",
      "Training: Epoch 176, Batch 4, Loss: 0.061\n",
      "Training: Epoch 176, Batch 5, Loss: 0.079\n",
      "Training: Epoch 176, Batch 6, Loss: 0.079\n",
      "Training: Epoch 176, Batch 7, Loss: 0.075\n",
      "Training: Epoch 176, Batch 8, Loss: 0.095\n",
      "Training: Epoch 176, Batch 9, Loss: 0.091\n",
      "Training: Epoch 176, Batch 10, Loss: 0.087\n",
      "Training: Epoch 176, Batch 11, Loss: 0.07\n",
      "Training: Epoch 176, Batch 12, Loss: 0.096\n",
      "Training: Epoch 176, Batch 13, Loss: 0.076\n",
      "Training: Epoch 176, Batch 14, Loss: 0.102\n",
      "Training: Epoch 176, Batch 15, Loss: 0.103\n",
      "Training: Epoch 176, Batch 16, Loss: 0.083\n",
      "Training: Epoch 176, Batch 17, Loss: 0.088\n",
      "Training: Epoch 176, Batch 18, Loss: 0.089\n",
      "Training: Epoch 176, Batch 19, Loss: 0.101\n",
      "Training: Epoch 176, Batch 20, Loss: 0.063\n",
      "Training: Epoch 176, Batch 21, Loss: 0.105\n",
      "Training: Epoch 176, Batch 22, Loss: 0.075\n",
      "Training: Epoch 176, Batch 23, Loss: 0.089\n",
      "Training: Epoch 176, Batch 24, Loss: 0.088\n",
      "Training: Epoch 176, Batch 25, Loss: 0.086\n",
      "Training: Epoch 176, Batch 26, Loss: 0.069\n",
      "Training: Epoch 176, Batch 27, Loss: 0.082\n",
      "Training: Epoch 176, Batch 28, Loss: 0.089\n",
      "Training: Epoch 176, Batch 29, Loss: 0.085\n",
      "Training: Epoch 176, Batch 30, Loss: 0.095\n",
      "Training: Epoch 176, Batch 31, Loss: 0.086\n",
      "Training: Epoch 176, Batch 32, Loss: 0.079\n",
      "Training: Epoch 176, Batch 33, Loss: 0.109\n",
      "Training: Epoch 176, Batch 34, Loss: 0.097\n",
      "Training: Epoch 176, Batch 35, Loss: 0.105\n",
      "Training: Epoch 176, Batch 36, Loss: 0.075\n",
      "Training: Epoch 176, Batch 37, Loss: 0.096\n",
      "Training: Epoch 176, Batch 38, Loss: 0.092\n",
      "Training: Epoch 176, Batch 39, Loss: 0.09\n",
      "Training: Epoch 176, Batch 40, Loss: 0.085\n",
      "Training: Epoch 176, Batch 41, Loss: 0.078\n",
      "Training: Epoch 176, Batch 42, Loss: 0.066\n",
      "Training: Epoch 176, Batch 43, Loss: 0.079\n",
      "Training: Epoch 176, Batch 44, Loss: 0.073\n",
      "Training: Epoch 176, Batch 45, Loss: 0.082\n",
      "Training: Epoch 176, Batch 46, Loss: 0.053\n",
      "Training: Epoch 176, Batch 47, Loss: 0.076\n",
      "Training: Epoch 176, Batch 48, Loss: 0.095\n",
      "Training: Epoch 176, Batch 49, Loss: 0.086\n",
      "Training: Epoch 176, Batch 50, Loss: 0.101\n",
      "Training: Epoch 176, Batch 51, Loss: 0.082\n",
      "Training: Epoch 176, Batch 52, Loss: 0.068\n",
      "Training: Epoch 176, Batch 53, Loss: 0.064\n",
      "Training: Epoch 176, Batch 54, Loss: 0.097\n",
      "Training: Epoch 176, Batch 55, Loss: 0.073\n",
      "Training: Epoch 176, Batch 56, Loss: 0.092\n",
      "Training: Epoch 176, Batch 57, Loss: 0.084\n",
      "Training: Epoch 176, Batch 58, Loss: 0.107\n",
      "Training: Epoch 176, Batch 59, Loss: 0.094\n",
      "Training: Epoch 176, Batch 60, Loss: 0.073\n",
      "Training: Epoch 176, Batch 61, Loss: 0.08\n",
      "Training: Epoch 176, Batch 62, Loss: 0.07\n",
      "Training: Epoch 176, Batch 63, Loss: 0.085\n",
      "Training: Epoch 176, Batch 64, Loss: 0.11\n",
      "Training: Epoch 176, Batch 65, Loss: 0.098\n",
      "Training: Epoch 176, Batch 66, Loss: 0.08\n",
      "Training: Epoch 176, Batch 67, Loss: 0.099\n",
      "Training: Epoch 176, Batch 68, Loss: 0.096\n",
      "Training: Epoch 176, Batch 69, Loss: 0.1\n",
      "Training: Epoch 176, Batch 70, Loss: 0.1\n",
      "Training: Epoch 176, Batch 71, Loss: 0.068\n",
      "Training: Epoch 176, Batch 72, Loss: 0.086\n",
      "Training: Epoch 176, Batch 73, Loss: 0.062\n",
      "Training: Epoch 176, Batch 74, Loss: 0.107\n",
      "Training: Epoch 176, Batch 75, Loss: 0.114\n",
      "Training: Epoch 176, Batch 76, Loss: 0.115\n",
      "Training: Epoch 176, Batch 77, Loss: 0.075\n",
      "Training: Epoch 176, Batch 78, Loss: 0.077\n",
      "Training: Epoch 176, Batch 79, Loss: 0.117\n",
      "Training: Epoch 176, Batch 80, Loss: 0.074\n",
      "Training: Epoch 176, Batch 81, Loss: 0.073\n",
      "Training: Epoch 176, Batch 82, Loss: 0.095\n",
      "Training: Epoch 176, Batch 83, Loss: 0.071\n",
      "Training: Epoch 176, Batch 84, Loss: 0.082\n",
      "Training: Epoch 176, Batch 85, Loss: 0.065\n",
      "Training: Epoch 176, Batch 86, Loss: 0.112\n",
      "Training: Epoch 176, Batch 87, Loss: 0.089\n",
      "Training: Epoch 176, Batch 88, Loss: 0.088\n",
      "Training: Epoch 176, Batch 89, Loss: 0.084\n",
      "Val: Epoch 176, Loss: 0.352\n",
      "Training: Epoch 177, Batch 0, Loss: 0.099\n",
      "Training: Epoch 177, Batch 1, Loss: 0.084\n",
      "Training: Epoch 177, Batch 2, Loss: 0.071\n",
      "Training: Epoch 177, Batch 3, Loss: 0.101\n",
      "Training: Epoch 177, Batch 4, Loss: 0.078\n",
      "Training: Epoch 177, Batch 5, Loss: 0.073\n",
      "Training: Epoch 177, Batch 6, Loss: 0.095\n",
      "Training: Epoch 177, Batch 7, Loss: 0.091\n",
      "Training: Epoch 177, Batch 8, Loss: 0.089\n",
      "Training: Epoch 177, Batch 9, Loss: 0.081\n",
      "Training: Epoch 177, Batch 10, Loss: 0.069\n",
      "Training: Epoch 177, Batch 11, Loss: 0.085\n",
      "Training: Epoch 177, Batch 12, Loss: 0.055\n",
      "Training: Epoch 177, Batch 13, Loss: 0.09\n",
      "Training: Epoch 177, Batch 14, Loss: 0.084\n",
      "Training: Epoch 177, Batch 15, Loss: 0.056\n",
      "Training: Epoch 177, Batch 16, Loss: 0.063\n",
      "Training: Epoch 177, Batch 17, Loss: 0.095\n",
      "Training: Epoch 177, Batch 18, Loss: 0.069\n",
      "Training: Epoch 177, Batch 19, Loss: 0.099\n",
      "Training: Epoch 177, Batch 20, Loss: 0.083\n",
      "Training: Epoch 177, Batch 21, Loss: 0.146\n",
      "Training: Epoch 177, Batch 22, Loss: 0.073\n",
      "Training: Epoch 177, Batch 23, Loss: 0.099\n",
      "Training: Epoch 177, Batch 24, Loss: 0.096\n",
      "Training: Epoch 177, Batch 25, Loss: 0.075\n",
      "Training: Epoch 177, Batch 26, Loss: 0.1\n",
      "Training: Epoch 177, Batch 27, Loss: 0.073\n",
      "Training: Epoch 177, Batch 28, Loss: 0.085\n",
      "Training: Epoch 177, Batch 29, Loss: 0.094\n",
      "Training: Epoch 177, Batch 30, Loss: 0.079\n",
      "Training: Epoch 177, Batch 31, Loss: 0.098\n",
      "Training: Epoch 177, Batch 32, Loss: 0.086\n",
      "Training: Epoch 177, Batch 33, Loss: 0.081\n",
      "Training: Epoch 177, Batch 34, Loss: 0.101\n",
      "Training: Epoch 177, Batch 35, Loss: 0.11\n",
      "Training: Epoch 177, Batch 36, Loss: 0.071\n",
      "Training: Epoch 177, Batch 37, Loss: 0.077\n",
      "Training: Epoch 177, Batch 38, Loss: 0.074\n",
      "Training: Epoch 177, Batch 39, Loss: 0.092\n",
      "Training: Epoch 177, Batch 40, Loss: 0.076\n",
      "Training: Epoch 177, Batch 41, Loss: 0.106\n",
      "Training: Epoch 177, Batch 42, Loss: 0.1\n",
      "Training: Epoch 177, Batch 43, Loss: 0.066\n",
      "Training: Epoch 177, Batch 44, Loss: 0.075\n",
      "Training: Epoch 177, Batch 45, Loss: 0.058\n",
      "Training: Epoch 177, Batch 46, Loss: 0.083\n",
      "Training: Epoch 177, Batch 47, Loss: 0.119\n",
      "Training: Epoch 177, Batch 48, Loss: 0.09\n",
      "Training: Epoch 177, Batch 49, Loss: 0.099\n",
      "Training: Epoch 177, Batch 50, Loss: 0.072\n",
      "Training: Epoch 177, Batch 51, Loss: 0.086\n",
      "Training: Epoch 177, Batch 52, Loss: 0.07\n",
      "Training: Epoch 177, Batch 53, Loss: 0.108\n",
      "Training: Epoch 177, Batch 54, Loss: 0.091\n",
      "Training: Epoch 177, Batch 55, Loss: 0.124\n",
      "Training: Epoch 177, Batch 56, Loss: 0.112\n",
      "Training: Epoch 177, Batch 57, Loss: 0.099\n",
      "Training: Epoch 177, Batch 58, Loss: 0.072\n",
      "Training: Epoch 177, Batch 59, Loss: 0.084\n",
      "Training: Epoch 177, Batch 60, Loss: 0.066\n",
      "Training: Epoch 177, Batch 61, Loss: 0.066\n",
      "Training: Epoch 177, Batch 62, Loss: 0.071\n",
      "Training: Epoch 177, Batch 63, Loss: 0.071\n",
      "Training: Epoch 177, Batch 64, Loss: 0.07\n",
      "Training: Epoch 177, Batch 65, Loss: 0.099\n",
      "Training: Epoch 177, Batch 66, Loss: 0.065\n",
      "Training: Epoch 177, Batch 67, Loss: 0.075\n",
      "Training: Epoch 177, Batch 68, Loss: 0.085\n",
      "Training: Epoch 177, Batch 69, Loss: 0.095\n",
      "Training: Epoch 177, Batch 70, Loss: 0.104\n",
      "Training: Epoch 177, Batch 71, Loss: 0.084\n",
      "Training: Epoch 177, Batch 72, Loss: 0.088\n",
      "Training: Epoch 177, Batch 73, Loss: 0.084\n",
      "Training: Epoch 177, Batch 74, Loss: 0.094\n",
      "Training: Epoch 177, Batch 75, Loss: 0.095\n",
      "Training: Epoch 177, Batch 76, Loss: 0.094\n",
      "Training: Epoch 177, Batch 77, Loss: 0.081\n",
      "Training: Epoch 177, Batch 78, Loss: 0.099\n",
      "Training: Epoch 177, Batch 79, Loss: 0.071\n",
      "Training: Epoch 177, Batch 80, Loss: 0.092\n",
      "Training: Epoch 177, Batch 81, Loss: 0.072\n",
      "Training: Epoch 177, Batch 82, Loss: 0.09\n",
      "Training: Epoch 177, Batch 83, Loss: 0.078\n",
      "Training: Epoch 177, Batch 84, Loss: 0.074\n",
      "Training: Epoch 177, Batch 85, Loss: 0.094\n",
      "Training: Epoch 177, Batch 86, Loss: 0.101\n",
      "Training: Epoch 177, Batch 87, Loss: 0.094\n",
      "Training: Epoch 177, Batch 88, Loss: 0.099\n",
      "Training: Epoch 177, Batch 89, Loss: 0.08\n",
      "Val: Epoch 177, Loss: 0.354\n",
      "Training: Epoch 178, Batch 0, Loss: 0.097\n",
      "Training: Epoch 178, Batch 1, Loss: 0.108\n",
      "Training: Epoch 178, Batch 2, Loss: 0.093\n",
      "Training: Epoch 178, Batch 3, Loss: 0.098\n",
      "Training: Epoch 178, Batch 4, Loss: 0.078\n",
      "Training: Epoch 178, Batch 5, Loss: 0.137\n",
      "Training: Epoch 178, Batch 6, Loss: 0.098\n",
      "Training: Epoch 178, Batch 7, Loss: 0.066\n",
      "Training: Epoch 178, Batch 8, Loss: 0.045\n",
      "Training: Epoch 178, Batch 9, Loss: 0.084\n",
      "Training: Epoch 178, Batch 10, Loss: 0.14\n",
      "Training: Epoch 178, Batch 11, Loss: 0.114\n",
      "Training: Epoch 178, Batch 12, Loss: 0.101\n",
      "Training: Epoch 178, Batch 13, Loss: 0.117\n",
      "Training: Epoch 178, Batch 14, Loss: 0.083\n",
      "Training: Epoch 178, Batch 15, Loss: 0.066\n",
      "Training: Epoch 178, Batch 16, Loss: 0.085\n",
      "Training: Epoch 178, Batch 17, Loss: 0.093\n",
      "Training: Epoch 178, Batch 18, Loss: 0.079\n",
      "Training: Epoch 178, Batch 19, Loss: 0.077\n",
      "Training: Epoch 178, Batch 20, Loss: 0.093\n",
      "Training: Epoch 178, Batch 21, Loss: 0.069\n",
      "Training: Epoch 178, Batch 22, Loss: 0.088\n",
      "Training: Epoch 178, Batch 23, Loss: 0.073\n",
      "Training: Epoch 178, Batch 24, Loss: 0.103\n",
      "Training: Epoch 178, Batch 25, Loss: 0.08\n",
      "Training: Epoch 178, Batch 26, Loss: 0.076\n",
      "Training: Epoch 178, Batch 27, Loss: 0.11\n",
      "Training: Epoch 178, Batch 28, Loss: 0.104\n",
      "Training: Epoch 178, Batch 29, Loss: 0.078\n",
      "Training: Epoch 178, Batch 30, Loss: 0.084\n",
      "Training: Epoch 178, Batch 31, Loss: 0.083\n",
      "Training: Epoch 178, Batch 32, Loss: 0.086\n",
      "Training: Epoch 178, Batch 33, Loss: 0.078\n",
      "Training: Epoch 178, Batch 34, Loss: 0.066\n",
      "Training: Epoch 178, Batch 35, Loss: 0.14\n",
      "Training: Epoch 178, Batch 36, Loss: 0.069\n",
      "Training: Epoch 178, Batch 37, Loss: 0.083\n",
      "Training: Epoch 178, Batch 38, Loss: 0.073\n",
      "Training: Epoch 178, Batch 39, Loss: 0.075\n",
      "Training: Epoch 178, Batch 40, Loss: 0.078\n",
      "Training: Epoch 178, Batch 41, Loss: 0.081\n",
      "Training: Epoch 178, Batch 42, Loss: 0.113\n",
      "Training: Epoch 178, Batch 43, Loss: 0.066\n",
      "Training: Epoch 178, Batch 44, Loss: 0.064\n",
      "Training: Epoch 178, Batch 45, Loss: 0.102\n",
      "Training: Epoch 178, Batch 46, Loss: 0.074\n",
      "Training: Epoch 178, Batch 47, Loss: 0.074\n",
      "Training: Epoch 178, Batch 48, Loss: 0.083\n",
      "Training: Epoch 178, Batch 49, Loss: 0.096\n",
      "Training: Epoch 178, Batch 50, Loss: 0.095\n",
      "Training: Epoch 178, Batch 51, Loss: 0.073\n",
      "Training: Epoch 178, Batch 52, Loss: 0.068\n",
      "Training: Epoch 178, Batch 53, Loss: 0.08\n",
      "Training: Epoch 178, Batch 54, Loss: 0.077\n",
      "Training: Epoch 178, Batch 55, Loss: 0.101\n",
      "Training: Epoch 178, Batch 56, Loss: 0.103\n",
      "Training: Epoch 178, Batch 57, Loss: 0.074\n",
      "Training: Epoch 178, Batch 58, Loss: 0.067\n",
      "Training: Epoch 178, Batch 59, Loss: 0.076\n",
      "Training: Epoch 178, Batch 60, Loss: 0.088\n",
      "Training: Epoch 178, Batch 61, Loss: 0.071\n",
      "Training: Epoch 178, Batch 62, Loss: 0.068\n",
      "Training: Epoch 178, Batch 63, Loss: 0.089\n",
      "Training: Epoch 178, Batch 64, Loss: 0.072\n",
      "Training: Epoch 178, Batch 65, Loss: 0.075\n",
      "Training: Epoch 178, Batch 66, Loss: 0.1\n",
      "Training: Epoch 178, Batch 67, Loss: 0.089\n",
      "Training: Epoch 178, Batch 68, Loss: 0.083\n",
      "Training: Epoch 178, Batch 69, Loss: 0.113\n",
      "Training: Epoch 178, Batch 70, Loss: 0.076\n",
      "Training: Epoch 178, Batch 71, Loss: 0.083\n",
      "Training: Epoch 178, Batch 72, Loss: 0.082\n",
      "Training: Epoch 178, Batch 73, Loss: 0.072\n",
      "Training: Epoch 178, Batch 74, Loss: 0.086\n",
      "Training: Epoch 178, Batch 75, Loss: 0.081\n",
      "Training: Epoch 178, Batch 76, Loss: 0.086\n",
      "Training: Epoch 178, Batch 77, Loss: 0.089\n",
      "Training: Epoch 178, Batch 78, Loss: 0.102\n",
      "Training: Epoch 178, Batch 79, Loss: 0.118\n",
      "Training: Epoch 178, Batch 80, Loss: 0.071\n",
      "Training: Epoch 178, Batch 81, Loss: 0.081\n",
      "Training: Epoch 178, Batch 82, Loss: 0.08\n",
      "Training: Epoch 178, Batch 83, Loss: 0.066\n",
      "Training: Epoch 178, Batch 84, Loss: 0.061\n",
      "Training: Epoch 178, Batch 85, Loss: 0.111\n",
      "Training: Epoch 178, Batch 86, Loss: 0.081\n",
      "Training: Epoch 178, Batch 87, Loss: 0.078\n",
      "Training: Epoch 178, Batch 88, Loss: 0.093\n",
      "Training: Epoch 178, Batch 89, Loss: 0.106\n",
      "Val: Epoch 178, Loss: 0.333\n",
      "Training: Epoch 179, Batch 0, Loss: 0.093\n",
      "Training: Epoch 179, Batch 1, Loss: 0.085\n",
      "Training: Epoch 179, Batch 2, Loss: 0.09\n",
      "Training: Epoch 179, Batch 3, Loss: 0.111\n",
      "Training: Epoch 179, Batch 4, Loss: 0.13\n",
      "Training: Epoch 179, Batch 5, Loss: 0.073\n",
      "Training: Epoch 179, Batch 6, Loss: 0.064\n",
      "Training: Epoch 179, Batch 7, Loss: 0.086\n",
      "Training: Epoch 179, Batch 8, Loss: 0.108\n",
      "Training: Epoch 179, Batch 9, Loss: 0.092\n",
      "Training: Epoch 179, Batch 10, Loss: 0.127\n",
      "Training: Epoch 179, Batch 11, Loss: 0.083\n",
      "Training: Epoch 179, Batch 12, Loss: 0.065\n",
      "Training: Epoch 179, Batch 13, Loss: 0.092\n",
      "Training: Epoch 179, Batch 14, Loss: 0.077\n",
      "Training: Epoch 179, Batch 15, Loss: 0.085\n",
      "Training: Epoch 179, Batch 16, Loss: 0.083\n",
      "Training: Epoch 179, Batch 17, Loss: 0.074\n",
      "Training: Epoch 179, Batch 18, Loss: 0.101\n",
      "Training: Epoch 179, Batch 19, Loss: 0.067\n",
      "Training: Epoch 179, Batch 20, Loss: 0.086\n",
      "Training: Epoch 179, Batch 21, Loss: 0.093\n",
      "Training: Epoch 179, Batch 22, Loss: 0.088\n",
      "Training: Epoch 179, Batch 23, Loss: 0.072\n",
      "Training: Epoch 179, Batch 24, Loss: 0.083\n",
      "Training: Epoch 179, Batch 25, Loss: 0.085\n",
      "Training: Epoch 179, Batch 26, Loss: 0.074\n",
      "Training: Epoch 179, Batch 27, Loss: 0.072\n",
      "Training: Epoch 179, Batch 28, Loss: 0.109\n",
      "Training: Epoch 179, Batch 29, Loss: 0.071\n",
      "Training: Epoch 179, Batch 30, Loss: 0.082\n",
      "Training: Epoch 179, Batch 31, Loss: 0.103\n",
      "Training: Epoch 179, Batch 32, Loss: 0.06\n",
      "Training: Epoch 179, Batch 33, Loss: 0.103\n",
      "Training: Epoch 179, Batch 34, Loss: 0.08\n",
      "Training: Epoch 179, Batch 35, Loss: 0.133\n",
      "Training: Epoch 179, Batch 36, Loss: 0.101\n",
      "Training: Epoch 179, Batch 37, Loss: 0.084\n",
      "Training: Epoch 179, Batch 38, Loss: 0.099\n",
      "Training: Epoch 179, Batch 39, Loss: 0.077\n",
      "Training: Epoch 179, Batch 40, Loss: 0.094\n",
      "Training: Epoch 179, Batch 41, Loss: 0.066\n",
      "Training: Epoch 179, Batch 42, Loss: 0.073\n",
      "Training: Epoch 179, Batch 43, Loss: 0.065\n",
      "Training: Epoch 179, Batch 44, Loss: 0.075\n",
      "Training: Epoch 179, Batch 45, Loss: 0.073\n",
      "Training: Epoch 179, Batch 46, Loss: 0.093\n",
      "Training: Epoch 179, Batch 47, Loss: 0.066\n",
      "Training: Epoch 179, Batch 48, Loss: 0.078\n",
      "Training: Epoch 179, Batch 49, Loss: 0.073\n",
      "Training: Epoch 179, Batch 50, Loss: 0.081\n",
      "Training: Epoch 179, Batch 51, Loss: 0.086\n",
      "Training: Epoch 179, Batch 52, Loss: 0.074\n",
      "Training: Epoch 179, Batch 53, Loss: 0.091\n",
      "Training: Epoch 179, Batch 54, Loss: 0.089\n",
      "Training: Epoch 179, Batch 55, Loss: 0.081\n",
      "Training: Epoch 179, Batch 56, Loss: 0.092\n",
      "Training: Epoch 179, Batch 57, Loss: 0.097\n",
      "Training: Epoch 179, Batch 58, Loss: 0.062\n",
      "Training: Epoch 179, Batch 59, Loss: 0.067\n",
      "Training: Epoch 179, Batch 60, Loss: 0.089\n",
      "Training: Epoch 179, Batch 61, Loss: 0.079\n",
      "Training: Epoch 179, Batch 62, Loss: 0.071\n",
      "Training: Epoch 179, Batch 63, Loss: 0.082\n",
      "Training: Epoch 179, Batch 64, Loss: 0.082\n",
      "Training: Epoch 179, Batch 65, Loss: 0.091\n",
      "Training: Epoch 179, Batch 66, Loss: 0.073\n",
      "Training: Epoch 179, Batch 67, Loss: 0.075\n",
      "Training: Epoch 179, Batch 68, Loss: 0.087\n",
      "Training: Epoch 179, Batch 69, Loss: 0.107\n",
      "Training: Epoch 179, Batch 70, Loss: 0.067\n",
      "Training: Epoch 179, Batch 71, Loss: 0.069\n",
      "Training: Epoch 179, Batch 72, Loss: 0.102\n",
      "Training: Epoch 179, Batch 73, Loss: 0.067\n",
      "Training: Epoch 179, Batch 74, Loss: 0.083\n",
      "Training: Epoch 179, Batch 75, Loss: 0.087\n",
      "Training: Epoch 179, Batch 76, Loss: 0.127\n",
      "Training: Epoch 179, Batch 77, Loss: 0.086\n",
      "Training: Epoch 179, Batch 78, Loss: 0.086\n",
      "Training: Epoch 179, Batch 79, Loss: 0.096\n",
      "Training: Epoch 179, Batch 80, Loss: 0.083\n",
      "Training: Epoch 179, Batch 81, Loss: 0.092\n",
      "Training: Epoch 179, Batch 82, Loss: 0.095\n",
      "Training: Epoch 179, Batch 83, Loss: 0.08\n",
      "Training: Epoch 179, Batch 84, Loss: 0.126\n",
      "Training: Epoch 179, Batch 85, Loss: 0.081\n",
      "Training: Epoch 179, Batch 86, Loss: 0.073\n",
      "Training: Epoch 179, Batch 87, Loss: 0.086\n",
      "Training: Epoch 179, Batch 88, Loss: 0.083\n",
      "Training: Epoch 179, Batch 89, Loss: 0.088\n",
      "Val: Epoch 179, Loss: 0.349\n",
      "Training: Epoch 180, Batch 0, Loss: 0.095\n",
      "Training: Epoch 180, Batch 1, Loss: 0.065\n",
      "Training: Epoch 180, Batch 2, Loss: 0.074\n",
      "Training: Epoch 180, Batch 3, Loss: 0.074\n",
      "Training: Epoch 180, Batch 4, Loss: 0.071\n",
      "Training: Epoch 180, Batch 5, Loss: 0.096\n",
      "Training: Epoch 180, Batch 6, Loss: 0.117\n",
      "Training: Epoch 180, Batch 7, Loss: 0.069\n",
      "Training: Epoch 180, Batch 8, Loss: 0.09\n",
      "Training: Epoch 180, Batch 9, Loss: 0.099\n",
      "Training: Epoch 180, Batch 10, Loss: 0.07\n",
      "Training: Epoch 180, Batch 11, Loss: 0.086\n",
      "Training: Epoch 180, Batch 12, Loss: 0.094\n",
      "Training: Epoch 180, Batch 13, Loss: 0.068\n",
      "Training: Epoch 180, Batch 14, Loss: 0.1\n",
      "Training: Epoch 180, Batch 15, Loss: 0.101\n",
      "Training: Epoch 180, Batch 16, Loss: 0.104\n",
      "Training: Epoch 180, Batch 17, Loss: 0.095\n",
      "Training: Epoch 180, Batch 18, Loss: 0.086\n",
      "Training: Epoch 180, Batch 19, Loss: 0.091\n",
      "Training: Epoch 180, Batch 20, Loss: 0.07\n",
      "Training: Epoch 180, Batch 21, Loss: 0.078\n",
      "Training: Epoch 180, Batch 22, Loss: 0.128\n",
      "Training: Epoch 180, Batch 23, Loss: 0.097\n",
      "Training: Epoch 180, Batch 24, Loss: 0.092\n",
      "Training: Epoch 180, Batch 25, Loss: 0.122\n",
      "Training: Epoch 180, Batch 26, Loss: 0.095\n",
      "Training: Epoch 180, Batch 27, Loss: 0.107\n",
      "Training: Epoch 180, Batch 28, Loss: 0.07\n",
      "Training: Epoch 180, Batch 29, Loss: 0.098\n",
      "Training: Epoch 180, Batch 30, Loss: 0.069\n",
      "Training: Epoch 180, Batch 31, Loss: 0.053\n",
      "Training: Epoch 180, Batch 32, Loss: 0.084\n",
      "Training: Epoch 180, Batch 33, Loss: 0.078\n",
      "Training: Epoch 180, Batch 34, Loss: 0.069\n",
      "Training: Epoch 180, Batch 35, Loss: 0.082\n",
      "Training: Epoch 180, Batch 36, Loss: 0.072\n",
      "Training: Epoch 180, Batch 37, Loss: 0.085\n",
      "Training: Epoch 180, Batch 38, Loss: 0.095\n",
      "Training: Epoch 180, Batch 39, Loss: 0.092\n",
      "Training: Epoch 180, Batch 40, Loss: 0.073\n",
      "Training: Epoch 180, Batch 41, Loss: 0.111\n",
      "Training: Epoch 180, Batch 42, Loss: 0.108\n",
      "Training: Epoch 180, Batch 43, Loss: 0.104\n",
      "Training: Epoch 180, Batch 44, Loss: 0.088\n",
      "Training: Epoch 180, Batch 45, Loss: 0.07\n",
      "Training: Epoch 180, Batch 46, Loss: 0.094\n",
      "Training: Epoch 180, Batch 47, Loss: 0.093\n",
      "Training: Epoch 180, Batch 48, Loss: 0.072\n",
      "Training: Epoch 180, Batch 49, Loss: 0.083\n",
      "Training: Epoch 180, Batch 50, Loss: 0.079\n",
      "Training: Epoch 180, Batch 51, Loss: 0.079\n",
      "Training: Epoch 180, Batch 52, Loss: 0.095\n",
      "Training: Epoch 180, Batch 53, Loss: 0.082\n",
      "Training: Epoch 180, Batch 54, Loss: 0.088\n",
      "Training: Epoch 180, Batch 55, Loss: 0.076\n",
      "Training: Epoch 180, Batch 56, Loss: 0.068\n",
      "Training: Epoch 180, Batch 57, Loss: 0.109\n",
      "Training: Epoch 180, Batch 58, Loss: 0.094\n",
      "Training: Epoch 180, Batch 59, Loss: 0.087\n",
      "Training: Epoch 180, Batch 60, Loss: 0.074\n",
      "Training: Epoch 180, Batch 61, Loss: 0.067\n",
      "Training: Epoch 180, Batch 62, Loss: 0.069\n",
      "Training: Epoch 180, Batch 63, Loss: 0.074\n",
      "Training: Epoch 180, Batch 64, Loss: 0.089\n",
      "Training: Epoch 180, Batch 65, Loss: 0.089\n",
      "Training: Epoch 180, Batch 66, Loss: 0.094\n",
      "Training: Epoch 180, Batch 67, Loss: 0.07\n",
      "Training: Epoch 180, Batch 68, Loss: 0.094\n",
      "Training: Epoch 180, Batch 69, Loss: 0.085\n",
      "Training: Epoch 180, Batch 70, Loss: 0.064\n",
      "Training: Epoch 180, Batch 71, Loss: 0.091\n",
      "Training: Epoch 180, Batch 72, Loss: 0.103\n",
      "Training: Epoch 180, Batch 73, Loss: 0.091\n",
      "Training: Epoch 180, Batch 74, Loss: 0.087\n",
      "Training: Epoch 180, Batch 75, Loss: 0.089\n",
      "Training: Epoch 180, Batch 76, Loss: 0.104\n",
      "Training: Epoch 180, Batch 77, Loss: 0.084\n",
      "Training: Epoch 180, Batch 78, Loss: 0.065\n",
      "Training: Epoch 180, Batch 79, Loss: 0.088\n",
      "Training: Epoch 180, Batch 80, Loss: 0.092\n",
      "Training: Epoch 180, Batch 81, Loss: 0.081\n",
      "Training: Epoch 180, Batch 82, Loss: 0.061\n",
      "Training: Epoch 180, Batch 83, Loss: 0.086\n",
      "Training: Epoch 180, Batch 84, Loss: 0.056\n",
      "Training: Epoch 180, Batch 85, Loss: 0.077\n",
      "Training: Epoch 180, Batch 86, Loss: 0.094\n",
      "Training: Epoch 180, Batch 87, Loss: 0.046\n",
      "Training: Epoch 180, Batch 88, Loss: 0.098\n",
      "Training: Epoch 180, Batch 89, Loss: 0.067\n",
      "Val: Epoch 180, Loss: 0.358\n",
      "Training: Epoch 181, Batch 0, Loss: 0.108\n",
      "Training: Epoch 181, Batch 1, Loss: 0.067\n",
      "Training: Epoch 181, Batch 2, Loss: 0.062\n",
      "Training: Epoch 181, Batch 3, Loss: 0.082\n",
      "Training: Epoch 181, Batch 4, Loss: 0.106\n",
      "Training: Epoch 181, Batch 5, Loss: 0.079\n",
      "Training: Epoch 181, Batch 6, Loss: 0.082\n",
      "Training: Epoch 181, Batch 7, Loss: 0.053\n",
      "Training: Epoch 181, Batch 8, Loss: 0.075\n",
      "Training: Epoch 181, Batch 9, Loss: 0.074\n",
      "Training: Epoch 181, Batch 10, Loss: 0.084\n",
      "Training: Epoch 181, Batch 11, Loss: 0.079\n",
      "Training: Epoch 181, Batch 12, Loss: 0.108\n",
      "Training: Epoch 181, Batch 13, Loss: 0.078\n",
      "Training: Epoch 181, Batch 14, Loss: 0.057\n",
      "Training: Epoch 181, Batch 15, Loss: 0.05\n",
      "Training: Epoch 181, Batch 16, Loss: 0.109\n",
      "Training: Epoch 181, Batch 17, Loss: 0.127\n",
      "Training: Epoch 181, Batch 18, Loss: 0.082\n",
      "Training: Epoch 181, Batch 19, Loss: 0.075\n",
      "Training: Epoch 181, Batch 20, Loss: 0.086\n",
      "Training: Epoch 181, Batch 21, Loss: 0.081\n",
      "Training: Epoch 181, Batch 22, Loss: 0.113\n",
      "Training: Epoch 181, Batch 23, Loss: 0.096\n",
      "Training: Epoch 181, Batch 24, Loss: 0.068\n",
      "Training: Epoch 181, Batch 25, Loss: 0.063\n",
      "Training: Epoch 181, Batch 26, Loss: 0.069\n",
      "Training: Epoch 181, Batch 27, Loss: 0.075\n",
      "Training: Epoch 181, Batch 28, Loss: 0.096\n",
      "Training: Epoch 181, Batch 29, Loss: 0.079\n",
      "Training: Epoch 181, Batch 30, Loss: 0.092\n",
      "Training: Epoch 181, Batch 31, Loss: 0.109\n",
      "Training: Epoch 181, Batch 32, Loss: 0.071\n",
      "Training: Epoch 181, Batch 33, Loss: 0.069\n",
      "Training: Epoch 181, Batch 34, Loss: 0.082\n",
      "Training: Epoch 181, Batch 35, Loss: 0.104\n",
      "Training: Epoch 181, Batch 36, Loss: 0.091\n",
      "Training: Epoch 181, Batch 37, Loss: 0.079\n",
      "Training: Epoch 181, Batch 38, Loss: 0.088\n",
      "Training: Epoch 181, Batch 39, Loss: 0.118\n",
      "Training: Epoch 181, Batch 40, Loss: 0.059\n",
      "Training: Epoch 181, Batch 41, Loss: 0.064\n",
      "Training: Epoch 181, Batch 42, Loss: 0.081\n",
      "Training: Epoch 181, Batch 43, Loss: 0.118\n",
      "Training: Epoch 181, Batch 44, Loss: 0.073\n",
      "Training: Epoch 181, Batch 45, Loss: 0.082\n",
      "Training: Epoch 181, Batch 46, Loss: 0.087\n",
      "Training: Epoch 181, Batch 47, Loss: 0.084\n",
      "Training: Epoch 181, Batch 48, Loss: 0.089\n",
      "Training: Epoch 181, Batch 49, Loss: 0.067\n",
      "Training: Epoch 181, Batch 50, Loss: 0.094\n",
      "Training: Epoch 181, Batch 51, Loss: 0.084\n",
      "Training: Epoch 181, Batch 52, Loss: 0.075\n",
      "Training: Epoch 181, Batch 53, Loss: 0.077\n",
      "Training: Epoch 181, Batch 54, Loss: 0.065\n",
      "Training: Epoch 181, Batch 55, Loss: 0.077\n",
      "Training: Epoch 181, Batch 56, Loss: 0.096\n",
      "Training: Epoch 181, Batch 57, Loss: 0.092\n",
      "Training: Epoch 181, Batch 58, Loss: 0.084\n",
      "Training: Epoch 181, Batch 59, Loss: 0.101\n",
      "Training: Epoch 181, Batch 60, Loss: 0.082\n",
      "Training: Epoch 181, Batch 61, Loss: 0.073\n",
      "Training: Epoch 181, Batch 62, Loss: 0.073\n",
      "Training: Epoch 181, Batch 63, Loss: 0.07\n",
      "Training: Epoch 181, Batch 64, Loss: 0.069\n",
      "Training: Epoch 181, Batch 65, Loss: 0.076\n",
      "Training: Epoch 181, Batch 66, Loss: 0.082\n",
      "Training: Epoch 181, Batch 67, Loss: 0.085\n",
      "Training: Epoch 181, Batch 68, Loss: 0.079\n",
      "Training: Epoch 181, Batch 69, Loss: 0.118\n",
      "Training: Epoch 181, Batch 70, Loss: 0.086\n",
      "Training: Epoch 181, Batch 71, Loss: 0.092\n",
      "Training: Epoch 181, Batch 72, Loss: 0.072\n",
      "Training: Epoch 181, Batch 73, Loss: 0.095\n",
      "Training: Epoch 181, Batch 74, Loss: 0.064\n",
      "Training: Epoch 181, Batch 75, Loss: 0.08\n",
      "Training: Epoch 181, Batch 76, Loss: 0.115\n",
      "Training: Epoch 181, Batch 77, Loss: 0.085\n",
      "Training: Epoch 181, Batch 78, Loss: 0.094\n",
      "Training: Epoch 181, Batch 79, Loss: 0.055\n",
      "Training: Epoch 181, Batch 80, Loss: 0.075\n",
      "Training: Epoch 181, Batch 81, Loss: 0.132\n",
      "Training: Epoch 181, Batch 82, Loss: 0.071\n",
      "Training: Epoch 181, Batch 83, Loss: 0.102\n",
      "Training: Epoch 181, Batch 84, Loss: 0.083\n",
      "Training: Epoch 181, Batch 85, Loss: 0.089\n",
      "Training: Epoch 181, Batch 86, Loss: 0.106\n",
      "Training: Epoch 181, Batch 87, Loss: 0.095\n",
      "Training: Epoch 181, Batch 88, Loss: 0.123\n",
      "Training: Epoch 181, Batch 89, Loss: 0.073\n",
      "Val: Epoch 181, Loss: 0.339\n",
      "Training: Epoch 182, Batch 0, Loss: 0.097\n",
      "Training: Epoch 182, Batch 1, Loss: 0.088\n",
      "Training: Epoch 182, Batch 2, Loss: 0.06\n",
      "Training: Epoch 182, Batch 3, Loss: 0.072\n",
      "Training: Epoch 182, Batch 4, Loss: 0.079\n",
      "Training: Epoch 182, Batch 5, Loss: 0.097\n",
      "Training: Epoch 182, Batch 6, Loss: 0.095\n",
      "Training: Epoch 182, Batch 7, Loss: 0.089\n",
      "Training: Epoch 182, Batch 8, Loss: 0.068\n",
      "Training: Epoch 182, Batch 9, Loss: 0.077\n",
      "Training: Epoch 182, Batch 10, Loss: 0.085\n",
      "Training: Epoch 182, Batch 11, Loss: 0.077\n",
      "Training: Epoch 182, Batch 12, Loss: 0.076\n",
      "Training: Epoch 182, Batch 13, Loss: 0.105\n",
      "Training: Epoch 182, Batch 14, Loss: 0.075\n",
      "Training: Epoch 182, Batch 15, Loss: 0.074\n",
      "Training: Epoch 182, Batch 16, Loss: 0.06\n",
      "Training: Epoch 182, Batch 17, Loss: 0.084\n",
      "Training: Epoch 182, Batch 18, Loss: 0.116\n",
      "Training: Epoch 182, Batch 19, Loss: 0.097\n",
      "Training: Epoch 182, Batch 20, Loss: 0.096\n",
      "Training: Epoch 182, Batch 21, Loss: 0.076\n",
      "Training: Epoch 182, Batch 22, Loss: 0.096\n",
      "Training: Epoch 182, Batch 23, Loss: 0.071\n",
      "Training: Epoch 182, Batch 24, Loss: 0.089\n",
      "Training: Epoch 182, Batch 25, Loss: 0.061\n",
      "Training: Epoch 182, Batch 26, Loss: 0.068\n",
      "Training: Epoch 182, Batch 27, Loss: 0.08\n",
      "Training: Epoch 182, Batch 28, Loss: 0.109\n",
      "Training: Epoch 182, Batch 29, Loss: 0.071\n",
      "Training: Epoch 182, Batch 30, Loss: 0.082\n",
      "Training: Epoch 182, Batch 31, Loss: 0.074\n",
      "Training: Epoch 182, Batch 32, Loss: 0.111\n",
      "Training: Epoch 182, Batch 33, Loss: 0.083\n",
      "Training: Epoch 182, Batch 34, Loss: 0.083\n",
      "Training: Epoch 182, Batch 35, Loss: 0.081\n",
      "Training: Epoch 182, Batch 36, Loss: 0.101\n",
      "Training: Epoch 182, Batch 37, Loss: 0.06\n",
      "Training: Epoch 182, Batch 38, Loss: 0.1\n",
      "Training: Epoch 182, Batch 39, Loss: 0.096\n",
      "Training: Epoch 182, Batch 40, Loss: 0.084\n",
      "Training: Epoch 182, Batch 41, Loss: 0.082\n",
      "Training: Epoch 182, Batch 42, Loss: 0.07\n",
      "Training: Epoch 182, Batch 43, Loss: 0.096\n",
      "Training: Epoch 182, Batch 44, Loss: 0.094\n",
      "Training: Epoch 182, Batch 45, Loss: 0.065\n",
      "Training: Epoch 182, Batch 46, Loss: 0.104\n",
      "Training: Epoch 182, Batch 47, Loss: 0.104\n",
      "Training: Epoch 182, Batch 48, Loss: 0.094\n",
      "Training: Epoch 182, Batch 49, Loss: 0.075\n",
      "Training: Epoch 182, Batch 50, Loss: 0.106\n",
      "Training: Epoch 182, Batch 51, Loss: 0.071\n",
      "Training: Epoch 182, Batch 52, Loss: 0.071\n",
      "Training: Epoch 182, Batch 53, Loss: 0.072\n",
      "Training: Epoch 182, Batch 54, Loss: 0.092\n",
      "Training: Epoch 182, Batch 55, Loss: 0.156\n",
      "Training: Epoch 182, Batch 56, Loss: 0.101\n",
      "Training: Epoch 182, Batch 57, Loss: 0.069\n",
      "Training: Epoch 182, Batch 58, Loss: 0.083\n",
      "Training: Epoch 182, Batch 59, Loss: 0.084\n",
      "Training: Epoch 182, Batch 60, Loss: 0.079\n",
      "Training: Epoch 182, Batch 61, Loss: 0.089\n",
      "Training: Epoch 182, Batch 62, Loss: 0.067\n",
      "Training: Epoch 182, Batch 63, Loss: 0.085\n",
      "Training: Epoch 182, Batch 64, Loss: 0.074\n",
      "Training: Epoch 182, Batch 65, Loss: 0.07\n",
      "Training: Epoch 182, Batch 66, Loss: 0.104\n",
      "Training: Epoch 182, Batch 67, Loss: 0.082\n",
      "Training: Epoch 182, Batch 68, Loss: 0.076\n",
      "Training: Epoch 182, Batch 69, Loss: 0.097\n",
      "Training: Epoch 182, Batch 70, Loss: 0.082\n",
      "Training: Epoch 182, Batch 71, Loss: 0.09\n",
      "Training: Epoch 182, Batch 72, Loss: 0.099\n",
      "Training: Epoch 182, Batch 73, Loss: 0.099\n",
      "Training: Epoch 182, Batch 74, Loss: 0.078\n",
      "Training: Epoch 182, Batch 75, Loss: 0.089\n",
      "Training: Epoch 182, Batch 76, Loss: 0.089\n",
      "Training: Epoch 182, Batch 77, Loss: 0.069\n",
      "Training: Epoch 182, Batch 78, Loss: 0.117\n",
      "Training: Epoch 182, Batch 79, Loss: 0.095\n",
      "Training: Epoch 182, Batch 80, Loss: 0.091\n",
      "Training: Epoch 182, Batch 81, Loss: 0.081\n",
      "Training: Epoch 182, Batch 82, Loss: 0.106\n",
      "Training: Epoch 182, Batch 83, Loss: 0.073\n",
      "Training: Epoch 182, Batch 84, Loss: 0.084\n",
      "Training: Epoch 182, Batch 85, Loss: 0.102\n",
      "Training: Epoch 182, Batch 86, Loss: 0.098\n",
      "Training: Epoch 182, Batch 87, Loss: 0.088\n",
      "Training: Epoch 182, Batch 88, Loss: 0.101\n",
      "Training: Epoch 182, Batch 89, Loss: 0.106\n",
      "Val: Epoch 182, Loss: 0.352\n",
      "Training: Epoch 183, Batch 0, Loss: 0.09\n",
      "Training: Epoch 183, Batch 1, Loss: 0.076\n",
      "Training: Epoch 183, Batch 2, Loss: 0.071\n",
      "Training: Epoch 183, Batch 3, Loss: 0.076\n",
      "Training: Epoch 183, Batch 4, Loss: 0.133\n",
      "Training: Epoch 183, Batch 5, Loss: 0.092\n",
      "Training: Epoch 183, Batch 6, Loss: 0.08\n",
      "Training: Epoch 183, Batch 7, Loss: 0.071\n",
      "Training: Epoch 183, Batch 8, Loss: 0.086\n",
      "Training: Epoch 183, Batch 9, Loss: 0.1\n",
      "Training: Epoch 183, Batch 10, Loss: 0.064\n",
      "Training: Epoch 183, Batch 11, Loss: 0.092\n",
      "Training: Epoch 183, Batch 12, Loss: 0.121\n",
      "Training: Epoch 183, Batch 13, Loss: 0.082\n",
      "Training: Epoch 183, Batch 14, Loss: 0.098\n",
      "Training: Epoch 183, Batch 15, Loss: 0.097\n",
      "Training: Epoch 183, Batch 16, Loss: 0.084\n",
      "Training: Epoch 183, Batch 17, Loss: 0.068\n",
      "Training: Epoch 183, Batch 18, Loss: 0.064\n",
      "Training: Epoch 183, Batch 19, Loss: 0.121\n",
      "Training: Epoch 183, Batch 20, Loss: 0.072\n",
      "Training: Epoch 183, Batch 21, Loss: 0.074\n",
      "Training: Epoch 183, Batch 22, Loss: 0.081\n",
      "Training: Epoch 183, Batch 23, Loss: 0.089\n",
      "Training: Epoch 183, Batch 24, Loss: 0.06\n",
      "Training: Epoch 183, Batch 25, Loss: 0.097\n",
      "Training: Epoch 183, Batch 26, Loss: 0.078\n",
      "Training: Epoch 183, Batch 27, Loss: 0.117\n",
      "Training: Epoch 183, Batch 28, Loss: 0.071\n",
      "Training: Epoch 183, Batch 29, Loss: 0.087\n",
      "Training: Epoch 183, Batch 30, Loss: 0.099\n",
      "Training: Epoch 183, Batch 31, Loss: 0.089\n",
      "Training: Epoch 183, Batch 32, Loss: 0.112\n",
      "Training: Epoch 183, Batch 33, Loss: 0.07\n",
      "Training: Epoch 183, Batch 34, Loss: 0.082\n",
      "Training: Epoch 183, Batch 35, Loss: 0.054\n",
      "Training: Epoch 183, Batch 36, Loss: 0.082\n",
      "Training: Epoch 183, Batch 37, Loss: 0.076\n",
      "Training: Epoch 183, Batch 38, Loss: 0.097\n",
      "Training: Epoch 183, Batch 39, Loss: 0.105\n",
      "Training: Epoch 183, Batch 40, Loss: 0.101\n",
      "Training: Epoch 183, Batch 41, Loss: 0.064\n",
      "Training: Epoch 183, Batch 42, Loss: 0.074\n",
      "Training: Epoch 183, Batch 43, Loss: 0.091\n",
      "Training: Epoch 183, Batch 44, Loss: 0.072\n",
      "Training: Epoch 183, Batch 45, Loss: 0.089\n",
      "Training: Epoch 183, Batch 46, Loss: 0.068\n",
      "Training: Epoch 183, Batch 47, Loss: 0.112\n",
      "Training: Epoch 183, Batch 48, Loss: 0.079\n",
      "Training: Epoch 183, Batch 49, Loss: 0.054\n",
      "Training: Epoch 183, Batch 50, Loss: 0.071\n",
      "Training: Epoch 183, Batch 51, Loss: 0.073\n",
      "Training: Epoch 183, Batch 52, Loss: 0.067\n",
      "Training: Epoch 183, Batch 53, Loss: 0.094\n",
      "Training: Epoch 183, Batch 54, Loss: 0.093\n",
      "Training: Epoch 183, Batch 55, Loss: 0.079\n",
      "Training: Epoch 183, Batch 56, Loss: 0.098\n",
      "Training: Epoch 183, Batch 57, Loss: 0.121\n",
      "Training: Epoch 183, Batch 58, Loss: 0.078\n",
      "Training: Epoch 183, Batch 59, Loss: 0.091\n",
      "Training: Epoch 183, Batch 60, Loss: 0.088\n",
      "Training: Epoch 183, Batch 61, Loss: 0.064\n",
      "Training: Epoch 183, Batch 62, Loss: 0.102\n",
      "Training: Epoch 183, Batch 63, Loss: 0.063\n",
      "Training: Epoch 183, Batch 64, Loss: 0.096\n",
      "Training: Epoch 183, Batch 65, Loss: 0.098\n",
      "Training: Epoch 183, Batch 66, Loss: 0.095\n",
      "Training: Epoch 183, Batch 67, Loss: 0.078\n",
      "Training: Epoch 183, Batch 68, Loss: 0.097\n",
      "Training: Epoch 183, Batch 69, Loss: 0.067\n",
      "Training: Epoch 183, Batch 70, Loss: 0.07\n",
      "Training: Epoch 183, Batch 71, Loss: 0.081\n",
      "Training: Epoch 183, Batch 72, Loss: 0.096\n",
      "Training: Epoch 183, Batch 73, Loss: 0.063\n",
      "Training: Epoch 183, Batch 74, Loss: 0.067\n",
      "Training: Epoch 183, Batch 75, Loss: 0.1\n",
      "Training: Epoch 183, Batch 76, Loss: 0.095\n",
      "Training: Epoch 183, Batch 77, Loss: 0.088\n",
      "Training: Epoch 183, Batch 78, Loss: 0.066\n",
      "Training: Epoch 183, Batch 79, Loss: 0.078\n",
      "Training: Epoch 183, Batch 80, Loss: 0.078\n",
      "Training: Epoch 183, Batch 81, Loss: 0.097\n",
      "Training: Epoch 183, Batch 82, Loss: 0.081\n",
      "Training: Epoch 183, Batch 83, Loss: 0.063\n",
      "Training: Epoch 183, Batch 84, Loss: 0.076\n",
      "Training: Epoch 183, Batch 85, Loss: 0.062\n",
      "Training: Epoch 183, Batch 86, Loss: 0.084\n",
      "Training: Epoch 183, Batch 87, Loss: 0.098\n",
      "Training: Epoch 183, Batch 88, Loss: 0.087\n",
      "Training: Epoch 183, Batch 89, Loss: 0.11\n",
      "Val: Epoch 183, Loss: 0.347\n",
      "Training: Epoch 184, Batch 0, Loss: 0.092\n",
      "Training: Epoch 184, Batch 1, Loss: 0.073\n",
      "Training: Epoch 184, Batch 2, Loss: 0.08\n",
      "Training: Epoch 184, Batch 3, Loss: 0.091\n",
      "Training: Epoch 184, Batch 4, Loss: 0.066\n",
      "Training: Epoch 184, Batch 5, Loss: 0.06\n",
      "Training: Epoch 184, Batch 6, Loss: 0.093\n",
      "Training: Epoch 184, Batch 7, Loss: 0.061\n",
      "Training: Epoch 184, Batch 8, Loss: 0.065\n",
      "Training: Epoch 184, Batch 9, Loss: 0.094\n",
      "Training: Epoch 184, Batch 10, Loss: 0.089\n",
      "Training: Epoch 184, Batch 11, Loss: 0.07\n",
      "Training: Epoch 184, Batch 12, Loss: 0.122\n",
      "Training: Epoch 184, Batch 13, Loss: 0.093\n",
      "Training: Epoch 184, Batch 14, Loss: 0.08\n",
      "Training: Epoch 184, Batch 15, Loss: 0.078\n",
      "Training: Epoch 184, Batch 16, Loss: 0.076\n",
      "Training: Epoch 184, Batch 17, Loss: 0.104\n",
      "Training: Epoch 184, Batch 18, Loss: 0.1\n",
      "Training: Epoch 184, Batch 19, Loss: 0.098\n",
      "Training: Epoch 184, Batch 20, Loss: 0.058\n",
      "Training: Epoch 184, Batch 21, Loss: 0.112\n",
      "Training: Epoch 184, Batch 22, Loss: 0.079\n",
      "Training: Epoch 184, Batch 23, Loss: 0.095\n",
      "Training: Epoch 184, Batch 24, Loss: 0.081\n",
      "Training: Epoch 184, Batch 25, Loss: 0.068\n",
      "Training: Epoch 184, Batch 26, Loss: 0.081\n",
      "Training: Epoch 184, Batch 27, Loss: 0.093\n",
      "Training: Epoch 184, Batch 28, Loss: 0.091\n",
      "Training: Epoch 184, Batch 29, Loss: 0.113\n",
      "Training: Epoch 184, Batch 30, Loss: 0.078\n",
      "Training: Epoch 184, Batch 31, Loss: 0.087\n",
      "Training: Epoch 184, Batch 32, Loss: 0.079\n",
      "Training: Epoch 184, Batch 33, Loss: 0.086\n",
      "Training: Epoch 184, Batch 34, Loss: 0.096\n",
      "Training: Epoch 184, Batch 35, Loss: 0.071\n",
      "Training: Epoch 184, Batch 36, Loss: 0.078\n",
      "Training: Epoch 184, Batch 37, Loss: 0.075\n",
      "Training: Epoch 184, Batch 38, Loss: 0.066\n",
      "Training: Epoch 184, Batch 39, Loss: 0.069\n",
      "Training: Epoch 184, Batch 40, Loss: 0.074\n",
      "Training: Epoch 184, Batch 41, Loss: 0.06\n",
      "Training: Epoch 184, Batch 42, Loss: 0.079\n",
      "Training: Epoch 184, Batch 43, Loss: 0.118\n",
      "Training: Epoch 184, Batch 44, Loss: 0.063\n",
      "Training: Epoch 184, Batch 45, Loss: 0.065\n",
      "Training: Epoch 184, Batch 46, Loss: 0.095\n",
      "Training: Epoch 184, Batch 47, Loss: 0.089\n",
      "Training: Epoch 184, Batch 48, Loss: 0.087\n",
      "Training: Epoch 184, Batch 49, Loss: 0.089\n",
      "Training: Epoch 184, Batch 50, Loss: 0.088\n",
      "Training: Epoch 184, Batch 51, Loss: 0.079\n",
      "Training: Epoch 184, Batch 52, Loss: 0.139\n",
      "Training: Epoch 184, Batch 53, Loss: 0.079\n",
      "Training: Epoch 184, Batch 54, Loss: 0.084\n",
      "Training: Epoch 184, Batch 55, Loss: 0.105\n",
      "Training: Epoch 184, Batch 56, Loss: 0.074\n",
      "Training: Epoch 184, Batch 57, Loss: 0.073\n",
      "Training: Epoch 184, Batch 58, Loss: 0.084\n",
      "Training: Epoch 184, Batch 59, Loss: 0.088\n",
      "Training: Epoch 184, Batch 60, Loss: 0.089\n",
      "Training: Epoch 184, Batch 61, Loss: 0.079\n",
      "Training: Epoch 184, Batch 62, Loss: 0.084\n",
      "Training: Epoch 184, Batch 63, Loss: 0.087\n",
      "Training: Epoch 184, Batch 64, Loss: 0.085\n",
      "Training: Epoch 184, Batch 65, Loss: 0.093\n",
      "Training: Epoch 184, Batch 66, Loss: 0.064\n",
      "Training: Epoch 184, Batch 67, Loss: 0.067\n",
      "Training: Epoch 184, Batch 68, Loss: 0.063\n",
      "Training: Epoch 184, Batch 69, Loss: 0.092\n",
      "Training: Epoch 184, Batch 70, Loss: 0.103\n",
      "Training: Epoch 184, Batch 71, Loss: 0.084\n",
      "Training: Epoch 184, Batch 72, Loss: 0.089\n",
      "Training: Epoch 184, Batch 73, Loss: 0.09\n",
      "Training: Epoch 184, Batch 74, Loss: 0.076\n",
      "Training: Epoch 184, Batch 75, Loss: 0.098\n",
      "Training: Epoch 184, Batch 76, Loss: 0.119\n",
      "Training: Epoch 184, Batch 77, Loss: 0.075\n",
      "Training: Epoch 184, Batch 78, Loss: 0.129\n",
      "Training: Epoch 184, Batch 79, Loss: 0.071\n",
      "Training: Epoch 184, Batch 80, Loss: 0.093\n",
      "Training: Epoch 184, Batch 81, Loss: 0.058\n",
      "Training: Epoch 184, Batch 82, Loss: 0.071\n",
      "Training: Epoch 184, Batch 83, Loss: 0.071\n",
      "Training: Epoch 184, Batch 84, Loss: 0.076\n",
      "Training: Epoch 184, Batch 85, Loss: 0.106\n",
      "Training: Epoch 184, Batch 86, Loss: 0.084\n",
      "Training: Epoch 184, Batch 87, Loss: 0.107\n",
      "Training: Epoch 184, Batch 88, Loss: 0.081\n",
      "Training: Epoch 184, Batch 89, Loss: 0.064\n",
      "Val: Epoch 184, Loss: 0.352\n",
      "Training: Epoch 185, Batch 0, Loss: 0.07\n",
      "Training: Epoch 185, Batch 1, Loss: 0.073\n",
      "Training: Epoch 185, Batch 2, Loss: 0.083\n",
      "Training: Epoch 185, Batch 3, Loss: 0.06\n",
      "Training: Epoch 185, Batch 4, Loss: 0.118\n",
      "Training: Epoch 185, Batch 5, Loss: 0.076\n",
      "Training: Epoch 185, Batch 6, Loss: 0.072\n",
      "Training: Epoch 185, Batch 7, Loss: 0.073\n",
      "Training: Epoch 185, Batch 8, Loss: 0.092\n",
      "Training: Epoch 185, Batch 9, Loss: 0.091\n",
      "Training: Epoch 185, Batch 10, Loss: 0.065\n",
      "Training: Epoch 185, Batch 11, Loss: 0.064\n",
      "Training: Epoch 185, Batch 12, Loss: 0.085\n",
      "Training: Epoch 185, Batch 13, Loss: 0.086\n",
      "Training: Epoch 185, Batch 14, Loss: 0.092\n",
      "Training: Epoch 185, Batch 15, Loss: 0.102\n",
      "Training: Epoch 185, Batch 16, Loss: 0.081\n",
      "Training: Epoch 185, Batch 17, Loss: 0.075\n",
      "Training: Epoch 185, Batch 18, Loss: 0.065\n",
      "Training: Epoch 185, Batch 19, Loss: 0.107\n",
      "Training: Epoch 185, Batch 20, Loss: 0.102\n",
      "Training: Epoch 185, Batch 21, Loss: 0.074\n",
      "Training: Epoch 185, Batch 22, Loss: 0.088\n",
      "Training: Epoch 185, Batch 23, Loss: 0.074\n",
      "Training: Epoch 185, Batch 24, Loss: 0.081\n",
      "Training: Epoch 185, Batch 25, Loss: 0.095\n",
      "Training: Epoch 185, Batch 26, Loss: 0.104\n",
      "Training: Epoch 185, Batch 27, Loss: 0.1\n",
      "Training: Epoch 185, Batch 28, Loss: 0.087\n",
      "Training: Epoch 185, Batch 29, Loss: 0.073\n",
      "Training: Epoch 185, Batch 30, Loss: 0.103\n",
      "Training: Epoch 185, Batch 31, Loss: 0.076\n",
      "Training: Epoch 185, Batch 32, Loss: 0.092\n",
      "Training: Epoch 185, Batch 33, Loss: 0.126\n",
      "Training: Epoch 185, Batch 34, Loss: 0.098\n",
      "Training: Epoch 185, Batch 35, Loss: 0.076\n",
      "Training: Epoch 185, Batch 36, Loss: 0.08\n",
      "Training: Epoch 185, Batch 37, Loss: 0.073\n",
      "Training: Epoch 185, Batch 38, Loss: 0.088\n",
      "Training: Epoch 185, Batch 39, Loss: 0.067\n",
      "Training: Epoch 185, Batch 40, Loss: 0.082\n",
      "Training: Epoch 185, Batch 41, Loss: 0.077\n",
      "Training: Epoch 185, Batch 42, Loss: 0.099\n",
      "Training: Epoch 185, Batch 43, Loss: 0.095\n",
      "Training: Epoch 185, Batch 44, Loss: 0.102\n",
      "Training: Epoch 185, Batch 45, Loss: 0.1\n",
      "Training: Epoch 185, Batch 46, Loss: 0.071\n",
      "Training: Epoch 185, Batch 47, Loss: 0.087\n",
      "Training: Epoch 185, Batch 48, Loss: 0.095\n",
      "Training: Epoch 185, Batch 49, Loss: 0.076\n",
      "Training: Epoch 185, Batch 50, Loss: 0.09\n",
      "Training: Epoch 185, Batch 51, Loss: 0.115\n",
      "Training: Epoch 185, Batch 52, Loss: 0.069\n",
      "Training: Epoch 185, Batch 53, Loss: 0.088\n",
      "Training: Epoch 185, Batch 54, Loss: 0.065\n",
      "Training: Epoch 185, Batch 55, Loss: 0.052\n",
      "Training: Epoch 185, Batch 56, Loss: 0.073\n",
      "Training: Epoch 185, Batch 57, Loss: 0.108\n",
      "Training: Epoch 185, Batch 58, Loss: 0.062\n",
      "Training: Epoch 185, Batch 59, Loss: 0.05\n",
      "Training: Epoch 185, Batch 60, Loss: 0.075\n",
      "Training: Epoch 185, Batch 61, Loss: 0.062\n",
      "Training: Epoch 185, Batch 62, Loss: 0.088\n",
      "Training: Epoch 185, Batch 63, Loss: 0.083\n",
      "Training: Epoch 185, Batch 64, Loss: 0.07\n",
      "Training: Epoch 185, Batch 65, Loss: 0.099\n",
      "Training: Epoch 185, Batch 66, Loss: 0.071\n",
      "Training: Epoch 185, Batch 67, Loss: 0.083\n",
      "Training: Epoch 185, Batch 68, Loss: 0.061\n",
      "Training: Epoch 185, Batch 69, Loss: 0.081\n",
      "Training: Epoch 185, Batch 70, Loss: 0.088\n",
      "Training: Epoch 185, Batch 71, Loss: 0.113\n",
      "Training: Epoch 185, Batch 72, Loss: 0.076\n",
      "Training: Epoch 185, Batch 73, Loss: 0.056\n",
      "Training: Epoch 185, Batch 74, Loss: 0.09\n",
      "Training: Epoch 185, Batch 75, Loss: 0.083\n",
      "Training: Epoch 185, Batch 76, Loss: 0.06\n",
      "Training: Epoch 185, Batch 77, Loss: 0.094\n",
      "Training: Epoch 185, Batch 78, Loss: 0.1\n",
      "Training: Epoch 185, Batch 79, Loss: 0.097\n",
      "Training: Epoch 185, Batch 80, Loss: 0.066\n",
      "Training: Epoch 185, Batch 81, Loss: 0.083\n",
      "Training: Epoch 185, Batch 82, Loss: 0.082\n",
      "Training: Epoch 185, Batch 83, Loss: 0.085\n",
      "Training: Epoch 185, Batch 84, Loss: 0.084\n",
      "Training: Epoch 185, Batch 85, Loss: 0.064\n",
      "Training: Epoch 185, Batch 86, Loss: 0.081\n",
      "Training: Epoch 185, Batch 87, Loss: 0.088\n",
      "Training: Epoch 185, Batch 88, Loss: 0.105\n",
      "Training: Epoch 185, Batch 89, Loss: 0.095\n",
      "Val: Epoch 185, Loss: 0.349\n",
      "Training: Epoch 186, Batch 0, Loss: 0.095\n",
      "Training: Epoch 186, Batch 1, Loss: 0.052\n",
      "Training: Epoch 186, Batch 2, Loss: 0.066\n",
      "Training: Epoch 186, Batch 3, Loss: 0.081\n",
      "Training: Epoch 186, Batch 4, Loss: 0.093\n",
      "Training: Epoch 186, Batch 5, Loss: 0.086\n",
      "Training: Epoch 186, Batch 6, Loss: 0.087\n",
      "Training: Epoch 186, Batch 7, Loss: 0.082\n",
      "Training: Epoch 186, Batch 8, Loss: 0.083\n",
      "Training: Epoch 186, Batch 9, Loss: 0.104\n",
      "Training: Epoch 186, Batch 10, Loss: 0.087\n",
      "Training: Epoch 186, Batch 11, Loss: 0.086\n",
      "Training: Epoch 186, Batch 12, Loss: 0.068\n",
      "Training: Epoch 186, Batch 13, Loss: 0.1\n",
      "Training: Epoch 186, Batch 14, Loss: 0.07\n",
      "Training: Epoch 186, Batch 15, Loss: 0.092\n",
      "Training: Epoch 186, Batch 16, Loss: 0.074\n",
      "Training: Epoch 186, Batch 17, Loss: 0.069\n",
      "Training: Epoch 186, Batch 18, Loss: 0.071\n",
      "Training: Epoch 186, Batch 19, Loss: 0.073\n",
      "Training: Epoch 186, Batch 20, Loss: 0.081\n",
      "Training: Epoch 186, Batch 21, Loss: 0.084\n",
      "Training: Epoch 186, Batch 22, Loss: 0.079\n",
      "Training: Epoch 186, Batch 23, Loss: 0.084\n",
      "Training: Epoch 186, Batch 24, Loss: 0.062\n",
      "Training: Epoch 186, Batch 25, Loss: 0.103\n",
      "Training: Epoch 186, Batch 26, Loss: 0.072\n",
      "Training: Epoch 186, Batch 27, Loss: 0.088\n",
      "Training: Epoch 186, Batch 28, Loss: 0.062\n",
      "Training: Epoch 186, Batch 29, Loss: 0.087\n",
      "Training: Epoch 186, Batch 30, Loss: 0.082\n",
      "Training: Epoch 186, Batch 31, Loss: 0.075\n",
      "Training: Epoch 186, Batch 32, Loss: 0.077\n",
      "Training: Epoch 186, Batch 33, Loss: 0.107\n",
      "Training: Epoch 186, Batch 34, Loss: 0.096\n",
      "Training: Epoch 186, Batch 35, Loss: 0.07\n",
      "Training: Epoch 186, Batch 36, Loss: 0.068\n",
      "Training: Epoch 186, Batch 37, Loss: 0.078\n",
      "Training: Epoch 186, Batch 38, Loss: 0.09\n",
      "Training: Epoch 186, Batch 39, Loss: 0.075\n",
      "Training: Epoch 186, Batch 40, Loss: 0.074\n",
      "Training: Epoch 186, Batch 41, Loss: 0.087\n",
      "Training: Epoch 186, Batch 42, Loss: 0.084\n",
      "Training: Epoch 186, Batch 43, Loss: 0.063\n",
      "Training: Epoch 186, Batch 44, Loss: 0.105\n",
      "Training: Epoch 186, Batch 45, Loss: 0.069\n",
      "Training: Epoch 186, Batch 46, Loss: 0.081\n",
      "Training: Epoch 186, Batch 47, Loss: 0.078\n",
      "Training: Epoch 186, Batch 48, Loss: 0.118\n",
      "Training: Epoch 186, Batch 49, Loss: 0.085\n",
      "Training: Epoch 186, Batch 50, Loss: 0.112\n",
      "Training: Epoch 186, Batch 51, Loss: 0.106\n",
      "Training: Epoch 186, Batch 52, Loss: 0.071\n",
      "Training: Epoch 186, Batch 53, Loss: 0.083\n",
      "Training: Epoch 186, Batch 54, Loss: 0.078\n",
      "Training: Epoch 186, Batch 55, Loss: 0.088\n",
      "Training: Epoch 186, Batch 56, Loss: 0.071\n",
      "Training: Epoch 186, Batch 57, Loss: 0.09\n",
      "Training: Epoch 186, Batch 58, Loss: 0.073\n",
      "Training: Epoch 186, Batch 59, Loss: 0.071\n",
      "Training: Epoch 186, Batch 60, Loss: 0.093\n",
      "Training: Epoch 186, Batch 61, Loss: 0.081\n",
      "Training: Epoch 186, Batch 62, Loss: 0.086\n",
      "Training: Epoch 186, Batch 63, Loss: 0.089\n",
      "Training: Epoch 186, Batch 64, Loss: 0.1\n",
      "Training: Epoch 186, Batch 65, Loss: 0.088\n",
      "Training: Epoch 186, Batch 66, Loss: 0.103\n",
      "Training: Epoch 186, Batch 67, Loss: 0.078\n",
      "Training: Epoch 186, Batch 68, Loss: 0.074\n",
      "Training: Epoch 186, Batch 69, Loss: 0.068\n",
      "Training: Epoch 186, Batch 70, Loss: 0.069\n",
      "Training: Epoch 186, Batch 71, Loss: 0.09\n",
      "Training: Epoch 186, Batch 72, Loss: 0.072\n",
      "Training: Epoch 186, Batch 73, Loss: 0.073\n",
      "Training: Epoch 186, Batch 74, Loss: 0.083\n",
      "Training: Epoch 186, Batch 75, Loss: 0.104\n",
      "Training: Epoch 186, Batch 76, Loss: 0.083\n",
      "Training: Epoch 186, Batch 77, Loss: 0.071\n",
      "Training: Epoch 186, Batch 78, Loss: 0.107\n",
      "Training: Epoch 186, Batch 79, Loss: 0.087\n",
      "Training: Epoch 186, Batch 80, Loss: 0.114\n",
      "Training: Epoch 186, Batch 81, Loss: 0.075\n",
      "Training: Epoch 186, Batch 82, Loss: 0.076\n",
      "Training: Epoch 186, Batch 83, Loss: 0.056\n",
      "Training: Epoch 186, Batch 84, Loss: 0.123\n",
      "Training: Epoch 186, Batch 85, Loss: 0.114\n",
      "Training: Epoch 186, Batch 86, Loss: 0.076\n",
      "Training: Epoch 186, Batch 87, Loss: 0.07\n",
      "Training: Epoch 186, Batch 88, Loss: 0.095\n",
      "Training: Epoch 186, Batch 89, Loss: 0.088\n",
      "Val: Epoch 186, Loss: 0.409\n",
      "Training: Epoch 187, Batch 0, Loss: 0.098\n",
      "Training: Epoch 187, Batch 1, Loss: 0.103\n",
      "Training: Epoch 187, Batch 2, Loss: 0.083\n",
      "Training: Epoch 187, Batch 3, Loss: 0.056\n",
      "Training: Epoch 187, Batch 4, Loss: 0.116\n",
      "Training: Epoch 187, Batch 5, Loss: 0.071\n",
      "Training: Epoch 187, Batch 6, Loss: 0.075\n",
      "Training: Epoch 187, Batch 7, Loss: 0.103\n",
      "Training: Epoch 187, Batch 8, Loss: 0.092\n",
      "Training: Epoch 187, Batch 9, Loss: 0.077\n",
      "Training: Epoch 187, Batch 10, Loss: 0.069\n",
      "Training: Epoch 187, Batch 11, Loss: 0.056\n",
      "Training: Epoch 187, Batch 12, Loss: 0.062\n",
      "Training: Epoch 187, Batch 13, Loss: 0.069\n",
      "Training: Epoch 187, Batch 14, Loss: 0.065\n",
      "Training: Epoch 187, Batch 15, Loss: 0.078\n",
      "Training: Epoch 187, Batch 16, Loss: 0.125\n",
      "Training: Epoch 187, Batch 17, Loss: 0.063\n",
      "Training: Epoch 187, Batch 18, Loss: 0.102\n",
      "Training: Epoch 187, Batch 19, Loss: 0.083\n",
      "Training: Epoch 187, Batch 20, Loss: 0.092\n",
      "Training: Epoch 187, Batch 21, Loss: 0.101\n",
      "Training: Epoch 187, Batch 22, Loss: 0.061\n",
      "Training: Epoch 187, Batch 23, Loss: 0.099\n",
      "Training: Epoch 187, Batch 24, Loss: 0.092\n",
      "Training: Epoch 187, Batch 25, Loss: 0.106\n",
      "Training: Epoch 187, Batch 26, Loss: 0.099\n",
      "Training: Epoch 187, Batch 27, Loss: 0.089\n",
      "Training: Epoch 187, Batch 28, Loss: 0.063\n",
      "Training: Epoch 187, Batch 29, Loss: 0.093\n",
      "Training: Epoch 187, Batch 30, Loss: 0.085\n",
      "Training: Epoch 187, Batch 31, Loss: 0.069\n",
      "Training: Epoch 187, Batch 32, Loss: 0.066\n",
      "Training: Epoch 187, Batch 33, Loss: 0.074\n",
      "Training: Epoch 187, Batch 34, Loss: 0.081\n",
      "Training: Epoch 187, Batch 35, Loss: 0.081\n",
      "Training: Epoch 187, Batch 36, Loss: 0.08\n",
      "Training: Epoch 187, Batch 37, Loss: 0.076\n",
      "Training: Epoch 187, Batch 38, Loss: 0.084\n",
      "Training: Epoch 187, Batch 39, Loss: 0.074\n",
      "Training: Epoch 187, Batch 40, Loss: 0.102\n",
      "Training: Epoch 187, Batch 41, Loss: 0.066\n",
      "Training: Epoch 187, Batch 42, Loss: 0.067\n",
      "Training: Epoch 187, Batch 43, Loss: 0.087\n",
      "Training: Epoch 187, Batch 44, Loss: 0.085\n",
      "Training: Epoch 187, Batch 45, Loss: 0.1\n",
      "Training: Epoch 187, Batch 46, Loss: 0.077\n",
      "Training: Epoch 187, Batch 47, Loss: 0.064\n",
      "Training: Epoch 187, Batch 48, Loss: 0.106\n",
      "Training: Epoch 187, Batch 49, Loss: 0.082\n",
      "Training: Epoch 187, Batch 50, Loss: 0.089\n",
      "Training: Epoch 187, Batch 51, Loss: 0.063\n",
      "Training: Epoch 187, Batch 52, Loss: 0.079\n",
      "Training: Epoch 187, Batch 53, Loss: 0.063\n",
      "Training: Epoch 187, Batch 54, Loss: 0.066\n",
      "Training: Epoch 187, Batch 55, Loss: 0.066\n",
      "Training: Epoch 187, Batch 56, Loss: 0.079\n",
      "Training: Epoch 187, Batch 57, Loss: 0.069\n",
      "Training: Epoch 187, Batch 58, Loss: 0.104\n",
      "Training: Epoch 187, Batch 59, Loss: 0.072\n",
      "Training: Epoch 187, Batch 60, Loss: 0.11\n",
      "Training: Epoch 187, Batch 61, Loss: 0.069\n",
      "Training: Epoch 187, Batch 62, Loss: 0.092\n",
      "Training: Epoch 187, Batch 63, Loss: 0.086\n",
      "Training: Epoch 187, Batch 64, Loss: 0.085\n",
      "Training: Epoch 187, Batch 65, Loss: 0.096\n",
      "Training: Epoch 187, Batch 66, Loss: 0.063\n",
      "Training: Epoch 187, Batch 67, Loss: 0.085\n",
      "Training: Epoch 187, Batch 68, Loss: 0.08\n",
      "Training: Epoch 187, Batch 69, Loss: 0.072\n",
      "Training: Epoch 187, Batch 70, Loss: 0.112\n",
      "Training: Epoch 187, Batch 71, Loss: 0.093\n",
      "Training: Epoch 187, Batch 72, Loss: 0.113\n",
      "Training: Epoch 187, Batch 73, Loss: 0.108\n",
      "Training: Epoch 187, Batch 74, Loss: 0.097\n",
      "Training: Epoch 187, Batch 75, Loss: 0.075\n",
      "Training: Epoch 187, Batch 76, Loss: 0.085\n",
      "Training: Epoch 187, Batch 77, Loss: 0.076\n",
      "Training: Epoch 187, Batch 78, Loss: 0.062\n",
      "Training: Epoch 187, Batch 79, Loss: 0.073\n",
      "Training: Epoch 187, Batch 80, Loss: 0.081\n",
      "Training: Epoch 187, Batch 81, Loss: 0.098\n",
      "Training: Epoch 187, Batch 82, Loss: 0.079\n",
      "Training: Epoch 187, Batch 83, Loss: 0.069\n",
      "Training: Epoch 187, Batch 84, Loss: 0.102\n",
      "Training: Epoch 187, Batch 85, Loss: 0.069\n",
      "Training: Epoch 187, Batch 86, Loss: 0.084\n",
      "Training: Epoch 187, Batch 87, Loss: 0.075\n",
      "Training: Epoch 187, Batch 88, Loss: 0.109\n",
      "Training: Epoch 187, Batch 89, Loss: 0.098\n",
      "Val: Epoch 187, Loss: 0.364\n",
      "Training: Epoch 188, Batch 0, Loss: 0.075\n",
      "Training: Epoch 188, Batch 1, Loss: 0.088\n",
      "Training: Epoch 188, Batch 2, Loss: 0.068\n",
      "Training: Epoch 188, Batch 3, Loss: 0.079\n",
      "Training: Epoch 188, Batch 4, Loss: 0.08\n",
      "Training: Epoch 188, Batch 5, Loss: 0.07\n",
      "Training: Epoch 188, Batch 6, Loss: 0.09\n",
      "Training: Epoch 188, Batch 7, Loss: 0.065\n",
      "Training: Epoch 188, Batch 8, Loss: 0.085\n",
      "Training: Epoch 188, Batch 9, Loss: 0.106\n",
      "Training: Epoch 188, Batch 10, Loss: 0.075\n",
      "Training: Epoch 188, Batch 11, Loss: 0.097\n",
      "Training: Epoch 188, Batch 12, Loss: 0.074\n",
      "Training: Epoch 188, Batch 13, Loss: 0.093\n",
      "Training: Epoch 188, Batch 14, Loss: 0.075\n",
      "Training: Epoch 188, Batch 15, Loss: 0.087\n",
      "Training: Epoch 188, Batch 16, Loss: 0.059\n",
      "Training: Epoch 188, Batch 17, Loss: 0.088\n",
      "Training: Epoch 188, Batch 18, Loss: 0.096\n",
      "Training: Epoch 188, Batch 19, Loss: 0.111\n",
      "Training: Epoch 188, Batch 20, Loss: 0.085\n",
      "Training: Epoch 188, Batch 21, Loss: 0.079\n",
      "Training: Epoch 188, Batch 22, Loss: 0.066\n",
      "Training: Epoch 188, Batch 23, Loss: 0.08\n",
      "Training: Epoch 188, Batch 24, Loss: 0.069\n",
      "Training: Epoch 188, Batch 25, Loss: 0.077\n",
      "Training: Epoch 188, Batch 26, Loss: 0.074\n",
      "Training: Epoch 188, Batch 27, Loss: 0.073\n",
      "Training: Epoch 188, Batch 28, Loss: 0.064\n",
      "Training: Epoch 188, Batch 29, Loss: 0.1\n",
      "Training: Epoch 188, Batch 30, Loss: 0.102\n",
      "Training: Epoch 188, Batch 31, Loss: 0.111\n",
      "Training: Epoch 188, Batch 32, Loss: 0.084\n",
      "Training: Epoch 188, Batch 33, Loss: 0.063\n",
      "Training: Epoch 188, Batch 34, Loss: 0.096\n",
      "Training: Epoch 188, Batch 35, Loss: 0.075\n",
      "Training: Epoch 188, Batch 36, Loss: 0.075\n",
      "Training: Epoch 188, Batch 37, Loss: 0.059\n",
      "Training: Epoch 188, Batch 38, Loss: 0.094\n",
      "Training: Epoch 188, Batch 39, Loss: 0.081\n",
      "Training: Epoch 188, Batch 40, Loss: 0.106\n",
      "Training: Epoch 188, Batch 41, Loss: 0.09\n",
      "Training: Epoch 188, Batch 42, Loss: 0.103\n",
      "Training: Epoch 188, Batch 43, Loss: 0.079\n",
      "Training: Epoch 188, Batch 44, Loss: 0.081\n",
      "Training: Epoch 188, Batch 45, Loss: 0.081\n",
      "Training: Epoch 188, Batch 46, Loss: 0.078\n",
      "Training: Epoch 188, Batch 47, Loss: 0.085\n",
      "Training: Epoch 188, Batch 48, Loss: 0.077\n",
      "Training: Epoch 188, Batch 49, Loss: 0.092\n",
      "Training: Epoch 188, Batch 50, Loss: 0.085\n",
      "Training: Epoch 188, Batch 51, Loss: 0.077\n",
      "Training: Epoch 188, Batch 52, Loss: 0.1\n",
      "Training: Epoch 188, Batch 53, Loss: 0.074\n",
      "Training: Epoch 188, Batch 54, Loss: 0.08\n",
      "Training: Epoch 188, Batch 55, Loss: 0.071\n",
      "Training: Epoch 188, Batch 56, Loss: 0.088\n",
      "Training: Epoch 188, Batch 57, Loss: 0.082\n",
      "Training: Epoch 188, Batch 58, Loss: 0.086\n",
      "Training: Epoch 188, Batch 59, Loss: 0.078\n",
      "Training: Epoch 188, Batch 60, Loss: 0.071\n",
      "Training: Epoch 188, Batch 61, Loss: 0.073\n",
      "Training: Epoch 188, Batch 62, Loss: 0.071\n",
      "Training: Epoch 188, Batch 63, Loss: 0.073\n",
      "Training: Epoch 188, Batch 64, Loss: 0.125\n",
      "Training: Epoch 188, Batch 65, Loss: 0.068\n",
      "Training: Epoch 188, Batch 66, Loss: 0.095\n",
      "Training: Epoch 188, Batch 67, Loss: 0.101\n",
      "Training: Epoch 188, Batch 68, Loss: 0.105\n",
      "Training: Epoch 188, Batch 69, Loss: 0.089\n",
      "Training: Epoch 188, Batch 70, Loss: 0.08\n",
      "Training: Epoch 188, Batch 71, Loss: 0.108\n",
      "Training: Epoch 188, Batch 72, Loss: 0.068\n",
      "Training: Epoch 188, Batch 73, Loss: 0.072\n",
      "Training: Epoch 188, Batch 74, Loss: 0.097\n",
      "Training: Epoch 188, Batch 75, Loss: 0.068\n",
      "Training: Epoch 188, Batch 76, Loss: 0.075\n",
      "Training: Epoch 188, Batch 77, Loss: 0.077\n",
      "Training: Epoch 188, Batch 78, Loss: 0.084\n",
      "Training: Epoch 188, Batch 79, Loss: 0.058\n",
      "Training: Epoch 188, Batch 80, Loss: 0.067\n",
      "Training: Epoch 188, Batch 81, Loss: 0.083\n",
      "Training: Epoch 188, Batch 82, Loss: 0.121\n",
      "Training: Epoch 188, Batch 83, Loss: 0.093\n",
      "Training: Epoch 188, Batch 84, Loss: 0.077\n",
      "Training: Epoch 188, Batch 85, Loss: 0.069\n",
      "Training: Epoch 188, Batch 86, Loss: 0.086\n",
      "Training: Epoch 188, Batch 87, Loss: 0.072\n",
      "Training: Epoch 188, Batch 88, Loss: 0.089\n",
      "Training: Epoch 188, Batch 89, Loss: 0.079\n",
      "Val: Epoch 188, Loss: 0.371\n",
      "Training: Epoch 189, Batch 0, Loss: 0.089\n",
      "Training: Epoch 189, Batch 1, Loss: 0.071\n",
      "Training: Epoch 189, Batch 2, Loss: 0.078\n",
      "Training: Epoch 189, Batch 3, Loss: 0.092\n",
      "Training: Epoch 189, Batch 4, Loss: 0.078\n",
      "Training: Epoch 189, Batch 5, Loss: 0.114\n",
      "Training: Epoch 189, Batch 6, Loss: 0.093\n",
      "Training: Epoch 189, Batch 7, Loss: 0.079\n",
      "Training: Epoch 189, Batch 8, Loss: 0.078\n",
      "Training: Epoch 189, Batch 9, Loss: 0.065\n",
      "Training: Epoch 189, Batch 10, Loss: 0.088\n",
      "Training: Epoch 189, Batch 11, Loss: 0.073\n",
      "Training: Epoch 189, Batch 12, Loss: 0.104\n",
      "Training: Epoch 189, Batch 13, Loss: 0.087\n",
      "Training: Epoch 189, Batch 14, Loss: 0.115\n",
      "Training: Epoch 189, Batch 15, Loss: 0.102\n",
      "Training: Epoch 189, Batch 16, Loss: 0.062\n",
      "Training: Epoch 189, Batch 17, Loss: 0.07\n",
      "Training: Epoch 189, Batch 18, Loss: 0.083\n",
      "Training: Epoch 189, Batch 19, Loss: 0.084\n",
      "Training: Epoch 189, Batch 20, Loss: 0.107\n",
      "Training: Epoch 189, Batch 21, Loss: 0.094\n",
      "Training: Epoch 189, Batch 22, Loss: 0.073\n",
      "Training: Epoch 189, Batch 23, Loss: 0.075\n",
      "Training: Epoch 189, Batch 24, Loss: 0.056\n",
      "Training: Epoch 189, Batch 25, Loss: 0.078\n",
      "Training: Epoch 189, Batch 26, Loss: 0.049\n",
      "Training: Epoch 189, Batch 27, Loss: 0.057\n",
      "Training: Epoch 189, Batch 28, Loss: 0.093\n",
      "Training: Epoch 189, Batch 29, Loss: 0.081\n",
      "Training: Epoch 189, Batch 30, Loss: 0.102\n",
      "Training: Epoch 189, Batch 31, Loss: 0.076\n",
      "Training: Epoch 189, Batch 32, Loss: 0.097\n",
      "Training: Epoch 189, Batch 33, Loss: 0.084\n",
      "Training: Epoch 189, Batch 34, Loss: 0.1\n",
      "Training: Epoch 189, Batch 35, Loss: 0.077\n",
      "Training: Epoch 189, Batch 36, Loss: 0.086\n",
      "Training: Epoch 189, Batch 37, Loss: 0.07\n",
      "Training: Epoch 189, Batch 38, Loss: 0.105\n",
      "Training: Epoch 189, Batch 39, Loss: 0.076\n",
      "Training: Epoch 189, Batch 40, Loss: 0.088\n",
      "Training: Epoch 189, Batch 41, Loss: 0.052\n",
      "Training: Epoch 189, Batch 42, Loss: 0.085\n",
      "Training: Epoch 189, Batch 43, Loss: 0.101\n",
      "Training: Epoch 189, Batch 44, Loss: 0.068\n",
      "Training: Epoch 189, Batch 45, Loss: 0.077\n",
      "Training: Epoch 189, Batch 46, Loss: 0.07\n",
      "Training: Epoch 189, Batch 47, Loss: 0.099\n",
      "Training: Epoch 189, Batch 48, Loss: 0.081\n",
      "Training: Epoch 189, Batch 49, Loss: 0.071\n",
      "Training: Epoch 189, Batch 50, Loss: 0.059\n",
      "Training: Epoch 189, Batch 51, Loss: 0.081\n",
      "Training: Epoch 189, Batch 52, Loss: 0.074\n",
      "Training: Epoch 189, Batch 53, Loss: 0.082\n",
      "Training: Epoch 189, Batch 54, Loss: 0.093\n",
      "Training: Epoch 189, Batch 55, Loss: 0.095\n",
      "Training: Epoch 189, Batch 56, Loss: 0.07\n",
      "Training: Epoch 189, Batch 57, Loss: 0.092\n",
      "Training: Epoch 189, Batch 58, Loss: 0.074\n",
      "Training: Epoch 189, Batch 59, Loss: 0.074\n",
      "Training: Epoch 189, Batch 60, Loss: 0.089\n",
      "Training: Epoch 189, Batch 61, Loss: 0.088\n",
      "Training: Epoch 189, Batch 62, Loss: 0.08\n",
      "Training: Epoch 189, Batch 63, Loss: 0.101\n",
      "Training: Epoch 189, Batch 64, Loss: 0.1\n",
      "Training: Epoch 189, Batch 65, Loss: 0.067\n",
      "Training: Epoch 189, Batch 66, Loss: 0.064\n",
      "Training: Epoch 189, Batch 67, Loss: 0.071\n",
      "Training: Epoch 189, Batch 68, Loss: 0.077\n",
      "Training: Epoch 189, Batch 69, Loss: 0.08\n",
      "Training: Epoch 189, Batch 70, Loss: 0.059\n",
      "Training: Epoch 189, Batch 71, Loss: 0.101\n",
      "Training: Epoch 189, Batch 72, Loss: 0.097\n",
      "Training: Epoch 189, Batch 73, Loss: 0.104\n",
      "Training: Epoch 189, Batch 74, Loss: 0.094\n",
      "Training: Epoch 189, Batch 75, Loss: 0.071\n",
      "Training: Epoch 189, Batch 76, Loss: 0.098\n",
      "Training: Epoch 189, Batch 77, Loss: 0.069\n",
      "Training: Epoch 189, Batch 78, Loss: 0.109\n",
      "Training: Epoch 189, Batch 79, Loss: 0.081\n",
      "Training: Epoch 189, Batch 80, Loss: 0.072\n",
      "Training: Epoch 189, Batch 81, Loss: 0.078\n",
      "Training: Epoch 189, Batch 82, Loss: 0.09\n",
      "Training: Epoch 189, Batch 83, Loss: 0.075\n",
      "Training: Epoch 189, Batch 84, Loss: 0.067\n",
      "Training: Epoch 189, Batch 85, Loss: 0.082\n",
      "Training: Epoch 189, Batch 86, Loss: 0.085\n",
      "Training: Epoch 189, Batch 87, Loss: 0.069\n",
      "Training: Epoch 189, Batch 88, Loss: 0.063\n",
      "Training: Epoch 189, Batch 89, Loss: 0.089\n",
      "Val: Epoch 189, Loss: 0.362\n",
      "Training: Epoch 190, Batch 0, Loss: 0.065\n",
      "Training: Epoch 190, Batch 1, Loss: 0.064\n",
      "Training: Epoch 190, Batch 2, Loss: 0.086\n",
      "Training: Epoch 190, Batch 3, Loss: 0.077\n",
      "Training: Epoch 190, Batch 4, Loss: 0.077\n",
      "Training: Epoch 190, Batch 5, Loss: 0.105\n",
      "Training: Epoch 190, Batch 6, Loss: 0.083\n",
      "Training: Epoch 190, Batch 7, Loss: 0.094\n",
      "Training: Epoch 190, Batch 8, Loss: 0.105\n",
      "Training: Epoch 190, Batch 9, Loss: 0.091\n",
      "Training: Epoch 190, Batch 10, Loss: 0.065\n",
      "Training: Epoch 190, Batch 11, Loss: 0.09\n",
      "Training: Epoch 190, Batch 12, Loss: 0.067\n",
      "Training: Epoch 190, Batch 13, Loss: 0.078\n",
      "Training: Epoch 190, Batch 14, Loss: 0.066\n",
      "Training: Epoch 190, Batch 15, Loss: 0.058\n",
      "Training: Epoch 190, Batch 16, Loss: 0.096\n",
      "Training: Epoch 190, Batch 17, Loss: 0.077\n",
      "Training: Epoch 190, Batch 18, Loss: 0.079\n",
      "Training: Epoch 190, Batch 19, Loss: 0.07\n",
      "Training: Epoch 190, Batch 20, Loss: 0.094\n",
      "Training: Epoch 190, Batch 21, Loss: 0.069\n",
      "Training: Epoch 190, Batch 22, Loss: 0.062\n",
      "Training: Epoch 190, Batch 23, Loss: 0.09\n",
      "Training: Epoch 190, Batch 24, Loss: 0.079\n",
      "Training: Epoch 190, Batch 25, Loss: 0.083\n",
      "Training: Epoch 190, Batch 26, Loss: 0.069\n",
      "Training: Epoch 190, Batch 27, Loss: 0.082\n",
      "Training: Epoch 190, Batch 28, Loss: 0.1\n",
      "Training: Epoch 190, Batch 29, Loss: 0.065\n",
      "Training: Epoch 190, Batch 30, Loss: 0.093\n",
      "Training: Epoch 190, Batch 31, Loss: 0.053\n",
      "Training: Epoch 190, Batch 32, Loss: 0.084\n",
      "Training: Epoch 190, Batch 33, Loss: 0.071\n",
      "Training: Epoch 190, Batch 34, Loss: 0.086\n",
      "Training: Epoch 190, Batch 35, Loss: 0.082\n",
      "Training: Epoch 190, Batch 36, Loss: 0.093\n",
      "Training: Epoch 190, Batch 37, Loss: 0.087\n",
      "Training: Epoch 190, Batch 38, Loss: 0.095\n",
      "Training: Epoch 190, Batch 39, Loss: 0.077\n",
      "Training: Epoch 190, Batch 40, Loss: 0.084\n",
      "Training: Epoch 190, Batch 41, Loss: 0.115\n",
      "Training: Epoch 190, Batch 42, Loss: 0.109\n",
      "Training: Epoch 190, Batch 43, Loss: 0.089\n",
      "Training: Epoch 190, Batch 44, Loss: 0.074\n",
      "Training: Epoch 190, Batch 45, Loss: 0.073\n",
      "Training: Epoch 190, Batch 46, Loss: 0.084\n",
      "Training: Epoch 190, Batch 47, Loss: 0.073\n",
      "Training: Epoch 190, Batch 48, Loss: 0.076\n",
      "Training: Epoch 190, Batch 49, Loss: 0.093\n",
      "Training: Epoch 190, Batch 50, Loss: 0.082\n",
      "Training: Epoch 190, Batch 51, Loss: 0.066\n",
      "Training: Epoch 190, Batch 52, Loss: 0.086\n",
      "Training: Epoch 190, Batch 53, Loss: 0.085\n",
      "Training: Epoch 190, Batch 54, Loss: 0.069\n",
      "Training: Epoch 190, Batch 55, Loss: 0.076\n",
      "Training: Epoch 190, Batch 56, Loss: 0.095\n",
      "Training: Epoch 190, Batch 57, Loss: 0.114\n",
      "Training: Epoch 190, Batch 58, Loss: 0.114\n",
      "Training: Epoch 190, Batch 59, Loss: 0.059\n",
      "Training: Epoch 190, Batch 60, Loss: 0.058\n",
      "Training: Epoch 190, Batch 61, Loss: 0.068\n",
      "Training: Epoch 190, Batch 62, Loss: 0.054\n",
      "Training: Epoch 190, Batch 63, Loss: 0.102\n",
      "Training: Epoch 190, Batch 64, Loss: 0.075\n",
      "Training: Epoch 190, Batch 65, Loss: 0.071\n",
      "Training: Epoch 190, Batch 66, Loss: 0.074\n",
      "Training: Epoch 190, Batch 67, Loss: 0.093\n",
      "Training: Epoch 190, Batch 68, Loss: 0.103\n",
      "Training: Epoch 190, Batch 69, Loss: 0.08\n",
      "Training: Epoch 190, Batch 70, Loss: 0.096\n",
      "Training: Epoch 190, Batch 71, Loss: 0.076\n",
      "Training: Epoch 190, Batch 72, Loss: 0.071\n",
      "Training: Epoch 190, Batch 73, Loss: 0.077\n",
      "Training: Epoch 190, Batch 74, Loss: 0.083\n",
      "Training: Epoch 190, Batch 75, Loss: 0.083\n",
      "Training: Epoch 190, Batch 76, Loss: 0.066\n",
      "Training: Epoch 190, Batch 77, Loss: 0.094\n",
      "Training: Epoch 190, Batch 78, Loss: 0.084\n",
      "Training: Epoch 190, Batch 79, Loss: 0.076\n",
      "Training: Epoch 190, Batch 80, Loss: 0.081\n",
      "Training: Epoch 190, Batch 81, Loss: 0.067\n",
      "Training: Epoch 190, Batch 82, Loss: 0.081\n",
      "Training: Epoch 190, Batch 83, Loss: 0.079\n",
      "Training: Epoch 190, Batch 84, Loss: 0.087\n",
      "Training: Epoch 190, Batch 85, Loss: 0.067\n",
      "Training: Epoch 190, Batch 86, Loss: 0.069\n",
      "Training: Epoch 190, Batch 87, Loss: 0.089\n",
      "Training: Epoch 190, Batch 88, Loss: 0.093\n",
      "Training: Epoch 190, Batch 89, Loss: 0.098\n",
      "Val: Epoch 190, Loss: 0.36\n",
      "Training: Epoch 191, Batch 0, Loss: 0.11\n",
      "Training: Epoch 191, Batch 1, Loss: 0.081\n",
      "Training: Epoch 191, Batch 2, Loss: 0.087\n",
      "Training: Epoch 191, Batch 3, Loss: 0.075\n",
      "Training: Epoch 191, Batch 4, Loss: 0.068\n",
      "Training: Epoch 191, Batch 5, Loss: 0.064\n",
      "Training: Epoch 191, Batch 6, Loss: 0.096\n",
      "Training: Epoch 191, Batch 7, Loss: 0.08\n",
      "Training: Epoch 191, Batch 8, Loss: 0.119\n",
      "Training: Epoch 191, Batch 9, Loss: 0.069\n",
      "Training: Epoch 191, Batch 10, Loss: 0.095\n",
      "Training: Epoch 191, Batch 11, Loss: 0.073\n",
      "Training: Epoch 191, Batch 12, Loss: 0.091\n",
      "Training: Epoch 191, Batch 13, Loss: 0.093\n",
      "Training: Epoch 191, Batch 14, Loss: 0.074\n",
      "Training: Epoch 191, Batch 15, Loss: 0.094\n",
      "Training: Epoch 191, Batch 16, Loss: 0.079\n",
      "Training: Epoch 191, Batch 17, Loss: 0.081\n",
      "Training: Epoch 191, Batch 18, Loss: 0.071\n",
      "Training: Epoch 191, Batch 19, Loss: 0.077\n",
      "Training: Epoch 191, Batch 20, Loss: 0.101\n",
      "Training: Epoch 191, Batch 21, Loss: 0.097\n",
      "Training: Epoch 191, Batch 22, Loss: 0.088\n",
      "Training: Epoch 191, Batch 23, Loss: 0.084\n",
      "Training: Epoch 191, Batch 24, Loss: 0.096\n",
      "Training: Epoch 191, Batch 25, Loss: 0.06\n",
      "Training: Epoch 191, Batch 26, Loss: 0.065\n",
      "Training: Epoch 191, Batch 27, Loss: 0.08\n",
      "Training: Epoch 191, Batch 28, Loss: 0.053\n",
      "Training: Epoch 191, Batch 29, Loss: 0.088\n",
      "Training: Epoch 191, Batch 30, Loss: 0.076\n",
      "Training: Epoch 191, Batch 31, Loss: 0.083\n",
      "Training: Epoch 191, Batch 32, Loss: 0.069\n",
      "Training: Epoch 191, Batch 33, Loss: 0.091\n",
      "Training: Epoch 191, Batch 34, Loss: 0.087\n",
      "Training: Epoch 191, Batch 35, Loss: 0.111\n",
      "Training: Epoch 191, Batch 36, Loss: 0.085\n",
      "Training: Epoch 191, Batch 37, Loss: 0.067\n",
      "Training: Epoch 191, Batch 38, Loss: 0.116\n",
      "Training: Epoch 191, Batch 39, Loss: 0.066\n",
      "Training: Epoch 191, Batch 40, Loss: 0.096\n",
      "Training: Epoch 191, Batch 41, Loss: 0.084\n",
      "Training: Epoch 191, Batch 42, Loss: 0.105\n",
      "Training: Epoch 191, Batch 43, Loss: 0.082\n",
      "Training: Epoch 191, Batch 44, Loss: 0.068\n",
      "Training: Epoch 191, Batch 45, Loss: 0.087\n",
      "Training: Epoch 191, Batch 46, Loss: 0.087\n",
      "Training: Epoch 191, Batch 47, Loss: 0.065\n",
      "Training: Epoch 191, Batch 48, Loss: 0.076\n",
      "Training: Epoch 191, Batch 49, Loss: 0.071\n",
      "Training: Epoch 191, Batch 50, Loss: 0.096\n",
      "Training: Epoch 191, Batch 51, Loss: 0.085\n",
      "Training: Epoch 191, Batch 52, Loss: 0.065\n",
      "Training: Epoch 191, Batch 53, Loss: 0.101\n",
      "Training: Epoch 191, Batch 54, Loss: 0.084\n",
      "Training: Epoch 191, Batch 55, Loss: 0.077\n",
      "Training: Epoch 191, Batch 56, Loss: 0.079\n",
      "Training: Epoch 191, Batch 57, Loss: 0.079\n",
      "Training: Epoch 191, Batch 58, Loss: 0.069\n",
      "Training: Epoch 191, Batch 59, Loss: 0.073\n",
      "Training: Epoch 191, Batch 60, Loss: 0.066\n",
      "Training: Epoch 191, Batch 61, Loss: 0.081\n",
      "Training: Epoch 191, Batch 62, Loss: 0.119\n",
      "Training: Epoch 191, Batch 63, Loss: 0.067\n",
      "Training: Epoch 191, Batch 64, Loss: 0.09\n",
      "Training: Epoch 191, Batch 65, Loss: 0.073\n",
      "Training: Epoch 191, Batch 66, Loss: 0.086\n",
      "Training: Epoch 191, Batch 67, Loss: 0.076\n",
      "Training: Epoch 191, Batch 68, Loss: 0.088\n",
      "Training: Epoch 191, Batch 69, Loss: 0.079\n",
      "Training: Epoch 191, Batch 70, Loss: 0.052\n",
      "Training: Epoch 191, Batch 71, Loss: 0.065\n",
      "Training: Epoch 191, Batch 72, Loss: 0.083\n",
      "Training: Epoch 191, Batch 73, Loss: 0.085\n",
      "Training: Epoch 191, Batch 74, Loss: 0.075\n",
      "Training: Epoch 191, Batch 75, Loss: 0.067\n",
      "Training: Epoch 191, Batch 76, Loss: 0.1\n",
      "Training: Epoch 191, Batch 77, Loss: 0.079\n",
      "Training: Epoch 191, Batch 78, Loss: 0.07\n",
      "Training: Epoch 191, Batch 79, Loss: 0.1\n",
      "Training: Epoch 191, Batch 80, Loss: 0.075\n",
      "Training: Epoch 191, Batch 81, Loss: 0.085\n",
      "Training: Epoch 191, Batch 82, Loss: 0.066\n",
      "Training: Epoch 191, Batch 83, Loss: 0.074\n",
      "Training: Epoch 191, Batch 84, Loss: 0.082\n",
      "Training: Epoch 191, Batch 85, Loss: 0.11\n",
      "Training: Epoch 191, Batch 86, Loss: 0.087\n",
      "Training: Epoch 191, Batch 87, Loss: 0.093\n",
      "Training: Epoch 191, Batch 88, Loss: 0.091\n",
      "Training: Epoch 191, Batch 89, Loss: 0.084\n",
      "Val: Epoch 191, Loss: 0.349\n",
      "Training: Epoch 192, Batch 0, Loss: 0.072\n",
      "Training: Epoch 192, Batch 1, Loss: 0.081\n",
      "Training: Epoch 192, Batch 2, Loss: 0.072\n",
      "Training: Epoch 192, Batch 3, Loss: 0.098\n",
      "Training: Epoch 192, Batch 4, Loss: 0.08\n",
      "Training: Epoch 192, Batch 5, Loss: 0.06\n",
      "Training: Epoch 192, Batch 6, Loss: 0.068\n",
      "Training: Epoch 192, Batch 7, Loss: 0.082\n",
      "Training: Epoch 192, Batch 8, Loss: 0.076\n",
      "Training: Epoch 192, Batch 9, Loss: 0.067\n",
      "Training: Epoch 192, Batch 10, Loss: 0.087\n",
      "Training: Epoch 192, Batch 11, Loss: 0.084\n",
      "Training: Epoch 192, Batch 12, Loss: 0.075\n",
      "Training: Epoch 192, Batch 13, Loss: 0.076\n",
      "Training: Epoch 192, Batch 14, Loss: 0.081\n",
      "Training: Epoch 192, Batch 15, Loss: 0.098\n",
      "Training: Epoch 192, Batch 16, Loss: 0.088\n",
      "Training: Epoch 192, Batch 17, Loss: 0.061\n",
      "Training: Epoch 192, Batch 18, Loss: 0.065\n",
      "Training: Epoch 192, Batch 19, Loss: 0.072\n",
      "Training: Epoch 192, Batch 20, Loss: 0.063\n",
      "Training: Epoch 192, Batch 21, Loss: 0.074\n",
      "Training: Epoch 192, Batch 22, Loss: 0.104\n",
      "Training: Epoch 192, Batch 23, Loss: 0.064\n",
      "Training: Epoch 192, Batch 24, Loss: 0.105\n",
      "Training: Epoch 192, Batch 25, Loss: 0.094\n",
      "Training: Epoch 192, Batch 26, Loss: 0.068\n",
      "Training: Epoch 192, Batch 27, Loss: 0.081\n",
      "Training: Epoch 192, Batch 28, Loss: 0.085\n",
      "Training: Epoch 192, Batch 29, Loss: 0.073\n",
      "Training: Epoch 192, Batch 30, Loss: 0.093\n",
      "Training: Epoch 192, Batch 31, Loss: 0.095\n",
      "Training: Epoch 192, Batch 32, Loss: 0.064\n",
      "Training: Epoch 192, Batch 33, Loss: 0.086\n",
      "Training: Epoch 192, Batch 34, Loss: 0.067\n",
      "Training: Epoch 192, Batch 35, Loss: 0.088\n",
      "Training: Epoch 192, Batch 36, Loss: 0.133\n",
      "Training: Epoch 192, Batch 37, Loss: 0.076\n",
      "Training: Epoch 192, Batch 38, Loss: 0.073\n",
      "Training: Epoch 192, Batch 39, Loss: 0.083\n",
      "Training: Epoch 192, Batch 40, Loss: 0.09\n",
      "Training: Epoch 192, Batch 41, Loss: 0.084\n",
      "Training: Epoch 192, Batch 42, Loss: 0.102\n",
      "Training: Epoch 192, Batch 43, Loss: 0.076\n",
      "Training: Epoch 192, Batch 44, Loss: 0.071\n",
      "Training: Epoch 192, Batch 45, Loss: 0.099\n",
      "Training: Epoch 192, Batch 46, Loss: 0.072\n",
      "Training: Epoch 192, Batch 47, Loss: 0.104\n",
      "Training: Epoch 192, Batch 48, Loss: 0.081\n",
      "Training: Epoch 192, Batch 49, Loss: 0.064\n",
      "Training: Epoch 192, Batch 50, Loss: 0.073\n",
      "Training: Epoch 192, Batch 51, Loss: 0.061\n",
      "Training: Epoch 192, Batch 52, Loss: 0.072\n",
      "Training: Epoch 192, Batch 53, Loss: 0.094\n",
      "Training: Epoch 192, Batch 54, Loss: 0.084\n",
      "Training: Epoch 192, Batch 55, Loss: 0.096\n",
      "Training: Epoch 192, Batch 56, Loss: 0.09\n",
      "Training: Epoch 192, Batch 57, Loss: 0.095\n",
      "Training: Epoch 192, Batch 58, Loss: 0.088\n",
      "Training: Epoch 192, Batch 59, Loss: 0.069\n",
      "Training: Epoch 192, Batch 60, Loss: 0.095\n",
      "Training: Epoch 192, Batch 61, Loss: 0.093\n",
      "Training: Epoch 192, Batch 62, Loss: 0.096\n",
      "Training: Epoch 192, Batch 63, Loss: 0.062\n",
      "Training: Epoch 192, Batch 64, Loss: 0.068\n",
      "Training: Epoch 192, Batch 65, Loss: 0.076\n",
      "Training: Epoch 192, Batch 66, Loss: 0.094\n",
      "Training: Epoch 192, Batch 67, Loss: 0.073\n",
      "Training: Epoch 192, Batch 68, Loss: 0.082\n",
      "Training: Epoch 192, Batch 69, Loss: 0.076\n",
      "Training: Epoch 192, Batch 70, Loss: 0.094\n",
      "Training: Epoch 192, Batch 71, Loss: 0.079\n",
      "Training: Epoch 192, Batch 72, Loss: 0.094\n",
      "Training: Epoch 192, Batch 73, Loss: 0.075\n",
      "Training: Epoch 192, Batch 74, Loss: 0.083\n",
      "Training: Epoch 192, Batch 75, Loss: 0.064\n",
      "Training: Epoch 192, Batch 76, Loss: 0.096\n",
      "Training: Epoch 192, Batch 77, Loss: 0.087\n",
      "Training: Epoch 192, Batch 78, Loss: 0.065\n",
      "Training: Epoch 192, Batch 79, Loss: 0.096\n",
      "Training: Epoch 192, Batch 80, Loss: 0.068\n",
      "Training: Epoch 192, Batch 81, Loss: 0.06\n",
      "Training: Epoch 192, Batch 82, Loss: 0.1\n",
      "Training: Epoch 192, Batch 83, Loss: 0.099\n",
      "Training: Epoch 192, Batch 84, Loss: 0.078\n",
      "Training: Epoch 192, Batch 85, Loss: 0.063\n",
      "Training: Epoch 192, Batch 86, Loss: 0.056\n",
      "Training: Epoch 192, Batch 87, Loss: 0.068\n",
      "Training: Epoch 192, Batch 88, Loss: 0.073\n",
      "Training: Epoch 192, Batch 89, Loss: 0.088\n",
      "Val: Epoch 192, Loss: 0.357\n",
      "Training: Epoch 193, Batch 0, Loss: 0.076\n",
      "Training: Epoch 193, Batch 1, Loss: 0.052\n",
      "Training: Epoch 193, Batch 2, Loss: 0.085\n",
      "Training: Epoch 193, Batch 3, Loss: 0.102\n",
      "Training: Epoch 193, Batch 4, Loss: 0.078\n",
      "Training: Epoch 193, Batch 5, Loss: 0.073\n",
      "Training: Epoch 193, Batch 6, Loss: 0.093\n",
      "Training: Epoch 193, Batch 7, Loss: 0.072\n",
      "Training: Epoch 193, Batch 8, Loss: 0.065\n",
      "Training: Epoch 193, Batch 9, Loss: 0.071\n",
      "Training: Epoch 193, Batch 10, Loss: 0.079\n",
      "Training: Epoch 193, Batch 11, Loss: 0.109\n",
      "Training: Epoch 193, Batch 12, Loss: 0.061\n",
      "Training: Epoch 193, Batch 13, Loss: 0.09\n",
      "Training: Epoch 193, Batch 14, Loss: 0.11\n",
      "Training: Epoch 193, Batch 15, Loss: 0.063\n",
      "Training: Epoch 193, Batch 16, Loss: 0.076\n",
      "Training: Epoch 193, Batch 17, Loss: 0.077\n",
      "Training: Epoch 193, Batch 18, Loss: 0.083\n",
      "Training: Epoch 193, Batch 19, Loss: 0.085\n",
      "Training: Epoch 193, Batch 20, Loss: 0.091\n",
      "Training: Epoch 193, Batch 21, Loss: 0.073\n",
      "Training: Epoch 193, Batch 22, Loss: 0.071\n",
      "Training: Epoch 193, Batch 23, Loss: 0.076\n",
      "Training: Epoch 193, Batch 24, Loss: 0.114\n",
      "Training: Epoch 193, Batch 25, Loss: 0.078\n",
      "Training: Epoch 193, Batch 26, Loss: 0.087\n",
      "Training: Epoch 193, Batch 27, Loss: 0.076\n",
      "Training: Epoch 193, Batch 28, Loss: 0.081\n",
      "Training: Epoch 193, Batch 29, Loss: 0.093\n",
      "Training: Epoch 193, Batch 30, Loss: 0.092\n",
      "Training: Epoch 193, Batch 31, Loss: 0.087\n",
      "Training: Epoch 193, Batch 32, Loss: 0.085\n",
      "Training: Epoch 193, Batch 33, Loss: 0.099\n",
      "Training: Epoch 193, Batch 34, Loss: 0.07\n",
      "Training: Epoch 193, Batch 35, Loss: 0.103\n",
      "Training: Epoch 193, Batch 36, Loss: 0.082\n",
      "Training: Epoch 193, Batch 37, Loss: 0.072\n",
      "Training: Epoch 193, Batch 38, Loss: 0.066\n",
      "Training: Epoch 193, Batch 39, Loss: 0.085\n",
      "Training: Epoch 193, Batch 40, Loss: 0.08\n",
      "Training: Epoch 193, Batch 41, Loss: 0.086\n",
      "Training: Epoch 193, Batch 42, Loss: 0.092\n",
      "Training: Epoch 193, Batch 43, Loss: 0.083\n",
      "Training: Epoch 193, Batch 44, Loss: 0.058\n",
      "Training: Epoch 193, Batch 45, Loss: 0.087\n",
      "Training: Epoch 193, Batch 46, Loss: 0.066\n",
      "Training: Epoch 193, Batch 47, Loss: 0.073\n",
      "Training: Epoch 193, Batch 48, Loss: 0.105\n",
      "Training: Epoch 193, Batch 49, Loss: 0.07\n",
      "Training: Epoch 193, Batch 50, Loss: 0.068\n",
      "Training: Epoch 193, Batch 51, Loss: 0.091\n",
      "Training: Epoch 193, Batch 52, Loss: 0.085\n",
      "Training: Epoch 193, Batch 53, Loss: 0.09\n",
      "Training: Epoch 193, Batch 54, Loss: 0.061\n",
      "Training: Epoch 193, Batch 55, Loss: 0.084\n",
      "Training: Epoch 193, Batch 56, Loss: 0.086\n",
      "Training: Epoch 193, Batch 57, Loss: 0.08\n",
      "Training: Epoch 193, Batch 58, Loss: 0.062\n",
      "Training: Epoch 193, Batch 59, Loss: 0.075\n",
      "Training: Epoch 193, Batch 60, Loss: 0.095\n",
      "Training: Epoch 193, Batch 61, Loss: 0.061\n",
      "Training: Epoch 193, Batch 62, Loss: 0.086\n",
      "Training: Epoch 193, Batch 63, Loss: 0.06\n",
      "Training: Epoch 193, Batch 64, Loss: 0.065\n",
      "Training: Epoch 193, Batch 65, Loss: 0.054\n",
      "Training: Epoch 193, Batch 66, Loss: 0.112\n",
      "Training: Epoch 193, Batch 67, Loss: 0.069\n",
      "Training: Epoch 193, Batch 68, Loss: 0.066\n",
      "Training: Epoch 193, Batch 69, Loss: 0.085\n",
      "Training: Epoch 193, Batch 70, Loss: 0.08\n",
      "Training: Epoch 193, Batch 71, Loss: 0.081\n",
      "Training: Epoch 193, Batch 72, Loss: 0.091\n",
      "Training: Epoch 193, Batch 73, Loss: 0.079\n",
      "Training: Epoch 193, Batch 74, Loss: 0.07\n",
      "Training: Epoch 193, Batch 75, Loss: 0.062\n",
      "Training: Epoch 193, Batch 76, Loss: 0.063\n",
      "Training: Epoch 193, Batch 77, Loss: 0.063\n",
      "Training: Epoch 193, Batch 78, Loss: 0.116\n",
      "Training: Epoch 193, Batch 79, Loss: 0.088\n",
      "Training: Epoch 193, Batch 80, Loss: 0.076\n",
      "Training: Epoch 193, Batch 81, Loss: 0.108\n",
      "Training: Epoch 193, Batch 82, Loss: 0.091\n",
      "Training: Epoch 193, Batch 83, Loss: 0.077\n",
      "Training: Epoch 193, Batch 84, Loss: 0.081\n",
      "Training: Epoch 193, Batch 85, Loss: 0.081\n",
      "Training: Epoch 193, Batch 86, Loss: 0.073\n",
      "Training: Epoch 193, Batch 87, Loss: 0.072\n",
      "Training: Epoch 193, Batch 88, Loss: 0.078\n",
      "Training: Epoch 193, Batch 89, Loss: 0.097\n",
      "Val: Epoch 193, Loss: 0.346\n",
      "Training: Epoch 194, Batch 0, Loss: 0.108\n",
      "Training: Epoch 194, Batch 1, Loss: 0.092\n",
      "Training: Epoch 194, Batch 2, Loss: 0.065\n",
      "Training: Epoch 194, Batch 3, Loss: 0.077\n",
      "Training: Epoch 194, Batch 4, Loss: 0.079\n",
      "Training: Epoch 194, Batch 5, Loss: 0.104\n",
      "Training: Epoch 194, Batch 6, Loss: 0.114\n",
      "Training: Epoch 194, Batch 7, Loss: 0.1\n",
      "Training: Epoch 194, Batch 8, Loss: 0.106\n",
      "Training: Epoch 194, Batch 9, Loss: 0.111\n",
      "Training: Epoch 194, Batch 10, Loss: 0.063\n",
      "Training: Epoch 194, Batch 11, Loss: 0.09\n",
      "Training: Epoch 194, Batch 12, Loss: 0.054\n",
      "Training: Epoch 194, Batch 13, Loss: 0.07\n",
      "Training: Epoch 194, Batch 14, Loss: 0.078\n",
      "Training: Epoch 194, Batch 15, Loss: 0.076\n",
      "Training: Epoch 194, Batch 16, Loss: 0.068\n",
      "Training: Epoch 194, Batch 17, Loss: 0.063\n",
      "Training: Epoch 194, Batch 18, Loss: 0.055\n",
      "Training: Epoch 194, Batch 19, Loss: 0.108\n",
      "Training: Epoch 194, Batch 20, Loss: 0.111\n",
      "Training: Epoch 194, Batch 21, Loss: 0.097\n",
      "Training: Epoch 194, Batch 22, Loss: 0.088\n",
      "Training: Epoch 194, Batch 23, Loss: 0.088\n",
      "Training: Epoch 194, Batch 24, Loss: 0.069\n",
      "Training: Epoch 194, Batch 25, Loss: 0.073\n",
      "Training: Epoch 194, Batch 26, Loss: 0.069\n",
      "Training: Epoch 194, Batch 27, Loss: 0.09\n",
      "Training: Epoch 194, Batch 28, Loss: 0.073\n",
      "Training: Epoch 194, Batch 29, Loss: 0.072\n",
      "Training: Epoch 194, Batch 30, Loss: 0.065\n",
      "Training: Epoch 194, Batch 31, Loss: 0.086\n",
      "Training: Epoch 194, Batch 32, Loss: 0.079\n",
      "Training: Epoch 194, Batch 33, Loss: 0.07\n",
      "Training: Epoch 194, Batch 34, Loss: 0.094\n",
      "Training: Epoch 194, Batch 35, Loss: 0.075\n",
      "Training: Epoch 194, Batch 36, Loss: 0.081\n",
      "Training: Epoch 194, Batch 37, Loss: 0.091\n",
      "Training: Epoch 194, Batch 38, Loss: 0.067\n",
      "Training: Epoch 194, Batch 39, Loss: 0.081\n",
      "Training: Epoch 194, Batch 40, Loss: 0.08\n",
      "Training: Epoch 194, Batch 41, Loss: 0.067\n",
      "Training: Epoch 194, Batch 42, Loss: 0.064\n",
      "Training: Epoch 194, Batch 43, Loss: 0.079\n",
      "Training: Epoch 194, Batch 44, Loss: 0.072\n",
      "Training: Epoch 194, Batch 45, Loss: 0.086\n",
      "Training: Epoch 194, Batch 46, Loss: 0.063\n",
      "Training: Epoch 194, Batch 47, Loss: 0.074\n",
      "Training: Epoch 194, Batch 48, Loss: 0.083\n",
      "Training: Epoch 194, Batch 49, Loss: 0.064\n",
      "Training: Epoch 194, Batch 50, Loss: 0.078\n",
      "Training: Epoch 194, Batch 51, Loss: 0.109\n",
      "Training: Epoch 194, Batch 52, Loss: 0.067\n",
      "Training: Epoch 194, Batch 53, Loss: 0.055\n",
      "Training: Epoch 194, Batch 54, Loss: 0.089\n",
      "Training: Epoch 194, Batch 55, Loss: 0.085\n",
      "Training: Epoch 194, Batch 56, Loss: 0.085\n",
      "Training: Epoch 194, Batch 57, Loss: 0.08\n",
      "Training: Epoch 194, Batch 58, Loss: 0.055\n",
      "Training: Epoch 194, Batch 59, Loss: 0.067\n",
      "Training: Epoch 194, Batch 60, Loss: 0.098\n",
      "Training: Epoch 194, Batch 61, Loss: 0.059\n",
      "Training: Epoch 194, Batch 62, Loss: 0.078\n",
      "Training: Epoch 194, Batch 63, Loss: 0.073\n",
      "Training: Epoch 194, Batch 64, Loss: 0.068\n",
      "Training: Epoch 194, Batch 65, Loss: 0.077\n",
      "Training: Epoch 194, Batch 66, Loss: 0.069\n",
      "Training: Epoch 194, Batch 67, Loss: 0.096\n",
      "Training: Epoch 194, Batch 68, Loss: 0.067\n",
      "Training: Epoch 194, Batch 69, Loss: 0.067\n",
      "Training: Epoch 194, Batch 70, Loss: 0.07\n",
      "Training: Epoch 194, Batch 71, Loss: 0.077\n",
      "Training: Epoch 194, Batch 72, Loss: 0.08\n",
      "Training: Epoch 194, Batch 73, Loss: 0.065\n",
      "Training: Epoch 194, Batch 74, Loss: 0.076\n",
      "Training: Epoch 194, Batch 75, Loss: 0.07\n",
      "Training: Epoch 194, Batch 76, Loss: 0.098\n",
      "Training: Epoch 194, Batch 77, Loss: 0.079\n",
      "Training: Epoch 194, Batch 78, Loss: 0.082\n",
      "Training: Epoch 194, Batch 79, Loss: 0.067\n",
      "Training: Epoch 194, Batch 80, Loss: 0.087\n",
      "Training: Epoch 194, Batch 81, Loss: 0.101\n",
      "Training: Epoch 194, Batch 82, Loss: 0.072\n",
      "Training: Epoch 194, Batch 83, Loss: 0.07\n",
      "Training: Epoch 194, Batch 84, Loss: 0.058\n",
      "Training: Epoch 194, Batch 85, Loss: 0.088\n",
      "Training: Epoch 194, Batch 86, Loss: 0.078\n",
      "Training: Epoch 194, Batch 87, Loss: 0.078\n",
      "Training: Epoch 194, Batch 88, Loss: 0.111\n",
      "Training: Epoch 194, Batch 89, Loss: 0.066\n",
      "Val: Epoch 194, Loss: 0.384\n",
      "Training: Epoch 195, Batch 0, Loss: 0.07\n",
      "Training: Epoch 195, Batch 1, Loss: 0.074\n",
      "Training: Epoch 195, Batch 2, Loss: 0.07\n",
      "Training: Epoch 195, Batch 3, Loss: 0.08\n",
      "Training: Epoch 195, Batch 4, Loss: 0.084\n",
      "Training: Epoch 195, Batch 5, Loss: 0.067\n",
      "Training: Epoch 195, Batch 6, Loss: 0.071\n",
      "Training: Epoch 195, Batch 7, Loss: 0.062\n",
      "Training: Epoch 195, Batch 8, Loss: 0.114\n",
      "Training: Epoch 195, Batch 9, Loss: 0.092\n",
      "Training: Epoch 195, Batch 10, Loss: 0.065\n",
      "Training: Epoch 195, Batch 11, Loss: 0.075\n",
      "Training: Epoch 195, Batch 12, Loss: 0.085\n",
      "Training: Epoch 195, Batch 13, Loss: 0.073\n",
      "Training: Epoch 195, Batch 14, Loss: 0.073\n",
      "Training: Epoch 195, Batch 15, Loss: 0.122\n",
      "Training: Epoch 195, Batch 16, Loss: 0.071\n",
      "Training: Epoch 195, Batch 17, Loss: 0.096\n",
      "Training: Epoch 195, Batch 18, Loss: 0.074\n",
      "Training: Epoch 195, Batch 19, Loss: 0.068\n",
      "Training: Epoch 195, Batch 20, Loss: 0.064\n",
      "Training: Epoch 195, Batch 21, Loss: 0.075\n",
      "Training: Epoch 195, Batch 22, Loss: 0.083\n",
      "Training: Epoch 195, Batch 23, Loss: 0.083\n",
      "Training: Epoch 195, Batch 24, Loss: 0.075\n",
      "Training: Epoch 195, Batch 25, Loss: 0.076\n",
      "Training: Epoch 195, Batch 26, Loss: 0.104\n",
      "Training: Epoch 195, Batch 27, Loss: 0.062\n",
      "Training: Epoch 195, Batch 28, Loss: 0.124\n",
      "Training: Epoch 195, Batch 29, Loss: 0.083\n",
      "Training: Epoch 195, Batch 30, Loss: 0.091\n",
      "Training: Epoch 195, Batch 31, Loss: 0.087\n",
      "Training: Epoch 195, Batch 32, Loss: 0.062\n",
      "Training: Epoch 195, Batch 33, Loss: 0.093\n",
      "Training: Epoch 195, Batch 34, Loss: 0.096\n",
      "Training: Epoch 195, Batch 35, Loss: 0.095\n",
      "Training: Epoch 195, Batch 36, Loss: 0.098\n",
      "Training: Epoch 195, Batch 37, Loss: 0.076\n",
      "Training: Epoch 195, Batch 38, Loss: 0.08\n",
      "Training: Epoch 195, Batch 39, Loss: 0.084\n",
      "Training: Epoch 195, Batch 40, Loss: 0.072\n",
      "Training: Epoch 195, Batch 41, Loss: 0.108\n",
      "Training: Epoch 195, Batch 42, Loss: 0.093\n",
      "Training: Epoch 195, Batch 43, Loss: 0.083\n",
      "Training: Epoch 195, Batch 44, Loss: 0.075\n",
      "Training: Epoch 195, Batch 45, Loss: 0.148\n",
      "Training: Epoch 195, Batch 46, Loss: 0.092\n",
      "Training: Epoch 195, Batch 47, Loss: 0.074\n",
      "Training: Epoch 195, Batch 48, Loss: 0.074\n",
      "Training: Epoch 195, Batch 49, Loss: 0.08\n",
      "Training: Epoch 195, Batch 50, Loss: 0.096\n",
      "Training: Epoch 195, Batch 51, Loss: 0.073\n",
      "Training: Epoch 195, Batch 52, Loss: 0.075\n",
      "Training: Epoch 195, Batch 53, Loss: 0.061\n",
      "Training: Epoch 195, Batch 54, Loss: 0.068\n",
      "Training: Epoch 195, Batch 55, Loss: 0.066\n",
      "Training: Epoch 195, Batch 56, Loss: 0.076\n",
      "Training: Epoch 195, Batch 57, Loss: 0.077\n",
      "Training: Epoch 195, Batch 58, Loss: 0.066\n",
      "Training: Epoch 195, Batch 59, Loss: 0.08\n",
      "Training: Epoch 195, Batch 60, Loss: 0.075\n",
      "Training: Epoch 195, Batch 61, Loss: 0.069\n",
      "Training: Epoch 195, Batch 62, Loss: 0.054\n",
      "Training: Epoch 195, Batch 63, Loss: 0.08\n",
      "Training: Epoch 195, Batch 64, Loss: 0.114\n",
      "Training: Epoch 195, Batch 65, Loss: 0.088\n",
      "Training: Epoch 195, Batch 66, Loss: 0.093\n",
      "Training: Epoch 195, Batch 67, Loss: 0.074\n",
      "Training: Epoch 195, Batch 68, Loss: 0.082\n",
      "Training: Epoch 195, Batch 69, Loss: 0.078\n",
      "Training: Epoch 195, Batch 70, Loss: 0.072\n",
      "Training: Epoch 195, Batch 71, Loss: 0.088\n",
      "Training: Epoch 195, Batch 72, Loss: 0.092\n",
      "Training: Epoch 195, Batch 73, Loss: 0.085\n",
      "Training: Epoch 195, Batch 74, Loss: 0.083\n",
      "Training: Epoch 195, Batch 75, Loss: 0.072\n",
      "Training: Epoch 195, Batch 76, Loss: 0.082\n",
      "Training: Epoch 195, Batch 77, Loss: 0.1\n",
      "Training: Epoch 195, Batch 78, Loss: 0.076\n",
      "Training: Epoch 195, Batch 79, Loss: 0.066\n",
      "Training: Epoch 195, Batch 80, Loss: 0.123\n",
      "Training: Epoch 195, Batch 81, Loss: 0.071\n",
      "Training: Epoch 195, Batch 82, Loss: 0.079\n",
      "Training: Epoch 195, Batch 83, Loss: 0.074\n",
      "Training: Epoch 195, Batch 84, Loss: 0.058\n",
      "Training: Epoch 195, Batch 85, Loss: 0.066\n",
      "Training: Epoch 195, Batch 86, Loss: 0.061\n",
      "Training: Epoch 195, Batch 87, Loss: 0.08\n",
      "Training: Epoch 195, Batch 88, Loss: 0.082\n",
      "Training: Epoch 195, Batch 89, Loss: 0.075\n",
      "Val: Epoch 195, Loss: 0.377\n",
      "Training: Epoch 196, Batch 0, Loss: 0.07\n",
      "Training: Epoch 196, Batch 1, Loss: 0.069\n",
      "Training: Epoch 196, Batch 2, Loss: 0.092\n",
      "Training: Epoch 196, Batch 3, Loss: 0.067\n",
      "Training: Epoch 196, Batch 4, Loss: 0.072\n",
      "Training: Epoch 196, Batch 5, Loss: 0.087\n",
      "Training: Epoch 196, Batch 6, Loss: 0.088\n",
      "Training: Epoch 196, Batch 7, Loss: 0.063\n",
      "Training: Epoch 196, Batch 8, Loss: 0.104\n",
      "Training: Epoch 196, Batch 9, Loss: 0.064\n",
      "Training: Epoch 196, Batch 10, Loss: 0.089\n",
      "Training: Epoch 196, Batch 11, Loss: 0.083\n",
      "Training: Epoch 196, Batch 12, Loss: 0.071\n",
      "Training: Epoch 196, Batch 13, Loss: 0.057\n",
      "Training: Epoch 196, Batch 14, Loss: 0.096\n",
      "Training: Epoch 196, Batch 15, Loss: 0.067\n",
      "Training: Epoch 196, Batch 16, Loss: 0.072\n",
      "Training: Epoch 196, Batch 17, Loss: 0.097\n",
      "Training: Epoch 196, Batch 18, Loss: 0.076\n",
      "Training: Epoch 196, Batch 19, Loss: 0.066\n",
      "Training: Epoch 196, Batch 20, Loss: 0.067\n",
      "Training: Epoch 196, Batch 21, Loss: 0.091\n",
      "Training: Epoch 196, Batch 22, Loss: 0.066\n",
      "Training: Epoch 196, Batch 23, Loss: 0.09\n",
      "Training: Epoch 196, Batch 24, Loss: 0.09\n",
      "Training: Epoch 196, Batch 25, Loss: 0.059\n",
      "Training: Epoch 196, Batch 26, Loss: 0.054\n",
      "Training: Epoch 196, Batch 27, Loss: 0.084\n",
      "Training: Epoch 196, Batch 28, Loss: 0.087\n",
      "Training: Epoch 196, Batch 29, Loss: 0.084\n",
      "Training: Epoch 196, Batch 30, Loss: 0.102\n",
      "Training: Epoch 196, Batch 31, Loss: 0.083\n",
      "Training: Epoch 196, Batch 32, Loss: 0.074\n",
      "Training: Epoch 196, Batch 33, Loss: 0.073\n",
      "Training: Epoch 196, Batch 34, Loss: 0.082\n",
      "Training: Epoch 196, Batch 35, Loss: 0.076\n",
      "Training: Epoch 196, Batch 36, Loss: 0.08\n",
      "Training: Epoch 196, Batch 37, Loss: 0.063\n",
      "Training: Epoch 196, Batch 38, Loss: 0.062\n",
      "Training: Epoch 196, Batch 39, Loss: 0.085\n",
      "Training: Epoch 196, Batch 40, Loss: 0.065\n",
      "Training: Epoch 196, Batch 41, Loss: 0.085\n",
      "Training: Epoch 196, Batch 42, Loss: 0.084\n",
      "Training: Epoch 196, Batch 43, Loss: 0.076\n",
      "Training: Epoch 196, Batch 44, Loss: 0.068\n",
      "Training: Epoch 196, Batch 45, Loss: 0.06\n",
      "Training: Epoch 196, Batch 46, Loss: 0.085\n",
      "Training: Epoch 196, Batch 47, Loss: 0.078\n",
      "Training: Epoch 196, Batch 48, Loss: 0.093\n",
      "Training: Epoch 196, Batch 49, Loss: 0.078\n",
      "Training: Epoch 196, Batch 50, Loss: 0.084\n",
      "Training: Epoch 196, Batch 51, Loss: 0.067\n",
      "Training: Epoch 196, Batch 52, Loss: 0.078\n",
      "Training: Epoch 196, Batch 53, Loss: 0.084\n",
      "Training: Epoch 196, Batch 54, Loss: 0.065\n",
      "Training: Epoch 196, Batch 55, Loss: 0.103\n",
      "Training: Epoch 196, Batch 56, Loss: 0.073\n",
      "Training: Epoch 196, Batch 57, Loss: 0.072\n",
      "Training: Epoch 196, Batch 58, Loss: 0.075\n",
      "Training: Epoch 196, Batch 59, Loss: 0.07\n",
      "Training: Epoch 196, Batch 60, Loss: 0.091\n",
      "Training: Epoch 196, Batch 61, Loss: 0.088\n",
      "Training: Epoch 196, Batch 62, Loss: 0.075\n",
      "Training: Epoch 196, Batch 63, Loss: 0.103\n",
      "Training: Epoch 196, Batch 64, Loss: 0.082\n",
      "Training: Epoch 196, Batch 65, Loss: 0.089\n",
      "Training: Epoch 196, Batch 66, Loss: 0.071\n",
      "Training: Epoch 196, Batch 67, Loss: 0.096\n",
      "Training: Epoch 196, Batch 68, Loss: 0.091\n",
      "Training: Epoch 196, Batch 69, Loss: 0.082\n",
      "Training: Epoch 196, Batch 70, Loss: 0.09\n",
      "Training: Epoch 196, Batch 71, Loss: 0.064\n",
      "Training: Epoch 196, Batch 72, Loss: 0.098\n",
      "Training: Epoch 196, Batch 73, Loss: 0.094\n",
      "Training: Epoch 196, Batch 74, Loss: 0.098\n",
      "Training: Epoch 196, Batch 75, Loss: 0.088\n",
      "Training: Epoch 196, Batch 76, Loss: 0.079\n",
      "Training: Epoch 196, Batch 77, Loss: 0.062\n",
      "Training: Epoch 196, Batch 78, Loss: 0.096\n",
      "Training: Epoch 196, Batch 79, Loss: 0.09\n",
      "Training: Epoch 196, Batch 80, Loss: 0.08\n",
      "Training: Epoch 196, Batch 81, Loss: 0.071\n",
      "Training: Epoch 196, Batch 82, Loss: 0.061\n",
      "Training: Epoch 196, Batch 83, Loss: 0.086\n",
      "Training: Epoch 196, Batch 84, Loss: 0.072\n",
      "Training: Epoch 196, Batch 85, Loss: 0.091\n",
      "Training: Epoch 196, Batch 86, Loss: 0.073\n",
      "Training: Epoch 196, Batch 87, Loss: 0.094\n",
      "Training: Epoch 196, Batch 88, Loss: 0.088\n",
      "Training: Epoch 196, Batch 89, Loss: 0.093\n",
      "Val: Epoch 196, Loss: 0.372\n",
      "Training: Epoch 197, Batch 0, Loss: 0.108\n",
      "Training: Epoch 197, Batch 1, Loss: 0.099\n",
      "Training: Epoch 197, Batch 2, Loss: 0.056\n",
      "Training: Epoch 197, Batch 3, Loss: 0.074\n",
      "Training: Epoch 197, Batch 4, Loss: 0.085\n",
      "Training: Epoch 197, Batch 5, Loss: 0.071\n",
      "Training: Epoch 197, Batch 6, Loss: 0.075\n",
      "Training: Epoch 197, Batch 7, Loss: 0.07\n",
      "Training: Epoch 197, Batch 8, Loss: 0.083\n",
      "Training: Epoch 197, Batch 9, Loss: 0.065\n",
      "Training: Epoch 197, Batch 10, Loss: 0.079\n",
      "Training: Epoch 197, Batch 11, Loss: 0.075\n",
      "Training: Epoch 197, Batch 12, Loss: 0.076\n",
      "Training: Epoch 197, Batch 13, Loss: 0.075\n",
      "Training: Epoch 197, Batch 14, Loss: 0.066\n",
      "Training: Epoch 197, Batch 15, Loss: 0.08\n",
      "Training: Epoch 197, Batch 16, Loss: 0.072\n",
      "Training: Epoch 197, Batch 17, Loss: 0.088\n",
      "Training: Epoch 197, Batch 18, Loss: 0.093\n",
      "Training: Epoch 197, Batch 19, Loss: 0.082\n",
      "Training: Epoch 197, Batch 20, Loss: 0.054\n",
      "Training: Epoch 197, Batch 21, Loss: 0.1\n",
      "Training: Epoch 197, Batch 22, Loss: 0.097\n",
      "Training: Epoch 197, Batch 23, Loss: 0.075\n",
      "Training: Epoch 197, Batch 24, Loss: 0.072\n",
      "Training: Epoch 197, Batch 25, Loss: 0.054\n",
      "Training: Epoch 197, Batch 26, Loss: 0.057\n",
      "Training: Epoch 197, Batch 27, Loss: 0.077\n",
      "Training: Epoch 197, Batch 28, Loss: 0.079\n",
      "Training: Epoch 197, Batch 29, Loss: 0.093\n",
      "Training: Epoch 197, Batch 30, Loss: 0.08\n",
      "Training: Epoch 197, Batch 31, Loss: 0.084\n",
      "Training: Epoch 197, Batch 32, Loss: 0.087\n",
      "Training: Epoch 197, Batch 33, Loss: 0.066\n",
      "Training: Epoch 197, Batch 34, Loss: 0.116\n",
      "Training: Epoch 197, Batch 35, Loss: 0.088\n",
      "Training: Epoch 197, Batch 36, Loss: 0.064\n",
      "Training: Epoch 197, Batch 37, Loss: 0.072\n",
      "Training: Epoch 197, Batch 38, Loss: 0.078\n",
      "Training: Epoch 197, Batch 39, Loss: 0.094\n",
      "Training: Epoch 197, Batch 40, Loss: 0.091\n",
      "Training: Epoch 197, Batch 41, Loss: 0.089\n",
      "Training: Epoch 197, Batch 42, Loss: 0.095\n",
      "Training: Epoch 197, Batch 43, Loss: 0.066\n",
      "Training: Epoch 197, Batch 44, Loss: 0.072\n",
      "Training: Epoch 197, Batch 45, Loss: 0.073\n",
      "Training: Epoch 197, Batch 46, Loss: 0.063\n",
      "Training: Epoch 197, Batch 47, Loss: 0.09\n",
      "Training: Epoch 197, Batch 48, Loss: 0.088\n",
      "Training: Epoch 197, Batch 49, Loss: 0.057\n",
      "Training: Epoch 197, Batch 50, Loss: 0.082\n",
      "Training: Epoch 197, Batch 51, Loss: 0.083\n",
      "Training: Epoch 197, Batch 52, Loss: 0.063\n",
      "Training: Epoch 197, Batch 53, Loss: 0.07\n",
      "Training: Epoch 197, Batch 54, Loss: 0.072\n",
      "Training: Epoch 197, Batch 55, Loss: 0.066\n",
      "Training: Epoch 197, Batch 56, Loss: 0.069\n",
      "Training: Epoch 197, Batch 57, Loss: 0.071\n",
      "Training: Epoch 197, Batch 58, Loss: 0.066\n",
      "Training: Epoch 197, Batch 59, Loss: 0.081\n",
      "Training: Epoch 197, Batch 60, Loss: 0.093\n",
      "Training: Epoch 197, Batch 61, Loss: 0.094\n",
      "Training: Epoch 197, Batch 62, Loss: 0.071\n",
      "Training: Epoch 197, Batch 63, Loss: 0.062\n",
      "Training: Epoch 197, Batch 64, Loss: 0.088\n",
      "Training: Epoch 197, Batch 65, Loss: 0.069\n",
      "Training: Epoch 197, Batch 66, Loss: 0.079\n",
      "Training: Epoch 197, Batch 67, Loss: 0.072\n",
      "Training: Epoch 197, Batch 68, Loss: 0.079\n",
      "Training: Epoch 197, Batch 69, Loss: 0.053\n",
      "Training: Epoch 197, Batch 70, Loss: 0.079\n",
      "Training: Epoch 197, Batch 71, Loss: 0.105\n",
      "Training: Epoch 197, Batch 72, Loss: 0.08\n",
      "Training: Epoch 197, Batch 73, Loss: 0.064\n",
      "Training: Epoch 197, Batch 74, Loss: 0.098\n",
      "Training: Epoch 197, Batch 75, Loss: 0.091\n",
      "Training: Epoch 197, Batch 76, Loss: 0.104\n",
      "Training: Epoch 197, Batch 77, Loss: 0.091\n",
      "Training: Epoch 197, Batch 78, Loss: 0.064\n",
      "Training: Epoch 197, Batch 79, Loss: 0.087\n",
      "Training: Epoch 197, Batch 80, Loss: 0.072\n",
      "Training: Epoch 197, Batch 81, Loss: 0.08\n",
      "Training: Epoch 197, Batch 82, Loss: 0.085\n",
      "Training: Epoch 197, Batch 83, Loss: 0.095\n",
      "Training: Epoch 197, Batch 84, Loss: 0.065\n",
      "Training: Epoch 197, Batch 85, Loss: 0.078\n",
      "Training: Epoch 197, Batch 86, Loss: 0.084\n",
      "Training: Epoch 197, Batch 87, Loss: 0.075\n",
      "Training: Epoch 197, Batch 88, Loss: 0.09\n",
      "Training: Epoch 197, Batch 89, Loss: 0.106\n",
      "Val: Epoch 197, Loss: 0.377\n",
      "Training: Epoch 198, Batch 0, Loss: 0.079\n",
      "Training: Epoch 198, Batch 1, Loss: 0.063\n",
      "Training: Epoch 198, Batch 2, Loss: 0.093\n",
      "Training: Epoch 198, Batch 3, Loss: 0.081\n",
      "Training: Epoch 198, Batch 4, Loss: 0.073\n",
      "Training: Epoch 198, Batch 5, Loss: 0.067\n",
      "Training: Epoch 198, Batch 6, Loss: 0.084\n",
      "Training: Epoch 198, Batch 7, Loss: 0.092\n",
      "Training: Epoch 198, Batch 8, Loss: 0.098\n",
      "Training: Epoch 198, Batch 9, Loss: 0.063\n",
      "Training: Epoch 198, Batch 10, Loss: 0.113\n",
      "Training: Epoch 198, Batch 11, Loss: 0.081\n",
      "Training: Epoch 198, Batch 12, Loss: 0.078\n",
      "Training: Epoch 198, Batch 13, Loss: 0.06\n",
      "Training: Epoch 198, Batch 14, Loss: 0.083\n",
      "Training: Epoch 198, Batch 15, Loss: 0.074\n",
      "Training: Epoch 198, Batch 16, Loss: 0.083\n",
      "Training: Epoch 198, Batch 17, Loss: 0.106\n",
      "Training: Epoch 198, Batch 18, Loss: 0.082\n",
      "Training: Epoch 198, Batch 19, Loss: 0.072\n",
      "Training: Epoch 198, Batch 20, Loss: 0.091\n",
      "Training: Epoch 198, Batch 21, Loss: 0.088\n",
      "Training: Epoch 198, Batch 22, Loss: 0.066\n",
      "Training: Epoch 198, Batch 23, Loss: 0.072\n",
      "Training: Epoch 198, Batch 24, Loss: 0.07\n",
      "Training: Epoch 198, Batch 25, Loss: 0.058\n",
      "Training: Epoch 198, Batch 26, Loss: 0.088\n",
      "Training: Epoch 198, Batch 27, Loss: 0.088\n",
      "Training: Epoch 198, Batch 28, Loss: 0.093\n",
      "Training: Epoch 198, Batch 29, Loss: 0.072\n",
      "Training: Epoch 198, Batch 30, Loss: 0.077\n",
      "Training: Epoch 198, Batch 31, Loss: 0.066\n",
      "Training: Epoch 198, Batch 32, Loss: 0.089\n",
      "Training: Epoch 198, Batch 33, Loss: 0.06\n",
      "Training: Epoch 198, Batch 34, Loss: 0.065\n",
      "Training: Epoch 198, Batch 35, Loss: 0.069\n",
      "Training: Epoch 198, Batch 36, Loss: 0.071\n",
      "Training: Epoch 198, Batch 37, Loss: 0.084\n",
      "Training: Epoch 198, Batch 38, Loss: 0.096\n",
      "Training: Epoch 198, Batch 39, Loss: 0.089\n",
      "Training: Epoch 198, Batch 40, Loss: 0.083\n",
      "Training: Epoch 198, Batch 41, Loss: 0.097\n",
      "Training: Epoch 198, Batch 42, Loss: 0.101\n",
      "Training: Epoch 198, Batch 43, Loss: 0.088\n",
      "Training: Epoch 198, Batch 44, Loss: 0.078\n",
      "Training: Epoch 198, Batch 45, Loss: 0.093\n",
      "Training: Epoch 198, Batch 46, Loss: 0.078\n",
      "Training: Epoch 198, Batch 47, Loss: 0.084\n",
      "Training: Epoch 198, Batch 48, Loss: 0.066\n",
      "Training: Epoch 198, Batch 49, Loss: 0.063\n",
      "Training: Epoch 198, Batch 50, Loss: 0.059\n",
      "Training: Epoch 198, Batch 51, Loss: 0.077\n",
      "Training: Epoch 198, Batch 52, Loss: 0.092\n",
      "Training: Epoch 198, Batch 53, Loss: 0.084\n",
      "Training: Epoch 198, Batch 54, Loss: 0.075\n",
      "Training: Epoch 198, Batch 55, Loss: 0.108\n",
      "Training: Epoch 198, Batch 56, Loss: 0.055\n",
      "Training: Epoch 198, Batch 57, Loss: 0.096\n",
      "Training: Epoch 198, Batch 58, Loss: 0.053\n",
      "Training: Epoch 198, Batch 59, Loss: 0.077\n",
      "Training: Epoch 198, Batch 60, Loss: 0.067\n",
      "Training: Epoch 198, Batch 61, Loss: 0.106\n",
      "Training: Epoch 198, Batch 62, Loss: 0.087\n",
      "Training: Epoch 198, Batch 63, Loss: 0.081\n",
      "Training: Epoch 198, Batch 64, Loss: 0.08\n",
      "Training: Epoch 198, Batch 65, Loss: 0.119\n",
      "Training: Epoch 198, Batch 66, Loss: 0.081\n",
      "Training: Epoch 198, Batch 67, Loss: 0.073\n",
      "Training: Epoch 198, Batch 68, Loss: 0.065\n",
      "Training: Epoch 198, Batch 69, Loss: 0.056\n",
      "Training: Epoch 198, Batch 70, Loss: 0.074\n",
      "Training: Epoch 198, Batch 71, Loss: 0.083\n",
      "Training: Epoch 198, Batch 72, Loss: 0.089\n",
      "Training: Epoch 198, Batch 73, Loss: 0.058\n",
      "Training: Epoch 198, Batch 74, Loss: 0.055\n",
      "Training: Epoch 198, Batch 75, Loss: 0.068\n",
      "Training: Epoch 198, Batch 76, Loss: 0.077\n",
      "Training: Epoch 198, Batch 77, Loss: 0.064\n",
      "Training: Epoch 198, Batch 78, Loss: 0.076\n",
      "Training: Epoch 198, Batch 79, Loss: 0.075\n",
      "Training: Epoch 198, Batch 80, Loss: 0.089\n",
      "Training: Epoch 198, Batch 81, Loss: 0.075\n",
      "Training: Epoch 198, Batch 82, Loss: 0.073\n",
      "Training: Epoch 198, Batch 83, Loss: 0.052\n",
      "Training: Epoch 198, Batch 84, Loss: 0.07\n",
      "Training: Epoch 198, Batch 85, Loss: 0.11\n",
      "Training: Epoch 198, Batch 86, Loss: 0.086\n",
      "Training: Epoch 198, Batch 87, Loss: 0.078\n",
      "Training: Epoch 198, Batch 88, Loss: 0.088\n",
      "Training: Epoch 198, Batch 89, Loss: 0.071\n",
      "Val: Epoch 198, Loss: 0.369\n",
      "Training: Epoch 199, Batch 0, Loss: 0.067\n",
      "Training: Epoch 199, Batch 1, Loss: 0.074\n",
      "Training: Epoch 199, Batch 2, Loss: 0.1\n",
      "Training: Epoch 199, Batch 3, Loss: 0.084\n",
      "Training: Epoch 199, Batch 4, Loss: 0.096\n",
      "Training: Epoch 199, Batch 5, Loss: 0.069\n",
      "Training: Epoch 199, Batch 6, Loss: 0.082\n",
      "Training: Epoch 199, Batch 7, Loss: 0.089\n",
      "Training: Epoch 199, Batch 8, Loss: 0.073\n",
      "Training: Epoch 199, Batch 9, Loss: 0.058\n",
      "Training: Epoch 199, Batch 10, Loss: 0.066\n",
      "Training: Epoch 199, Batch 11, Loss: 0.052\n",
      "Training: Epoch 199, Batch 12, Loss: 0.083\n",
      "Training: Epoch 199, Batch 13, Loss: 0.08\n",
      "Training: Epoch 199, Batch 14, Loss: 0.07\n",
      "Training: Epoch 199, Batch 15, Loss: 0.064\n",
      "Training: Epoch 199, Batch 16, Loss: 0.076\n",
      "Training: Epoch 199, Batch 17, Loss: 0.059\n",
      "Training: Epoch 199, Batch 18, Loss: 0.078\n",
      "Training: Epoch 199, Batch 19, Loss: 0.091\n",
      "Training: Epoch 199, Batch 20, Loss: 0.08\n",
      "Training: Epoch 199, Batch 21, Loss: 0.091\n",
      "Training: Epoch 199, Batch 22, Loss: 0.09\n",
      "Training: Epoch 199, Batch 23, Loss: 0.073\n",
      "Training: Epoch 199, Batch 24, Loss: 0.076\n",
      "Training: Epoch 199, Batch 25, Loss: 0.089\n",
      "Training: Epoch 199, Batch 26, Loss: 0.082\n",
      "Training: Epoch 199, Batch 27, Loss: 0.082\n",
      "Training: Epoch 199, Batch 28, Loss: 0.089\n",
      "Training: Epoch 199, Batch 29, Loss: 0.104\n",
      "Training: Epoch 199, Batch 30, Loss: 0.059\n",
      "Training: Epoch 199, Batch 31, Loss: 0.07\n",
      "Training: Epoch 199, Batch 32, Loss: 0.084\n",
      "Training: Epoch 199, Batch 33, Loss: 0.08\n",
      "Training: Epoch 199, Batch 34, Loss: 0.077\n",
      "Training: Epoch 199, Batch 35, Loss: 0.076\n",
      "Training: Epoch 199, Batch 36, Loss: 0.072\n",
      "Training: Epoch 199, Batch 37, Loss: 0.076\n",
      "Training: Epoch 199, Batch 38, Loss: 0.067\n",
      "Training: Epoch 199, Batch 39, Loss: 0.071\n",
      "Training: Epoch 199, Batch 40, Loss: 0.109\n",
      "Training: Epoch 199, Batch 41, Loss: 0.099\n",
      "Training: Epoch 199, Batch 42, Loss: 0.077\n",
      "Training: Epoch 199, Batch 43, Loss: 0.103\n",
      "Training: Epoch 199, Batch 44, Loss: 0.079\n",
      "Training: Epoch 199, Batch 45, Loss: 0.08\n",
      "Training: Epoch 199, Batch 46, Loss: 0.088\n",
      "Training: Epoch 199, Batch 47, Loss: 0.081\n",
      "Training: Epoch 199, Batch 48, Loss: 0.081\n",
      "Training: Epoch 199, Batch 49, Loss: 0.094\n",
      "Training: Epoch 199, Batch 50, Loss: 0.071\n",
      "Training: Epoch 199, Batch 51, Loss: 0.057\n",
      "Training: Epoch 199, Batch 52, Loss: 0.097\n",
      "Training: Epoch 199, Batch 53, Loss: 0.065\n",
      "Training: Epoch 199, Batch 54, Loss: 0.086\n",
      "Training: Epoch 199, Batch 55, Loss: 0.06\n",
      "Training: Epoch 199, Batch 56, Loss: 0.057\n",
      "Training: Epoch 199, Batch 57, Loss: 0.106\n",
      "Training: Epoch 199, Batch 58, Loss: 0.065\n",
      "Training: Epoch 199, Batch 59, Loss: 0.066\n",
      "Training: Epoch 199, Batch 60, Loss: 0.104\n",
      "Training: Epoch 199, Batch 61, Loss: 0.066\n",
      "Training: Epoch 199, Batch 62, Loss: 0.07\n",
      "Training: Epoch 199, Batch 63, Loss: 0.077\n",
      "Training: Epoch 199, Batch 64, Loss: 0.06\n",
      "Training: Epoch 199, Batch 65, Loss: 0.081\n",
      "Training: Epoch 199, Batch 66, Loss: 0.088\n",
      "Training: Epoch 199, Batch 67, Loss: 0.091\n",
      "Training: Epoch 199, Batch 68, Loss: 0.097\n",
      "Training: Epoch 199, Batch 69, Loss: 0.069\n",
      "Training: Epoch 199, Batch 70, Loss: 0.07\n",
      "Training: Epoch 199, Batch 71, Loss: 0.078\n",
      "Training: Epoch 199, Batch 72, Loss: 0.099\n",
      "Training: Epoch 199, Batch 73, Loss: 0.074\n",
      "Training: Epoch 199, Batch 74, Loss: 0.134\n",
      "Training: Epoch 199, Batch 75, Loss: 0.104\n",
      "Training: Epoch 199, Batch 76, Loss: 0.064\n",
      "Training: Epoch 199, Batch 77, Loss: 0.106\n",
      "Training: Epoch 199, Batch 78, Loss: 0.078\n",
      "Training: Epoch 199, Batch 79, Loss: 0.084\n",
      "Training: Epoch 199, Batch 80, Loss: 0.093\n",
      "Training: Epoch 199, Batch 81, Loss: 0.071\n",
      "Training: Epoch 199, Batch 82, Loss: 0.072\n",
      "Training: Epoch 199, Batch 83, Loss: 0.051\n",
      "Training: Epoch 199, Batch 84, Loss: 0.075\n",
      "Training: Epoch 199, Batch 85, Loss: 0.085\n",
      "Training: Epoch 199, Batch 86, Loss: 0.092\n",
      "Training: Epoch 199, Batch 87, Loss: 0.074\n",
      "Training: Epoch 199, Batch 88, Loss: 0.055\n",
      "Training: Epoch 199, Batch 89, Loss: 0.091\n",
      "Val: Epoch 199, Loss: 0.374\n",
      "Training: Epoch 200, Batch 0, Loss: 0.082\n",
      "Training: Epoch 200, Batch 1, Loss: 0.073\n",
      "Training: Epoch 200, Batch 2, Loss: 0.103\n",
      "Training: Epoch 200, Batch 3, Loss: 0.062\n",
      "Training: Epoch 200, Batch 4, Loss: 0.093\n",
      "Training: Epoch 200, Batch 5, Loss: 0.086\n",
      "Training: Epoch 200, Batch 6, Loss: 0.091\n",
      "Training: Epoch 200, Batch 7, Loss: 0.08\n",
      "Training: Epoch 200, Batch 8, Loss: 0.091\n",
      "Training: Epoch 200, Batch 9, Loss: 0.077\n",
      "Training: Epoch 200, Batch 10, Loss: 0.077\n",
      "Training: Epoch 200, Batch 11, Loss: 0.068\n",
      "Training: Epoch 200, Batch 12, Loss: 0.091\n",
      "Training: Epoch 200, Batch 13, Loss: 0.077\n",
      "Training: Epoch 200, Batch 14, Loss: 0.071\n",
      "Training: Epoch 200, Batch 15, Loss: 0.078\n",
      "Training: Epoch 200, Batch 16, Loss: 0.078\n",
      "Training: Epoch 200, Batch 17, Loss: 0.086\n",
      "Training: Epoch 200, Batch 18, Loss: 0.081\n",
      "Training: Epoch 200, Batch 19, Loss: 0.063\n",
      "Training: Epoch 200, Batch 20, Loss: 0.067\n",
      "Training: Epoch 200, Batch 21, Loss: 0.07\n",
      "Training: Epoch 200, Batch 22, Loss: 0.062\n",
      "Training: Epoch 200, Batch 23, Loss: 0.07\n",
      "Training: Epoch 200, Batch 24, Loss: 0.078\n",
      "Training: Epoch 200, Batch 25, Loss: 0.111\n",
      "Training: Epoch 200, Batch 26, Loss: 0.065\n",
      "Training: Epoch 200, Batch 27, Loss: 0.087\n",
      "Training: Epoch 200, Batch 28, Loss: 0.078\n",
      "Training: Epoch 200, Batch 29, Loss: 0.053\n",
      "Training: Epoch 200, Batch 30, Loss: 0.111\n",
      "Training: Epoch 200, Batch 31, Loss: 0.065\n",
      "Training: Epoch 200, Batch 32, Loss: 0.081\n",
      "Training: Epoch 200, Batch 33, Loss: 0.08\n",
      "Training: Epoch 200, Batch 34, Loss: 0.072\n",
      "Training: Epoch 200, Batch 35, Loss: 0.084\n",
      "Training: Epoch 200, Batch 36, Loss: 0.055\n",
      "Training: Epoch 200, Batch 37, Loss: 0.077\n",
      "Training: Epoch 200, Batch 38, Loss: 0.073\n",
      "Training: Epoch 200, Batch 39, Loss: 0.076\n",
      "Training: Epoch 200, Batch 40, Loss: 0.096\n",
      "Training: Epoch 200, Batch 41, Loss: 0.074\n",
      "Training: Epoch 200, Batch 42, Loss: 0.067\n",
      "Training: Epoch 200, Batch 43, Loss: 0.082\n",
      "Training: Epoch 200, Batch 44, Loss: 0.071\n",
      "Training: Epoch 200, Batch 45, Loss: 0.081\n",
      "Training: Epoch 200, Batch 46, Loss: 0.062\n",
      "Training: Epoch 200, Batch 47, Loss: 0.07\n",
      "Training: Epoch 200, Batch 48, Loss: 0.09\n",
      "Training: Epoch 200, Batch 49, Loss: 0.081\n",
      "Training: Epoch 200, Batch 50, Loss: 0.075\n",
      "Training: Epoch 200, Batch 51, Loss: 0.086\n",
      "Training: Epoch 200, Batch 52, Loss: 0.063\n",
      "Training: Epoch 200, Batch 53, Loss: 0.086\n",
      "Training: Epoch 200, Batch 54, Loss: 0.082\n",
      "Training: Epoch 200, Batch 55, Loss: 0.09\n",
      "Training: Epoch 200, Batch 56, Loss: 0.083\n",
      "Training: Epoch 200, Batch 57, Loss: 0.074\n",
      "Training: Epoch 200, Batch 58, Loss: 0.082\n",
      "Training: Epoch 200, Batch 59, Loss: 0.08\n",
      "Training: Epoch 200, Batch 60, Loss: 0.08\n",
      "Training: Epoch 200, Batch 61, Loss: 0.108\n",
      "Training: Epoch 200, Batch 62, Loss: 0.131\n",
      "Training: Epoch 200, Batch 63, Loss: 0.073\n",
      "Training: Epoch 200, Batch 64, Loss: 0.077\n",
      "Training: Epoch 200, Batch 65, Loss: 0.067\n",
      "Training: Epoch 200, Batch 66, Loss: 0.086\n",
      "Training: Epoch 200, Batch 67, Loss: 0.095\n",
      "Training: Epoch 200, Batch 68, Loss: 0.083\n",
      "Training: Epoch 200, Batch 69, Loss: 0.089\n",
      "Training: Epoch 200, Batch 70, Loss: 0.063\n",
      "Training: Epoch 200, Batch 71, Loss: 0.066\n",
      "Training: Epoch 200, Batch 72, Loss: 0.07\n",
      "Training: Epoch 200, Batch 73, Loss: 0.079\n",
      "Training: Epoch 200, Batch 74, Loss: 0.071\n",
      "Training: Epoch 200, Batch 75, Loss: 0.1\n",
      "Training: Epoch 200, Batch 76, Loss: 0.068\n",
      "Training: Epoch 200, Batch 77, Loss: 0.081\n",
      "Training: Epoch 200, Batch 78, Loss: 0.068\n",
      "Training: Epoch 200, Batch 79, Loss: 0.097\n",
      "Training: Epoch 200, Batch 80, Loss: 0.075\n",
      "Training: Epoch 200, Batch 81, Loss: 0.08\n",
      "Training: Epoch 200, Batch 82, Loss: 0.061\n",
      "Training: Epoch 200, Batch 83, Loss: 0.067\n",
      "Training: Epoch 200, Batch 84, Loss: 0.065\n",
      "Training: Epoch 200, Batch 85, Loss: 0.081\n",
      "Training: Epoch 200, Batch 86, Loss: 0.09\n",
      "Training: Epoch 200, Batch 87, Loss: 0.064\n",
      "Training: Epoch 200, Batch 88, Loss: 0.063\n",
      "Training: Epoch 200, Batch 89, Loss: 0.078\n",
      "Val: Epoch 200, Loss: 0.371\n",
      "Best model found at epoch 41\n",
      "Total training time: 5916.865437746048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\Documents\\MasterProject590\\code\\demos\\Project2\\semseg_functions.py:315: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_list[-1],map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./seg_models\\best_transunet_model.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96    937035\n",
      "           1       0.92      0.86      0.89   1187442\n",
      "           2       0.75      0.92      0.83    496963\n",
      "\n",
      "    accuracy                           0.90   2621440\n",
      "   macro avg       0.88      0.91      0.89   2621440\n",
      "weighted avg       0.91      0.90      0.90   2621440\n",
      "\n",
      "Training loss: 0.22307865023612977\n"
     ]
    }
   ],
   "source": [
    "#now train with train+fake, augmented\n",
    "X_train_aug_fake, Y_train_aug_fake = augment_train(X_train_with_fake, Y_train_with_fake, augment_times=2)\n",
    "\n",
    "print(\"X_train_aug shape:\", X_train_aug_fake.shape)\n",
    "print(\"Y_train_aug shape:\", Y_train_aug_fake.shape)\n",
    "\n",
    "#X_train,Y_train,X_val,Y_val=load_imgs_labels()\n",
    "#model=train_model_transunet(X_train,Y_train,X_val,Y_val)\n",
    "start_time = time.time()\n",
    "model, best_model_loss=train_model_transunet(X_train_aug_fake,Y_train_aug_fake,X_val,Y_val, lr= 0.003, momentum= 0.9, weight_decay= 0.01)\n",
    "end_time = time.time()\n",
    "print(\"Total training time:\", end_time-start_time)\n",
    "y_val_pred=make_predictions_transunet(X_val,model=None)\n",
    "y_val_pred_lbls=y_val_pred.argmax(1)\n",
    "print(classification_report(Y_val.numpy().flatten(),y_val_pred_lbls.flatten()))\n",
    "#print loss\n",
    "print(\"Training loss:\", best_model_loss)\n",
    "\n",
    "\n",
    "# Flatten prediction: shape (B, C, H, W) → (N, C)\n",
    "y_val_pred_flat = y_val_pred.transpose(0, 2, 3, 1).reshape(-1, y_val_pred.shape[1])\n",
    "\n",
    "# Flatten true labels: shape (B, H, W) → (N,)\n",
    "y_true = Y_val.numpy().flatten()\n",
    "\n",
    "# Binarize true labels for multiclass AUROC\n",
    "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(y_true_binarized, y_val_pred_flat, multi_class='ovr')\n",
    "\n",
    "print(\"AUROC:\", auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdce84-a7b4-4c84-98b8-cdc50a90050d",
   "metadata": {},
   "source": [
    "Follow this tutorial: https://github.com/jlevy44/medstudent_resident_informatics_tutorials/blob/main/1_image_analysis/2_image_segmentation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27418981-7cac-47c0-9970-cbd32fd372c5",
   "metadata": {},
   "source": [
    "# Load specimens data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a54fc3-5c3f-440a-9044-5406b77436dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sps=pd.read_pickle(\"specimens_toy_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969973e-4a48-48c5-9ebe-442873bc77a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.concat([sps[k][\"metadata\"].assign(class_=lambda x: k) for k in sps])\n",
    "df[\"class_\"]=pd.Categorical(df[\"class_\"],[\"neg\",\"aty\",\"sus\",\"pos\"])\n",
    "    #[\"nc_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd62a3e-fa18-402e-bd68-402f902de097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"class_\",y=\"nc_ratio\",data=df)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7b9d8-e790-423e-9417-0bd4d8377141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2921c760890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sps[\"neg\"][\"imgs\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60986c4-5d87-4168-803e-9cce9e776f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "resize = lambda x: cv2.resize(x,(256,256),interpolation=cv2.INTER_CUBIC)\n",
    "all_images=reduce(lambda x,y: x+y,[list(map(resize,sps[k][\"imgs\"])) for k in sps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc6fdc-dd97-4dbd-a8d5-6923b22fdb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aty</th>\n",
       "      <th>nc_ratio</th>\n",
       "      <th>nuclear_area</th>\n",
       "      <th>cyto_area</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057022</td>\n",
       "      <td>0.141928</td>\n",
       "      <td>7221.0</td>\n",
       "      <td>43657.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037513</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>7597.0</td>\n",
       "      <td>35660.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056971</td>\n",
       "      <td>0.150782</td>\n",
       "      <td>7442.0</td>\n",
       "      <td>41914.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077020</td>\n",
       "      <td>0.182437</td>\n",
       "      <td>8177.0</td>\n",
       "      <td>36644.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111039</td>\n",
       "      <td>0.183712</td>\n",
       "      <td>8696.0</td>\n",
       "      <td>38639.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.143248</td>\n",
       "      <td>0.359070</td>\n",
       "      <td>16533.0</td>\n",
       "      <td>29511.0</td>\n",
       "      <td>sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.304277</td>\n",
       "      <td>14783.0</td>\n",
       "      <td>33801.0</td>\n",
       "      <td>sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.519353</td>\n",
       "      <td>0.424544</td>\n",
       "      <td>21172.0</td>\n",
       "      <td>28698.0</td>\n",
       "      <td>sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.498367</td>\n",
       "      <td>0.386391</td>\n",
       "      <td>15150.0</td>\n",
       "      <td>24059.0</td>\n",
       "      <td>sus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.226941</td>\n",
       "      <td>0.327733</td>\n",
       "      <td>14786.0</td>\n",
       "      <td>30330.0</td>\n",
       "      <td>sus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aty  nc_ratio  nuclear_area  cyto_area class_\n",
       "0   0.057022  0.141928        7221.0    43657.0    neg\n",
       "1   0.037513  0.175625        7597.0    35660.0    neg\n",
       "2   0.056971  0.150782        7442.0    41914.0    neg\n",
       "3   0.077020  0.182437        8177.0    36644.0    neg\n",
       "4   0.111039  0.183712        8696.0    38639.0    neg\n",
       "..       ...       ...           ...        ...    ...\n",
       "20  0.143248  0.359070       16533.0    29511.0    sus\n",
       "21  0.079847  0.304277       14783.0    33801.0    sus\n",
       "22  0.519353  0.424544       21172.0    28698.0    sus\n",
       "23  0.498367  0.386391       15150.0    24059.0    sus\n",
       "24  0.226941  0.327733       14786.0    30330.0    sus\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describes above images, assess performance for NC ratio, class assignment, etc\n",
    "df.head(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf04570-09f3-4561-ae52-82ecbe566bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         aty  nc_ratio  nuclear_area  cyto_area class_\n",
      "0   0.057022  0.141928        7221.0    43657.0    neg\n",
      "1   0.037513  0.175625        7597.0    35660.0    neg\n",
      "2   0.056971  0.150782        7442.0    41914.0    neg\n",
      "3   0.077020  0.182437        8177.0    36644.0    neg\n",
      "4   0.111039  0.183712        8696.0    38639.0    neg\n",
      "..       ...       ...           ...        ...    ...\n",
      "20  0.143248  0.359070       16533.0    29511.0    sus\n",
      "21  0.079847  0.304277       14783.0    33801.0    sus\n",
      "22  0.519353  0.424544       21172.0    28698.0    sus\n",
      "23  0.498367  0.386391       15150.0    24059.0    sus\n",
      "24  0.226941  0.327733       14786.0    30330.0    sus\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['neg', 'pos', 'aty', 'sus'])\n",
      "dict_keys(['imgs', 'metadata'])\n",
      "(44, 34, 3)\n",
      "neg has 25 images\n",
      "pos has 25 images\n",
      "aty has 25 images\n",
      "sus has 25 images\n",
      "Index(['aty', 'nc_ratio', 'nuclear_area', 'cyto_area'], dtype='object')\n",
      "RangeIndex(start=0, stop=25, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(sps.keys())\n",
    "#print nested keys\n",
    "print(sps[\"neg\"].keys())\n",
    "#print shape of imgs\n",
    "print(sps[\"neg\"][\"imgs\"][0].shape)\n",
    "#for all classes\n",
    "for k in sps:\n",
    "    print(f\"{k} has {len(sps[k]['imgs'])} images\")\n",
    "#print keys for metadata\n",
    "print(sps[\"neg\"][\"metadata\"].keys())\n",
    "#check if classes have keys\n",
    "print(sps[\"neg\"][\"metadata\"][\"nc_ratio\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070cf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"class_\",y=\"nuclear_area\",data=df)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23282559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"class_\",y=\"cyto_area\",data=df)\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
